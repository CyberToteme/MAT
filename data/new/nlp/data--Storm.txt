SATD	 todo support multiple levels includes 
SATD	 when all nimbodes down and one few them come unfortunately there might not exact way know which one contains the most updated blob 
SATD	 todo this assumes key only from the one field not need have order fields 
SATD	 the following code duplicated the constructor mqttpublisher reproduce here fail the client side ssl misconfigured rather than when the topology deployed the cluster 
SATD	 should remove the third blob because the first has the reset timestamp 
SATD	 get rid multiple url 
SATD	 todo track file offsets instead line number 
SATD	 todo support more configuration options for now were defaulting the hbasexml files found the classpath 
SATD	 this bit ugly but works order maintain the same directory structure that existed before need have storm conf storm jar and storm code shared directory and need set the permissions for that entire directory but the tracking per item basis are going end running the permission modification code once for each blob that downloaded times this case because the permission modification code runs separate process are doing global lock avoid any races between multiple versions running the same time ideally this would per topology basis but that lot harder and the changes run fairly quickly should not big deal 
SATD	 could not find fully compatible version look see there possibly compatible version right below 
SATD	 resourceutilsjava not available the classpath let parse out the resources want 
SATD	 filesmove with nonempty directory doesnt work well windows this not atomic but does work 
SATD	 not thread safe have one instance per producer thread synchronize externally 
SATD	 todo substitution implementation not exactly efficient kind memory 
SATD	 todo need better way this 
SATD	 todo need able set the tick tuple time the message timeout ideally without parameterization 
SATD	 connection unavailable will drop pending messages and let atleastonce message replay kick another option would buffer the messages memory but this option has the risk causing oom errors especially for topologies that disable message acking because dont know whether the connection recovery will succeed not and how long the recovery will take 
SATD	 todo consider adding shuffle grouping after the spout avoid much routing the argsreturninfo all over the place least until its possible just pack bolt logic into the spout itself 
SATD	 this hack for nonras scheduler topology and worker resources 
SATD	 todo move this logic the model class 
SATD	 for some reason the new code ackers null get 
SATD	 this bit hack list then component stream want format this componentstream 
SATD	 todo dry this code with whats 
SATD	 should fail the tuple kill the worker 
SATD	 todo streams should uniquely identifiable 
SATD	 todo would love standardize this 
SATD	 fixme this class can moved webapp once porting done 
SATD	 this isnt strictly necessary but doesnt hurt and ensures that the machine stays date even callbacks dont all work exactly right 
SATD	 work around should get alternative working way 
SATD	 the topology zookeeper authentication configuration unset 
SATD	 read last this should cause evicted next put 
SATD	 todo more collection content type checking 
SATD	 fixme were using default config since cannot serialized still needs provide some options externally 
SATD	 todo this can only ever null someone doing something odd with mocking should really fix the mocking and remove this 
SATD	 todo put some better exception mapping todo move populatecontext filter 
SATD	 should fail the batch kill the worker 
SATD	 getting the exact response code bit more complex todo should use better client 
SATD	 todo should worker even take the topologyid input this should deducible from cluster state searching through assignments what about theres inconsistency assignments but nimbus should guarantee this consistency param conf storm configuration param context param topologyid topology param assignmentid assignment param supervisorport parent supervisor thrift server port param port port which the worker runs param workerid worker 
SATD	 this bit ugly but shows how this would happen worker will use the same apis 
SATD	 fixme stores map topoconf topologycontext and expose these derived classes 
SATD	 original implementation doesnt actually check delete succeeded not 
SATD	 doesnt seem like you should have this but java serialization wacky and doesnt call the default constructor 
SATD	 this bit ugly the json are expecting should the form component resource value but because value coming from json going number and want double the goal through each entry and update accordingly 
SATD	 may though unlikely lose metering here state transition too frequent less than millisecond 
SATD	 want throw exception path doesnt exist 
SATD	 todo better way this would great 
SATD	 todo the future this might better common webapp location 
SATD	 fixme should moved stormclient when can removed 
SATD	 todo figure out how want deal with overrides users may want add streams even when overriding other properties for now just add them blindly which could lead potentially invalid topology 
SATD	 more accurate that threadsleep but still not great 
SATD	 todo ignore the master batch coordinator 
SATD	 this test rather ugly but the only way see the error messages are working correctly 
SATD	 todo need able replace existing fields with the function fields like cascading fieldsreplace 
SATD	 todo wrap this set the stream name 
SATD	 todo this isnt right its not the map anymore 
SATD	 todo add method for drpc stream needs know how automatically return results etc too expensive batch per drpc request 
SATD	 todo the inner join incrementally emitting the cross join with this tuple against all other sides todo only cross join least one tuple each side 
SATD	 todo once everything java this should not possible any more 
SATD	 heck for backward compatibility need pass hbase conf the conf instance instance persistentmap making copy 
SATD	 this hack allow zookeepermain called this command 
SATD	 perhaps there better way this 
SATD	 todo can optimize further only querying backing map for keys not the cache 
SATD	 todo this causing issues 
SATD	 todo need invoke hook provided the topology giving chance create user resources this would part the initialization hook need separate into workercontext and workerusercontext actually just via interfaces just need make sure hide setresource from tasks 
SATD	 not implemented 
SATD	 todo what would good test ensure that least somewhat defensively copied 
SATD	 todo the future want way include this logic the spout itself make unnecessary having storm include metadata about which grouping tuple came from 
SATD	 todo does this work well windows 
SATD	 filecontext supports atomic rename whereas filesystem doesnt 
SATD	 not enough guaranteed use the age the topology instead todo need good way only this once 
SATD	 use parsewithexception instead parse can capture deserialization errors the log they are likely bugs the spout code 
SATD	 todo take away knowledge storms internals here 
SATD	 todo should handle ref 
SATD	 todo make sure test these two functions manual tests 
SATD	 todo get this from type instead hardcoding nimbus establish clientserver transport via plugin 
SATD	 there bug some versions that returns for the uptime 
SATD	 need set active false before calling onkill current implementation does not return 
SATD	 this kind unnecessary for clojure 
SATD	 todo this class reserved for supporting messages with different schemas current only one schema the cache 
SATD	 bad files dir config 
SATD	 fixme can filter listkeys with local blobstore when storm going resolved workaround call getblobmeta for all keys 
SATD	 min this really means something wrong even very slow node 
SATD	 todo check for null grouping args 
SATD	 todo perhaps can adjust the frequency later 
SATD	 reestablish connection eventhub servers using the right offset tbd might optimized with cache 
SATD	 todo handle the case where there may schema 
SATD	 seems safer not follow symlinks since dont expect them here 
SATD	 this because json doesnt allow numbers keys todo replace json with better form encoding 
SATD	 todo optimize this computation perhaps inner loop can outside avoid rescanning tuples 
SATD	 likely because bug try get another way 
WITHOUT_CLASSIFICATION	 while disabling retain the sampling pct 
WITHOUT_CLASSIFICATION	 hearbeat upon 
WITHOUT_CLASSIFICATION	 requestedmemonheap 
WITHOUT_CLASSIFICATION	 test environment variable substitution 
WITHOUT_CLASSIFICATION	 assignments 
WITHOUT_CLASSIFICATION	 verify that all messages are emitted ack all the messages 
WITHOUT_CLASSIFICATION	 executioncommand 
WITHOUT_CLASSIFICATION	 boolean track deactivated state 
WITHOUT_CLASSIFICATION	 track punctuation nonbatch mode that the punctuation acked after all the processors have emitted the punctuation downstream 
WITHOUT_CLASSIFICATION	 local executors and localtaskids running this worker 
WITHOUT_CLASSIFICATION	 only emit have declared fields 
WITHOUT_CLASSIFICATION	 all types files included 
WITHOUT_CLASSIFICATION	 want capture the full time range the target size had one bucket less then 
WITHOUT_CLASSIFICATION	 use batch size that matches the default credit size 
WITHOUT_CLASSIFICATION	 use the local setting for the login config rather than the topologys 
WITHOUT_CLASSIFICATION	 get the nimbodes with the latest version 
WITHOUT_CLASSIFICATION	 destination taskid 
WITHOUT_CLASSIFICATION	 component 
WITHOUT_CLASSIFICATION	 fail the last emitted tuple and verify that the spout wont retry because its above the emit limit 
WITHOUT_CLASSIFICATION	 generate null response then authentication has completed not warn and return without sending response back the server 
WITHOUT_CLASSIFICATION	 supervisor assignment idsupervisor 
WITHOUT_CLASSIFICATION	 the windowmanager scan loop early 
WITHOUT_CLASSIFICATION	 failed send the jms message fail the tuple fast 
WITHOUT_CLASSIFICATION	 set the first assignment 
WITHOUT_CLASSIFICATION	 root 
WITHOUT_CLASSIFICATION	 update the count the state here the first argument the initial value for the count and the second argument function that increments the count for each value received 
WITHOUT_CLASSIFICATION	 test write 
WITHOUT_CLASSIFICATION	 key 
WITHOUT_CLASSIFICATION	 topologyid 
WITHOUT_CLASSIFICATION	 start emitting right now 
WITHOUT_CLASSIFICATION	 format date worker logs 
WITHOUT_CLASSIFICATION	 map 
WITHOUT_CLASSIFICATION	 use different blobstore dir doesnt conflict with other test 
WITHOUT_CLASSIFICATION	 timestamp either milliseconds seconds which this metric occurred 
WITHOUT_CLASSIFICATION	 noop 
WITHOUT_CLASSIFICATION	 update the current count for this object 
WITHOUT_CLASSIFICATION	 ranked fourth since rack has alot memory but not cpu 
WITHOUT_CLASSIFICATION	 each controlmessage encoded code short each taskmessage encoded task short len int payload byte 
WITHOUT_CLASSIFICATION	 this call returns immediately 
WITHOUT_CLASSIFICATION	 for testing 
WITHOUT_CLASSIFICATION	 test test when more workers are available due topology worker max heap size limit but there memory still available wordspout going contain executors that needs scheduling each those executors has memory requirement the cluster contains free workerslots for this topolology each worker limited max heap size thus one executor not going able get scheduled thus failing the scheduling this topology and executors this 
WITHOUT_CLASSIFICATION	 set clean time really high doesnt kick 
WITHOUT_CLASSIFICATION	 set for nimbus only 
WITHOUT_CLASSIFICATION	 lag 
WITHOUT_CLASSIFICATION	 creates arraylargestid filled with nulls 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 close the input stream 
WITHOUT_CLASSIFICATION	 dependency uploading only makes sense for distributed mode 
WITHOUT_CLASSIFICATION	 read line and ack 
WITHOUT_CLASSIFICATION	 usedcpu 
WITHOUT_CLASSIFICATION	 failed tuples retried then send tuples from hdfs 
WITHOUT_CLASSIFICATION	 happens when part just rather than denoting some directory 
WITHOUT_CLASSIFICATION	 next verify that the blob store correct before start 
WITHOUT_CLASSIFICATION	 the connection ready once the channel active see 
WITHOUT_CLASSIFICATION	 test for keylist download 
WITHOUT_CLASSIFICATION	 tuples should available store before they are added window manager 
WITHOUT_CLASSIFICATION	 memory required topot memory required topot 
WITHOUT_CLASSIFICATION	 this dsl yaml etc topology 
WITHOUT_CLASSIFICATION	 check for required fields check for substruct validity 
WITHOUT_CLASSIFICATION	 periodically calls refreshload sec simulate worker load update timer 
WITHOUT_CLASSIFICATION	 remotetaskid jcqueue some entries maybe null emits those tasksids from this worker 
WITHOUT_CLASSIFICATION	 encoders 
WITHOUT_CLASSIFICATION	 commit frequency count 
WITHOUT_CLASSIFICATION	 check iterable 
WITHOUT_CLASSIFICATION	 set acl below that can shared other users well but allows only read 
WITHOUT_CLASSIFICATION	 emit any remaining messages 
WITHOUT_CLASSIFICATION	 autohdfs specified not attempt login using keytabs only kept for backward compatibility 
WITHOUT_CLASSIFICATION	 ack 
WITHOUT_CLASSIFICATION	 task ids should pulled first 
WITHOUT_CLASSIFICATION	 referenced from metric 
WITHOUT_CLASSIFICATION	 pulse 
WITHOUT_CLASSIFICATION	 add reference one and then remove reference again has newer timestamp 
WITHOUT_CLASSIFICATION	 writes multiple metric values into the database batch operation the tree map keeps the keys sorted 
WITHOUT_CLASSIFICATION	 get first and last block times for multiple runs and strategies 
WITHOUT_CLASSIFICATION	 the worker and running check for profiling requests 
WITHOUT_CLASSIFICATION	 the other config does not have set 
WITHOUT_CLASSIFICATION	 memoffheap 
WITHOUT_CLASSIFICATION	 capacity 
WITHOUT_CLASSIFICATION	 new line beginning each line instead end for better recovery from 
WITHOUT_CLASSIFICATION	 exceptions are captured and thrown the end the batch the executor 
WITHOUT_CLASSIFICATION	 this thread will send out messages destined for remote tasks other workers 
WITHOUT_CLASSIFICATION	 another conversion lets just make this all common 
WITHOUT_CLASSIFICATION	 store the time which the query started executing the sql standard says that functions such currenttimestamp return the same value throughout the query 
WITHOUT_CLASSIFICATION	 maintain backward compatibility for 
WITHOUT_CLASSIFICATION	 checkpoint the state every seconds 
WITHOUT_CLASSIFICATION	 cannot launch the container yet the resources may still updating 
WITHOUT_CLASSIFICATION	 use bootstrap tuple wait for topology running 
WITHOUT_CLASSIFICATION	 aze 
WITHOUT_CLASSIFICATION	 spout cpu gpu bolt cpu gpu bolt cpu gpu total cpu gpu this node has cpu gpu left 
WITHOUT_CLASSIFICATION	 this case will arise case nonsequential offset being processed the topic doesnt contain offset nextcommitoffset possible the topic compacted deleted the consumer should jump the next logical point the topic next logical offset should the first element after nextcommitoffset the ascending ordered emitted set 
WITHOUT_CLASSIFICATION	 topology can set resources terms cpu and memory for each component 
WITHOUT_CLASSIFICATION	 add with past 
WITHOUT_CLASSIFICATION	 when moving pacemaker workerbeats can leaked too 
WITHOUT_CLASSIFICATION	 seconds 
WITHOUT_CLASSIFICATION	 race condition with another thread and lost try again 
WITHOUT_CLASSIFICATION	 the producers are shut down first keep going until the queue empty 
WITHOUT_CLASSIFICATION	 dont allow any cluster wide configuration 
WITHOUT_CLASSIFICATION	 evicted metadata needs stored immediately metadata lookups count being the cache 
WITHOUT_CLASSIFICATION	 will have the correct settings that cannot overriden the submitter 
WITHOUT_CLASSIFICATION	 map describing which topologies are using which slots this node the format the map the following 
WITHOUT_CLASSIFICATION	 track how many times each supervisor slot has been listed bad 
WITHOUT_CLASSIFICATION	 when they are successfully processed 
WITHOUT_CLASSIFICATION	 all sent events are stored pending 
WITHOUT_CLASSIFICATION	 topo has large tasks 
WITHOUT_CLASSIFICATION	 ignore any exceptions might doing test for authentication 
WITHOUT_CLASSIFICATION	 first failure the initial delay not interesting 
WITHOUT_CLASSIFICATION	 boltspecific configuration for windowed bolts specify the window length time duration 
WITHOUT_CLASSIFICATION	 resourcesmap 
WITHOUT_CLASSIFICATION	 contains one tuple per stream being joined refs fields that will part output fields 
WITHOUT_CLASSIFICATION	 remote subject 
WITHOUT_CLASSIFICATION	 default parser uses for quoting identifiers switching dqid double quoted identifiers needed for array and map access arr etc work 
WITHOUT_CLASSIFICATION	 the second tuple should not ackd because the batch should cleared and this will 
WITHOUT_CLASSIFICATION	 need adjust the throughput accordingly that stays the same aggregate 
WITHOUT_CLASSIFICATION	 test scheduling does not cause negative resources 
WITHOUT_CLASSIFICATION	 return now without sending upstream here since client not authorized 
WITHOUT_CLASSIFICATION	 reader 
WITHOUT_CLASSIFICATION	 ranked first since rack has the most balanced set resources 
WITHOUT_CLASSIFICATION	 configs 
WITHOUT_CLASSIFICATION	 waiting returned 
WITHOUT_CLASSIFICATION	 validate path defined 
WITHOUT_CLASSIFICATION	 blostore launch command with topology blobstore map here are giving local name that can read from the file binstorm jar 
WITHOUT_CLASSIFICATION	 for some odd reason they are leaked 
WITHOUT_CLASSIFICATION	 get topology constraints 
WITHOUT_CLASSIFICATION	 ensure the second file has later modified timestamp the spout should pick the first file first 
WITHOUT_CLASSIFICATION	 launch heartbeat threads immediately that slowloading tasks dont cause the worker timeout 
WITHOUT_CLASSIFICATION	 tuple contains string object json format 
WITHOUT_CLASSIFICATION	 returns list tuple key val from table val from row 
WITHOUT_CLASSIFICATION	 bolt cpu gpu total cpu gpu this node has cpu gpu left 
WITHOUT_CLASSIFICATION	 the priority topology describes the importance the topology decreasing importance starting from the highest priority and the priority importance decreases the priority number increases recommended range but hard limit set there are not enough resources cluster the priority combination with how far over guarantees 
WITHOUT_CLASSIFICATION	 the second tuple used wait for the spout rotate its pending map 
WITHOUT_CLASSIFICATION	 does the actual ack when the state saved 
WITHOUT_CLASSIFICATION	 unknown version should treated current version which supports rpc heartbeat 
WITHOUT_CLASSIFICATION	 there are few possible files that would want clean basedir tmp basename basedir tmp basename current basedir basenameversion basedir basenamecurrent basedir basenameversion general always want delete the tmp files they are there 
WITHOUT_CLASSIFICATION	 check for case someone called their user user name this line contains the user name for the pid were looking example line user name 
WITHOUT_CLASSIFICATION	 need reverse the order elements delete files from oldest newest 
WITHOUT_CLASSIFICATION	 ignored the file did not match 
WITHOUT_CLASSIFICATION	 cleanup internal assignments 
WITHOUT_CLASSIFICATION	 jms options 
WITHOUT_CLASSIFICATION	 has been acked 
WITHOUT_CLASSIFICATION	 check exec satisfy spread 
WITHOUT_CLASSIFICATION	 event sent checkpoint shall created 
WITHOUT_CLASSIFICATION	 dynamic fields 
WITHOUT_CLASSIFICATION	 wait for more acks before proceeding 
WITHOUT_CLASSIFICATION	 get query filter 
WITHOUT_CLASSIFICATION	 allocate another array switched 
WITHOUT_CLASSIFICATION	 jump 
WITHOUT_CLASSIFICATION	 verify that offset was last committed offset since this the offset the spout should resume 
WITHOUT_CLASSIFICATION	 modprinc maxlife mins principal kadmin 
WITHOUT_CLASSIFICATION	 acquire lock file 
WITHOUT_CLASSIFICATION	 now selecting from the full set should cause the fourth task chosen 
WITHOUT_CLASSIFICATION	 node 
WITHOUT_CLASSIFICATION	 prevstatus 
WITHOUT_CLASSIFICATION	 configs 
WITHOUT_CLASSIFICATION	 the new partition should discovered and the message should emitted 
WITHOUT_CLASSIFICATION	 error message returned something went wrong 
WITHOUT_CLASSIFICATION	 the failed executions should not cause rotations and any new files 
WITHOUT_CLASSIFICATION	 producers 
WITHOUT_CLASSIFICATION	 only logset when theres been change the assignment 
WITHOUT_CLASSIFICATION	 singlerel 
WITHOUT_CLASSIFICATION	 only some data has arrived each input stream 
WITHOUT_CLASSIFICATION	 ack for message that failed once least and was reemitted then the record itself will use that determine the needs told about and then remove the record itself 
WITHOUT_CLASSIFICATION	 metric name 
WITHOUT_CLASSIFICATION	 bolt cpu gpu bolt cpu gpu bolt cpu gpu total cpu gpu this node has cpu gpu left 
WITHOUT_CLASSIFICATION	 componentexecutors 
WITHOUT_CLASSIFICATION	 the manually set config supervisor will overwrite resources assigned 
WITHOUT_CLASSIFICATION	 when this master not leader and get heartbeats report from supervisornode just ignore 
WITHOUT_CLASSIFICATION	 try locking another file the same time 
WITHOUT_CLASSIFICATION	 each time try schedule new component simulate taking second longer 
WITHOUT_CLASSIFICATION	 now need build the array 
WITHOUT_CLASSIFICATION	 file should moved archive 
WITHOUT_CLASSIFICATION	 create couple files consume 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 current state 
WITHOUT_CLASSIFICATION	 workers requested less than took then know some workers track died since have more workers than are supposed have 
WITHOUT_CLASSIFICATION	 returns void the event should continue false the event should not done 
WITHOUT_CLASSIFICATION	 user jerry submits another topology into full cluster 
WITHOUT_CLASSIFICATION	 doing nothing probably due oom issue and hoping will handle 
WITHOUT_CLASSIFICATION	 should remain unchanged 
WITHOUT_CLASSIFICATION	 just sure 
WITHOUT_CLASSIFICATION	 launchtimesecs 
WITHOUT_CLASSIFICATION	 there wont batchinfo for the success stream 
WITHOUT_CLASSIFICATION	 strategy determine the fetch offset the first realized the spout upon activation 
WITHOUT_CLASSIFICATION	 start accepting requests 
WITHOUT_CLASSIFICATION	 this could fail blob gets deleted mistake dont crash nimbus 
WITHOUT_CLASSIFICATION	 status 
WITHOUT_CLASSIFICATION	 create default pipeline implementation 
WITHOUT_CLASSIFICATION	 public object executecontext 
WITHOUT_CLASSIFICATION	 scheduling changed after killed all the processes 
WITHOUT_CLASSIFICATION	 this finds all active topologies blob keys from all local topology blob keys 
WITHOUT_CLASSIFICATION	 sasl transport 
WITHOUT_CLASSIFICATION	 for cgroups limit max long 
WITHOUT_CLASSIFICATION	 not available 
WITHOUT_CLASSIFICATION	 scheduled 
WITHOUT_CLASSIFICATION	 config mainmethods 
WITHOUT_CLASSIFICATION	 any errorexception thrown fetch from zookeeper 
WITHOUT_CLASSIFICATION	 initial state 
WITHOUT_CLASSIFICATION	 errorexception thrown just skip 
WITHOUT_CLASSIFICATION	 metricname 
WITHOUT_CLASSIFICATION	 verify the signature 
WITHOUT_CLASSIFICATION	 empty 
WITHOUT_CLASSIFICATION	 set really small will cleanup 
WITHOUT_CLASSIFICATION	 look for deleted log timeouts 
WITHOUT_CLASSIFICATION	 authz authn password 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 but that only there bug one the password providers 
WITHOUT_CLASSIFICATION	 numusedworkers 
WITHOUT_CLASSIFICATION	 bolt should also receive from checkpoint streams bolt bolt 
WITHOUT_CLASSIFICATION	 already points where want 
WITHOUT_CLASSIFICATION	 really make this work well 
WITHOUT_CLASSIFICATION	 mapping 
WITHOUT_CLASSIFICATION	 equivalent create command command line 
WITHOUT_CLASSIFICATION	 keyclassstring 
WITHOUT_CLASSIFICATION	 there are any abandoned files pick oldest one 
WITHOUT_CLASSIFICATION	 assigning internally 
WITHOUT_CLASSIFICATION	 topology priority 
WITHOUT_CLASSIFICATION	 totalsharedoffheap 
WITHOUT_CLASSIFICATION	 retry till least element drained 
WITHOUT_CLASSIFICATION	 schedule mid block 
WITHOUT_CLASSIFICATION	 key fields 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 request from authorized hosts and group should allowed 
WITHOUT_CLASSIFICATION	 now need free some resources 
WITHOUT_CLASSIFICATION	 all internal state except for the current buckets are 
WITHOUT_CLASSIFICATION	 update the isleader field for each nimbus summary 
WITHOUT_CLASSIFICATION	 has the the node its doing the partitioning 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 lets checkpoint that can get the last checkpoint when restarting 
WITHOUT_CLASSIFICATION	 allow requesting slots number bigger than available slots 
WITHOUT_CLASSIFICATION	 activation expired list should contain even the ones expired due 
WITHOUT_CLASSIFICATION	 not sure what could cause this 
WITHOUT_CLASSIFICATION	 specific 
WITHOUT_CLASSIFICATION	 flag indicating hivewriter was closed 
WITHOUT_CLASSIFICATION	 stream number cube pairs 
WITHOUT_CLASSIFICATION	 default 
WITHOUT_CLASSIFICATION	 run default scheduler nonisolated topologies 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 list all daemon logs 
WITHOUT_CLASSIFICATION	 already checked this 
WITHOUT_CLASSIFICATION	 add any autocredential expiry metrics from the worker 
WITHOUT_CLASSIFICATION	 this ensures that list values always written the same way regardless whether its java collection one clojures persistent collections which have different serializers doing this lets deserialize arraylist and avoid writing the class here 
WITHOUT_CLASSIFICATION	 create couple input files read 
WITHOUT_CLASSIFICATION	 follow the model service loaders even though not service 
WITHOUT_CLASSIFICATION	 should double ack same msg should still 
WITHOUT_CLASSIFICATION	 not process events beyond current 
WITHOUT_CLASSIFICATION	 generate some supervisors that are depleted one resource 
WITHOUT_CLASSIFICATION	 run spout 
WITHOUT_CLASSIFICATION	 await all results 
WITHOUT_CLASSIFICATION	 worker slot which was never back normal tolerance period will removed from cache 
WITHOUT_CLASSIFICATION	 attention whb can null 
WITHOUT_CLASSIFICATION	 waiting for this also ensures that the first tuple gets failed resettimeout doesnt work 
WITHOUT_CLASSIFICATION	 propagate interrupt 
WITHOUT_CLASSIFICATION	 save the metadata for all types strings matches 
WITHOUT_CLASSIFICATION	 populate node component assignments 
WITHOUT_CLASSIFICATION	 for serialization 
WITHOUT_CLASSIFICATION	 wildcard directory 
WITHOUT_CLASSIFICATION	 just output the word value with count 
WITHOUT_CLASSIFICATION	 send watermark event which should trigger three windows 
WITHOUT_CLASSIFICATION	 tests for case when subject null security turned off and 
WITHOUT_CLASSIFICATION	 both things are not expected and should not happen 
WITHOUT_CLASSIFICATION	 thenreturn always returns the same object which already consumed the time user tries getblob 
WITHOUT_CLASSIFICATION	 process all metadata 
WITHOUT_CLASSIFICATION	 update the keycurrent symlink first create tmp symlink and 
WITHOUT_CLASSIFICATION	 arbitrary message returned when scheduling done 
WITHOUT_CLASSIFICATION	 resource also present resources map will overwrite the above 
WITHOUT_CLASSIFICATION	 heartbeats stats 
WITHOUT_CLASSIFICATION	 can local shuffle 
WITHOUT_CLASSIFICATION	 request impersonate users from unauthroized groups should rejected 
WITHOUT_CLASSIFICATION	 lets reread the children storms the source truth and see new one was created the background 
WITHOUT_CLASSIFICATION	 naive implementation but might good enough 
WITHOUT_CLASSIFICATION	 this special case where the jar was not uploaded will not download already the classpath 
WITHOUT_CLASSIFICATION	 dependencyartifacts 
WITHOUT_CLASSIFICATION	 update the word counts the state here the first argument the initial value for the state and the second argument function that adds the count the current value the state 
WITHOUT_CLASSIFICATION	 parallelism same 
WITHOUT_CLASSIFICATION	 need search more not going help 
WITHOUT_CLASSIFICATION	 would only happen are for now 
WITHOUT_CLASSIFICATION	 test for replication 
WITHOUT_CLASSIFICATION	 direct 
WITHOUT_CLASSIFICATION	 lock dir config 
WITHOUT_CLASSIFICATION	 once every updaterateperiodns 
WITHOUT_CLASSIFICATION	 kill the container and restart 
WITHOUT_CLASSIFICATION	 avoid system dependent things 
WITHOUT_CLASSIFICATION	 for this part the test interleve the differnt rotation types 
WITHOUT_CLASSIFICATION	 guarantees list unused string ids exists once the list empty creates new list 
WITHOUT_CLASSIFICATION	 reached eof didnt read anything 
WITHOUT_CLASSIFICATION	 set the shard iterator for last fetched sequence number start from correct position shard 
WITHOUT_CLASSIFICATION	 dont wait for timetrigger fire since this could lead timing issues unit tests set large value and trigger manually 
WITHOUT_CLASSIFICATION	 bolt that subscribes the intermediate bolt and publishes jms topic 
WITHOUT_CLASSIFICATION	 just and try delte the others 
WITHOUT_CLASSIFICATION	 tuple payload serializer specified via configuration 
WITHOUT_CLASSIFICATION	 also called from 
WITHOUT_CLASSIFICATION	 load the first part entries 
WITHOUT_CLASSIFICATION	 future got interrupted exception want interrupt parent thread itself 
WITHOUT_CLASSIFICATION	 ignore changes scheduling while downloading the topology blobs dont support canceling the download through the future yet because pending blobs may shared multiple workers and cancel may lead race condition keep everything sync just wait for all workers 
WITHOUT_CLASSIFICATION	 doublearg 
WITHOUT_CLASSIFICATION	 node and supervisor are the same 
WITHOUT_CLASSIFICATION	 read line and see another log entry was made 
WITHOUT_CLASSIFICATION	 read initial lines file then check lock exists 
WITHOUT_CLASSIFICATION	 now lets get the creds for the topos can verify those well 
WITHOUT_CLASSIFICATION	 used recognize the pattern active log files may remove the current from this list 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 this class consists exclusively static factory mainmethods that create instances that are essential work with the jpmml library 
WITHOUT_CLASSIFICATION	 seconds passed not timing out 
WITHOUT_CLASSIFICATION	 end executor summary 
WITHOUT_CLASSIFICATION	 test whether the integer power 
WITHOUT_CLASSIFICATION	 release things that dont need wait for finish downloading 
WITHOUT_CLASSIFICATION	 rocksdb should insert sorted key order 
WITHOUT_CLASSIFICATION	 updating file few times every seconds 
WITHOUT_CLASSIFICATION	 dropping the parallelism the bolts instead can find solution reasonable amount work when backtracking 
WITHOUT_CLASSIFICATION	 emit and ack the rest 
WITHOUT_CLASSIFICATION	 configs for memory enforcement done the supervisor not cgroups directly 
WITHOUT_CLASSIFICATION	 icredentialsrenewer 
WITHOUT_CLASSIFICATION	 only need keep track failed tuples commits kafka are controlled tuple acks which happens only for atleastonce processing semantics 
WITHOUT_CLASSIFICATION	 todo file rotation 
WITHOUT_CLASSIFICATION	 copy case want modify 
WITHOUT_CLASSIFICATION	 this read default value for other configurations 
WITHOUT_CLASSIFICATION	 this should trigger the scan find the next aligned window end but not produce any activations 
WITHOUT_CLASSIFICATION	 argslist 
WITHOUT_CLASSIFICATION	 consume both files 
WITHOUT_CLASSIFICATION	 jms topic spout 
WITHOUT_CLASSIFICATION	 set nimbusinfo 
WITHOUT_CLASSIFICATION	 what want 
WITHOUT_CLASSIFICATION	 gets nimbus subject with nimbusprincipal set 
WITHOUT_CLASSIFICATION	 include partition the file name that index for different partitions are independent 
WITHOUT_CLASSIFICATION	 with known best input 
WITHOUT_CLASSIFICATION	 too fast not reported 
WITHOUT_CLASSIFICATION	 record returned put the sequence number the emittedpershard tie back with ack fail 
WITHOUT_CLASSIFICATION	 for point for point 
WITHOUT_CLASSIFICATION	 null log any unhandled errors stderr 
WITHOUT_CLASSIFICATION	 targetloglevel 
WITHOUT_CLASSIFICATION	 creates mongoclient described uri 
WITHOUT_CLASSIFICATION	 empty still 
WITHOUT_CLASSIFICATION	 retire writers 
WITHOUT_CLASSIFICATION	 iprincipaltolocal 
WITHOUT_CLASSIFICATION	 sentencespout mybolt 
WITHOUT_CLASSIFICATION	 the resource aware scheduler used 
WITHOUT_CLASSIFICATION	 since user derek has exceeded his resource guarantee while user jerry has not topo topo could evicted because they have the same priority 
WITHOUT_CLASSIFICATION	 class offset 
WITHOUT_CLASSIFICATION	 the connection not sent unless response requested 
WITHOUT_CLASSIFICATION	 now that the root fine can start look the other paths under 
WITHOUT_CLASSIFICATION	 convenience data structure speedup lookups 
WITHOUT_CLASSIFICATION	 returns the recorded throughput since the last call since this meter was instantiated being called for fisrt time 
WITHOUT_CLASSIFICATION	 noop could add configs through the webxml wanted something stand alone here 
WITHOUT_CLASSIFICATION	 storm 
WITHOUT_CLASSIFICATION	 offset where processing will resume upon spout restart 
WITHOUT_CLASSIFICATION	 file offset and byte offset should always zero when searching multiple workers multiple ports 
WITHOUT_CLASSIFICATION	 grab lock 
WITHOUT_CLASSIFICATION	 gets collection 
WITHOUT_CLASSIFICATION	 blobs are not supported local mode return nothing 
WITHOUT_CLASSIFICATION	 filtered negative value 
WITHOUT_CLASSIFICATION	 noop dont actually want change log levels for tests 
WITHOUT_CLASSIFICATION	 transfer encoding should set jersey sets default 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 agg spout stats 
WITHOUT_CLASSIFICATION	 keep this constructor for backward compatibility 
WITHOUT_CLASSIFICATION	 noop purpose 
WITHOUT_CLASSIFICATION	 deleting closed file should return true 
WITHOUT_CLASSIFICATION	 stream name specified 
WITHOUT_CLASSIFICATION	 validate metrics aggregations found for for all agglevels when searching port 
WITHOUT_CLASSIFICATION	 assume topology 
WITHOUT_CLASSIFICATION	 with principals the subject acl should always set worldeverything 
WITHOUT_CLASSIFICATION	 errortimesecs 
WITHOUT_CLASSIFICATION	 shouldnt happen 
WITHOUT_CLASSIFICATION	 topoids 
WITHOUT_CLASSIFICATION	 generously adapted from avroserializerscala which has asl license 
WITHOUT_CLASSIFICATION	 just ignore the exception 
WITHOUT_CLASSIFICATION	 receives msgs from remote workers and feeds them local executors any receiving local executor under back pressure 
WITHOUT_CLASSIFICATION	 avoid reordering emits stop first failure 
WITHOUT_CLASSIFICATION	 didnt take gpus into account everything would fit under single slot but because there only gpu per node and each the spouts needs gpu has scheduled least nodes and hence slots because this all the bolts will scheduled single slot with one the spouts and the other spout its own slot everything that can shared shared 
WITHOUT_CLASSIFICATION	 producerfwdconsumer measurement 
WITHOUT_CLASSIFICATION	 try uploading second one and should failed throwing runtimeexception 
WITHOUT_CLASSIFICATION	 start the thread pool 
WITHOUT_CLASSIFICATION	 the spout must able reemit all retriable tuples even the maxpollrecords set low value compared 
WITHOUT_CLASSIFICATION	 stream metric value note that sidoutstats may contain both long and double values 
WITHOUT_CLASSIFICATION	 all the events should expired when the next watermark received 
WITHOUT_CLASSIFICATION	 test for subject with principals and acls set default 
WITHOUT_CLASSIFICATION	 copy the half the buffer the first half 
WITHOUT_CLASSIFICATION	 remove something randomly 
WITHOUT_CLASSIFICATION	 found the topology lets get the conf 
WITHOUT_CLASSIFICATION	 since made sys components visible the component map has all system components 
WITHOUT_CLASSIFICATION	 noop 
WITHOUT_CLASSIFICATION	 computes tumbling window average 
WITHOUT_CLASSIFICATION	 check lock file contents 
WITHOUT_CLASSIFICATION	 queryplanner streams mode configures the topology with compiled classes need add new classes into topology jar topology will serialized and sent nimbus and deserialized and executed workers 
WITHOUT_CLASSIFICATION	 all done can launch the worker now 
WITHOUT_CLASSIFICATION	 login and also update the subject field this instance 
WITHOUT_CLASSIFICATION	 map from stream name batch 
WITHOUT_CLASSIFICATION	 create symbolic link relative tar parent dir 
WITHOUT_CLASSIFICATION	 set the metrics sample rate force update the executor stats every time something happens this necessary because relies the executor emit stats accurate 
WITHOUT_CLASSIFICATION	 check node alive 
WITHOUT_CLASSIFICATION	 even the topology not valid still need remap all 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 translating the name this call happens different callback from validating the user name and password this has stateless though cannot save the password provider away sure got the same one that validated the password the password providers are written correctly this should never happen because they cannot read the name they would return null but the off chance that something goes wrong with the translation because mismatch try skip the bad one 
WITHOUT_CLASSIFICATION	 now rebalance and add new partition 
WITHOUT_CLASSIFICATION	 shutdown server process since could not handle thrift requests any more 
WITHOUT_CLASSIFICATION	 when worker bootup worker will start setup initial connections other workers when all connection ready will count down this latch and spout and bolt will activated assuming the topology not deactivated 
WITHOUT_CLASSIFICATION	 json parsing fail error received 
WITHOUT_CLASSIFICATION	 memoryusage 
WITHOUT_CLASSIFICATION	 object handling interaction with kinesis 
WITHOUT_CLASSIFICATION	 spout stats 
WITHOUT_CLASSIFICATION	 spout implementation 
WITHOUT_CLASSIFICATION	 emit 
WITHOUT_CLASSIFICATION	 boltobject 
WITHOUT_CLASSIFICATION	 use custom class loader set testing environment 
WITHOUT_CLASSIFICATION	 topo has one single huge task that can not handled the smallsuper 
WITHOUT_CLASSIFICATION	 user derek submits another topology into full cluster topo should not able scheduled initially but since topo has higher priority than topo topo will evicted that topo can scheduled 
WITHOUT_CLASSIFICATION	 throws ioexceptions for call next succeeds thereafter 
WITHOUT_CLASSIFICATION	 remove reverse lookup from map 
WITHOUT_CLASSIFICATION	 now rebalance 
WITHOUT_CLASSIFICATION	 scans the database look for metadata string and returns the metadata info 
WITHOUT_CLASSIFICATION	 numtasks 
WITHOUT_CLASSIFICATION	 deprecated favor nonthreaded rotatingmap 
WITHOUT_CLASSIFICATION	 trust that the file exists 
WITHOUT_CLASSIFICATION	 this test works because mocking spout splits the tuples evenly among the tasks 
WITHOUT_CLASSIFICATION	 mapping from storm tuple rocketmq message 
WITHOUT_CLASSIFICATION	 usedmem 
WITHOUT_CLASSIFICATION	 key transformers 
WITHOUT_CLASSIFICATION	 any events are scheduled sleep until event generation any recurring events are scheduled then will always through this branch sleeping only the exact necessary amount time give upper bound millis the sleeping time limit the response time for detecting any new event within secs 
WITHOUT_CLASSIFICATION	 dont want override the client there thrift server and running would not test any the actual thrift code 
WITHOUT_CLASSIFICATION	 each drpc request always single attempt 
WITHOUT_CLASSIFICATION	 add the callers cache cant add the stringmetadatacache since that could cause eviction database write which want only occur from the inserting thread 
WITHOUT_CLASSIFICATION	 this partition new and should start the committed offset 
WITHOUT_CLASSIFICATION	 assuming sidefields are preserving its order 
WITHOUT_CLASSIFICATION	 blocking call 
WITHOUT_CLASSIFICATION	 above gives extra empty string the end below removes that 
WITHOUT_CLASSIFICATION	 remote address 
WITHOUT_CLASSIFICATION	 far matches keep going 
WITHOUT_CLASSIFICATION	 fail are forced try again 
WITHOUT_CLASSIFICATION	 attempt find the string the database 
WITHOUT_CLASSIFICATION	 setup test message 
WITHOUT_CLASSIFICATION	 prior the orgapache change 
WITHOUT_CLASSIFICATION	 delete one worker failed from topo assignment enable actual schedule for testing 
WITHOUT_CLASSIFICATION	 actual ret mapstring mapstring longdouble 
WITHOUT_CLASSIFICATION	 time sleep between retries milliseconds 
WITHOUT_CLASSIFICATION	 ranked fifth since rack has not cpu resources 
WITHOUT_CLASSIFICATION	 time last flush this writer 
WITHOUT_CLASSIFICATION	 this attempt give all the streams equal opportunity emit something 
WITHOUT_CLASSIFICATION	 this the end key for whole scan 
WITHOUT_CLASSIFICATION	 transfers messages destined other workers 
WITHOUT_CLASSIFICATION	 make sure that have received least integer length 
WITHOUT_CLASSIFICATION	 name 
WITHOUT_CLASSIFICATION	 test write again 
WITHOUT_CLASSIFICATION	 will closed automatically when shutting down the dfs cluster 
WITHOUT_CLASSIFICATION	 should remove key 
WITHOUT_CLASSIFICATION	 batch spout then contains txid 
WITHOUT_CLASSIFICATION	 called with bad port not the config searching should done 
WITHOUT_CLASSIFICATION	 for partitionpersist 
WITHOUT_CLASSIFICATION	 the dir empty try delete may fail but that 
WITHOUT_CLASSIFICATION	 empty class 
WITHOUT_CLASSIFICATION	 seems this can fail returning false throwing exception convert false ret value exception 
WITHOUT_CLASSIFICATION	 found the next offset commit 
WITHOUT_CLASSIFICATION	 this only used for loggingmetrics dont crash the process over 
WITHOUT_CLASSIFICATION	 counter for spout wait strategy counter for back pressure wait strategy 
WITHOUT_CLASSIFICATION	 now lets create token and verify that can connect 
WITHOUT_CLASSIFICATION	 todo log 
WITHOUT_CLASSIFICATION	 this validates the structure the topology 
WITHOUT_CLASSIFICATION	 note that portdir active worker containing active logs 
WITHOUT_CLASSIFICATION	 may output many tuples for given input tuple 
WITHOUT_CLASSIFICATION	 now multiple 
WITHOUT_CLASSIFICATION	 the user wants explicitly set auto offset reset policy should respect but when the spout configured for atleastonce processing should default seeking the earliest offset case theres offset out range error rather than seeking the latest kafkas default this type error will typically happen when the consumer requests offset that was deleted 
WITHOUT_CLASSIFICATION	 hash 
WITHOUT_CLASSIFICATION	 bookkeeping 
WITHOUT_CLASSIFICATION	 instances this type are sent from nettyworker upstream workertransfer indicate backpressure situation 
WITHOUT_CLASSIFICATION	 assumption therere put and delete for same target parameter list 
WITHOUT_CLASSIFICATION	 default need this different user 
WITHOUT_CLASSIFICATION	 set the default heap memory size for supervisortest 
WITHOUT_CLASSIFICATION	 common 
WITHOUT_CLASSIFICATION	 this the first time initialize the resources 
WITHOUT_CLASSIFICATION	 need enforcement topology level not single worker level because for cgroups each page shared memory goes the worker that touched first may need make this more plugable the future and let the resource isolation manager tell what 
WITHOUT_CLASSIFICATION	 headers 
WITHOUT_CLASSIFICATION	 update set the second assignment 
WITHOUT_CLASSIFICATION	 create reader and some checks 
WITHOUT_CLASSIFICATION	 principal 
WITHOUT_CLASSIFICATION	 nonstatic impl mainmethods exist for mocking purposes 
WITHOUT_CLASSIFICATION	 topo evicted since user bobby dont have any resource guarantees and topo the next lowest priority for user bobby 
WITHOUT_CLASSIFICATION	 evaluator 
WITHOUT_CLASSIFICATION	 replicationcount 
WITHOUT_CLASSIFICATION	 delete file and retry creation 
WITHOUT_CLASSIFICATION	 givenwhen 
WITHOUT_CLASSIFICATION	 the latch not started yet start 
WITHOUT_CLASSIFICATION	 offsets emitted are void 
WITHOUT_CLASSIFICATION	 but topo was submitted earlier thus choose that one evict somewhat arbitrary 
WITHOUT_CLASSIFICATION	 dont include sys 
WITHOUT_CLASSIFICATION	 storm topology name 
WITHOUT_CLASSIFICATION	 defaults info level when the logger isnt found previously 
WITHOUT_CLASSIFICATION	 specific reason mock this one easiest ways make dummy instance 
WITHOUT_CLASSIFICATION	 remotetaskid truefalse indicates remote task under 
WITHOUT_CLASSIFICATION	 use the default server port 
WITHOUT_CLASSIFICATION	 play and ack tuple 
WITHOUT_CLASSIFICATION	 emit the averages downstream 
WITHOUT_CLASSIFICATION	 for reporting errors 
WITHOUT_CLASSIFICATION	 common aggregate 
WITHOUT_CLASSIFICATION	 bind and start accept incoming connections 
WITHOUT_CLASSIFICATION	 package access for unit test 
WITHOUT_CLASSIFICATION	 this test where are configured point right single artifact 
WITHOUT_CLASSIFICATION	 required required required required required required required required required 
WITHOUT_CLASSIFICATION	 assume filter choices have been made and since selection was made all levels are valid 
WITHOUT_CLASSIFICATION	 open sasl transport with the login credential 
WITHOUT_CLASSIFICATION	 let first lock 
WITHOUT_CLASSIFICATION	 min values 
WITHOUT_CLASSIFICATION	 validate search port 
WITHOUT_CLASSIFICATION	 merge with existing assignments 
WITHOUT_CLASSIFICATION	 initialize state for batch 
WITHOUT_CLASSIFICATION	 offset are pending failed but not retriable 
WITHOUT_CLASSIFICATION	 null istimedout means worker never reported any heartbeat 
WITHOUT_CLASSIFICATION	 rwrr 
WITHOUT_CLASSIFICATION	 one time scheduling 
WITHOUT_CLASSIFICATION	 regardless ticketrenewwindow setting above and the ticket expiry time thread will not sleep between refresh attempts any less than minute milliseconds minute 
WITHOUT_CLASSIFICATION	 and wait for the message get through the spout acks use the same path timeout resets 
WITHOUT_CLASSIFICATION	 todo add metrics 
WITHOUT_CLASSIFICATION	 subprocesses must send their pid first thing 
WITHOUT_CLASSIFICATION	 null for system bolt 
WITHOUT_CLASSIFICATION	 assume that get doesnt have any families defined this for not digging deeply 
WITHOUT_CLASSIFICATION	 the best way force backtracking change the heuristic the components are reversed hard find answer 
WITHOUT_CLASSIFICATION	 local mode there jar 
WITHOUT_CLASSIFICATION	 extract spout resource info 
WITHOUT_CLASSIFICATION	 class path entries that are neither directories nor archives zip jar files nor the asterisk wildcard character are ignored 
WITHOUT_CLASSIFICATION	 topologyversion 
WITHOUT_CLASSIFICATION	 convert sources json serializable format 
WITHOUT_CLASSIFICATION	 cpuguarantee 
WITHOUT_CLASSIFICATION	 toplogy worgenspout fieldsgrouping countbolt 
WITHOUT_CLASSIFICATION	 careful about adding additional tests the dfscluster will shared 
WITHOUT_CLASSIFICATION	 start metastore 
WITHOUT_CLASSIFICATION	 get transaction already exists and attempt greater than the attempt there 
WITHOUT_CLASSIFICATION	 type 
WITHOUT_CLASSIFICATION	 set committed looks like some messages have been committed each partition 
WITHOUT_CLASSIFICATION	 should not returned since this executor not part the topologys assignment 
WITHOUT_CLASSIFICATION	 required required required required required required optional optional optional optional optional optional optional optional optional optional optional 
WITHOUT_CLASSIFICATION	 jprofile start 
WITHOUT_CLASSIFICATION	 find retirement candidates 
WITHOUT_CLASSIFICATION	 committed offset the offset where processing will resume upon spout restart initially set fetchoffset 
WITHOUT_CLASSIFICATION	 allow freqsec expire 
WITHOUT_CLASSIFICATION	 schedule topo 
WITHOUT_CLASSIFICATION	 flatmapfunction aware prepare let handle preparation 
WITHOUT_CLASSIFICATION	 advance time and then trigger call kafka consumer commit 
WITHOUT_CLASSIFICATION	 verify that the tuple not emitted again 
WITHOUT_CLASSIFICATION	 use this instead storms built one that can specify without knowledge storms internals 
WITHOUT_CLASSIFICATION	 setup hfs bolt 
WITHOUT_CLASSIFICATION	 wait for seconds 
WITHOUT_CLASSIFICATION	 put global stream for spouts 
WITHOUT_CLASSIFICATION	 using monotonically increasing attempt downstream tasks can memory efficient clearing out state for old attempts soon they see higher attempt for transaction 
WITHOUT_CLASSIFICATION	 how partition for second stage aggregation 
WITHOUT_CLASSIFICATION	 required optional optional optional optional 
WITHOUT_CLASSIFICATION	 try the loader plugin configured 
WITHOUT_CLASSIFICATION	 bail out 
WITHOUT_CLASSIFICATION	 the user not set lets see what the request context 
WITHOUT_CLASSIFICATION	 being the position the fields this seq the remainder the seq the size 
WITHOUT_CLASSIFICATION	 notjump closed strict mode 
WITHOUT_CLASSIFICATION	 asserts that commitsync has been called once that there are only commits one topic and that the committed offset covers messagecount messages 
WITHOUT_CLASSIFICATION	 allow poll the partition not the limit 
WITHOUT_CLASSIFICATION	 when this ever null 
WITHOUT_CLASSIFICATION	 read error and input streams this would free the buffers 
WITHOUT_CLASSIFICATION	 test for replication with nimbus user 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 the below field declarations are also used commonclj define the event logger output fields 
WITHOUT_CLASSIFICATION	 result 
WITHOUT_CLASSIFICATION	 iautocredentials 
WITHOUT_CLASSIFICATION	 topologygetbolt aka sys tasks most specifically acker tasks 
WITHOUT_CLASSIFICATION	 windowtotransferred 
WITHOUT_CLASSIFICATION	 there most one schedule per message 
WITHOUT_CLASSIFICATION	 make sure that even though nexttuple doesnt receive valid data the offset will checkpointed after checkpointinterval seconds 
WITHOUT_CLASSIFICATION	 retrieve any existing aggregation matching this one and update the values 
WITHOUT_CLASSIFICATION	 private constructor 
WITHOUT_CLASSIFICATION	 taskids first 
WITHOUT_CLASSIFICATION	 keeps track flight tuples 
WITHOUT_CLASSIFICATION	 loggerinfoemit for partition partitiongetid offset offset 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 this because the tests are checking that hard cap maxpollrecords uncommitted offsets exists 
WITHOUT_CLASSIFICATION	 good far check are cgroup 
WITHOUT_CLASSIFICATION	 supervisor which was never back normal tolerance period will removed from cache 
WITHOUT_CLASSIFICATION	 maybe needs start phase where can retrieval update phase and then finish phase shouldnt really oneatatime interface since have all the tuples already tood used for the new values stream the list needed able get reduceragg and combineragg persistentaggregate for grouped streams working efficiently 
WITHOUT_CLASSIFICATION	 java classpath expanded all jarjar files the directory 
WITHOUT_CLASSIFICATION	 verify that offset was committed for the given topicpartition since processing should resume 
WITHOUT_CLASSIFICATION	 could not lock try another file 
WITHOUT_CLASSIFICATION	 use the hash index for prefix searches 
WITHOUT_CLASSIFICATION	 compacted away 
WITHOUT_CLASSIFICATION	 done 
WITHOUT_CLASSIFICATION	 check map 
WITHOUT_CLASSIFICATION	 tuples may ackedfailed after the spout deactivates have able handle this too 
WITHOUT_CLASSIFICATION	 zkhoststring for solr gettingstarted example 
WITHOUT_CLASSIFICATION	 not blocking call cannot emit will add tuple pendingemits and return false pendingemits can null 
WITHOUT_CLASSIFICATION	 waiting fetched 
WITHOUT_CLASSIFICATION	 stream number square pairs 
WITHOUT_CLASSIFICATION	 outputfields 
WITHOUT_CLASSIFICATION	 timers 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 not use canonical file name here are using symbolic links read file data and performing atomic move while updating files 
WITHOUT_CLASSIFICATION	 initiate connection remote destination 
WITHOUT_CLASSIFICATION	 assume that there could worker already the node that under the minworkercpu budget its possible could combine with lets disregard minworkercpu from the request and validate that cpu rough fit 
WITHOUT_CLASSIFICATION	 generating list random numbers and removing the ones that already are use 
WITHOUT_CLASSIFICATION	 client api invoke blob store api functionality 
WITHOUT_CLASSIFICATION	 delete everything hdfs 
WITHOUT_CLASSIFICATION	 not send upstream other handlers further action needs 
WITHOUT_CLASSIFICATION	 test class override the write directory 
WITHOUT_CLASSIFICATION	 retry once after minute 
WITHOUT_CLASSIFICATION	 update this only after writing hdfs 
WITHOUT_CLASSIFICATION	 ranked second since rack has balanced set resources but less than rack 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 comma separated list topics consumer group for which the offset needs calculated bootstrap brokers security protocol connect kafka properties file containing additional kafka consumer configs 
WITHOUT_CLASSIFICATION	 configs hdfs bolt 
WITHOUT_CLASSIFICATION	 aggregating metric did not exist dont look for further ones with smaller timestamps 
WITHOUT_CLASSIFICATION	 rotate files when they reach 
WITHOUT_CLASSIFICATION	 create authentication callback handler 
WITHOUT_CLASSIFICATION	 port testshuffleloadeven 
WITHOUT_CLASSIFICATION	 given 
WITHOUT_CLASSIFICATION	 consume file 
WITHOUT_CLASSIFICATION	 requested assigned guaranteedavailable 
WITHOUT_CLASSIFICATION	 jprofile dump 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 are launching now 
WITHOUT_CLASSIFICATION	 tests that isscheduled isready and are mutually consistent when there are multiple messages scheduled partition 
WITHOUT_CLASSIFICATION	 can updatestatebykey statequery processors 
WITHOUT_CLASSIFICATION	 these are mandatory parameters 
WITHOUT_CLASSIFICATION	 scan the entire window handle out order events the case time based windows 
WITHOUT_CLASSIFICATION	 reader type config 
WITHOUT_CLASSIFICATION	 windowtostats 
WITHOUT_CLASSIFICATION	 find number constraints per component keycomp value constraints 
WITHOUT_CLASSIFICATION	 set the inmemory filesystem 
WITHOUT_CLASSIFICATION	 whether find all documents according the query filter 
WITHOUT_CLASSIFICATION	 metrics are off verify null 
WITHOUT_CLASSIFICATION	 check that one message fails repeatedly the retry cap limits how many times the message can reemitted 
WITHOUT_CLASSIFICATION	 mock state store and receiver 
WITHOUT_CLASSIFICATION	 test commit second creates properly 
WITHOUT_CLASSIFICATION	 out order events should processed upto the lag 
WITHOUT_CLASSIFICATION	 process has not terminated check has completed not just destroy 
WITHOUT_CLASSIFICATION	 dont update unless there are tuples this helps out with things like global partition persist where multiple tasks may still exist for this processor only want the global one anything 
WITHOUT_CLASSIFICATION	 compute the stats for the different input streams 
WITHOUT_CLASSIFICATION	 because the simple topology was scheduled first want sure that didnt put anything the gpu nodes 
WITHOUT_CLASSIFICATION	 wait for available queue 
WITHOUT_CLASSIFICATION	 username 
WITHOUT_CLASSIFICATION	 make sure can store the worker tokens even creds are provided 
WITHOUT_CLASSIFICATION	 this bolt does not emit anything 
WITHOUT_CLASSIFICATION	 should only happen badly configured system 
WITHOUT_CLASSIFICATION	 ignores invalid usertopokey 
WITHOUT_CLASSIFICATION	 are cleared 
WITHOUT_CLASSIFICATION	 return false stop scan 
WITHOUT_CLASSIFICATION	 submit topology storm cluster 
WITHOUT_CLASSIFICATION	 prevent daemon log reads from pathing into worker logs 
WITHOUT_CLASSIFICATION	 totalnodeshared 
WITHOUT_CLASSIFICATION	 link and several other trident classes inherit from these classes are serialized out part the bolts and spouts topology often for each boltspout the topology the following are marked transient because they are never used after the topology created keeping them around just wastes space the serialized topology 
WITHOUT_CLASSIFICATION	 read once since the first file empty the spout should continue with file 
WITHOUT_CLASSIFICATION	 fail supervisor 
WITHOUT_CLASSIFICATION	 update blob interface 
WITHOUT_CLASSIFICATION	 default aways distributed but here local cluster being used 
WITHOUT_CLASSIFICATION	 this cheating bit since maxpollrecords would normally spread this across multiple polls 
WITHOUT_CLASSIFICATION	 spy object that tries mock the real object store 
WITHOUT_CLASSIFICATION	 should not show files outside log root 
WITHOUT_CLASSIFICATION	 workerheartbeats 
WITHOUT_CLASSIFICATION	 zeroout the half prevent accidental matches 
WITHOUT_CLASSIFICATION	 sleep bit between emits ensure that dont reach the cap too quickly since this spout used test time based windows 
WITHOUT_CLASSIFICATION	 transferred totals 
WITHOUT_CLASSIFICATION	 consume file 
WITHOUT_CLASSIFICATION	 test listkeys 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 congested contract much more quickly 
WITHOUT_CLASSIFICATION	 setup broker 
WITHOUT_CLASSIFICATION	 bolt aggregate 
WITHOUT_CLASSIFICATION	 memory requirement large enough that two executors can not fully assigned one node 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 now lets load setting gets and should still get valid map back 
WITHOUT_CLASSIFICATION	 disablelogincache indicates whether not use the logincache exclude from the keystring 
WITHOUT_CLASSIFICATION	 commands contains one more null value spout compiled with lower version stormkafkaclient 
WITHOUT_CLASSIFICATION	 namedloggerlevel 
WITHOUT_CLASSIFICATION	 note the queue has thread safe 
WITHOUT_CLASSIFICATION	 access foo make most recently used 
WITHOUT_CLASSIFICATION	 other scenario covers when maxseqnumber and nimbus seq number are equal 
WITHOUT_CLASSIFICATION	 compute the word counts the last two second window 
WITHOUT_CLASSIFICATION	 dispatches the right join method innerleftrightouter based the joininfojointype 
WITHOUT_CLASSIFICATION	 partition info does not change eventhub 
WITHOUT_CLASSIFICATION	 timestamp 
WITHOUT_CLASSIFICATION	 seconds 
WITHOUT_CLASSIFICATION	 add all fetched records the set failed records they are present failed set 
WITHOUT_CLASSIFICATION	 used 
WITHOUT_CLASSIFICATION	 create multiple copies test topology 
WITHOUT_CLASSIFICATION	 now need map them all back again 
WITHOUT_CLASSIFICATION	 now compile 
WITHOUT_CLASSIFICATION	 eventlogport 
WITHOUT_CLASSIFICATION	 sync assignmentsidinfo local 
WITHOUT_CLASSIFICATION	 ensure fields per tuple and null fields 
WITHOUT_CLASSIFICATION	 offset committed are failed maxpollrecords are emitted fail the last tuples only offset not failed advance time the failed tuples become ready for retry and check that the spout will emit retriable tuples for all the failed tuples that are within tuples the committed offset 
WITHOUT_CLASSIFICATION	 assume key the first field 
WITHOUT_CLASSIFICATION	 use redis for state persistence 
WITHOUT_CLASSIFICATION	 found existing token and not going expire any time soon dont bother adding new token 
WITHOUT_CLASSIFICATION	 spout notified that message returned for retrying was actually emitted hence remove from set and wait for its ack fail but still keep counts map retry again failure remove ack 
WITHOUT_CLASSIFICATION	 current version supports rpc heartbeat 
WITHOUT_CLASSIFICATION	 certain states might only accept onetuple keys those should just throw error 
WITHOUT_CLASSIFICATION	 set the size case are recovering already downloaded object 
WITHOUT_CLASSIFICATION	 find primary key from constructor 
WITHOUT_CLASSIFICATION	 sort executors based component constraints 
WITHOUT_CLASSIFICATION	 should 
WITHOUT_CLASSIFICATION	 config settings 
WITHOUT_CLASSIFICATION	 test launch topo together should able use either mem cpu resource due exact division 
WITHOUT_CLASSIFICATION	 file offset should zero since searcharchived false 
WITHOUT_CLASSIFICATION	 access 
WITHOUT_CLASSIFICATION	 the spout should now commit all the offsets since all offsets are either acked were missing when retrying 
WITHOUT_CLASSIFICATION	 servers should rotated before the old client removed from clientforserver race with getwriteclient could cause put back the map 
WITHOUT_CLASSIFICATION	 now test regular updateblob 
WITHOUT_CLASSIFICATION	 recancel current thread also interrupted 
WITHOUT_CLASSIFICATION	 also fail the last tuple from partition two since the failed tuple beyond the limit should not retried until earlier messages are acked 
WITHOUT_CLASSIFICATION	 test launch topo only both mem and cpu should exactly used 
WITHOUT_CLASSIFICATION	 field name does not match static field test matches dynamic field 
WITHOUT_CLASSIFICATION	 sleep prevent race conditions 
WITHOUT_CLASSIFICATION	 weak supervisor node 
WITHOUT_CLASSIFICATION	 default ordered 
WITHOUT_CLASSIFICATION	 ensure the loggers are configured the workerxml before trying use them here 
WITHOUT_CLASSIFICATION	 release lock file and check 
WITHOUT_CLASSIFICATION	 also put generic resource with value the resources list verify that doesnt affect the sorting 
WITHOUT_CLASSIFICATION	 offheapnode 
WITHOUT_CLASSIFICATION	 its newbyteoffset negative this normal are out bytes read from small file 
WITHOUT_CLASSIFICATION	 dont bother blocking full queue just drop metrics case cant keep 
WITHOUT_CLASSIFICATION	 update scenario and explain the code logic written here especially when nimbus crashes and comes after and before update 
WITHOUT_CLASSIFICATION	 means 
WITHOUT_CLASSIFICATION	 save the evicted keyvalue the database immediately 
WITHOUT_CLASSIFICATION	 should and 
WITHOUT_CLASSIFICATION	 localorshuffle 
WITHOUT_CLASSIFICATION	 the sym link are pointing 
WITHOUT_CLASSIFICATION	 cpu memory not set the values stored and 
WITHOUT_CLASSIFICATION	 initialize serverside sasl functionality havent yet which case are looking the first sasl message from the client 
WITHOUT_CLASSIFICATION	 resend status case prev notification was missed reordered 
WITHOUT_CLASSIFICATION	 slots will null while supervisor has been removed from cached supervisors 
WITHOUT_CLASSIFICATION	 just return the first metric meet 
WITHOUT_CLASSIFICATION	 boolean cache for local mode decision 
WITHOUT_CLASSIFICATION	 when authnid and authzid are not equal authnid attempting impersonate authzid 
WITHOUT_CLASSIFICATION	 kinesis spout kinesisconfig object 
WITHOUT_CLASSIFICATION	 spouts 
WITHOUT_CLASSIFICATION	 add new ports cached supervisor need modifiable set allow removing ports later 
WITHOUT_CLASSIFICATION	 binaryarg 
WITHOUT_CLASSIFICATION	 jms producer 
WITHOUT_CLASSIFICATION	 for failed message add failed set will retried otherwise ack remove from emitted either way 
WITHOUT_CLASSIFICATION	 there are trigger values earlier attempts this new batch emit pending triggers 
WITHOUT_CLASSIFICATION	 when 
WITHOUT_CLASSIFICATION	 this code logic covers the update scenarios when the nimbus goes down before syncing the blob nimbus and update happens seqnum for nimbus and maxseqnumber then next sequence number maxseqnumber 
WITHOUT_CLASSIFICATION	 should done now 
WITHOUT_CLASSIFICATION	 getters 
WITHOUT_CLASSIFICATION	 trigger the window 
WITHOUT_CLASSIFICATION	 offset offset offset offset offset offset offset offset 
WITHOUT_CLASSIFICATION	 non blocking call cannot emit destination immediately such tuples will added pendingemits argument 
WITHOUT_CLASSIFICATION	 renewal threads main loop exits from here thread will exit 
WITHOUT_CLASSIFICATION	 validate 
WITHOUT_CLASSIFICATION	 shutdownable mainmethods 
WITHOUT_CLASSIFICATION	 new supervisor cache 
WITHOUT_CLASSIFICATION	 need get acl from meta 
WITHOUT_CLASSIFICATION	 test scheduling new topology does not disturb other assignments unnecessarily 
WITHOUT_CLASSIFICATION	 windowtoemitted 
WITHOUT_CLASSIFICATION	 the encryption key must hexadecimal 
WITHOUT_CLASSIFICATION	 execute and process latency 
WITHOUT_CLASSIFICATION	 there should now maxpollrecords emitted all 
WITHOUT_CLASSIFICATION	 first just set the keys null then flag remove them beginning next commit when know the current and last value are both null 
WITHOUT_CLASSIFICATION	 without fragmentation the cluster would able schedule both topologies each node lets call each node with both topologies scheduled scheduled schedule the cluster blocks topologies measuring the time schedule the blocks the first middle and last blocks attempt schedule the following the last block has number scheduling failures due cluster fragmentation and its time dominated attempting evict topologies timing results for scheduling are noisy result multiple runs and use median values for firstblock and lastblock times somewhere statistician crying the ratio lastblock firstblock remains fairly constant took firstblock lastblock ratio firstblock lastblock ratio firstblock lastblock ratio took firstblock lastblock ratio firstblock lastblock ratio firstblock lastblock ratio took firstblock lastblock ratio firstblock lastblock ratio firstblock lastblock ratio took firstblock lastblock ratio firstblock lastblock ratio firstblock lastblock ratio took firstblock lastblock ratio firstblock lastblock ratio firstblock lastblock ratio choose the median value the values above 
WITHOUT_CLASSIFICATION	 find the number bytes with nonleading zeros 
WITHOUT_CLASSIFICATION	 check avoids multiple log msgs when idle loop 
WITHOUT_CLASSIFICATION	 schedule left over system tasks 
WITHOUT_CLASSIFICATION	 this doesnt follow symlinks which what want 
WITHOUT_CLASSIFICATION	 build put query 
WITHOUT_CLASSIFICATION	 window partitions 
WITHOUT_CLASSIFICATION	 take ownership stale lock 
WITHOUT_CLASSIFICATION	 are capturing exceptions thrown blitzers child threads into this data structure that can properly passfail this test the reason that blitzer doesnt report exceptions which known bug blitzer 
WITHOUT_CLASSIFICATION	 set size cleanup another one 
WITHOUT_CLASSIFICATION	 should not seek the paused partition 
WITHOUT_CLASSIFICATION	 verify digest rejected 
WITHOUT_CLASSIFICATION	 system bolt not part backpressure 
WITHOUT_CLASSIFICATION	 check just the one port 
WITHOUT_CLASSIFICATION	 add with current 
WITHOUT_CLASSIFICATION	 required 
WITHOUT_CLASSIFICATION	 value the metric 
WITHOUT_CLASSIFICATION	 overflowq size the time the last bpstatus was sent 
WITHOUT_CLASSIFICATION	 tests download topology blobs local mode topology without resources folder 
WITHOUT_CLASSIFICATION	 retry locking and verify 
WITHOUT_CLASSIFICATION	 default 
WITHOUT_CLASSIFICATION	 contents the key starts with nimbus host port information 
WITHOUT_CLASSIFICATION	 context not used the default implementation but included the interface case useful subclasses 
WITHOUT_CLASSIFICATION	 get more than one stateful operation need process the current group that have one stateful operation per stateful bolt 
WITHOUT_CLASSIFICATION	 nothing for conf now 
WITHOUT_CLASSIFICATION	 add our messages and verify metrics are recorded 
WITHOUT_CLASSIFICATION	 looks like usage might not supported 
WITHOUT_CLASSIFICATION	 ensure nimbus assigns topologies quickly possible 
WITHOUT_CLASSIFICATION	 put legacy values 
WITHOUT_CLASSIFICATION	 try get the topology conf from nimbus can reuse 
WITHOUT_CLASSIFICATION	 funcargs 
WITHOUT_CLASSIFICATION	 use instead for field delimiter 
WITHOUT_CLASSIFICATION	 complexity that linear scan treemap 
WITHOUT_CLASSIFICATION	 nextoffset the last offset from last batch 
WITHOUT_CLASSIFICATION	 spout aggregate 
WITHOUT_CLASSIFICATION	 use storms zookeeper servers not specified 
WITHOUT_CLASSIFICATION	 clean memory 
WITHOUT_CLASSIFICATION	 configs are present generic map and legacy the legacy values will overwritten 
WITHOUT_CLASSIFICATION	 for each isolated topology compute even distribution executors workers the number workers specified for the topology compute distribution workers machines determine host list slot topology executors iterate through hosts and machine good only running workers from one isolated topology all workers running match one the distributions executors for that topology matches one the workers blacklist the good hosts and remove those workers from the list need assigned workers otherwise unassign all other workers for isolated topologies assigned 
WITHOUT_CLASSIFICATION	 now check that the spout will not emit anything else since nothing has been committed 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 none 
WITHOUT_CLASSIFICATION	 the metrics store not critical the operation the cluster allow nimbus come 
WITHOUT_CLASSIFICATION	 check the credential our principal 
WITHOUT_CLASSIFICATION	 system bolt doesnt call reporterror 
WITHOUT_CLASSIFICATION	 join against diff stream compared 
WITHOUT_CLASSIFICATION	 parsed topology definition 
WITHOUT_CLASSIFICATION	 compile parameters 
WITHOUT_CLASSIFICATION	 check for all ports 
WITHOUT_CLASSIFICATION	 streaid indicates where tuple came from 
WITHOUT_CLASSIFICATION	 for the node dont know have another one unless look the contents 
WITHOUT_CLASSIFICATION	 workerhooks 
WITHOUT_CLASSIFICATION	 validate search stream 
WITHOUT_CLASSIFICATION	 debugoptions 
WITHOUT_CLASSIFICATION	 storm support launch workers older version the config comes from the older version replace the package name 
WITHOUT_CLASSIFICATION	 update the watermark this timestamp 
WITHOUT_CLASSIFICATION	 create spouts 
WITHOUT_CLASSIFICATION	 need wait until sasl channel also ready 
WITHOUT_CLASSIFICATION	 perf critical path would nice avoid iterator allocation here and below 
WITHOUT_CLASSIFICATION	 all column families 
WITHOUT_CLASSIFICATION	 generate some that has alot memory but little cpu 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 userspout jdbcbolt 
WITHOUT_CLASSIFICATION	 all things are from dependencies 
WITHOUT_CLASSIFICATION	 nothing 
WITHOUT_CLASSIFICATION	 test exist with nonexistent key 
WITHOUT_CLASSIFICATION	 testing whether acls are set worldeverything 
WITHOUT_CLASSIFICATION	 iterate through all executor heartbeats 
WITHOUT_CLASSIFICATION	 there are free slots that can take advantage now 
WITHOUT_CLASSIFICATION	 need more data 
WITHOUT_CLASSIFICATION	 port 
WITHOUT_CLASSIFICATION	 register call back for blobstore 
WITHOUT_CLASSIFICATION	 taskstart 
WITHOUT_CLASSIFICATION	 tests for case when subject null security turned and acls for the blob are set worldeverything 
WITHOUT_CLASSIFICATION	 restart 
WITHOUT_CLASSIFICATION	 performs projection the tuples based projectionfields 
WITHOUT_CLASSIFICATION	 are running should recover the blobs 
WITHOUT_CLASSIFICATION	 something happened and couldnt find the file ignore for now 
WITHOUT_CLASSIFICATION	 setup spout 
WITHOUT_CLASSIFICATION	 callback caller 
WITHOUT_CLASSIFICATION	 testing whether acls are set worldeverything here the acl should not contain worldeverything because the subject neither null nor empty the acl should however contain usereverything user needs have 
WITHOUT_CLASSIFICATION	 inputs 
WITHOUT_CLASSIFICATION	 make sure lines from each file were read all 
WITHOUT_CLASSIFICATION	 topology 
WITHOUT_CLASSIFICATION	 look for public instance variable 
WITHOUT_CLASSIFICATION	 need one large set all and then clean via lru 
WITHOUT_CLASSIFICATION	 all other cases check for the latest update sequence the blob the nimbus and assign the appropriate number check all are have same sequence number 
WITHOUT_CLASSIFICATION	 local worker heartbeat can null cause some errorexception 
WITHOUT_CLASSIFICATION	 because local mode its not separate process supervisor will register this case returns false then distributed mode 
WITHOUT_CLASSIFICATION	 compare contents files 
WITHOUT_CLASSIFICATION	 true this offsetmanager has made least one commit kafka 
WITHOUT_CLASSIFICATION	 minimum version supporting storm would 
WITHOUT_CLASSIFICATION	 assignedcpu 
WITHOUT_CLASSIFICATION	 sleep before cleaning files 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 state query added the existing stateful bolt 
WITHOUT_CLASSIFICATION	 attempts lookup the unique for string that may not exist yet returns 
WITHOUT_CLASSIFICATION	 only used for timedrotationpolicy 
WITHOUT_CLASSIFICATION	 bolt 
WITHOUT_CLASSIFICATION	 error occurs but assignment has not changed 
WITHOUT_CLASSIFICATION	 ensure there only the default stream when configuring the spout should safe ignore the parameter here 
WITHOUT_CLASSIFICATION	 batch played with tuples initially 
WITHOUT_CLASSIFICATION	 save try again later 
WITHOUT_CLASSIFICATION	 this was byte test 
WITHOUT_CLASSIFICATION	 pendingprepare has entries 
WITHOUT_CLASSIFICATION	 static state 
WITHOUT_CLASSIFICATION	 got least one getpulseresponse message 
WITHOUT_CLASSIFICATION	 overrides are disabled wont replace anything that already exists 
WITHOUT_CLASSIFICATION	 fall through purpose 
WITHOUT_CLASSIFICATION	 mock the supervisor failed supervisor 
WITHOUT_CLASSIFICATION	 restart topology with different topology 
WITHOUT_CLASSIFICATION	 set null and get the old value 
WITHOUT_CLASSIFICATION	 test with integer value 
WITHOUT_CLASSIFICATION	 schedule nimbus code sync thread sync code from other nimbuses 
WITHOUT_CLASSIFICATION	 assignment has changed 
WITHOUT_CLASSIFICATION	 pretend storm 
WITHOUT_CLASSIFICATION	 required required required 
WITHOUT_CLASSIFICATION	 now verify that when switched can recover 
WITHOUT_CLASSIFICATION	 doesnt manipulate tuples lists stuff that things like aggregating into cassandra cleaner dont need lists everywhere just store the single value there 
WITHOUT_CLASSIFICATION	 wrapper hold global and window averages 
WITHOUT_CLASSIFICATION	 start the part the log file are interested 
WITHOUT_CLASSIFICATION	 windows should set this false cause symlink compressed file doesnt work properly 
WITHOUT_CLASSIFICATION	 set closing true prevent any further reconnection attempts 
WITHOUT_CLASSIFICATION	 there are some different levels accuracy here and want deal with all them 
WITHOUT_CLASSIFICATION	 the spout should have emitted the tuple and must have committed before emit 
WITHOUT_CLASSIFICATION	 populate with existing assignments 
WITHOUT_CLASSIFICATION	 ignore not tupleimpl type faster than checking and then casting 
WITHOUT_CLASSIFICATION	 store can null during testing when mocking utils 
WITHOUT_CLASSIFICATION	 output the sum all the known counts for this key 
WITHOUT_CLASSIFICATION	 read the short field 
WITHOUT_CLASSIFICATION	 filesystem path the resource 
WITHOUT_CLASSIFICATION	 topohistory 
WITHOUT_CLASSIFICATION	 should rewrite this file move 
WITHOUT_CLASSIFICATION	 tests subclassing 
WITHOUT_CLASSIFICATION	 send response client 
WITHOUT_CLASSIFICATION	 get trigger values only they have more than zero 
WITHOUT_CLASSIFICATION	 all messages except the first acked message should have been emitted 
WITHOUT_CLASSIFICATION	 theres enough bytes the buffer read 
WITHOUT_CLASSIFICATION	 get host all assignable worker slots for nonblacklisted machines assigned not assigned will then have list machines that need assigned machine topology list list executors match each spec machine who has the right number workers free everything else that machine and assign those slots one topology time blacklist all machines who had production slots defined log isolated topologies who werent able get enough slots machines run default scheduler isolated topologies that didnt have enough slots nonisolated topologies remaining machines set blacklist what was initially 
WITHOUT_CLASSIFICATION	 noop prepare should have already been called 
WITHOUT_CLASSIFICATION	 demonstrate that the spout doesnt ack pending tuples when skipping compacted tuples the pending tuples should allowed finish normally 
WITHOUT_CLASSIFICATION	 failed get anything from artifactory try get from our local cache 
WITHOUT_CLASSIFICATION	 test when worker fails ras does not alter existing assignments healthy workers 
WITHOUT_CLASSIFICATION	 keep track how many times see each taskid 
WITHOUT_CLASSIFICATION	 make sure that have received least short 
WITHOUT_CLASSIFICATION	 previous code used this method generate the string ensure the two match 
WITHOUT_CLASSIFICATION	 should acked once 
WITHOUT_CLASSIFICATION	 window length 
WITHOUT_CLASSIFICATION	 need add empty string else nto added query param 
WITHOUT_CLASSIFICATION	 storm regression test verify that remote worker can handle many tasks one executor 
WITHOUT_CLASSIFICATION	 attempt schedule multiple copies different topologies topot and topot blocks without fragmentation possible schedule all topologies but fragmentation causes topologies not schedule for the last block 
WITHOUT_CLASSIFICATION	 two seconds tumbling window 
WITHOUT_CLASSIFICATION	 this verifies that partitions cant prevent each other from retrying tuples due the limit 
WITHOUT_CLASSIFICATION	 another thread could writing out the metadata cache the database 
WITHOUT_CLASSIFICATION	 duplicate case 
WITHOUT_CLASSIFICATION	 needed keep simplefileobject constructor happy 
WITHOUT_CLASSIFICATION	 constraints and spreads 
WITHOUT_CLASSIFICATION	 remove executor details assigned the failed worker 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 executorinfo 
WITHOUT_CLASSIFICATION	 otherwise dont bother them 
WITHOUT_CLASSIFICATION	 aggregate matching metrics over bucket timeframes well process starting with the longest bucket the metric for this does not exist dont have 
WITHOUT_CLASSIFICATION	 this the topology page know the user authorized 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 the offset the last available message 
WITHOUT_CLASSIFICATION	 call firemessageread since the client allowed perform this request the clients request will now proceed the next pipeline component namely stormclienthandler 
WITHOUT_CLASSIFICATION	 with exhibitor 
WITHOUT_CLASSIFICATION	 creating nimbus hosts containing latest version blob 
WITHOUT_CLASSIFICATION	 jsonconf 
WITHOUT_CLASSIFICATION	 check lock file presence 
WITHOUT_CLASSIFICATION	 interval which commit offsets milliseconds 
WITHOUT_CLASSIFICATION	 remove the slot from the existing assignments 
WITHOUT_CLASSIFICATION	 spout with parallel instances 
WITHOUT_CLASSIFICATION	 just ignore these for now are going throw away anyways 
WITHOUT_CLASSIFICATION	 holds remaining streams 
WITHOUT_CLASSIFICATION	 class that has the logic handle tuple failure 
WITHOUT_CLASSIFICATION	 sets link solrfieldsmapper use the default solr collection there one defined 
WITHOUT_CLASSIFICATION	 adds the serialized and base file the credentials map string with the filename the key 
WITHOUT_CLASSIFICATION	 works emitting null the collector since the planner knows this add node with new output fields just passes the tuple forward 
WITHOUT_CLASSIFICATION	 get existing tuples and pendingunsuccessful triggers for this and add them windowmanager 
WITHOUT_CLASSIFICATION	 consumer rebalance listener the same thread the caller 
WITHOUT_CLASSIFICATION	 truststore file assume the truststore the keystore 
WITHOUT_CLASSIFICATION	 needed could make config for update thread pool size 
WITHOUT_CLASSIFICATION	 updating blacklist file periodically with random words 
WITHOUT_CLASSIFICATION	 all failed events are put toresend which sorted events offset 
WITHOUT_CLASSIFICATION	 anonymous user 
WITHOUT_CLASSIFICATION	 error 
WITHOUT_CLASSIFICATION	 optimizes relnode with ruleset 
WITHOUT_CLASSIFICATION	 kill newly submit 
WITHOUT_CLASSIFICATION	 task under backpressure initially 
WITHOUT_CLASSIFICATION	 enable metrics 
WITHOUT_CLASSIFICATION	 partitions evicted window state 
WITHOUT_CLASSIFICATION	 for each owner get resources configs and aggregate 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 get mapping components executors 
WITHOUT_CLASSIFICATION	 indexed 
WITHOUT_CLASSIFICATION	 configs topo parallelism 
WITHOUT_CLASSIFICATION	 next scheduled refresh sooner than now mintimebeforelogin 
WITHOUT_CLASSIFICATION	 fileoffset one past last scanned file 
WITHOUT_CLASSIFICATION	 this partition was previously assigned the consumer position shouldnt change 
WITHOUT_CLASSIFICATION	 catch any runtime exceptions caused eviction 
WITHOUT_CLASSIFICATION	 this ignored javac currently but usejavautilzip should 
WITHOUT_CLASSIFICATION	 required required required optional optional optional optional optional optional optional 
WITHOUT_CLASSIFICATION	 make sure the property was actually set 
WITHOUT_CLASSIFICATION	 boltspecific configuration for windowed bolts specify the sliding interval time duration 
WITHOUT_CLASSIFICATION	 sanity check the provided test data 
WITHOUT_CLASSIFICATION	 split the sentences words 
WITHOUT_CLASSIFICATION	 otherwise poll see any new event was scheduled this essence the response time for detecting any new event schedulings when there are scheduled events 
WITHOUT_CLASSIFICATION	 lock file has been updated since last time then leave this lock file alone 
WITHOUT_CLASSIFICATION	 records that have been polled and are queued emitted the nexttuple call one record emitted per nexttuple 
WITHOUT_CLASSIFICATION	 meta 
WITHOUT_CLASSIFICATION	 sends the same tuple list scoredpredicted values all the declared streams 
WITHOUT_CLASSIFICATION	 always check recq acking enabled 
WITHOUT_CLASSIFICATION	 package access for unit tests 
WITHOUT_CLASSIFICATION	 jcqueue spoutq new jcqueuespoutq jcqueue ackq new jcqueueackq final ackingproducer ackingproducer new ackq final acker acker new ackerackq spoutq acker 
WITHOUT_CLASSIFICATION	 task ids experiencing can null task ids longer experiencing can null 
WITHOUT_CLASSIFICATION	 instantiate the hdfsbolt 
WITHOUT_CLASSIFICATION	 this method should return sequential numbers starting 
WITHOUT_CLASSIFICATION	 statespouts 
WITHOUT_CLASSIFICATION	 have copied and pasted some the needed mainmethods here with few changes logging 
WITHOUT_CLASSIFICATION	 gsidtoinputstats 
WITHOUT_CLASSIFICATION	 only place fall though the loop over again 
WITHOUT_CLASSIFICATION	 thread died before could get the info skip 
WITHOUT_CLASSIFICATION	 should not have flushed file system yet 
WITHOUT_CLASSIFICATION	 make sure the worker down before try shoot any child processes 
WITHOUT_CLASSIFICATION	 not assign the highest sequence number 
WITHOUT_CLASSIFICATION	 slotsused origrequest 
WITHOUT_CLASSIFICATION	 max heap size for worker used topology 
WITHOUT_CLASSIFICATION	 tmpdir will handled separately 
WITHOUT_CLASSIFICATION	 that store passed windowstateupdater remove them after committing the batch 
WITHOUT_CLASSIFICATION	 this arbitrary choice make the result consistent with calculatemin any value would valid here becase there are nonzero resources the total set resources were trying average values 
WITHOUT_CLASSIFICATION	 the component system component and are hiding them keep going 
WITHOUT_CLASSIFICATION	 errors 
WITHOUT_CLASSIFICATION	 metastoreuri 
WITHOUT_CLASSIFICATION	 ack the tuple and commit since the tuple more than max poll records behind the most recent emitted tuple the consumer wont catch this poll 
WITHOUT_CLASSIFICATION	 load drivermanager first avoid any race condition between drivermanager static initialization block and specific driver classs static initialization block phoenixdriver should take this workaround since prepare method synchronized but worker can initialize multiple abstractjdbcbolt instances and they would make race condition just need ensure that drivermanager class always initialized earlier than provider below line should called first than initializing provider 
WITHOUT_CLASSIFICATION	 class directinserter 
WITHOUT_CLASSIFICATION	 keys sorted descending order 
WITHOUT_CLASSIFICATION	 unpin the last partition 
WITHOUT_CLASSIFICATION	 now check for autocreds that are missing from the command line but only the command line used 
WITHOUT_CLASSIFICATION	 store inprocess triggers batch store for batch retries for any failures 
WITHOUT_CLASSIFICATION	 deleting this early does not hurt anything 
WITHOUT_CLASSIFICATION	 request from hosts that are not authorized should rejected 
WITHOUT_CLASSIFICATION	 ignoredexpected 
WITHOUT_CLASSIFICATION	 the user from the token bob verify that the name was set correctly 
WITHOUT_CLASSIFICATION	 package level for unit tests 
WITHOUT_CLASSIFICATION	 case 
WITHOUT_CLASSIFICATION	 topology 
WITHOUT_CLASSIFICATION	 gets database 
WITHOUT_CLASSIFICATION	 server 
WITHOUT_CLASSIFICATION	 hive principal stormhivewitzencom storm hive keytab hivemetastoreuris 
WITHOUT_CLASSIFICATION	 sharedmemonheap 
WITHOUT_CLASSIFICATION	 ignore file names config 
WITHOUT_CLASSIFICATION	 normal create update sync scenario returns the greatest sequence number the set 
WITHOUT_CLASSIFICATION	 for jackson 
WITHOUT_CLASSIFICATION	 heartbeat ensure its longer stale and read back the heartbeat data 
WITHOUT_CLASSIFICATION	 this cannot happen since were using standard charset 
WITHOUT_CLASSIFICATION	 how often poll exhibitor cluster millis 
WITHOUT_CLASSIFICATION	 intended behavior 
WITHOUT_CLASSIFICATION	 expected 
WITHOUT_CLASSIFICATION	 index null memory cpu 
WITHOUT_CLASSIFICATION	 should the topology active inactive 
WITHOUT_CLASSIFICATION	 get mapping execs components 
WITHOUT_CLASSIFICATION	 play tuple 
WITHOUT_CLASSIFICATION	 expect the bolt log exactly one decorated line per emit 
WITHOUT_CLASSIFICATION	 this must defensively copied because bolt probably has only one rotation policy object 
WITHOUT_CLASSIFICATION	 test that the setloggerlevel function was not called 
WITHOUT_CLASSIFICATION	 required optional optional optional optional optional optional optional optional optional optional optional optional optional optional optional optional optional 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 cluster forgets about its previous status scheduled just leave 
WITHOUT_CLASSIFICATION	 try again empty assignment has been nulled 
WITHOUT_CLASSIFICATION	 lastly the default servlet for root content always needed satisfy servlet spec 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 read lines file 
WITHOUT_CLASSIFICATION	 object associated with json field already json 
WITHOUT_CLASSIFICATION	 required required required required required 
WITHOUT_CLASSIFICATION	 check component declared for spreading 
WITHOUT_CLASSIFICATION	 first need some configs 
WITHOUT_CLASSIFICATION	 trigger occurred create aggregation and keep them store 
WITHOUT_CLASSIFICATION	 check can run topology with that version storm 
WITHOUT_CLASSIFICATION	 repartitioning involved does perpartition aggregate key before emitting the results downstream 
WITHOUT_CLASSIFICATION	 deletes metadata strings before the provided timestamp 
WITHOUT_CLASSIFICATION	 assume that within the minimum congestion still fine not congested grow but slowly 
WITHOUT_CLASSIFICATION	 the worker orphan the worker that fails the healthy worker 
WITHOUT_CLASSIFICATION	 same txid can prepared again but the next txid cannot prepared when previous one not committed yet 
WITHOUT_CLASSIFICATION	 topology executor ids component stats 
WITHOUT_CLASSIFICATION	 merge contents config into topology config 
WITHOUT_CLASSIFICATION	 convenience method for registering combinedmetric 
WITHOUT_CLASSIFICATION	 map from topology set sets executors 
WITHOUT_CLASSIFICATION	 make key list download 
WITHOUT_CLASSIFICATION	 totalworkers 
WITHOUT_CLASSIFICATION	 all tuples acked 
WITHOUT_CLASSIFICATION	 update the size the objects 
WITHOUT_CLASSIFICATION	 should 
WITHOUT_CLASSIFICATION	 completelatencyms 
WITHOUT_CLASSIFICATION	 copy the data 
WITHOUT_CLASSIFICATION	 get metric name 
WITHOUT_CLASSIFICATION	 there are remote outbound tasks dont start the thread 
WITHOUT_CLASSIFICATION	 download missing blobs from potential nimbodes 
WITHOUT_CLASSIFICATION	 just ignore any errorexception 
WITHOUT_CLASSIFICATION	 avoid allocating spoutackinfo obj not necessary 
WITHOUT_CLASSIFICATION	 not going timeout for while 
WITHOUT_CLASSIFICATION	 try emit all messages ensure only are emitted 
WITHOUT_CLASSIFICATION	 only try reading once 
WITHOUT_CLASSIFICATION	 jpmml evaluator 
WITHOUT_CLASSIFICATION	 for each partition the spout allowed retry all tuples between the committed offset and ahead not allowed retry tuples past that limit this makes the actual limit per partition maxpollrecords reached the tuple the limit the earliest retriable tuple the spout tuple below the limit and receives full maxpollrecords tuples the poll 
WITHOUT_CLASSIFICATION	 submit topology 
WITHOUT_CLASSIFICATION	 poll metrics every minute then kill topology after specified duration 
WITHOUT_CLASSIFICATION	 validate least two agg level none metrics exist 
WITHOUT_CLASSIFICATION	 allow the failed record retry 
WITHOUT_CLASSIFICATION	 listens for all metrics dumps them text configured hostport use add this your topologys configuration java hostport edit the stormyaml config file yaml class argument examplecom parallelismhint 
WITHOUT_CLASSIFICATION	 for now not make transaction when removing topology assignment from local overdue assignment may left local disk should check the local disk assignment valid when initializing topology files does not exist the workerpossibly alive will reassigned timedout topology files exist but the topology invalid just let supervisor make sync topology files exist and topology files valid recover the container 
WITHOUT_CLASSIFICATION	 node under which commit the sequence number messages 
WITHOUT_CLASSIFICATION	 just few polls check that nothing more emitted 
WITHOUT_CLASSIFICATION	 topo should evicted since its been the longest 
WITHOUT_CLASSIFICATION	 ack few 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 clean the profiler actions that are not being processed 
WITHOUT_CLASSIFICATION	 cassandra doesnt actually shut down until jvm shutdown need wait for that first 
WITHOUT_CLASSIFICATION	 authenticate removed after authentication completes 
WITHOUT_CLASSIFICATION	 get sorted list unassigned executors based number constraints 
WITHOUT_CLASSIFICATION	 now schedule gpu but with the simple topology place 
WITHOUT_CLASSIFICATION	 dont have anything 
WITHOUT_CLASSIFICATION	 targetsize bytes 
WITHOUT_CLASSIFICATION	 spout settings 
WITHOUT_CLASSIFICATION	 defaults 
WITHOUT_CLASSIFICATION	 used for reporting used ports when heartbeating 
WITHOUT_CLASSIFICATION	 any change this code must serializable compatible there will problems 
WITHOUT_CLASSIFICATION	 aggregate the count 
WITHOUT_CLASSIFICATION	 noop 
WITHOUT_CLASSIFICATION	 make sure the timestamp the metadata has the latest time 
WITHOUT_CLASSIFICATION	 some components might have different resource configs 
WITHOUT_CLASSIFICATION	 iterate again 
WITHOUT_CLASSIFICATION	 just quit 
WITHOUT_CLASSIFICATION	 additional safety check make sure that topologysubmitter going valid value 
WITHOUT_CLASSIFICATION	 root password 
WITHOUT_CLASSIFICATION	 dont exit not running unless error 
WITHOUT_CLASSIFICATION	 unknown should only happen during compilation some unit tests 
WITHOUT_CLASSIFICATION	 convert targets json serializable format 
WITHOUT_CLASSIFICATION	 stream words 
WITHOUT_CLASSIFICATION	 insert child inbetween parent and its current child nodes 
WITHOUT_CLASSIFICATION	 shuffle 
WITHOUT_CLASSIFICATION	 check that only the tuple the currently assigned partition retried 
WITHOUT_CLASSIFICATION	 optional optional optional optional optional optional optional optional optional optional optional optional optional optional optional optional 
WITHOUT_CLASSIFICATION	 just ignore the exception 
WITHOUT_CLASSIFICATION	 from localizertest 
WITHOUT_CLASSIFICATION	 execstats 
WITHOUT_CLASSIFICATION	 first should have expired due expire events threshold 
WITHOUT_CLASSIFICATION	 seconds passed timed out 
WITHOUT_CLASSIFICATION	 topic compaction enabled kafka sometimes need commit past gap deleted offsets since the kafka consumer should return offsets order can assume that message acked then any prior message will have been emitted least once see acked message and some the offsets preceding were not emitted they must have been compacted away and should skipped 
WITHOUT_CLASSIFICATION	 since made sys components hidden the component map empty for this worker 
WITHOUT_CLASSIFICATION	 nodehost 
WITHOUT_CLASSIFICATION	 methods for validating confs 
WITHOUT_CLASSIFICATION	 also add support for worker tokens 
WITHOUT_CLASSIFICATION	 build phase segregate tuples the window into streams first streams tuples into probe rest into hashmaps hashedinputs 
WITHOUT_CLASSIFICATION	 now check for overlap the node 
WITHOUT_CLASSIFICATION	 the window partition that holds the events 
WITHOUT_CLASSIFICATION	 number retry attempts for 
WITHOUT_CLASSIFICATION	 same txid can committed again but the txid committed must the last prepared one 
WITHOUT_CLASSIFICATION	 make every attempt sync the data have cant done then kill the bolt with runtime exception the filesystem presumably very bad state 
WITHOUT_CLASSIFICATION	 fall through not supported 
WITHOUT_CLASSIFICATION	 when tuple tracking enabled the spout must not commit acked tuples atmostonce mode because they were committed before being emitted 
WITHOUT_CLASSIFICATION	 avoid locking will through the map twice should small probably not big deal 
WITHOUT_CLASSIFICATION	 emit the count for the words that occurred atleast five times the last two seconds 
WITHOUT_CLASSIFICATION	 for backwards compatability 
WITHOUT_CLASSIFICATION	 nothing expires until threshold hit 
WITHOUT_CLASSIFICATION	 default seconds cache the size cheap 
WITHOUT_CLASSIFICATION	 ack all emitted messages and commit them 
WITHOUT_CLASSIFICATION	 normally this noop 
WITHOUT_CLASSIFICATION	 perf critical path dont use iterators 
WITHOUT_CLASSIFICATION	 nothing 
WITHOUT_CLASSIFICATION	 read the partitions transaction ids and offsets from the old stormkafka user path 
WITHOUT_CLASSIFICATION	 max number events cached memory 
WITHOUT_CLASSIFICATION	 get document 
WITHOUT_CLASSIFICATION	 required required optional optional 
WITHOUT_CLASSIFICATION	 read from state store not found use startingoffset 
WITHOUT_CLASSIFICATION	 validate args 
WITHOUT_CLASSIFICATION	 the match this candidate offset failed start over with the next candidate byte from the buffer 
WITHOUT_CLASSIFICATION	 ensure always same order for registrations with treemap 
WITHOUT_CLASSIFICATION	 initialize spout using the same populated data same kafkaunitrule 
WITHOUT_CLASSIFICATION	 refresh the ticket granting ticket tgt periodically how often refresh determined the tgts existing expiry date and the configured for testing and development you can decrease the interval expiration tickets for example minutes running 
WITHOUT_CLASSIFICATION	 populate worker comp assignments 
WITHOUT_CLASSIFICATION	 non error scenarios for the azure data lake store file system adl the output stream must closed before the file associated with deleted for adlfs deleting the file also removes any handles the file hence outclose will fail 
WITHOUT_CLASSIFICATION	 wildcard file 
WITHOUT_CLASSIFICATION	 groups username command return nonconsistent across different unixes 
WITHOUT_CLASSIFICATION	 cached topology executor ids used for deciding timeout workers heartbeatscache 
WITHOUT_CLASSIFICATION	 create windowed stream five seconds duration 
WITHOUT_CLASSIFICATION	 spout should ack failed messages after they hit the retry limit 
WITHOUT_CLASSIFICATION	 take ones complement 
WITHOUT_CLASSIFICATION	 environment variable substitution 
WITHOUT_CLASSIFICATION	 dont modify the original 
WITHOUT_CLASSIFICATION	 nothing 
WITHOUT_CLASSIFICATION	 the frequency reporting 
WITHOUT_CLASSIFICATION	 sleep for seconds 
WITHOUT_CLASSIFICATION	 early detectionearly fail 
WITHOUT_CLASSIFICATION	 ensures overflowcount overflowlimit set disables overflow limiting 
WITHOUT_CLASSIFICATION	 initialize the hashedinputs data structure 
WITHOUT_CLASSIFICATION	 the current lat and count buckets are protected different lock from the other buckets this reduce the lock contention when doing complex calculations never grab the instance object lock 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 found 
WITHOUT_CLASSIFICATION	 emit and fail the same tuple until weve reached retry limit 
WITHOUT_CLASSIFICATION	 dont prorate anything all approximate extra bucket not that bad 
WITHOUT_CLASSIFICATION	 parts empty for cgroups else what mapped that are looking for 
WITHOUT_CLASSIFICATION	 wrapping makes mutable 
WITHOUT_CLASSIFICATION	 test deep equal 
WITHOUT_CLASSIFICATION	 save the current user help with recovery 
WITHOUT_CLASSIFICATION	 taskid jcqueue initialized after local executors are initialized 
WITHOUT_CLASSIFICATION	 shard iterator not present for this message get 
WITHOUT_CLASSIFICATION	 this triggers cannot convert null int 
WITHOUT_CLASSIFICATION	 this also tracks how many times worker transitioning out state 
WITHOUT_CLASSIFICATION	 storm blobstore update file blacklisttxt key 
WITHOUT_CLASSIFICATION	 note that delete the return value 
WITHOUT_CLASSIFICATION	 waitsecs 
WITHOUT_CLASSIFICATION	 get the list keys from blobstore 
WITHOUT_CLASSIFICATION	 the following are required were defining core storm topology dag yaml etc 
WITHOUT_CLASSIFICATION	 use this weird wrapper pattern temporarily for mocking clojure test 
WITHOUT_CLASSIFICATION	 archive dir config 
WITHOUT_CLASSIFICATION	 remove 
WITHOUT_CLASSIFICATION	 track resources user resourceset concurrenthashmap explicitly used everywhere this class because uses locks guarantee atomicity for compute and computeifabsent where concurrentmap allows for retry the function passed and would require the function have side effects 
WITHOUT_CLASSIFICATION	 write the mocking backwards the actual method not called the spy object 
WITHOUT_CLASSIFICATION	 user will decide which topologies are run and which ones are not 
WITHOUT_CLASSIFICATION	 topo evicted lowest priority 
WITHOUT_CLASSIFICATION	 the retry service returns message that not failed set then ignore should never happen 
WITHOUT_CLASSIFICATION	 the key the map the worker and the value the corresponding workerslot object 
WITHOUT_CLASSIFICATION	 specified via boltselect used declaring output fields protected string fieldnames xyz format stream name used for naming output fields 
WITHOUT_CLASSIFICATION	 check lock file gone 
WITHOUT_CLASSIFICATION	 map from batchgroupid coordspec 
WITHOUT_CLASSIFICATION	 test another topology getting blob with updated version should update version now 
WITHOUT_CLASSIFICATION	 make sure all workers scheduled rack the favored nodes would have put different rack but because that rack does not have free space run the topology falls back this rack 
WITHOUT_CLASSIFICATION	 base for exponential function seconds for retrying for second third and failures 
WITHOUT_CLASSIFICATION	 topologyid workerid executors 
WITHOUT_CLASSIFICATION	 timestamp decide when commit again 
WITHOUT_CLASSIFICATION	 nimbus being newly elected leader change recurring pattern addresses these problems 
WITHOUT_CLASSIFICATION	 authorize 
WITHOUT_CLASSIFICATION	 wait for locks expire 
WITHOUT_CLASSIFICATION	 should have created blobdir 
WITHOUT_CLASSIFICATION	 free slot 
WITHOUT_CLASSIFICATION	 test launch topo and they together request little more mem than available one the topos will not 
WITHOUT_CLASSIFICATION	 executemsavg 
WITHOUT_CLASSIFICATION	 customserialized 
WITHOUT_CLASSIFICATION	 class pair 
WITHOUT_CLASSIFICATION	 try modify the list which should fail 
WITHOUT_CLASSIFICATION	 default batch size 
WITHOUT_CLASSIFICATION	 add default user acl when only empty user acl not present 
WITHOUT_CLASSIFICATION	 totalspoutlag 
WITHOUT_CLASSIFICATION	 stats 
WITHOUT_CLASSIFICATION	 make the consumer return single message for each partition 
WITHOUT_CLASSIFICATION	 adding metadata avoid null pointer exception 
WITHOUT_CLASSIFICATION	 add endofbatch indicator 
WITHOUT_CLASSIFICATION	 works out 
WITHOUT_CLASSIFICATION	 rebalance 
WITHOUT_CLASSIFICATION	 wait and check for expiry again 
WITHOUT_CLASSIFICATION	 the maximum number states that will searched looking for solution the constraint solver strategy 
WITHOUT_CLASSIFICATION	 length parts should greater than 
WITHOUT_CLASSIFICATION	 call prepare with our available taskids 
WITHOUT_CLASSIFICATION	 consume the iterator traversing and thus emptying 
WITHOUT_CLASSIFICATION	 stream cannot null 
WITHOUT_CLASSIFICATION	 taken care finally block 
WITHOUT_CLASSIFICATION	 submit topology wait for few min and terminate 
WITHOUT_CLASSIFICATION	 since user jerry has enough resource guarantee 
WITHOUT_CLASSIFICATION	 abandon file 
WITHOUT_CLASSIFICATION	 this filter makes sure receive only key row but not values associated with those rows 
WITHOUT_CLASSIFICATION	 without exhibitor 
WITHOUT_CLASSIFICATION	 for backward compatibility 
WITHOUT_CLASSIFICATION	 calc cidsidinputstats 
WITHOUT_CLASSIFICATION	 emit message each partition and revoke the first partition 
WITHOUT_CLASSIFICATION	 acls are not set for the blob default 
WITHOUT_CLASSIFICATION	 metrics related 
WITHOUT_CLASSIFICATION	 required required required optional optional optional optional optional optional optional optional 
WITHOUT_CLASSIFICATION	 imeta 
WITHOUT_CLASSIFICATION	 routine level 
WITHOUT_CLASSIFICATION	 this should not happen because checked for public isfieldallowed 
WITHOUT_CLASSIFICATION	 bolts 
WITHOUT_CLASSIFICATION	 container collection tuples 
WITHOUT_CLASSIFICATION	 the limit should not enforced since only meaningful atleastonce mode 
WITHOUT_CLASSIFICATION	 need more data 
WITHOUT_CLASSIFICATION	 while 
WITHOUT_CLASSIFICATION	 spouts that use them only one uses they can created inline with the add 
WITHOUT_CLASSIFICATION	 havent found string keep searching 
WITHOUT_CLASSIFICATION	 prevent issue when the implementation fieldnames not serializable returns calcite pair which not serializable 
WITHOUT_CLASSIFICATION	 the jsonconf populated topologybuilder 
WITHOUT_CLASSIFICATION	 group node 
WITHOUT_CLASSIFICATION	 acl 
WITHOUT_CLASSIFICATION	 heartbeat here that worker process dies this fails its important that worker heartbeat supervisor asap that supervisor knows 
WITHOUT_CLASSIFICATION	 uptimesecs 
WITHOUT_CLASSIFICATION	 hdfs keytabprincipal have been supplied login otherwise assume they are logged already running insecure hdfs 
WITHOUT_CLASSIFICATION	 this directory file 
WITHOUT_CLASSIFICATION	 producer 
WITHOUT_CLASSIFICATION	 might need set the number acker executors and eventlogger executors the estimated number workers 
WITHOUT_CLASSIFICATION	 hbase has some entries 
WITHOUT_CLASSIFICATION	 will adjust weights based off the minimum load 
WITHOUT_CLASSIFICATION	 tried all the slots and none them worked 
WITHOUT_CLASSIFICATION	 need block the task run the executor safe run even after metrics are closed 
WITHOUT_CLASSIFICATION	 componentdebug 
WITHOUT_CLASSIFICATION	 should throw 
WITHOUT_CLASSIFICATION	 nimbus admin 
WITHOUT_CLASSIFICATION	 component overrides 
WITHOUT_CLASSIFICATION	 let add the kerbclientprinc and kerbticket need clone the ticket because assumes tgt unique for each subject sharing tgt with multiple subjects can cause expired tgt never refresh 
WITHOUT_CLASSIFICATION	 stop emitting certain point because log rolling breaks the tests 
WITHOUT_CLASSIFICATION	 shard iterator corresponding position shard for new messages 
WITHOUT_CLASSIFICATION	 level longer idling with threadsleep 
WITHOUT_CLASSIFICATION	 this does not have atomic worst case update when one not needed 
WITHOUT_CLASSIFICATION	 the windows should persisted state 
WITHOUT_CLASSIFICATION	 todo deduplicate this logic with the code nimbus 
WITHOUT_CLASSIFICATION	 define our taskids and loads 
WITHOUT_CLASSIFICATION	 test for supervisor admin 
WITHOUT_CLASSIFICATION	 read another line and see another log entry was made 
WITHOUT_CLASSIFICATION	 control cpu usage 
WITHOUT_CLASSIFICATION	 emitted offsets list 
WITHOUT_CLASSIFICATION	 there acked tupled after compaction gap the spout should commit immediately 
WITHOUT_CLASSIFICATION	 main 
WITHOUT_CLASSIFICATION	 commit solr and ack according the commit strategy 
WITHOUT_CLASSIFICATION	 spouts 
WITHOUT_CLASSIFICATION	 even though normally bolts not need care about thread safety this particular bolt different maintains static field that prepopulated before the topology starts written into the topology and then read from after the topology completed all this potentially different threads 
WITHOUT_CLASSIFICATION	 activate deactivate close declare outputs 
WITHOUT_CLASSIFICATION	 this will only ever grow need worry about falling off the end 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 update streamstate based stateupdates 
WITHOUT_CLASSIFICATION	 equivalent update command command line 
WITHOUT_CLASSIFICATION	 the partition revocation hook must called before the new partitions are assigned the consumer 
WITHOUT_CLASSIFICATION	 new topology needs scheduled 
WITHOUT_CLASSIFICATION	 small control algorithm adjust the amount time that sleep make more accurate 
WITHOUT_CLASSIFICATION	 cached globalstreamid 
WITHOUT_CLASSIFICATION	 special cases for storm 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 partition state path 
WITHOUT_CLASSIFICATION	 everything should fit single slot 
WITHOUT_CLASSIFICATION	 last fetched sequence number corresponding position shard 
WITHOUT_CLASSIFICATION	 sorted acked sequence numbers needed figure out what sequence number can committed 
WITHOUT_CLASSIFICATION	 check that null meta makes the spout seek latest and that the returned meta correct 
WITHOUT_CLASSIFICATION	 tuple 
WITHOUT_CLASSIFICATION	 todo jsonify stormtopology the minimum should send source info 
WITHOUT_CLASSIFICATION	 timer 
WITHOUT_CLASSIFICATION	 dont allow topoconf override various clusterspecific properties specifically adding the cluster settings the topoconf here will make sure these settings also override the subsequently generated conf picked locally the classpath will dealing with confs the submitted topoconf created here the combined classpath conf with the topoconf added top the nimbus conf with conf above added top first forcing the topology conf contain the nimbus settings guarantee all three confs 
WITHOUT_CLASSIFICATION	 switch the new assignment even localization hasnt completed empty state 
WITHOUT_CLASSIFICATION	 calcite ensures that the value structurized the table definition hence can use index directly elaborate table bar defined integer name varchar deptid integer and query like insert into bar select name from foo executed calcite makes the projection name null the value before insert 
WITHOUT_CLASSIFICATION	 clearing assignments 
WITHOUT_CLASSIFICATION	 with earliest the spout should also resume where left off rather than restart the earliest offset 
WITHOUT_CLASSIFICATION	 load fully loaded load fully loaded 
WITHOUT_CLASSIFICATION	 emit results 
WITHOUT_CLASSIFICATION	 setup timer for commit elapse time tracking 
WITHOUT_CLASSIFICATION	 this additional check and download for nimbus high availability case you have more than one nimbus 
WITHOUT_CLASSIFICATION	 write the tuple 
WITHOUT_CLASSIFICATION	 get the most recent artifact string and then parse the yaml 
WITHOUT_CLASSIFICATION	 proposedrefresh too far the future its after ticket expires simply return now 
WITHOUT_CLASSIFICATION	 cached curatorframework mainly used for blobstore 
WITHOUT_CLASSIFICATION	 construct message containing the sasl response and send the server 
WITHOUT_CLASSIFICATION	 now check that the spout will emit another messages 
WITHOUT_CLASSIFICATION	 processlatencyms 
WITHOUT_CLASSIFICATION	 thread safety assumes collectoremit calls are externally synchronized needed 
WITHOUT_CLASSIFICATION	 test for user having write admin privileges change replication blob 
WITHOUT_CLASSIFICATION	 message was acked after being retried clear the state for that message 
WITHOUT_CLASSIFICATION	 reset commit timer such that commit happens next call nexttuple 
WITHOUT_CLASSIFICATION	 the retry schedules for two messages should unrelated 
WITHOUT_CLASSIFICATION	 boltspecific configuration for windowed bolts specify the time interval for generating watermark events watermark event tracks the progress time when tuple timestamp used this config effective only link specified 
WITHOUT_CLASSIFICATION	 group field 
WITHOUT_CLASSIFICATION	 stream words emitted the queryspout used the keys query the state 
WITHOUT_CLASSIFICATION	 add supervisors that might have crashed but workers are still alive 
WITHOUT_CLASSIFICATION	 put owner stormbaselist mapping ownertobasesmap this owner the input parameter null add all the owners with stormbase and guarantees else add only this owner the input paramter the map 
WITHOUT_CLASSIFICATION	 the system low memory cannot kind and need shoot something 
WITHOUT_CLASSIFICATION	 the child processes typically exit sec mins later they are still around something wrong 
WITHOUT_CLASSIFICATION	 only log the leader has changed not interesting otherwise 
WITHOUT_CLASSIFICATION	 race happened and probably not running 
WITHOUT_CLASSIFICATION	 required required optional 
WITHOUT_CLASSIFICATION	 authorize client allowed dorequest and only the client 
WITHOUT_CLASSIFICATION	 this spout added test purpose just failing fast doesnt hurt much 
WITHOUT_CLASSIFICATION	 minimum version supporting storm would 
WITHOUT_CLASSIFICATION	 advance the time and replay the failed tuple 
WITHOUT_CLASSIFICATION	 boltspecific configuration for windowed bolts specify the sliding interval count number tuples 
WITHOUT_CLASSIFICATION	 only need keep track acked tuples commits kafka are controlled tuple acks which happens only for atleastonce processing semantics 
WITHOUT_CLASSIFICATION	 not close this inputstream method will used from jetty server 
WITHOUT_CLASSIFICATION	 partition ids 
WITHOUT_CLASSIFICATION	 the current assignment already running new assignment will never promoted currassignment because timer not being compared equals equivalent meaning newassignment always equals currassignment 
WITHOUT_CLASSIFICATION	 this happens the min too small 
WITHOUT_CLASSIFICATION	 config 
WITHOUT_CLASSIFICATION	 should not show files outside worker log root 
WITHOUT_CLASSIFICATION	 valid delete before whats been committed since those batches will never accessed again 
WITHOUT_CLASSIFICATION	 client should not sending otherthansasl messages before saslserverhandler has removed itself from the pipeline such nonsasl requests will denied the authorize channel handler the next handler upstream the server pipeline sasl authentication has not completed 
WITHOUT_CLASSIFICATION	 window system state 
WITHOUT_CLASSIFICATION	 used internally merge values groupbykeyandwindow 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 register the newly established channel 
WITHOUT_CLASSIFICATION	 when storetuplesinstore false then the given windowstorefactory only used store triggers and 
WITHOUT_CLASSIFICATION	 obtain serializer object 
WITHOUT_CLASSIFICATION	 verify correct unwrapping partitions and delegation assignment 
WITHOUT_CLASSIFICATION	 meter declared here can registered any daemon and currently used supervisor 
WITHOUT_CLASSIFICATION	 send flush tuple all local executors 
WITHOUT_CLASSIFICATION	 include the topology name worker port the file name that multiple event loggers can log independently 
WITHOUT_CLASSIFICATION	 another kafkaspout instance this topology already committed therefore does not apply 
WITHOUT_CLASSIFICATION	 adjust the divisor for the average account for any skipped resources those where the total was 
WITHOUT_CLASSIFICATION	 bolt overrides 
WITHOUT_CLASSIFICATION	 rate 
WITHOUT_CLASSIFICATION	 schedule the heartbeat one thread pool 
WITHOUT_CLASSIFICATION	 ensure the commit timer has expired 
WITHOUT_CLASSIFICATION	 didnt get the group just return empty list 
WITHOUT_CLASSIFICATION	 parts for cgroup else maps hierarchy proccgroups 
WITHOUT_CLASSIFICATION	 yes are putting config that not the same type pulled out 
WITHOUT_CLASSIFICATION	 replicationfactor 
WITHOUT_CLASSIFICATION	 cleanup 
WITHOUT_CLASSIFICATION	 max number window events memory 
WITHOUT_CLASSIFICATION	 non blocking returns count how many inserts succeeded 
WITHOUT_CLASSIFICATION	 concurrent deletion only one thread should succeed 
WITHOUT_CLASSIFICATION	 now lets update but not advance time should get old map again 
WITHOUT_CLASSIFICATION	 remove the unneeded entries from the graph want keep all our nodes and the nodes that they are connected directly parents and children 
WITHOUT_CLASSIFICATION	 have enough resources now 
WITHOUT_CLASSIFICATION	 dont emit anything allow configured spout wait strategy kick 
WITHOUT_CLASSIFICATION	 was scheduled for retry and reemitted remove from schedule 
WITHOUT_CLASSIFICATION	 onheap 
WITHOUT_CLASSIFICATION	 filter configured allow anyone 
WITHOUT_CLASSIFICATION	 setup spout with mock consumer can get the rebalance listener 
WITHOUT_CLASSIFICATION	 note variable used lambda expression should final effectively final will cause compilation error and variable type should implement the serializable interface isnt primitive type will cause not serializable exception 
WITHOUT_CLASSIFICATION	 hosts this user authorized impersonate from 
WITHOUT_CLASSIFICATION	 worker crashes the states all workers are rolled back and initstate message sent across the topology that crashed workers can initialize their state the bolts that have their state already initialized need not reinitialized 
WITHOUT_CLASSIFICATION	 enable 
WITHOUT_CLASSIFICATION	 note that sometimes the tuples active may less than maxspoutpending maxspoutpending active acked there wont commit for because isnt committed yet and there wont batch for because theres maxspoutpending active 
WITHOUT_CLASSIFICATION	 multivalue field split non default token match dynamic fields the form txt this field wont indexed solr 
WITHOUT_CLASSIFICATION	 map consisting all workers the node 
WITHOUT_CLASSIFICATION	 had timeout but the timeout longer active 
WITHOUT_CLASSIFICATION	 sample fielddescriptor streamxyz 
WITHOUT_CLASSIFICATION	 this odd case for rolling upgrade where the user the old assignment may null but not the new one although all other ways they are the same this happens want use the assignment with the owner 
WITHOUT_CLASSIFICATION	 dont override the host name everything looks like nimbus 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 this also helpful optimization that state implementations dont need manually 
WITHOUT_CLASSIFICATION	 sigar uses jni and does not work local mode 
WITHOUT_CLASSIFICATION	 for mesos this hostnametopologyid 
WITHOUT_CLASSIFICATION	 writablebytechannel channel which implements closeable hence although declared autocloseable superclose here should only throws ioexception rethrow conform the signature 
WITHOUT_CLASSIFICATION	 retire them 
WITHOUT_CLASSIFICATION	 create factory class 
WITHOUT_CLASSIFICATION	 assignmentid 
WITHOUT_CLASSIFICATION	 assignedmemoffheap 
WITHOUT_CLASSIFICATION	 topology with multiple spouts 
WITHOUT_CLASSIFICATION	 populate metric values using the provided key 
WITHOUT_CLASSIFICATION	 done separately like with setting the 
WITHOUT_CLASSIFICATION	 since the largest unpinned entry before loaded 
WITHOUT_CLASSIFICATION	 commits offsets during deactivation 
WITHOUT_CLASSIFICATION	 reason try execute previous attempt than weve already seen 
WITHOUT_CLASSIFICATION	 pipeline component 
WITHOUT_CLASSIFICATION	 should have been reemitted 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 add the event logger details 
WITHOUT_CLASSIFICATION	 support topologies older version run might have loose the constraints that the configs older version can pass the validation 
WITHOUT_CLASSIFICATION	 there race backpressure too 
WITHOUT_CLASSIFICATION	 free the error stream buffer 
WITHOUT_CLASSIFICATION	 name 
WITHOUT_CLASSIFICATION	 partitioned example case emitter task receives later transaction than its emitted far when sees the earlier txid should know emit nothing 
WITHOUT_CLASSIFICATION	 some times bolt spout will have some memory that shared between the instances these are typically caches but could anything like static database that memory mapped into the processes these can declared separately and added the bolts and 
WITHOUT_CLASSIFICATION	 creates mongouri from the given string 
WITHOUT_CLASSIFICATION	 verify that only committed the message the assigned partition 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 this can happen when topology first coming its thrown the blobstore code 
WITHOUT_CLASSIFICATION	 fall back string which already set 
WITHOUT_CLASSIFICATION	 there can more then one line cgroups are mounted more then one place but assume the first good enough 
WITHOUT_CLASSIFICATION	 the resource that not used should count being used 
WITHOUT_CLASSIFICATION	 could block 
WITHOUT_CLASSIFICATION	 one tuple and one rotation should yield one file with data 
WITHOUT_CLASSIFICATION	 null acks every tuple 
WITHOUT_CLASSIFICATION	 explicit delete for ephemeral node ensure this session creates the entry 
WITHOUT_CLASSIFICATION	 the spout must respect even some tuples have been acked but not committed 
WITHOUT_CLASSIFICATION	 projection 
WITHOUT_CLASSIFICATION	 search all metadata strings 
WITHOUT_CLASSIFICATION	 this should never happen because only the primary nimbus active but just case declare the race safe even lose 
WITHOUT_CLASSIFICATION	 should remove the blob since cache size set really small 
WITHOUT_CLASSIFICATION	 newreader true and tuple null then empty reader 
WITHOUT_CLASSIFICATION	 populate user password map with jaas configuration entries from the server section usernames are distinguished from other options prefixing the username with user prefix 
WITHOUT_CLASSIFICATION	 read remaining lines file then ensure lock gone 
WITHOUT_CLASSIFICATION	 havent received the entire object yet return and wait for more bytes 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 schedule the simple topology first 
WITHOUT_CLASSIFICATION	 first offset this batch 
WITHOUT_CLASSIFICATION	 this tuple should removed from emitted only inside the ack method this ensure that the offsetmanager for that topicpartition updated and allows commit progression 
WITHOUT_CLASSIFICATION	 add element and bar should drop out 
WITHOUT_CLASSIFICATION	 below calls shouldnt propagate any exceptions 
WITHOUT_CLASSIFICATION	 private string timestampfield 
WITHOUT_CLASSIFICATION	 need able lookup bolts then switch based 
WITHOUT_CLASSIFICATION	 parse the output clear the input stream buffer 
WITHOUT_CLASSIFICATION	 treat like jar 
WITHOUT_CLASSIFICATION	 this very private and does not need exposed 
WITHOUT_CLASSIFICATION	 fetch records from kinesis starting sequence number for message passed argument any other messages fetched and are the failed queue will also 
WITHOUT_CLASSIFICATION	 its possible for target have multiple tasks reads multiple sources 
WITHOUT_CLASSIFICATION	 tests for case when subject null security turned and 
WITHOUT_CLASSIFICATION	 make sure samplingpct within bounds 
WITHOUT_CLASSIFICATION	 will fail since doesnt implement extend dnstoswitchmapping 
WITHOUT_CLASSIFICATION	 port range 
WITHOUT_CLASSIFICATION	 try grab another lock while dir locked 
WITHOUT_CLASSIFICATION	 schedule tasks that are not part components returned from topologygetspout 
WITHOUT_CLASSIFICATION	 function call when timer killed 
WITHOUT_CLASSIFICATION	 setup const spout 
WITHOUT_CLASSIFICATION	 now schedule all the topologies that need scheduled 
WITHOUT_CLASSIFICATION	 critical path dont use iterators 
WITHOUT_CLASSIFICATION	 good 
WITHOUT_CLASSIFICATION	 this default ensures things expire most past the expiration time 
WITHOUT_CLASSIFICATION	 this should the load metrics there will usually only one message but there are multiple only process the latest one 
WITHOUT_CLASSIFICATION	 should remove the second blob first 
WITHOUT_CLASSIFICATION	 get close enough 
WITHOUT_CLASSIFICATION	 comma separated offsets 
WITHOUT_CLASSIFICATION	 close file and retry creation 
WITHOUT_CLASSIFICATION	 track serialized size messages 
WITHOUT_CLASSIFICATION	 map the value 
WITHOUT_CLASSIFICATION	 string does not exist 
WITHOUT_CLASSIFICATION	 sync the filesystem after every tuples 
WITHOUT_CLASSIFICATION	 for kryo compatibility 
WITHOUT_CLASSIFICATION	 log median ratios for different strategies 
WITHOUT_CLASSIFICATION	 grouping assignment node see the nodes diff then notify nodessupervisors synchronize its owned assignment because the number existing assignments small for every scheduling round 
WITHOUT_CLASSIFICATION	 metric value 
WITHOUT_CLASSIFICATION	 removed since that what going trigger the retry for cleanup 
WITHOUT_CLASSIFICATION	 level waiting 
WITHOUT_CLASSIFICATION	 uncompressfalse 
WITHOUT_CLASSIFICATION	 this partition was previously assigned this spout 
WITHOUT_CLASSIFICATION	 add new records kafka and check that the next batch contains these records 
WITHOUT_CLASSIFICATION	 scheduler histogram 
WITHOUT_CLASSIFICATION	 precondition the new and current assignments must equivalent 
WITHOUT_CLASSIFICATION	 submit storm cluster 
WITHOUT_CLASSIFICATION	 for example have three nodessupervisor supervisor supervisor cluster slots before sort supervisor supervisor supervisor supervisor supervisor supervisor supervisor supervisor supervisor slots after sort supervisor supervisor supervisor supervisor supervisor supervisor supervisor supervisor supervisor 
WITHOUT_CLASSIFICATION	 ignore 
WITHOUT_CLASSIFICATION	 this shouldnt throw check because nothing configured yet 
WITHOUT_CLASSIFICATION	 drain element and ensure relieved trypublish succeeds 
WITHOUT_CLASSIFICATION	 save the private worker key away can test too 
WITHOUT_CLASSIFICATION	 found spout spout 
WITHOUT_CLASSIFICATION	 taskidindexingbase queue list all recvqs local this worker 
WITHOUT_CLASSIFICATION	 spoutobject 
WITHOUT_CLASSIFICATION	 the short term the goal not shoot anyone unless really need the heap should limit the memory usage most cases reasonable amount someone using way more than they requested this bug and should not allow 
WITHOUT_CLASSIFICATION	 for native protocol below all variables must bound with native protocol above variables can left unset which case they will ignored server side tombstones will generated 
WITHOUT_CLASSIFICATION	 location the file the artifactory archive also used name file cache 
WITHOUT_CLASSIFICATION	 int short 
WITHOUT_CLASSIFICATION	 migrate the coordinator currtx currattempts and meta directories the new spout expects the list topic partitions coordinator meta 
WITHOUT_CLASSIFICATION	 implementations 
WITHOUT_CLASSIFICATION	 emit messages and fail all them then ensure that the spout will retry them when the retry backoff has passed 
WITHOUT_CLASSIFICATION	 generate sasl response but only actually send the response 
WITHOUT_CLASSIFICATION	 overloading the readint method accomodate subject order check for authorization security turned 
WITHOUT_CLASSIFICATION	 get and set the start time before getting current time order avoid potential race with the gauge 
WITHOUT_CLASSIFICATION	 make sure dont process too frequently 
WITHOUT_CLASSIFICATION	 fields 
WITHOUT_CLASSIFICATION	 hadoop 
WITHOUT_CLASSIFICATION	 boltmsgqueue should have least one entry the moment 
WITHOUT_CLASSIFICATION	 intermediate bolt subscribes jms spout anchors tuples and autoacks 
WITHOUT_CLASSIFICATION	 map track number failures for each kinesis message that failed 
WITHOUT_CLASSIFICATION	 transform the stream words stream word pairs 
WITHOUT_CLASSIFICATION	 yes this should topo name but makes this simpler 
WITHOUT_CLASSIFICATION	 create transport factory that will invoke our auth callback for digest 
WITHOUT_CLASSIFICATION	 for the given processor node received punctuation from all tasks its parent windowed streams 
WITHOUT_CLASSIFICATION	 test for nimbus admin 
WITHOUT_CLASSIFICATION	 max lag 
WITHOUT_CLASSIFICATION	 bolt stats 
WITHOUT_CLASSIFICATION	 statespoutobject 
WITHOUT_CLASSIFICATION	 database 
WITHOUT_CLASSIFICATION	 emit second batch 
WITHOUT_CLASSIFICATION	 when there input field then the whole tuple considered for comparison 
WITHOUT_CLASSIFICATION	 for each executor nodeport pair 
WITHOUT_CLASSIFICATION	 publish retained message the broker 
WITHOUT_CLASSIFICATION	 this distinguish from transactionattempt 
WITHOUT_CLASSIFICATION	 just and try delete the others 
WITHOUT_CLASSIFICATION	 created lets chmod properly 
WITHOUT_CLASSIFICATION	 stop searching the message known ready for retry 
WITHOUT_CLASSIFICATION	 daemon common mainmethods 
WITHOUT_CLASSIFICATION	 bobby has guarantee topo and topo evicted 
WITHOUT_CLASSIFICATION	 validate search topology and executor 
WITHOUT_CLASSIFICATION	 hard coded max number states search 
WITHOUT_CLASSIFICATION	 consumer sets topology that reads the given kafka spouts and logs the received messages 
WITHOUT_CLASSIFICATION	 this support things like persisting off drpc stream which inherently unreliable and wont have attempt 
WITHOUT_CLASSIFICATION	 convert nodeport nodeinfo again 
WITHOUT_CLASSIFICATION	 effectively disable commits based time 
WITHOUT_CLASSIFICATION	 current and version not match roll back the version file match what current pointing 
WITHOUT_CLASSIFICATION	 any other failure result the assumption that the strategy set the status 
WITHOUT_CLASSIFICATION	 shutdownable via 
WITHOUT_CLASSIFICATION	 this since concat null string will actually concat null which not the expected 
WITHOUT_CLASSIFICATION	 storm config 
WITHOUT_CLASSIFICATION	 test for replication using supervisor access 
WITHOUT_CLASSIFICATION	 its possible string used multiple types metadata strings 
WITHOUT_CLASSIFICATION	 this avoids race condition with canceltimer 
WITHOUT_CLASSIFICATION	 resources missing from used are using none that resource 
WITHOUT_CLASSIFICATION	 idx index the type this field the fieldtype list 
WITHOUT_CLASSIFICATION	 build get query 
WITHOUT_CLASSIFICATION	 delete and all tables 
WITHOUT_CLASSIFICATION	 acls for the blob are set default empty acl list only for localfsblobstore 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 the output field the spout lambda provided the boltmessagefield that this gets written out the message the kafka topic the tuples have key field the messages are written kafka without key 
WITHOUT_CLASSIFICATION	 memfree buffers cached memfree buffers cached 
WITHOUT_CLASSIFICATION	 nothing 
WITHOUT_CLASSIFICATION	 client 
WITHOUT_CLASSIFICATION	 right now this only used for sending metrics nimbus but may want combine with the heartbeattimer some point 
WITHOUT_CLASSIFICATION	 default cache size converted bytes 
WITHOUT_CLASSIFICATION	 should never happened since apply uuid 
WITHOUT_CLASSIFICATION	 checkpoint spout should been added 
WITHOUT_CLASSIFICATION	 locate expired lock files any try take ownership oldest lock first 
WITHOUT_CLASSIFICATION	 this may may not reported depending when process exits 
WITHOUT_CLASSIFICATION	 sort available slots size from large small 
WITHOUT_CLASSIFICATION	 case plugin icontext class 
WITHOUT_CLASSIFICATION	 able delete the blob without checking metas acl skip checking everything and continue deleting local files 
WITHOUT_CLASSIFICATION	 ignored cgroups not setup dont anything with 
WITHOUT_CLASSIFICATION	 the spout must reemit failed messages waiting for retry even not allowed poll for new messages due being exceeded 
WITHOUT_CLASSIFICATION	 check see have enough slots before trying get them 
WITHOUT_CLASSIFICATION	 the supervisor 
WITHOUT_CLASSIFICATION	 off blobstore and get assume dir passed exists and has correct permission 
WITHOUT_CLASSIFICATION	 share some common metadata strings validate they not get deleted 
WITHOUT_CLASSIFICATION	 simulate worker loss 
WITHOUT_CLASSIFICATION	 topology with two unconnected partitions 
WITHOUT_CLASSIFICATION	 inputfields can equal outfields but multiple aggregators cannot have intersection outfields 
WITHOUT_CLASSIFICATION	 run only once 
WITHOUT_CLASSIFICATION	 acknowledge all changing blobs futures 
WITHOUT_CLASSIFICATION	 the resources are already normalized 
WITHOUT_CLASSIFICATION	 used recognize the pattern some meta files worker log directory 
WITHOUT_CLASSIFICATION	 name 
WITHOUT_CLASSIFICATION	 just output the word value with count the hbasebolt will handle incrementing the counter 
WITHOUT_CLASSIFICATION	 have not moved java worker yet 
WITHOUT_CLASSIFICATION	 update the latest timestamp and add the string cache 
WITHOUT_CLASSIFICATION	 schedule first block 
WITHOUT_CLASSIFICATION	 close the state force flush 
WITHOUT_CLASSIFICATION	 when partitions are reassigned the spout should seek with the first poll offset strategy for new partitions previously assigned partitions should left alone since the spout keeps the emitted and acked state for those 
WITHOUT_CLASSIFICATION	 offheapworker 
WITHOUT_CLASSIFICATION	 jms topic provider 
WITHOUT_CLASSIFICATION	 class dirlockingthread 
WITHOUT_CLASSIFICATION	 still need return the first pending list 
WITHOUT_CLASSIFICATION	 timestamp used for sharditeratortype attimestamp can null 
WITHOUT_CLASSIFICATION	 get factory class name 
WITHOUT_CLASSIFICATION	 blocking call that can interrupted using threadinterrupt 
WITHOUT_CLASSIFICATION	 download updated blobs from potential nimbodes 
WITHOUT_CLASSIFICATION	 consumer 
WITHOUT_CLASSIFICATION	 tell cassandra where the configuration files are use the test configuration file 
WITHOUT_CLASSIFICATION	 maximum uncommitted records count has reached dont emit any new records and return 
WITHOUT_CLASSIFICATION	 min 
WITHOUT_CLASSIFICATION	 check lock creationdeletion and contents 
WITHOUT_CLASSIFICATION	 always have space between 
WITHOUT_CLASSIFICATION	 windowstate table should already created with cftuples column 
WITHOUT_CLASSIFICATION	 archive passed must contain symlink named tmptestsymlink not zip file 
WITHOUT_CLASSIFICATION	 bolt 
WITHOUT_CLASSIFICATION	 topologies 
WITHOUT_CLASSIFICATION	 join the squares and the cubes stream within the window the values the squares stream having the same key that the cubes stream within the window will joined together 
WITHOUT_CLASSIFICATION	 acquire lock file and verify worked 
WITHOUT_CLASSIFICATION	 scheduling changed 
WITHOUT_CLASSIFICATION	 please pick small artifact which has small transitive dependency and lets mark ignore want run test even without internet maven central often not stable 
WITHOUT_CLASSIFICATION	 last evaluated and last expired message ids per task stream source taskid streamid 
WITHOUT_CLASSIFICATION	 for some reasons can not get supervisor port info supervisor shutdown just skip for this scheduling round 
WITHOUT_CLASSIFICATION	 need set after setting memorylimitinbytes error might occur 
WITHOUT_CLASSIFICATION	 cpu 
WITHOUT_CLASSIFICATION	 required required optional optional optional optional optional optional optional optional optional optional optional optional optional optional 
WITHOUT_CLASSIFICATION	 save little typing 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 the events should put window when the first watermark received 
WITHOUT_CLASSIFICATION	 change this template choose tools templates and open the template the editor 
WITHOUT_CLASSIFICATION	 only one the multireducers will receive the tuples 
WITHOUT_CLASSIFICATION	 merge stdout and stderr 
WITHOUT_CLASSIFICATION	 capacity for spout 
WITHOUT_CLASSIFICATION	 this spout owns partitions and 
WITHOUT_CLASSIFICATION	 cpuusage 
WITHOUT_CLASSIFICATION	 wait for the process finish and check the exit code 
WITHOUT_CLASSIFICATION	 the old trident kafka spout always returns true like this 
WITHOUT_CLASSIFICATION	 utility mainmethods 
WITHOUT_CLASSIFICATION	 late tuple stream 
WITHOUT_CLASSIFICATION	 when tuple tracking enabled the spout must not replay tuples guarantee mode 
WITHOUT_CLASSIFICATION	 memory the constraining resource 
WITHOUT_CLASSIFICATION	 tuple values are mapped with metric timestamp value map tagktagv respectively 
WITHOUT_CLASSIFICATION	 adds addressedtuple destination not full else adds pendingemits its not null 
WITHOUT_CLASSIFICATION	 then facing backpressure 
WITHOUT_CLASSIFICATION	 hidden sys component 
WITHOUT_CLASSIFICATION	 sleep bit avoid hogging the cpu 
WITHOUT_CLASSIFICATION	 the position behind the committed offset this can happen some cases message failed lots more than maxpollrecords later messages were acked and the failed message then gets acked the consumer may only part way through catching where was when went back retry the failed tuple skip the consumer forward the committed offset 
WITHOUT_CLASSIFICATION	 for 
WITHOUT_CLASSIFICATION	 info 
WITHOUT_CLASSIFICATION	 jprofilestart not used when you see jprofilestop start profiling and save away stop when timeout happens 
WITHOUT_CLASSIFICATION	 register metrics 
WITHOUT_CLASSIFICATION	 serverport 
WITHOUT_CLASSIFICATION	 try maintain rolling upgrade compatible with releases 
WITHOUT_CLASSIFICATION	 extract the field from tuple field may nested field xyz 
WITHOUT_CLASSIFICATION	 try append open file 
WITHOUT_CLASSIFICATION	 until ctrlc 
WITHOUT_CLASSIFICATION	 for the topology which wants rebalance specified the scratchtopoid exclude its assignment meaning that all the slots occupied its assignment will treated free slot the scheduler code 
WITHOUT_CLASSIFICATION	 not blacklist then add and set the resume time according config 
WITHOUT_CLASSIFICATION	 first topology should get evicted for higher priority lower value second topology successfully schedule 
WITHOUT_CLASSIFICATION	 strong supervisor node 
WITHOUT_CLASSIFICATION	 topology state transitions 
WITHOUT_CLASSIFICATION	 all events since last clear 
WITHOUT_CLASSIFICATION	 keys 
WITHOUT_CLASSIFICATION	 deny unsupported operations 
WITHOUT_CLASSIFICATION	 flush disk 
WITHOUT_CLASSIFICATION	 events were found the previous window interval scan through the events the queue find the next window intervals based event 
WITHOUT_CLASSIFICATION	 null then use zookeeper used storm 
WITHOUT_CLASSIFICATION	 the other tuples are used reset the first tuples timeout 
WITHOUT_CLASSIFICATION	 builds json list 
WITHOUT_CLASSIFICATION	 this store used only for storing triggered aggregated results but not tuples storetuplesinstore set false int below call 
WITHOUT_CLASSIFICATION	 graph with kinds nodes operation partition spout all operations have finishbatch and can optionally committers 
WITHOUT_CLASSIFICATION	 emit all remaining messages failed tuples retry immediately with current configuration need wait 
WITHOUT_CLASSIFICATION	 are the same process cannot recover anything 
WITHOUT_CLASSIFICATION	 sorted failed sequence numbers needed figure out what sequence number can committed 
WITHOUT_CLASSIFICATION	 skip special case storm killworkers already invoked 
WITHOUT_CLASSIFICATION	 windowtoacked 
WITHOUT_CLASSIFICATION	 there race logconfig where they can leaked some versions storm 
WITHOUT_CLASSIFICATION	 expected 
WITHOUT_CLASSIFICATION	 common stats 
WITHOUT_CLASSIFICATION	 allow searching when startbyteoffset filelen doesnt blow length files 
WITHOUT_CLASSIFICATION	 noop need create links local mode 
WITHOUT_CLASSIFICATION	 dont need take care sync cause were always updating heartbeat 
WITHOUT_CLASSIFICATION	 producers this just get some data kafka normally you would getting this data from elsewhere 
WITHOUT_CLASSIFICATION	 get startend indices for blocks 
WITHOUT_CLASSIFICATION	 there security are done 
WITHOUT_CLASSIFICATION	 log file permissions 
WITHOUT_CLASSIFICATION	 security off admin allowed group allowed user 
WITHOUT_CLASSIFICATION	 optional optional optional optional optional optional optional 
WITHOUT_CLASSIFICATION	 prevent filename from pathing into worker logs outside daemon log root 
WITHOUT_CLASSIFICATION	 weight 
WITHOUT_CLASSIFICATION	 test commit creates properly 
WITHOUT_CLASSIFICATION	 ignored 
WITHOUT_CLASSIFICATION	 get the nodes 
WITHOUT_CLASSIFICATION	 some tests rely reading the worker log there are too many emits and too much logged the log might roll breaking the test ensure the time based windowing tests can emit for minutes 
WITHOUT_CLASSIFICATION	 totalresources 
WITHOUT_CLASSIFICATION	 taskidindexingbase queue some entries can null outbound for this executor instance 
WITHOUT_CLASSIFICATION	 topologystats 
WITHOUT_CLASSIFICATION	 batch replayed with tuples 
WITHOUT_CLASSIFICATION	 want update longest scheduling time real time case scheduler get stuck get current time before starttime avoid potential race with schedulers timer 
WITHOUT_CLASSIFICATION	 atomically decrement the count its greater than threshold and return the event should evicted 
WITHOUT_CLASSIFICATION	 ran out buffer for the search 
WITHOUT_CLASSIFICATION	 returns true there was change the situation 
WITHOUT_CLASSIFICATION	 proxy timeout 
WITHOUT_CLASSIFICATION	 set topology name that sample trident topology can use stream name 
WITHOUT_CLASSIFICATION	 look for available port 
WITHOUT_CLASSIFICATION	 storeslength users bengaluru 
WITHOUT_CLASSIFICATION	 add messages 
WITHOUT_CLASSIFICATION	 always make sure clean everything else before worker directory 
WITHOUT_CLASSIFICATION	 races are okay this just avoid extra work for each page load 
WITHOUT_CLASSIFICATION	 partition should not have been evicted 
WITHOUT_CLASSIFICATION	 note could add support for setting the replication factor 
WITHOUT_CLASSIFICATION	 delete anything older than hour 
WITHOUT_CLASSIFICATION	 only have set amount time can wait for before looping around again 
WITHOUT_CLASSIFICATION	 look local blobstore 
WITHOUT_CLASSIFICATION	 events with past should expire 
WITHOUT_CLASSIFICATION	 ifn 
WITHOUT_CLASSIFICATION	 the list all executors preferably sorted make assignments simpler 
WITHOUT_CLASSIFICATION	 this for backwards compatibility 
WITHOUT_CLASSIFICATION	 see locktimeoutsec time has elapsed since last selected the lock file 
WITHOUT_CLASSIFICATION	 the supervisor the node down add orphaned slot hold the unsupervised worker 
WITHOUT_CLASSIFICATION	 not set recoverpartial not set recoverpartial 
WITHOUT_CLASSIFICATION	 can use the task index starting from the partition 
WITHOUT_CLASSIFICATION	 read the length field 
WITHOUT_CLASSIFICATION	 authorizationid not set set authenticationid 
WITHOUT_CLASSIFICATION	 the first transaction the new batch 
WITHOUT_CLASSIFICATION	 end include processing 
WITHOUT_CLASSIFICATION	 reusing tupleinfo object directly call executorackspoutmsg are not sending msgs perf critical 
WITHOUT_CLASSIFICATION	 ack tuple 
WITHOUT_CLASSIFICATION	 verify that the commit logic can handle offset voids due log compaction 
WITHOUT_CLASSIFICATION	 the maximum number state search before stopping 
WITHOUT_CLASSIFICATION	 kafka must able return more messages than that order for the tests meaningful 
WITHOUT_CLASSIFICATION	 log the user and get the tgt 
WITHOUT_CLASSIFICATION	 longarg 
WITHOUT_CLASSIFICATION	 make sure theres enough bytes the buffer 
WITHOUT_CLASSIFICATION	 check see there are any existing files already localized 
WITHOUT_CLASSIFICATION	 generate random storm 
WITHOUT_CLASSIFICATION	 null value string value acceptable 
WITHOUT_CLASSIFICATION	 since this processor type committer this occurs the commit phase 
WITHOUT_CLASSIFICATION	 ignore the future 
WITHOUT_CLASSIFICATION	 get the worker count back can assert each test function 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 seconds passed still not timing out 
WITHOUT_CLASSIFICATION	 are going skip over cpu and memory because they are captured elsewhere 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 this code here ensures that only one attempt ever tracked for batch when 
WITHOUT_CLASSIFICATION	 discard the pending records that are already committed 
WITHOUT_CLASSIFICATION	 will not follow sym links 
WITHOUT_CLASSIFICATION	 commit solr and ack every tuple 
WITHOUT_CLASSIFICATION	 local node 
WITHOUT_CLASSIFICATION	 calls this before actually killing the worker locally sends task finished update 
WITHOUT_CLASSIFICATION	 keep track free slots 
WITHOUT_CLASSIFICATION	 should pass 
WITHOUT_CLASSIFICATION	 optional optional optional optional optional 
WITHOUT_CLASSIFICATION	 there are more pending consumed messages and storm delivered ack for all 
WITHOUT_CLASSIFICATION	 timer null only the processing guarantee atmostonce 
WITHOUT_CLASSIFICATION	 give hook chance alter the clock 
WITHOUT_CLASSIFICATION	 populating request context 
WITHOUT_CLASSIFICATION	 allow poll there are retriable tuples within the limit 
WITHOUT_CLASSIFICATION	 build cluster and connect 
WITHOUT_CLASSIFICATION	 check log file contents 
WITHOUT_CLASSIFICATION	 create thread process insertion all metrics 
WITHOUT_CLASSIFICATION	 deleting open file should return true 
WITHOUT_CLASSIFICATION	 most clojure tests currently try access the blobs using getblob since checks for updating the correct version the blob part nimbus before performing any operation there necessity stub several test cases ignore this method valid trade off return nimbusdetails which include the details the current nimbus host port data are not initialized part the test moreover this applies only local blobstore when used along with nimbus 
WITHOUT_CLASSIFICATION	 get spread components 
WITHOUT_CLASSIFICATION	 shared off heap node memory 
WITHOUT_CLASSIFICATION	 reemit second batch 
WITHOUT_CLASSIFICATION	 thread safe same instance can used across multiple threads 
WITHOUT_CLASSIFICATION	 topology source class that can produce stormtopology thrift object 
WITHOUT_CLASSIFICATION	 for the case that ackfail message arrives before ackinit 
WITHOUT_CLASSIFICATION	 properties file substitution 
WITHOUT_CLASSIFICATION	 number spout executors 
WITHOUT_CLASSIFICATION	 jdk tries automatically drain the input streams for when the process exits but since close not synchronized creates race close the stream first and the same recycled the stream draining thread will attempt drain that may block oom cause bizarre behavior see issue fixed build 
WITHOUT_CLASSIFICATION	 initialstatus 
WITHOUT_CLASSIFICATION	 solo 
WITHOUT_CLASSIFICATION	 this sink and result emit 
WITHOUT_CLASSIFICATION	 yes its just test purpose 
WITHOUT_CLASSIFICATION	 retrieving encapsulated retrieval interface 
WITHOUT_CLASSIFICATION	 memoryguarantee 
WITHOUT_CLASSIFICATION	 dont really care too much about the scheduling topologygpu because was scheduled 
WITHOUT_CLASSIFICATION	 ignored will with default timeout 
WITHOUT_CLASSIFICATION	 where state stored zookeeper only for batch spout types 
WITHOUT_CLASSIFICATION	 the blobstore good now lets get the list all topo ids 
WITHOUT_CLASSIFICATION	 method which initializes nimbus admin 
WITHOUT_CLASSIFICATION	 case control message 
WITHOUT_CLASSIFICATION	 then exception 
WITHOUT_CLASSIFICATION	 numerrchoice 
WITHOUT_CLASSIFICATION	 kinesis stream name read from 
WITHOUT_CLASSIFICATION	 the spout must respect after committing set records 
WITHOUT_CLASSIFICATION	 other builder functions not exposed onfactory registerwith mbeanserver mapstringtimeunit specificrateunits 
WITHOUT_CLASSIFICATION	 restart topology with the same topology which mimics the behavior partition reassignment 
WITHOUT_CLASSIFICATION	 everything scheduled correctly need search any more 
WITHOUT_CLASSIFICATION	 nodes the descending order priority processornode has higher priority than partition and window nodes that the topological order iterator will group many processor nodes together possible has higher priority than statequeryprocessor that statequeryprocessor can mapped the same statefulbolt that part 
WITHOUT_CLASSIFICATION	 abandoned files then pick oldest file sourcedirpath lock and rename 
WITHOUT_CLASSIFICATION	 ack not process the record again restart and move next message 
WITHOUT_CLASSIFICATION	 then 
WITHOUT_CLASSIFICATION	 validate cpu settings 
WITHOUT_CLASSIFICATION	 release both locks 
WITHOUT_CLASSIFICATION	 children only ever null does not exist this happens during unit tests and because nonexistant directory definition clean are ignoring 
WITHOUT_CLASSIFICATION	 last partition not evicted 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 have something schedule 
WITHOUT_CLASSIFICATION	 support for worker tokens similar iautocredentials implementation 
WITHOUT_CLASSIFICATION	 unexpected error 
WITHOUT_CLASSIFICATION	 numexecutors 
WITHOUT_CLASSIFICATION	 blank result communicates that there are more blobs 
WITHOUT_CLASSIFICATION	 filesmove with nonempty directory doesnt work well windows not atomic 
WITHOUT_CLASSIFICATION	 play tuple 
WITHOUT_CLASSIFICATION	 each thread will have its own request context 
WITHOUT_CLASSIFICATION	 the current processor preserves the key and already partitioned key skip the repartition 
WITHOUT_CLASSIFICATION	 test for nimbus itself user 
WITHOUT_CLASSIFICATION	 register most recent relogin attempt 
WITHOUT_CLASSIFICATION	 decoder 
WITHOUT_CLASSIFICATION	 this allowed because the committed message brings the below the cap 
WITHOUT_CLASSIFICATION	 retnumsupervisors 
WITHOUT_CLASSIFICATION	 only enable cleanup blobstore nimbus 
WITHOUT_CLASSIFICATION	 disregard first line because has header already read 
WITHOUT_CLASSIFICATION	 sleep for mins 
WITHOUT_CLASSIFICATION	 imperative not run the function inside the timer lock otherwise possible deadlock the deals with other locks like the submit lock 
WITHOUT_CLASSIFICATION	 idtoboltaggstats 
WITHOUT_CLASSIFICATION	 lets use the number actually scheduled workers way bridge ras and nonras 
WITHOUT_CLASSIFICATION	 obtained empirical testing see comment block above 
WITHOUT_CLASSIFICATION	 verify workertokenmanager recognizes the expired workertoken 
WITHOUT_CLASSIFICATION	 good increment tasks this component being executed 
WITHOUT_CLASSIFICATION	 order executors scheduled 
WITHOUT_CLASSIFICATION	 does not exist 
WITHOUT_CLASSIFICATION	 metadata information commit kafka unique per spout instance 
WITHOUT_CLASSIFICATION	 number times had backtrack 
WITHOUT_CLASSIFICATION	 null tuple not configured emitted should marked emitted and acked immediately allow its offset commited kafka 
WITHOUT_CLASSIFICATION	 non impersonating request should permitted 
WITHOUT_CLASSIFICATION	 set the number workers the same partition number the idea have spout and partial count bolt coexist one worker avoid shuffling messages across workers storm cluster 
WITHOUT_CLASSIFICATION	 topology being null used for tests probably should fix that some point but not trivial 
WITHOUT_CLASSIFICATION	 helper classes 
WITHOUT_CLASSIFICATION	 stop searching soon passed current time 
WITHOUT_CLASSIFICATION	 register imetric instance storm will then call getvalueandreset the metric every and the returned value sent all metrics consumers you must call this during iboltprepare ispoutopen return the imetric argument unchanged 
WITHOUT_CLASSIFICATION	 expired 
WITHOUT_CLASSIFICATION	 commit polled records immediately ensure delivery atmostonce 
WITHOUT_CLASSIFICATION	 nonblacklisted supervisor 
WITHOUT_CLASSIFICATION	 distributed mode send heartbeat directly master local supervisor goes down 
WITHOUT_CLASSIFICATION	 class batchinserter 
WITHOUT_CLASSIFICATION	 pause other topicpartitions only poll from current topicpartition 
WITHOUT_CLASSIFICATION	 map assignments organized node with the following format 
WITHOUT_CLASSIFICATION	 earliest start 
WITHOUT_CLASSIFICATION	 can regular nodes static state processor nodes 
WITHOUT_CLASSIFICATION	 has closed the writer its safe remove the writer from the map here 
WITHOUT_CLASSIFICATION	 ensure that the first three tasks have been selected before 
WITHOUT_CLASSIFICATION	 swapping two arrays 
WITHOUT_CLASSIFICATION	 the streamid defined use for the grouping otherwise assume storms default stream 
WITHOUT_CLASSIFICATION	 groups 
WITHOUT_CLASSIFICATION	 print the results stdout 
WITHOUT_CLASSIFICATION	 verify that bobs token has expired 
WITHOUT_CLASSIFICATION	 just make note the oldest expired lock now and check its still unmodified after locktimeoutsec 
WITHOUT_CLASSIFICATION	 take the batched metric data and write the database 
WITHOUT_CLASSIFICATION	 assume message immediately acked nonack mode 
WITHOUT_CLASSIFICATION	 executors 
WITHOUT_CLASSIFICATION	 debug only once have confidence can lose this 
WITHOUT_CLASSIFICATION	 enable acking 
WITHOUT_CLASSIFICATION	 required required required required 
WITHOUT_CLASSIFICATION	 identify the join field for the stream and look tuple field can nested field outerkeyinnerkey 
WITHOUT_CLASSIFICATION	 just skip when any error happens wait for next round assignments reassign 
WITHOUT_CLASSIFICATION	 requestedcpu 
WITHOUT_CLASSIFICATION	 theres enough bytes the buffer read 
WITHOUT_CLASSIFICATION	 returns false are done with this section rows 
WITHOUT_CLASSIFICATION	 for others using too much really question how much memory free the system 
WITHOUT_CLASSIFICATION	 partition ids 
WITHOUT_CLASSIFICATION	 topology may deployed deactivated mode wait for activation 
WITHOUT_CLASSIFICATION	 random number generator 
WITHOUT_CLASSIFICATION	 junit ensures that the temporary folder removed after the test finishes 
WITHOUT_CLASSIFICATION	 instead iterating again would possible commit and update the state for each topicpartition the prior loop but the multiple network calls should more expensive than iterating twice over small loop 
WITHOUT_CLASSIFICATION	 source dir config 
WITHOUT_CLASSIFICATION	 read initial lines file then check lock exists 
WITHOUT_CLASSIFICATION	 consider all events for the initial window 
WITHOUT_CLASSIFICATION	 initialize assignment map 
WITHOUT_CLASSIFICATION	 save metric keyvalue batched 
WITHOUT_CLASSIFICATION	 signature 
WITHOUT_CLASSIFICATION	 allow blacklist scheduler cache the supervisor 
WITHOUT_CLASSIFICATION	 invoke setter 
WITHOUT_CLASSIFICATION	 done for requests 
WITHOUT_CLASSIFICATION	 this class assumes that there most one retry schedule per message this set time 
WITHOUT_CLASSIFICATION	 remove the executors cache let recompute 
WITHOUT_CLASSIFICATION	 numfails 
WITHOUT_CLASSIFICATION	 check annotation one our 
WITHOUT_CLASSIFICATION	 return false cant increment anymore 
WITHOUT_CLASSIFICATION	 thread polling every seconds update the wordset seconds which used filterwords bolt filter the words 
WITHOUT_CLASSIFICATION	 records 
WITHOUT_CLASSIFICATION	 for tests reader will not null 
WITHOUT_CLASSIFICATION	 fullclassname 
WITHOUT_CLASSIFICATION	 acked messages sorted ascending order offset 
WITHOUT_CLASSIFICATION	 advance time and then trigger first call kafka consumer commit the commit must progress offset 
WITHOUT_CLASSIFICATION	 get topology info 
WITHOUT_CLASSIFICATION	 make logic simple assumes that all the tables have one which should extended support composed key 
WITHOUT_CLASSIFICATION	 are not really running anything make this simple check for 
WITHOUT_CLASSIFICATION	 select tasks once more than the number tasks available 
WITHOUT_CLASSIFICATION	 iautocredentials icredentialsrenewer iprincipaltolocal 
WITHOUT_CLASSIFICATION	 remove any configs that are specific host that might mess with the running topology 
WITHOUT_CLASSIFICATION	 subscribe callback implementation 
WITHOUT_CLASSIFICATION	 removing self not create deadlock where nimbus trying download missing blob from itself 
WITHOUT_CLASSIFICATION	 the states recovered 
WITHOUT_CLASSIFICATION	 topo evicted since user bobby dont have any resource guarantees and topo the lowest priority for user bobby 
WITHOUT_CLASSIFICATION	 always provide mocked hivewriter 
WITHOUT_CLASSIFICATION	 use cannot calculate assume that bad 
WITHOUT_CLASSIFICATION	 report messagesizes metric enabled nonnull 
WITHOUT_CLASSIFICATION	 nodes 
WITHOUT_CLASSIFICATION	 perf critical check avoid unnecessary allocation 
WITHOUT_CLASSIFICATION	 not symmetric difference performing aentryset bentryset 
WITHOUT_CLASSIFICATION	 and provides consumer bolt 
WITHOUT_CLASSIFICATION	 the elements having the same key within the window will grouped together and the corresponding values will merged the result pairstreamstring iterabledouble with stock symbol the key and stock prices for that symbol within the window the value 
WITHOUT_CLASSIFICATION	 returns nil doesnt exist 
WITHOUT_CLASSIFICATION	 these triggers will retried part batch retries 
WITHOUT_CLASSIFICATION	 emit and ack some tuples ensure that some polled tuples remain cached the spout emitting less than maxpollrecords 
WITHOUT_CLASSIFICATION	 nature join field for the current stream field for the other stream 
WITHOUT_CLASSIFICATION	 new document should inserted there are matches the query filter 
WITHOUT_CLASSIFICATION	 schedule nimbus inbox cleaner 
WITHOUT_CLASSIFICATION	 setup topology 
WITHOUT_CLASSIFICATION	 key has not been created yet and the first time being created 
WITHOUT_CLASSIFICATION	 cleanup thread killing topology assignment and starting the topology 
WITHOUT_CLASSIFICATION	 offset commits have ever been done for this consumer group and topicpartition start the beginning end depending 
WITHOUT_CLASSIFICATION	 the current executor are trying schedule 
WITHOUT_CLASSIFICATION	 totaltasks 
WITHOUT_CLASSIFICATION	 metricvalue 
WITHOUT_CLASSIFICATION	 find the smallest offset toresend list 
WITHOUT_CLASSIFICATION	 reached far add the set messages waiting retried with next retry time based how many times failed 
WITHOUT_CLASSIFICATION	 end test 
WITHOUT_CLASSIFICATION	 onheap and offheap memory requirement 
WITHOUT_CLASSIFICATION	 emit the messages 
WITHOUT_CLASSIFICATION	 wrapper class handy for the client code use the json parser build use with json parser 
WITHOUT_CLASSIFICATION	 executordetails task mapstring type resource mapstring type that resource double amount 
WITHOUT_CLASSIFICATION	 remove from failedpershard anyway 
WITHOUT_CLASSIFICATION	 serializedparts 
WITHOUT_CLASSIFICATION	 remove contiguous elements from the head the heap 
WITHOUT_CLASSIFICATION	 merge and push unions rules 
WITHOUT_CLASSIFICATION	 test read 
WITHOUT_CLASSIFICATION	 find the smallest offset pending list 
WITHOUT_CLASSIFICATION	 create root directory not exist 
WITHOUT_CLASSIFICATION	 shard iterator type based kinesis api beginning time latest timestamp are only supported 
WITHOUT_CLASSIFICATION	 log writer command 
WITHOUT_CLASSIFICATION	 componenttonumtasks 
WITHOUT_CLASSIFICATION	 jsonaware not working for nested element map write json format from here 
WITHOUT_CLASSIFICATION	 join the streams order streamjoinorder 
WITHOUT_CLASSIFICATION	 explicitly anchor emits corresponding input tuples only default window anchoring will anchor them all tuples window 
WITHOUT_CLASSIFICATION	 the following tests are run for both hdfs and local store test the 
WITHOUT_CLASSIFICATION	 covers scenarios expalined scenario when nimbus holding the latest update goes down before downloaded nimbus nimbus gets elected leader 
WITHOUT_CLASSIFICATION	 end test 
WITHOUT_CLASSIFICATION	 can null for things like partitionpersist occuring off drpc stream 
WITHOUT_CLASSIFICATION	 key shouldnt iterator since its marked deleted 
WITHOUT_CLASSIFICATION	 defaults seconds 
WITHOUT_CLASSIFICATION	 the combination the lock and the finished flag ensure that never timed out has been finished 
WITHOUT_CLASSIFICATION	 note istrategyclass enforced daemonconf error will thrown nimbus topology submission and not the client prior submitting the topology 
WITHOUT_CLASSIFICATION	 convert the state back stream and print the results 
WITHOUT_CLASSIFICATION	 make sure weve handled all supervisors the host before break 
WITHOUT_CLASSIFICATION	 execsummary 
WITHOUT_CLASSIFICATION	 will used instead 
WITHOUT_CLASSIFICATION	 workers 
WITHOUT_CLASSIFICATION	 other members 
WITHOUT_CLASSIFICATION	 worker command 
WITHOUT_CLASSIFICATION	 reset all the weights 
WITHOUT_CLASSIFICATION	 when nid and zid are not equal nid attempting impersonate zid 
WITHOUT_CLASSIFICATION	 offset was previously committed for this consumer group and topicpartition either this another topology 
WITHOUT_CLASSIFICATION	 the user here from the jaas conf bob impersonation done verify that 
WITHOUT_CLASSIFICATION	 tar not native windows use simple java based implementation for tests and simple tar archives 
WITHOUT_CLASSIFICATION	 this means are pointing file 
WITHOUT_CLASSIFICATION	 user configurable 
WITHOUT_CLASSIFICATION	 wildcard given file 
WITHOUT_CLASSIFICATION	 details 
WITHOUT_CLASSIFICATION	 check adding reference local resource with topology same name 
WITHOUT_CLASSIFICATION	 supervisor health check 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 check exec can worker based user defined component exclusions 
WITHOUT_CLASSIFICATION	 first verify that something has high load its distribution will drop over time 
WITHOUT_CLASSIFICATION	 daemons can only nimbus supervisor worker 
WITHOUT_CLASSIFICATION	 ignore nonodeexists exceptions because when sync may populate curr with stale data since zookeeper reads are eventually consistent 
WITHOUT_CLASSIFICATION	 spout internals 
WITHOUT_CLASSIFICATION	 get tasks the user authorized for this topology 
WITHOUT_CLASSIFICATION	 check for substruct validity 
WITHOUT_CLASSIFICATION	 this takes care setting coord streams for spouts and bolts 
WITHOUT_CLASSIFICATION	 note dont return from this method parseexception avoid triggering the spout wait strategy due emits instead back into the loop and generate tuple from next file 
WITHOUT_CLASSIFICATION	 this happens when the key not found the cache loader returns null and this exception thrown because the cache cannot store null 
WITHOUT_CLASSIFICATION	 rack list host names that rack 
WITHOUT_CLASSIFICATION	 first reemit any previously failed tuples from retrylist 
WITHOUT_CLASSIFICATION	 nimbus metrics distribution 
WITHOUT_CLASSIFICATION	 authz authn 
WITHOUT_CLASSIFICATION	 check the user allowed read this 
WITHOUT_CLASSIFICATION	 now parse and return the map 
WITHOUT_CLASSIFICATION	 after this resources should contain all the kinds resources can count for the group see kind resource another node not resourceskeyset well throw 
WITHOUT_CLASSIFICATION	 when using the guarantee mode the spout must commit tuples periodically regardless whether theyve been acked 
WITHOUT_CLASSIFICATION	 expect notify supervisors almost the same time 
WITHOUT_CLASSIFICATION	 mastercodedir 
WITHOUT_CLASSIFICATION	 increment the fail count started with 
WITHOUT_CLASSIFICATION	 when reading the conf nimbus want fall back our own settings 
WITHOUT_CLASSIFICATION	 may null worker tokens are not supported the thrift transport 
WITHOUT_CLASSIFICATION	 read line 
WITHOUT_CLASSIFICATION	 expected 
WITHOUT_CLASSIFICATION	 todo 
WITHOUT_CLASSIFICATION	 construct the final assignments adding starttimes etc into 
WITHOUT_CLASSIFICATION	 sharedmemory 
WITHOUT_CLASSIFICATION	 this just case supervisor down that disk doesnt fill shouldnt take supervisor seconds between listing dir and reading 
WITHOUT_CLASSIFICATION	 components 
WITHOUT_CLASSIFICATION	 for testing careful doesnt clone 
WITHOUT_CLASSIFICATION	 the write failed try sync anything already written 
WITHOUT_CLASSIFICATION	 schema change should have forced rotation 
WITHOUT_CLASSIFICATION	 these can chained like with setting the cpu requirement 
WITHOUT_CLASSIFICATION	 getter mainmethods 
WITHOUT_CLASSIFICATION	 add the nid the real user reqcontexts subject which will used during authorization 
WITHOUT_CLASSIFICATION	 always empty processing guarantee none atmostonce 
WITHOUT_CLASSIFICATION	 set keep blobs each size 
WITHOUT_CLASSIFICATION	 seek next offset after last offset from previous batch 
WITHOUT_CLASSIFICATION	 this not atomic something bad happens the middle need able recover 
WITHOUT_CLASSIFICATION	 the unique topology for the topology that created this metadata 
WITHOUT_CLASSIFICATION	 locate oldest expired lock file any and take ownership 
WITHOUT_CLASSIFICATION	 populating request context 
WITHOUT_CLASSIFICATION	 check last block scheduling time does not get significantly slower 
WITHOUT_CLASSIFICATION	 null wasnt sampled 
WITHOUT_CLASSIFICATION	 expecting inside remoteexception 
WITHOUT_CLASSIFICATION	 now pending toresend 
WITHOUT_CLASSIFICATION	 cant leave choices empty initiate similar shufflegrouping 
WITHOUT_CLASSIFICATION	 minheap 
WITHOUT_CLASSIFICATION	 retries management 
WITHOUT_CLASSIFICATION	 close all the created htable instances 
WITHOUT_CLASSIFICATION	 the service must able remove retry schedules for unnecessary partitions 
WITHOUT_CLASSIFICATION	 the default false the default false 
WITHOUT_CLASSIFICATION	 use redis based state store for persistence 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 ackersnull when ackercount not explicitly set the topology 
WITHOUT_CLASSIFICATION	 whether they are ibasicbolt irichbolt instances 
WITHOUT_CLASSIFICATION	 this really should impossible because off the min load and inc anything within but just sure never issue especially with float rounding etc 
WITHOUT_CLASSIFICATION	 therefore the timer newassignment wont invoked 
WITHOUT_CLASSIFICATION	 performs hashjoin constructing hash map the smaller set iterating over the larger set and finding matching rows the hash map 
WITHOUT_CLASSIFICATION	 all down which unlikely hence there might need update the blob all down 
WITHOUT_CLASSIFICATION	 watermark interval 
WITHOUT_CLASSIFICATION	 cant move this outside without breaking backward compatibility 
WITHOUT_CLASSIFICATION	 tuples that were successfully ackedemitted these tuples will committed periodically when the commit timer expires 
WITHOUT_CLASSIFICATION	 inner join core implementation 
WITHOUT_CLASSIFICATION	 this should throw because auth failed 
WITHOUT_CLASSIFICATION	 ipersistentmap 
WITHOUT_CLASSIFICATION	 race condition with delete 
WITHOUT_CLASSIFICATION	 the tick should cause tuple ackd 
WITHOUT_CLASSIFICATION	 the consumer should not seeking retry the failed tuple should just continuing from the current position 
WITHOUT_CLASSIFICATION	 interrupted thrown when are shutting down just ignore for now 
WITHOUT_CLASSIFICATION	 worker launched through external commands hence count their exceptions toward shell exceptions 
WITHOUT_CLASSIFICATION	 jstack dump 
WITHOUT_CLASSIFICATION	 the result aggregation forwarded the redisstorebolt the forwarded tuple keyvalue pair word count with key value being the field names 
WITHOUT_CLASSIFICATION	 waiting for spout tuples isnt strictly necessary since also wait for bolt emits but anyway allow two minutes for topology startup then wait for most the time should take produce windows 
WITHOUT_CLASSIFICATION	 noop the events are acked execute 
WITHOUT_CLASSIFICATION	 list files 
WITHOUT_CLASSIFICATION	 workerchildopts validates 
WITHOUT_CLASSIFICATION	 ignore workers that are still bound slot which monitored supervisor 
WITHOUT_CLASSIFICATION	 all events are sent successfully return last sent offset 
WITHOUT_CLASSIFICATION	 metric timestamp value map tagktagv respectively 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 the first field the batch 
WITHOUT_CLASSIFICATION	 stats 
WITHOUT_CLASSIFICATION	 the writer must closed before removed from the map failed might lose some data 
WITHOUT_CLASSIFICATION	 realm ignored 
WITHOUT_CLASSIFICATION	 clocks sync 
WITHOUT_CLASSIFICATION	 some cases the new localassignment may equivalent the old but not equal those cases want update the current assignment the same the new assignment 
WITHOUT_CLASSIFICATION	 validate single task return 
WITHOUT_CLASSIFICATION	 now also check that more tuples are polled for since both partitions are their limits 
WITHOUT_CLASSIFICATION	 force send error 
WITHOUT_CLASSIFICATION	 overloading the method accomodate subject order check for authorization 
WITHOUT_CLASSIFICATION	 null worker means generate one 
WITHOUT_CLASSIFICATION	 there race credentials where they can leaked some versions storm 
WITHOUT_CLASSIFICATION	 play all tuples 
WITHOUT_CLASSIFICATION	 this will fail the test since user derek does not have entry for memory 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 messageid 
WITHOUT_CLASSIFICATION	 rebalanceoptions 
WITHOUT_CLASSIFICATION	 for most scenes avoid inner array resizing 
WITHOUT_CLASSIFICATION	 early return shard assigned probably because number executors number shards 
WITHOUT_CLASSIFICATION	 acquire another lock file and verify failed 
WITHOUT_CLASSIFICATION	 commit offsets 
WITHOUT_CLASSIFICATION	 catching and logging because there subsequent update and delete the nonleader nimbodes might throw exception 
WITHOUT_CLASSIFICATION	 nimbus compatibility 
WITHOUT_CLASSIFICATION	 returns either the source component name the stream name for the tuple 
WITHOUT_CLASSIFICATION	 want able select the measurement interval reporting window dont need different reports want able specify format and configs specific the format with perhaps defaults overall 
WITHOUT_CLASSIFICATION	 modifies justassignedkeys 
WITHOUT_CLASSIFICATION	 this called async lets assume that something care about 
WITHOUT_CLASSIFICATION	 remove uploaded jars blobs not artifacts since theyre shared across the cluster note that dont handle texception delete jars blobs because its safer leave some blobs instead topology not running 
WITHOUT_CLASSIFICATION	 get storm values and emit 
WITHOUT_CLASSIFICATION	 complete the send 
WITHOUT_CLASSIFICATION	 initial delay for the commit and assignment refresh timers 
WITHOUT_CLASSIFICATION	 todo enable setstatespout gets implemented testexpected 
WITHOUT_CLASSIFICATION	 here dont set the tuples context and emit unanchored the checkpoint tuple will trigger checkpoint the receiver with the emitted tuples 
WITHOUT_CLASSIFICATION	 storm configuration 
WITHOUT_CLASSIFICATION	 looks for files the directory with current suffix 
WITHOUT_CLASSIFICATION	 this test sends broadcast all connected clients from the server need wait until the server has registered the client connected before sending load metrics its not enough wait until the client reports that the channel open because the server event loop may not have finished running channelactive for the new channel send metrics too early the server will broadcast one waiting for the response here ensure that the client will registered the server before send load metrics 
WITHOUT_CLASSIFICATION	 checks for assertion when turn security 
WITHOUT_CLASSIFICATION	 listener implementation 
WITHOUT_CLASSIFICATION	 not required not required 
WITHOUT_CLASSIFICATION	 this will only get updated once 
WITHOUT_CLASSIFICATION	 determine how long sleep from looking tickets expiry should not allow the ticket expire but should take into consideration will not sleep less than unless doing would cause ticket expiration 
WITHOUT_CLASSIFICATION	 try append closed file 
WITHOUT_CLASSIFICATION	 convert thrift stats java maps 
WITHOUT_CLASSIFICATION	 sharedresources 
WITHOUT_CLASSIFICATION	 make the spout commit any acked tuples 
WITHOUT_CLASSIFICATION	 users 
WITHOUT_CLASSIFICATION	 heartbeat for this one should 
WITHOUT_CLASSIFICATION	 clear the kerberos state but the tokens are not cleared per the java kerberos login module code only the kerberos credentials 
WITHOUT_CLASSIFICATION	 copy constructor 
WITHOUT_CLASSIFICATION	 writes the offsets the new format the user partitions paths 
WITHOUT_CLASSIFICATION	 specify configuration object used 
WITHOUT_CLASSIFICATION	 the spout should emit most one message per call nexttuple this necessary for storm able throttle the spout according maxspoutpending 
WITHOUT_CLASSIFICATION	 reserved for future 
WITHOUT_CLASSIFICATION	 same set events part three windows 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 stream stock quotes 
WITHOUT_CLASSIFICATION	 mapfunction aware cleanup let handle cleaning 
WITHOUT_CLASSIFICATION	 stream name unspecified 
WITHOUT_CLASSIFICATION	 topo has large tasks 
WITHOUT_CLASSIFICATION	 success 
WITHOUT_CLASSIFICATION	 set watermark interval high value and trigger manually fix timing issues 
WITHOUT_CLASSIFICATION	 fail tuple 
WITHOUT_CLASSIFICATION	 tuples that have been emitted but that are the wire pending being acked failed 
WITHOUT_CLASSIFICATION	 ensure nimbus has leadership otherwise topology submission will fail 
WITHOUT_CLASSIFICATION	 ignore 
WITHOUT_CLASSIFICATION	 this latch closed need create new instance 
WITHOUT_CLASSIFICATION	 actually mapstring mapstring mapstring longdouble 
WITHOUT_CLASSIFICATION	 objects are absent they were zero both this iteration and the last only this one need report zero 
WITHOUT_CLASSIFICATION	 with realm hdfswitzendcom 
WITHOUT_CLASSIFICATION	 get new random number and seed make sure that runs are consistent where possible 
WITHOUT_CLASSIFICATION	 tuple arrives from spout can passed otherwise the value the first field the tuple 
WITHOUT_CLASSIFICATION	 totaltopologies 
WITHOUT_CLASSIFICATION	 simulate the time trigger setting the reference time and invoking ontrigger manually 
WITHOUT_CLASSIFICATION	 returns paused topicpartitions 
WITHOUT_CLASSIFICATION	 the free pool never has anything running 
WITHOUT_CLASSIFICATION	 the time now twice the message timeout the second tuple should expire since was not acked 
WITHOUT_CLASSIFICATION	 define our taskids 
WITHOUT_CLASSIFICATION	 wrap 
WITHOUT_CLASSIFICATION	 user class supplied this also provides bridge trident 
WITHOUT_CLASSIFICATION	 trigger manually avoid timing issues 
WITHOUT_CLASSIFICATION	 executorid 
WITHOUT_CLASSIFICATION	 create links artifacts dir 
WITHOUT_CLASSIFICATION	 other classes from config 
WITHOUT_CLASSIFICATION	 means delegate batch size trident batch size 
WITHOUT_CLASSIFICATION	 initial delay for the assignment refresh timer 
WITHOUT_CLASSIFICATION	 names 
WITHOUT_CLASSIFICATION	 wait for lock expire 
WITHOUT_CLASSIFICATION	 that fails use config 
WITHOUT_CLASSIFICATION	 verify simple rejected 
WITHOUT_CLASSIFICATION	 filter executorsummarys with empty stats 
WITHOUT_CLASSIFICATION	 backward compatibility 
WITHOUT_CLASSIFICATION	 verify recorded messages size metrics 
WITHOUT_CLASSIFICATION	 first partition second partition 
WITHOUT_CLASSIFICATION	 ranked third since rack has lot cpu but not lot memory 
WITHOUT_CLASSIFICATION	 fragmentedcpu 
WITHOUT_CLASSIFICATION	 last batch meta null but this not the first batch emitted for this partition this emitter instance this replay the first batch for this partition use the offset the consumer started 
WITHOUT_CLASSIFICATION	 dont start new requests there exception 
WITHOUT_CLASSIFICATION	 require there both topology and component this case parse out such 
WITHOUT_CLASSIFICATION	 there one task inside one executor for each worker the topology taskid always therefore you can only sendunanchored tuples colocated systembolt this bolt was conceived export worker stats via metrics api 
WITHOUT_CLASSIFICATION	 now scan all metadata and remove any matching string ids from this list 
WITHOUT_CLASSIFICATION	 ignored 
WITHOUT_CLASSIFICATION	 save the memory limit can enforce less strictly 
WITHOUT_CLASSIFICATION	 executor resources 
WITHOUT_CLASSIFICATION	 could not recover container will null 
WITHOUT_CLASSIFICATION	 returns null its not drpc group 
WITHOUT_CLASSIFICATION	 pump more msgs than size verify msg count expexted 
WITHOUT_CLASSIFICATION	 check negative resource count 
WITHOUT_CLASSIFICATION	 ack tuple 
WITHOUT_CLASSIFICATION	 log any info sent the error stream 
WITHOUT_CLASSIFICATION	 fill the half with new bytes from the stream 
WITHOUT_CLASSIFICATION	 drpc token only works for the invocations transport not for the basic thrift transport 
WITHOUT_CLASSIFICATION	 mergewith accstats compkey cidstatknum 
WITHOUT_CLASSIFICATION	 map the key needed 
WITHOUT_CLASSIFICATION	 setup devnull bolt 
WITHOUT_CLASSIFICATION	 failedwithexitcode were mimicing hadoops health checks treat nonzero exit codes indicators that the scripts failed execute properly not that the system unhealthy which case dont want start killing things 
WITHOUT_CLASSIFICATION	 fail both emitted tuples 
WITHOUT_CLASSIFICATION	 theres not enough bytes the buffer 
WITHOUT_CLASSIFICATION	 oneproducerconsumer twoproducerconsumer producerfwdconsumer 
WITHOUT_CLASSIFICATION	 should allowed retry times addition original try 
WITHOUT_CLASSIFICATION	 todo handle regular rich spout without batches need lots updates support this throughout 
WITHOUT_CLASSIFICATION	 check allowedworkers only the scheduler not the resource aware scheduler 
WITHOUT_CLASSIFICATION	 check that trypublish tryoverflowpublish work expected 
WITHOUT_CLASSIFICATION	 put tuple cause the first tuple acked 
WITHOUT_CLASSIFICATION	 failures happen you dont get explosion memory usage the tasks 
WITHOUT_CLASSIFICATION	 httpserverdestroy 
WITHOUT_CLASSIFICATION	 seek directly the earliest retriable message for each retriable topic partition 
WITHOUT_CLASSIFICATION	 hide the deadports from the allports these deadports can reused next round assignments 
WITHOUT_CLASSIFICATION	 resets the last access time for key 
WITHOUT_CLASSIFICATION	 action 
WITHOUT_CLASSIFICATION	 singleton instance allows mock delegated static mainmethods our 
WITHOUT_CLASSIFICATION	 when click link the logviewer expect the match line somewhere near the middle the page subtract half the default page length from the offset which found the match 
WITHOUT_CLASSIFICATION	 generate topologies 
WITHOUT_CLASSIFICATION	 allowing keytab based login for backward compatibility 
WITHOUT_CLASSIFICATION	 owner 
WITHOUT_CLASSIFICATION	 map tag value pairs 
WITHOUT_CLASSIFICATION	 just for testing purpose after the migration testingclj this class could removed 
WITHOUT_CLASSIFICATION	 only rack use the second rack with gpus the first rack with gpus 
WITHOUT_CLASSIFICATION	 used worker only keep latch 
WITHOUT_CLASSIFICATION	 throws parseexception effectively produces lines from each file read 
WITHOUT_CLASSIFICATION	 ras resource aware scheduler 
WITHOUT_CLASSIFICATION	 starting empty 
WITHOUT_CLASSIFICATION	 ack return the first pending list 
WITHOUT_CLASSIFICATION	 storm configuration 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 highest sequence number that can committed for this shard 
WITHOUT_CLASSIFICATION	 the batch size can larger than half the full recvqueue size avoid contention issues 
WITHOUT_CLASSIFICATION	 exact variable time that added the current bucket 
WITHOUT_CLASSIFICATION	 completemsavg 
WITHOUT_CLASSIFICATION	 events should not scanned all since timeevictionpolicy lag should break 
WITHOUT_CLASSIFICATION	 get from cluster statezookeeper every time collect the stats may replace with other statestore later 
WITHOUT_CLASSIFICATION	 note that only uses the supervisordetails the rest the arguments are there satisfy the inimbus interface 
WITHOUT_CLASSIFICATION	 the key and value txids are guaranteed converted utf encoded string 
WITHOUT_CLASSIFICATION	 clear workers off all hosts that are not blacklisted 
WITHOUT_CLASSIFICATION	 creating blob again before launching topology 
WITHOUT_CLASSIFICATION	 assignedmemonheap 
WITHOUT_CLASSIFICATION	 commit 
WITHOUT_CLASSIFICATION	 user jerry submits topo 
WITHOUT_CLASSIFICATION	 optional optional optional optional optional optional 
WITHOUT_CLASSIFICATION	 records mbs memory footprint the worst case 
WITHOUT_CLASSIFICATION	 this updated the worker and the topology has shared access 
WITHOUT_CLASSIFICATION	 need release resources associated with the worker event loop group 
WITHOUT_CLASSIFICATION	 assertion 
WITHOUT_CLASSIFICATION	 noop 
WITHOUT_CLASSIFICATION	 protected using the object lock 
WITHOUT_CLASSIFICATION	 distribution should even for all nodes when loads are even 
WITHOUT_CLASSIFICATION	 implementation for converting kinesis record storm tuple 
WITHOUT_CLASSIFICATION	 callback that does nothing 
WITHOUT_CLASSIFICATION	 case deactivate was called before 
WITHOUT_CLASSIFICATION	 close the socket which releases connection has created any 
WITHOUT_CLASSIFICATION	 remove any entries the cache 
WITHOUT_CLASSIFICATION	 accstats compkey boltstatsspoutstats 
WITHOUT_CLASSIFICATION	 update current key list inside the blobstore the version changes 
WITHOUT_CLASSIFICATION	 lock protects against multiple topologies being submitted once and 
WITHOUT_CLASSIFICATION	 windowtofailed 
WITHOUT_CLASSIFICATION	 one more column families 
WITHOUT_CLASSIFICATION	 supervisorid 
WITHOUT_CLASSIFICATION	 wait for all locks expire then heart beat locks 
WITHOUT_CLASSIFICATION	 create sequence format instance 
WITHOUT_CLASSIFICATION	 blob key not specified use file 
WITHOUT_CLASSIFICATION	 lock log entry every tuples effectively disable commits based time 
WITHOUT_CLASSIFICATION	 todo finish 
WITHOUT_CLASSIFICATION	 this prevent the potential bug that the login cache enabled and then disabled and then enabled again and the logincachekey remains unchanged will use the login cache from which could wrong because the tgt cache well the principle could have been changed during 
WITHOUT_CLASSIFICATION	 some other form unix 
WITHOUT_CLASSIFICATION	 element sojourn time milliseconds 
WITHOUT_CLASSIFICATION	 suppressing exceptions dont care for errors abort 
WITHOUT_CLASSIFICATION	 need get the next node iterator 
WITHOUT_CLASSIFICATION	 creating blacklist file read from the disk 
WITHOUT_CLASSIFICATION	 treeset uses compareto instead equals for the set contract ensure that can save two retry schedules with the same timestamp 
WITHOUT_CLASSIFICATION	 thread object thread will null refresh thread not needed 
WITHOUT_CLASSIFICATION	 encoder 
WITHOUT_CLASSIFICATION	 dont ack tick tuples 
WITHOUT_CLASSIFICATION	 dont let the user set who launch 
WITHOUT_CLASSIFICATION	 acls for the blob are set worldeverything 
WITHOUT_CLASSIFICATION	 create another input file and reverify same behavior 
WITHOUT_CLASSIFICATION	 setup default producer 
WITHOUT_CLASSIFICATION	 pregenerate commonly used keys for scans 
WITHOUT_CLASSIFICATION	 sasl authentication disabled saslchannelready initialized true otherwise false 
WITHOUT_CLASSIFICATION	 number values must odd compute median below 
WITHOUT_CLASSIFICATION	 noop windows gets support for run user will need find way support this 
WITHOUT_CLASSIFICATION	 wordspout countbolt redisbolt 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 storm blobstore create file blacklisttxt acl orwa key 
WITHOUT_CLASSIFICATION	 setup topology 
WITHOUT_CLASSIFICATION	 emitted 
WITHOUT_CLASSIFICATION	 the body the message message currentoffset message 
WITHOUT_CLASSIFICATION	 object capturing all related information for storing committed sequence numbers 
WITHOUT_CLASSIFICATION	 theres race condition with delete either blobstore this should thrown the caller indicate that the key invalid now 
WITHOUT_CLASSIFICATION	 hostname 
WITHOUT_CLASSIFICATION	 stop services without killing the process instead 
WITHOUT_CLASSIFICATION	 path should defined most systems 
WITHOUT_CLASSIFICATION	 setup 
WITHOUT_CLASSIFICATION	 backoff for test retry service just check that messages will retry immediately 
WITHOUT_CLASSIFICATION	 just need 
WITHOUT_CLASSIFICATION	 javac option remove these when the javac zip impl fixed httpbissueid 
WITHOUT_CLASSIFICATION	 both assignments are null just wait 
WITHOUT_CLASSIFICATION	 for each partition the spout allowed retry all tuples between the committed offset and ahead must retry tuples within that limit even more tuples were emitted 
WITHOUT_CLASSIFICATION	 for local cluster 
WITHOUT_CLASSIFICATION	 check that null meta makes the spout seek earliest and that the returned meta correct 
WITHOUT_CLASSIFICATION	 messagesnext null can happen lost the connection and subsequently reconnected timed out 
WITHOUT_CLASSIFICATION	 emits sliding window and global averages 
WITHOUT_CLASSIFICATION	 topologies that were deemed invalid 
WITHOUT_CLASSIFICATION	 addition add all the owners with guarantees 
WITHOUT_CLASSIFICATION	 after consumer rebalance during closedeactivate always empty processing guarantee none atmostonce 
WITHOUT_CLASSIFICATION	 for local test 
WITHOUT_CLASSIFICATION	 window should compacted and events should expired 
WITHOUT_CLASSIFICATION	 add more events with current 
WITHOUT_CLASSIFICATION	 the manually set config supervisor will overwrite 
WITHOUT_CLASSIFICATION	 left join core implementation 
WITHOUT_CLASSIFICATION	 returns true pendingemits empty 
WITHOUT_CLASSIFICATION	 now ack msg and check 
WITHOUT_CLASSIFICATION	 race with delete not here the replication 
WITHOUT_CLASSIFICATION	 ignore 
WITHOUT_CLASSIFICATION	 this needs thread safe 
WITHOUT_CLASSIFICATION	 the worst case will return serialized name after password provider said that the password was okay that case the acls are likely prevent the request from going through anyways 
WITHOUT_CLASSIFICATION	 enable blobstore acl validation 
WITHOUT_CLASSIFICATION	 nodeinfo 
WITHOUT_CLASSIFICATION	 metrics 
WITHOUT_CLASSIFICATION	 tests that isscheduled isready and are mutually consistent when there are messages from multiple partitions scheduled 
WITHOUT_CLASSIFICATION	 this might partial key grouping 
WITHOUT_CLASSIFICATION	 make sure resources dir created 
WITHOUT_CLASSIFICATION	 make sure support different user reading same blob 
WITHOUT_CLASSIFICATION	 validate search metric 
WITHOUT_CLASSIFICATION	 map node ids node objects 
WITHOUT_CLASSIFICATION	 pass cases 
WITHOUT_CLASSIFICATION	 construct transport plugin 
WITHOUT_CLASSIFICATION	 reference key 
WITHOUT_CLASSIFICATION	 initialize slots for this node 
WITHOUT_CLASSIFICATION	 quoting javadoc filter returns code null this abstract pathname does not denote directory error occurs 
WITHOUT_CLASSIFICATION	 were making mock ignoring 
WITHOUT_CLASSIFICATION	 expire the token 
WITHOUT_CLASSIFICATION	 create links blobs 
WITHOUT_CLASSIFICATION	 maps transaction ids jms message ids 
WITHOUT_CLASSIFICATION	 testing whether acls are set worldeverything here are testing only for localfsblobstore the hdfsblobstore gets the subject information the local system user and behaves always authenticated 
WITHOUT_CLASSIFICATION	 define our taskids the test expects these incrementing one from zero 
WITHOUT_CLASSIFICATION	 for kryo 
WITHOUT_CLASSIFICATION	 static ensure eventhough the class created using reflection can still get the topology actions 
WITHOUT_CLASSIFICATION	 convenience method for registering reducedmetric 
WITHOUT_CLASSIFICATION	 one instance per executor avoids false sharing cpu cache 
WITHOUT_CLASSIFICATION	 functionname 
WITHOUT_CLASSIFICATION	 theres race condition with delete blobstore this should thrown the caller indicate that the key invalid now 
WITHOUT_CLASSIFICATION	 deletes metrics matching the filter options 
WITHOUT_CLASSIFICATION	 must specify column schema when providing custom query 
WITHOUT_CLASSIFICATION	 case task message 
WITHOUT_CLASSIFICATION	 populate metric 
WITHOUT_CLASSIFICATION	 the false parameter ensures overwriting the version file not appending 
WITHOUT_CLASSIFICATION	 since the last tuple the partition more than maxpollrecords ahead the failed tuple shouldnt emitted here 
WITHOUT_CLASSIFICATION	 acls have two user acls for empty user and principal discard empty user acl 
WITHOUT_CLASSIFICATION	 perform scan given filter options and return results either metric raw data 
WITHOUT_CLASSIFICATION	 function called timer reset log levels last set debug 
WITHOUT_CLASSIFICATION	 oneproducerconsumer measurement twoproducerconsumer measurement measurement 
WITHOUT_CLASSIFICATION	 set operator sets the value field document 
WITHOUT_CLASSIFICATION	 schedule last block 
WITHOUT_CLASSIFICATION	 submit storm cluster 
WITHOUT_CLASSIFICATION	 batch replayed with tuples 
WITHOUT_CLASSIFICATION	 add the authnid the real user reqcontexts subject which will used during authorization 
WITHOUT_CLASSIFICATION	 return null its not single emit 
WITHOUT_CLASSIFICATION	 mergewith partial mergewith sumor accout spoutout 
WITHOUT_CLASSIFICATION	 config spout log progress lock file for each tuple 
WITHOUT_CLASSIFICATION	 defaults 
WITHOUT_CLASSIFICATION	 the value follows pre executed alltime split default split default split default split default executelatencies alltime split default split default split default split default pre 
WITHOUT_CLASSIFICATION	 these should match the test resources 
WITHOUT_CLASSIFICATION	 write string array nework int followed int byte array compressed strings handles also null arrays and null values could generalised using introspection 
WITHOUT_CLASSIFICATION	 numworkers 
WITHOUT_CLASSIFICATION	 wait for ready channel connected and maybe authentication 
WITHOUT_CLASSIFICATION	 required for instantiation via reflection must call prepare thereafter 
WITHOUT_CLASSIFICATION	 this will best effort flushing since the linger period was set creation 
WITHOUT_CLASSIFICATION	 second predicate for condition uses the fact that long addition over the limit circles back 
WITHOUT_CLASSIFICATION	 yes eat the exception 
WITHOUT_CLASSIFICATION	 this technically does not conform with rfc but should work long you dont have any really odd names your kdc 
WITHOUT_CLASSIFICATION	 invalidate the iterator 
WITHOUT_CLASSIFICATION	 only put this owner the map 
WITHOUT_CLASSIFICATION	 example spout generate random strings bolt get the first part string bolt output the tuple 
WITHOUT_CLASSIFICATION	 and try renew the ticket 
WITHOUT_CLASSIFICATION	 reload from cached file 
WITHOUT_CLASSIFICATION	 seconds 
WITHOUT_CLASSIFICATION	 just throw away local mode 
WITHOUT_CLASSIFICATION	 fail cases 
WITHOUT_CLASSIFICATION	 first off want verify that root good 
WITHOUT_CLASSIFICATION	 max outstanding tuples 
WITHOUT_CLASSIFICATION	 nimbus groups admin 
WITHOUT_CLASSIFICATION	 almost all cases these should the same but warn the user just case something goes wrong 
WITHOUT_CLASSIFICATION	 fail all emitted messages except the last one try commit 
WITHOUT_CLASSIFICATION	 public timestampfield thistimestampfield timestampfield return this 
WITHOUT_CLASSIFICATION	 some cases users will want drop retrying old batches the topology should start over from scratch the ignores committed offsets should not retry batches for old topologies the batch retry should skipped entirely 
WITHOUT_CLASSIFICATION	 run until ctrlc 
WITHOUT_CLASSIFICATION	 automatically turn into batch spout should take parameters how much batch public stream newstreamirichspout spout node new null spout spoutnode spouttypebatch return addnoden 
WITHOUT_CLASSIFICATION	 now login 
WITHOUT_CLASSIFICATION	 will only serialize amqpvalue type 
WITHOUT_CLASSIFICATION	 necessary that this produce deterministic assignment based the key seed the random from the key 
WITHOUT_CLASSIFICATION	 given for this iteration 
WITHOUT_CLASSIFICATION	 check for required fields 
WITHOUT_CLASSIFICATION	 global grouping fields with empty list 
WITHOUT_CLASSIFICATION	 spout 
WITHOUT_CLASSIFICATION	 offset and messageid are used interchangeably 
WITHOUT_CLASSIFICATION	 olog 
WITHOUT_CLASSIFICATION	 msec 
WITHOUT_CLASSIFICATION	 print metrics every sec kill topology after min 
WITHOUT_CLASSIFICATION	 this histogram reflects the data distribution across only one clustersummary data distribution across all entities type data from all nimbustopologies one moment hence use half the cachingwindow time ensure retains only data from the most recent update 
WITHOUT_CLASSIFICATION	 blocking call under the hood must invoke after launch cause some services must initialized 
WITHOUT_CLASSIFICATION	 start the threads 
WITHOUT_CLASSIFICATION	 the inputwindow gives view all the events the window events that expired since last activation the window events that newly arrived since last activation the window 
WITHOUT_CLASSIFICATION	 memonheap 
WITHOUT_CLASSIFICATION	 the old token could not deserialized this bad but are going replace anyways just keep going 
WITHOUT_CLASSIFICATION	 then for this iteration 
WITHOUT_CLASSIFICATION	 case didnt fill enough 
WITHOUT_CLASSIFICATION	 cycle spout activation 
WITHOUT_CLASSIFICATION	 check for latest sequence number key inside zookeeper and return nimbodes containing the latest sequence number 
WITHOUT_CLASSIFICATION	 need download temp file and then unpack into the one requested 
WITHOUT_CLASSIFICATION	 add identity partitions between groups 
WITHOUT_CLASSIFICATION	 acking tuples for partitions that are longer assigned useless since the spout will not allowed commit them 
WITHOUT_CLASSIFICATION	 read few lines from file dont ack 
WITHOUT_CLASSIFICATION	 check for blobstore with authentication 
WITHOUT_CLASSIFICATION	 key val val key val val 
WITHOUT_CLASSIFICATION	 setup hdfs spout 
WITHOUT_CLASSIFICATION	 read lines dont ack commit pos should remain same 
WITHOUT_CLASSIFICATION	 playing from the repl and defining functions file wont exist 
WITHOUT_CLASSIFICATION	 under ras the number workers determined the scheduler and the settings the conf are ignored confsetnumworkers 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 check for null which can exist because race condition which nimbus nodes may have been removed when connections are reconnected after getting children the above line 
WITHOUT_CLASSIFICATION	 specificstats 
WITHOUT_CLASSIFICATION	 register file cleanup after jvm shutdown 
WITHOUT_CLASSIFICATION	 todo conditionally load properties from file our resource 
WITHOUT_CLASSIFICATION	 dont need sleep here because the blocked call its fine call this function tight loop 
WITHOUT_CLASSIFICATION	 triggers when assignment should refreshed 
WITHOUT_CLASSIFICATION	 clocks are sync then simply take ownership the oldest expired lock 
WITHOUT_CLASSIFICATION	 first sync assignments local then sync processes 
WITHOUT_CLASSIFICATION	 samplingpct 
WITHOUT_CLASSIFICATION	 check for new file every often 
WITHOUT_CLASSIFICATION	 waited for second loop around and try again 
WITHOUT_CLASSIFICATION	 topo should not able scheduled 
WITHOUT_CLASSIFICATION	 create new config make additive true inherit parents appenders 
WITHOUT_CLASSIFICATION	 prints the total with low probability 
WITHOUT_CLASSIFICATION	 this task containing worker will killed assignments sync tasktonodeport will empty map which refreshed workerstate 
WITHOUT_CLASSIFICATION	 all 
WITHOUT_CLASSIFICATION	 class joininfo 
WITHOUT_CLASSIFICATION	 supervisor metrics distribution 
WITHOUT_CLASSIFICATION	 inner join age and gender records field 
WITHOUT_CLASSIFICATION	 with uncommitted earliest the spout should pick where left off when reactivating 
WITHOUT_CLASSIFICATION	 test ras spreads executors across multiple workers based the set limit for worker used the topology 
WITHOUT_CLASSIFICATION	 filter supervisor 
WITHOUT_CLASSIFICATION	 not include the success stream part the batch should not trigger coordination tuples and just metadata tuple assist cleanup should not trigger batch tracking 
WITHOUT_CLASSIFICATION	 load pmml model from file 
WITHOUT_CLASSIFICATION	 this code here handles case where previous commit failed and the partitions changed since the last commit this clears out any state for the removed partitions for this txid make sure only single task ever does this were also guaranteed that its impossible for there another writer the directory for that partition because only single commit can happening once this because order for another attempt the batch commit the batch phase must have succeeded between hence all tasks for the prior commit must have finished committing whether successfully not 
WITHOUT_CLASSIFICATION	 shell 
WITHOUT_CLASSIFICATION	 clean some things the user should not set not security issue just might confuse the topology 
WITHOUT_CLASSIFICATION	 prevent timer check heartbeat based last thing before activate 
WITHOUT_CLASSIFICATION	 data 
WITHOUT_CLASSIFICATION	 only holds msgs from other workers via workertransfer when recvqueue full 
WITHOUT_CLASSIFICATION	 heap dump 
WITHOUT_CLASSIFICATION	 wait for all tasks complete 
WITHOUT_CLASSIFICATION	 ack rest 
WITHOUT_CLASSIFICATION	 check that only two message ids were generated 
WITHOUT_CLASSIFICATION	 login will sleep until time from last refresh tickets expiry has been reached which time will wake 
WITHOUT_CLASSIFICATION	 above forloop has closed all the writers its safe clear the map here 
WITHOUT_CLASSIFICATION	 get executor heartbeat 
WITHOUT_CLASSIFICATION	 name list empty return empty map 
WITHOUT_CLASSIFICATION	 include sys should not matter 
WITHOUT_CLASSIFICATION	 detected mainq full try adding overflow 
WITHOUT_CLASSIFICATION	 finds the metadata string that matches the string and type provided the string should exist 
WITHOUT_CLASSIFICATION	 validate search time 
WITHOUT_CLASSIFICATION	 checks the tasks which had back pressure are now free again sends update other workers 
WITHOUT_CLASSIFICATION	 submit topology storm cluster 
WITHOUT_CLASSIFICATION	 fragmentedmem 
WITHOUT_CLASSIFICATION	 distributed mode 
WITHOUT_CLASSIFICATION	 need read new one 
WITHOUT_CLASSIFICATION	 sidtooutputstats 
WITHOUT_CLASSIFICATION	 return the smaller pending and toresend 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 the spout must respect when requestingemitting tuples 
WITHOUT_CLASSIFICATION	 day values 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 get numexecutors 
WITHOUT_CLASSIFICATION	 default this noop 
WITHOUT_CLASSIFICATION	 normalize state 
WITHOUT_CLASSIFICATION	 javaobject 
WITHOUT_CLASSIFICATION	 for acked message add acked set and remove from emitted and failed 
WITHOUT_CLASSIFICATION	 can track when was last used for later deletion database cleanup 
WITHOUT_CLASSIFICATION	 avoid buffering 
WITHOUT_CLASSIFICATION	 the newtimeouts map now contains logger timeout 
WITHOUT_CLASSIFICATION	 try locking again 
WITHOUT_CLASSIFICATION	 construct thshaserver 
WITHOUT_CLASSIFICATION	 version 
WITHOUT_CLASSIFICATION	 the acked message was emittedpershard that means need remove from the emittedpershard which 
WITHOUT_CLASSIFICATION	 serializes java object json 
WITHOUT_CLASSIFICATION	 resume polling the last committed offset the first offset that not marked processed 
WITHOUT_CLASSIFICATION	 invalid key remove from blobstore 
WITHOUT_CLASSIFICATION	 thriftify stats mainmethods 
WITHOUT_CLASSIFICATION	 wordspout countbolt mongoupdatebolt 
WITHOUT_CLASSIFICATION	 size identifier 
WITHOUT_CLASSIFICATION	 calc sidoutputstats 
WITHOUT_CLASSIFICATION	 noop 
WITHOUT_CLASSIFICATION	 ranked last since rack has neither cpu nor memory available 
WITHOUT_CLASSIFICATION	 flatmapfunction aware cleanup let handle cleaning 
WITHOUT_CLASSIFICATION	 construct message containing the sasl response and send the 
WITHOUT_CLASSIFICATION	 this bolt does not emit tuples 
WITHOUT_CLASSIFICATION	 dont try move the jar file local mode does not exist because was not uploaded 
WITHOUT_CLASSIFICATION	 nothing scheduled here throw away all the profileactions 
WITHOUT_CLASSIFICATION	 loggerinfoemitted new batches listeventssize 
WITHOUT_CLASSIFICATION	 not used placeholder for gui etc 
WITHOUT_CLASSIFICATION	 extend the config with defaults and the command line 
WITHOUT_CLASSIFICATION	 setting value any nonnull string 
WITHOUT_CLASSIFICATION	 any stop profile actions that hadnt timed out yet should restart after the worker running again 
WITHOUT_CLASSIFICATION	 remove existing schedule for the message 
WITHOUT_CLASSIFICATION	 totals 
WITHOUT_CLASSIFICATION	 asserts that commitsync has been called once that there are only commits one topic and that the committed offset covers messagecount messages 
WITHOUT_CLASSIFICATION	 stormassignment 
WITHOUT_CLASSIFICATION	 find homedir 
WITHOUT_CLASSIFICATION	 delete the current index file and rename the tmp file atomically replace the index file orphan tmp files are handled gettxnrecord 
WITHOUT_CLASSIFICATION	 validate search host 
WITHOUT_CLASSIFICATION	 avoid case different blob version when blob not downloaded first time download 
WITHOUT_CLASSIFICATION	 iterate the tuples 
WITHOUT_CLASSIFICATION	 create thread delete old metrics and metadata 
WITHOUT_CLASSIFICATION	 want register topo directory getchildren callback for all workers this dir 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 expecting this exception 
WITHOUT_CLASSIFICATION	 case backpressurestatus 
WITHOUT_CLASSIFICATION	 metriclist 
WITHOUT_CLASSIFICATION	 validates 
WITHOUT_CLASSIFICATION	 give the topology time come without using wait for the spouts complete 
WITHOUT_CLASSIFICATION	 include sys 
WITHOUT_CLASSIFICATION	 sometimes external things used with testing dont shut down all the way 
WITHOUT_CLASSIFICATION	 key supervisor key value supervisor ports 
WITHOUT_CLASSIFICATION	 run aggregator compute the result 
WITHOUT_CLASSIFICATION	 this noop 
WITHOUT_CLASSIFICATION	 repartitioning involved does perpartition reduce key before emitting the results downstream 
WITHOUT_CLASSIFICATION	 configs from get configs from conf 
WITHOUT_CLASSIFICATION	 password 
WITHOUT_CLASSIFICATION	 set acl user doesnt have read access 
WITHOUT_CLASSIFICATION	 scans from key start the key before end calling back until callback indicates not process further 
WITHOUT_CLASSIFICATION	 unsuccesful fail the pending tuples 
WITHOUT_CLASSIFICATION	 this test two phases the first phase fills the buckets with tuples each 
WITHOUT_CLASSIFICATION	 reset property 
WITHOUT_CLASSIFICATION	 version 
WITHOUT_CLASSIFICATION	 pulseids 
WITHOUT_CLASSIFICATION	 this method enables the metrics accessed from outside the jcqueue class 
WITHOUT_CLASSIFICATION	 verify lock file location verify lock filename 
WITHOUT_CLASSIFICATION	 pass for the case running tons tasks single executor 
WITHOUT_CLASSIFICATION	 acked message should not failed since fails and gets reemitted moves emittedpershard from failedpershard defensive coding 
WITHOUT_CLASSIFICATION	 all null tuples should commited meaning they were considered emitted and acked 
WITHOUT_CLASSIFICATION	 the start index positioned find any possible occurrence search string that did not quite fit the buffer the previous read 
WITHOUT_CLASSIFICATION	 generate another rack supervisors with less resources 
WITHOUT_CLASSIFICATION	 scheduling changed while running 
WITHOUT_CLASSIFICATION	 load from state 
WITHOUT_CLASSIFICATION	 boolean indicate whether timer active 
WITHOUT_CLASSIFICATION	 valid javac option which another bug 
WITHOUT_CLASSIFICATION	 map the worker the components the worker able enforce constraints 
WITHOUT_CLASSIFICATION	 any receive call after exceeding max pending messages results null 
WITHOUT_CLASSIFICATION	 invoke service handler 
WITHOUT_CLASSIFICATION	 finally delete any basenameversion files that are not pointed the current version 
WITHOUT_CLASSIFICATION	 choosing atmost words update the blacklist file for filtering 
WITHOUT_CLASSIFICATION	 assume the recvqueue stable which the arrival rate equal the consumption rate this assumption does not hold the calculation sojourn time should also consider departure rate according queuing theory 
WITHOUT_CLASSIFICATION	 serializedjava 
WITHOUT_CLASSIFICATION	 generate sasl response server using channellocal sasl client 
WITHOUT_CLASSIFICATION	 gets nimbus subject with nimbusprincipal set 
WITHOUT_CLASSIFICATION	 topologystatus 
WITHOUT_CLASSIFICATION	 take the max the default and whatever the user put here each nodes resources can the sum several operations the simplest thing get the max the situation want avoid that the user sets low resources one node and when that node combined with bunch others the sum still that low resource count any component isnt set want use the default right now this code does not check that just takes the max the summed resource counts for simplicitys sake could perform some more complicated logic more accurate but the benefits are very small and only apply some very odd corner cases 
WITHOUT_CLASSIFICATION	 indexed 
WITHOUT_CLASSIFICATION	 unblock downloading accepting the futures 
WITHOUT_CLASSIFICATION	 this finds all dependency blob keys from active topologies from all local blob keys 
WITHOUT_CLASSIFICATION	 nimbuses 
WITHOUT_CLASSIFICATION	 emit all messages and check that they are emitted ack the messages too 
WITHOUT_CLASSIFICATION	 rest jerrys running topologies 
WITHOUT_CLASSIFICATION	 since asked for tuples starting seekoffset some retriable records must have been compacted away ack the first offset received the record not already acked currently the topology 
WITHOUT_CLASSIFICATION	 always retain resources use 
WITHOUT_CLASSIFICATION	 update worker tokens needed 
WITHOUT_CLASSIFICATION	 consumer 
WITHOUT_CLASSIFICATION	 not blocking call cannot emit will add tuple pendingemits and return false pendingemits can null 
WITHOUT_CLASSIFICATION	 cannot since can doublemaxvalue should not return infinity that case 
WITHOUT_CLASSIFICATION	 the failed tuples are ready for retry make appear like and were compacted away 
WITHOUT_CLASSIFICATION	 helpful for debugging tests 
WITHOUT_CLASSIFICATION	 workerresources 
WITHOUT_CLASSIFICATION	 else use the exponential backoff logic and handle long overflow 
WITHOUT_CLASSIFICATION	 complete access the blob 
WITHOUT_CLASSIFICATION	 streams 
WITHOUT_CLASSIFICATION	 reasonable size for simple class 
WITHOUT_CLASSIFICATION	 order avoid going over maxnodes may need steal from myself even though other pools have free nodes figure out how much each group should provide 
WITHOUT_CLASSIFICATION	 factory methods declaring modeloutputs default stream 
WITHOUT_CLASSIFICATION	 persist the window state 
WITHOUT_CLASSIFICATION	 hdfs related settings 
WITHOUT_CLASSIFICATION	 race condition with delete 
WITHOUT_CLASSIFICATION	 timesecs 
WITHOUT_CLASSIFICATION	 hour values 
WITHOUT_CLASSIFICATION	 noop 
WITHOUT_CLASSIFICATION	 gets minmax task pairs executors 
WITHOUT_CLASSIFICATION	 tick should have flushed 
WITHOUT_CLASSIFICATION	 test for subject with principals and acls set worldeverything 
WITHOUT_CLASSIFICATION	 create empty files filesdir 
WITHOUT_CLASSIFICATION	 initialize worker slot for every port even there assignment 
WITHOUT_CLASSIFICATION	 explicit delete for ephmeral node ensure this session creates the entry 
WITHOUT_CLASSIFICATION	 for global cleanup for active workers dir make sure for the last 
WITHOUT_CLASSIFICATION	 repartition that state query fields grouping works correctly this can optimized further 
WITHOUT_CLASSIFICATION	 the logwriter turn launches the actual worker 
WITHOUT_CLASSIFICATION	 the config consists single key config its values are used instead this means that the same config files can used with flux and the 
WITHOUT_CLASSIFICATION	 offset was not committed this topology therefore applies only when the topology first deployed 
WITHOUT_CLASSIFICATION	 this likely happen when try commit something that was cleaned this expected and acceptable 
WITHOUT_CLASSIFICATION	 credupdatelock not needed here because creds are being added for the first time 
WITHOUT_CLASSIFICATION	 required required optional optional optional optional optional optional optional optional 
WITHOUT_CLASSIFICATION	 get pmml model from blobstore 
WITHOUT_CLASSIFICATION	 boltspecific configuration for windowed bolts specify the name the field the tuple that holds the message this used track the windowing boundaries and avoid reevaluating the windows during recovery 
WITHOUT_CLASSIFICATION	 create metric for memory 
WITHOUT_CLASSIFICATION	 kafka 
WITHOUT_CLASSIFICATION	 delete and recreate lock file returns false somebody else already deleted take ownership 
WITHOUT_CLASSIFICATION	 maps storm tuple redis key and value 
WITHOUT_CLASSIFICATION	 this will fail since jerry doesnt have either cpu memory entries 
WITHOUT_CLASSIFICATION	 removeclean changed requests that are not for 
WITHOUT_CLASSIFICATION	 bolt that subscribes the intermediate bolt and autoacks 
WITHOUT_CLASSIFICATION	 delete absent file should return false 
WITHOUT_CLASSIFICATION	 transferred 
WITHOUT_CLASSIFICATION	 test with dummy testsubject for cases where subject null security turned 
WITHOUT_CLASSIFICATION	 should synchronize supervisor doesnt launch anything after being down optimization 
WITHOUT_CLASSIFICATION	 default parallelism its omitted the topology will still function 
WITHOUT_CLASSIFICATION	 pendingcommit has entries 
WITHOUT_CLASSIFICATION	 query the streamstate for each input task stream and compute recoverystates 
WITHOUT_CLASSIFICATION	 required optional required 
WITHOUT_CLASSIFICATION	 reset for next run 
WITHOUT_CLASSIFICATION	 that fails fall back the file 
WITHOUT_CLASSIFICATION	 back off 
WITHOUT_CLASSIFICATION	 settable 
WITHOUT_CLASSIFICATION	 first retry then retry time current time initial delay 
WITHOUT_CLASSIFICATION	 windows the host process still holds lock the logfile 
WITHOUT_CLASSIFICATION	 each evicted partition has 
WITHOUT_CLASSIFICATION	 the response should empty since you should not able list files outside the worker log root 
WITHOUT_CLASSIFICATION	 totalexecutors 
WITHOUT_CLASSIFICATION	 try create the parent directory may not work 
WITHOUT_CLASSIFICATION	 simulate time starts out are going just leave here 
WITHOUT_CLASSIFICATION	 optional optional 
WITHOUT_CLASSIFICATION	 required optional optional optional 
WITHOUT_CLASSIFICATION	 disable log every sec 
WITHOUT_CLASSIFICATION	 handles tuple events emit ack etc 
WITHOUT_CLASSIFICATION	 boolval 
WITHOUT_CLASSIFICATION	 only log accesses that fetched something 
WITHOUT_CLASSIFICATION	 make sure that the error thread exits 
WITHOUT_CLASSIFICATION	 look hdfs blobstore again 
WITHOUT_CLASSIFICATION	 check avoids multiple log msgs when spinning idle loop 
WITHOUT_CLASSIFICATION	 add events 
WITHOUT_CLASSIFICATION	 create test dnstoswitchmapping plugin 
WITHOUT_CLASSIFICATION	 for the currently tested assignment map the node the components able enforce constraints 
WITHOUT_CLASSIFICATION	 otherwise tuples were emitted directly 
WITHOUT_CLASSIFICATION	 expiry before next scheduled refresh 
WITHOUT_CLASSIFICATION	 the system still has some free memory give them grace period 
WITHOUT_CLASSIFICATION	 tuple contains string object json format tuple contains java object that must serialized json solrjsonmapper 
WITHOUT_CLASSIFICATION	 topo has small tasks whose mem usage does not exactly divide nodes mem capacity 
WITHOUT_CLASSIFICATION	 bolt bolt should also receive from checkpoint spout 
WITHOUT_CLASSIFICATION	 cache the msgs grouped destination node 
WITHOUT_CLASSIFICATION	 add unique identifier each tuple which helpful for debugging 
WITHOUT_CLASSIFICATION	 the redis bolt sink 
WITHOUT_CLASSIFICATION	 since this tumbling window calculation use all the tuples the window compute the avg 
WITHOUT_CLASSIFICATION	 respectively 
WITHOUT_CLASSIFICATION	 sleep for seconds 
WITHOUT_CLASSIFICATION	 create array the right type 
WITHOUT_CLASSIFICATION	 storm will try get metrics from the spout even while deactivated the spout must able handle this 
WITHOUT_CLASSIFICATION	 initialization only complete after the first call 
WITHOUT_CLASSIFICATION	 mock failure 
WITHOUT_CLASSIFICATION	 update nextoffset 
WITHOUT_CLASSIFICATION	 based how java handles the classpath 
WITHOUT_CLASSIFICATION	 ordered partition keys 
WITHOUT_CLASSIFICATION	 this should mean that were pointed directory 
WITHOUT_CLASSIFICATION	 renames files and returns the new file path 
WITHOUT_CLASSIFICATION	 leave the acked offsets and consumer position they were resume where left off 
WITHOUT_CLASSIFICATION	 test for user having read write admin access read replication for blob 
WITHOUT_CLASSIFICATION	 instead the scheduler lets you set the maximum heap size for any worker 
WITHOUT_CLASSIFICATION	 test time schedule large cluster scheduling with fragmentation 
WITHOUT_CLASSIFICATION	 when for this iteration 
WITHOUT_CLASSIFICATION	 can happen during shutdown drpc while topology still 
WITHOUT_CLASSIFICATION	 mapstreamname joininfo 
WITHOUT_CLASSIFICATION	 size the resource 
WITHOUT_CLASSIFICATION	 leadership coordination may incomplete when launchserver called previous behavior did one time check which could cause nimbus not process transitions similar problem exists for 
WITHOUT_CLASSIFICATION	 should promote only fetch storm bases topologies that need scheduling 
WITHOUT_CLASSIFICATION	 for faster insertion rocksdb 
WITHOUT_CLASSIFICATION	 mapstreamname mapkey listtuple 
WITHOUT_CLASSIFICATION	 move tmp current that the operation atomic 
WITHOUT_CLASSIFICATION	 supervisorsummaries 
WITHOUT_CLASSIFICATION	 this needs appropriately large drown out any time advances performed during topology boot 
WITHOUT_CLASSIFICATION	 not scheduled never failed never emitted scheduled and ready retried 
WITHOUT_CLASSIFICATION	 the node does not exist then the version must 
WITHOUT_CLASSIFICATION	 wait interfal for retrying after first failure 
WITHOUT_CLASSIFICATION	 only add topologies that are not sharing nodes with other topologies 
WITHOUT_CLASSIFICATION	 read and ack remaining lines 
WITHOUT_CLASSIFICATION	 create the blobstores 
WITHOUT_CLASSIFICATION	 seqable 
WITHOUT_CLASSIFICATION	 new topology needs scheduled topo should evicted even though topo from user jerry older topo will not evicted 
WITHOUT_CLASSIFICATION	 with auth 
WITHOUT_CLASSIFICATION	 warm seconds 
WITHOUT_CLASSIFICATION	 number evicted events 
WITHOUT_CLASSIFICATION	 add spouts groups can get parallelisms 
WITHOUT_CLASSIFICATION	 setup kafka spout 
WITHOUT_CLASSIFICATION	 offset management 
WITHOUT_CLASSIFICATION	 have the new credentials pass the logincontext constructor 
WITHOUT_CLASSIFICATION	 check see the cgroup mounted all 
WITHOUT_CLASSIFICATION	 emit crossjoin all emitted tuples 
WITHOUT_CLASSIFICATION	 copy everything from local blobstore hdfs 
WITHOUT_CLASSIFICATION	 check that the spout will reemit all failed tuples and other tuples 
WITHOUT_CLASSIFICATION	 every executor has instance this class 
WITHOUT_CLASSIFICATION	 customobject 
WITHOUT_CLASSIFICATION	 test substitution where the target type list 
WITHOUT_CLASSIFICATION	 implementation for handling the failed messages retry logic 
WITHOUT_CLASSIFICATION	 the kafkaconsumer commitsync api docs the committed offset should the next message your application will consume 
WITHOUT_CLASSIFICATION	 should not throw 
WITHOUT_CLASSIFICATION	 log the connection error only once 
WITHOUT_CLASSIFICATION	 try get blobmeta this will check the key exists and the subject has authorization 
WITHOUT_CLASSIFICATION	 todo batch updating 
WITHOUT_CLASSIFICATION	 configured for achieving max throughput single worker mode empirically found for reference numbers taken macbook pro mid acker millsec batchszk recvqsizek millsec batchsz recvqsizek acker millsec lat microsec batchsz boltwaitparkmicros acker millsec lat micros batchsz receivebuffersizek boltwait bpwait progressivedefaults acker millsec lat micros batchsz boltwaitparkmicros 
WITHOUT_CLASSIFICATION	 insure that keytab used only one login per process executed 
WITHOUT_CLASSIFICATION	 means 
WITHOUT_CLASSIFICATION	 test the happy path emit batches sequence 
WITHOUT_CLASSIFICATION	 print the values stdout 
WITHOUT_CLASSIFICATION	 wait strategy when the netty channel not writable 
WITHOUT_CLASSIFICATION	 the following come from the jvm specification table 
WITHOUT_CLASSIFICATION	 called flushtupletimer thread 
WITHOUT_CLASSIFICATION	 ack received for message then add the ackedpershard treeset treeset because while committing need figure out what the 
WITHOUT_CLASSIFICATION	 get trigger count value from store 
WITHOUT_CLASSIFICATION	 passed workers local clusters exposed thrift server distributed mode 
WITHOUT_CLASSIFICATION	 topology will not able successfully scheduled config largest memory requirement component the topology 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 netty timertask already defined and hence fully qualified name 
WITHOUT_CLASSIFICATION	 executor form starttaskid endtaskid 
WITHOUT_CLASSIFICATION	 get per task components 
WITHOUT_CLASSIFICATION	 bolts 
WITHOUT_CLASSIFICATION	 verify that some ticks are received the interval between ticks validated the bolt too few and the checks will time out too many and the bolt may crash not reliably but the test should become flaky 
WITHOUT_CLASSIFICATION	 measurement 
WITHOUT_CLASSIFICATION	 add more events with gap 
WITHOUT_CLASSIFICATION	 error should not leaked according the code but they are not important enough fail the build 
WITHOUT_CLASSIFICATION	 supervisors 
WITHOUT_CLASSIFICATION	 end test 
WITHOUT_CLASSIFICATION	 copy cluster that can modify but does not get committed back cluster unless scheduling succeeds 
WITHOUT_CLASSIFICATION	 the jitter allows the clients get the data different times and avoids thundering herd 
WITHOUT_CLASSIFICATION	 ranked last since rack has not cpu resources 
WITHOUT_CLASSIFICATION	 read line and ack 
WITHOUT_CLASSIFICATION	 seconds milliseconds 
WITHOUT_CLASSIFICATION	 use default stormgenerated file names 
WITHOUT_CLASSIFICATION	 nothing expired yet 
WITHOUT_CLASSIFICATION	 should pass now 
WITHOUT_CLASSIFICATION	 filtered out 
WITHOUT_CLASSIFICATION	 sometimes leader election indicates the current nimbus leader but the host was recently restarted and currently not leader 
WITHOUT_CLASSIFICATION	 show progress bar know were not stuck especially slow connections 
WITHOUT_CLASSIFICATION	 end test 
WITHOUT_CLASSIFICATION	 todo timestamps 
WITHOUT_CLASSIFICATION	 ignore 
WITHOUT_CLASSIFICATION	 the timeout thread handling 
WITHOUT_CLASSIFICATION	 slots schedule for some reason skip 
WITHOUT_CLASSIFICATION	 end test 
WITHOUT_CLASSIFICATION	 parallelismhint 
WITHOUT_CLASSIFICATION	 commit offsets that are ready committed for every topic partition 
WITHOUT_CLASSIFICATION	 its likely that bolt shutting down need throw runtimeexception just ignore 
WITHOUT_CLASSIFICATION	 create empty file 
WITHOUT_CLASSIFICATION	 testing whether acls are set worldeverything here the acl should not contain worldeverything because the subject neither null nor empty the acl should however contain usereverything user needs have complete access the blob 
WITHOUT_CLASSIFICATION	 this assumes that infields and outfields are the same for combineragg assumption also made above 
WITHOUT_CLASSIFICATION	 converts metadata string into unique integer updates the timestamp the string 
WITHOUT_CLASSIFICATION	 there will legacy values they will the outer conf 
WITHOUT_CLASSIFICATION	 wait until all workers supervisors and nimbus waiting 
WITHOUT_CLASSIFICATION	 construct groups mapping for the fixedgroupsmapping class 
WITHOUT_CLASSIFICATION	 this test where are configured point right artifact dir 
WITHOUT_CLASSIFICATION	 cond prevents staying stuck with consuming overflow 
WITHOUT_CLASSIFICATION	 the elements having the same key within the window will grouped together and their values will reduced using the given reduce function here the result pairstreamstring double with stock symbol the key and the maximum price for that symbol within the window the value 
WITHOUT_CLASSIFICATION	 secretversion 
WITHOUT_CLASSIFICATION	 get the directory put uncompressed archives 
WITHOUT_CLASSIFICATION	 expecting failcount 
WITHOUT_CLASSIFICATION	 now know for sure that this bad 
WITHOUT_CLASSIFICATION	 redis has chunk but more 
WITHOUT_CLASSIFICATION	 file order calculation significant sorting done unixformat names casefolded order get platformindependent sort and calculate the same all platforms 
WITHOUT_CLASSIFICATION	 resultcreate states that you must ensure that the keyvalues are already sorted 
WITHOUT_CLASSIFICATION	 one group subscribes the same stream with same partitioning multiple times merge those together otherwise can end with many output streams created for that partitioning need split into multiple output streams because same input having different partitioning the group 
WITHOUT_CLASSIFICATION	 global variables only used internally class 
WITHOUT_CLASSIFICATION	 shard iterator corresponding position shard for failed messages 
WITHOUT_CLASSIFICATION	 acquire lock dir 
WITHOUT_CLASSIFICATION	 find the most recent child and load that 
WITHOUT_CLASSIFICATION	 atmostonce mode must commit tuples before they are emitted the topology ensure that spout crash wont cause replays 
WITHOUT_CLASSIFICATION	 cached supervisor doesnt show 
WITHOUT_CLASSIFICATION	 else leader noop 
WITHOUT_CLASSIFICATION	 val xor value 
WITHOUT_CLASSIFICATION	 check log file content line count tuples emitted 
WITHOUT_CLASSIFICATION	 return the first message retried from the set will return the message with the earliest retry time current time 
WITHOUT_CLASSIFICATION	 amount data written and rotation policies 
WITHOUT_CLASSIFICATION	 this possibly lossy the case where value deleted because has received messages over the metrics collection period and new messages are starting come this because dont want the overhead synchronize just have the metric absolutely perfect 
WITHOUT_CLASSIFICATION	 locate login configuration 
WITHOUT_CLASSIFICATION	 the key was removed should delete too 
WITHOUT_CLASSIFICATION	 namely the two eds the orphaned worker and the healthy worker 
WITHOUT_CLASSIFICATION	 instantiation 
WITHOUT_CLASSIFICATION	 compute the stats for these and save them 
WITHOUT_CLASSIFICATION	 not for this topology skip 
WITHOUT_CLASSIFICATION	 generate some that have neither resource verify that the strategy will prioritize this last 
WITHOUT_CLASSIFICATION	 notjump open not strict mode 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 split gzipmagic into readable bytes 
WITHOUT_CLASSIFICATION	 check log file content line count tuples emitted 
WITHOUT_CLASSIFICATION	 after which nimbus comes back and read update performed 
WITHOUT_CLASSIFICATION	 get existing assignment just the map default filter out ones which have executor timeout figure out available slots cluster add that the used valid slots get total slots figure out how many executors should each slot only keep existing slots that satisfy one those slots for rest reassign them across remaining slots edge case for slots with executor timeout but with supervisor timeout just treat these valid slots that can reassigned worst comes worse the executor will timeout and wont assign here next time around 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 first block 
WITHOUT_CLASSIFICATION	 end metrics 
WITHOUT_CLASSIFICATION	 any errorexception thrown just ignore 
WITHOUT_CLASSIFICATION	 start threads after metadata cache created 
WITHOUT_CLASSIFICATION	 node for basepath nothing remove 
WITHOUT_CLASSIFICATION	 test with long value 
WITHOUT_CLASSIFICATION	 create stream word pairs 
WITHOUT_CLASSIFICATION	 hbase tokens are not renewable always have get new ones 
WITHOUT_CLASSIFICATION	 task run 
WITHOUT_CLASSIFICATION	 class 
WITHOUT_CLASSIFICATION	 initialize with storm configuration 
WITHOUT_CLASSIFICATION	 kafka throws their own type exception when interrupted throw new java ensure storm can recognize the exception reaction interrupt 
WITHOUT_CLASSIFICATION	 metric win value win metric value 
WITHOUT_CLASSIFICATION	 else local noop 
WITHOUT_CLASSIFICATION	 return null mount options string that not part cgroups 
WITHOUT_CLASSIFICATION	 past limit quit 
WITHOUT_CLASSIFICATION	 the whole bytes were not received yet return null 
WITHOUT_CLASSIFICATION	 executor summaries 
WITHOUT_CLASSIFICATION	 metrics rpc 
WITHOUT_CLASSIFICATION	 netclsns not supported ubuntu 
WITHOUT_CLASSIFICATION	 returns map from task componentid 
WITHOUT_CLASSIFICATION	 very stream name matches stream name was specified 
WITHOUT_CLASSIFICATION	 build new metadata based emitted records 
WITHOUT_CLASSIFICATION	 drop the change notifications are not running anything right now 
WITHOUT_CLASSIFICATION	 lets build topology 
WITHOUT_CLASSIFICATION	 iterate over tuples the current window 
WITHOUT_CLASSIFICATION	 ignored 
WITHOUT_CLASSIFICATION	 supervisor admin 
WITHOUT_CLASSIFICATION	 while holding currentlock avoid deadlocks 
WITHOUT_CLASSIFICATION	 obtain context object 
WITHOUT_CLASSIFICATION	 protected using lock this counter 
WITHOUT_CLASSIFICATION	 again dont want exit because logging issues 
WITHOUT_CLASSIFICATION	 validate search topology 
WITHOUT_CLASSIFICATION	 canonically the metrics data exported time bucketed when doing counts convert the absolute values here into time buckets 
WITHOUT_CLASSIFICATION	 simulate lock file lease expiring and getting closed hdfs 
WITHOUT_CLASSIFICATION	 tuple values are mapped with 
WITHOUT_CLASSIFICATION	 refresh interval msec last time the command was performed env for the command execution 
WITHOUT_CLASSIFICATION	 max rounds scanning the dirs 
WITHOUT_CLASSIFICATION	 configs from loader try read from 
WITHOUT_CLASSIFICATION	 requestid 
WITHOUT_CLASSIFICATION	 service off now just interrupt 
WITHOUT_CLASSIFICATION	 fail tuple and call nexttuple then fail tuple 
WITHOUT_CLASSIFICATION	 this bolt dosent emit downstream bolts 
WITHOUT_CLASSIFICATION	 check that reemit emits exactly the same tuples the last batch even kafka returns more messages 
WITHOUT_CLASSIFICATION	 todo add logging that not all tuples were received 
WITHOUT_CLASSIFICATION	 executelatencyms 
WITHOUT_CLASSIFICATION	 each context will have single client channel worker event loop group 
WITHOUT_CLASSIFICATION	 try find way merge this code with whats already done tridentboltexecutor 
WITHOUT_CLASSIFICATION	 component metric value note that input may contain both long and double values 
WITHOUT_CLASSIFICATION	 common fields 
WITHOUT_CLASSIFICATION	 compacted away 
WITHOUT_CLASSIFICATION	 stream words 
WITHOUT_CLASSIFICATION	 this fine still have watch from the successful exists call 
WITHOUT_CLASSIFICATION	 now lets advance time 
WITHOUT_CLASSIFICATION	 ioexception from reading the version files ignored 
WITHOUT_CLASSIFICATION	 does not block 
WITHOUT_CLASSIFICATION	 check that nonnull meta makes the spout seek according the provided metadata and that the returned meta correct 
WITHOUT_CLASSIFICATION	 class mockcollector 
WITHOUT_CLASSIFICATION	 the global stream this the from component must part 
WITHOUT_CLASSIFICATION	 invalidate the cache something the node changed 
WITHOUT_CLASSIFICATION	 suppressing exceptions dont care for errors connection close 
WITHOUT_CLASSIFICATION	 ignored 
WITHOUT_CLASSIFICATION	 stormid 
WITHOUT_CLASSIFICATION	 list array conversion 
WITHOUT_CLASSIFICATION	 locate our thrift transport plugin 
WITHOUT_CLASSIFICATION	 switch cachedgauge this starts hurt performance 
WITHOUT_CLASSIFICATION	 declare separate punctuation stream per output stream that the receiving bolt can subscribe this stream with all grouping and process the punctuation once receives from all upstream tasks 
WITHOUT_CLASSIFICATION	 sync sending will return sendresult 
WITHOUT_CLASSIFICATION	 acked 
WITHOUT_CLASSIFICATION	 not change unless add state not stored the parent class 
WITHOUT_CLASSIFICATION	 storm rotation policy other than timedrotationpolicy causes npe cleanup 
WITHOUT_CLASSIFICATION	 user with impersonation acl should reject 
WITHOUT_CLASSIFICATION	 this method expected thread safe 
WITHOUT_CLASSIFICATION	 are done nothing that short going work here 
WITHOUT_CLASSIFICATION	 less really per seconds 
WITHOUT_CLASSIFICATION	 precommit can invoked during recovery before the state initialized 
WITHOUT_CLASSIFICATION	 not set lot things are not really going work all that well 
WITHOUT_CLASSIFICATION	 distributed mode 
WITHOUT_CLASSIFICATION	 add special pathspec static content mapped the homepath 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 ack both emitted tuples 
WITHOUT_CLASSIFICATION	 resetloglevel 
WITHOUT_CLASSIFICATION	 use jsonserializer the default serializer 
WITHOUT_CLASSIFICATION	 call firechannelread since the client allowed perform this request the clients request will now proceed the next pipeline component namely stormclienthandler 
WITHOUT_CLASSIFICATION	 sliding interval 
WITHOUT_CLASSIFICATION	 drpc spout then contains function 
WITHOUT_CLASSIFICATION	 partial writes prior lines 
WITHOUT_CLASSIFICATION	 deletes the state inside the zookeeper for key for which the 
WITHOUT_CLASSIFICATION	 ilookup 
WITHOUT_CLASSIFICATION	 disconnects dont fail 
WITHOUT_CLASSIFICATION	 nimbus itself 
WITHOUT_CLASSIFICATION	 make the new assignments for topologies 
WITHOUT_CLASSIFICATION	 late tuple emitted 
WITHOUT_CLASSIFICATION	 was trycause but looked the code around this and key not found not wrapped runtime not needed 
WITHOUT_CLASSIFICATION	 user jerry submits another topology 
WITHOUT_CLASSIFICATION	 key shouldnt iterator 
WITHOUT_CLASSIFICATION	 blobstore directory private 
WITHOUT_CLASSIFICATION	 the merged configs are only for the reset logic 
WITHOUT_CLASSIFICATION	 now see can create new token for bob and try again 
WITHOUT_CLASSIFICATION	 create socket with server 
WITHOUT_CLASSIFICATION	 remove offsetmanagers for all partitions that are longer assigned this spout 
WITHOUT_CLASSIFICATION	 need have slots separate hosts the topology needs gpus memory and cpu the bolt instances must separate nodes because they each need gpus the bolt instances must the same node they each need gpu this assumes that are packing the components avoid fragmentation the bolt and spout instances fill the rest 
WITHOUT_CLASSIFICATION	 when empty 
WITHOUT_CLASSIFICATION	 remove any expired keys after possibly inserting new ones 
WITHOUT_CLASSIFICATION	 were either going empty starting fresh blob download either way the changing blob notifications are outdated 
WITHOUT_CLASSIFICATION	 verify that the following acked now committed tuples are not emitted again since the consumer position was somewhere the middle the acked tuples when the commit happened this verifies that the spout keeps the consumer position ahead the committed offset when committing 
WITHOUT_CLASSIFICATION	 flushed the buffers completely 
WITHOUT_CLASSIFICATION	 next file 
WITHOUT_CLASSIFICATION	 subscribe parents punctuation stream 
WITHOUT_CLASSIFICATION	 set the current timestamp the reference time for the eviction policy evict the events 
WITHOUT_CLASSIFICATION	 resources 
WITHOUT_CLASSIFICATION	 cannot connect there client section the jaas conf 
WITHOUT_CLASSIFICATION	 metrics 
WITHOUT_CLASSIFICATION	 skip any resources where the total the percent used for this resource isnt meaningful fall back prioritizing cpu memory and any other resources ignoring this value 
WITHOUT_CLASSIFICATION	 initialcapacity set since its the default inital capacity 
WITHOUT_CLASSIFICATION	 raw input data scored predicted pmml model read from file null using blobstore pmml model downloaded from blobstore null using file 
WITHOUT_CLASSIFICATION	 poll 
WITHOUT_CLASSIFICATION	 measurement 
WITHOUT_CLASSIFICATION	 cant find the resources directory resources jar the classpath just create empty resources directory this way can check later that the topology jar was fully downloaded 
WITHOUT_CLASSIFICATION	 acquire locks filefilefile 
WITHOUT_CLASSIFICATION	 successfully decoded frame 
WITHOUT_CLASSIFICATION	 well assume the metadata was recently used still the cache 
WITHOUT_CLASSIFICATION	 number events per windowpartition 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 reuse the retrieved iterator 
WITHOUT_CLASSIFICATION	 add cassandra cluster contact points 
WITHOUT_CLASSIFICATION	 fail all emitted messages except the first commit the first 
WITHOUT_CLASSIFICATION	 string does not exist create using unique string and add cache 
WITHOUT_CLASSIFICATION	 this class should combined with 
WITHOUT_CLASSIFICATION	 keeping for backward compatibility 
WITHOUT_CLASSIFICATION	 required required optional optional optional 
WITHOUT_CLASSIFICATION	 use servers backup they exist 
WITHOUT_CLASSIFICATION	 its more likely file read exception here dont differentiate 
WITHOUT_CLASSIFICATION	 select new file one not open already 
WITHOUT_CLASSIFICATION	 some cases might limiting memory the supervisor and not the cgroups 
WITHOUT_CLASSIFICATION	 possible that this component already scheduled this node worker when backtrack cannot remove 
WITHOUT_CLASSIFICATION	 test can reemit the second batch 
WITHOUT_CLASSIFICATION	 outputsfields can empty this bolt acts like sink topology 
WITHOUT_CLASSIFICATION	 iterating multiple times should produce same events 
WITHOUT_CLASSIFICATION	 executor resides one one worker one executor and executor another worker the other node 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 optional 
WITHOUT_CLASSIFICATION	 are pretending nimbus here 
WITHOUT_CLASSIFICATION	 wait for leader elected topology submission can rejected 
WITHOUT_CLASSIFICATION	 stateful processor immediately follows window specification 
WITHOUT_CLASSIFICATION	 user not authorized 
WITHOUT_CLASSIFICATION	 stormversion 
WITHOUT_CLASSIFICATION	 validator definitions 
WITHOUT_CLASSIFICATION	 should fail 
WITHOUT_CLASSIFICATION	 batch sync sending 
WITHOUT_CLASSIFICATION	 dont emit anything allow configured spout wait strategy kick 
WITHOUT_CLASSIFICATION	 downloading all blobs finished this the precondition for all codes below 
WITHOUT_CLASSIFICATION	 initial timeout second workers commit suicide after this 
WITHOUT_CLASSIFICATION	 since read last should evicted and should exist 
WITHOUT_CLASSIFICATION	 run 
WITHOUT_CLASSIFICATION	 nummatchessought nummatchesfound 
WITHOUT_CLASSIFICATION	 validate memory settings 
WITHOUT_CLASSIFICATION	 set principal rebalanceoptions nil because users are not suppose set this 
WITHOUT_CLASSIFICATION	 add tick tuple each second force acknowledgement pending tuples 
WITHOUT_CLASSIFICATION	 has successfully authenticated with this server 
WITHOUT_CLASSIFICATION	 state found for this shard then set the sequence number 
WITHOUT_CLASSIFICATION	 failing tuples for partitions that are longer assigned useless since the spout will not allowed commit them they later pass 
WITHOUT_CLASSIFICATION	 required required required required required optional optional optional optional optional optional 
WITHOUT_CLASSIFICATION	 errors bit special because older versions storm the worker created the parent directories lazily because this means need auto create least the topoid directory for all running topos 
WITHOUT_CLASSIFICATION	 look impt hdfs timestamp may not reflect recent appends double check the timestamp last line file see when the last update was made 
WITHOUT_CLASSIFICATION	 clear cache 
WITHOUT_CLASSIFICATION	 throwing exception 
WITHOUT_CLASSIFICATION	 set upper limit how much cpu can used all workers running supervisor node this done that some cpu cycles will remain free run the daemons and other miscellaneous operations 
WITHOUT_CLASSIFICATION	 this gets called repeatedly for apparent reason dont anything 
WITHOUT_CLASSIFICATION	 join users and stores city name 
WITHOUT_CLASSIFICATION	 for testing only invoked via reflection 
WITHOUT_CLASSIFICATION	 first streams data goes into the probe 
WITHOUT_CLASSIFICATION	 fail fast 
WITHOUT_CLASSIFICATION	 hostport workersummary 
WITHOUT_CLASSIFICATION	 files are worldwide readable and owner writable 
WITHOUT_CLASSIFICATION	 storm tuple redis keyvalue mapper 
WITHOUT_CLASSIFICATION	 add configs from resources like hdfssitexml 
WITHOUT_CLASSIFICATION	 maybe apersistentset which dont support addall 
WITHOUT_CLASSIFICATION	 since made user not authorized component map empty 
WITHOUT_CLASSIFICATION	 create stateupdater with the given windowstorefactory remove triggered aggregation results form store 
WITHOUT_CLASSIFICATION	 get all metadata from the cache put into the database use new map prevent threading issues with writer thread 
WITHOUT_CLASSIFICATION	 avro strings are stored using special avro utf type instead using java primitives 
WITHOUT_CLASSIFICATION	 dont error timer shut down happens when the elector closed 
WITHOUT_CLASSIFICATION	 with tuples per second 
WITHOUT_CLASSIFICATION	 comma separated list connect strings connect zookeeper localhost 
WITHOUT_CLASSIFICATION	 lose the race but doesnt matter 
WITHOUT_CLASSIFICATION	 fall throw purpose 
WITHOUT_CLASSIFICATION	 yes can delete something that not because races but that for metrics 
WITHOUT_CLASSIFICATION	 remove old connections atomically 
WITHOUT_CLASSIFICATION	 enum conversion 
WITHOUT_CLASSIFICATION	 noop 
WITHOUT_CLASSIFICATION	 dont permit path traversal for calls intended read from the daemon logs 
WITHOUT_CLASSIFICATION	 put bolt message first then put task ids 
WITHOUT_CLASSIFICATION	 make sure the parent directory there and ready 
WITHOUT_CLASSIFICATION	 nothing assigned yet should emit nothing 
WITHOUT_CLASSIFICATION	 filter sys streams necessary 
WITHOUT_CLASSIFICATION	 calling choosetasks should finished before refreshing ring adjusting might needed with really slow machine allow race condition between refreshing ring and choosing tasks will not make exact even distribution though diff expected small given that all threadtasks are finished before refreshing ring 
WITHOUT_CLASSIFICATION	 there could collisions keytostring returns only part result 
WITHOUT_CLASSIFICATION	 object handling interaction 
WITHOUT_CLASSIFICATION	 search for the remaining bucket metrics 
WITHOUT_CLASSIFICATION	 gainleadership system event dont log issue 
WITHOUT_CLASSIFICATION	 only keep important conf keys 
WITHOUT_CLASSIFICATION	 javaxjms objects 
WITHOUT_CLASSIFICATION	 get the last successfully committed state from state store 
WITHOUT_CLASSIFICATION	 since only give leadership were waiting for blobs sync makes sense wait full sync cycle before trying for leadership again 
WITHOUT_CLASSIFICATION	 keys shouldnt appear twice 
WITHOUT_CLASSIFICATION	 filter 
WITHOUT_CLASSIFICATION	 any errorexception thrown report directly nimbus 
WITHOUT_CLASSIFICATION	 all time 
WITHOUT_CLASSIFICATION	 this should not happen localhost but does are still 
WITHOUT_CLASSIFICATION	 may the task restarted the middle and the state needs initialized fail fast and trigger recovery 
WITHOUT_CLASSIFICATION	 async sending 
WITHOUT_CLASSIFICATION	 enables avoid projection unless the final stream being joined 
WITHOUT_CLASSIFICATION	 when topology was launched 
WITHOUT_CLASSIFICATION	 lock timeout 
WITHOUT_CLASSIFICATION	 helper mainmethods 
WITHOUT_CLASSIFICATION	 something odd happened try again later 
WITHOUT_CLASSIFICATION	 groups this user authorized impersonate 
WITHOUT_CLASSIFICATION	 session timeout milliseconds 
WITHOUT_CLASSIFICATION	 stream overrides 
WITHOUT_CLASSIFICATION	 evicted enough topologies have hope scheduling try now and dont evict more than needed 
WITHOUT_CLASSIFICATION	 error 
WITHOUT_CLASSIFICATION	 attempt find the string cache 
WITHOUT_CLASSIFICATION	 validate search executor 
WITHOUT_CLASSIFICATION	 datasize 
WITHOUT_CLASSIFICATION	 intended not guarding with trywithresource since otherwise test will fail 
WITHOUT_CLASSIFICATION	 since using stringwriter not need close 
WITHOUT_CLASSIFICATION	 waiting for spout tuples isnt strictly necessary since also wait for bolt emits but anyway 
WITHOUT_CLASSIFICATION	 stormcore needed here for backwards compatibility 
WITHOUT_CLASSIFICATION	 eventloghost 
WITHOUT_CLASSIFICATION	 below regex uses negative lookahead not split the middle json objects json arrays this needed parse valid json objectarrays passed options via stormcmd windows this not issue while using stormpy since urlencodes the options and the below regex just does split the commas that separates each option note this regex handles only valid json strings and could produce invalid results the options contain unencoded invalid json strings with unmatched can replace below code with split once stormcmd fixed send urlencoded options 
WITHOUT_CLASSIFICATION	 node topologyid double 
WITHOUT_CLASSIFICATION	 return object 
WITHOUT_CLASSIFICATION	 the outputstream done 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 level parknanosl 
WITHOUT_CLASSIFICATION	 create framed transport 
WITHOUT_CLASSIFICATION	 wait until time out 
WITHOUT_CLASSIFICATION	 clean for resource isolation enabled 
WITHOUT_CLASSIFICATION	 devnull bolt 
WITHOUT_CLASSIFICATION	 release the reference all blobs associated with this topology 
WITHOUT_CLASSIFICATION	 lasterror 
WITHOUT_CLASSIFICATION	 check that blob can deleted when temporary file exists the blob directory 
WITHOUT_CLASSIFICATION	 fields with embedded commas doublequote characters 
WITHOUT_CLASSIFICATION	 this means but not 
WITHOUT_CLASSIFICATION	 messageblob 
WITHOUT_CLASSIFICATION	 noop for zookeeper implementation 
WITHOUT_CLASSIFICATION	 max number files delete for every round 
WITHOUT_CLASSIFICATION	 print lookup result with low probability 
WITHOUT_CLASSIFICATION	 only off the topology for now 
WITHOUT_CLASSIFICATION	 never rollback 
WITHOUT_CLASSIFICATION	 create another spout take over processing and read few lines 
WITHOUT_CLASSIFICATION	 delay delay current time are bigger than long max value 
WITHOUT_CLASSIFICATION	 this case are ignoring the coord stuff and only looking 
WITHOUT_CLASSIFICATION	 maximum number retries 
WITHOUT_CLASSIFICATION	 setup idbolt devnullbolt 
WITHOUT_CLASSIFICATION	 nodeid topologyid workerid execs 
WITHOUT_CLASSIFICATION	 all the jms unacked messages are going redelivered clear the pendingacks 
WITHOUT_CLASSIFICATION	 add all the owners the map 
WITHOUT_CLASSIFICATION	 prefer local tasks target tasks possible 
WITHOUT_CLASSIFICATION	 latest offset 
WITHOUT_CLASSIFICATION	 first failure add the count map 
WITHOUT_CLASSIFICATION	 handle input 
WITHOUT_CLASSIFICATION	 user authorized 
WITHOUT_CLASSIFICATION	 drop back down 
WITHOUT_CLASSIFICATION	 imperative that dont emit any tuples from here since output factory cannot gotten until preparation done therefore receivers wont ready receive tuples yet cant emit tuples from here anyway since its not within batch context which only startbatch execute and finishbatch 
WITHOUT_CLASSIFICATION	 topology tracking topology dir and resources 
WITHOUT_CLASSIFICATION	 skip uploading first one since dont test upload for now 
WITHOUT_CLASSIFICATION	 this can happen the supervisor crashed after launching worker that never came 
WITHOUT_CLASSIFICATION	 generate some that has alot cpu but little memory 
WITHOUT_CLASSIFICATION	 loop through the arguments hit list that has convered array perform the conversion 
WITHOUT_CLASSIFICATION	 the second part the test the rate doubles per second but the rate tracker increases its result slowly push the tuples per second buckets out and relpace them 
WITHOUT_CLASSIFICATION	 process stream definitions 
WITHOUT_CLASSIFICATION	 failed 
WITHOUT_CLASSIFICATION	 validate port 
WITHOUT_CLASSIFICATION	 not configurable prevent change between topology restarts 
WITHOUT_CLASSIFICATION	 topologies running noop 
WITHOUT_CLASSIFICATION	 for windowed bolt windowed output collector will the anchoringacking 
WITHOUT_CLASSIFICATION	 inject output bolt 
WITHOUT_CLASSIFICATION	 non blocking returns truefalse indicating successfailure fails full 
WITHOUT_CLASSIFICATION	 scansetcaching 
WITHOUT_CLASSIFICATION	 fail only the last tuple 
WITHOUT_CLASSIFICATION	 required required required required required required required optional optional optional optional optional optional optional optional optional optional optional 
WITHOUT_CLASSIFICATION	 consume file partially 
WITHOUT_CLASSIFICATION	 generate sasl response but only actually send the response its nonnull 
WITHOUT_CLASSIFICATION	 generate random numbers 
WITHOUT_CLASSIFICATION	 nothing except validate heartbeat for now 
WITHOUT_CLASSIFICATION	 retrieve authentication configuration 
WITHOUT_CLASSIFICATION	 send expire command for hash only once expires key itself entirely use with caution 
WITHOUT_CLASSIFICATION	 retry forever 
WITHOUT_CLASSIFICATION	 check minor optimization 
WITHOUT_CLASSIFICATION	 all writessyncs will fail this should cause runtimeexception 
WITHOUT_CLASSIFICATION	 now create params map put our conf 
WITHOUT_CLASSIFICATION	 convention each share corresponds cpu core core full time the guaranteed number approximately should 
WITHOUT_CLASSIFICATION	 optional optional optional optional 
WITHOUT_CLASSIFICATION	 returns messageids order emission 
WITHOUT_CLASSIFICATION	 required required required required required optional 
WITHOUT_CLASSIFICATION	 fail count greater than maxretries discard ack for for maxretries failures are allowed maximum 
WITHOUT_CLASSIFICATION	 eventhubs bolt configurations partition mode with partitionmodetrue you need create the same number tasks the number eventhubs partitions and each bolt task will only send data one partition the partition the task the bolt event format the formatter convert tuple bytes for eventhubs null the default format common delimited tuple fields 
WITHOUT_CLASSIFICATION	 guard npe 
WITHOUT_CLASSIFICATION	 replaces normal aggregation here with global grouping because needs consistent across batches 
WITHOUT_CLASSIFICATION	 add our collection 
WITHOUT_CLASSIFICATION	 login our principal 
WITHOUT_CLASSIFICATION	 find document from mongodb 
WITHOUT_CLASSIFICATION	 msg 
WITHOUT_CLASSIFICATION	 noop 
WITHOUT_CLASSIFICATION	 login our user 
WITHOUT_CLASSIFICATION	 first check that respected when emitting from scratch 
WITHOUT_CLASSIFICATION	 perform join 
WITHOUT_CLASSIFICATION	 only host should returned given filter 
WITHOUT_CLASSIFICATION	 verify correct wrappingunwrapping partition and delegation partition assignment 
WITHOUT_CLASSIFICATION	 for chainedaggregator 
WITHOUT_CLASSIFICATION	 have crummy cache show off shared memory accounting 
WITHOUT_CLASSIFICATION	 key already exists while creating the blob else update 
WITHOUT_CLASSIFICATION	 ensure that serializations are same for all tasks matter whats 
WITHOUT_CLASSIFICATION	 connection timeout milliseconds 
WITHOUT_CLASSIFICATION	 the following are required for backwards compatibility with clojure code 
WITHOUT_CLASSIFICATION	 spawn tar utility untar archive for full fledged unix behavior such resolving symlinks tar archives 
WITHOUT_CLASSIFICATION	 the contract rankablecopy returns rankable value not 
WITHOUT_CLASSIFICATION	 unauthorized 
WITHOUT_CLASSIFICATION	 create already existing open file override flag 
WITHOUT_CLASSIFICATION	 could also make this static but not due mock 
WITHOUT_CLASSIFICATION	 blobstore state 
WITHOUT_CLASSIFICATION	 key dir needs number number buckets choose one know where look 
WITHOUT_CLASSIFICATION	 compute window length adjustment delta account for time drift 
WITHOUT_CLASSIFICATION	 processmsavg 
WITHOUT_CLASSIFICATION	 backtracking algorithm does not take into account the ordering executors worker reduce traversal space 
WITHOUT_CLASSIFICATION	 ignore 
WITHOUT_CLASSIFICATION	 spoutbolt object 
WITHOUT_CLASSIFICATION	 sampling metrics 
WITHOUT_CLASSIFICATION	 inputstream done 
WITHOUT_CLASSIFICATION	 check processor has specific priority first 
WITHOUT_CLASSIFICATION	 skip uploading first one since want test rollback not upload 
WITHOUT_CLASSIFICATION	 bits 
WITHOUT_CLASSIFICATION	 bolt implementation 
WITHOUT_CLASSIFICATION	 read all the topologies 
WITHOUT_CLASSIFICATION	 required optional optional optional optional optional optional 
WITHOUT_CLASSIFICATION	 split the stream numbers into streams even and odd numbers the first stream contains even and the second contains odd numbers 
WITHOUT_CLASSIFICATION	 has been emitted and pending ack fail 
WITHOUT_CLASSIFICATION	 value greater than longmaxvalue truncates longmaxvalue 
WITHOUT_CLASSIFICATION	 use jsonscheme the default scheme 
WITHOUT_CLASSIFICATION	 build components that may referenced spouts bolts etc the map will string object where the object fully constructed class instance 
WITHOUT_CLASSIFICATION	 mapfunction aware prepare let handle preparation 
WITHOUT_CLASSIFICATION	 two constructor signatures used initialize validators one constructor takes input map arguments the other doesnt take any arguments default constructor validator has constructor that takes map argument call that constructor 
WITHOUT_CLASSIFICATION	 connect 
WITHOUT_CLASSIFICATION	 configure for achieving max throughput single worker mode empirically found expect millsec millsec with batchsz millsec lat microsec with acker batchsz 
WITHOUT_CLASSIFICATION	 return taskmessage object 
WITHOUT_CLASSIFICATION	 static fields 
WITHOUT_CLASSIFICATION	 metrics 
WITHOUT_CLASSIFICATION	 maxretries dont retry and return false per interface contract 
WITHOUT_CLASSIFICATION	 find the number data bytes length byte 
WITHOUT_CLASSIFICATION	 sharedmemoffheap 
WITHOUT_CLASSIFICATION	 add new connections atomically 
WITHOUT_CLASSIFICATION	 setup stringgen spout 
WITHOUT_CLASSIFICATION	 get numtasks 
WITHOUT_CLASSIFICATION	 watermark events are not added the queue 
WITHOUT_CLASSIFICATION	 some mount options and relatime type are not cgroups related 
WITHOUT_CLASSIFICATION	 bolts 
WITHOUT_CLASSIFICATION	 update histograms based the new summary most common implementation reporter reports gauges before histograms because derivativegauge will trigger cache refresh upon reporters query histogram will also updated before query 
WITHOUT_CLASSIFICATION	 employed when incoming data employed when outbound path congested 
WITHOUT_CLASSIFICATION	 update the offsetmanager for each committed partition and update 
WITHOUT_CLASSIFICATION	 create keyspace not supported the current datastax driver 
WITHOUT_CLASSIFICATION	 suppressing exceptions dont care for errors heartbeats 
WITHOUT_CLASSIFICATION	 schema changes should have forced file rotations 
WITHOUT_CLASSIFICATION	 test when supervisor and worker fails ras does not alter existing assignments 
WITHOUT_CLASSIFICATION	 finish reading the file 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 passing factory rather than the actual object avoid enforcing the strong requirement having have modelrunner serializable 
WITHOUT_CLASSIFICATION	 script 
WITHOUT_CLASSIFICATION	 initial setup 
WITHOUT_CLASSIFICATION	 string does not exist database 
WITHOUT_CLASSIFICATION	 dont use the classpath part this just empty list 
WITHOUT_CLASSIFICATION	 treat reassign remove and add 
WITHOUT_CLASSIFICATION	 get latest sequence number the blob present the zookeeper possible refactor this piece code 
WITHOUT_CLASSIFICATION	 throttle this spout bit avoid maxing out cpu 
WITHOUT_CLASSIFICATION	 whatever remains the tab are non matching left rows 
WITHOUT_CLASSIFICATION	 explicit anchoring emits corresponding input tuples only default window anchoring will anchor them all tuples window 
WITHOUT_CLASSIFICATION	 scheduling status set failother eviction policy will attempted make space for this topology 
WITHOUT_CLASSIFICATION	 banner 
WITHOUT_CLASSIFICATION	 didnt find but there are races want check again after sync 
WITHOUT_CLASSIFICATION	 empty factoryargs 
WITHOUT_CLASSIFICATION	 make the assignment null let slot clean the disk assignment 
WITHOUT_CLASSIFICATION	 authentication client complete will also send saslcomplete message the client 
WITHOUT_CLASSIFICATION	 race condition with another thread and lost try again 
WITHOUT_CLASSIFICATION	 convenience alternative prepare for use tests 
WITHOUT_CLASSIFICATION	 use while loop try decode more messages possible single call 
WITHOUT_CLASSIFICATION	 windows should aligned the slide size starting firstwindowendtime windowsec because all windows are aligned the slide size can partition the spout emitted timestamps which window they should fall this checks that the partitioned spout emits fall the expected windows based the logs from the spout and bolt 
WITHOUT_CLASSIFICATION	 shouldnt propagate any exceptions 
WITHOUT_CLASSIFICATION	 get one message time for backward compatibility behaviour 
WITHOUT_CLASSIFICATION	 seconds from now 
WITHOUT_CLASSIFICATION	 spout 
WITHOUT_CLASSIFICATION	 update the shard iterator next one case this fetch does not give the message 
WITHOUT_CLASSIFICATION	 local mode just get the local nimbus instance and set the heartbeats 
WITHOUT_CLASSIFICATION	 ensure that choice and choice are not the same task 
WITHOUT_CLASSIFICATION	 need extract not what are looking for 
WITHOUT_CLASSIFICATION	 queries the state and emits the matching key value results the stream state returned the updatestatebykey passed the argument statequery 
WITHOUT_CLASSIFICATION	 keep committing when topology deactivated since ack and fail keep getting called deactivated topology 
WITHOUT_CLASSIFICATION	 heartbeats related 
WITHOUT_CLASSIFICATION	 join helper concat fields the record 
WITHOUT_CLASSIFICATION	 convert all strings numeric ids for the metric key and add the metadata cache 
WITHOUT_CLASSIFICATION	 once storm baselined java can use charset instead which obsoletes this method 
WITHOUT_CLASSIFICATION	 make sure that defined key string case wrong stuff got put into configjava 
WITHOUT_CLASSIFICATION	 writing random words blacklisted 
WITHOUT_CLASSIFICATION	 more acls can added here 
WITHOUT_CLASSIFICATION	 wait for all locks expire then heart beat locks and verify stale lock 
WITHOUT_CLASSIFICATION	 idtospoutaggstats 
WITHOUT_CLASSIFICATION	 emit all messages and fail the first one while acking the rest 
WITHOUT_CLASSIFICATION	 aggregation stats mainmethods 
WITHOUT_CLASSIFICATION	 parse cmd line args 
WITHOUT_CLASSIFICATION	 schedule topology 
WITHOUT_CLASSIFICATION	 singleton instance allows mock delegated static mainmethods our tests subclassing 
WITHOUT_CLASSIFICATION	 purposely simulate second bucket size the rate will always per second 
WITHOUT_CLASSIFICATION	 wordspout lookupbolt 
WITHOUT_CLASSIFICATION	 stringarg 
WITHOUT_CLASSIFICATION	 you cant define topologysource and dsl topology the same time 
WITHOUT_CLASSIFICATION	 can null nested field xyz becomes stringxyz either streamxyz xyz depending whether stream name present 
WITHOUT_CLASSIFICATION	 task not used just pick static value 
WITHOUT_CLASSIFICATION	 make sure all workers scheduled rack 
WITHOUT_CLASSIFICATION	 requestedmemoffheap 
WITHOUT_CLASSIFICATION	 for testing 
WITHOUT_CLASSIFICATION	 parallelism double 
WITHOUT_CLASSIFICATION	 two distinct schema should result only two files 
WITHOUT_CLASSIFICATION	 initialize serverside sasl functionality havent yet which case are looking the first sasl message from the 
WITHOUT_CLASSIFICATION	 this spout owns partitions 
WITHOUT_CLASSIFICATION	 then get and return the file string 
WITHOUT_CLASSIFICATION	 sliding windows should produce one window every slidesize tuples wait for the spout emit least enough tuples get minboltemit windows and least one full window 
WITHOUT_CLASSIFICATION	 add all the components 
WITHOUT_CLASSIFICATION	 monitor for assignment changes often possible shutdown happens fast possible 
WITHOUT_CLASSIFICATION	 user defined callback 
WITHOUT_CLASSIFICATION	 let worker tokens work insecure 
WITHOUT_CLASSIFICATION	 were rescheduled while waiting for the resources updated but the container already not running 
WITHOUT_CLASSIFICATION	 nodehost not null here newconnections only nonempty assignment was not null above host port 
WITHOUT_CLASSIFICATION	 supervisor port should only presented worker which supports rpc heartbeat 
WITHOUT_CLASSIFICATION	 update the value state 
WITHOUT_CLASSIFICATION	 the first seek offset for each topic partition the offset this spout instance started processing 
WITHOUT_CLASSIFICATION	 cassandra daemon calls systemexit windows which kills the test 
WITHOUT_CLASSIFICATION	 rotate once per timeout period that has passed since last time this was called this necessary since this method may called arbitrary intervals 
WITHOUT_CLASSIFICATION	 timer discarded after the initial launch assignment 
WITHOUT_CLASSIFICATION	 check resources 
WITHOUT_CLASSIFICATION	 later this will joined back with returninfo and all the results 
WITHOUT_CLASSIFICATION	 based transactional topologies 
WITHOUT_CLASSIFICATION	 threadsleep 
WITHOUT_CLASSIFICATION	 jms queue provider 
WITHOUT_CLASSIFICATION	 remove resources 
WITHOUT_CLASSIFICATION	 this verify that low maxpollrecords does not interfere with reemitting failed tuples 
WITHOUT_CLASSIFICATION	 the node does not exist fineexpected 
WITHOUT_CLASSIFICATION	 default sliding window count 
WITHOUT_CLASSIFICATION	 verify that failed offsets will only retry the corresponding message exists when log compaction enabled kafka possible that tuple can fail and then impossible retry because the message kafka has been deleted the spout needs quietly ack such tuples allow commits progress past the deleted offset 
WITHOUT_CLASSIFICATION	 boolarg 
WITHOUT_CLASSIFICATION	 distribution should exactly even 
WITHOUT_CLASSIFICATION	 attempt find callers cache 
WITHOUT_CLASSIFICATION	 benchmark label 
WITHOUT_CLASSIFICATION	 messages 
WITHOUT_CLASSIFICATION	 merge the old credentials creds nimbus created are not lost and case the user forgot upload something important this time 
WITHOUT_CLASSIFICATION	 generated code will not compilable since return type myplus and type are different 
WITHOUT_CLASSIFICATION	 examine the response message from server 
WITHOUT_CLASSIFICATION	 force triggers building ring 
WITHOUT_CLASSIFICATION	 nothing here could not get message 
WITHOUT_CLASSIFICATION	 required 
WITHOUT_CLASSIFICATION	 try use zookeeper secret 
WITHOUT_CLASSIFICATION	 check for uncaught exceptions during the execution the trigger and fail fast the uncaught exceptions will wrapped executionexception and thrown when futureget invoked 
WITHOUT_CLASSIFICATION	 need relogin some other thread might have logged into hadoop using their credentials autohbase might also part nimbu auto creds 
WITHOUT_CLASSIFICATION	 when this master not leader and get sync request from node just return nil which will cause clientnode get unknown error the nodesupervisor will sync timer task 
WITHOUT_CLASSIFICATION	 size matches check the streams are expected 
WITHOUT_CLASSIFICATION	 emulate the call withlatetuplestream method 
WITHOUT_CLASSIFICATION	 set the stddev the skewed keys the length but then use the absolute value that everything skewed towards 
WITHOUT_CLASSIFICATION	 storm hbase keytab 
WITHOUT_CLASSIFICATION	 there are windowedbatched processors would ack immediately 
WITHOUT_CLASSIFICATION	 the spout should not emit any more tuples 
WITHOUT_CLASSIFICATION	 helper static vars for each platform 
WITHOUT_CLASSIFICATION	 taskend 
WITHOUT_CLASSIFICATION	 not change this sysout 
WITHOUT_CLASSIFICATION	 try adding main queue its overflow not empty 
WITHOUT_CLASSIFICATION	 bolt bolt bolt 
WITHOUT_CLASSIFICATION	 new assignment 
WITHOUT_CLASSIFICATION	 generally used compare how files were actually written and compare expectations based total 
WITHOUT_CLASSIFICATION	 retries the connect fails 
WITHOUT_CLASSIFICATION	 then stop running 
WITHOUT_CLASSIFICATION	 commonstats 
WITHOUT_CLASSIFICATION	 find the task the events from this component route 
WITHOUT_CLASSIFICATION	 handle ctrlc 
WITHOUT_CLASSIFICATION	 the empty partition was not invalidated flush but evicted from cache 
WITHOUT_CLASSIFICATION	 componentexecutors maybe apersistentmap which dont support put 
WITHOUT_CLASSIFICATION	 possible get asked about eviction before have context due this case should hold all the events when the first watermark received the context will set and the events will reevaluated for eviction 
WITHOUT_CLASSIFICATION	 add tuple the batch state 
WITHOUT_CLASSIFICATION	 redis config parameters for the redisstorebolt 
WITHOUT_CLASSIFICATION	 this fine because the only time this shared when its local context 
WITHOUT_CLASSIFICATION	 usedports 
WITHOUT_CLASSIFICATION	 schedulermeta 
WITHOUT_CLASSIFICATION	 the oldest pqsize files this directory will placed with the newest the root 
WITHOUT_CLASSIFICATION	 required optional 
WITHOUT_CLASSIFICATION	 make sure all workers scheduled rack 
WITHOUT_CLASSIFICATION	 read remaining lines file then ensure lock gone 
WITHOUT_CLASSIFICATION	 get currently unused unique string 
WITHOUT_CLASSIFICATION	 use streamid source component name field tuple distinguish incoming tuple streams 
WITHOUT_CLASSIFICATION	 the spout must reemit retriable tuples even they fail out order the spout should able skip tuples has already emitted when retrying messages even those tuples are also retries 
WITHOUT_CLASSIFICATION	 business logic 
WITHOUT_CLASSIFICATION	 user jerry submits another topology but this one should scheduled since has higher priority than than the 
WITHOUT_CLASSIFICATION	 the last slot fill 
WITHOUT_CLASSIFICATION	 operation level exceptions 
WITHOUT_CLASSIFICATION	 extract bolt resource info 
WITHOUT_CLASSIFICATION	 executed 
WITHOUT_CLASSIFICATION	 sort port from small large 
WITHOUT_CLASSIFICATION	 sort comps number constraints 
WITHOUT_CLASSIFICATION	 build new metadata based the consumer position want the next emit start the current consumer position make meta that indicates that position the last emitted offset this helps avoid cases like storm and simplifies the seek logic 
WITHOUT_CLASSIFICATION	 emit empty batches simulating new records being present kafka 
WITHOUT_CLASSIFICATION	 atmostonce mode the offsets are committed after every poll and not periodically controlled the timer 
WITHOUT_CLASSIFICATION	 test topology already partially scheduled one rack 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 total tuples should recovered batch batch replayed batch 
WITHOUT_CLASSIFICATION	 its possible that permissions were not set properly the directory and the user who supposed own the dir does not this case try the delete the supervisor user 
WITHOUT_CLASSIFICATION	 create the directory matter what this can check was downloaded the future 
WITHOUT_CLASSIFICATION	 busy wait 
WITHOUT_CLASSIFICATION	 short 
WITHOUT_CLASSIFICATION	 check that the emitter can handle emitting empty batches new partition the spout configured seek latest the partition empty the initial batches may empty 
WITHOUT_CLASSIFICATION	 string metastoredblocation 
WITHOUT_CLASSIFICATION	 this here avoid overridable call the constructor 
WITHOUT_CLASSIFICATION	 pending empty return the smallest toresend 
WITHOUT_CLASSIFICATION	 attempt scheduling both topologies this triggered negative resource event the second topology incorrectly scheduled with the first place 
WITHOUT_CLASSIFICATION	 ignored the file system are does not support this dont 
WITHOUT_CLASSIFICATION	 kill process when timeout 
WITHOUT_CLASSIFICATION	 find login file configuration from storm configuration 
WITHOUT_CLASSIFICATION	 compareandset added because 
WITHOUT_CLASSIFICATION	 test for subject with principals 
WITHOUT_CLASSIFICATION	 connect callback implementation 
WITHOUT_CLASSIFICATION	 other case just set this trigger resync later 
WITHOUT_CLASSIFICATION	 force process terminated 
WITHOUT_CLASSIFICATION	 acquire slot 
WITHOUT_CLASSIFICATION	 returns list list slots reverse sorted number slots 
WITHOUT_CLASSIFICATION	 play and fail tuple 
WITHOUT_CLASSIFICATION	 delete 
WITHOUT_CLASSIFICATION	 doing below because its affecting storm metrics most likely had make tick tuple mandatory argument since its positional 
WITHOUT_CLASSIFICATION	 thread safety mostly around acl acl needs updated changed atomically more then one thread may trying update time but that because the change atomic 
WITHOUT_CLASSIFICATION	 could replaced when metrics support remove all functions 
WITHOUT_CLASSIFICATION	 required optional optional optional optional optional optional optional optional optional optional optional optional optional optional optional optional optional optional optional optional optional optional optional optional optional optional optional optional optional optional optional 
WITHOUT_CLASSIFICATION	 else assume the same teh superacl which covered creatorall 
WITHOUT_CLASSIFICATION	 topo has small tasks should able exactly use both the cpu and mem the cluster 
WITHOUT_CLASSIFICATION	 ensure that the original batch discarded and new one persisted 
WITHOUT_CLASSIFICATION	 was not there before need run 
WITHOUT_CLASSIFICATION	 stream random sentences 
WITHOUT_CLASSIFICATION	 reference archive 
WITHOUT_CLASSIFICATION	 default all the values are 
WITHOUT_CLASSIFICATION	 object representing information paramaters use while connecting kinesis using kinesis client 
WITHOUT_CLASSIFICATION	 read lines file 
WITHOUT_CLASSIFICATION	 noop grouper 
WITHOUT_CLASSIFICATION	 release things that dont need wait for 
WITHOUT_CLASSIFICATION	 trigger manually avoid timing issues 
WITHOUT_CLASSIFICATION	 actual value mapstring longdouble win stream value 
WITHOUT_CLASSIFICATION	 file should read 
WITHOUT_CLASSIFICATION	 check see any shard has already fetched records waiting emitted which case dont fetch more 
WITHOUT_CLASSIFICATION	 for testing 
WITHOUT_CLASSIFICATION	 local mode the main process should never exit its own 
WITHOUT_CLASSIFICATION	 first delete everything that longer exists 
WITHOUT_CLASSIFICATION	 killoptions 
WITHOUT_CLASSIFICATION	 additional tests that beyond what this test primarily about 
WITHOUT_CLASSIFICATION	 old buckets and their length are only touched when rotating gathering the metrics which should not that frequent such all access them should protected synchronizing with the ratetracker instance 
WITHOUT_CLASSIFICATION	 null tuple should added the ack list since definition direct ack 
WITHOUT_CLASSIFICATION	 dont know better way validate that failed 
WITHOUT_CLASSIFICATION	 the tick should not cause any acks since the batch was empty except for acking itself 
WITHOUT_CLASSIFICATION	 have three mutually disjoint treesets per shard any given time keep track what sequence number can committed zookeeper emittedpershard ackedpershard and failedpershard any record starts entering emittedpershard ack moves from emittedpershard ackedpershard and fail retry service tells retry then moves from emittedpershard failedpershard the failed records will move from failedpershard emittedpershard when the failed record emitted again retry logic for deciding what sequence number commit find the highest sequence number from ackedpershard called such that there sequence number emittedpershard failedpershard that satisfies for ackedpershard emittedpershard and failedpershard then can only commit and not because still pending and has failed 
WITHOUT_CLASSIFICATION	 use exhibitor servers 
WITHOUT_CLASSIFICATION	 reserved for saving topology data 
WITHOUT_CLASSIFICATION	 map records that were fetched from kinesis result failure and are waiting emitted 
WITHOUT_CLASSIFICATION	 this can things like have simple drpc that doesnt need use batch processing 
WITHOUT_CLASSIFICATION	 stop iterating the middle the partition 
WITHOUT_CLASSIFICATION	 componenttype 
WITHOUT_CLASSIFICATION	 configure the server 
WITHOUT_CLASSIFICATION	 assign partitions the spout 
WITHOUT_CLASSIFICATION	 its return null 
WITHOUT_CLASSIFICATION	 should assert file size 
WITHOUT_CLASSIFICATION	 approvedworkers 
WITHOUT_CLASSIFICATION	 jms queue spout 
WITHOUT_CLASSIFICATION	 first make the cache dir 
WITHOUT_CLASSIFICATION	 emit some more messages 
WITHOUT_CLASSIFICATION	 just case get something are confused about can continue processing the rest the tasks 
WITHOUT_CLASSIFICATION	 need add the new futures the existing ones 
WITHOUT_CLASSIFICATION	 logging exception while client connecting 
WITHOUT_CLASSIFICATION	 the scheduler generally will try pack executors into workers until the max heap size met but this can vary depending the specific scheduling strategy selected the reason for this try and balance the maximum pause time might take which larger for larger heaps against better performance because not needing tuples 
WITHOUT_CLASSIFICATION	 wordspout countbolt mongoinsertbolt 
WITHOUT_CLASSIFICATION	 isleader 
WITHOUT_CLASSIFICATION	 unknown error just skip 
WITHOUT_CLASSIFICATION	 factory methods declaring modeloutputs multiple streams 
WITHOUT_CLASSIFICATION	 session 
WITHOUT_CLASSIFICATION	 executornodeport 
WITHOUT_CLASSIFICATION	 index and fieldindex are precomputed delegates built over many operations using persistent data structures 
WITHOUT_CLASSIFICATION	 validation only configs some configs inside configjava may reference classes dont want expose stormclient but still want validate that they reference valid class allow this happen part the validation the client side with annotations static final members the config class and other validations here avoid naming them the same thing because clojure code walks these two classes and creates clojure constants for these values 
WITHOUT_CLASSIFICATION	 pulses 
WITHOUT_CLASSIFICATION	 common 
WITHOUT_CLASSIFICATION	 required for jackson serialization 
WITHOUT_CLASSIFICATION	 timestamp millisecond means disabling filter 
WITHOUT_CLASSIFICATION	 todo batch finding 
WITHOUT_CLASSIFICATION	 perf critical loop dont use iterators 
WITHOUT_CLASSIFICATION	 componentid 
WITHOUT_CLASSIFICATION	 commit frequency seconds 
WITHOUT_CLASSIFICATION	 there race here that can still lose 
WITHOUT_CLASSIFICATION	 jprofile stop 
WITHOUT_CLASSIFICATION	 class 
WITHOUT_CLASSIFICATION	 aggworkerstats tests 
WITHOUT_CLASSIFICATION	 break the code out sync thrift protocol 
WITHOUT_CLASSIFICATION	 server 
WITHOUT_CLASSIFICATION	 status scheduling the topology success fail 
WITHOUT_CLASSIFICATION	 with realm stormwitzendcom 
WITHOUT_CLASSIFICATION	 calc sidoutputstats 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 the removed writer should have been closed 
WITHOUT_CLASSIFICATION	 jmock see for more information 
WITHOUT_CLASSIFICATION	 convert each record into hashmap using fieldnames keys 
WITHOUT_CLASSIFICATION	 used for local cluster heartbeating 
WITHOUT_CLASSIFICATION	 servicetype 
WITHOUT_CLASSIFICATION	 apply new log settings just received 
WITHOUT_CLASSIFICATION	 being null means the source spout node 
WITHOUT_CLASSIFICATION	 look hdfs blobstore 
WITHOUT_CLASSIFICATION	 the first tuple should acked and should not have failed 
WITHOUT_CLASSIFICATION	 this section simply put the formatted log filename and corresponding port the matching 
WITHOUT_CLASSIFICATION	 topoowner 
WITHOUT_CLASSIFICATION	 filter configured should fail all users 
WITHOUT_CLASSIFICATION	 validating class implementation could fail nonnimbus daemons nimbus will catch the class not found startup and log error message just validating this string for now 
WITHOUT_CLASSIFICATION	 clocks are not sync 
WITHOUT_CLASSIFICATION	 jdkversion 
WITHOUT_CLASSIFICATION	 read record from file emit collector and record progress 
WITHOUT_CLASSIFICATION	 this should always set digest 
WITHOUT_CLASSIFICATION	 were rescheduled while waiting for the worker come 
WITHOUT_CLASSIFICATION	 get from and add lookup cache 
WITHOUT_CLASSIFICATION	 list all files for this topology 
WITHOUT_CLASSIFICATION	 examine the response message from server 
WITHOUT_CLASSIFICATION	 alice has digest jaas section all 
WITHOUT_CLASSIFICATION	 test basic substitution 
WITHOUT_CLASSIFICATION	 monotonically increasing for correlating sentrecvd msgs restarts from crash 
WITHOUT_CLASSIFICATION	 for unit tests 
WITHOUT_CLASSIFICATION	 just mkdir stormzookeeperroot dir 
WITHOUT_CLASSIFICATION	 nothing else should emitted all tuples are acked except for the final tuple which pending 
WITHOUT_CLASSIFICATION	 topologyname 
WITHOUT_CLASSIFICATION	 ensure checkpoint interval not less than sane low value 
WITHOUT_CLASSIFICATION	 end topology state transitions 
WITHOUT_CLASSIFICATION	 get metric name 
WITHOUT_CLASSIFICATION	 matches and matchcount not changed 
WITHOUT_CLASSIFICATION	 but throughput the same 
WITHOUT_CLASSIFICATION	 without auth 
WITHOUT_CLASSIFICATION	 creds 
WITHOUT_CLASSIFICATION	 tracks order which msg came 
WITHOUT_CLASSIFICATION	 the first tuple wil used check timeout reset 
WITHOUT_CLASSIFICATION	 hbase principal stormhbasewitzencom 
WITHOUT_CLASSIFICATION	 write the tuple jms destination 
WITHOUT_CLASSIFICATION	 call updatemetricfromrpc with params 
WITHOUT_CLASSIFICATION	 this here only for testing 
WITHOUT_CLASSIFICATION	 nothing 
WITHOUT_CLASSIFICATION	 preserve interrupt status 
WITHOUT_CLASSIFICATION	 how many states searched far 
WITHOUT_CLASSIFICATION	 noop need create links local mode 
WITHOUT_CLASSIFICATION	 usage let and then explicitly terminate metrics will printed when application terminated 
WITHOUT_CLASSIFICATION	 propagate that task gets canceled and the exception can retrieved from executorfutureget 
WITHOUT_CLASSIFICATION	 allow blacklist scheduler cache the supervisor with added port 
WITHOUT_CLASSIFICATION	 flushes local and remote messages 
WITHOUT_CLASSIFICATION	 allow the revocation hook commit offsets for the revoked partitions 
WITHOUT_CLASSIFICATION	 roll next 
WITHOUT_CLASSIFICATION	 topology will scheduled 
WITHOUT_CLASSIFICATION	 ensure filename doesnt contain parts 
WITHOUT_CLASSIFICATION	 reinit cache and partitions 
WITHOUT_CLASSIFICATION	 boilerplate overrides cast result from base type joinbolt user doesnt have down cast when invoking these mainmethods 
WITHOUT_CLASSIFICATION	 case nonicontext plugin must have makecontexttopoconf method that returns icontext object 
WITHOUT_CLASSIFICATION	 metrics has just been collected lets also log 
WITHOUT_CLASSIFICATION	 not exposed withclockclock 
WITHOUT_CLASSIFICATION	 validate search component 
WITHOUT_CLASSIFICATION	 remove any previously created cache instance 
WITHOUT_CLASSIFICATION	 release earliest blacklist but release all supervisors given blacklisted host 
WITHOUT_CLASSIFICATION	 stop counting when past current time 
WITHOUT_CLASSIFICATION	 this can happen when multiple clients doing mkdir same time 
WITHOUT_CLASSIFICATION	 remove uploaded jars blobs not artifacts since theyre shared across the cluster 
WITHOUT_CLASSIFICATION	 creates brand new tuples with brand new fields 
WITHOUT_CLASSIFICATION	 topology metrics distribution 
WITHOUT_CLASSIFICATION	 its method with zero args 
WITHOUT_CLASSIFICATION	 not call default constructor 
WITHOUT_CLASSIFICATION	 its nonnull 
WITHOUT_CLASSIFICATION	 storm 
WITHOUT_CLASSIFICATION	 done capturing topology information 
WITHOUT_CLASSIFICATION	 next tuple 
WITHOUT_CLASSIFICATION	 the metrics processor not critical the operation the cluster allow supervisor come 
WITHOUT_CLASSIFICATION	 add more events with past 
WITHOUT_CLASSIFICATION	 force create windowed bolt with identity nodes that dont have stateful processor inside windowed bolt 
WITHOUT_CLASSIFICATION	 intarg 
WITHOUT_CLASSIFICATION	 configs kafka spout 
WITHOUT_CLASSIFICATION	 its likely that bolt shutting down need die just ignore and loop will terminated eventually 
WITHOUT_CLASSIFICATION	 get all the tuples batch and add 
WITHOUT_CLASSIFICATION	 not process current timestamp since tuples might arrive while the trigger executing 
WITHOUT_CLASSIFICATION	 when tuple tracking enabled the spout must not replay tuples atmostonce mode 
WITHOUT_CLASSIFICATION	 there are records not call flush 
WITHOUT_CLASSIFICATION	 add null for missing fields usually case outer joins 
WITHOUT_CLASSIFICATION	 dont want run the test cgroups are not setup 
WITHOUT_CLASSIFICATION	 initialize the network topography 
WITHOUT_CLASSIFICATION	 read remaining lines 
WITHOUT_CLASSIFICATION	 resolve references 
WITHOUT_CLASSIFICATION	 for completeness 
WITHOUT_CLASSIFICATION	 the topology are scheduling 
WITHOUT_CLASSIFICATION	 should still fail 
WITHOUT_CLASSIFICATION	 factories 
WITHOUT_CLASSIFICATION	 test when supervisor fails ras does not alter existing assignments 
WITHOUT_CLASSIFICATION	 start trigger once the initialization done 
WITHOUT_CLASSIFICATION	 reference key 
WITHOUT_CLASSIFICATION	 backtracking ever get here there really isnt lot hope that will find scheduling 
WITHOUT_CLASSIFICATION	 kafka consumer configuration 
WITHOUT_CLASSIFICATION	 ensure instance per producer thd 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 ignored not set 
WITHOUT_CLASSIFICATION	 now fail tuple partition one and verify that allowed retry because the failed tuple below the limit 
WITHOUT_CLASSIFICATION	 ack the tuple and commit the waiting emit list should now cleared and the next emitted tuple should the last tuple the partition which hasnt been emitted yet 
WITHOUT_CLASSIFICATION	 kept memory avoid going kinesis again for retry 
WITHOUT_CLASSIFICATION	 counted 
WITHOUT_CLASSIFICATION	 isset assignments 
WITHOUT_CLASSIFICATION	 the supervisors this also allows you declare the serializations sequence 
WITHOUT_CLASSIFICATION	 should not show files outside daemon log root 
WITHOUT_CLASSIFICATION	 class filelockingthread 
WITHOUT_CLASSIFICATION	 closing the channel and reconnecting should done before handling the messages 
WITHOUT_CLASSIFICATION	 all internal state except for the count the current bucket are 
WITHOUT_CLASSIFICATION	 workers requested more than currently have 
WITHOUT_CLASSIFICATION	 streamid 
WITHOUT_CLASSIFICATION	 path 
WITHOUT_CLASSIFICATION	 now add some more events and new watermark and check that the previous events are expired 
WITHOUT_CLASSIFICATION	 tasks figure out what tasks talk looking topology runtime 
WITHOUT_CLASSIFICATION	 instead iterating over all the tuples the window compute the sum the values for the new events are added and old events are subtracted similar optimizations might possible other windowing computations 
WITHOUT_CLASSIFICATION	 answer when ask for private key 
WITHOUT_CLASSIFICATION	 fail 
WITHOUT_CLASSIFICATION	 schedstatus 
WITHOUT_CLASSIFICATION	 pick worker mock failed 
WITHOUT_CLASSIFICATION	 batch 
WITHOUT_CLASSIFICATION	 data 
WITHOUT_CLASSIFICATION	 offset committed are failed but not retriable the spout should now emit another maxpollrecords messages 
WITHOUT_CLASSIFICATION	 only start those requested 
WITHOUT_CLASSIFICATION	 set use the default resource aware strategy when using the 
WITHOUT_CLASSIFICATION	 boltspecific configuration for windowed bolts specify the window length count number tuples the window 
WITHOUT_CLASSIFICATION	 topologyconf 
WITHOUT_CLASSIFICATION	 check format 
WITHOUT_CLASSIFICATION	 remove the port from the supervisor and make sure the blacklist scheduler can remove the port without 
WITHOUT_CLASSIFICATION	 create wrap transport factory that could apply user credential during connections 
WITHOUT_CLASSIFICATION	 component stats 
WITHOUT_CLASSIFICATION	 invalidate after releasing the lock the parition pinned before could invalidate will get invalidated the next flush when the entry gets evicted from the cache 
WITHOUT_CLASSIFICATION	 link the components together 
WITHOUT_CLASSIFICATION	 mark the current buffer position before reading tasklen field because the whole frame might not the buffer yet will reset the buffer position the marked position 
WITHOUT_CLASSIFICATION	 attempt find the string cache this will update the lru 
WITHOUT_CLASSIFICATION	 kafka spout configuration 
WITHOUT_CLASSIFICATION	 json record doesnt need columns the same order table hive 
WITHOUT_CLASSIFICATION	 the interval between retries exhibitor operation 
WITHOUT_CLASSIFICATION	 value fields 
WITHOUT_CLASSIFICATION	 running daemon mode would pass error calling thread 
WITHOUT_CLASSIFICATION	 batch 
WITHOUT_CLASSIFICATION	 resources assigned ras resource aware scheduler 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 found good result are done 
WITHOUT_CLASSIFICATION	 pending still empty 
WITHOUT_CLASSIFICATION	 informs other workers about back pressure situation runs the nettyworker thread 
WITHOUT_CLASSIFICATION	 sleep for mins 
WITHOUT_CLASSIFICATION	 legacy resource parsing 
WITHOUT_CLASSIFICATION	 required required 
WITHOUT_CLASSIFICATION	 last offset this batch 
WITHOUT_CLASSIFICATION	 given processornodes and static state nodes 
WITHOUT_CLASSIFICATION	 create the blobstore 
WITHOUT_CLASSIFICATION	 the window boundaries are windowstart windowend 
WITHOUT_CLASSIFICATION	 batch 
WITHOUT_CLASSIFICATION	 
WITHOUT_CLASSIFICATION	 storm 
WITHOUT_CLASSIFICATION	 could make this configurable the future 
WITHOUT_CLASSIFICATION	 sub process used execute the command 
WITHOUT_CLASSIFICATION	 that worker running and moves 
WITHOUT_CLASSIFICATION	 map track next retry time for each kinesis message that failed 
WITHOUT_CLASSIFICATION	 executorstats 
WITHOUT_CLASSIFICATION	 rwx 
WITHOUT_CLASSIFICATION	 long crctuple tuple 
WITHOUT_CLASSIFICATION	 spout 
WITHOUT_CLASSIFICATION	 need more data 
WITHOUT_CLASSIFICATION	 wait all events expire 
WITHOUT_CLASSIFICATION	 create new session the user gave empty session string this the use case when the user wishes list blobs starting from the beginning 
WITHOUT_CLASSIFICATION	 host 
WITHOUT_CLASSIFICATION	 called after all executor objects the worker are created and before this object used 
WITHOUT_CLASSIFICATION	 redis has three chunks which last chunk only has entries 
WITHOUT_CLASSIFICATION	 read property file for extra consumer properties 
WITHOUT_CLASSIFICATION	 debug logging turned should just log the leader all the time 
WITHOUT_CLASSIFICATION	 lock file has expired then own 
WITHOUT_CLASSIFICATION	 iterate workersummary and find the one with the port 
WITHOUT_CLASSIFICATION	 now can calculate percentage 
WITHOUT_CLASSIFICATION	 queue records per shard fetched from kinesis and are waiting emitted 
WITHOUT_CLASSIFICATION	 change the change this minutes 
WITHOUT_CLASSIFICATION	 timestamp 
WITHOUT_CLASSIFICATION	 spout overrides 
WITHOUT_CLASSIFICATION	 merge with existing statuses 
WITHOUT_CLASSIFICATION	 least 
WITHOUT_CLASSIFICATION	 sorted set records retrued based retry time earliest retrytime record comes first 
WITHOUT_CLASSIFICATION	 check that only subscribed one componentstream for statespout setsubscribedstate appropriately 
WITHOUT_CLASSIFICATION	 factory mainmethods 
WITHOUT_CLASSIFICATION	 get sequence number details from latest sequence number the blob 
WITHOUT_CLASSIFICATION	 create stream random numbers from spout that emits random integers extracting the tuple value index 
WITHOUT_CLASSIFICATION	 schedule topology history cleaner 
WITHOUT_CLASSIFICATION	 will commit progress into lock file commit threshold reached 
WITHOUT_CLASSIFICATION	 create and configure topology 
WITHOUT_CLASSIFICATION	 map hold partition level and topic level metrics 
WITHOUT_CLASSIFICATION	 setup some filesdirs emulate supervisor restart 
WITHOUT_CLASSIFICATION	 the versions are different roll back whatever current 
WITHOUT_CLASSIFICATION	 only for test 
WITHOUT_CLASSIFICATION	 supervisor contains bad slots 
WITHOUT_CLASSIFICATION	 couldshould use 
WITHOUT_CLASSIFICATION	 save the current state for recovery 
WITHOUT_CLASSIFICATION	 sub directories store either files uncompressed archives respectively 
WITHOUT_CLASSIFICATION	 dependencyjars 
WITHOUT_CLASSIFICATION	 ksec 
WITHOUT_CLASSIFICATION	 the subset earliest retriable offsets that are pollable partitions 
WITHOUT_CLASSIFICATION	 convert millis 
WITHOUT_CLASSIFICATION	 workersummaries 
WITHOUT_CLASSIFICATION	 class configs 
WITHOUT_CLASSIFICATION	 call firechannelread since the client allowed perform this request the clients request will now proceed the next 
WITHOUT_CLASSIFICATION	 enabledisable acking 
WITHOUT_CLASSIFICATION	 tgt not bother with ticket management 
WITHOUT_CLASSIFICATION	 fileoffset the index last scanned file 
WITHOUT_CLASSIFICATION	 the failed tuples are ready for retry make appear like and the first partition were compacted away this case the second partition acts control verify that only skip past offsets that are longer present 
WITHOUT_CLASSIFICATION	 worker dirs 
WITHOUT_CLASSIFICATION	 this point there nothing all likelihood any filesystem operations will fail the next tuple will almost certainly fail write andor sync which force rotation that will give rotateandreset chance work which includes creating fresh file handle 
WITHOUT_CLASSIFICATION	 required required required required required required 
WITHOUT_CLASSIFICATION	 final stormtopology topology 
WITHOUT_CLASSIFICATION	 loglevel 
WITHOUT_CLASSIFICATION	 which case its noop 
WITHOUT_CLASSIFICATION	 verify that the poll started the earliest retriable tuple offset 
WITHOUT_CLASSIFICATION	 now check memory only 
WITHOUT_CLASSIFICATION	 continue without idling 
WITHOUT_CLASSIFICATION	 init the writer once the cache setup 
WITHOUT_CLASSIFICATION	 this because cant currently merge splitting logic into spout not the most kosher algorithm here since the grouper indexes are being trounced via the adding nodes random groups but 
WITHOUT_CLASSIFICATION	 load pmml model from blob store 
WITHOUT_CLASSIFICATION	 add nimbuses 
WITHOUT_CLASSIFICATION	 heap memory used help calculate the heap the java process for the worker off heap memory for things like jni memory allocated off heap when using the shellbolt shellspout this case the off heap just example are not using 
WITHOUT_CLASSIFICATION	 expectedowner being null means that security disabled which why are uploading credentials with security disabled 
WITHOUT_CLASSIFICATION	 allowedid null the constructor can assign what needsetc 
WITHOUT_CLASSIFICATION	 verify that more tuples are emitted and all tuples are committed 
WITHOUT_CLASSIFICATION	 emitted messages for partitions that are longer assigned this spout cant acked and should not retried hence remove them from emitted collection 
WITHOUT_CLASSIFICATION	 treat supervisor bad only all its slots matched the cached supervisor track how many times cached supervisor has been marked bad 
WITHOUT_CLASSIFICATION	 spouts 
WITHOUT_CLASSIFICATION	 acked once 
WITHOUT_CLASSIFICATION	 get load from the cache optionally pinning the entry that wont get evicted from the cache 
WITHOUT_CLASSIFICATION	 key for hdfs kerberos configs 
