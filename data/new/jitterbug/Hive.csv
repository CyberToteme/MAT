projectname,classification,commenttext
Hive,SATD,//  FIXME: probably this should also be integrated with isSame() logics 
Hive,SATD,//  Wait for t1 to block just be sure. Not ideal... 
Hive,SATD,// HIVE-17328: not sure this is correct... I don't think is gets wrapped in UDFToInteger.... 
Hive,SATD,//  We expect this to never happen in practice. Can pool paths even have angled braces? 
Hive,SATD,//  TODO: This does not work correctly. None of the partitions is created but the folder   for the first two is created. It is because in HiveMetaStore.add_partitions_core when   going through the partitions the first two are already put and started in the thread   pool when the exception occurs in the third one. When the exception occurs we go to   the finally part but the map can be empty (it depends on the progress of the other   threads) so the folders won't be deleted.      Assert.assertFalse(metaStore.isPathExists(new Path(tableLocation + "/year=2016"))); 
Hive,SATD,//  TODO: remove this after stashing only rqd pieces from opconverter 
Hive,SATD,//  TODO: should we try to make a giant array for one cache call to avoid overhead? 
Hive,SATD,//  Forward the row to reducer as is.   Discard the row.   Vectorized - may forward the row not sure yet. 
Hive,SATD,//  7. Handle any move session requests. The way move session works right now is   a) sessions get moved to destination pool if there is capacity in destination pool   b) if there is no capacity in destination pool the session gets killed (since we cannot pause a query)   TODO: in future this the process of killing can be delayed until the point where a session is actually required.   We could consider delaying the move (when destination capacity is full) until there is claim in src pool.   May be change command to support ... DELAYED MOVE TO etl ... which will run under src cluster fraction as long 
Hive,SATD,//  Not thread-safe. 
Hive,SATD,// it would be better if AlreadyExistsException had an errorCode field.... 
Hive,SATD,//  TODO: this can probably be replaced with much less code via dynamic dispatch and/or templates. 
Hive,SATD,//  TODO Handle this properly 
Hive,SATD,//  TODO: Do we need maxLength checking? 
Hive,SATD,//  TODO: prewarm and update can probably be merged. 
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#getTblProps()}. To be removed in Hive 0.16. 
Hive,SATD,//  TODO: disabling this test as tez publishes counters only after task completion which will cause write side counters   to be not validated correctly (DAG will be completed before validation)    @Test(timeout = 60000) 
Hive,SATD,//  TODO: might want to increase the default batch size. 1024 is viable; MS gets OOM if too high. 
Hive,SATD,//  TODO: remove when averageTypeValueSize method RelMdSize 
Hive,SATD,//  We store all caches in variables to change the main one based on config.   This is not thread safe between different split generations (and wasn't anyway). 
Hive,SATD,//  $x/$user/appcache/$appId/${dagId}/output/$mapId   TODO: Once Shuffle is out of NM this can use MR APIs to convert   between App and Job 
Hive,SATD,// todo: does this need the finalDestination? 
Hive,SATD,//  todo: add LIMIT 1 instead of count - should be more efficient 
Hive,SATD,/*      * TODO: client.executeStatement do not support listing resources command     * (beeline> list jar)      */
Hive,SATD,//  Note: scheduler will call this based on lack of sources at schedule time and set this         to true... there's no easy way to work around this. Need better classes 
Hive,SATD,//  TODO: will this also fix windowing? try 
Hive,SATD,//  but let's make it a little bit more explicit. 
Hive,SATD,//  TODO: This should inherit from VolcanoCost and should just override isLE   method. 
Hive,SATD,//  TODO: 1) check for duplicates 2) We assume in clause values to be   present in NDV which may not be correct (Range check can find it) 3) We   assume values in NDV set is uniformly distributed over col values   (account for skewness - histogram). 
Hive,SATD,//  TODO: if we didn't care about the column order we could switch join sides here 
Hive,SATD,//  TODO: we could remember if it's unsupported and stop sending calls; although it might         be a bad idea for HS2+standalone metastore that could be updated with support.         Maybe we should just remember this for some time. 
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#location(String)}. To be removed in Hive 0.16. 
Hive,SATD,//  TODO: why is this like that? 
Hive,SATD,/*  TODO Escape handling may be changed by a follow on.     * The largest issue is ; which are treated as statement     * terminators for the cli. Once the cli is fixed this     * code should be re-investigated      */
Hive,SATD,//  Delete data?   Fail if table doesn't exist?   Need results back? 
Hive,SATD,//  TODO: This does not work correctly. None of the partitions is created but the folder   for the first two is created. It is because in HiveMetaStore.add_partitions_core when   going through the partitions the first two are already put and started in the thread   pool when the exception occurs in the third one.   When the exception occurs we go to the finally part but the map can be empty   (it depends on the progress of the other threads) so the folders won't be deleted.   Assert.assertTrue(metaStore.isPathExists(new Path(partition1.getSd().getLocation())));   Assert.assertTrue(metaStore.isPathExists(new Path(partition2.getSd().getLocation())));   Assert.assertTrue(metaStore.isPathExists(new Path(partition3.getSd().getLocation()))); 
Hive,SATD,//  Note: we assume that this isn't an already malformed query;         we don't check for that here - it will fail later anyway. 
Hive,SATD,//  TODO - not clear if we should cache these or not.  For now don't bother 
Hive,SATD,//  TODO: this needs to be removed; see TestReplicationScenarios* comments. 
Hive,SATD,// BUG: This will not work in remote mode - HIVE-5153 
Hive,SATD,//  TODO Change this method to make the output easier to parse (parse programmatically) 
Hive,SATD,//  TODO: remove? 
Hive,SATD,//  Wouldn't it make more sense to return the first element of the list returned by the   previous call? 
Hive,SATD,//  a better logic would be to find the alias 
Hive,SATD,//  we need to enforce the size here even the types are the same 
Hive,SATD,//  This method may not be safe as it can throw an NPE if a key or value is null. 
Hive,SATD,//  TODO: this is an ugly hack because Tez plugin isolation does not make sense for LLAP plugins.         We are going to register a thread-local here for now so that the scheduler initializing         in the same thread after the communicator will pick up. Or the other way around. 
Hive,SATD,//  TODO MS-SPLIT uncomment once we move EventMessage over 
Hive,SATD,//  Follow hive's rules for type inference as oppose to Calcite's   for return type.  TODO: Perhaps we should do this for all functions not just +- 
Hive,SATD,//  TODO: [HIVE-6289] while getting stats from metastore we currently only get one col at         a time; this could be improved - get all necessary columns in advance then use local.   TODO: [HIVE-6292] aggregations could be done directly in metastore. Hive over MySQL! 
Hive,SATD,//  TODO: see planIndexReading; this is not needed here. 
Hive,SATD,//  TODO: why is it stored in both table and dpCtx? 
Hive,SATD,//  TODO: Use threadpool for more concurrency?   TODO: check/set all files or only directories  
Hive,SATD,//  TODO HIVE-15865 Handle additional reasons like OS launch failed 
Hive,SATD,//  TODO: 1) handle Agg Func Name translation 2) is it correct to add func 
Hive,SATD,//  TODO: Both of these are TException why do we need these separate clauses? 
Hive,SATD,//  TODO: if two HS2s start at exactly the same time which could happen during a coordinated         restart they could start generating the same IDs. Should we store the startTime 
Hive,SATD,//  TODO: given the specific data and lookups perhaps the nested thing should not be a map         In fact CSLM has slow single-threaded operation and one file is probably often read         by just one (or few) threads so a much more simple DS with locking might be better.         Let's use CSLM for now since it's available. 
Hive,SATD,//  TODO Ideally this should be done independent of whether mr is setup or not. 
Hive,SATD,//  This is not modeled as a @Before because it needs to be parameterized per-test.   If there is a better way to do this we should do it. 
Hive,SATD,//  todo HIVE-5269 
Hive,SATD,//  Make sure null-valued ConfVar properties do not override the Hadoop Configuration   NOTE: Comment out the following test case for now until a better way to test is found   as this test case cannot be reliably tested. The reason for this is that Hive does   overwrite fs.default.name in HiveConf if the property is set in system properties.   checkHadoopConf(ConfVars.HADOOPFS.varname "core-site.xml");   checkConfVar(ConfVars.HADOOPFS null);   checkHiveConf(ConfVars.HADOOPFS.varname "core-site.xml"); 
Hive,SATD,//  @deprecated in favour of {@link HCatPartition.#getDatabaseName()}. To be removed in Hive 0.16. 
Hive,SATD,// TODO: due to value 101 this probably should throw an exception 
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#getSortCols()}. To be removed in Hive 0.16. 
Hive,SATD,//  Hmm.. not good   the only type expected here is STRUCT which maps to HCatRecord   - anything else is an error. Return null as the inspector. 
Hive,SATD,//  TODO: should these rather be arrays? 
Hive,SATD,//  TODO Change all this to be based on a regular interface instead of relying on the Proto service - Exception signatures cannot be controlled without this for the moment. 
Hive,SATD,//  PolicyChangeListener will be implemented later 
Hive,SATD,//  TODO: do we actually need this reader? the caller just extracts child readers. 
Hive,SATD,//  TODO HIVE-14042. What is mergeWork and why is it not part of the regular operator chain.   The mergeMapOp.initialize call further down can block and will not receive information   about an abort request. 
Hive,SATD,//  TODO HIVE-15163. Handle cases where nodes go down and come back on the same port. Historic information 
Hive,SATD,//  TODO: most protocol exceptions are probably unrecoverable... throw? 
Hive,SATD,//  TODO: do we also need to remove the MapJoin from the list of RS's children? 
Hive,SATD,//  TODO: why is there a TezSession in MR ExecDriver? 
Hive,SATD,//  Replace INSERT OVERWRITE by MERGE equivalent rewriting.   Here we need to do this complex AST rewriting that generates the same plan   that a MERGE clause would generate because CBO does not support MERGE yet.   TODO: Support MERGE as first class member in CBO to simplify this logic. 
Hive,SATD,//  TODO: Current implementation of replication will result in DROP_PARTITION under replication   scope being called per-partition instead of multiple partitions. However to be robust we   must still handle the case of multiple partitions in case this assumption changes in the   future. However if this assumption changes we will not be very performant if we fetch   each partition one-by-one and then decide on inspection whether or not this is a candidate   for dropping. Thus we need a way to push this filter (replicationSpec.allowEventReplacementInto)   to the  metastore to allow it to do drop a partition or not depending on a Predicate on the   parameter key values. 
Hive,SATD,//  TODO: should we pass curr instead of null? 
Hive,SATD,//  Really not sure if this should go here.  Will have   to see how the storage mechanism evolves. 
Hive,SATD,//  TODO Force fs to file:// setup staging dir?        conf.set("fs.defaultFS" "file:///");        conf.set(TezConfiguration.TEZ_AM_STAGING_DIR "/tmp"); 
Hive,SATD,// todo: why not just use getRootDir()? 
Hive,SATD,//  TODO: lossy conversion! 
Hive,SATD,//  TODO: remove the copy after ORC-158 and ORC-197 
Hive,SATD,//  TODO: If the DB name doesn't match with the metadata from dump then need to rewrite the original and expanded   texts using new DB name. Currently it refers to the source database name. 
Hive,SATD,//  TODO: remove this constructor 
Hive,SATD,//  TODO: add the ability to extractFileTail to read from multiple buffers? 
Hive,SATD,//  TODO : instead of simply restricting by message format we should eventually   move to a jdbc-driver-stype registering of message format and picking message   factory per event to decode. For now however since all messages have the   same factory restricting by message format is effectively a guard against   older leftover data that would cause us problems. 
Hive,SATD,//  TODO: When hive moves to java8 make updateTimezone() as default method in 
Hive,SATD,//  Not strictly necessary noone will look at it. 
Hive,SATD,//  2**exponent part is scaling down while 10**scale is scaling up.   Now it's tricky.   unscaledValue = significand * 10**scale / 2**twoScaleDown 
Hive,SATD,//  TODO CAT - I am fairly certain that most calls to this are in error.  This should only be   used when the database location is unset which should never happen except when a   new database is being created.  Once I have confirmation of this change calls of this to   getDatabasePath() since it does the right thing.  Also merge this with   determineDatabasePath() as it duplicates much of the logic. 
Hive,SATD,//  TODO: Should this be the concern of the mutator? 
Hive,SATD,//  TODO: Provide support for reporting errors   This should never happen as server always returns a valid status on success 
Hive,SATD,/*  TODO: ideally when the splits UDF is made a proper API coordinator should not   *        be managed as a global. HS2 should create it and then pass it around.  */
Hive,SATD,//  TODO: convert sqlState etc. 
Hive,SATD,//  TODO Include EXTERNAL_PREEMPTION in this list? 
Hive,SATD,//  To workaround AvroUTF8 
Hive,SATD,//  TODO needs to go in InitializeInput? as part of InputJobInfo 
Hive,SATD,//  Note that this logic may drop some of the tables of the database   even if the drop database fail for any reason   TODO: Fix this 
Hive,SATD,//  Some walkers extending DefaultGraphWalker e.g. ForwardWalker   do not use opQueue and rely uniquely in the toWalk structure   thus we store the results produced by the dispatcher here   TODO: rewriting the logic of those walkers to use opQueue 
Hive,SATD,//  This is a corner case where we have an extract of time unit like day/month pushed as Extraction Fn  @TODO The best way to fix this is to add explicit output Druid types to Calcite Extraction Functions impls 
Hive,SATD,//  Workaround for HADOOP-12659 - remove when Hadoop 2.7.X is no longer supported. 
Hive,SATD,//  We could pass in the number of nodes that we expect instead of -1.   Also a single concurrent request per node is currently hardcoded. 
Hive,SATD,//  TODO: Strangely the default parametrization is to ignore missing tables 
Hive,SATD,//  FIXME : should clean up TEST_PATH but not doing it now for debugging's sake 
Hive,SATD,//  This will throw error if we close pout early. 
Hive,SATD,//  It is not a very clean way and should be modified later - due to   compatibility reasons   user sees the results as json for custom scripts and has no way for   specifying that.   Right now it is hard-coded in the code 
Hive,SATD,//  TODO This test passes fine locally but fails on Linux not sure why 
Hive,SATD,//  TODO: SeekableInputStream.readFully eventually calls a Hadoop method that used to be         buggy in 2.7 and also anyway just does a copy for a direct buffer. Do a copy here.   ((SeekableInputStream)stream).readFully(bb); 
Hive,SATD,//  TODO: 1) Expand to other functions as needed 2) What about types other than primitive. 
Hive,SATD,//  Set footer cache for current split generation. See field comment - not thread safe. 
Hive,SATD,//  TODO: the below seem like they should just be combined into partitionDesc 
Hive,SATD,//  CallableWithNdc inherits from NDC only when call() is invoked. CallableWithNdc has to   extended to provide access to its ndcStack that is cloned during creation. Until then   we will use reflection to access the private field.   FIXME: HIVE-14243 follow to remove this reflection 
Hive,SATD,//  TODO: this is brittle. Who said everyone has to upgrade using upgrade process? 
Hive,SATD,/*    * Check whether a task can run to completion or may end up blocking on it's sources.   * This currently happens via looking up source state.   * TODO: Eventually this should lookup the Hive Processor to figure out whether   * it's reached a state where it can finish - especially in cases of failures   * after data has been fetched.   *   * @return true if the task can finish false otherwise    */
Hive,SATD,//  UNDONE: How to look for all NULLs in a multi-key?????  Let nulls through for now. 
Hive,SATD,//  Note: this can still conflict with parallel transactions. We do not currently handle         parallel changes from two admins (by design :(). 
Hive,SATD,//  TODO: time good enough for now - we'll likely improve this.   We may also work in something the equivalent of pid thrid and move to nanos to ensure   uniqueness. 
Hive,SATD,//  FIXME: somehow place pointers that re-execution compilation have failed; the query have been successfully compiled before? 
Hive,SATD,//  UNDONE: Haven't finished isRepeated 
Hive,SATD,//  hack instead figure out a way to get the db paths 
Hive,SATD,// TODO: support complex types   for complex type we simply return 0 
Hive,SATD,//  TODO: the control flow for this needs to be defined. Hive is supposed to be thread-local. 
Hive,SATD,// todo: should be at the top of the file... 
Hive,SATD,//  Get rid of TOK_SELEXPR 
Hive,SATD,//  Clear the work map after build. TODO: remove caching instead? 
Hive,SATD,//  DO_NOT_UPDATE_STATS is supposed to be a transient parameter that is only passed via RPC   We want to avoid this property from being persistent.     NOTE: If this property *is* set as table property we will remove it which is incorrect but   we can't distinguish between these two cases     This problem was introduced by HIVE-10228. A better approach would be to pass the property 
Hive,SATD,//  This is using the payload from the RootVertexInitializer corresponding   to InputName. Ideally it should be using it's own configuration class -   but that 
Hive,SATD,//  like HiveHBaseTableInputFormat cannot be used with this (todo) 
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#collectionItemsTerminatedBy()}. To be removed in Hive 0.16. 
Hive,SATD,//  TODO: Once HBASE-11163 is completed use that API or switch to   using mapreduce version of the APIs. rather than mapred   Copied from HBase's TableMapreduceUtil since it is not public API 
Hive,SATD,//  TODO: Fetch partitions in batches?   TODO: Threadpool to process partitions? 
Hive,SATD,//  TODO : simple wrap & rethrow for now clean up with error codes 
Hive,SATD,// todo: add method to only get current i.e. skip history - more efficient 
Hive,SATD,/*  * Simple wrapper of object with ObjectInspector. *  * TODO: we need to redefine the hashCode and equals methods so that it can be * put into a HashMap as a key. *  * This class also serves as a facility for a function that returns both an * object and an ObjectInspector.  */
Hive,SATD,//  The ordering of types here is used to determine which numeric types   are common/convertible to one another. Probably better to rely on the   ordering explicitly defined here than to assume that the enum values   that were arbitrarily assigned in PrimitiveCategory work for our purposes. 
Hive,SATD,//  Something else is wrong 
Hive,SATD,//  TODO: Comments in RexShuttle.visitCall() mention other   types in this category. Need to resolve those together   and preferably in the base class RexShuttle. 
Hive,SATD,//  TODO: Verify if this is needed (Why can't it be always null/empty 
Hive,SATD,//  is the outer join that we saw most recently is a right outer join? 
Hive,SATD,//  TODO: this relies on HDFS not changing the format; we assume if we could get inode ID this         is still going to work. Otherwise file IDs can be turned off. Later we should use         as public utility method in HDFS to obtain the inode-based path. 
Hive,SATD,//  TODO: should it rather do a prefix? 
Hive,SATD,/*    * TODO This method is temporary. Ideally Hive should only need to pass to Tez the amount of memory   *      it requires to do the map join and Tez should take care of figuring out how much to allocate   * Adjust the percentage of memory to be reserved for the processor from Tez   * based on the actual requested memory by the Map Join i.e. HIVECONVERTJOINNOCONDITIONALTASKTHRESHOLD   * @return the adjusted percentage    */
Hive,SATD,//  A hack to verify that authorization check passed. Exception can be thrown be cause   the functions are not being called with valid params.   verify that exception has come from ObjectStore code which means that the 
Hive,SATD,//  TODO: should this use getUserFromAuthenticator? 
Hive,SATD,// TODO: Move this to calcite 
Hive,SATD,//  TODO: add this to metadatareader in ORC - SI => metadata buffer not just metadata. 
Hive,SATD,//  TODO: This should come from type system; Currently there is no definition 
Hive,SATD,//  TODO At the moment there's no way of knowing whether a query is running or not.   A race is possible between dagComplete and registerFragment - where the registerFragment   is processed after a dagCompletes.   May need to keep track of completed dags for a certain time duration to avoid this.   Alternately - send in an explicit dag start message before any other message is processed.   Multiple threads communicating from a single AM gets in the way of this. 
Hive,SATD,/*     Should we allow writing to non-transactional tables in an explicit transaction?  The user may    issue ROLLBACK but these tables won't rollback.    Can do this by checking ReadEntity/WriteEntity to determine whether it's reading/writing    any non acid and raise an appropriate error    * Driver.acidSinks and Driver.transactionalInQuery can be used if any acid is in the query */
Hive,SATD,//  TODO: implement? 
Hive,SATD,// todo: what is this checking???? 
Hive,SATD,//  I think this is wrong the drop table statement should come on the table topic not the   DB topic - Alan. 
Hive,SATD,//  TODO: rather Tez sessions should not depend on SessionState. 
Hive,SATD,//  todo: support tez/vectorization 
Hive,SATD,//  TODO: read this somewhere useful like the task scheduler 
Hive,SATD,//  TODO Add support for serialization of values here 
Hive,SATD,//  TODO: Convert genIncludedColumns and setSearchArgument to use TypeDescription. 
Hive,SATD,//  TODO: when this code is a little less hot change most logs to debug.   We will determine what to do under lock and then do stuff outside of the lock.   The approach is state-based. We consider the task to have a duck when we have decided to   give it one; the sends below merely fix the discrepancy with the actual state. We may add the   ability to wait for LLAPs to positively ack the revokes in future.   The "procedural" approach requires that we track the ducks traveling on network   concurrent terminations etc. So while more precise it's much more complex. 
Hive,SATD,//  TODO: why doesn't this use context? 
Hive,SATD,//  Note: this is redundant with types 
Hive,SATD,//  The following 2 lines are exactly what MySQL does TODO: why do we do this? 
Hive,SATD,//  temporary variable for testing. This is added just to turn off this feature in case of a bug in   deployment. It has not been documented in hive-default.xml intentionally this should be removed 
Hive,SATD,//  TODO need session handle 
Hive,SATD,//  This is kind of hacky - the read entity contains the old table whereas   the write entity   contains the new table. This is needed for rename - both the old and the   new table names are   passed 
Hive,SATD,//  UNDONE: For now don't add more small keys... 
Hive,SATD,//  TODO: can this ever happen? 
Hive,SATD,//  TODO: there's a potential problem here if some table uses external schema like Avro         with a very large type name. It seems like the view does not derive the SerDe from         the table so it won't be able to just get the type from the deserializer like the         table does; we won't be able to properly store the type in the RDBMS metastore. 
Hive,SATD,//  TODO: this should depends on input format and be in a map or something. 
Hive,SATD,//  TODO: we can actually consider storing ALL the delta encoded row offsets - not a lot of         overhead compared to the data itself and with row offsets we could use columnar         blocks for inconsistent splits. We are not optimizing for inconsistent splits for now. 
Hive,SATD,//  TODO: should this just use physical IDs? 
Hive,SATD,//  TODO: wtf?!! why is this in this method? This has nothing to do with anything. 
Hive,SATD,//  This class isn't used and I suspect does totally the wrong thing.  It's only here so that I   can provide some output format to the tables and partitions I create.  I actually write to 
Hive,SATD,//  TODO: does arg need type cast? 
Hive,SATD,// what??!! 
Hive,SATD,//  TODO not sure this is the right exception 
Hive,SATD,//  we need to convert the Hive type to the SQL type name   TODO: this would be better handled in an enum 
Hive,SATD,//  TODO: NPE should not be thrown 
Hive,SATD,//  CONSIDER: Allocate a larger initial size. 
Hive,SATD,//  No good way to find out (may even have no app). 
Hive,SATD,//  Hardcode SASL here. ZKDTSM only supports none or sasl and we never want none. 
Hive,SATD,//  We support List<Object> Set<Object> and Object[]   so we have to do differently. 
Hive,SATD,//  If wh is still null after just having initialized it bail out - something's very wrong. 
Hive,SATD,//  TODO Convert this to an Assert.fail once HIVE-14682 is fixed 
Hive,SATD,//  TODO: we should be able to enable caches separately 
Hive,SATD,//  For dynamic partitioned hash join the big table will also be coming from a ReduceSinkOperator   Check for this condition.   TODO: use indexOf() or parentRS.getTag()? 
Hive,SATD,//  TODO:   Following HiveSubQueryFinder has been copied from RexUtil::SubQueryFinder   since there is BUG in there (CALCITE-1726).   Once CALCITE-1726 is fixed we should get rid of the following code 
Hive,SATD,//  TODO: Extend rule so it can be applied for these cases. 
Hive,SATD,//  TODO: Support case DATE: 
Hive,SATD,//  TODO figure out a better way to set repeat for Binary type 
Hive,SATD,//  TODO: If we are ok with breaking compatibility of existing 3rd party StorageHandlers   this method could be moved to the HiveStorageHandler interface. 
Hive,SATD,//  TODO: This global lock may not be necessary as all concurrent methods in ICacheableMetaStoreClient   are synchronized. 
Hive,SATD,// todo: FileSystem#setPermission() - should this make sure to set 777 on jobs/ ? 
Hive,SATD,/*  * Builder for relational expressions. * TODO: *  Note that this is copied from Calcite's RelBulder *  because CALCITE-1493 hasn't been fixed yet *  This should be deleted and replaced with RelBuilder in SubqueryRemoveRule *  once CALCITE-1493 is fixed. *  EDIT: Although CALCITE-1493 has been fixed and released but HIVE now has special handling *    in join (it gets a flag to see if semi join is to be created or not). So we still can not *    replace this with Calcite's RelBuilder * * <p>{@code RelBuilder} does not make possible anything that you could not * also accomplish by calling the factory methods of the particular relational * expression. But it makes common tasks more straightforward and concise. * * <p>{@code RelBuilder} uses factories to create relational expressions. * By default it uses the default factories which create logical relational * expressions ({@link org.apache.calcite.rel.logical.LogicalFilter} * {@link org.apache.calcite.rel.logical.LogicalProject} and so forth). * But you could override those factories so that say {@code filter} creates * instead a {@code HiveFilter}. * * <p>It is not thread-safe.  */
Hive,SATD,//  TODO: Setting autocommit should not generate an exception as long as it is set to false   beeLine.autocommitStatus(getConnection()); 
Hive,SATD,//  TODO: precision and scale would be practically invalid for string conversion (3838) 
Hive,SATD,//  TODO: Should this really default to FETCH_NEXT? 
Hive,SATD,//  TODO: Not sure about the use of this. Should we instead use workerIdentity as sessionId? 
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#tableType(HCatTable.Type)}. To be removed in Hive 0.16. 
Hive,SATD,//  TODO: trace ranges here? Between data cache and incomplete cb cache 
Hive,SATD,//  FIXME: retain old error; or create a new one? 
Hive,SATD,//  we don't remove the work from the sparkWork here. The removal is done later. 
Hive,SATD,//  TODO: need to move from Python to Java for the rest of the script. 
Hive,SATD,//  check if input pruning is possible   TODO: this code is buggy - it relies on having one file per bucket; no MM support (by design). 
Hive,SATD,//  todo: strictly speaking you can commit an empty txn thus 2nd conjunct is wrong but   only   possible for for multi-stmt txns 
Hive,SATD,//  View DDL   "alter view add partition" does not work because of the nature of implementation   of the DDL in hive. Hive will internally invoke another Driver on the select statement   and HCat does not let "select" statement through. I cannot find a way to get around it   without modifying hive code. So just leave it unsupported. 
Hive,SATD,// todo: to test these need to link against 3.x libs - maven profiles?  runStatementOnDriver("create table TFlat (a int b int) stored as orc tblproperties('transactional'='false')");  runStatementOnDriver("create table TFlatText (a int b int) stored as textfile tblproperties('transactional'='false')"); 
Hive,SATD,//  NOTE : This is hacky and this section of code is fragile depending on DN code varnames   so it's likely to stop working at some time in the future especially if we upgrade DN   versions so we actively need to find a better way to make sure the leak doesn't happen   instead of just clearing out the cache after every call. 
Hive,SATD,//  TODO: should never happen? 
Hive,SATD,//  UNDONE: Don't know why HIVE-12894 causes this to return 0?   assertEquals(0.33 reader.getProgress() 0.01); 
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#getLocation()}. To be removed in Hive 0.16. 
Hive,SATD,//  we do not support Windows we will revisit this if we really need it for windows. 
Hive,SATD,//  Pass an empty list as no columns will be written to the file.   TODO I should be able to make this work for update 
Hive,SATD,//  TODO: throw an exception? 
Hive,SATD,//  TODO: move to DynamicSerDe when it's ready 
Hive,SATD,//  TODO: Replace with direct call to ProgressHelper when reliably available. 
Hive,SATD,//  TODO: this is the only place that uses keepTmpDir. Why? 
Hive,SATD,//  TODO: use serdeConstants.COLLECTION_DELIM when the typo is fixed 
Hive,SATD,//  Indicates whether a node had a recent communication failure.   This is primarily for tracking and logging purposes for the moment.   TODO At some point treat task rejection and communication failures differently. 
Hive,SATD,//  TODO: move other protocols to use this too. 
Hive,SATD,//  TODO Move the following 2 properties out of Configuration to a constant. 
Hive,SATD,/*  * Creates size estimators for java objects. The estimators attempt to do most of the reflection * work at initialization time and also take some shortcuts to minimize the amount of work done * during the actual estimation. * TODO: clean up  */
Hive,SATD,//  TODO: move to a base class? 
Hive,SATD,//  Since the MapJoin has had all of its other parents removed at this point   it would be bad here if processReduceSinkToHashJoin() tries to do anything 
Hive,SATD,// todo: should this be done for MM?  is it ok to use CombineHiveInputFormat with MM 
Hive,SATD,//  todo this should be changed to be evaluated lazily especially for single segment case 
Hive,SATD,//  TODO Disable blacklisting in Tez when using LLAP until this is properly supported.   Blacklisting can cause containers to move to a terminating state which can cause attempt to be marked as failed.   This becomes problematic when we set #allowedFailures to 0   TODO HIVE-13484 What happens when we try scheduling a task on a node that Tez at this point thinks is blacklisted. 
Hive,SATD,// todo should this check be in conformToAcid()? 
Hive,SATD,//  TODO: Split count is not same as no of buckets 
Hive,SATD,// TODO: Cols that come through PTF should it retain (VirtualColumness)? 
Hive,SATD,//  TODO : verify if any quoting is needed for keys 
Hive,SATD,// todo: this should check that the job actually completed and likely use completion time 
Hive,SATD,//  TODO: move this to logicalEquals 
Hive,SATD,/*  * TODO:<br> * 1. Could we use combined RR instead of list of RR ?<br> * 2. Use Column Processing from TypeCheckProcFactory<br> * 3. Why not use GB expr ?  */
Hive,SATD,//  TODO: Temporary for debugging. Doesn't interfere with MTT failures (unlike LOG.debug). 
Hive,SATD,//  TODO Deprecation reason does not seem to reflect in the config ?   The ordering is important in case of keys which are also deprecated.   Unset will unset the deprecated keys and all its variants. 
Hive,SATD,//  GrpSet Col already part of input RS   TODO: Can't we just copy the ExprNodeDEsc from input (Do we need to   explicitly set table alias to null & VC to false 
Hive,SATD,// todo: DataOperationType is set conservatively here we'd really want to distinguish update/delete  and insert/select and if resource (that is written to) is ACID or not 
Hive,SATD,//  TODO [MM gap]: CTAS may currently be broken. It used to work. See the old code and why isCtas isn't used? 
Hive,SATD,// todo: add partitioned table that needs conversion to MM/Acid 
Hive,SATD,//  TODO: Do we really need all this nonsense? 
Hive,SATD,//  This is bad but we have to sort the keys of the maps in order   to be commutative. 
Hive,SATD,// @TODO this seems to be the same as org.apache.hadoop.hive.ql.parse.CalcitePlanner.TableType.DRUID do we really need both 
Hive,SATD,//  TODO: NPE should not be thrown. 
Hive,SATD,/*  * Tests for the worker thread and its MR jobs. * todo: most delta files in this test suite use txn id range i.e. [NN+M] * That means that they all look like they were created by compaction or by streaming api. * Delta files created by SQL should have [NN] range (and a suffix in v1.3 and later) * Need to change some of these to have better test coverage.  */
Hive,SATD,//  not good if we reach here this was initialized at setMetaStoreHandler() time.   this means handler.getWh() is returning null. Error out. 
Hive,SATD,/*  * The processor context for partition pruner. This contains the table alias * that is being currently processed. * TODO: this class may be not useful.  */
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#nullDefinedAs()}. To be removed in Hive 0.16. 
Hive,SATD,//  TODO: enable this for production debug switching between two small buffers?  new CasLog(); 
Hive,SATD,/*  * A helper class to isolate newer HBase features from users running against older versions of * HBase that don't provide those features. * * TODO: remove this class when it's okay to drop support for earlier version of HBase.  */
Hive,SATD,//  NOTE: For Uniform Hash or no buckets/partitions when the key is empty we will use the VectorReduceSinkEmptyKeyOperator instead. 
Hive,SATD,//  TODO: verify if this is needed 
Hive,SATD,//  TODO: this class is completely unnecessary... 1-on-1 mapping with parent. 
Hive,SATD,/*    * If moving across different FileSystems or differnent encryption zone need to do a File copy instead of rename.   * TODO- consider if need to do this for different file authority.   * @throws HiveException    */
Hive,SATD,//  TODO: support propagation for partitioning/ordering in windowing 
Hive,SATD,//  named columns join   TODO: we can also do the same for semi join but it seems that other   DBMS does not support it yet. 
Hive,SATD,/*  * Helper class that generates SQL queries with syntax specific to target DB * todo: why throw MetaException?  */
Hive,SATD,//  We can continue   TODO: Need to check that this is the same MV that we are rebuilding 
Hive,SATD,//  Guess if CommonJoinResolver will work. If CommonJoinResolver may   convert a join operation correlation optimizer will not merge that join.   TODO: If hive.auto.convert.join.noconditionaltask=true for a JoinOperator   that has both intermediate tables and query input tables as input tables   we should be able to guess if this JoinOperator will be converted to a MapJoin   based on hive.auto.convert.join.noconditionaltask.size. 
Hive,SATD,//  TODO: could we log in from ticket cache instead? no good method on UGI right now. 
Hive,SATD,//  TODO: support for binary spec? presumably we'd parse it somewhere earlier 
Hive,SATD,//  redundant TODO: callers of this often get part_vals out of name for no reason... 
Hive,SATD,//  TODO MS-SPLIT for now keep a copy of HiveConf around as we need to call other methods with   it. This should be changed to Configuration once everything that this calls that requires   HiveConf is moved to the standalone metastore. 
Hive,SATD,/*    * Closes the client releasing any {@link IMetaStoreClient meta store} connections held. Does not notify any open   * transactions (TODO: perhaps it should?)    */
Hive,SATD,//  TODO: will this work? 
Hive,SATD,//  We don't have the entire part; copy both whatever we intended to cache and the rest   to an allocated buffer. We could try to optimize a bit if we have contiguous buffers   with gaps but it's probably not needed. 
Hive,SATD,/*      * TODO: Hack fix until HIVE-5848 is addressed. non-exact type shouldn't be promoted     * to exact type as FunctionRegistry.getCommonClass() might do. This corrects     * that.      */
Hive,SATD,//  FIXME: old implementation returned null; exception maybe? 
Hive,SATD,//  Optimize the scenario when there are no grouping keys - only 1 reducer is needed 
Hive,SATD,//  TODO: is Decimal an exact numeric or approximate numeric? 
Hive,SATD,//  TODO: why doesn't this use one of the existing options implementations?! 
Hive,SATD,//  Ensure there's no threadlocal. We don't expect one.   We don't ever want to create key paths with world visibility. Why is that even an option?!! 
Hive,SATD,/*    * todo: when job is complete should print the msgCount table to log     */
Hive,SATD,//  TODO explain should use a FetchTask for reading 
Hive,SATD,//  This detail not desired. 
Hive,SATD,//  TODO: use the other HdfsUtils here 
Hive,SATD,//  First check if the registry has been updated since the error and skip the error if   we have received new valid registry info (TODO: externally add a grace period for this?). 
Hive,SATD,//  TODO: calculate from cached values. 
Hive,SATD,//  Array size not big enough? 
Hive,SATD,//  UNDONE: Needed to longTest? 
Hive,SATD,//  TODO Reduce the number of lookups that happen here. This shouldn't go to HDFS for each call. 
Hive,SATD,//  No data to read for this stripe. Check if we have some included index-only columns.   TODO: there may be a bug here. Could there be partial RG filtering on index-only column? 
Hive,SATD,//  FIXME. Do the right thing Luke. 
Hive,SATD,//  TODO make it so I can randomize the column order 
Hive,SATD,//  TODO: right now we treat each slice as a stripe with a single RG and never bother         with indexes. In phase 4 we need to add indexing and filtering. 
Hive,SATD,//  TODO: a pattern from Curator. Better error handling? 
Hive,SATD,//  IO thread pool. Listening is used for unhandled errors for now (TODO: remove?) 
Hive,SATD,//  Now we need to look for any values that the user set that MetastoreConf doesn't know about.   TODO Commenting this out for now as it breaks because the conf values aren't getting properly   interpolated in case of variables.  See HIVE-17788. 
Hive,SATD,//  FIXME: including this in the signature will almost certenly differ even if the operator is doing the same   there might be conflicting usages of logicalCompare? 
Hive,SATD,//  MultiMRInput may not. Fix once TEZ-3302 is resolved. 
Hive,SATD,//  Preempt only if there are no pending preemptions on the same host   When the premption registers the request at the highest priority will be given the slot   even if the initial preemption was caused by some other task.   TODO Maybe register which task the preemption was for to avoid a bad non-local allocation. 
Hive,SATD,//  TODO: this is wrong; this test sets up dummy txn manager and so it cannot create ACID tables.         This used to work by accident now this works due a test flag. The test needs to be fixed.         Also applies for a couple more tests. 
Hive,SATD,//  TODO: why is this needed? we could just save the host and port? 
Hive,SATD,//  TODO There needs to be a mechanism to figure out different attempts for the same task. Delays   could potentially be changed based on this. 
Hive,SATD,// it's not wrong to take all delete events for bucketed tables but it's more efficient  to only take those that belong to the 'bucket' assuming we trust the file name  un-bucketed table - get all files 
Hive,SATD,/*        * Determine an *initial* input vector expression.       *       * Note: we may have to convert it later from DECIMAL_64 to regular decimal.        */
Hive,SATD,//  Note - this is a little bit confusing; the special treatment of stripe-level buffers   is because we run the ColumnStreamData refcount one ahead (as specified above). It   may look like this would release the buffers too many times (one release from the   consumer one from releaseInitialRefcounts below and one here); however this is   merely handling a special case where all the batches that are sharing the stripe-   level stream have been processed before we got here; they have all decRef-ed the CSD   but have not released the buffers because of that extra refCount. So this is   essentially the "consumer" refcount being released here. 
Hive,SATD,//  this doesn't always work since some JDBC drivers (e.g.   Oracle's) return a blank string from getTableName. 
Hive,SATD,//  TODO: Can this be moved out of the main callback path 
Hive,SATD,// TODO: add more expected test result here 
Hive,SATD,//  TODO MS-SPLIT - for now we have construct this by reflection because IMetaStoreClient   can't be   moved until after HiveMetaStore is moved which can't be moved until this is moved. 
Hive,SATD,// todo: need a test where we actually have more than 1 file 
Hive,SATD,//  Here comes the ugly part... 
Hive,SATD,//  To be removed in Hive 0.16. 
Hive,SATD,//  OPTIMIZATION for later. 
Hive,SATD,//  Is there a way to provide char length here?   It might actually be ok as long as there is an object inspector (with char length)   receiving this value. 
Hive,SATD,//  This command exists solely to output this message. TODO: can we do it w/o an error? 
Hive,SATD,//  TODO: Add support for AND clauses under OR clauses   first-cut takes a known minimal tree and no others.   $expr = (a=1)           (a=1 or a=2)           (a in (12))           ($expr and *) 
Hive,SATD,//  TODO: Set this up as a tree instead of a flat list. 
Hive,SATD,/*  * Operator factory for predicate pushdown processing of operator graph Each * operator determines the pushdown predicates by walking the expression tree. * Each operator merges its own pushdown predicates with those of its children * Finally the TableScan operator gathers all the predicates and inserts a * filter operator after itself. TODO: Further optimizations 1) Multi-insert * case 2) Create a filter operator for those predicates that couldn't be pushed * to the previous operators in the data flow 3) Merge multiple sequential * filter predicates into so that plans are more readable 4) Remove predicates * from filter operators that have been pushed. Currently these pushed * predicates are evaluated twice.  */
Hive,SATD,//  HIVE-12244 call currently ineffective 
Hive,SATD,//  Note: no location check; the buffer is always locked for move here. 
Hive,SATD,//  TODO MS-SPLIT For now if we cannot load the default PartitionExpressionForMetastore   class (since it's from ql) load the DefaultPartitionExpressionProxy which just throws   UnsupportedOperationExceptions.  This allows existing Hive instances to work but also   allows us to instantiate the metastore stand alone for testing.  Not sure if this is   the best long term solution. 
Hive,SATD,//  TODO: this is very brittle given that Hive supports nested directories in the tables.         The caller should pass a flag explicitly telling us if the directories in the         input are data or parent of data. For now retain this for backward compat. 
Hive,SATD,//  TODO: these appear to always be called under write lock. Do they need sync? 
Hive,SATD,//  TODO: we could perhaps reuse the same directory for HiveResources? 
Hive,SATD,/*    * If there's a mismatch between static and object name or a mismatch between   * vector and non-vector operator name the optimizer doens't work correctly.    */
Hive,SATD,//  Not really sure how to refer to this (or if we can).   TODO: We could find a different from branch for the union that might have an alias?         Or we could add an alias here to refer to but that might break other branches. 
Hive,SATD,//  TODO : instantiating FS objects are generally costly. Refactor 
Hive,SATD,//  TODO: when PB is upgraded to 2.6 newInstance(ByteBuffer) method should be used here. 
Hive,SATD,/*  All the code paths below propagate nulls even if neither arg2 nor arg3     * have nulls. This is to reduce the number of code paths and shorten the     * code at the expense of maybe doing unnecessary work if neither input     * has nulls. This could be improved in the future by expanding the number     * of code paths.      */
Hive,SATD,//  @deprecated in favour of {@link HCatPartition.#getPartitionKeyValMap()}. To be removed in Hive 0.16. 
Hive,SATD,// TODO: Remove this once Calcite FilterProjectTransposeRule can take rule operand 
Hive,SATD,//  TODO: we could fall back to trying one by one and only ignore the failed ones. 
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#getStorageHandler()}. To be removed in Hive 0.16. 
Hive,SATD,//  First try temp table   TODO CAT - I think the right thing here is to always put temp tables in the current   catalog.  But we don't yet have a notion of current catalog so we'll have to hold on   until we do. 
Hive,SATD,// TODO: set other Table properties as needed 
Hive,SATD,//  Don't pass in the pool set - not thread safe; if the user is trying to force us to   use a non-existent pool we want to fail anyway. We will fail later during get. 
Hive,SATD,// TODO: Since OperationLog is moved to package o.a.h.h.ql.session   we may add a Enum there and map FetchOrientation to it. 
Hive,SATD,//  TODO: ideally this only needs to be called if the result   type will also change. However since that requires   support from type inference rules to tell whether a rule   decides return type based on input types for now all   operators will be recreated with new type if any operand   changed unless the operator has "built-in" type. 
Hive,SATD,//  TODO: ideally we should store shortened representation of only the necessary fields         in HBase; it will probably require custom SARG application code. 
Hive,SATD,//  This is a massive hack.  The compactor threads have to access packages in ql (such as   AcidInputFormat).  ql depends on metastore so we can't directly access those.  To deal   with this the compactor thread classes have been put in ql and they are instantiated here   dyanmically.  This is not ideal but it avoids a massive refactoring of Hive packages.     Wrap the start of the threads in a catch Throwable loop so that any failures   don't doom the rest of the metastore. 
Hive,SATD,//  FIXME: there were 2 afterclass methods...i guess this is the right order...maybe not 
Hive,SATD,//  TODO HIVE-13483 Get all of these properties from the registry. This will need to take care of different instances   publishing potentially different values when we support changing configurations dynamically. 
Hive,SATD,//  TODO: replace with withTimeout after we get the relevant guava upgrade. 
Hive,SATD,/*    * TODO: need to turn on rules that's commented out and add more if necessary.    */
Hive,SATD,/* todo: handle renaming files somewhere */
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#getBucketCols()}. To be removed in Hive 0.16. 
Hive,SATD,//  TODO: this doesn't include superclass. 
Hive,SATD,//  FIXME: move this to ColStat related part 
Hive,SATD,//  TODO: Not sure that this is the correct behavior. It doesn't make sense to create the   partition without column info. This should be investigated later. 
Hive,SATD,//  Note : preservePartitionSpecs=true implies inheritTableSpecs=false but   but preservePartitionSpecs=false(default) here is not sufficient enough   info to set inheritTableSpecs=true 
Hive,SATD,//  FIXME: this should be changeto valueOf ...   that will also kill that fallback 'none' which is I think more like a problem than a   feature ;) 
Hive,SATD,//  TODO Setup a set of threads to process incoming requests.   Make sure requests for a single dag/query are handled by the same thread 
Hive,SATD,//  TODO: add alter database support in HCat 
Hive,SATD,//  TODO add tests for partitions in other catalogs 
Hive,SATD,//  TODO I suspect we could skip much of the stuff above this in the function in the case   of update and delete.  But I don't understand all of the side effects of the above   code and don't want to skip over it yet. 
Hive,SATD,//  TODO: expireAfterAccess locks cache segments on put and expired get. It doesn't look too bad         but if we find some perf issues it might be a good idea to remove this - we are probably         not caching that many constructors.   Note that weakKeys causes "==" to be used for key compare; this will only work   for classes in the same classloader. Should be ok in this case. 
Hive,SATD,//  TODO Why is the queue name set again. It has already been setup via setQueueName. Do only one of the two.
Hive,SATD,//  TODO Create and init session sets up queue isDefault - but does not initialize the configuration 
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#sortCols(Map<String String>)}.   To be removed in Hive 0.16. 
Hive,SATD,//  TODO: Handle Query Hints; currently we ignore them 
Hive,SATD,//  TODO: Currently we only support EQUAL operator on two references.   We might extend the logic to support other (order-preserving)   UDFs here. 
Hive,SATD,//  is the right was at the left side of a right outer join? 
Hive,SATD,//  TODO: why does this only kill non-default sessions?   Nothing for workload management since that only deals with default ones. 
Hive,SATD,//  TODO: should this use getPartitionDescFromPathRecursively? That's what other code uses. 
Hive,SATD,//  TODO: Fix this 
Hive,SATD,//  ### FIXME: doing the multi-line handling down here means   higher-level logic never sees the extra lines. So   for example if a script is being saved it won't include   the continuation lines! This is logged as sf.net   bug 879518. 
Hive,SATD,//  REVIEW jhyde 29-Oct-2007: This rule is non-static depends on the state   of members in RelDecorrelator and has side-effects in the decorrelator.   This breaks the contract of a planner rule and the rule will not be   reusable in other planners. 
Hive,SATD,//  We can loop thru all the tables to check if they are ACID first and then perform cleanup   but it's more efficient to unconditionally perform cleanup for the database especially   when there are a lot of tables 
Hive,SATD,//  TODO: Implement this 
Hive,SATD,//  TODO: allow using unsafe optionally.   bounds check first to trigger bugs whether the first byte matches or not 
Hive,SATD,//  TODO: this doesn't appear to be used anywhere. 
Hive,SATD,//  for auto convert map-joins it not safe to dedup in here (todo) 
Hive,SATD,//  We're scanning a tree from roots to leaf (this is not technically   correct demux and mux operators might form a diamond shape but   we will only scan one path and ignore the others because the   diamond shape is always contained in a single vertex). The scan   is depth first and because we remove parents when we pack a pipeline   into a vertex we will never visit any node twice. But because of that   we might have a situation where we need to connect 'work' that comes after   the 'work' we're currently looking at.     Also note: the concept of leaf and root is reversed in hive for historical 
Hive,SATD,//  The following parameters are not supported yet. TODO Add support 
Hive,SATD,//  TODO: this should be   unique 
Hive,SATD,// todo: Concurrent insert/update of same partition - should pass 
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#fieldsTerminatedBy()}. To be removed in Hive 0.16. 
Hive,SATD,//  TODO: this is invalid for ACID tables and we cannot access AcidUtils here. 
Hive,SATD,/*    * After each major compaction stats need to be updated on each column of the   * table/partition which previously had stats.   * 1. create a bucketed ORC backed table (Orc is currently required by ACID)   * 2. populate 2 partitions with data   * 3. compute stats   * 4. insert some data into the table using StreamingAPI   * 5. Trigger major compaction (which should update stats)   * 6. check that stats have been updated   *   * @throws Exception todo:   *                   2. add non-partitioned test   *                   4. add a test with sorted table?    */
Hive,SATD,/*    * in Hive 1.3.0 delta file names changed to delta_xxxx_yyyy_zzzz; prior to that   * the name was delta_xxxx_yyyy.  We want to run compaction tests such that both formats   * are used since new (1.3) code has to be able to read old files.    */
Hive,SATD,//  TODO: should call HiveHFileOutputFormat#setOutputPath 
Hive,SATD,//  TODO: we could try to get superclass or generic interfaces. 
Hive,SATD,//  TODO: this actually calls the metrics system and getMetrics - that may be expensive.         For now it looks like it should be ok to do on WM thread. 
Hive,SATD,//  TODO: get rid of the builders - they serve no purpose... just call ctors directly. 
Hive,SATD,//  TODO: Verify GB having is not a separate filter (if so we shouldn't   introduce derived table) 
Hive,SATD,/* Q: why don't we lock the snapshot here???  Instead of having client make an explicit call    whenever it chooses    A: If we want to rely on locks for transaction scheduling we must get the snapshot after lock    acquisition.  Relying on locks is a pessimistic strategy which works better under high    contention. */
Hive,SATD,//  TODO: temporary need to expose from ORC utils (note the difference in null checks) 
Hive,SATD,//  TODO: maybe use stack of est+obj pairs instead of recursion. 
Hive,SATD,//  TODO: shortcut for last col below length? 
Hive,SATD,//  TEMPORARY: In order to avoid a new version of storage-api do the conversion here... 
Hive,SATD,// TODO: these constraints should be supported for partition columns 
Hive,SATD,//  We have a nested setcolref. Process that and start from scratch TODO: use stack? 
Hive,SATD,//  TODO: is this correct? based on the same logic as HIVE-14200 
Hive,SATD,//  TODO refactor the following into the pipeline 
Hive,SATD,//  TODO: change to FileInputFormat.... field after MAPREDUCE-7086. 
Hive,SATD,//  TODO: if we ever use this endpoint for anything else refactor cycling into a separate class. 
Hive,SATD,//  something is seriously wrong if this is happening 
Hive,SATD,//  TODO: Ordering seems to affect the distinctness needs checking disabling. 
Hive,SATD,//  TODO: avoid put() by working directly in OutStream? 
Hive,SATD,//  Can't fetch prefix on colqual must pull the entire qualifier   TODO use an iterator to do the filter server-side. 
Hive,SATD,//  These tests inherently cause exceptions to be written to the test output   logs. This is undesirable since you it might appear to someone looking   at the test output logs as if something is failing when it isn't. Not   sure 
Hive,SATD,//     return HiveConf.getPositionFromInternalName(fieldName);   The above line should have been all the implementation that   we need but due to a bug in that impl which recognizes   only single-digit columns we need another impl here. 
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#getPartCols()}. To be removed in Hive 0.16. 
Hive,SATD,//  TODO: Verify if we need to use ConstantObjectInspector to unwrap data 
Hive,SATD,//  2) Generate HiveTableFunctionScan RelNode for lateral view   TODO: Support different functions (not only INLINE) with LATERAL VIEW JOIN 
Hive,SATD,// todo: this is actually not adding anything since LockComponent uses a Trie to "promote" a lock  except by accident - when we have a partitioned target table we have a ReadEntity and WriteEntity  for the table so we mark ReadEntity and then delete WriteEntity (replace with Partition entries)  so DbTxnManager skips Read lock on the ReadEntity....  input.noLockNeeded()? 
Hive,SATD,// TODO- cleanup once parquet support Timestamp type annotation. 
Hive,SATD,//  TODO: buffers are accounted for at allocation time but ideally we should report the memory         overhead from the java objects to memory manager and remove it when discarding file. 
Hive,SATD,//  TODO: cleanup this 
Hive,SATD,//  TODO: HIVE-13624 Do we need maxLength checking? 
Hive,SATD,//  In addBatchToWriter we have passed the batch to both ORC and operator pipeline   (neither ever changes the vectors). We'd need a set of vectors batch to write to.   TODO: for now create this from scratch. Ideally we should return the vectors from ops.         We could also have the ORC thread create it for us in its spare time... 
Hive,SATD,//  TODO: enforce max length 
Hive,SATD,//  TODO: would it make sense to return buffers asynchronously? 
Hive,SATD,//  TODO: The best solution is to support NaN in expression reduction. 
Hive,SATD,//  TODO: ideally this should be moved outside to HiveMetaStore to be shared between         all the RawStore-s. Right now there's no method to create a pool. 
Hive,SATD,//  TODO HIVE-14042. Abort handling. 
Hive,SATD,// todo: update to search by ID once HIVE-13353 is done 
Hive,SATD,//  Note: type param is not available here. 
Hive,SATD,//  TODO: When function privileges are implemented they should be deleted here. 
Hive,SATD,//  TODO: perhaps move to Orc InStream? 
Hive,SATD,// TODO: should not throw different exceptions for different HMS deployment types 
Hive,SATD,//  TODO: Clean up all the other paths that are created. 
Hive,SATD,//  TODO: ideally when col-stats-accurate stuff is stored in some sane structure this should         to retrieve partsToUpdate in a single query; no checking partition params in java. 
Hive,SATD,//  UNDONE: Missing date/time interval data types 
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#getCols()}. To be removed in Hive 0.16. 
Hive,SATD,//  TODO: refactor this out 
Hive,SATD,//  TODO This needs to be looked at. Map of Map to Map... Made concurrent for now since split generation   can happen in parallel. 
Hive,SATD,//  TODO: Fix the expressions later. 
Hive,SATD,//  @deprecated in favour of {@link #create(HCatTable)}. To be removed in Hive 0.16. 
Hive,SATD,//  TODO: handle ExprNodeColumnListDesc 
Hive,SATD,//  5. Push Down Semi Joins  TODO: Enable this later 
Hive,SATD,// todo: add TXNS.COMMENT filed and set it to 'aborted by system due to timeout'  easier to read logs 
Hive,SATD,//  TODO RIVEN switch this back to package level when we can move TestHadoopAuthBridge23 into   riven. 
Hive,SATD,//  TODO Change this over to just store local dir indices instead of the entire path. Far more efficient. 
Hive,SATD,//  TODO: we might revisit this in create-drop-recreate cases needs some thinking on. 
Hive,SATD,//  TODO: why is this in text formatter?!! 
Hive,SATD,/*  * NOTE: this rule is replicated from Calcite's SubqueryRemoveRule * Transform that converts IN EXISTS and scalar sub-queries into joins. * TODO: *  Reason this is replicated instead of using Calcite's is *    Calcite creates null literal with null type but hive needs it to be properly typed * * <p>Sub-queries are represented by {@link RexSubQuery} expressions. * * <p>A sub-query may or may not be correlated. If a sub-query is correlated * the wrapped {@link RelNode} will contain a {@link RexCorrelVariable} before * the rewrite and the product of the rewrite will be a {@link Correlate}. * The Correlate can be removed using {@link RelDecorrelator}.  */
Hive,SATD,//  truncate (TODO: posix_fallocate?) 
Hive,SATD,//  NOTE: This code tries to get all key-value pairs out of the map.   It's not very efficient. The more efficient way should be to let MapOI   return an Iterator. This is currently not supported by MapOI yet. 
Hive,SATD,//  UNDONE: Why do we need to specify BinarySortableSerDe explicitly here??? 
Hive,SATD,// todo: last param is bogus. why is this hardcoded? 
Hive,SATD,//  TODO: move this to a common method   Note: this gets IDs by name so we assume indices don't need to be adjusted for ACID. 
Hive,SATD,//  DecorrelateRexShuttle ends up decorrelating expressions cor.col1 <> $4   to $4=$4 if value generator is not generated $4<>$4 is further simplified   to false. This is wrong and messes up the whole tree. To prevent this visitCall   is overridden to rewrite/simply such predicates to is not null.   we also need to take care that we do this only for correlated predicates and   not user specified explicit predicates   TODO:  This code should be removed once CALCITE-1851 is fixed and   there is support of not equal 
Hive,SATD,//  TODO: need proper clone. Meanwhile let's at least keep this horror in one place 
Hive,SATD,//  Note that we pass job config to the record reader but use global config for LLAP IO.   TODO: add tracing to serde reader 
Hive,SATD,//  @deprecated in favour of {@link HCatPartition.#getTableName()}. To be removed in Hive 0.16. 
Hive,SATD,//  FIXME: support template types. It currently has conflict with ExprNodeConstantDesc 
Hive,SATD,/*  * This rule is a copy of {@link org.apache.calcite.rel.rules.AggregateReduceFunctionsRule} * that regenerates Hive specific aggregate operators. * * TODO: When CALCITE-2216 is completed we should be able to remove much of this code and * just override the relevant methods. * * Planner rule that reduces aggregate functions in * {@link org.apache.calcite.rel.core.Aggregate}s to simpler forms. * * <p>Rewrites: * <ul> * * <li>AVG(x) &rarr; SUM(x) / COUNT(x) * * <li>STDDEV_POP(x) &rarr; SQRT( *     (SUM(x * x) - SUM(x) * SUM(x) / COUNT(x)) *    / COUNT(x)) * * <li>STDDEV_SAMP(x) &rarr; SQRT( *     (SUM(x * x) - SUM(x) * SUM(x) / COUNT(x)) *     / CASE COUNT(x) WHEN 1 THEN NULL ELSE COUNT(x) - 1 END) * * <li>VAR_POP(x) &rarr; (SUM(x * x) - SUM(x) * SUM(x) / COUNT(x)) *     / COUNT(x) * * <li>VAR_SAMP(x) &rarr; (SUM(x * x) - SUM(x) * SUM(x) / COUNT(x)) *        / CASE COUNT(x) WHEN 1 THEN NULL ELSE COUNT(x) - 1 END * </ul>  */
Hive,SATD,//  TODO: Handle more than 2 inputs for setop 
Hive,SATD,//  TODO: separate model is needed for compressedOops which can be guessed from memory size. 
Hive,SATD,// TODO: Should we convert MultiJoin to be a child of HiveJoin 
Hive,SATD,//  TODO should be doing security check here.  Users should not be   able to see each other's locks. 
Hive,SATD,//  We do no handle anything but OK for now. Again we need a real client for this API.   TODO: handle 401 and return a new connection? nothing for now 
Hive,SATD,//  TODO: close basically resets the object to a bunch of nulls.         We should ideally not reuse the object because it's pointless and error-prone. 
Hive,SATD,// todo: createOptionsForReader() assumes it's !isOriginal.... why? 
Hive,SATD,//  TODO: Required due to SessionState.getHDFSSessionPath. Why wasn't it required before? 
Hive,SATD,//  TODO Change this to not serialize the entire Configuration - minor. 
Hive,SATD,//  TODO: For object inspector fields assigning 16KB for now. To better estimate the memory size every   object inspectors have to implement MemoryEstimate interface which is a lot of change with little benefit compared 
Hive,SATD,//  UNDONE: Add support for DATE TIMESTAMP INTERVAL_YEAR_MONTH INTERVAL_DAY_TIME... 
Hive,SATD,//  TODO: there was code here to create guess-estimate for collection wrt how usage changes   when removing elements. However it's too error-prone for anything involving   pre-allocated capacity so it was discarded. 
Hive,SATD,//  Extract the buckedID from pathFilesMap this is more accurate method   however. it may not work in certain cases where buckets are named   after files used while loading data. In such case fallback to old   potential inaccurate method.   The accepted file names are such as 000000_0 000001_0_copy_1. 
Hive,SATD,//  This is a bit hackish to fix mismatch between SARG and Hive types   for Timestamp and Date. TODO: Move those types to storage-api. 
Hive,SATD,//  TODO HIVE-14042. Move to using a loop and a timed wait once TEZ-3302 is fixed. 
Hive,SATD,//  TODO: add a configurable option to skip the history and just drop it? 
Hive,SATD,//  TODO: refactor this into an utility LLAP tests use this pattern a lot 
Hive,SATD,//  TODO: make aliases unique otherwise needless rewriting takes place 
Hive,SATD,/*    * Derive additional attributes to be rendered by EXPLAIN.   * TODO: this method is relied upon by custom input formats to set jobconf properties.   *       This is madness? - This is Hive Storage Handlers!    */
Hive,SATD,/*    * Connects to the {@link IMetaStoreClient meta store} that will be used to manage {@link Transaction} life-cycles.   * Also checks that the tables destined to receive mutation events are able to do so. The client should only hold one   * open transaction at any given time (TODO: enforce this).    */
Hive,SATD,//  TODO: this should have an option for directory to inherit from the parent table         including bucketing and list bucketing for the use in compaction when the         latter runs inside a transaction. 
Hive,SATD,//  UNDONE: Parameterize for implementation variation? 
Hive,SATD,//  TODO: ifExists could be moved to metastore. In fact it already supports that. Check it         for now since we get parts for output anyway so we can get the error message         earlier... If we get rid of output we can get rid of this. 
Hive,SATD,//  FIXME: moved default value to here...for now   i think this features is never really used from the command line 
Hive,SATD,//  TODO : Should be moved out. 
Hive,SATD,//  TODO - types need to be checked. 
Hive,SATD,//  TODO: handle multi joins 
Hive,SATD,//  TODO: ugly hack because Java doesn't have dtors and Tez input hangs on shutdown. 
Hive,SATD,//  TODO: Make script output prefixing configurable. Had to disable this since   it results in lots of test diffs. 
Hive,SATD,//  TODO: also support fileKey in splits like OrcSplit does 
Hive,SATD,//  TODO: when txn stats are implemented use writeIds to determine stats accuracy 
Hive,SATD,//  Hive is pretty simple (read: stupid) in writing out values via the serializer.   We're just going to go through matching indices.  Hive formats normally   handle mismatches with null.  We don't have that option so instead we'll   end up throwing an exception for invalid records. 
Hive,SATD,//  TODO handle negations 
Hive,SATD,//  TODO: handle task to container map events in case of hard failures 
Hive,SATD,// TODO: partition names in getPartitionsByNames are not case insensitive 
Hive,SATD,//  todo this should be configured in serde 
Hive,SATD,//  TODO: Have to put in the support for AS clause 
Hive,SATD,//  Ideally we should use HiveRelNode convention. However since Volcano planner   throws in that case because DruidQuery does not implement the interface   we set it as Bindable. Currently we do not use convention in Hive hence that   should be fine.   TODO: If we want to make use of convention (e.g. while directly generating operator   tree instead of AST) this should be changed. 
Hive,SATD,// Call getSplit on the InputFormat create an HCatSplit for each  underlying split. When the desired number of input splits is missing  use a default number (denoted by zero).  TODO(malewicz): Currently each partition is split independently into  a desired number. However we want the union of all partitions to be  split into a desired number while maintaining balanced sizes of input 
Hive,SATD,//  TODO: do we need to handle the "this is what MySQL does" here? 
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#bucketCols(List<FieldSchema>) and HCatTable.#numBuckets(int)}.   To be removed in Hive 0.16. 
Hive,SATD,//  TODO Watches on the output dirs need to be cancelled at some point. For now - via the expiry. 
Hive,SATD,/*          * TODO: Use the hard link feature of hdfs         * once https://issues.apache.org/jira/browse/HDFS-3370 is done          */
Hive,SATD,//  TODO: allow >1 port per host? 
Hive,SATD,//  NOTE: This is for generating the internal path name for partitions. Users   should always use the MetaStore API to get the path name for a partition.   Users should not directly take partition values and turn it into a path   name by themselves because the logic below may change in the future.     In the future it's OK to add new chars to the escape list and old data   won't be corrupt because the full path name in metastore is stored.   In that case Hive will continue to read the old data but when it creates   new partitions it will use new names.   edit : There are some use cases for which adding new chars does not seem   to be backward compatible - Eg. if partition was created with name having   a special char that you want to start escaping and then you try dropping   the partition with a hive version that now escapes the special char using   the list below then the drop partition fails to work. 
Hive,SATD,//  TODO can we be more precise than stringstring? 
Hive,SATD,//  TODO: this is wrong; this test sets up dummy txn manager and so it cannot create ACID tables.         If I change it to use proper txn manager the setup for some tests hangs.         This used to work by accident now this works due a test flag. The test needs to be fixed.   Create table 
Hive,SATD,//  TODO - currently no way to test alter partition as HCatClient doesn't support it. 
Hive,SATD,//  Note - some of these scenarios could be handled but they are not supported right now.   The reason is that we bind a query to app/user using the signed token information and   we don't want to bother figuring out which one to use in case of ambiguity w/o a use case.   Ambiguous user.   Ambiguous user.   Ambiguous user.   Ambiguous app. 
Hive,SATD,//  only support bulkload when a hfile.family.path has been specified.   TODO: support detecting cf's from column mapping   TODO: support loading into multiple CF's at a time 
Hive,SATD,//  TODO Why is this changed from the default in hive-conf? 
Hive,SATD,//  TODO: need to set catalog parameter 
Hive,SATD,//  TODO: Should have a check on the server side. Embedded metastore throws   NullPointerException remote throws TTransportException 
Hive,SATD,//  TODO: this will probably send a message to AM. Is that needed here? 
Hive,SATD,//  There's full hash code stored in front of the key. We could check that first. If keyLength   is <= 4 it obviously doesn't make sense less bytes to check in a key. Then if there's a   match we check it in vain. But what is the proportion of matches? For writes it could be 0   if all keys are unique for reads we hope it's really high. Then if there's a mismatch what   probability is there that key mismatches in <4 bytes (so just checking the key is faster)? 
Hive,SATD,/*    * Given a RexCall & TableScan find max no of nulls. Currently it picks the   * col with max no of nulls.   *    * TODO: improve this   *    * @param call   * @param t   * @return    */
Hive,SATD,//  NOTE: BeeLineOpts uses Reflector in an extensive way to call getters and setters on itself   If you want to add any getters or setters to this class but not have it interfere with   saved variables in beeline.properties careful use of this marker is needed.   Also possible to get this by naming these functions obtainBlah instead of getBlah   and so on but that is not explicit and will likely surprise people looking at the   code in the future. Better to be explicit in intent. 
Hive,SATD,//  TODO: should this be currentDirs? 
Hive,SATD,//  TODO What else is required in this environment map. 
Hive,SATD,//  FIXME: HIVE-18703 should probably move this method somewhere else 
Hive,SATD,// TODO these bytes should be versioned 
Hive,SATD,// TODO 1.0 miniCluster is slow this test times out make it work 
Hive,SATD,/*    * Send dropped table notifications. Subscribers can receive these notifications for   * dropped tables by listening on topic "HCAT" with message selector string   * {@value org.apache.hive.hcatalog.common.HCatConstants#HCAT_EVENT} =   * {@value org.apache.hive.hcatalog.common.HCatConstants#HCAT_DROP_TABLE_EVENT}   * </br>   * TODO: DataNucleus 2.0.3 currently used by the HiveMetaStore for persistence has been   * found to throw NPE when serializing objects that contain null. For this reason we override   * some fields in the StorageDescriptor of this notification. This should be fixed after   * HIVE-2084 "Upgrade datanucleus from 2.0.3 to 3.0.1" is resolved.    */
Hive,SATD,/*  * This utility is designed to help with upgrading to Hive 3.0.  On-disk layout for transactional * tables has changed in 3.0 and require pre-processing before upgrade to ensure they are readable * by Hive 3.0.  Some transactional tables (identified by this utility) require Major compaction * to be run on them before upgrading to 3.0.  Once this compaction starts no more * update/delete/merge statements may be executed on these tables until upgrade is finished. * * Additionally a new type of transactional tables was added in 3.0 - insert-only tables.  These * tables support ACID semantics and work with any Input/OutputFormat.  Any Managed tables may * be made insert-only transactional table. These tables don't support Update/Delete/Merge commands. * * This utility works in 2 modes: preUpgrade and postUpgrade. * In preUpgrade mode it has to have 2.x Hive jars on the classpath.  It will perform analysis on * existing transactional tables determine which require compaction and generate a set of SQL * commands to launch all of these compactions. * * Note that depending on the number of tables/partitions and amount of data in them compactions * may take a significant amount of time and resources.  The script output by this utility includes * some heuristics that may help estimate the time required.  If no script is produced no action * is needed.  For compactions to run an instance of standalone Hive Metastore must be running. * Please make sure hive.compactor.worker.threads is sufficiently high - this specifies the limit * of concurrent compactions that may be run.  Each compaction job is a Map-Reduce job. * hive.compactor.job.queue may be used to set a Yarn queue ame where all compaction jobs will be * submitted. * * In postUpgrade mode Hive 3.0 jars/hive-site.xml should be on the classpath. This utility will * find all the tables that may be made transactional (with ful CRUD support) and generate * Alter Table commands to do so.  It will also find all tables that may not support full CRUD * but can be made insert-only transactional tables and generate corresponding Alter Table commands. * * TODO: rename files * * "execute" option may be supplied in both modes to have the utility automatically execute the * equivalent of the generated commands * * "location" option may be supplied followed by a path to set the location for the generated * scripts.  */
Hive,SATD,//  srcs = new FileStatus[0]; Why is this needed? 
Hive,SATD,//  TODO: should probably throw an exception here. 
Hive,SATD,//  2. Convert Agg Fn args and type of args to Calcite   TODO: Does HQL allows expressions as aggregate args or can it only be 
Hive,SATD,//  TODO: note that the token is not renewable right now and will last for 2 weeks by default. 
Hive,SATD,//  TODO: Should this be also TOP_DOWN? 
Hive,SATD,/*  * TODO: Most of the code in this class is ripped from ZooKeeper tests. Instead * of redoing it we should contribute updates to their code which let us more * easily access testing helper objects. * *XXX: copied from the only used class by qtestutil from hbase-tests  */
Hive,SATD,//  If it's constant = constant or column = column we can't fetch any ranges   TODO We can try to be smarter and push up the value to some node which 
Hive,SATD,//  TODO: Implement propConstDistUDAFParams 
Hive,SATD,//  TODO: implement implicit AsyncRDDActions conversion instead of jc.monitor()?   TODO: how to handle stage failures? 
Hive,SATD,//  TODO: should we check isAssignableFrom? 
Hive,SATD,//  For replication add-ptns we need to follow a insert-if-not-exist alter-if-exists scenario.   TODO : ideally we should push this mechanism to the metastore because otherwise we have   no choice but to iterate over the partitions here. 
Hive,SATD,//  TODO: should we create the batch from vrbctx and reuse the vectors like below? Future work. 
Hive,SATD,//  this is a hacky way of doing the quotes since it will match any 2 of   these so   "[ hello this is something to split [" would be considered to be quoted. 
Hive,SATD,//  TODO: Do the type checking of the expressions 
Hive,SATD,//  Make a tree out of the filter.   TODO: this is all pretty ugly. The only reason we need all these transformations         is to maintain support for simple filters for HCat users that query metastore.         If forcing everyone to use thick client is out of the question maybe we could         parse the filter into standard hive expressions and not all this separate tree 
Hive,SATD,//  Not safe to continue for RS-GBY-GBY-LIM kind of pipelines. See HIVE-10607 for more. 
Hive,SATD,//  Hack for tables with no columns   Treat it as a table with a single column called "col" 
Hive,SATD,//  TODO: if we expect one dir why don't we enforce it? 
Hive,SATD,//  Post serialization separators are automatically inserted between different fields in the   struct. Currently there is not way to disable that. So the work around here is to pad the 
Hive,SATD,//  We only support limited unselected column following by order by.   TODO: support unselected columns in genericUDTF and windowing functions.   We examine the order by in this query block and adds in column needed   by order by in select list. 
Hive,SATD,//  TODO: if we want to be explicit about this dump not being a replication dump we can   uncomment this else section but currently unneeded. Will require a lot of golden file   regen if we do so. 
Hive,SATD,//  TODO: refactor this in HIVE-6366 
Hive,SATD,//  TODO: (a = 1) and NOT (a is NULL) can be potentially folded earlier into a NO-OP 
Hive,SATD,//  @todo: remove this. 8/28/14 hb   for now adding because RelOptUtil.classifyFilters has an assertion about   column counts that is not true for semiJoins. 
Hive,SATD,//  TODO: this seems to indicate that priorities change too little...         perhaps we need to adjust the policy. 
Hive,SATD,//  Note - we need srcFs rather than fs because it is possible that the _files lists files   which are from a different filesystem than the fs where the _files file itself was loaded   from. Currently it is possible for eg. to do REPL LOAD hdfs://<ip>/dir/ and for the _files   in it to contain hdfs://<name>/ entries and/or vice-versa and this causes errors.   It might also be possible that there will be a mix of them in a given _files file.   TODO: revisit close to the end of replv2 dev to see if our assumption now still holds   and if not so optimize. 
Hive,SATD,//  Note: with some trickery we could add logic for each type in ConfVars; for now the   potential spurious mismatches (e.g. 0 and 0.0 for float) should be easy to work around. 
Hive,SATD,//  FIXME: hiveServer2SiteUrl is not settable? 
Hive,SATD,//  The following check is only a guard against failures.   TODO: Knowing which expr is constant in GBY's aggregation function   arguments could be better done using Metadata provider of Calcite.  check the corresponding expression in exprs to see if it is literal 
Hive,SATD,//  TODO: Remove in Hive 0.16.   This is required only to support the deprecated HCatAddPartitionDesc.Builder interfaces. 
Hive,SATD,// TODO: if partitions are loaded lazily via the iterator then we will have to avoid conversion of everything here as it defeats the purpose. 
Hive,SATD,/*      * Figures out the aliases for whom it is safe to push predicates based on     * ANSI SQL semantics. The join conditions are left associative so "a     * RIGHT OUTER JOIN b LEFT OUTER JOIN c INNER JOIN d" is interpreted as     * "((a RIGHT OUTER JOIN b) LEFT OUTER JOIN c) INNER JOIN d".  For inner     * joins both the left and right join subexpressions are considered for     * pushing down aliases for the right outer join the right subexpression     * is considered and the left ignored and for the left outer join the     * left subexpression is considered and the left ignored. Here aliases b     * and d are eligible to be pushed up.     *     * TODO: further optimization opportunity for the case a.c1 = b.c1 and b.c2     * = c.c2 a and b are first joined and then the result with c. But the     * second join op currently treats a and b as separate aliases and thus     * disallowing predicate expr containing both tables a and b (such as a.c3     * + a.c4 > 20). Such predicates also can be pushed just above the second     * join and below the first join     *     * @param op     *          Join Operator     * @param rr     *          Row resolver     * @return set of qualified aliases      */
Hive,SATD,//  TODO: not stopping umbilical explicitly as some taskKill requests may get scheduled during queryComplete   which will be using the umbilical. HIVE-16021 should fix this until then leave umbilical open and wait for   it to be closed after max idle timeout (10s default) 
Hive,SATD,//  TODO [MM gap?]: by design; no-one seems to use LB tables. They will work but not convert.                   It's possible to work around this by re-creating and re-inserting the table. 
Hive,SATD,//  TODO: Should be moved out. 
Hive,SATD,//  TODO: I/O threadpool could be here - one thread per stripe; for now linear. 
Hive,SATD,//  Optionally do some filtering of rows...   UNDONE 
Hive,SATD,//  TODO: Should have a check on the server side. Embedded metastore throws   InvalidObjectException remote throws TApplicationException 
Hive,SATD,//  FIXME: Support pruning dynamic partitioning. 
Hive,SATD,//  FIXME: sideeffect will leave the last query set at the session level 
Hive,SATD,//  TODO: use faster non-sync inputstream 
Hive,SATD,//  TODO: should this rather use a threadlocal for NUMA affinity? 
Hive,SATD,// TODO: this object is created once to call one method and then immediately destroyed.  So it's basically just a roundabout way to pass arguments to a static method. Simplify? 
Hive,SATD,//  TODO:pc implement max 
Hive,SATD,//  TODO Make sure this method is eventually used to find the prep / batch scripts. 
Hive,SATD,/*      * This doesn't throw any exceptions because we don't want the Compaction to appear as failed     * if stats gathering fails since this prevents Cleaner from doing it's job and if there are     * multiple failures auto initiated compactions will stop which leads to problems that are     * much worse than stale stats.     *     * todo: longer term we should write something COMPACTION_QUEUE.CQ_META_INFO.  This is a binary     * field so need to figure out the msg format and how to surface it in SHOW COMPACTIONS etc      */
Hive,SATD,//  TODO: transitive dependencies warning? 
Hive,SATD,//  We are in HS2 get the token locally.   TODO: coordinator should be passed in; HIVE-13698. Must be initialized for now. 
Hive,SATD,//  TODO: Ideally AcidUtils class and various constants should be in common. 
Hive,SATD,//  HACK: We actually need BlockMissingException but that is not available 
Hive,SATD,//  TODO HIVE-14042. Handling of dummyOps and propagating abort information to them 
Hive,SATD,//  TODO This - at least for the session pool - will always be the hive user. How does doAs above this affect things ? 
Hive,SATD,//  TODO: this is currently broken. We need to set memory manager to a bogus implementation         to avoid problems with memory manager actually tracking the usage. 
Hive,SATD,//  TODO: for one-block case we could move notification for the last block out of the loop. 
Hive,SATD,//  TODO: figure out a better data structure for node list(?) 
Hive,SATD,// why isn't PPD working.... - it is working but storage layer doesn't do row level filtering; only row group level 
Hive,SATD,//  Note : Currently this implementation does not "fall back" to regular copy if distcp   is tried and it fails. We depend upon that behaviour in cases like replication   wherein if distcp fails there is good reason to not plod along with a trivial   implementation and fail instead. 
Hive,SATD,//  TODO: this is never used 
Hive,SATD,//  TODO: versions could also be picked at build time. 
Hive,SATD,//  A previous solution is based on tableAlias and colAlias which is   unsafe esp. when CBO generates derived table names. see HIVE-13602.   For correctness purpose we only trust colExpMap.   We assume that CBO can do the constantPropagation before this function is   called to help improve the performance.   UnionOperator LimitOperator and FilterOperator are special they should already be   column-position aligned.
Hive,SATD,//  Hack!! - refactor once the metadata APIs with types are ready 
Hive,SATD,//  TODO: if this cannot evict enough it will spin infinitely. Terminate at some point? 
Hive,SATD,//  but it is not OK to convert if the join is on (ac) 
Hive,SATD,//  TODO: ideally we should have a test for session itself. 
Hive,SATD,//  TODO : if needed verify that recordschema entry for fieldname matches appropriate type. 
Hive,SATD,//  FIXME: null value is treated differently on the other end..when those filter will be 
Hive,SATD,/*  * TODO:<br> * 1. Change the output col/ExprNodeColumn names to external names.<br> * 2. Verify if we need to use the "KEY."/"VALUE." in RS cols; switch to * external names if possible.<br> * 3. In ExprNode & in ColumnInfo the tableAlias/VirtualColumn is specified * differently for different GB/RS in pipeline. Remove the different treatments. * 4. VirtualColMap needs to be maintained *  */
Hive,SATD,//  Replace the entire current DiskRange with new cached range.   In case of an inexact match in either of the below it may throw. We do not currently   support the case where the caller requests a single cache buffer via multiple smaller   sub-ranges; if that happens this may throw. Noone does it now though.   TODO: should we actively assert here for cache buffers larger than range? 
Hive,SATD,//  TODO: Fill in when PARTITION_DONE_EVENT is supported. 
Hive,SATD,//  TODO For now this affects non broadcast unsorted cases as well. Make use of the edge   property when it's available. 
Hive,SATD,//  TODO: most other options are probably unrecoverable... throw? 
Hive,SATD,//  this is a temporary hack to fix things that are not fixed in the compiler 
Hive,SATD,//  Should be fixed in Accumulo 1.5.2 and 1.6.1 
Hive,SATD,//  This is hackery but having hive-common depend on standalone-metastore is really bad   because it will pull all of the metastore code into every module.  We need to check that   we aren't using the standalone metastore.  If we are we should treat it the same as a 
Hive,SATD,// todo: fix this - it has to run in 3.0 since tables may be unbucketed 
Hive,SATD,//  Not sure why this method doesn't throw any exceptions   but since the interface doesn't allow it we'll just swallow them and   move on.  This OK-ish since releaseLocks() is only called for RO/AC queries; it  would be really bad to eat exceptions here for write operations 
Hive,SATD,//  TODO: Implement this when tez is upgraded. TEZ-3550 
Hive,SATD,//  TODO: there should be a better way to do this code just needs to be modified 
Hive,SATD,//  TODO Session re-use completely disabled for doAs=true. Always launches a new session. 
Hive,SATD,//  TODO In case of a failure to heartbeat tasks for the specific DAG should ideally be KILLED 
Hive,SATD,//  TODO Check if all required tables are allowed if so get it from cache 
Hive,SATD,//  TODO: Only the qualified name should be left here 
Hive,SATD,//  FIXME: this is a secret contract; reusein getAggrKey() creates a more closer relation to the StatsGatherer 
Hive,SATD,//  Note: it's not quite clear why this is done inside this if. Seems like it should be on the top level. 
Hive,SATD,//  TODO: why is this synchronized? 
Hive,SATD,//  TODO: local cache is created once so the configs for future queries will not be honored. 
Hive,SATD,//  Support for dynamic partitions can be added later   The following is not optimized:   insert overwrite table T1(ds='1' hr) select key value hr from T2 where ds = '1';   where T1 and T2 are bucketed by the same keys and partitioned by ds. hr 
Hive,SATD,//  FIXME: using real scaling by new/old ration might yield better results? 
Hive,SATD,// todo: try this with acid default - it seem making table acid in listener is too late 
Hive,SATD,/*  * Context class for operator tree walker for partition pruner. * TODO: this class may be not useful.  */
Hive,SATD,//  Thrift cannot write read-only buffers... oh well.   TODO: actually thrift never writes to the buffer so we could use reflection to         unset the unnecessary read-only flag if allocation/copy perf becomes a problem. 
Hive,SATD,//  TODO should be replaced by CliServiceClient 
Hive,SATD,//  @deprecated in favour of {@link #Builder(HCatTable boolean)}. To be removed in Hive 0.16. 
Hive,SATD,//  TODO: Change ExprNodeConverter to be independent of Partition Expr 
Hive,SATD,//  We are not going to verify SD for each partition. Just verify for the table.   ToDo: we need verify the partition column instead 
Hive,SATD,// todo: ConditionalTask#addDependentTask(Task) doesn't do the right thing: HIVE-18978 
Hive,SATD,// TODO: Can columns retain virtualness out of union 
Hive,SATD,//  TODO: why do we invent our own error path op top of the one from Future.get? 
Hive,SATD,//  TODO is there a more correct way to get the literal value for the Object? 
Hive,SATD,/*  * todo: This need review re: thread safety.  Various places (see callsers of * {@link SessionState#setCurrentSessionState(SessionState)}) pass SessionState to forked threads. * Currently it looks like those threads only read metadata but this is fragile. * Also maps (in SessionState) where tempt table metadata is stored are concurrent and so * any put/get crosses a memory barrier and so does using most {@code java.util.concurrent.*} * so the readers of the objects in these maps should have the most recent view of the object. * But again could be fragile.  */
Hive,SATD,//  arguments then we can use a more efficient form. 
Hive,SATD,//  TODO: Something is preventing the process from terminating after main() adding exit() as hacky solution. 
Hive,SATD,//  TODO: write error to the channel? there's no mechanism for that now. 
Hive,SATD,//  TODO: reuse columnvector-s on hasBatch - save the array by column? take apart each list. 
Hive,SATD,//  todo: hold onto this predicate so that we don't add it to the Filter Operator. 
Hive,SATD,//  TODO Ideally remove elements from this once it's known that no tasks are linked to the instance (all deallocated) 
Hive,SATD,//  TODO: can we blindly copy sort trait? What if inputs changed and we   are now sorting by different cols 
Hive,SATD,//  TODO: This works different in remote and embedded mode.   In embedded mode no exception happens. 
Hive,SATD,//  UNDONE: Need to copy the object. 
Hive,SATD,//  did remove those and gave CBO the proper AST. That is kinda hacky. 
Hive,SATD,//  FIXME: consider other operator info as well..not just conf? 
Hive,SATD,//  check # of dp   TODO: add an option to skip this if number of partitions checks is done by Triggers via   CREATED_DYNAMIC_PARTITION counter 
Hive,SATD,/*  vertex is started but not complete  */
Hive,SATD,//  TODO: need the description of how these maps are kept consistent. 
Hive,SATD,//  UNDONE: Need to copy the object? 
Hive,SATD,//  TODO filter->expr   TODO functionCache   TODO constraintCache   TODO need sd nested copy?   TODO String intern   TODO monitor event queue   TODO initial load slow?   TODO size estimation 
Hive,SATD,//  TODO not 100% sure about this.  This call doesn't set the compression type in the conf   file the way getHiveRecordWriter does as ORC appears to read the value for itself.  Not   sure if this is correct or not. 
Hive,SATD,/*    * TODO : Refactor   *   * There is an upcoming patch that refactors this bit of code. Currently the idea is the following:   *   * By default ReplCopyWork will behave similarly to CopyWork and simply copy   * along data from the source to destination.   * If the flag readSrcAsFilesList is set changes the source behaviour of this CopyTask and   * instead of copying explicit files this will then fall back to a behaviour wherein an _files is   * read from the source and the files specified by the _files are then copied to the destination.   *   * This allows us a lazy-copy-on-source and a pull-from destination semantic that we want   * to use from replication.    */
Hive,SATD,/*  A scratch variable is created here. This could be optimized in the future     * by perhaps using thread-local storage to allocate this scratch field.      */
Hive,SATD,//  Ideally there should be a better way to determine that the followingWork contains   a dynamic partitioned hash join but in some cases (createReduceWork()) it looks like   the work must be created/connected first before the GenTezProcContext can be updated   with the mapjoin/work relationship. 
Hive,SATD,// Future thought: this may be expensive so consider having a thread pool run in parallel 
Hive,SATD,/*      * Number of rows processed between checks for minReductionHashAggr factor     * TODO: there is overlap between numRowsCompareHashAggr and checkInterval      */
Hive,SATD,//  TODO: LlapNodeId is just a host+port pair; we could make this class more generic. 
Hive,SATD,//  Note: we assume here that plan has been validated beforehand so we don't verify 
Hive,SATD,//  Implement in future if needed. 
Hive,SATD,//  TODO: move this into ctor? EW would need to create CacheWriter then 
Hive,SATD,//  After SPARK-2321 we only use JobMetricsListener to get job metrics   TODO: remove it when the new API provides equivalent functionality 
Hive,SATD,//  TODO: could we do this only if the OF is actually used? 
Hive,SATD,//  TODO: we may add app name etc. later 
Hive,SATD,//  TODO no fk across catalogs 
Hive,SATD,//  TODO: This does not work because materialized views need the creation metadata   to be updated in case tables used were replicated to a different database.  run("CREATE MATERIALIZED VIEW " + dbName + ".mat_view AS SELECT a FROM " + dbName + ".ptned where b=1" driver);  verifySetup("SELECT a from " + dbName + ".mat_view" ptn_data_1 driver); 
Hive,SATD,//  FIXME: oss seems to contain duplicates 
Hive,SATD,//  TODO: danger of stack overflow... needs a retry limit? 
Hive,SATD,//  Cannot drop db1 because mv1 uses one of its tables   TODO: Error message coming from metastore is currently not very concise   (foreign key violation) we should make it easily understandable 
Hive,SATD,//  TODO: ideally QueryTracker should have fragment-to-query mapping. 
Hive,SATD,//  TODO: WTF? The old code seems to just drop the ball here. 
Hive,SATD,//  Hack to initialize cache with 0 expiry time causing it to return a new hive client every time   Otherwise the cache doesn't play well with the second test method with the client gets closed() in the   tearDown() of the previous test 
Hive,SATD,//  @deprecated in favour of {@link HCatPartition.#getLocation()}. To be removed in Hive 0.16. 
Hive,SATD,//  TODO HIVE-12449. Make use of progress notifications once Hive starts sending them out.   progressNotified = task.getAndClearProgressNotification(); 
Hive,SATD,//  TODO Evil!  Need to figure out a way to remove this sleep. 
Hive,SATD,//  TODO: all the extrapolation logic should be moved out of this class 
Hive,SATD,//  FIXME: this add seems suspicious...10 lines below the value returned by this method used as betterDS 
Hive,SATD,//  this is a hack for now to handle the group by case 
Hive,SATD,//  All other distinct keys will just be forwarded. This could be optimized... 
Hive,SATD,//  This is a workaround for DERBY-6358 and Oracle bug; it is pretty horrible. 
Hive,SATD,// @TODO This is fetching all the rows at once from broker or multiple historical nodes   Move to use scan query to avoid GC back pressure on the nodes 
Hive,SATD,// todo: strictly speaking there is a bug here.  heartbeat*() commits but both heartbeat and  checkLock() are in the same retry block so if checkLock() throws heartbeat is also retired 
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#partCols(List<FieldSchema>)}. To be removed in Hive 0.16. 
Hive,SATD,//  Wow something's really wrong. 
Hive,SATD,//  UNDONE: Does this random range need to go as high as 38? 
Hive,SATD,//  TODO : Java 1.7+ support using String with switches but IDEs don't all seem to know that.   If casing is fine for now. But we should eventually remove this. Also I didn't want to   create another enum just for this. 
Hive,SATD,//  We have found an invalid decimal value while enforcing precision and   scale. Ideally   we would replace it with null here which is what Hive does. However   we need to plumb   this thru up somehow because otherwise having different expression   type in AST causes   the plan generation to fail after CBO probably due to some residual   state in SA/QB.   For now we will not run CBO in the presence of invalid decimal 
Hive,SATD,//  Code initially inspired by Google ObjectExplorer.   TODO: roll in the direct-only estimators from fields. Various other optimizations possible. 
Hive,SATD,//  Dirty hack as this will throw away spaces and other things - find a better 
Hive,SATD,//  TODO: should local cache also be by fileId? Preserve the original logic for now. 
Hive,SATD,//  TODO: do we need to get to child? 
Hive,SATD,//  TODO: refactor with cache impl? it has the same merge logic 
Hive,SATD,/*    * Dirty hack to set the environment variables using reflection code. This method is for testing   * purposes only and should not be used elsewhere    */
Hive,SATD,//  TODO: Decorelation of subquery should be done before attempting   Partition Pruning; otherwise Expression evaluation may try to execute   corelated sub query. 
Hive,SATD,/*    * TODO: 1) isSamplingPred 2) sampleDesc 3) isSortedFilter    */
Hive,SATD,// @TODO it will be nice to refactor it 
Hive,SATD,// todo: this should not throw  todo: this should take "comment" as parameter to set in CC_META_INFO to provide some context for the failure 
Hive,SATD,//  TODO: replace this with a Map? 
Hive,SATD,//  TODO: remove some of these fields as needed? 
Hive,SATD,//  TODO: this is not valid. Function names for built-in UDFs are specified in   FunctionRegistry and only happen to match annotations. For user UDFs the   name is what user specifies at creation time (annotation can be absent 
Hive,SATD,//  TODO: verify that this is correct 
Hive,SATD,//  TODO: we could try to get the declaring object and infer argument... stupid Java. 
Hive,SATD,//  close&destroy is used in seq coupling most of the time - the difference is either not clear; or not relevant - remove? 
Hive,SATD,// todo: this doesn;t check if compaction is already running (even though Initiator does but we 
Hive,SATD,//  This is a little bit weird. We'll do the MS call outside of the lock. Our caller calls us   under lock so we'd preserve the lock state for them; their finally block will release the 
Hive,SATD,// todo: we really need some comments to explain exactly why each of these is removed 
Hive,SATD,//  ### FIXME: this is broken for multi-line SQL 
Hive,SATD,// Not implemented 
Hive,SATD,//  Slice boundaries may not match split boundaries due to torn rows in either direction   so this counter may not be consistent with splits. This is also why we increment   requested bytes here instead of based on the split - we don't want the metrics to be   inconsistent with each other. No matter what we determine here at least we'll account   for both in the same manner. 
Hive,SATD,//  This is kinda hacky - we "know" these are LlaSerDeDataBuffer-s. 
Hive,SATD,//  TODO: perhaps can be made more efficient by creating a byte[] directly 
Hive,SATD,// this is not strictly accurate but 'type' cannot be null. 
Hive,SATD,//  TODO: for non columnar we don't need to do this... might as well update all stats. 
Hive,SATD,//  TODO: this should ideally not create AddPartitionDesc per partition 
Hive,SATD,//  TODO: should we also whitelist input formats here? from mapred.input.format.class 
Hive,SATD,//  Not public since we must have the deserialize read object. 
Hive,SATD,//  TODO: checking 2 children is useless compare already does that. 
Hive,SATD,//  TODO: why does the original code not just use _dataStream that it passes in as stream? 
Hive,SATD,//  This is a bogus hack because it copies the contents of the SQL file   intended for creating derby databases and thus will inexorably get   out of date with it.  I'm open to any suggestions on how to make this   read the file in a build friendly way. 
Hive,SATD,//  This if/else chain looks ugly in the inner loop but given that it will be 100% the same   for a given operator branch prediction should work quite nicely on it.   RecordUpdateer expects to get the actual row not a serialized version of it.  Thus we 
Hive,SATD,// TODO this has to find a better home it's also hardcoded as default in hive would be nice 
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#sortCols(ArrayList<Order>)}. To be removed in Hive 0.16. 
Hive,SATD,//  TODO? add upstream? 
Hive,SATD,//  TODO: Should have a check on the server side. Embedded metastore throws   NullPointerException remote throws MetaException 
Hive,SATD,//  load the list of DP partitions and return the list of partition specs   TODO: In a follow-up to HIVE-1361 we should refactor loadDynamicPartitions   to use Utilities.getFullDPSpecs() to get the list of full partSpecs.   After that check the number of DPs created to not exceed the limit and   iterate over it and call loadPartition() here.   The reason we don't do inside HIVE-1361 is the latter is large and we 
Hive,SATD,//  There are 3 options for this ConditionalTask:   1) Merge the partitions   2) Move the partitions (i.e. don't merge the partitions)   3) Merge some partitions and move other partitions (i.e. merge some partitions and don't   merge others) in this case the merge is done first followed by the move to prevent   conflicts.   TODO: if we are not dealing with concatenate DDL we should not create a merge+move path 
Hive,SATD,/*    * TODO: this would be more flexible doing a SQL select statement rather than using InputFormat directly   * see {@link org.apache.hive.hcatalog.streaming.TestStreaming#checkDataWritten2(Path long long int String String...)}   * @param numSplitsExpected   * @return   * @throws Exception    */
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#getDbName()}. To be removed in Hive 0.16. 
Hive,SATD,//  TODO HIVE-16134. Differentiate between EXTERNAL_PREEMPTION_WAITQUEU vs EXTERNAL_PREEMPTION_FINISHABLE? 
Hive,SATD,//  TODO: pointless 
Hive,SATD,//  This is kind of not pretty but this is how we detect whether buffer was cached.   We would always set this for lookups at put time. 
Hive,SATD,//  TODO: move these test parameters to more specific places... there's no need to have them here 
Hive,SATD,//  TODO: fs checksum only available on hdfs need to         find a solution for other fs (eg local fs s3 etc) 
Hive,SATD,//  FIXME: possible alternative: move both OpSignature/OpTreeSignature into   under some class as nested ones; and that way this factory level caching can be made "transparent" 
Hive,SATD,//  Neither "expired" nor "olderThan" criteria selected. This better not be an attempt to delete tokens. 
Hive,SATD,//  FIXME: Hadoop3 made the incompatible change for dfs.client.datanode-restart.timeout   while spark2 is still using Hadoop2.   Spark requires Hive to support Hadoop3 first then Spark can start   working on Hadoop3 support. Remove this after Spark supports Hadoop3. 
Hive,SATD,/*    * Variables used by LLAP daemons.   * TODO: Eventually auto-populate this based on prefixes. The conf variables   * will need to be renamed for this.    */
Hive,SATD,//  TODO: setFileMetadata could just create schema. Called in two places; clean up later. 
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#comment()}. To be removed in Hive 0.16. 
Hive,SATD,//  this is workaround for hadoop-17 - libjars are not added to classpath of the 
Hive,SATD,/* todo: we need some sort of validation phase over original AST to make things user friendly; for example if     original command refers to a column that doesn't exist this will be caught when processing the rewritten query but     the errors will point at locations that the user can't map to anything     - VALUES clause must have the same number of values as target table (including partition cols).  Part cols go last in Select clause of Insert as Select     todo: do we care to preserve comments in original SQL?     todo: check if identifiers are propertly escaped/quoted in the generated SQL - it's currently inconsistent      Look at UnparseTranslator.addIdentifierTranslation() - it does unescape + unparse...     todo: consider "WHEN NOT MATCHED BY SOURCE THEN UPDATE SET TargetTable.Col1 = SourceTable.Col1 "; what happens when source is empty?  This should be a runtime error - maybe not      the outer side of ROJ is empty => the join produces 0 rows.  If supporting WHEN NOT MATCHED BY SOURCE then this should be a runtime error     */
Hive,SATD,//  TODO: wtf? This doesn't do anything. 
Hive,SATD,//  TODO: why is this needed? 
Hive,SATD,/*  * NOTE: this whole logic is replicated from Calcite's RelDecorrelator *  and is exteneded to make it suitable for HIVE *    We should get rid of this and replace it with Calcite's RelDecorrelator *    once that works with Join Project etc instead of Join Project. *    At this point this has differed from Calcite's version significantly so cannot *    get rid of this. * * RelDecorrelator replaces all correlated expressions (corExp) in a relational * expression (RelNode) tree with non-correlated expressions that are produced * from joining the RelNode that produces the corExp with the RelNode that * references it. * * <p>TODO:</p> * <ul> *   <li>replace {@code CorelMap} constructor parameter with a RelNode *   <li>make {@link #currentRel} immutable (would require a fresh *      RelDecorrelator for each node being decorrelated)</li> *   <li>make fields of {@code CorelMap} immutable</li> *   <li>make sub-class rules static and have them create their own *   de-correlator</li> * </ul>  */
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#serdeParam(Map<String String>)}.   To be removed in Hive 0.16. 
Hive,SATD,//  CONCERN: Leaking scratch column? 
Hive,SATD,//  TODO: this is an ugly hack; see the same in LlapTaskCommunicator for discussion. 
Hive,SATD,//  Derby and Oracle do not interpret filters ANSI-properly in some cases and need a workaround. 
Hive,SATD,//  TODO : currently not testing the following scenarios:     a) Multi-db wh-level REPL LOAD - need to add that     b) Insert into tables - quite a few cases need to be enumerated there including dyn adds. 
Hive,SATD,/*    * TODO: 1. PPD needs to get pushed in to TS   *   * @param scanRel   * @return    */
Hive,SATD,//  2. Convert NONACIDORCTBL to ACID table.  //todo: remove trans_prop after HIVE-17089 
Hive,SATD,//  FIXME: possibly the distinction between table/partition is not need; however it was like this before....will change it later 
Hive,SATD,//  don't take directories into account for quick stats TODO: wtf? 
Hive,SATD,/*    * Fixup the children and parents of a new vector child.   *   * 1) Add new vector child to the vector parent's children list.   *   * 2) Copy and fixup the parent list of the original child instead of just assuming a 1:1   *    relationship.   *   *    a) When the child is MapJoinOperator it will have an extra parent HashTableDummyOperator   *       for the MapJoinOperator's small table.  It needs to be fixed up too.    */
Hive,SATD,//  TODO: The copy of data is unnecessary but there is no work-around 
Hive,SATD,/*    * Get the list of partitions that need to update statistics.   * TODO: we should reuse the Partitions generated at compile time   * since getting the list of partitions is quite expensive.   *   * @return a list of partitions that need to update statistics.   * @throws HiveException    */
Hive,SATD,//  TODO: This test should be removed once ACID tables replication is supported. 
Hive,SATD,//  TODO: there is no easy and reliable way to compute the memory used by the executor threads and on-heap cache. 
Hive,SATD,//  TODO: normally the result is not necessary; might make sense to pass false 
Hive,SATD,//  Remove new-alloc flag on first use. Full unlock after that would imply force-discarding   this buffer is acceptable. This is kind of an ugly compact between the cache and us. 
Hive,SATD,//  Only attempt to do this if cmd was successful.   FIXME: it would be probably better to move this to an after-execution 
Hive,SATD,//  TODO Cleanup pending tasks etc so that the next dag is not affected. 
Hive,SATD,//  TODO: does this include partition columns? 
Hive,SATD,//            work on BytesColumnVector output columns??? 
Hive,SATD,//  Two ReduceSinkOperators are correlated means that   they have same sorting columns (key columns) same partitioning columns   same sorting orders and no conflict on the numbers of reducers.   TODO: we should relax this condition   TODO: we need to handle aggregation functions with distinct keyword. In this case   distinct columns will be added to the key columns. 
Hive,SATD,//  FIXME: move TestJsonSerDe from hcat to serde2 
Hive,SATD,//  TODO Confirm this is safe 
Hive,SATD,//  TODO: execute errors like this currently don't return good error 
Hive,SATD,//  THIS IS NOT WORKING workaround is to set it as part of java opts -Duser.timezone="UTC" 
Hive,SATD,//  simply get the next day and go back half a day. This is not ideal but seems to work. 
Hive,SATD,//  TODO: maybe we should throw this as-is too. ThriftCLIService currently catches Exception         so the combination determines what would kill the HS2 executor thread. For now         let's only allow OOM to propagate. 
Hive,SATD,//  TODO May be possible to do finer grained locks. 
Hive,SATD,//  TODO: this check is somewhat bogus as the maxJvmMemory != Xmx parameters (see annotation in LlapServiceDriver) 
Hive,SATD,//  TODO: Check if maximum size compatible with AbsoluteKeyOffset.maxSize. 
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#escapeChar()}. 
Hive,SATD,//  If the sorted columns is a superset of bucketed columns store this fact.   It can be later used to   optimize some group-by queries. Note that the order does not matter as   long as it in the first 
Hive,SATD,//  FIXME : replace with hive copy once that is copied 
Hive,SATD,//  TODO: revisit the fence 
Hive,SATD,//  TODO: 1) How to handle collisions? 2) Should we be cloning ColumnInfo or not? 
Hive,SATD,//  Optimize the scenario when there are no grouping keys and no distinct - 2   map-reduce jobs are not needed 
Hive,SATD,//  Join key expression is likely some expression involving functions/operators so there   is no actual table column for this. But the ReduceSink operator should still have an   output column corresponding to this expression using the columnInternalName.   TODO: does tableAlias matter for this kind of expression? 
Hive,SATD,//  TODO: why does Tez API use "Object" for this? 
Hive,SATD,//  TODO: this log statement looks wrong 
Hive,SATD,//  Relying on a task succeeding to reset the exponent.   There's no notifications on whether a task gets accepted or not. That would be ideal to   reset this. 
Hive,SATD,//  We need to override these methods due to difference in nullability between Hive and   Calcite for the return types of the aggregation  (in particular for COUNT and SUM0).   TODO: We should close the semantics gaps between Hive and Calcite for nullability of   aggregation calls return types. This might be useful to trigger some additional   rewriting rules that would remove unnecessary predicates etc. 
Hive,SATD,//  Cancel job if the monitor found job submission timeout.   TODO: If the timeout is because of lack of resources in the cluster we should   ideally also cancel the app request here. But w/o facilities from Spark or YARN   it's difficult to do it on hive side alone. See HIVE-12650. 
Hive,SATD,//  TODO: Should be checked on server side. On Embedded metastore it throws   NullPointerException on Remote metastore it throws TTransportException 
Hive,SATD,//  TODO: do we ever need the port? we could just do away with nodeId altogether. 
Hive,SATD,/*    * Metastore related options that the db is initialized against. When a conf   * var in this is list is changed the metastore instance for the CLI will   * be recreated so that the change will take effect.   * TODO - I suspect the vast majority of these don't need to be here.  But it requires testing   * before just pulling them out.    */
Hive,SATD,//  Originals split won't work due to MAPREDUCE-7086 issue in FileInputFormat. 
Hive,SATD,//  TODO: VectorizedParquetRecordReader doesn't support map array now the value of   ColumnProjectionUtils.READ_COLUMN_IDS_CONF_STR should be updated after support these data   types. 
Hive,SATD,//  TODO: if there are more fields perhaps there should be an array of class. 
Hive,SATD,//  Some columns in select are pruned. This may happen if those are constants.   TODO: the best solution is to hook the operator before fs with the select operator.    See smb_mapjoin_20.q for more details.  
Hive,SATD,//  TODO: getUserFromAuthenticator? 
Hive,SATD,//  TODO: this seems wrong (following what Hive Regular does) 
Hive,SATD,//  TODO: we're asking the metastore what its configuration for this var is - we may   want to revisit to pull from client side instead. The reason I have it this way   is because the metastore is more likely to have a reasonable config for this than   an arbitrary client. 
Hive,SATD,//  TODO: can this result in cross-thread reuse of session state? 
Hive,SATD,//  This condition-check could have been avoided but to honour the old   default of not calling if it wasn't set we retain that behaviour.   TODO:cleanup after verification that the outer if isn't really needed here 
Hive,SATD,//  TODO support only non nested case 
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#mapKeysTerminatedBy()}. To be removed in Hive 0.16. 
Hive,SATD,//  TODO: get rid of this 
Hive,SATD,// todo: this is not remotely accurate if you have many (relevant) original files 
Hive,SATD,//  TODO: we could remove extra copy for isUncompressed case by copying directly to cache. 
Hive,SATD,//  TODO HIVE-11687 It's possible for a bunch of tasks to come in around the same time without the   actual executor threads picking up any work. This will lead to unnecessary rejection of tasks. 
Hive,SATD,//  conflict when loaded. Some issue with framework which needs to be relook into later. 
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#fileFormat()}. To be removed in Hive 0.16. 
Hive,SATD,//  dangerous; let's explicitly add an incomplete CB. 
Hive,SATD,//  This is not a complete list barely make information schema work 
Hive,SATD,//  TODO: perhaps we should also summarize the triggers pointing to invalid pools. 
Hive,SATD,//  TODO: could we instead get FS from path here and add normal files for every UGI? 
Hive,SATD,//  We cannot get to root TableScan operator likely because there is a join or group-by   between topOp and root TableScan operator. We don't handle that case and simply return 
Hive,SATD,//  REVIEW:  are we supposed to be applying the getReadColumnIDs 
Hive,SATD,/*    * todo: this should accept a file of table names to exclude from non-acid to acid conversion   * todo: change script comments to a preamble instead of a footer   *   * how does rename script work?  "hadoop fs -mv oldname newname"    * and what what about S3?   * How does this actually get executed?   * all other actions are done via embedded JDBC   *   *    */
Hive,SATD,//  TODO: the global lock might be to coarse here. 
Hive,SATD,// todo: enums? that have both field name and value list 
Hive,SATD,//  if the result is not boolean and not all partition agree on the   result we don't remove the condition. Potentially it can miss   the case like "where ds % 3 == 1 or ds % 3 == 2"   TODO: handle this case by making result vector to handle all   constant values. 
Hive,SATD,//  Need to remove this static hack. But this is the way currently to get a session. 
Hive,SATD,//  TODO : code section copied over from SerDeUtils because of non-standard json production there   should use quotes for all field names. We should fix this there and then remove this copy.   See http://jackson.codehaus.org/1.7.3/javadoc/org/codehaus/jackson/JsonParser.Feature.html#ALLOW_UNQUOTED_FIELD_NAMES   for details - trying to enable Jackson to ignore that doesn't seem to work(compilation failure   when attempting to use that feature so having to change the production itself. 
Hive,SATD,//  Assume we should have the exact same object.   TODO: we could also compare the schema and SerDe and pass only those to the call         instead; most of the time these would be the same and LLAP IO can handle that. 
Hive,SATD,// todo: HIVE-15549  SORT_PARTITION_EDGE 
Hive,SATD,//  TODO - Allow the branch to be specified as a parameter to ptest rather than requiring a separate property file. 
Hive,SATD,//  Note that the tableExists flag as used by Auth is kinda a hack and   assumes only 1 table will ever be imported - this assumption is broken by   REPL LOAD.     However we've not chosen to expand this to a map of tables/etc since   we have expanded how auth works with REPL DUMP / REPL LOAD to simply   require ADMIN privileges rather than checking each object which   quickly becomes untenable and even more so costly on memory. 
Hive,SATD,//  TODO Change after HIVE-9987. For now there's no rack matching. 
Hive,SATD,/*    * Only a small set of operations is allowed inside an explicit transactions e.g. DML on   * Acid tables or ops w/o persistent side effects like USE DATABASE SHOW TABLES etc so   * that rollback is meaningful   * todo: mark all operations appropriately    */
Hive,SATD,// todo: once multistatement txns are supported add a test to run next 2 statements in a single txn 
Hive,SATD,//  TODO HiveQueryId extraction by parsing the Processor payload is ugly. This can be improved   once TEZ-2672 is fixed. 
Hive,SATD,//  UNDONE: Why don't these methods take decimalPlaces? 
Hive,SATD,/*     * Serializes decimal64 up to the maximum 64-bit precision (18 decimal digits).    *    * NOTE: Major assumption: the fast decimal has already been bounds checked and a least    * has a precision <= DECIMAL64_DECIMAL_DIGITS.  We do not bounds check here for better    * performance.     */
Hive,SATD,//  TODO: Refactor this and do in a more object oriented manner 
Hive,SATD,//  Some data is missing from the stream for PPD uncompressed read (because index offset is   relative to the entire stream and we only read part of stream if RGs are filtered; unlike   with compressed data where PPD only filters CBs so we always get full CB and index offset   is relative to CB). To take care of the case when UncompressedStream goes seeking around by   its incorrect (relative to partial stream) index offset we will increase the length by our   offset-relative-to-the-stream and also account for it in buffers (see createDiskRangeInfo).   So index offset now works; as long as noone seeks into this data before the RG (why would   they) everything works. This is hacky... Stream shouldn't depend on having all the data. 
Hive,SATD,//  TODO HIVE-15865 Ideally sort these by completion time once that is available. 
Hive,SATD,/*    * Generate a temporary path for dynamic partition pruning in Spark branch   * TODO: no longer need this if we use accumulator!   * @param basePath   * @param id   * @return    */
Hive,SATD,//  TODO: probably temporary before HIVE-13698; after that we may create one per session. 
Hive,SATD,//  FIXME manager's EndOfBatch threadlocal can be deleted 
Hive,SATD,//  TODO: most of the time there's no in-memory. Use an array? 
Hive,SATD,//  TODO: could we tell the policy that we don't care about these and have them evicted? or we         could just deallocate them when unlocked and free memory + handle that in eviction.         For now just abandon the blocks - eventually they'll get evicted. 
Hive,SATD,//  A single concurrent request per node is currently hardcoded. The node includes a port number   so different AMs on the same host count as different nodes; we only have one request type   and it is not useful to send more than one in parallel. 
Hive,SATD,//  TODO MS-SPLIT Switch this back once HiveMetaStoreClient is moved.  req.setCapabilities(HiveMetaStoreClient.TEST_VERSION); 
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#getTableType()}. To be removed in Hive 0.16. 
Hive,SATD,//  Currently MAP type is not supported. Add it back when Arrow 1.0 is released. 
Hive,SATD,//  TODO: why CAS if the result is not checked? 
Hive,SATD,//  TODO: Shouldn't we propgate vc? is it vc col from tab or all vc 
Hive,SATD,//  TODO: readEncodedColumns is not supposed to throw; errors should be propagated thru   consumer. It is potentially holding locked buffers and must perform its own cleanup.   Also currently readEncodedColumns is not stoppable. The consumer will discard the   data it receives for one stripe. We could probably interrupt it if it checked that. 
Hive,SATD,//  REVIEW jvs 29-Oct-2007:  Shouldn't it also be incorporating   the flavor attribute into the description? 
Hive,SATD,//  Requirements: for Bucket bucketed by their keys on both sides and fitting in memory   Obtain number of buckets  TODO: Incase of non bucketed splits would be computed based on data size/max part size 
Hive,SATD,//  Note: later we may be able to set multiple things together (except LIKE). 
Hive,SATD,//  May be null in tests   TODO: see javadoc 
Hive,SATD,//  XXX: makes no sense for me... possibly not needed anymore 
Hive,SATD,//        So the indices should line up... to be fixed in SE v2? 
Hive,SATD,/*     * The method for altering table props; may set the table to MM non-MM or not affect MM.    * todo: All such validation logic should be TransactionValidationListener    * @param tbl object image before alter table command (or null if not retrieved yet).    * @param props prop values set in this alter table command     */
Hive,SATD,//  TODO : verify if skipping charset here is okay 
Hive,SATD,//  TODO: support dynamic partition for CTAS 
Hive,SATD,//  TODO :  Some extra validation can also be added as this is a user provided parameter. 
Hive,SATD,//  todo: add time of abort which is not currently tracked. 
Hive,SATD,//  TODO: dump the end if wrapping around? 
Hive,SATD,//  TODO: Currently ignores GBY and PTF which may also buffer data in memory. 
Hive,SATD,//  The queryId could either be picked up from the current request being processed or   generated. The current request isn't exactly correct since the query is 'done' once we   return the results. Generating a new one has the added benefit of working once this   is moved out of a UDTF into a proper API.   Setting this to the generated AppId which is unique.   Despite the differences in TaskSpec the vertex spec should be the same. 
Hive,SATD,//  Workaround for DN bug on Postgres:   http://www.datanucleus.org/servlet/forum/viewthread_thread7985_offset 
Hive,SATD,//  If necessary divide and multiply to get rid of fractional digits. 
Hive,SATD,// TODO: use common thread pool later? 
Hive,SATD,//  register all permanent functions. need improvement 
Hive,SATD,//  TODO: perhaps this could use a better implementation... for now even the Hive query result         set doesn't support this so assume the user knows what he's doing when calling us. 
Hive,SATD,//  This is our problem -- it means the configuration was wrong. 
Hive,SATD,//  to be used by clients of ServiceRegistry TODO: this is unnecessary 
Hive,SATD,//  TODO: should this also handle ACID operation etc.? seems to miss a lot of stuff from HIF. 
Hive,SATD,//  TODO Will these checks work if some other user logs in. Isn't a doAs check required somewhere here as well.   Should a doAs check happen here instead of after the user test.   With HiveServer2 - who is the incoming user in terms of UGI (the hive user itself or the user who actually submitted the query) 
Hive,SATD,//  TODO: get rid of deepCopy after making sure callers don't use references 
Hive,SATD,//  TODO: this is fishy - we init object inspectors based on first tag. We         should either init for each tag or if rowInspector doesn't really         matter then we can create this in ctor and get rid of firstRow. 
Hive,SATD,//  Snapshot was outdated when locks were acquired hence regenerate context   txn list and retry   TODO: Lock acquisition should be moved before analyze this is a bit hackish.   Currently we acquire a snapshot we compile the query wrt that snapshot   and then we acquire locks. If snapshot is still valid we continue as usual. 
Hive,SATD,//  TODO: option to allow converting ORC file to insert-only transactional? 
Hive,SATD,//  TODO: calculate this instead. Just because we're writing to the location doesn't mean that it'll   always be wanted in the meta store right away. 
Hive,SATD,//  TODO: propagate this error to TezJobMonitor somehow? Without using killQuery 
Hive,SATD,//  All users belong to public role implicitly add that role   TODO MS-SPLIT Change this back to HiveMetaStore.PUBLIC once HiveMetaStore has moved to   stand-alone metastore.  MRole publicRole = new MRole(HiveMetaStore.PUBLIC 0 HiveMetaStore.PUBLIC); 
Hive,SATD,/*    * Create a bare TableSnapshotRegionSplit. Needed because Writables require a   * default-constructed instance to hydrate from the DataInput.   *   * TODO: remove once HBASE-11555 is fixed.    */
Hive,SATD,//  TODO: do better with handling types of Exception here 
Hive,SATD,//  todo: returns json string. should recreate object from it? 
Hive,SATD,//  TODO: in these methods do we really need to deepcopy? 
Hive,SATD,//  TODO: numTasksToPreempt is currently always 1. 
Hive,SATD,//  TODO Optimization: Add a check to see if there's any capacity available. No point in 
Hive,SATD,//  Wait a while for existing tasks to terminate   XXX this will wait forever... :) 
Hive,SATD,//  todo replace below with joda-time which supports timezone 
Hive,SATD,//  TODO: why is this inconsistent with what we get by names? 
Hive,SATD,// Not implemented. 
Hive,SATD,// TODO this should be returning a class not just an int 
Hive,SATD,//  there are 2 or more distincts or distinct is not on count   TODO: may be the same count(distinct key) count(distinct key)   TODO: deal with duplicate count distinct key 
Hive,SATD,//  id - TODO: use a non-zero index to check for offset errors. 
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#comment(String)}. To be removed in Hive 0.16. 
Hive,SATD,//  TODO:pc need to enhance this with complex fields and getType_all function 
Hive,SATD,//  Hive adds the same mapping twice... I wish we could fix stuff like that. 
Hive,SATD,// todo: this should be moved to be an inner class of ReaderWrite as that is the only place it    is used 
Hive,SATD,//  HarFileSystem has a bug where this method does not work properly   if the underlying FS is HDFS. See MAPREDUCE-1877 for more   information. This method is from FileSystem. 
Hive,SATD,// TODO: Clean up/refactor assumptions 
Hive,SATD,//  TODO This executor seems unnecessary. Here and TezChild 
Hive,SATD,//  TODO: Verify GB having is not a seperate filter (if so we shouldn't   introduce derived table) 
Hive,SATD,/*  This is the TestPerformance Cli Driver for integrating performance regression tests as part of the Hive Unit tests. Currently this includes support for : 1. Running explain plans for TPCDS workload (non-partitioned dataset)  on 30TB scaleset. TODO : 1. Support for partitioned data set 2. Use HBase Metastore instead of DerbyThis suite differs from TestCliDriver w.r.t the fact that we modify the underlying metastoredatabase to reflect the dataset before running the queries. */
Hive,SATD,//  Hack note - different split strategies return differently typed lists yay Java.   This works purely by magic because we know which strategy produces which type. 
Hive,SATD,//  TODO: deriveExplainAttributes should be called here code is too fragile to move it around. 
Hive,SATD,/*  * Stores binary key/value in sorted manner to get top-n key/value * TODO: rename to TopNHeap?  */
Hive,SATD,//  FIXME: isNull is not updated; which might cause problems 
Hive,SATD,//  TODO: Should we use grpbyExprNDesc.getTypeInfo()? what if expr is   UDF 
Hive,SATD,//  TODO: we should really probably throw. Keep the existing logic for now. 
Hive,SATD,/*  * It's column level Parquet reader which is used to read a batch of records for a list column. * TODO Currently List type only support non nested case.  */
Hive,SATD,//  TODO: not clear why we don't do the rest of the cleanup if dagClient is not created.         E.g. jobClose will be called if we fail after dagClient creation but no before... 
Hive,SATD,// TODO HIVE-16862: Implement a similar feature like "hive.tez.dynamic.semijoin.reduction" in hive on spark 
Hive,SATD,//  TODO: Currently we do not expose any runtime info for non-streaming tables.   In future extend this add more information regarding table status.   e.g. Total size of segments in druid loadstatus of table on historical nodes etc. 
Hive,SATD,//  This is rather obscure. The end of last row cached is precisely at the split end offset.   If the split is in the middle of the file LRR would read one more row after that   therefore as unfortunate as it is we have to do a one-row read. However for that to   have happened someone should have supplied a split that ends inside the last row i.e.   a few bytes earlier than the current split which is pretty unlikely. What is more likely   is that the split and the last row both end at the end of file. Check for this. 
Hive,SATD,//  TODO: this should also happen on any error. Right now this task will just fail. 
Hive,SATD,//  TODO null can also mean that this operation was interrupted. Should we really try to re-create the session in that case ? 
Hive,SATD,//  TODO: Should we wait for the entry to actually be deleted from HDFS? Would have to   poll the reader count waiting for it to reach 0 at which point cleanup should occur. 
Hive,SATD,//  FIXME for ctas this is still needed because location is not set sometimes 
Hive,SATD,//  TODO Consolidate this code with TezChild. 
Hive,SATD,//  TODO: is this check even needed given what the caller checks? 
Hive,SATD,//  FIXME: file paths in strings should be changed to either File or Path ... anything but String 
Hive,SATD,//  TODO: why is "&& !isAcidIUDoperation" needed here? 
Hive,SATD,//  Get all simple fields for partitions and related objects which we can map one-on-one.   We will do this in 2 queries to use different existing indices for each one.   We do not get table and DB name assuming they are the same as we are using to filter.   TODO: We might want to tune the indexes instead. With current ones MySQL performs   poorly esp. with 'order by' w/o index on large tables even if the number of actual   results is small (query that returns 8 out of 32k partitions can go 4sec. to 0sec. by   just adding a \"PART_ID\" IN (...) filter that doesn't alter the results to it probably 
Hive,SATD,//  Tez session relies on a threadlocal for open... If we are on some non-session thread   just use the same SessionState we used for the initial sessions.   Technically given that all pool sessions are initially based on this state shoudln't   we also set this at all times and not rely on an external session stuff? We should   probably just get rid of the thread local usage in TezSessionState. 
Hive,SATD,//  hive input format doesn't handle the special condition of no paths + 1   split correctly. 
Hive,SATD,//     not external itself. Is that the case? Why? 
Hive,SATD,//  TODO: this is a stopgap fix. We really need to change all mappings by unique node ID         or at least (in this case) track the latest unique ID for LlapNode and retry all 
Hive,SATD,//  FIXME: druid storage handler relies on query.id to maintain some staging directories   expose queryid to session level 
Hive,SATD,//  TODO - we need to speed this up for the normal path where all partitions are under   the table and we don't have to stat every partition 
Hive,SATD,//  if this function is frequently used we need to optimize this. 
Hive,SATD,//  This is ugly in two ways...   1) We assume that LlapWrappableInputFormatInterface has NullWritable as first parameter.      Since we are using Java and not say a programming language there's no way to check.   2) We ignore the fact that 2nd arg is completely incompatible (VRB -> Writable) because      vectorization currently works by magic getting VRB from IF with non-VRB value param.   So we just cast blindly and hope for the best (which is obviously what happens). 
Hive,SATD,//  TODO: two possible improvements         1) Right now we kill all the queries here; we could just kill -qpDelta.         2) After the queries are killed queued queries would take their place.            If we could somehow restart queries we could instead put them at the front 
Hive,SATD,//  This method is inefficient. It's only used when something crosses buffer boundaries. 
Hive,SATD,//  TODO: why doesn't this check class name rather than toString? 
Hive,SATD,//  TODO: Modify Thrift IDL to generate export stage if needed 
Hive,SATD,//  Workaround for testing since tests can't set the env vars. 
Hive,SATD,//  TODO: the memory release could be optimized - we could release original buffers after we         are fully done with each original buffer from disk. For now release all at the end;         it doesn't increase the total amount of memory we hold just the duration a bit.         This is much simpler - we can just remember original ranges after reading them and         release them at the end. In a few cases where it's easy to determine that a buffer         can be freed in advance we remove it from the map. 
Hive,SATD,//  TODO: perhaps add counters for separate things and multiple buffer cases. 
Hive,SATD,//  TODO: this might only be applicable to TezSessionPoolManager; try moving it there? 
Hive,SATD,//  TODO CAT - a number of these need to be updated.  Don't bother with deprecated methods as   this is just an internal class.  Wait until we're ready to move all the catalog stuff up   into ql. 
Hive,SATD,//  in case of outer joins we need to pull in records from the sides we still   need to produce output for apart from the big table. for e.g. full outer join   TODO: this reproduces the logic of the loop that was here before assuming 
Hive,SATD,//  TODO: not clear why this check and skipSeek are needed. 
Hive,SATD,//  TODO: is this a safe assumption (name collision external names...) 
Hive,SATD,//  TODO: Cast Function in Calcite have a bug where it infer type on cast throws 
Hive,SATD,// @TODO FIX this we actually do not need this anymore 
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#getTableName()}. To be removed in Hive 0.16. 
Hive,SATD,//  Based on UserGroupInformation::createProxyUser.   TODO: use a proper method after we can depend on HADOOP-13081. 
Hive,SATD,//  TODO : isn't there a prior impl of an isDirectory utility PathFilter so users don't have to write their own? 
Hive,SATD,//  get rid of trivial case first so that we can safely assume non-null 
Hive,SATD,//  get the tmp URI path; it will be a hdfs path if not local mode   TODO [MM gap?]: this doesn't work however this is MR only.        The path for writer and reader mismatch:        Dump the side-table for tag ... -local-10004/HashTable-Stage-1/MapJoin-a-00-(ds%3D2008-04-08)mm_2.hashtable        Load back 1 hashtable file      -local-10004/HashTable-Stage-1/MapJoin-a-00-srcsortbucket3outof4.txt.hashtable 
Hive,SATD,//  TODO: this duplicates a method in ORC but the method should actually be here. 
Hive,SATD,//  TODO: will this work correctly with ACID? 
Hive,SATD,//  filter columns may have -1 as index which could be partition column in SARG.   TODO: should this then be >=? 
Hive,SATD,//  TODO: this interface is ugly. The two implementations are so far apart feature-wise 
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#linesTerminatedBy()}. To be removed in Hive 0.16. 
Hive,SATD,//  validate is false by default if we enable the constraint   TODO: A constraint like NOT NULL could be enabled using ALTER but VALIDATE remains    false in such cases. Ideally VALIDATE should be set to true to validate existing data 
Hive,SATD,//  TODO: this needs to be enhanced once change management based filesystem is implemented 
Hive,SATD,// todo: it would be nice to check the contents of the files... could use orc.FileDump - it has   methods to print to a supplied stream but those are package private 
Hive,SATD,/*      * Why no null and class checks?     * With the new design a WindowingSpec must contain a WindowFunctionSpec.     * todo: cleanup datastructs.      */
Hive,SATD,/*      * RW lock ensures we have a consistent view of the file data which is important given that     * we generate "stripe" boundaries arbitrarily. Reading buffer data itself doesn't require     * that this lock is held; however everything else in stripes list does.     * TODO: make more granular? We only care that each one reader sees consistent boundaries.     *       So we could shallow-copy the stripes list then have individual locks inside each.      */
Hive,SATD,//  TODO: wtf? 
Hive,SATD,//  TODO Avoid reading this from the environment 
Hive,SATD,//  TODO: we wish we could cache the Hive object but it's not thread safe and each         threadlocal we "cache" would need to be reinitialized for every query. This is         a huge PITA. Hive object will be cached internally but the compat check will be         done every time inside get(). 
Hive,SATD,//  TODO: can we merge neighboring splits? So we don't init so many readers. 
Hive,SATD,//  Don't break! We might find a better match later. 
Hive,SATD,//  No stats exist for this key; add a new object to the cache   TODO: get rid of deepCopy after making sure callers don't use references 
Hive,SATD,//  TODO: in the current impl triggers are added to RP. For tez no pool triggers (mapping between trigger name and   pool name) will exist which means all triggers applies to tez. For LLAP pool triggers has to exist for attaching   triggers to specific pools.   For usability   Provide a way for triggers sharing/inheritance possibly with following modes   ONLY - only to pool   INHERIT - child pools inherit from parent 
Hive,SATD,//  TODO: Using 0 might be wrong; might need to walk down to find the 
Hive,SATD,//  TODO: this should come through RelBuilder to the constructor as opposed to 
Hive,SATD,//  TODO : the contains message check is fragile we should refactor SemanticException to be   queriable for error code and not simply have a message   NOTE : IF_EXISTS might also want to invoke this but there's a good possibility   that IF_EXISTS is stricter about table existence and applies only to the ptn.   Therefore ignoring IF_EXISTS here. 
Hive,SATD,//  TODO : we were discussing an iter interface and also a LazyTuple   change this when plans for that solidifies. 
Hive,SATD,//  TODO: add method to UDFBridge to say if it is a cast func 
Hive,SATD,//  TODO Unregister the task for state updates which could in turn unregister the node. 
Hive,SATD,//  Note: we assume 0-length split is correct given now LRR interprets offsets (reading an   extra row). Should we instead assume 1+ chars and add 1 for isUnfortunate? 
Hive,SATD,//  TODO Maybe add the YARN URL for the app. 
Hive,SATD,//  Note: this particular bit will not work for MM tables as there can be multiple         directories for different MM IDs. We could put the path here that would account         for the current MM ID being written but it will not guarantee that other MM IDs         have the correct buckets. The existing code discards the inferred data when the 
Hive,SATD,//  TODO: not having aliases for path usually means some bug. Should it give up? 
Hive,SATD,//  TODO Get rid of MapOutputInfo if possible 
Hive,SATD,//  TODO: this object is created once to call one method and then immediately destroyed.         So it's basically just a roundabout way to pass arguments to a static method. Simplify? 
Hive,SATD,//  TODO This should be passed in the TaskAttemptContext instead 
Hive,SATD,//  FIXME: use a different exception type? 
Hive,SATD,/*      * This is little complicated.  First we look for our own config values on this.  If those     * aren't set we use the Hive ones.  But Hive also has multiple ways to do this so we need to     * look in both of theirs as well.  We can't use theirs directly because they wrap the     * codahale reporters in their own and we do not.      */
Hive,SATD,// TODO should replace with BytesWritable.copyData() once Hive  removes support for the Hadoop 0.20 series. 
Hive,SATD,//  If the import statement specified that we're importing to an external   table we seem to be doing the following:      a) We don't allow replacement in an unpartitioned pre-existing table      b) We don't allow replacement in a partitioned pre-existing table where that table is external   TODO : Does this simply mean we don't allow replacement in external tables if they already exist?      If so(i.e. the check is superfluous and wrong) this can be a simpler check. If not then      what we seem to be saying is that the only case we allow is to allow an IMPORT into an EXTERNAL      table in the statement if a destination partitioned table exists so long as it is actually 
Hive,SATD,// todo: handle Insert Overwrite as well: HIVE-18154 
Hive,SATD,//  TODO HIVE-15865: Include information about pending requests and last   allocation time once YARN Service provides this information. 
Hive,SATD,//  TODO: At this point we don't know the slot number of the requested host so can't rollover to next available 
Hive,SATD,//  will this be true here?   Don't create a new object if we are already out of memory 
Hive,SATD,//  TODO Replace this with a ExceptionHandler / ShutdownHook 
Hive,SATD,//  NOTE: this can be called outside of HS2 without calling setupPool. Basically it should be         able to handle not being initialized. Perhaps we should get rid of the instance and 
Hive,SATD,/*    * RowResolver of outer query. This is used to resolve co-rrelated columns in Filter   * TODO:   *  this currently will only be able to resolve reference to parent query's column   *  this will not work for references to grand-parent column    */
Hive,SATD,//  TODO use stripe statistics to jump over stripes 
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#fileFormat(String)}. To be removed in Hive 0.16. 
Hive,SATD,//  TODO: Why is this needed (doesn't represent any cols) 
Hive,SATD,//  TODO: this is invalid for SMB. Keep this for now for legacy reasons. See the other overload. 
Hive,SATD,//  TODO: fix this 
Hive,SATD,//  This probably should not happen; but it does... at least also stop the consumer. 
Hive,SATD,//  This seems like a very wrong implementation. 
Hive,SATD,// todo: should make abortTxns() write something into TXNS.TXN_META_INFO about this 
Hive,SATD,//  registry again just in case. TODO: maybe we should enforce that. 
Hive,SATD,//  TODO: lossy conversion distance is considered seconds similar to timestamp 
Hive,SATD,//  TODO: This is fraught with peril. 
Hive,SATD,//  TODO Not the best way to share the address 
Hive,SATD,/*  * This maps a split (path + offset) to an index based on the number of locations provided. * * If locations do not change across jobs the intention is to map the same split to the same node. * * A big problem is when nodes change (added removed temporarily removed and re-added) etc. That changes * the number of locations / position of locations - and will cause the cache to be almost completely invalidated. * * TODO: Support for consistent hashing when combining the split location generator and the ServiceRegistry. *  */
Hive,SATD,//  The list is empty.   Too many concurrent operations; spurious failure.   List is drained and recreated concurrently.   Same for the OTHER list; spurious.   TODO: the fact that concurrent re-creation of other list necessitates full stop is not         ideal... the reason is that the list NOT being re-created still uses the list         being re-created for boundary check; it needs the old value of the other marker.         However NO_DELTA means the other marker was already set to a new value. For now         assume concurrent re-creation is rare and the gap before commit is tiny. 
Hive,SATD,//  The record count from these counters may not be correct if the input vertex has   edges to more than one vertex since this value counts the records going to all   destination vertices. 
Hive,SATD,//  TODO: why is this copy-pasted from HiveInputFormat? 
Hive,SATD,//  negative length should take precedence over positive value? 
Hive,SATD,//  TODO: use DiskRangeList instead 
Hive,SATD,// todo: shouldn't ignoreEmptyFiles be set based on ExecutionEngine? 
Hive,SATD,//  All ErrorAndSolutions that ErrorHeuristic has generated. For the same error they   should be the same though it's possible that different file paths etc 
Hive,SATD,//  Different paths if running locally vs a remote fileSystem. Ideally this difference should not exist. 
Hive,SATD,// todo: should this not be passed in the c'tor? 
Hive,SATD,//  Currently deserialization of complex types is not supported 
Hive,SATD,//  TODO: what about partitions not in the default location? 
Hive,SATD,//  TODO: we currently put task info everywhere before we submit it and know the "real" node id.         Therefore we are going to store this separately. Ideally we should roll uniqueness 
Hive,SATD,//  It would be nice if OI could return typeInfo... 
Hive,SATD,// TODO replace IgnoreKeyTextOutputFormat with a  HiveOutputFormatWrapper in StorageHandler 
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#getNumBuckets()}. 
Hive,SATD,// TODO This line can be removed once precommit jenkins jobs move to Java 8 
Hive,SATD,//  Recovery is not implemented yet for PPD path. 
Hive,SATD,//  ShimLoader.getHadoopShims().isSecurityEnabled() will only check that   hadoopAuth is not simple it does not guarantee it is kerberos 
Hive,SATD,//  Find the class that has this method.   Note that Method.getDeclaringClass() may not work here because the method 
Hive,SATD,//  @deprecated in favour of {@link HCatAddPartitionDesc.#create(HCatPartition)}. To be removed in Hive 0.16. 
Hive,SATD,//  fs.permission.AccessControlException removed by HADOOP-11356 but Hive users on older   Hadoop versions may still see this exception .. have to reference by name. 
Hive,SATD,// this is dumb. HiveOperation is not always set. see HIVE-16447/HIVE-16443 
Hive,SATD,//  TODO: Once HIVE-18948 is in should be able to retrieve writeIdList from the conf.  cachedWriteIdList = AcidUtils.getValidTxnWriteIdList(conf);   
Hive,SATD,//  This is a non-pool session get rid of it. 
Hive,SATD,//  TODO: remove this 
Hive,SATD,//  Not implemented 
Hive,SATD,//  TODO: we only ever use one row of these at a time. Why do we need to cache multiple? 
Hive,SATD,/*    * getDeserializer   *   * Get the Deserializer for a table.   *   * @param conf   *          - hadoop config   * @param table   *          the table   * @return   *   Returns instantiated deserializer by looking up class name of deserializer stored in   *   storage descriptor of passed in table. Also initializes the deserializer with schema   *   of table.   * @exception MetaException   *              if any problems instantiating the Deserializer   *   *              todo - this should move somewhere into serde.jar   *    */
Hive,SATD,//  Not pretty but we need a way to get the size 
Hive,SATD,//  See ctor comment.   TODO: we should get rid of this 
Hive,SATD,//  in addition to that Druid allow numeric dimensions now so this check is not accurate 
Hive,SATD,//  converted = true; // [TODO]: should we check & convert type to String and set it to true? 
Hive,SATD,//  TODO: ideally we should make a special form of insert overwrite so that we:         1) Could use fast merge path for ORC and RC.         2) Didn't have to create a table. 
Hive,SATD,//  TODO: policy on deserialization errors 
Hive,SATD,//  TODO: Do we need to keep track of RR ColNameToPosMap for every op or 
Hive,SATD,// Creating new QueryState unfortunately causes all .q.out to change - do this in a separate ticket  Sharing QueryState between generating the plan and executing the query seems bad 
Hive,SATD,//  TODO: we currently pass null counters because this doesn't use LlapRecordReader.         Create counters for non-elevator-using fragments also? 
Hive,SATD,//  TODO: Not sure that this is the correct behavior. It doesn't make sense to create the   partition with column with invalid type. This should be investigated later. 
Hive,SATD,//  todo: use SemanticAnalyzer::genExprNodeDesc   currently SA not available to PTFTranslator. 
Hive,SATD,//  TODO: we might as well kill the AM at this point. How do we do that from here? 
Hive,SATD,//  bitsets can't be correctly serialized by Kryo's default serializer 
Hive,SATD,//  TODO Ideally move some of the other cleanup code from resetCurrentDag over here 
Hive,SATD,/*  * TODO:pc remove application logic to a separate interface.  */
Hive,SATD,// todo: should this be OK for MM table? 
Hive,SATD,//  TODO: this is a limitation of the AST rewriting approach that we will   not be able to overcome till proper integration of full multi-insert   queries with Calcite is implemented.   The current rewriting gather references from insert clauses and then   updates them with the new subquery references. However if insert   clauses use * or tab.* we cannot resolve the columns that we are   referring to. Thus we just bail out and those queries will not be   currently optimized by Calcite.   An example of such query is:   FROM T_A a LEFT JOIN T_B b ON a.id = b.id   INSERT OVERWRITE TABLE join_result_1   SELECT a.* b.*   INSERT OVERWRITE TABLE join_result_3   SELECT a.* b.*; 
Hive,SATD,//  TODO: delete tables/databases? 
Hive,SATD,// TODO: Improve this 
Hive,SATD,//  TODO: this only applies to current thread so it's not useful at all. 
Hive,SATD,//  Tracks tasks which could not be allocated immediately.   Tasks are tracked in the order requests come in at different priority levels.   TODO HIVE-13538 For tasks at the same priority level it may be worth attempting to schedule tasks with 
Hive,SATD,//  FIXME: current objective is to keep the previous outputs...but this is possibly bad.. 
Hive,SATD,//  Assume the IO is enabled on the daemon by default. We cannot reasonably check it here. 
Hive,SATD,// todo: since HIVE-16669 is not done Minor compact compacts insert delta as well - it should not  Assert.assertTrue("Actual line(file) " + i + " bc: " + rs.get(i) rs.get(i).endsWith(expected2[i][1])); 
Hive,SATD,/*    * Send dropped partition notifications. Subscribers can receive these notifications for a   * particular table by listening on a topic named "dbName.tableName" with message selector   * string {@value org.apache.hive.hcatalog.common.HCatConstants#HCAT_EVENT} =   * {@value org.apache.hive.hcatalog.common.HCatConstants#HCAT_DROP_PARTITION_EVENT}.   * </br>   * TODO: DataNucleus 2.0.3 currently used by the HiveMetaStore for persistence has been   * found to throw NPE when serializing objects that contain null. For this reason we override   * some fields in the StorageDescriptor of this notification. This should be fixed after   * HIVE-2084 "Upgrade datanucleus from 2.0.3 to 3.0.1" is resolved.    */
Hive,SATD,/*  A nice error message should be given to user.  */
Hive,SATD,//  Is smbJoin possible? We need correct order 
Hive,SATD,//  A lot of these methods could be done more efficiently by operating on the Text value   directly rather than converting to HiveChar. 
Hive,SATD,//  it's only for GBY which should forward all values associated with the key in the range   of limit. new value should be attatched with the key but in current implementation   only one values is allowed. with map-aggreagtion which is true by default   this is not common case so just forward new key/value and forget that (todo) 
Hive,SATD,//  ### REVIEW: oops somebody left the last command   unterminated; should we fix it for them or complain?   For now be nice and fix it. 
Hive,SATD,/*    * Checks whether a given url is in a valid format.   *   * The current uri format is: jdbc:hive://[host[:port]]   *   * jdbc:hive:// - run in embedded mode jdbc:hive://localhost - connect to   * localhost default port (10000) jdbc:hive://localhost:5050 - connect to   * localhost port 5050   *   * TODO: - write a better regex. - decide on uri format    */
Hive,SATD,//  Don't fail -- would be better to actually compute a range of [90+inf) 
Hive,SATD,// todo: is this pre or post upgrade?  todo: can different tables be in different FileSystems? 
Hive,SATD,//  Bloating partinfo with inputJobInfo is not good 
Hive,SATD,//  We do not need to generate the QB again but rather we use it directly 
Hive,SATD,//  TODO: ideally we'd register TezCounters here but it seems impossible before registerTask. 
Hive,SATD,//  TODO: We have a cache for Table objects in SemanticAnalyzer::getTableObjectByName()   We need to move that cache elsewhere and use it from places like this. 
Hive,SATD,//  TODO Change the indexCache to be a guava loading cache rather than a custom implementation. 
Hive,SATD,//  todo: fix comment as of HIVE-14988 
Hive,SATD,//  TODO: some SessionState internals are not thread safe. The compile-time internals are synced         via session-scope or global compile lock. The run-time internals work by magic!         They probably work because races are relatively unlikely and few tools run parallel         queries from the same session.         1) OperationState should be refactored out of SessionState and made thread-local. 
Hive,SATD,//  FIXME extract the right info type 
Hive,SATD,//  TODO: should this be configurable via annotation or extending @RunWith annotation? 
Hive,SATD,//  Needs more explanation here   Xmx is not the max heap value in JDK8. You need to subtract 50% of the survivor fraction   from this to get actual usable memory before it goes into GC 
Hive,SATD,//  TODO: in union20.q the tab alias is not properly propagated down the   operator tree. This happens when UNION ALL is used as sub query. Hence even   if column statistics are available the tab alias will be null which will fail   to get proper column statistics. For now assume worst case in which   denominator is 2. 
Hive,SATD,//  Optional feature not implemented 
Hive,SATD,//  TODO we don't support this but we should since users may create an empty partition and   then load data into it. 
Hive,SATD,//  TODO: backward compat for Hive <= 0.12. Can be removed later. 
Hive,SATD,//  @deprecated in favour of {@link HCatTable.#storageHandler(String)}. To be removed in Hive 0.16. 
Hive,SATD,//  FIXME : implement consolidateEvent(..) similar to dumpEvent(evevRoot) 
Hive,SATD,//  TODO: Support checking multiple child operators to merge further. 
Hive,SATD,//  According to calcite it is going to be removed before Calcite-2.0   TODO: to handle CorrelationId 
Hive,SATD,//  TODO: if there's versioning/etc. it will come in here. For now we rely on external         locking or ordering of calls. This should potentially return a Future for that. 
Hive,SATD,// todo: should this be done for MM?  is it ok to use CombineHiveInputFormat with MM? 
Hive,WITHOUT_CLASSIFICATION,//  Settings borrowed from TestJdbcWithMiniHS2 
Hive,WITHOUT_CLASSIFICATION,//  Used for sending notifications about a vertex completed. For canFinish 
Hive,WITHOUT_CLASSIFICATION,//  which should be interpreted in Instant semantics 
Hive,WITHOUT_CLASSIFICATION,//  Unwrap the bag. 
Hive,WITHOUT_CLASSIFICATION,//  Initialize dfs 
Hive,WITHOUT_CLASSIFICATION,//  Piggybacking in Import logic for now 
Hive,WITHOUT_CLASSIFICATION,//  This version of Hadoop does not support FileSystem.access(). 
Hive,WITHOUT_CLASSIFICATION,//  Go over the associated fields and look up the dependencies 
Hive,WITHOUT_CLASSIFICATION,/*          * Single-Column Long specific repeated lookup.          */
Hive,WITHOUT_CLASSIFICATION,//  If all BigTable input columns to key expressions are isRepeating then   calculate key once; lookup once. 
Hive,WITHOUT_CLASSIFICATION,// JDK 1.7 
Hive,WITHOUT_CLASSIFICATION,//  Don't fail the query just because of any lineage issue. 
Hive,WITHOUT_CLASSIFICATION,//  This shouldn't really happen on a byte array. 
Hive,WITHOUT_CLASSIFICATION,//  add new filter op 
Hive,WITHOUT_CLASSIFICATION,// execute in sync mode 
Hive,WITHOUT_CLASSIFICATION,//  add plugin module jars on demand 
Hive,WITHOUT_CLASSIFICATION,//    <Cleanup> <VectorExprArgType> 
Hive,WITHOUT_CLASSIFICATION,//  Update the lastInputFile with the currentInputFile. 
Hive,WITHOUT_CLASSIFICATION,//  attach the predicate and group by to the return clause 
Hive,WITHOUT_CLASSIFICATION,//  SORT_COLS 
Hive,WITHOUT_CLASSIFICATION,// SqlStdOperatorTable.COUNT 
Hive,WITHOUT_CLASSIFICATION,//  This should just generate one strategy with splits for base and insert_deltas. 
Hive,WITHOUT_CLASSIFICATION,//  The following 2 methods are for java serialization use only. 
Hive,WITHOUT_CLASSIFICATION,//  normal case convert all parameters 
Hive,WITHOUT_CLASSIFICATION,//  Thread to generate the separate rows beside the normal thread. 
Hive,WITHOUT_CLASSIFICATION,//  -1 day 10 hrs 11 mins 172800 secs = -1 day 10 hrs 11 mins + 2 days = 1 day 10 hrs 11 mins 
Hive,WITHOUT_CLASSIFICATION,//  only second stripes will satisfy condition and hence single split 
Hive,WITHOUT_CLASSIFICATION,//  How much we can write to current write buffer out of what we need. 
Hive,WITHOUT_CLASSIFICATION,// -----------------------------------------------------------------------------------------------   Comparison methods.  ----------------------------------------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  given a subquery it checks to see what is the aggegate function 
Hive,WITHOUT_CLASSIFICATION,/*    * number of rows received.    */
Hive,WITHOUT_CLASSIFICATION,// llap IO summary 
Hive,WITHOUT_CLASSIFICATION,//  metadata 
Hive,WITHOUT_CLASSIFICATION,//  If the predicate is on a numeric column and it specifies an   open range e.g. key < 20  we do not support conversion as negative   values are lexicographically stored after positive values and thus they   would be returned. 
Hive,WITHOUT_CLASSIFICATION,//  submit few queries 
Hive,WITHOUT_CLASSIFICATION,// however allow the partition comments to change 
Hive,WITHOUT_CLASSIFICATION,//  Add spark.hadoop prefix for yarn properties as SparkConf only accept properties   started with spark prefix Spark would remove spark.hadoop prefix lately and add   it to its hadoop configuration. 
Hive,WITHOUT_CLASSIFICATION,//  Only fetch the table if we actually have a listener 
Hive,WITHOUT_CLASSIFICATION,//  worst case 
Hive,WITHOUT_CLASSIFICATION,//  Technically for ifNotExists case we could insert one and discard the other   because the first one now "exists" but it seems better to report the problem   upstream as such a command doesn't make sense. 
Hive,WITHOUT_CLASSIFICATION,//  key * 265 
Hive,WITHOUT_CLASSIFICATION,//  Buddy block is free and in the same free list we have locked. Take it out for merge. 
Hive,WITHOUT_CLASSIFICATION,//  Now that we have made sure that the argument is of primitive type we can get the primitive   category 
Hive,WITHOUT_CLASSIFICATION,//  Interrupted. 
Hive,WITHOUT_CLASSIFICATION,//  return size 
Hive,WITHOUT_CLASSIFICATION,//    Rewrite the above plan:     CorrelateRel(left correlation condition = true)     LeftInputRel     Project-A (a RexNode)       Aggregate (groupby(0) agg0() agg1()...)         Project-B (references coVar)           RightInputRel (no correlated reference)   
Hive,WITHOUT_CLASSIFICATION,//  number n of elements   average of x elements   average of y elements   n times the covariance 
Hive,WITHOUT_CLASSIFICATION,// it happens when using -f and the line of cmds does not end with ; 
Hive,WITHOUT_CLASSIFICATION,//  Make sure zero trimming doesn't extend into the integer digits. 
Hive,WITHOUT_CLASSIFICATION,//  traverse all the joins and convert them if necessary 
Hive,WITHOUT_CLASSIFICATION,//  rc will be 1 at this point indicating failure. 
Hive,WITHOUT_CLASSIFICATION,// 'state' should not be null - future proofing 
Hive,WITHOUT_CLASSIFICATION,// link lockId to queryId 
Hive,WITHOUT_CLASSIFICATION,//  replace each of the position alias in ORDERBY with the actual column 
Hive,WITHOUT_CLASSIFICATION,// do nothing by default 
Hive,WITHOUT_CLASSIFICATION,//  Note: this sets LoadFileType incorrectly for ACID; is that relevant for import?         See setLoadFileType and setIsAcidIow calls elsewhere for an example. 
Hive,WITHOUT_CLASSIFICATION,//  Describe how to serialize data out to user script 
Hive,WITHOUT_CLASSIFICATION,//  two dots?? 
Hive,WITHOUT_CLASSIFICATION,//  make sure MAP task environment points to HADOOP_CREDSTORE_PASSWORD 
Hive,WITHOUT_CLASSIFICATION,//  stop in reserve order of start 
Hive,WITHOUT_CLASSIFICATION,/*      * 1. setup resolve make connections      */
Hive,WITHOUT_CLASSIFICATION,//  Update job state with the childJob id 
Hive,WITHOUT_CLASSIFICATION,//  Exists aleady. 
Hive,WITHOUT_CLASSIFICATION,//  As this partition (partdate=2008-01-01/partcity=london) is the only   partition under (partdate=2008-01-01) 
Hive,WITHOUT_CLASSIFICATION,//  Verify. 
Hive,WITHOUT_CLASSIFICATION,//  can the mapjoin present be converted to a bucketed mapjoin 
Hive,WITHOUT_CLASSIFICATION,//  skip Druid properties which are used in DruidSerde since they are also updated   after SerDeInfo properties are copied. 
Hive,WITHOUT_CLASSIFICATION,//  Note that permanent functions can only be properly checked from the session registry.   If permanent functions are read from the metastore during Hive initialization   the JARs are not loaded for the UDFs during that time and so Hive is unable to instantiate   the UDf classes to add to the persistent functions set.   Once a permanent UDF has been referenced in a session its FunctionInfo should be registered   in the session registry (and persistent set updated) so it can be looked up there. 
Hive,WITHOUT_CLASSIFICATION,//  middle item 
Hive,WITHOUT_CLASSIFICATION,// if there is WriteEntity with WriteType=UPDATE/DELETE for target table replace it with  WriteEntity for each partition 
Hive,WITHOUT_CLASSIFICATION,//  The underlying SSLSocket object is bound to host:port with the given SO_TIMEOUT 
Hive,WITHOUT_CLASSIFICATION,//  Since we want to display all the met and not met conditions in EXPLAIN we determine all   information first.... 
Hive,WITHOUT_CLASSIFICATION,// partition root 
Hive,WITHOUT_CLASSIFICATION,//  If a new MoveWork was created then we should link all dependent tasks from the MoveWork to link. 
Hive,WITHOUT_CLASSIFICATION,//  Note that the code updating the state of the task does it when it's out of the queue.   So the priorities in the queue should be correct; if the top task is not killable then   no task in the queue would be killable. 
Hive,WITHOUT_CLASSIFICATION,/*    * Create a new grouping key for grouping id.   * A dummy grouping id. is added. At runtime the group by operator   * creates 'n' rows per input row where 'n' is the number of grouping sets.    */
Hive,WITHOUT_CLASSIFICATION,// because 'local' inpath doesn't delete source files 
Hive,WITHOUT_CLASSIFICATION,//  deal with dynamic partition columns: convert ExprNodeDesc type to String?? 
Hive,WITHOUT_CLASSIFICATION,//  Try 2-arg version 
Hive,WITHOUT_CLASSIFICATION,//  replacing any previous mapping from old input). 
Hive,WITHOUT_CLASSIFICATION,//  sales.txt will need to be added as a resource. 
Hive,WITHOUT_CLASSIFICATION,/*  This is an illustration not a functioning example.  */
Hive,WITHOUT_CLASSIFICATION,//  There should be 1 new directory: base_0000001. 
Hive,WITHOUT_CLASSIFICATION,//  remainder is always positive 
Hive,WITHOUT_CLASSIFICATION,//  when converting from char the value should be stripped of any trailing spaces. 
Hive,WITHOUT_CLASSIFICATION,// check if May 23 1968 is Julian Day 2440000 
Hive,WITHOUT_CLASSIFICATION,//  This should not start the actual Tez AM. 
Hive,WITHOUT_CLASSIFICATION,//  for each dir get the InputFormat and do getSplits. 
Hive,WITHOUT_CLASSIFICATION,// safety valve for extreme cases 
Hive,WITHOUT_CLASSIFICATION,//  Note that we have 3 regex'es below 
Hive,WITHOUT_CLASSIFICATION,//  In case of unions or map-joins it is possible that the file has   already been seen. 
Hive,WITHOUT_CLASSIFICATION,//  In theory this should not happen - if the original copy of the UDF had this   data we should be able to set the UDF copy with this same settableData. 
Hive,WITHOUT_CLASSIFICATION,//  Parse validTxnList 
Hive,WITHOUT_CLASSIFICATION,//  inputs.add(new ReadEntity(partn)); // is this needed at all? 
Hive,WITHOUT_CLASSIFICATION,// test table without db portion 
Hive,WITHOUT_CLASSIFICATION,//  Record the final counters. 
Hive,WITHOUT_CLASSIFICATION,//  Stop HiveServer2 
Hive,WITHOUT_CLASSIFICATION,/*  first_name = 'alan'   */
Hive,WITHOUT_CLASSIFICATION,/*          * if skipNulls is true and there are no rows in valueChain => all rows         * in partition are null so far; so add null in o/p          */
Hive,WITHOUT_CLASSIFICATION,//  Expect query to be successfully completed now 
Hive,WITHOUT_CLASSIFICATION,//  if old view has partitions it could not be replaced 
Hive,WITHOUT_CLASSIFICATION,// Oracle specific parser 
Hive,WITHOUT_CLASSIFICATION,//  Base case. 
Hive,WITHOUT_CLASSIFICATION,// Asynch write completed  Up the semaphore 
Hive,WITHOUT_CLASSIFICATION,/*    * Override this method if you want to customize how the node dumps out its   * children.    */
Hive,WITHOUT_CLASSIFICATION,// e.g. analyze table page_view partition(dt='10/15/2014'country=’US’) 
Hive,WITHOUT_CLASSIFICATION,//  Does same thing with LazyFactory#createLazyObjectInspector except that this replaces   original keyOI with OI which is create by HBaseKeyFactory provided by serde property for hbase 
Hive,WITHOUT_CLASSIFICATION,//  We dont set perms or groups for default dir. 
Hive,WITHOUT_CLASSIFICATION,//  Setup timer task to check for hearbeat timeouts 
Hive,WITHOUT_CLASSIFICATION,// start concurrent txn 
Hive,WITHOUT_CLASSIFICATION,//  Also throws IOException when Binary is detected. 
Hive,WITHOUT_CLASSIFICATION,//  Some nasty examples that show how S3 log format is broken ... and to   test the regex   These are all sourced from genuine S3 logs   Text sample = new   Text("04ff331638adc13885d6c42059584deabbdeabcd55bf0bee491172a79a87b196 img.zemanta.com [09/Apr/2009:22:00:07 +0000] 190.225.84.114 65a011a29cdf8ec533ec3d1ccaae921c F4FC3FEAD8C00024 REST.GET.OBJECT pixy.gif \"GET /pixy.gif?x-id=23d25db1-160b-48bb-a932-e7dc1e88c321 HTTP/1.1\" 304 - - 828 3 - \"http://www.viamujer.com/2009/03/horoscopo-acuario-abril-mayo-y-junio-2009/\" \"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; .NET CLR 1.1.4322; .NET CLR 2.0.50727)\"");   Text sample = new   Text("04ff331638adc13885d6c42059584deabbdeabcd55bf0bee491172a79a87b196 img.zemanta.com [09/Apr/2009:22:19:49 +0000] 60.28.204.7 65a011a29cdf8ec533ec3d1ccaae921c 7D87B6835125671E REST.GET.OBJECT pixy.gif \"GET /pixy.gif?x-id=b50a4544-938b-4a63-992c-721d1a644b28 HTTP/1.1\" 200 - 828 828 4 3 \"\" \"ZhuaXia.com\"");   Text sample = new   Text("04ff331638adc13885d6c42059584deabbdeabcd55bf0bee491172a79a87b196 static.zemanta.com [09/Apr/2009:23:12:39 +0000] 65.94.12.181 65a011a29cdf8ec533ec3d1ccaae921c EEE6FFE9B9F9EA29 REST.HEAD.OBJECT readside/loader.js%22+defer%3D%22defer \"HEAD /readside/loader.js\"+defer=\"defer HTTP/1.0\" 403 AccessDenied 231 - 7 - \"-\" \"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.0)\""); 
Hive,WITHOUT_CLASSIFICATION,//  Call the function 
Hive,WITHOUT_CLASSIFICATION,//     LOG.info("har location : " + harLocn); 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#executeUpdate(java.lang.String java.lang.String[])    */
Hive,WITHOUT_CLASSIFICATION,/*      * A WindowFrame may contain just the Start Boundary or in the     * between style of expressing a WindowFrame both boundaries     * are specified.      */
Hive,WITHOUT_CLASSIFICATION,//  The partitioning columns of the child RS are more specific than   those of the parent RS. 
Hive,WITHOUT_CLASSIFICATION,//  Sample the first batch processed for variable sizes. 
Hive,WITHOUT_CLASSIFICATION,//  Phase 1 - create objects. 
Hive,WITHOUT_CLASSIFICATION,//  update for "{\"writeid\":0\"bucketid\":536936448\"rowid\":1}\t60\t80" 
Hive,WITHOUT_CLASSIFICATION,//  count (1) 
Hive,WITHOUT_CLASSIFICATION,// case 2: 23:59:59.999999999 
Hive,WITHOUT_CLASSIFICATION,//  Fail - "transactional" is set to true and the table is bucketed but doesn't use ORC 
Hive,WITHOUT_CLASSIFICATION,//  Use the expressions from Reduce Sink. 
Hive,WITHOUT_CLASSIFICATION,//  want the values which are not skewed 
Hive,WITHOUT_CLASSIFICATION,//  Only specified nodes of these types will be walked.   Empty set means all the nodes will be walked. 
Hive,WITHOUT_CLASSIFICATION,//  Valid txn list might be generated for a query compiled using this   command thus we need to reset it 
Hive,WITHOUT_CLASSIFICATION,//  run in the vectorized mode. 
Hive,WITHOUT_CLASSIFICATION,//  At this point. one p=2 task and task3(p=1) running. Ask for another p1 task. 
Hive,WITHOUT_CLASSIFICATION,//  Write files inside the sub-directory. 
Hive,WITHOUT_CLASSIFICATION,//  If it is a sub-directory then recursively list the files. 
Hive,WITHOUT_CLASSIFICATION,// for thread safe 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise we add to the join specs 
Hive,WITHOUT_CLASSIFICATION,//  If the target hash table is on disk spill this row to disk as well to be processed later 
Hive,WITHOUT_CLASSIFICATION,// this is a contrived example in practice this query would of course fail after drop table 
Hive,WITHOUT_CLASSIFICATION,//  It is a view 
Hive,WITHOUT_CLASSIFICATION,//  Not propagated. 
Hive,WITHOUT_CLASSIFICATION,//  Create the final Reduce Sink Operator 
Hive,WITHOUT_CLASSIFICATION,//  From https://msdn.microsoft.com/en-us/library/ms190476.aspx   e1 / e2   Precision: p1 - s1 + s2 + max(6 s1 + p2 + 1)   Scale: max(6 s1 + p2 + 1) 
Hive,WITHOUT_CLASSIFICATION,//  Let the Processor control start for Broadcast inputs. 
Hive,WITHOUT_CLASSIFICATION,//  since we are adding the user name to the scratch dir we do not   need to give more permissions here 
Hive,WITHOUT_CLASSIFICATION,//  If the schema version is already checked then go ahead and use this metastore 
Hive,WITHOUT_CLASSIFICATION,//  6.1 child can be EXPR AS ALIAS or EXPR. 
Hive,WITHOUT_CLASSIFICATION,//  leftInputRel contains unique keys   i.e. each row is distinct and can group by on all the left 
Hive,WITHOUT_CLASSIFICATION,//  Store the inputs in a HashMap since we can't get a ReadEntity from inputs since it is   implemented as a set.ReadEntity is used as the key so that the HashMap has the same behavior   of equals and hashCode 
Hive,WITHOUT_CLASSIFICATION,//  If this operator has been visited already by the rule   we do not need to apply the optimization 
Hive,WITHOUT_CLASSIFICATION,//  the oldSplit may be null during the split phase 
Hive,WITHOUT_CLASSIFICATION,//  First create the archive in a tmp dir so that if the job fails the 
Hive,WITHOUT_CLASSIFICATION,//  Close the session before we have to wait again. 
Hive,WITHOUT_CLASSIFICATION,// deltes can't be raw format 
Hive,WITHOUT_CLASSIFICATION,//  OPERATION_ID 
Hive,WITHOUT_CLASSIFICATION,//  short-circuited on client-side verifying that it's an empty object not null 
Hive,WITHOUT_CLASSIFICATION,//  Read the newly added db via CachedStore 
Hive,WITHOUT_CLASSIFICATION,/*        * Multi-Key specific declarations.        */
Hive,WITHOUT_CLASSIFICATION,//  The number of files for the table should be same as number of buckets. 
Hive,WITHOUT_CLASSIFICATION,//  get the join keys from parent ReduceSink operators 
Hive,WITHOUT_CLASSIFICATION,//  whether all files are not sufficient to reach sizeLeft 
Hive,WITHOUT_CLASSIFICATION,//  Not in VRB mode - the new cache data is ready we should use it. 
Hive,WITHOUT_CLASSIFICATION,//  Directory removal will be handled by cleanup at the SessionState level. 
Hive,WITHOUT_CLASSIFICATION,//  Use only 1 reducer if no reduce keys 
Hive,WITHOUT_CLASSIFICATION,//  Only set when setting up the secure config for ZK. 
Hive,WITHOUT_CLASSIFICATION,//  REPL LOAD 
Hive,WITHOUT_CLASSIFICATION,//  Make room for remainder. 
Hive,WITHOUT_CLASSIFICATION,//  Resolve storage handler (if any) 
Hive,WITHOUT_CLASSIFICATION,//  Restore default cost model 
Hive,WITHOUT_CLASSIFICATION,//  Test that input name does not change IOContext returned and that each thread gets its own. 
Hive,WITHOUT_CLASSIFICATION,//  Ignore exceptions from destroy 
Hive,WITHOUT_CLASSIFICATION,//  this is always non-null when conversion is completed 
Hive,WITHOUT_CLASSIFICATION,//  True if both are null 
Hive,WITHOUT_CLASSIFICATION,// Utility methods used to store pairs of ints as long. 
Hive,WITHOUT_CLASSIFICATION,//  is the nullIndicator 
Hive,WITHOUT_CLASSIFICATION,//  for group-by values with same key on top-K should be forwarded  flag used to control how TopN handled for PTF/Windowing partitions. 
Hive,WITHOUT_CLASSIFICATION,// get default value to be be stored in metastore 
Hive,WITHOUT_CLASSIFICATION,//  Add a new key or add a value to an existing key? 
Hive,WITHOUT_CLASSIFICATION,//  This one can be pushed 
Hive,WITHOUT_CLASSIFICATION,//  there is already a predicate on this src. 
Hive,WITHOUT_CLASSIFICATION,//  1. OB Expr sanity test   in strict mode in the presence of order by limit must be 
Hive,WITHOUT_CLASSIFICATION,//  adding DP ColumnInfo to the RowSchema signature 
Hive,WITHOUT_CLASSIFICATION,//  There are two areas of exploration for optimization here.   1.  We're serializing the schema with every object.  If we assume the schema       provided by the table is always correct we don't need to do this and       and can just send the serialized bytes.   2.  We serialize/deserialize to/from bytes immediately.  We may save some       time but doing this lazily but until there's evidence this is useful 
Hive,WITHOUT_CLASSIFICATION,//  Get input data 
Hive,WITHOUT_CLASSIFICATION,//  Master node will serialize readercontext and will make it available  at slaves. 
Hive,WITHOUT_CLASSIFICATION,/*  256 files x 1000 size for 1 splits  */
Hive,WITHOUT_CLASSIFICATION,// arrowAllocatorLimit is ignored if an allocator was previously created 
Hive,WITHOUT_CLASSIFICATION,//  Is the grouping sets data consumed in the current in MR job or 
Hive,WITHOUT_CLASSIFICATION,// completion of txnid:txnIdSelect 
Hive,WITHOUT_CLASSIFICATION,//  Write a value to the column vector and return back the byte buffer used. 
Hive,WITHOUT_CLASSIFICATION,//  When reading the file for first time we get the orc tail from the orc reader and cache it   in the footer cache. Subsequent requests will get the orc tail from the cache (if file   length and modification time is not changed) and populate the split info. If the split info   object contains the orc tail from the cache then we can skip creating orc reader avoiding   filesystem calls. 
Hive,WITHOUT_CLASSIFICATION,//  Obviously different expressions. 
Hive,WITHOUT_CLASSIFICATION,//  Assert the actual stack traces are exactly equal to the written ones    and are contained in "stackTraces" list in the submission order: 
Hive,WITHOUT_CLASSIFICATION,//  map from newInput 
Hive,WITHOUT_CLASSIFICATION,//  retain only the largest value for a register index 
Hive,WITHOUT_CLASSIFICATION,//  Probe space should be at least equal to the size of our designated wbSize 
Hive,WITHOUT_CLASSIFICATION,//  Skewed columns stuff. 
Hive,WITHOUT_CLASSIFICATION,//  key * 21 
Hive,WITHOUT_CLASSIFICATION,//  1. deal with non-partition columns 
Hive,WITHOUT_CLASSIFICATION,//  dummy instantiation to make sure any static/ctor code blocks of that   driver are loaded and ready to go. 
Hive,WITHOUT_CLASSIFICATION,//  the name of the dag is what is displayed in the AM/Job UI 
Hive,WITHOUT_CLASSIFICATION,//  Note that this is not real double hashing since we have consistent hash on top. 
Hive,WITHOUT_CLASSIFICATION,//  Can't vectorize 
Hive,WITHOUT_CLASSIFICATION,//  Read the value and key length for the first record. 
Hive,WITHOUT_CLASSIFICATION,//  List of conf entries not to turn into env vars 
Hive,WITHOUT_CLASSIFICATION,//  if limit is greater than available rows then do not update   statistics 
Hive,WITHOUT_CLASSIFICATION,/*  this is the bad part - the vectorized UDF returns the right result  */
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setAsciiStream(java.lang.String   * java.io.InputStream)    */
Hive,WITHOUT_CLASSIFICATION,//  An actual list deser its values 
Hive,WITHOUT_CLASSIFICATION,//  create new agg function calls and rest of project list together 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#setFetchSize(int)    */
Hive,WITHOUT_CLASSIFICATION,//  partition walker working on 
Hive,WITHOUT_CLASSIFICATION,//  instantiate new factory instance only if current one is not valid. 
Hive,WITHOUT_CLASSIFICATION,//  extra columns is difference between referenced columns vs needed   columns. The difference could be partition columns. 
Hive,WITHOUT_CLASSIFICATION,//  check if this user has grant privileges for this privileges on this   object 
Hive,WITHOUT_CLASSIFICATION,/*        * for each predicate:       * - does it refer to one or many aliases       * - if one: add it to the filterForPushing list of that alias       * - if many: add as a filter from merging trees.        */
Hive,WITHOUT_CLASSIFICATION,//  Cannot entries while we currently hold read lock so keep track of them to delete later. 
Hive,WITHOUT_CLASSIFICATION,//  Definitely a short; most shorts fall here 
Hive,WITHOUT_CLASSIFICATION,//  Use the serialization scale and format the string with trailing zeroes (or   round the decimal) if necessary. 
Hive,WITHOUT_CLASSIFICATION,//  Report the row if its the first row 
Hive,WITHOUT_CLASSIFICATION,//  Serialize using the SerDe then below deserialize using DeserializeRead. 
Hive,WITHOUT_CLASSIFICATION,//  Original hashcode with 0-d low bits. 
Hive,WITHOUT_CLASSIFICATION,//  Return an evaluator depending on the return type 
Hive,WITHOUT_CLASSIFICATION,//  We assume each partition has an unique SD. 
Hive,WITHOUT_CLASSIFICATION,//  FIELD_SCHEMAS 
Hive,WITHOUT_CLASSIFICATION,//  Check the output of FixAcidKeyIndex - it should indicate the index was fixed. 
Hive,WITHOUT_CLASSIFICATION,// nothing to do 
Hive,WITHOUT_CLASSIFICATION,//  Export is trivially undoable - in that nothing needs doing to undo it. 
Hive,WITHOUT_CLASSIFICATION,//  this returns the row as is because this formatter is only called when   the ThriftJDBCBinarySerDe was used to serialize the rows to thrift-able objects. 
Hive,WITHOUT_CLASSIFICATION,//  Serialization ctor. 
Hive,WITHOUT_CLASSIFICATION,//  Query that should fetch one column 
Hive,WITHOUT_CLASSIFICATION,//  Set the default to 0 -- if the created date is null there was 
Hive,WITHOUT_CLASSIFICATION,//  referenced by the current expression node. 
Hive,WITHOUT_CLASSIFICATION,//  Descriptor is not defined because it takes variable number of arguments with different   data types. 
Hive,WITHOUT_CLASSIFICATION,// note that in ToolRunner this is expected to be a local FS path  see GenericOptionsParser.getLibJars() 
Hive,WITHOUT_CLASSIFICATION,//  generate a selection operator for group-by keys only 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setDate(java.lang.String java.sql.Date)    */
Hive,WITHOUT_CLASSIFICATION,//  Change the type back to int so that the same alter can be attempted from connection 2. 
Hive,WITHOUT_CLASSIFICATION,//  2/ test LazyBinaryMap 
Hive,WITHOUT_CLASSIFICATION,//  This will turn on setugi on both client and server processes of the test. 
Hive,WITHOUT_CLASSIFICATION,//  leave it for GC to clean up 
Hive,WITHOUT_CLASSIFICATION,//  the last block that add() should append to   the current block where the cursor is in 
Hive,WITHOUT_CLASSIFICATION,//  Regrettable that we have to wrap the IOException into a RuntimeException   but throwing the exception is the appropriate result here and hasNext()   signature will only allow RuntimeExceptions. Iterator.hasNext() really   should have allowed IOExceptions 
Hive,WITHOUT_CLASSIFICATION,//  Verify that addNotificationEvent() updates the NotificationEvent with the new event ID 
Hive,WITHOUT_CLASSIFICATION,//  spacing 
Hive,WITHOUT_CLASSIFICATION,// give up 
Hive,WITHOUT_CLASSIFICATION,//  extract partition spec to file name part from path 
Hive,WITHOUT_CLASSIFICATION,//  Retrieve all partitions generated from partition pruner and partition 
Hive,WITHOUT_CLASSIFICATION,//  2. Test with doAs=true 
Hive,WITHOUT_CLASSIFICATION,//  validate database 
Hive,WITHOUT_CLASSIFICATION,//  If we're merging to the same location we can avoid some metastore calls 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#prepareStatement(java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,// LOG.debug("Running Hive Query: "+ sql); 
Hive,WITHOUT_CLASSIFICATION,//  The location is input and table is output for alter-table add partitions 
Hive,WITHOUT_CLASSIFICATION,//  Sort the n-gram list by frequencies in descending order 
Hive,WITHOUT_CLASSIFICATION,//  In this case we should expect the test to have failed at the very last read() check. 
Hive,WITHOUT_CLASSIFICATION,//  PROGRESSED_PERCENTAGE 
Hive,WITHOUT_CLASSIFICATION,//  Only offer these when the input file format is not the fast vectorized formats. 
Hive,WITHOUT_CLASSIFICATION,//  In that case it will be a Select but the rowOI need not be amended 
Hive,WITHOUT_CLASSIFICATION,//  Null-safe isSame 
Hive,WITHOUT_CLASSIFICATION,//  this path is intermediate data 
Hive,WITHOUT_CLASSIFICATION,//  Start the server 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getTimestamp(int java.util.Calendar)    */
Hive,WITHOUT_CLASSIFICATION,//  If we are caching the MV we include it in the cache 
Hive,WITHOUT_CLASSIFICATION,//  We use longs because we don't have unsigned ints 
Hive,WITHOUT_CLASSIFICATION,//  The input column can either be a string or a list of integer values. 
Hive,WITHOUT_CLASSIFICATION,//  Integer is too large -- cannot recover by trimming fractional digits. 
Hive,WITHOUT_CLASSIFICATION,//  if ast has two children   the 2nd child could be partition spec or columnName 
Hive,WITHOUT_CLASSIFICATION,//  typically alter table .. concatenate is run on only one partition/one table 
Hive,WITHOUT_CLASSIFICATION,//  first call FileUtils.mkdir to make sure that destf directory exists if not it creates 
Hive,WITHOUT_CLASSIFICATION,//  add the new op as the old 
Hive,WITHOUT_CLASSIFICATION,//  this is the case when we have a map-side SMB join   one input of the join is treated as a dummy vertex 
Hive,WITHOUT_CLASSIFICATION,//  IS_SET_SCHEDULING_POLICY 
Hive,WITHOUT_CLASSIFICATION,//  we need to count the current one as a map table then. 
Hive,WITHOUT_CLASSIFICATION,//  -33440539101030154945490585226577271520 is expected result 
Hive,WITHOUT_CLASSIFICATION,//  IS_SET_QUERY_PARALLELISM 
Hive,WITHOUT_CLASSIFICATION,//  use the short user name for the request 
Hive,WITHOUT_CLASSIFICATION,//  Changes the owner to a role and verify the change 
Hive,WITHOUT_CLASSIFICATION,//  partial test init 
Hive,WITHOUT_CLASSIFICATION,//  optional tblName was specified. 
Hive,WITHOUT_CLASSIFICATION,//  update stats but don't update NDV as it will not change 
Hive,WITHOUT_CLASSIFICATION,//  for every sampled alias we figure out splits to be sampled and add   them to return list 
Hive,WITHOUT_CLASSIFICATION,//  Cleanup the synthetic predicate in the tablescan operator and filter by   replacing it with "true" 
Hive,WITHOUT_CLASSIFICATION,//  Test that 2 exclusive partition locks coalesce to one 
Hive,WITHOUT_CLASSIFICATION,//  HiveServer2 global init file location 
Hive,WITHOUT_CLASSIFICATION,/* Example code to test specific scenarios:    LowLevelCacheImpl cache = new LowLevelCacheImpl(        LlapDaemonCacheMetrics.create("test" "1") new DummyCachePolicy()        new DummyAllocator() true -1); // no cleanup thread    final int FILE = 1;    cache.putFileData(FILE gaps(3756206 4261729 7294767 7547564) fbs(3) 0 Priority.NORMAL null null);    cache.putFileData(FILE gaps(7790545 11051556) fbs(1) 0 Priority.NORMAL null null);    cache.putFileData(FILE gaps(11864971 11912961 13350968 13393630) fbs(3) 0 Priority.NORMAL null null);    DiskRangeList dr = dr(3756206 7313562);    MutateHelper mh = new MutateHelper(dr);    dr = dr.insertAfter(dr(7790545 11051556));    dr = dr.insertAfter(dr(11864971 13393630));    BooleanRef g = new BooleanRef();    dr = cache.getFileData(FILE mh.next 0 testFactory null g); */
Hive,WITHOUT_CLASSIFICATION,//  Go through the root tasks and verify the input format of the map reduce task(s) is   HiveSortedInputFormat 
Hive,WITHOUT_CLASSIFICATION,//  bucket is the second field in the record id 
Hive,WITHOUT_CLASSIFICATION,//  Update the info of SEL operator based on the pruned reordered columns 
Hive,WITHOUT_CLASSIFICATION,//  In case cols are null 
Hive,WITHOUT_CLASSIFICATION,//  Get the UDTF Path 
Hive,WITHOUT_CLASSIFICATION,//  in alter-table-add-partition the table is output and location is input 
Hive,WITHOUT_CLASSIFICATION,//  try non-null path 
Hive,WITHOUT_CLASSIFICATION,//  Get the value length. 
Hive,WITHOUT_CLASSIFICATION,//  makes spilling prediction (isMemoryFull) to be too defensive which results in unnecessary spilling 
Hive,WITHOUT_CLASSIFICATION,//  since no division has occurred don't format with a decimal point 
Hive,WITHOUT_CLASSIFICATION,//  Build the bitset with not null columns 
Hive,WITHOUT_CLASSIFICATION,//  Don't set inputs and outputs - the locks have already been taken so it's pointless. 
Hive,WITHOUT_CLASSIFICATION,//  requests before it is started. 
Hive,WITHOUT_CLASSIFICATION,//  create the local work for this plan 
Hive,WITHOUT_CLASSIFICATION,//  Needed until there is no junit release with @BeforeParam @AfterParam (junit 4.13)   https://github.com/junit-team/junit4/commit/1bf8438b65858565dbb64736bfe13aae9cfc1b5a   Then we should remove our own copy 
Hive,WITHOUT_CLASSIFICATION,//  Empty values except first column 
Hive,WITHOUT_CLASSIFICATION,/*    * add array<struct> to the list of columns    */
Hive,WITHOUT_CLASSIFICATION,//  This also resets SessionState.get. 
Hive,WITHOUT_CLASSIFICATION,//  get the create table statement for the table and populate the output 
Hive,WITHOUT_CLASSIFICATION,//  replace each of the position alias in ORDERBY with the actual column name 
Hive,WITHOUT_CLASSIFICATION,//  Get columnNames from the first parent 
Hive,WITHOUT_CLASSIFICATION,//  Create the walker the rules dispatcher and the context. 
Hive,WITHOUT_CLASSIFICATION,//  check the ObjectInspector 
Hive,WITHOUT_CLASSIFICATION,//  HiveParser.identifier | HiveParse.KW_IF | HiveParse.KW_LEFT |   HiveParse.KW_RIGHT 
Hive,WITHOUT_CLASSIFICATION,//  Shutdown existing session manager 
Hive,WITHOUT_CLASSIFICATION,//  no hits on the index so return a no match range 
Hive,WITHOUT_CLASSIFICATION,//  This will be used by hadoop only in unsecure(/non kerberos) mode 
Hive,WITHOUT_CLASSIFICATION,//  null values 
Hive,WITHOUT_CLASSIFICATION,//  Create the context for the walker 
Hive,WITHOUT_CLASSIFICATION,//  Build the type property string if not supplied 
Hive,WITHOUT_CLASSIFICATION,//  whether it contains common join op; if contains return this common join op 
Hive,WITHOUT_CLASSIFICATION,/*    * Struct    */
Hive,WITHOUT_CLASSIFICATION,// should never happen - just in case 
Hive,WITHOUT_CLASSIFICATION,//  Add task to insert / delete materialized view from registry if needed 
Hive,WITHOUT_CLASSIFICATION,//  If using async we could also reserve one by one. 
Hive,WITHOUT_CLASSIFICATION,// if here it must be delta_x_y - insert events only so we must be compacting 
Hive,WITHOUT_CLASSIFICATION,//  Connect parent to fileSinkOp 
Hive,WITHOUT_CLASSIFICATION,//  run 5 sql inserts concurrently 
Hive,WITHOUT_CLASSIFICATION,//  Test in binary mode 
Hive,WITHOUT_CLASSIFICATION,/* getAcidState() is smart not to return any deltas in current if there is a base that covers    * them i.e. if they were compacted but not yet cleaned.  This means re-checking if    * compaction is needed should cheap(er) */
Hive,WITHOUT_CLASSIFICATION,//  It's possible that old metadata still refers to "decimal" as a column type w/o   precision/scale. In this case the default (100) is assumed. Thus do nothing here. 
Hive,WITHOUT_CLASSIFICATION,//  In the case where agg is count(*) or count($corVar) it is   changed to count(nullIndicator).   Note:  any non-nullable field from the RHS can be used as   the indicator however a "true" field is added to the   projection list from the RHS for simplicity to avoid   searching for non-null fields.     Project-A' (all gby keys + rewritten nullable ProjExpr)     Aggregate (groupby(all left input refs)                   count(nullIndicator) other aggs...)       Project-B' (all left input refs plus                      the rewritten original projected exprs)         Join(replace corvar to input ref from LeftInputRel)           LeftInputRel           Project (everything from RightInputRel plus                       the nullIndicator "true")             RightInputRel   
Hive,WITHOUT_CLASSIFICATION,//  If the new port is invalid find one - starting with the default client port.   If the default client port is not specified starting with a random port.   The random port is selected from the range between 49152 to 65535. These ports cannot be   registered with IANA and are intended for dynamic allocation (see http://bit.ly/dynports). 
Hive,WITHOUT_CLASSIFICATION,// AND NOT etc 
Hive,WITHOUT_CLASSIFICATION,//  This position is an aggregation.   As we store in oneRow only the aggregate results we need to adjust to the correct position   if there are keys in the GBy operator. 
Hive,WITHOUT_CLASSIFICATION,//  Subtract from self. 
Hive,WITHOUT_CLASSIFICATION,//  Set isNull before calls in case tney change their mind. 
Hive,WITHOUT_CLASSIFICATION,// if maxRetries is 0 code retries until batch decays to zero 
Hive,WITHOUT_CLASSIFICATION,//  We should fail if we try to get info out of the params 
Hive,WITHOUT_CLASSIFICATION,//  execution to fall back to row mode. 
Hive,WITHOUT_CLASSIFICATION,/*            * Optionally read current value's big length.  {Big Value Len} {Big Value Bytes}           * Since this is the first record the valueRefWord directs us.            */
Hive,WITHOUT_CLASSIFICATION,//  Avro requires nullable types to be defined as unions of some type T   and NULL. This is annoying and we're going to hide it from the user. 
Hive,WITHOUT_CLASSIFICATION,//  Verify the raw object that's been created 
Hive,WITHOUT_CLASSIFICATION,//  we will create subquery expression of boolean type 
Hive,WITHOUT_CLASSIFICATION,/*    * todo: fix https://issues.apache.org/jira/browse/HIVE-9995   * @throws Exception    */
Hive,WITHOUT_CLASSIFICATION,//  This is a valid YARN Service name. Parse it out. 
Hive,WITHOUT_CLASSIFICATION,//  Default value is empty string in which case no properties will be inherited. 
Hive,WITHOUT_CLASSIFICATION,//  reset to the hive-site.xml values for following param 
Hive,WITHOUT_CLASSIFICATION,//  Create the un-grouped splits 
Hive,WITHOUT_CLASSIFICATION,//  Not using the gauge to avoid races. 
Hive,WITHOUT_CLASSIFICATION,//  All data intitializations 
Hive,WITHOUT_CLASSIFICATION,//  If any table is empty an inner join involving the tables should yield 0 rows. 
Hive,WITHOUT_CLASSIFICATION,//  keep the arguments for reference - we want all the non-numeric   arguments to be the same 
Hive,WITHOUT_CLASSIFICATION,//  Trying using the cardinality from the value range. 
Hive,WITHOUT_CLASSIFICATION,//  Go through all joins - it should only contain selects and filters between 
Hive,WITHOUT_CLASSIFICATION,//  currently getProcedureColumns always returns an empty resultset for Hive 
Hive,WITHOUT_CLASSIFICATION,//  can be null in-case of junit tests. skip reset.   reset thread name at release time. 
Hive,WITHOUT_CLASSIFICATION,//  We skipped 'like' other ops should all work as long as the types are right. 
Hive,WITHOUT_CLASSIFICATION,//  Arithmetic with a type date (LongColumnVector storing epoch days) and type interval_day_time (IntervalDayTimeColumnVector storing 
Hive,WITHOUT_CLASSIFICATION,//  Convert the Accumulo token in a Hadoop token 
Hive,WITHOUT_CLASSIFICATION,/*    * is this expr a UDAF invocation; does it imply windowing   * @return   * 0 if implies neither   * 1 if implies aggregation   * 2 if implies count   * 3 if implies windowing    */
Hive,WITHOUT_CLASSIFICATION,// if here txn was not found (in expected state) 
Hive,WITHOUT_CLASSIFICATION,//  Change different fields and verify they were altered 
Hive,WITHOUT_CLASSIFICATION,//  Create session domain if not present 
Hive,WITHOUT_CLASSIFICATION,// put the new mapping 
Hive,WITHOUT_CLASSIFICATION,//  create a fake directory to throw exception 
Hive,WITHOUT_CLASSIFICATION,//  Assume db and table names are the same for all partition as provided in arguments. 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) Extends  */
Hive,WITHOUT_CLASSIFICATION,//  We found the Union 
Hive,WITHOUT_CLASSIFICATION,//  2) Build conditions for join and filter and start adding 
Hive,WITHOUT_CLASSIFICATION,/*  * An bytes key hash set optimized for vector map join. * * This is the abstract base for the multi-key and string bytes key hash set implementations.  */
Hive,WITHOUT_CLASSIFICATION,//  An optional byte array of FastHiveDecimal.FAST_SCRATCH_BUFFER_LEN_BIG_INTEGER_BYTES. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setObject(int java.lang.Object)    */
Hive,WITHOUT_CLASSIFICATION,//  Table itself doesn't exist in metastore nothing to validate. 
Hive,WITHOUT_CLASSIFICATION,//  MSCK called to add missing paritions into metastore and there are   missing partitions. 
Hive,WITHOUT_CLASSIFICATION,//  Cache pathExpr 
Hive,WITHOUT_CLASSIFICATION,//  Ignore shutdown errors since there are negative tests 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise if enabled deserialize rows using regular Serde and add the object   inspect-able Object[] row to a VectorizedRowBatch in the VectorMapOperator. 
Hive,WITHOUT_CLASSIFICATION,//  count number of digits in the value 
Hive,WITHOUT_CLASSIFICATION,//  Note here we create a fake directory along with fake files as original directories/files 
Hive,WITHOUT_CLASSIFICATION,//  return zz for "xx + yy AS zz" 
Hive,WITHOUT_CLASSIFICATION,//  Skip 
Hive,WITHOUT_CLASSIFICATION,// private static final String testTableName = "auto_purge_test_table"; 
Hive,WITHOUT_CLASSIFICATION,//  No deserialization of key(s) here -- just get reference to bytes. 
Hive,WITHOUT_CLASSIFICATION,//  validate the metadata for the getColumns result set 
Hive,WITHOUT_CLASSIFICATION,//  Bigger addition. 
Hive,WITHOUT_CLASSIFICATION,//  first set back the backup task with its children task. 
Hive,WITHOUT_CLASSIFICATION,//  authenticate using delegation tokens via the "DIGEST" mechanism 
Hive,WITHOUT_CLASSIFICATION,//  write stats objs persistently 
Hive,WITHOUT_CLASSIFICATION,//  TODO: plumb progress info thru the reader if we can get metadata from loader first. 
Hive,WITHOUT_CLASSIFICATION,/*    * HiveMetaStore keys reserved for updating ListenerEvent parameters.   *   * HIVE_METASTORE_TRANSACTION_ACTIVE This key is used to check if a listener event is run inside a current   *                                   transaction. A boolean value is used for active (true) or no active (false).    */
Hive,WITHOUT_CLASSIFICATION,//  4M 
Hive,WITHOUT_CLASSIFICATION,//  Hadoop vars 
Hive,WITHOUT_CLASSIFICATION,//  Boolean to store information about whether valid txn list was generated 
Hive,WITHOUT_CLASSIFICATION,// need to determine if a different type is needed for dummy partitions 
Hive,WITHOUT_CLASSIFICATION,//  ignore zero-divide cases 
Hive,WITHOUT_CLASSIFICATION,//  replication scope allows replacement and does not require empty directories 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:GroupInputSpecProto) 
Hive,WITHOUT_CLASSIFICATION,//  This is the last time we'll see the Table objects for views so add it to the inputs   now. isInsideView will tell if this view is embedded in another view. 
Hive,WITHOUT_CLASSIFICATION,//  For bootstrap load the create function should be always performed. 
Hive,WITHOUT_CLASSIFICATION,//  Determine which rows are non matches by determining the delta between inputSelected and   (current) batch selected. 
Hive,WITHOUT_CLASSIFICATION,//  Create the 'hive' catalog 
Hive,WITHOUT_CLASSIFICATION,//  basePersistDirectory - use druid default no need to be configured by user 
Hive,WITHOUT_CLASSIFICATION,//  These represent the bucketed columns 
Hive,WITHOUT_CLASSIFICATION,//  Reuse an existing connection 
Hive,WITHOUT_CLASSIFICATION,/* note that will throw if Anonymous mode is not allowed & user.name is not in query string of the request;      * this ensures that in the context of WebHCat PseudoAuthenticationHandler allows Anonymous even though      * WebHCat itself will throw if it can't figure out user.name */
Hive,WITHOUT_CLASSIFICATION,//  No alphabet needed. 
Hive,WITHOUT_CLASSIFICATION,/*      * Write a bunch of random rows that will be used for read benchmark.      */
Hive,WITHOUT_CLASSIFICATION,//  (End user) Transaction timeout in milliseconds. 
Hive,WITHOUT_CLASSIFICATION,//  First entry.   Existence. 
Hive,WITHOUT_CLASSIFICATION,//  Remove old temp table entry and add new entry to list of temp tables. 
Hive,WITHOUT_CLASSIFICATION,//  frequently occurring error 
Hive,WITHOUT_CLASSIFICATION,//  Normalize   i.e. significand is even 
Hive,WITHOUT_CLASSIFICATION,//  version with SEQ   version with RCF 
Hive,WITHOUT_CLASSIFICATION,//  append the path substring since previous match 
Hive,WITHOUT_CLASSIFICATION,//  Don't bother with aggregation in this case it will probably be invalid. 
Hive,WITHOUT_CLASSIFICATION,//  Failure / help 
Hive,WITHOUT_CLASSIFICATION,//  optional bool is_guaranteed = 2; 
Hive,WITHOUT_CLASSIFICATION,//  Second time. 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:QueryCompleteRequestProto) 
Hive,WITHOUT_CLASSIFICATION,//  null :: for non - partitioned table. 
Hive,WITHOUT_CLASSIFICATION,//  After all the rows are processed continue to generate results for the rows that results haven't generated.   For the case: X following and Y following process first Y-X results and then insert X nulls.   For the case X preceding and Y following process Y results. 
Hive,WITHOUT_CLASSIFICATION,//  Setting an empty collection of ranges will unexpectedly scan all data 
Hive,WITHOUT_CLASSIFICATION,//  skip the big table pos 
Hive,WITHOUT_CLASSIFICATION,//  first search from the posToVertex 
Hive,WITHOUT_CLASSIFICATION,//  ppd for multi-insert query is not yet implemented   we assume that nothing can is pushed beyond this operator 
Hive,WITHOUT_CLASSIFICATION,//  We haven't fixed the TMP path for this mapper yet 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#close()    */
Hive,WITHOUT_CLASSIFICATION,//  Test that two different tables don't collide on their locks 
Hive,WITHOUT_CLASSIFICATION,//  Note: this assumes both paths are qualified; which they are currently. 
Hive,WITHOUT_CLASSIFICATION,//  VarChar 
Hive,WITHOUT_CLASSIFICATION,// lazy-caching of the version. 
Hive,WITHOUT_CLASSIFICATION,//  Note that we use the same vectors in both batches. Clever very clever. 
Hive,WITHOUT_CLASSIFICATION,//  AST specific data 
Hive,WITHOUT_CLASSIFICATION,//  2. Build Rel for where Clause 
Hive,WITHOUT_CLASSIFICATION,//  Delete the temp file if the JVM terminate normally through Hadoop job   kill command.   Caveat: it won't be deleted if JVM is killed by 'kill -9'. 
Hive,WITHOUT_CLASSIFICATION,//  Important signum is given by the firstByte not by byte[keep]! 
Hive,WITHOUT_CLASSIFICATION,//  entry 2 will be null due to zero-divide 
Hive,WITHOUT_CLASSIFICATION,// these have been localized already 
Hive,WITHOUT_CLASSIFICATION,//  If lists recursively compare the list element types 
Hive,WITHOUT_CLASSIFICATION,//  clear out the union set. we don't need it anymore. 
Hive,WITHOUT_CLASSIFICATION,//  Note: this is called by someone who has ensured the buffer is not going to be moved. 
Hive,WITHOUT_CLASSIFICATION,//  Get the field objectInspector fieldName and the field object. 
Hive,WITHOUT_CLASSIFICATION,//  1. Get agg fn ret type in Calcite 
Hive,WITHOUT_CLASSIFICATION,// --------------------------- PTF handling ----------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  Update has failed. We won't try a low pri task. 
Hive,WITHOUT_CLASSIFICATION,//  using vint instead of 4 bytes 
Hive,WITHOUT_CLASSIFICATION,//  Create case sensitive columns list 
Hive,WITHOUT_CLASSIFICATION,// needed by kyro 
Hive,WITHOUT_CLASSIFICATION,//  Only set A = B command needs updating the configuration stored in client side. 
Hive,WITHOUT_CLASSIFICATION,//  If the field that is passed in is NOT a primitive and either the   field is not declared (no schema was given at initialization) or   the field is declared as a primitive in initialization serialize   the data to JSON string. Otherwise serialize the data in the 
Hive,WITHOUT_CLASSIFICATION,// assert !frame.corVarOutputPos.isEmpty(); 
Hive,WITHOUT_CLASSIFICATION,//  Bucket count 
Hive,WITHOUT_CLASSIFICATION,//           The first query happens to have 2 full batches. 
Hive,WITHOUT_CLASSIFICATION,//  The primitives. 
Hive,WITHOUT_CLASSIFICATION,//  Change the resource plan - resize B and C down D up and remove A remapping users to B.   Everything will be killed in A and B C won't change D will start one more query from   the queue and the query queued in A will be re-queued in B and started.   The fractions will also all change. 
Hive,WITHOUT_CLASSIFICATION,// test getLogicalLength() w/o side file 
Hive,WITHOUT_CLASSIFICATION,//  It's ok to skip a failed message if the target has changed back to the old value. 
Hive,WITHOUT_CLASSIFICATION,//  Check that the values in the older list are also in newer. Lists should already be sorted. 
Hive,WITHOUT_CLASSIFICATION,/*  * SemanticException.java * * Created on April 1 2008 1:20 PM * * To change this template choose Tools | Template Manager * and open the template in the editor.  */
Hive,WITHOUT_CLASSIFICATION,//  Store token in the cache 
Hive,WITHOUT_CLASSIFICATION,//  versions dont match return false. 
Hive,WITHOUT_CLASSIFICATION,//  The list of families that have been added to the scan 
Hive,WITHOUT_CLASSIFICATION,//  empty maps 
Hive,WITHOUT_CLASSIFICATION,//  Initialize the constants for the grouping sets so that they can be re-used for 
Hive,WITHOUT_CLASSIFICATION,//  Merge bytes 
Hive,WITHOUT_CLASSIFICATION,/*  1 files x 100 size for 99 splits  */
Hive,WITHOUT_CLASSIFICATION,//  to keep backward compatibility 
Hive,WITHOUT_CLASSIFICATION,//  no files in the partition 
Hive,WITHOUT_CLASSIFICATION,/*        * Repeating THEN expression?        */
Hive,WITHOUT_CLASSIFICATION,//  generate map reduce plans 
Hive,WITHOUT_CLASSIFICATION,//  SW.SR: Lock we are examining is shared read 
Hive,WITHOUT_CLASSIFICATION,//  Trim the bins down to the correct number of bins. 
Hive,WITHOUT_CLASSIFICATION,/*    * Lookup a byte array key in the hash map.   *   * @param keyBytes   *         A byte array containing the key within a range.   * @param keyStart   *         The offset the beginning of the key.   * @param keyLength   *         The length of the key.   * @param hashMapResult   *         The object to receive small table value(s) information on a MATCH.   *         Or for SPILL it has information on where to spill the big table row.   *   * @return   *         Whether the lookup was a match no match or spill (the partition with the key   *         is currently spilled).    */
Hive,WITHOUT_CLASSIFICATION,//  Found an exact match 
Hive,WITHOUT_CLASSIFICATION,//  We are missing a section at the end of the part... copy the start to non-cached. 
Hive,WITHOUT_CLASSIFICATION,//  needs at least --instances 
Hive,WITHOUT_CLASSIFICATION,//  4. Validate the effective Window Frames with the rules in {@link validateWindowFrame} 
Hive,WITHOUT_CLASSIFICATION,//  partition level column statistics test 
Hive,WITHOUT_CLASSIFICATION,//  This lock is used to make sure removalListener won't close a client that is being contemplated for returning by get() 
Hive,WITHOUT_CLASSIFICATION,//  thread local filesystem stats is private and cannot be cloned. So make a copy to new class 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#setHoldability(int)    */
Hive,WITHOUT_CLASSIFICATION,//  Fully copy over the contents of the new SD into the old SD 
Hive,WITHOUT_CLASSIFICATION,// view just being created   already created view being loaded 
Hive,WITHOUT_CLASSIFICATION,//  Each range checks for overflow first then moves digits. 
Hive,WITHOUT_CLASSIFICATION,/*      * @since 1.3.0     * This can be set to -1 to make the system generate old style (delta_xxxx_yyyy) file names.     * This is primarily needed for testing to make sure 1.3 code can still read files created     * by older code.  Also used by Comactor.      */
Hive,WITHOUT_CLASSIFICATION,//  Now release another session; the thread that gave up on reuse can proceed. 
Hive,WITHOUT_CLASSIFICATION,//  see autoColumnStats_2.q under TestMiniLlapLocalCliDriver 
Hive,WITHOUT_CLASSIFICATION,//  Merge cost 
Hive,WITHOUT_CLASSIFICATION,//  This currently only happens in tests. See getFileData comment on the interface. 
Hive,WITHOUT_CLASSIFICATION,//        AM reg info changes; add notifications ignore errors and update alloc. 
Hive,WITHOUT_CLASSIFICATION,// say table T has partition p we are generating  select cardinality_violation(ROW_ID p) WHERE ... GROUP BY ROW__ID p 
Hive,WITHOUT_CLASSIFICATION,//  there to avoid clashes. 
Hive,WITHOUT_CLASSIFICATION,//  Extract the bits of num into bytes[] from right to left 
Hive,WITHOUT_CLASSIFICATION,//  When we are doing row deserialization these are the regular deserializer   partition object inspector and vector row assigner. 
Hive,WITHOUT_CLASSIFICATION,//  optional int32 num_self_and_upstream_completed_tasks = 2; 
Hive,WITHOUT_CLASSIFICATION,/*  several hive classes depend on the metastore APIs which is not included             * in hive-exec.jar. These are the relatively safe ones - operators & io classes.              */
Hive,WITHOUT_CLASSIFICATION,//  Revert the projected columns back because vrg will be re-used. 
Hive,WITHOUT_CLASSIFICATION,//  sure that NULL is produced. 
Hive,WITHOUT_CLASSIFICATION,//  an object of Map 
Hive,WITHOUT_CLASSIFICATION,//  Make a copy of the source-table as would be done across class-loaders. 
Hive,WITHOUT_CLASSIFICATION,//  If a child of this expression uses a materialized view   then we decrease its cost by a certain factor. This is   useful for e.g. partial rewritings where a part of plan   does not use the materialization but we still want to   decrease its cost so it is chosen instead of the original   plan 
Hive,WITHOUT_CLASSIFICATION,//  The BigDecimal class recommends not converting directly from double to BigDecimal   so we convert through a string... 
Hive,WITHOUT_CLASSIFICATION,//  Whatever remains.   Take toTake blocks by splitting the block at offset. 
Hive,WITHOUT_CLASSIFICATION,//  NAME 
Hive,WITHOUT_CLASSIFICATION,//  select * constant and casts can be allowed without a threshold check 
Hive,WITHOUT_CLASSIFICATION,// There were no more batches AND  this is either the first batch or we've used up the current batch buffer.  goto return false 
Hive,WITHOUT_CLASSIFICATION,//  virtual columns needed 
Hive,WITHOUT_CLASSIFICATION,//  If unable to find stats for this StatsType return null so we can build stats 
Hive,WITHOUT_CLASSIFICATION,//  acc is short for accumulator. It's used to build the row before forwarding 
Hive,WITHOUT_CLASSIFICATION,//  rowId <= 'd' 
Hive,WITHOUT_CLASSIFICATION,// change the location of position alias process here 
Hive,WITHOUT_CLASSIFICATION,//  Keys are always primitive 
Hive,WITHOUT_CLASSIFICATION,//  We have to evaluate the input format to see if vectorization is enabled so   we do not set it right here. 
Hive,WITHOUT_CLASSIFICATION,//  Update the cache to add this new aggregate node 
Hive,WITHOUT_CLASSIFICATION,//  Find most significant bit with starting index as 0 
Hive,WITHOUT_CLASSIFICATION,//  Just run our value expressions over input batch. 
Hive,WITHOUT_CLASSIFICATION,//  test getBoolean rules on non-boolean columns 
Hive,WITHOUT_CLASSIFICATION,//  block. 
Hive,WITHOUT_CLASSIFICATION,//  Gather input works operators 
Hive,WITHOUT_CLASSIFICATION,//  key/value of the index is removed. retrieve memory usage 
Hive,WITHOUT_CLASSIFICATION,//  TODO: Convert to Semantic Exception 
Hive,WITHOUT_CLASSIFICATION,//  First try to use the blocks of half size in every arena. 
Hive,WITHOUT_CLASSIFICATION,//  give the cloned work a different name 
Hive,WITHOUT_CLASSIFICATION,// "originals" (written before table was converted to acid) is considered written by   writeid:0 which is always committed so there is no need to check wrt invalid write Ids  But originals written by Load Data for example can be in base_x or delta_x_x so we must  check if 'x' is committed or not evn if ROW_ID is not needed in the Operator pipeline. 
Hive,WITHOUT_CLASSIFICATION,//  "." : FIELD Expression 
Hive,WITHOUT_CLASSIFICATION,//  Unless this is overridden it does nothing 
Hive,WITHOUT_CLASSIFICATION,//  > 100 
Hive,WITHOUT_CLASSIFICATION,//  Return something. 
Hive,WITHOUT_CLASSIFICATION,//  given an ast node this method recursively goes over checkExpr ast. If it finds a node of type TOK_SUBQUERY_EXPR   it throws an error. 
Hive,WITHOUT_CLASSIFICATION,//  under exceptional load hadoop may not be able to look up status   of finished jobs (because it has purged them from memory). From   hive's perspective - it's equivalent to the job having failed.   So raise a meaningful exception 
Hive,WITHOUT_CLASSIFICATION,//  4. Perform a major compaction 
Hive,WITHOUT_CLASSIFICATION,//  -------------------------------- Second Pass ---------------------------------- //   Process operator tree in two steps: first we process the extra op trees generated   in the first pass. Then we process the main op tree and the result task will depend 
Hive,WITHOUT_CLASSIFICATION,// create scratch dir 
Hive,WITHOUT_CLASSIFICATION,//  case when mv2.deptno IS NULL AND mv2.deptname IS NULL then s else source.s + mv2.s end 
Hive,WITHOUT_CLASSIFICATION,/*              * Single-Column String outer get key.              */
Hive,WITHOUT_CLASSIFICATION,//  Since left has a longer digit tail and it doesn't move; we will shift the right digits   as we do our addition into the result. 
Hive,WITHOUT_CLASSIFICATION,//  we are in secure mode. 
Hive,WITHOUT_CLASSIFICATION,//  to return to a previous block. 
Hive,WITHOUT_CLASSIFICATION,//  The primitive object inspector of the source data type for any column being   converted.  Otherwise null. 
Hive,WITHOUT_CLASSIFICATION,//  print out all the stages that have no childStages. 
Hive,WITHOUT_CLASSIFICATION,//  Assume. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure the token made it into the UGI 
Hive,WITHOUT_CLASSIFICATION,//  HashStruct 
Hive,WITHOUT_CLASSIFICATION,//  1) test with txn.Commit() 
Hive,WITHOUT_CLASSIFICATION,//  Now finish task1 which will make capacity for task3 to run. Nothing is coming out of the delayed queue yet. 
Hive,WITHOUT_CLASSIFICATION,//  reset the result for the evicted index 
Hive,WITHOUT_CLASSIFICATION,// GenericUDFBridge udfBridge = (GenericUDFBridge) expr.getGenericUDF(); 
Hive,WITHOUT_CLASSIFICATION,//  drop any functions before dropping db 
Hive,WITHOUT_CLASSIFICATION,//  Apply the group and permissions to the leaf partition and files.   Need not bother in case of HDFS as permission is taken care of by setting UMask 
Hive,WITHOUT_CLASSIFICATION,//  For cases where the table is temporary 
Hive,WITHOUT_CLASSIFICATION,//  not an hbase row key. This should either be a prefix or an individual qualifier 
Hive,WITHOUT_CLASSIFICATION,//  Tests that different threads get the same object per attempt per input and different   between attempts/inputs; that attempt is inherited between threads; and that clearing   the attempt produces a different result. 
Hive,WITHOUT_CLASSIFICATION,//  get privileges for this user and its role on this object 
Hive,WITHOUT_CLASSIFICATION,//  Make certain the target directory exists. 
Hive,WITHOUT_CLASSIFICATION,/*  the following test uses a query that returns a group and a user entry.       the ldap atn should use the groupMembershipKey to identify the users for the returned group       and the authentication should succeed for the users of that group as well as the lone user4 in this case     */
Hive,WITHOUT_CLASSIFICATION,//  Pass the request on to the responder 
Hive,WITHOUT_CLASSIFICATION,//  This should never be thrown. 
Hive,WITHOUT_CLASSIFICATION,//  COLUMN_NAME 
Hive,WITHOUT_CLASSIFICATION,//  14. Give our final state to UI/API requests if any. 
Hive,WITHOUT_CLASSIFICATION,/*  We'll assume that there *may* be nulls in the input if !noNulls is true       * for an input vector. This is to be more forgiving of errors in loading       * the vectors. A properly-written vectorized iterator will make sure that       * isNull[0] is set if !noNulls and isRepeating are true for the vector.        */
Hive,WITHOUT_CLASSIFICATION,//  wait for failover to close sessions 
Hive,WITHOUT_CLASSIFICATION,/*        * For this particular file how many columns will we actually read?        */
Hive,WITHOUT_CLASSIFICATION,//  FOREIGN_KEY_COLS 
Hive,WITHOUT_CLASSIFICATION,//  Second value. 
Hive,WITHOUT_CLASSIFICATION,//  Verify SerializationUtils first. 
Hive,WITHOUT_CLASSIFICATION,//  we pushed the whole thing down 
Hive,WITHOUT_CLASSIFICATION,//  To avoid timing issues with notifications (and given that HDFS check is anyway the   authoritative one) don't wait infinitely for the notifier just wait a little bit 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see   * org.apache.hadoop.hive.ql.exec.UDFMethodResolver#getEvalMethod(java.util   * .List)    */
Hive,WITHOUT_CLASSIFICATION,//  time to actually run the dag (actual dag runtime) 
Hive,WITHOUT_CLASSIFICATION,//  FKTABLE_NAME 
Hive,WITHOUT_CLASSIFICATION,//  Find functions which name contains _to_find_ or _hidden_ in the default database 
Hive,WITHOUT_CLASSIFICATION,//  Create argument capturer   a class variable cast to this generic of generic class 
Hive,WITHOUT_CLASSIFICATION,//  only user belonging to admin role can drop existing role 
Hive,WITHOUT_CLASSIFICATION,//  optional int32 key_id = 4; 
Hive,WITHOUT_CLASSIFICATION,//  Expected to fail due to canceled token 
Hive,WITHOUT_CLASSIFICATION,//  TODO: Make use of this config to configure fetch size 
Hive,WITHOUT_CLASSIFICATION,// this should use HiveChar.getPaddedValue() but it's protected; currently (v0.13) 
Hive,WITHOUT_CLASSIFICATION,//  need to create the correct table descriptor for key/value 
Hive,WITHOUT_CLASSIFICATION,// exclude trailing comma 
Hive,WITHOUT_CLASSIFICATION,//  2. Add Dist UDAF args to reduce keys 
Hive,WITHOUT_CLASSIFICATION,//  Evaluate the key expressions of just this first batch to get the correct key. 
Hive,WITHOUT_CLASSIFICATION,//  need to iterate through all children even if one is found to be not a   candidate   in case if the other children could be individually pushed up 
Hive,WITHOUT_CLASSIFICATION,//  try to be more tolerant   if the input is invalid instead of incomplete we'll hit exception here again 
Hive,WITHOUT_CLASSIFICATION,/*  Cookies Manager is used to cache cookie returned by service.       The goal us to avoid doing KDC requests for every request. */
Hive,WITHOUT_CLASSIFICATION,//  find all targets recursively 
Hive,WITHOUT_CLASSIFICATION,//  Leverage the nice batching behaviour of async Loggers/Appenders:   we can signal the file manager that it needs to flush the buffer   to disk at the end of a batch.   From a user's point of view this means that all log events are   _always_ available in the log file without incurring the overhead   of immediateFlush=true. 
Hive,WITHOUT_CLASSIFICATION,//  Exists primarily to allow for easier unit tests. 
Hive,WITHOUT_CLASSIFICATION,//  register two tasks of same query but different am 
Hive,WITHOUT_CLASSIFICATION,//  For completed instances 
Hive,WITHOUT_CLASSIFICATION,//  print out the cbo info 
Hive,WITHOUT_CLASSIFICATION,/*  * Interface Design: * A TableFunction provides 2 interfaces of execution 'Batch' and 'Streaming'. * - In Batch mode the contract is Partition in - Partition Out * - In Streaming mode the contract is a stream of processRow calls - each of which may return 0 or more rows. *  * A Partition is not just a batch of rows it enables more than a single iteration of * the i/p data: multiple passes arbitrary access of input rows relative navigation between * rows(for e.g. lead/lag fns). Most PTFs will work in batch mode. *  * The Streaming mode gives up on the capabilities of Partitions for the benefit of smaller footprint * and faster processing. Window Function processing is an e.g. of this: when there are only Ranking * functions each row needs to be accessed once in the order it is provided; hence there is no need  * to hold all input rows in a Partition. The 'pattern' is: any time you want to only enhance/enrich  * an Input Row Streaming mode is the right choice. This is the fundamental difference between Ranking * fns and UDAFs: Ranking functions keep the original data intact whereas UDAF only return aggregate * information. *  * Finally we have provided a 'mixed' mode where a non Streaming TableFunction can provide its output * as an Iterator. As far as we can tell this is a special case for Windowing handling. If Windowing * is the only or last TableFunction in a chain it makes no sense to collect the output rows into a  * output Partition. We justify the pollution of the api by the observation that Windowing is a very  * common use case. *   */
Hive,WITHOUT_CLASSIFICATION,/*  It's valid case if a partition:  */
Hive,WITHOUT_CLASSIFICATION,//  Finally we remove the expression from the tree 
Hive,WITHOUT_CLASSIFICATION,//  these 5 delims passed as serde params 
Hive,WITHOUT_CLASSIFICATION,//  Tracks all instances including ones which have been disabled in the past. 
Hive,WITHOUT_CLASSIFICATION,//  Login from the keytab 
Hive,WITHOUT_CLASSIFICATION,//  Serialize the struct into a mutation 
Hive,WITHOUT_CLASSIFICATION,//  init input 
Hive,WITHOUT_CLASSIFICATION,//  INCLUDE_BITSET 
Hive,WITHOUT_CLASSIFICATION,//  Prefer date type arguments over other method signatures 
Hive,WITHOUT_CLASSIFICATION,/*    * It is a idempotent function to add various intermediate files as the source   * for the union. The plan has already been created.    */
Hive,WITHOUT_CLASSIFICATION,//  IS_SET_DEFAULT_POOL_PATH 
Hive,WITHOUT_CLASSIFICATION,// https://msdn.microsoft.com/en-us/library/ms189499.aspx  https://msdn.microsoft.com/en-us/library/ms187373.aspx 
Hive,WITHOUT_CLASSIFICATION,//  Blindly add this as a union type containing int and double!   Should be sufficient for the test case. 
Hive,WITHOUT_CLASSIFICATION,//  If the second operator has more than one child we stop gathering 
Hive,WITHOUT_CLASSIFICATION,//  If the filter is already on top of a TableScan 
Hive,WITHOUT_CLASSIFICATION,//  Find the first ancestor of this MoveTask which is some form of map reduce task   (Either standard local or a merge) 
Hive,WITHOUT_CLASSIFICATION,//  1. Construct ExpressionNodeDesc representing Join Condition 
Hive,WITHOUT_CLASSIFICATION,//  Array for the values to pass to evaluator. 
Hive,WITHOUT_CLASSIFICATION,//  End of master thread state 
Hive,WITHOUT_CLASSIFICATION,/*    * An implementation of KvSource that can handle key and value as BytesWritable objects.    */
Hive,WITHOUT_CLASSIFICATION,//  Return a single ArrayList where the first element is the number of histogram bins   and subsequent elements represent histogram (xy) pairs. 
Hive,WITHOUT_CLASSIFICATION,//  used for dynamic partitioning 
Hive,WITHOUT_CLASSIFICATION,//  With the integer type range checking we need to know the Hive data type. 
Hive,WITHOUT_CLASSIFICATION,// abort all remaining txns 
Hive,WITHOUT_CLASSIFICATION,/*  100 files x 1000 size for 11 splits  */
Hive,WITHOUT_CLASSIFICATION,//  Close file streams to avoid resource leaking 
Hive,WITHOUT_CLASSIFICATION,//  For now this can simply be fetched from a single registry instance. 
Hive,WITHOUT_CLASSIFICATION,//  If there is no "AS" clause the output schema will be "keyvalue" 
Hive,WITHOUT_CLASSIFICATION,//  10^16 
Hive,WITHOUT_CLASSIFICATION,//  Note: other standard ones include e.g. ClientUser and ClientHostname         but we don't need them for now. 
Hive,WITHOUT_CLASSIFICATION,// get KeyValuesReaders from the LogicalInput and add them to priority queue 
Hive,WITHOUT_CLASSIFICATION,//  Notify listeners of the changed value 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   * we should ideally not modify the tree we traverse.   * However since we need to walk the tree at any time when we modify the operator   * we might as well do it here.    */
Hive,WITHOUT_CLASSIFICATION,//  There should be 2 delta dirs plus 2 base dirs in the location 
Hive,WITHOUT_CLASSIFICATION,//  Now deprecated. 
Hive,WITHOUT_CLASSIFICATION,//  Adjust the memory - we have to account for what we have just evicted. 
Hive,WITHOUT_CLASSIFICATION,//  OWNER_TYPE 
Hive,WITHOUT_CLASSIFICATION,//  hash table loading happens in server side LlapDecider could kick out some fragments to run outside of LLAP.   Flip the flag at runtime in case if we are running outside of LLAP 
Hive,WITHOUT_CLASSIFICATION,//  How many ways each block splits into target size.   How many target-sized blocks remain from last split.   The header index for the beginning of the remainder. 
Hive,WITHOUT_CLASSIFICATION,//  A very simple counter to keep track of join entries for a key 
Hive,WITHOUT_CLASSIFICATION,//  This is an operator - so check whether it is unary or binary operator 
Hive,WITHOUT_CLASSIFICATION,// Divide operations are not CHECKED because the output is always of the type double 
Hive,WITHOUT_CLASSIFICATION,//  only the pattern of "VALUE._col([0-9]+)" should be handled. 
Hive,WITHOUT_CLASSIFICATION,//  4. Construct JoinLeafPredicateInfo 
Hive,WITHOUT_CLASSIFICATION,//  For some strange reason BigDecimal 0 can have a scale.  We do not support that. 
Hive,WITHOUT_CLASSIFICATION,// a convenience method that makes the intended owner for the delegation  token request the current user 
Hive,WITHOUT_CLASSIFICATION,//  Also determine if any nulls are present since for a join that means no match. 
Hive,WITHOUT_CLASSIFICATION,//  remove the context words from the end of the list 
Hive,WITHOUT_CLASSIFICATION,//  stripeRgs should have been initialized by this time with an empty array. 
Hive,WITHOUT_CLASSIFICATION,//  create the reloading folder to place jar files if not exist 
Hive,WITHOUT_CLASSIFICATION,//  Look for Pass-Thru case where InputFileFormat has VectorizedInputFormatInterface   and reads VectorizedRowBatch as a "row". 
Hive,WITHOUT_CLASSIFICATION,//  Fix up the case where parent expression's output data type physical variations is DECIMAL whereas   at least one of its children is DECIMAL_64. Some expressions like x % y for example only accepts DECIMAL   for x and y (at this time there is only DecimalColModuloDecimalColumn so both x and y has to be DECIMAL). 
Hive,WITHOUT_CLASSIFICATION,// must get statementId from file name since Acid 1.0 doesn't write it into bucketProperty 
Hive,WITHOUT_CLASSIFICATION,//  nulls on right no nulls on left 
Hive,WITHOUT_CLASSIFICATION,//  if ndvProduct is 0 then column stats state must be partial and we are missing 
Hive,WITHOUT_CLASSIFICATION,//  validate that the set of partition columns found in custom path must match 
Hive,WITHOUT_CLASSIFICATION,//  TODO: unpause fetching 
Hive,WITHOUT_CLASSIFICATION,//  if copy of jar to change management fails we fail the metastore transaction since the   user might delete the jars on HDFS externally after dropping the function hence having 
Hive,WITHOUT_CLASSIFICATION,//  fails the finally clause will remove the lock 
Hive,WITHOUT_CLASSIFICATION,//  we'll encode the absolute value (sign is separate) 
Hive,WITHOUT_CLASSIFICATION,//  Java TimeZone has no mention of thread safety. Use thread local instance to be safe. 
Hive,WITHOUT_CLASSIFICATION,//  [A: 1 B: 0] 
Hive,WITHOUT_CLASSIFICATION,//  reset the array to null values 
Hive,WITHOUT_CLASSIFICATION,//  This removes order-by only expressions from the projections. 
Hive,WITHOUT_CLASSIFICATION,//  no partitions bail early. 
Hive,WITHOUT_CLASSIFICATION,//  Make the columns list for the temp table (input data file). 
Hive,WITHOUT_CLASSIFICATION,//  InputStream open if the given sequence file is broken) to RCFile 
Hive,WITHOUT_CLASSIFICATION,//  In current implementation it will never happen but we leave it   here to make the logic complete. 
Hive,WITHOUT_CLASSIFICATION,//  Try to get the session quickly. 
Hive,WITHOUT_CLASSIFICATION,//  10^15 
Hive,WITHOUT_CLASSIFICATION,//  Here we do some query rewrite. We first get the new fetchRN which is   a sum of offset and fetch.   We then push it through by creating a new branchSort with the new   fetchRN but no offset. 
Hive,WITHOUT_CLASSIFICATION,//  optional string container_id_string = 5; 
Hive,WITHOUT_CLASSIFICATION,//  Check the restricted configs that the users cannot set. 
Hive,WITHOUT_CLASSIFICATION,//  Insert some data -> this will again generate only insert deltas and no delete deltas: delta_4_4 
Hive,WITHOUT_CLASSIFICATION,//  Expected exception - Embedded MetaStore 
Hive,WITHOUT_CLASSIFICATION,//  If the user has specified a location - external or not check if the user 
Hive,WITHOUT_CLASSIFICATION,//  We need to copy the data byte by byte only in case the   "outputLength < length" (which means there is at least one escaped 
Hive,WITHOUT_CLASSIFICATION,//  If the view is Inside another view it should have at least one parent 
Hive,WITHOUT_CLASSIFICATION,//  Read database via CachedStore 
Hive,WITHOUT_CLASSIFICATION,//  TEZ..) 
Hive,WITHOUT_CLASSIFICATION,//  Generate the partition columns from the parent input 
Hive,WITHOUT_CLASSIFICATION,//  Test incorrect totals. We don't normalize; just make sure we don't under- or overshoot. 
Hive,WITHOUT_CLASSIFICATION,//  The table containing the partition is not yet loaded in cache 
Hive,WITHOUT_CLASSIFICATION,//  collect the hiveConfList and HiveVarList separately so that they can be 
Hive,WITHOUT_CLASSIFICATION,//  Job properties are only relevant for non-native tables so   for native tables leave it null to avoid cluttering up 
Hive,WITHOUT_CLASSIFICATION,/*  Output of final result of the aggregation      */
Hive,WITHOUT_CLASSIFICATION,//  USER_NAME 
Hive,WITHOUT_CLASSIFICATION,//  create some "cover" to the result? 
Hive,WITHOUT_CLASSIFICATION,//  Metastore always support concurrency but certain ACID tests depend on this being set.  We 
Hive,WITHOUT_CLASSIFICATION,//  Verify dropPartition recycle part files 
Hive,WITHOUT_CLASSIFICATION,//  isRepeating and no nulls 
Hive,WITHOUT_CLASSIFICATION,/*  Move common logic to PrunerUtils.walkExprTree(...) so that it can be reused.  */
Hive,WITHOUT_CLASSIFICATION,//  The expression to identify the partition to be dropped 
Hive,WITHOUT_CLASSIFICATION,//  This method gets called only in the scope that a destination table already exists so   we're validating if the table is an appropriate destination to import into 
Hive,WITHOUT_CLASSIFICATION,//  With trim=false parsing cannot handle spaces 
Hive,WITHOUT_CLASSIFICATION,//  Read all credentials into the credentials instance stored in JobConf. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see   * org.apache.hadoop.hive.ql.optimizer.Transform#transform(org.apache.hadoop   * .hive.ql.parse.ParseContext)    */
Hive,WITHOUT_CLASSIFICATION,/*      * this is the case when the big table is a sub-query and is probably already bucketed by the     * join column in say a group by operation      */
Hive,WITHOUT_CLASSIFICATION,//  The fractional digits are gone; when rounding clear remaining round digits and add 1. 
Hive,WITHOUT_CLASSIFICATION,// HIVE-15458: we need to add a Project on top of Join since SemiJoin with Join as it's right input 
Hive,WITHOUT_CLASSIFICATION,//  varchar columns should have correct display size/precision 
Hive,WITHOUT_CLASSIFICATION,// https://github.com/brettwooldridge/HikariCP 
Hive,WITHOUT_CLASSIFICATION,//  Logger jobconf 
Hive,WITHOUT_CLASSIFICATION,//  plan needs to be complete before we execute and not modify it while execution in the driver. 
Hive,WITHOUT_CLASSIFICATION,//  Well don't recurse but make sure all children are initialized. 
Hive,WITHOUT_CLASSIFICATION,/*    * Overall information on this vectorized Map operation.    */
Hive,WITHOUT_CLASSIFICATION,//  fetch by namespace 
Hive,WITHOUT_CLASSIFICATION,//  TopN query results 
Hive,WITHOUT_CLASSIFICATION,//  Read the first batch.   Oh! the first batch itself was null. Close the reader. 
Hive,WITHOUT_CLASSIFICATION,//  Set up recursive reads for sub-directories. 
Hive,WITHOUT_CLASSIFICATION,/*  Returns an immutable map with the identity [0: 0 .. count-1: count-1].  */
Hive,WITHOUT_CLASSIFICATION,//  used for statistics 
Hive,WITHOUT_CLASSIFICATION,//  Add the expression to partition specification 
Hive,WITHOUT_CLASSIFICATION,//  10**38=   v[0]=0(0)v[1]=160047680(98a2240)v[2]=1518781562(5a86c47a)v[3]=1262177448(4b3b4ca8) 
Hive,WITHOUT_CLASSIFICATION,/*            * Optionally the next value's small length could be a 2nd integer in the value's           * information.            */
Hive,WITHOUT_CLASSIFICATION,//  The set of TableScanOperators for pruning OP trees 
Hive,WITHOUT_CLASSIFICATION,//  Native vectorization NOT supported. 
Hive,WITHOUT_CLASSIFICATION,//  establish mapping from the output column to the input column 
Hive,WITHOUT_CLASSIFICATION,//  If it is a LEFT / FULL OUTER JOIN and the left record did not produce   results we need to take that record replace the right side with NULL   values and produce the records 
Hive,WITHOUT_CLASSIFICATION,//  TODO: logging currently goes to hive.log 
Hive,WITHOUT_CLASSIFICATION,//  optional string vertex_name = 6; 
Hive,WITHOUT_CLASSIFICATION,/*  * Read from Arrow stream batch-by-batch  */
Hive,WITHOUT_CLASSIFICATION,//  TableDesc#getDeserializer() passes a null Configuration into the SerDe.   We shouldn't fail immediately in this case 
Hive,WITHOUT_CLASSIFICATION,//  If the bottom operator is not synthetic and it does not contain a limit 
Hive,WITHOUT_CLASSIFICATION,//  skip query hints 
Hive,WITHOUT_CLASSIFICATION,//  1024 is the default value   Clean up 
Hive,WITHOUT_CLASSIFICATION,//  show column level privileges 
Hive,WITHOUT_CLASSIFICATION,//  Pattern to remove the timestamp and other infrastructural info from the out file 
Hive,WITHOUT_CLASSIFICATION,//  We have a decimal.  After we enforce precision and scale will it become a NULL? 
Hive,WITHOUT_CLASSIFICATION,//  max can be 1 even when ndv is larger in IN clause than in column stats 
Hive,WITHOUT_CLASSIFICATION,// Authenticate using keytab 
Hive,WITHOUT_CLASSIFICATION,//  continue to read it or move to the secondary. 
Hive,WITHOUT_CLASSIFICATION,/*      * 3. build Reduce-side Op Graph      */
Hive,WITHOUT_CLASSIFICATION,//  can't be null   can't be null   can't be null 
Hive,WITHOUT_CLASSIFICATION,//  intentional fall through 
Hive,WITHOUT_CLASSIFICATION,//  Normal deduplication 
Hive,WITHOUT_CLASSIFICATION,// Copy table level hcat.* keys to the partition 
Hive,WITHOUT_CLASSIFICATION,// Again we done want to exit because of logging issues. 
Hive,WITHOUT_CLASSIFICATION,//  a timeout occurs 
Hive,WITHOUT_CLASSIFICATION,//  Replace this with valueOf. 
Hive,WITHOUT_CLASSIFICATION,//  we first merge all the adjacent bitvectors that we could merge and   derive new partition names and index. 
Hive,WITHOUT_CLASSIFICATION,//  If this is a q-test let's order the params map (lexicographically) by   key. This is to get consistent param ordering between Java7 and Java8. 
Hive,WITHOUT_CLASSIFICATION,//  Clean TXN_TO_WRITE_ID table for entries under min_uncommitted_txn referred by any open txns. 
Hive,WITHOUT_CLASSIFICATION,//  worst case when there are no column statistics 
Hive,WITHOUT_CLASSIFICATION,//  Set isNull before call in case it changes it mind. 
Hive,WITHOUT_CLASSIFICATION,//  Setup for actual notifications if not already done for a previous task. 
Hive,WITHOUT_CLASSIFICATION,//  obtain a second lock.  This shouldn't block cleaner as it was acquired after the initial 
Hive,WITHOUT_CLASSIFICATION,//  No expression therefore scan the whole table 
Hive,WITHOUT_CLASSIFICATION,//  Init and run are both potentially long and blocking operations. Synchronization   with the 'abort' operation will not work since if they end up blocking on a monitor   which does not belong to the lock the abort will end up getting blocked.   Both of these method invocations need to handle the abort call on their own. 
Hive,WITHOUT_CLASSIFICATION,// re-throw the exception as an IOException 
Hive,WITHOUT_CLASSIFICATION,//  We build a hash map from colName to object for old ColumnStats. 
Hive,WITHOUT_CLASSIFICATION,//  First we traverse the batch to evaluate and prepare the KeyWrappers 
Hive,WITHOUT_CLASSIFICATION,//  project. 
Hive,WITHOUT_CLASSIFICATION,//  LlapIoImpl.LOG.debug("Writing batch " + batch); 
Hive,WITHOUT_CLASSIFICATION,/*    * Serializes decimal64 up to the maximum 64-bit precision (18 decimal digits).    */
Hive,WITHOUT_CLASSIFICATION,//  for the first grandkid replace the original parent 
Hive,WITHOUT_CLASSIFICATION,//  Get one of the default separators to avoid having to set a custom separator 
Hive,WITHOUT_CLASSIFICATION,//  optional bool is_guaranteed = 12 [default = false]; 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise heuristics. 
Hive,WITHOUT_CLASSIFICATION,//  We're folding multiple masked lines into one. 
Hive,WITHOUT_CLASSIFICATION,//  if left-semi-join found a match and we do not have any additional predicates   skipping the rest of the rows in the rhs table of the semijoin 
Hive,WITHOUT_CLASSIFICATION,//  zero reducers 
Hive,WITHOUT_CLASSIFICATION,//  We only do the minimum cast for decimals. Other types are assumed safe; fix if needed.   We also don't do anything for non-primitive children (maybe we should assert). 
Hive,WITHOUT_CLASSIFICATION,//  (since Timestamps are averaged with double we don't need a PARTIAL2 class)   (and since Timestamps are output as double for AVG we don't need a FINAL class either)   {"VectorUDAFAvgMerge" "VectorUDAFAvgTimestampPartial2" "PARTIAL2"}   {"VectorUDAFAvgMerge" "VectorUDAFAvgTimestampFinal" "FINAL"} 
Hive,WITHOUT_CLASSIFICATION,//  STARTED_TIME 
Hive,WITHOUT_CLASSIFICATION,//  to the branch represented by the list. 
Hive,WITHOUT_CLASSIFICATION,// case HiveParser.TOK_ALTERVIEW_ADDPARTS: 
Hive,WITHOUT_CLASSIFICATION,//  This time it completes by adding just foreign key constraints for table t2. 
Hive,WITHOUT_CLASSIFICATION,//  Perform REPL-DUMP/LOAD 
Hive,WITHOUT_CLASSIFICATION,//  as seen by the users) 
Hive,WITHOUT_CLASSIFICATION,//  open client session 
Hive,WITHOUT_CLASSIFICATION,//  checking for null in the for-loop condition prevents null-ptr exception   and allows us to fail more gracefully with a parsing error. 
Hive,WITHOUT_CLASSIFICATION,//  also the location field in partition 
Hive,WITHOUT_CLASSIFICATION,//  Check that we do find all expected columns 
Hive,WITHOUT_CLASSIFICATION,//  used by FS based stats collector 
Hive,WITHOUT_CLASSIFICATION,//  Use full partition path for error case. 
Hive,WITHOUT_CLASSIFICATION,// HiveException is expected 
Hive,WITHOUT_CLASSIFICATION,//  create a paritioned table 
Hive,WITHOUT_CLASSIFICATION,//  By default this will be same as that of super class BaseSemanticAnalyzer. But need to obtain again 
Hive,WITHOUT_CLASSIFICATION,//  DEFAULT_CONSTRAINT_COLS 
Hive,WITHOUT_CLASSIFICATION,//  Finally try to reuse with something in the queue. Due to fairness this won't work. 
Hive,WITHOUT_CLASSIFICATION,//  The following repeatedX values will be set if any of the columns are repeating. 
Hive,WITHOUT_CLASSIFICATION,/*  * TestLazyHBaseObject is a test for the LazyHBaseXXX classes.  */
Hive,WITHOUT_CLASSIFICATION,//  Check if the partitions exist in the destTable 
Hive,WITHOUT_CLASSIFICATION,//  an extra value so that we can return it while reading ahead 
Hive,WITHOUT_CLASSIFICATION,// This string constant will be persisted in metastore to indicate whether corresponding 
Hive,WITHOUT_CLASSIFICATION,//  TBL_PATTERNS 
Hive,WITHOUT_CLASSIFICATION,//  mark the start of the sync   write sync   update lastSyncPos 
Hive,WITHOUT_CLASSIFICATION,//  2. Perform a major compaction. There should be an extra base dir now. 
Hive,WITHOUT_CLASSIFICATION,// Defining partition names in unsorted order 
Hive,WITHOUT_CLASSIFICATION,//  find any referenced resources 
Hive,WITHOUT_CLASSIFICATION,/*    * Abstract method to be overridden for task execution.    */
Hive,WITHOUT_CLASSIFICATION,//  contain the vc. 
Hive,WITHOUT_CLASSIFICATION,//  Add keys of this grouping set. 
Hive,WITHOUT_CLASSIFICATION,//  This is map of which vectorized row batch columns are the value columns. 
Hive,WITHOUT_CLASSIFICATION,// simulate Insert into 2 partitions 
Hive,WITHOUT_CLASSIFICATION,//  for last batch in row group adjust the batch size 
Hive,WITHOUT_CLASSIFICATION,//  In a YARN/Tez job don't have the Kerberos credentials anymore use the delegation token 
Hive,WITHOUT_CLASSIFICATION,//  We need to loop here to handle the case where consumer goes away. 
Hive,WITHOUT_CLASSIFICATION,// so that test doesn't block 
Hive,WITHOUT_CLASSIFICATION,//  We have deleteRecordId < currRecordIdInBatch we must now move on to find   next the larger deleteRecordId that can possibly match anything in the batch. 
Hive,WITHOUT_CLASSIFICATION,/*  id > 12 or  */
Hive,WITHOUT_CLASSIFICATION,//  total # of blocks   total # of elements in the RowContainer   temporary file holding the spilled blocks 
Hive,WITHOUT_CLASSIFICATION,//  value in the configuration object. 
Hive,WITHOUT_CLASSIFICATION,//  The below group of fields (pools etc.) can only be modified by the master thread. 
Hive,WITHOUT_CLASSIFICATION,//  SERDE_TYPE 
Hive,WITHOUT_CLASSIFICATION,//  Methods should really be protected but some places have to use this as a field. 
Hive,WITHOUT_CLASSIFICATION,//  the column map can not be generated 
Hive,WITHOUT_CLASSIFICATION,//  find the value of matched column 
Hive,WITHOUT_CLASSIFICATION,//  This is used to communicate over the LlapUmbilicalProtocol. Not related to tokens used to   talk to LLAP daemons itself via the securit work. 
Hive,WITHOUT_CLASSIFICATION,// note that recent metastore stores decimal in string. 
Hive,WITHOUT_CLASSIFICATION,//  write out a header for the payload 
Hive,WITHOUT_CLASSIFICATION,//  Timeseries query 
Hive,WITHOUT_CLASSIFICATION,//  value columns 
Hive,WITHOUT_CLASSIFICATION,/*    * A PTF input that represents a source in the overall Query. This could be a Table or a SubQuery.   * If a PTF chain requires execution by multiple PTF Operators;   * then the original Invocation object is decomposed into a set of Component Invocations.   * Every component Invocation but the first one ends in a PTFQueryInputSpec instance.   * During the construction of the Operator plan a PTFQueryInputSpec object in the chain implies connect the PTF Operator to the   * 'input' i.e. has been generated so far.    */
Hive,WITHOUT_CLASSIFICATION,//  Start hive server2 
Hive,WITHOUT_CLASSIFICATION,//  create N MapWorks and add them to the SparkWork 
Hive,WITHOUT_CLASSIFICATION,//  optional bool is_guaranteed = 3; 
Hive,WITHOUT_CLASSIFICATION,//  check if it is noscan command 
Hive,WITHOUT_CLASSIFICATION,//  It is not available do nothing 
Hive,WITHOUT_CLASSIFICATION,//  And use set to remember which virtual columns were actually referenced. 
Hive,WITHOUT_CLASSIFICATION,//  schema evolution will insert the acid columns to row schema for ACID read 
Hive,WITHOUT_CLASSIFICATION,//  Verify that when we have no kerberos credentials we pull the serialized Token 
Hive,WITHOUT_CLASSIFICATION,//  set output isRepeating to true to make sure it gets over-written   similarly with noNulls 
Hive,WITHOUT_CLASSIFICATION,//  FOREIGN_DB_NAME 
Hive,WITHOUT_CLASSIFICATION,//  Same primitive category 
Hive,WITHOUT_CLASSIFICATION,// then need to create metastore client that proxies as that user. 
Hive,WITHOUT_CLASSIFICATION,//  User takes precendence over groups unless ordered explicitly. 
Hive,WITHOUT_CLASSIFICATION,//  optional   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  1. If equalsCheck is true and the inputOI is the same as the outputOI OR 
Hive,WITHOUT_CLASSIFICATION,//  space usually 
Hive,WITHOUT_CLASSIFICATION,//  Since the UDTF operator feeds into a LVJ operator that will rename   all the internal names we can just use field name from the UDTF's OI   as the internal name 
Hive,WITHOUT_CLASSIFICATION,//  VALIDATE_CSTR 
Hive,WITHOUT_CLASSIFICATION,//  another quick path 
Hive,WITHOUT_CLASSIFICATION,//  if this columnFamily/columnQualifier pair is defined in the index build a new mutation   so key=value cf=columnFamily_columnQualifer cq=rowKey cv=columnVisibility value=[] 
Hive,WITHOUT_CLASSIFICATION,//  10 digit int is all in lowest 16 decimal digit longword. 
Hive,WITHOUT_CLASSIFICATION,//  standard case 
Hive,WITHOUT_CLASSIFICATION,//  Pull the table schema out of the Split info 
Hive,WITHOUT_CLASSIFICATION,//  Despite STRING being a primitive it can't be serialized as binary 
Hive,WITHOUT_CLASSIFICATION,//  1/ reserve spaces for the byte size of the list   which is a integer and takes four bytes 
Hive,WITHOUT_CLASSIFICATION,//  Testing negative substring index.   Start index -6 should yield the last 6 characters of the string 
Hive,WITHOUT_CLASSIFICATION,//  backward/forward compatible 
Hive,WITHOUT_CLASSIFICATION,//  Creating dummy table to control the event ID of TRUNCATE not to be 10 or 100 or 1000... 
Hive,WITHOUT_CLASSIFICATION,//  Ignore the pre-upgrade script errors 
Hive,WITHOUT_CLASSIFICATION,//  over here we should have some checks of the deserialized object against   the orginal object 
Hive,WITHOUT_CLASSIFICATION,//  remove from src pool 
Hive,WITHOUT_CLASSIFICATION,// should be an error since p=3 exists 
Hive,WITHOUT_CLASSIFICATION,//  for partitionless table initialize partValue to null 
Hive,WITHOUT_CLASSIFICATION,//  1. Insert some rows into MM table 
Hive,WITHOUT_CLASSIFICATION,//  as long as they are still in the same stream and are not already released. 
Hive,WITHOUT_CLASSIFICATION,//  Invoke the OutputFormat entrypoint 
Hive,WITHOUT_CLASSIFICATION,//  File name 
Hive,WITHOUT_CLASSIFICATION,//  add added jars 
Hive,WITHOUT_CLASSIFICATION,/*  Ideally we want to specify the different arguments to updateLocation as separate argNames.     * However if we did that HelpFormatter swallows all but the last argument. Note that this is     * a know issue with the HelpFormatter class that has not been fixed. We specify all arguments     * with a single argName to workaround this HelpFormatter bug.      */
Hive,WITHOUT_CLASSIFICATION,//  the context along 
Hive,WITHOUT_CLASSIFICATION,//  Case 1: Test with just originals => Single split strategy with two splits. 
Hive,WITHOUT_CLASSIFICATION,//  we have found a match. insert this distinct clause to head. 
Hive,WITHOUT_CLASSIFICATION,//  Wait if no exception happens otherwise retry immediately 
Hive,WITHOUT_CLASSIFICATION,// for conditional task next task list should return the children tasks of each task which  is contained in the conditional task. 
Hive,WITHOUT_CLASSIFICATION,//  Note the "& 0xff" is just a way to convert unsigned bytes to signed integer. 
Hive,WITHOUT_CLASSIFICATION,//  read from hive to test 
Hive,WITHOUT_CLASSIFICATION,//  Don't sync. 
Hive,WITHOUT_CLASSIFICATION,//  If this is a duplicate invocation of a function; don't add to WindowingSpec. 
Hive,WITHOUT_CLASSIFICATION,//  of objs) 
Hive,WITHOUT_CLASSIFICATION,/*      * Used only for Debugging or testing purposes      */
Hive,WITHOUT_CLASSIFICATION,//  fields belong to one of the next entries 
Hive,WITHOUT_CLASSIFICATION,//  Repeating null 
Hive,WITHOUT_CLASSIFICATION,//  The map should now be empty. 
Hive,WITHOUT_CLASSIFICATION,// do nothing 
Hive,WITHOUT_CLASSIFICATION,//  for each big table's bucket call the start forward 
Hive,WITHOUT_CLASSIFICATION,//  Normal case - an active session was removed from the pool.   Session was restarted out of bounds any user-side handling should be ignored. 
Hive,WITHOUT_CLASSIFICATION,//  TXNS table should have atleast one entry because we just inserted the newly opened txns. 
Hive,WITHOUT_CLASSIFICATION,//  need to set this only for replication tasks 
Hive,WITHOUT_CLASSIFICATION,//  Read count 
Hive,WITHOUT_CLASSIFICATION,//  This will only get called once since CompactRecordReader only returns one record   the input split.   Based on the split we're passed we go instantiate the real reader and then iterate on it   until it finishes.  since there is no way to parametrize instance of Class 
Hive,WITHOUT_CLASSIFICATION,//  merge join work. 
Hive,WITHOUT_CLASSIFICATION,// set authorization mode to V2 
Hive,WITHOUT_CLASSIFICATION,//  fill forwardCache with skipvector 
Hive,WITHOUT_CLASSIFICATION,//  begin conversion.. 
Hive,WITHOUT_CLASSIFICATION,//  we first take a look if any fieldSchemas contain COMMA 
Hive,WITHOUT_CLASSIFICATION,//  100 < key 
Hive,WITHOUT_CLASSIFICATION,//  Make sure we get a correct number of sessions in each queue and that we don't crash. 
Hive,WITHOUT_CLASSIFICATION,//  This path is only potentially encountered during setup   Otherwise a specific part_xxxx file name is generated and passed in. 
Hive,WITHOUT_CLASSIFICATION,//  HiveAuthorizer.filterListCmdObjects should not filter any object 
Hive,WITHOUT_CLASSIFICATION,// now tell LaunchMapper which files it should add to HADOOP_CLASSPATH 
Hive,WITHOUT_CLASSIFICATION,//  based on the ErrorMsg set in HiveException. 
Hive,WITHOUT_CLASSIFICATION,//  Serialize/deserialize 
Hive,WITHOUT_CLASSIFICATION,//  Data columns.   Partition columns. 
Hive,WITHOUT_CLASSIFICATION,//  Acquire 1st Txn Batch 
Hive,WITHOUT_CLASSIFICATION,// ALL privilege is expanded to these so it is not needed here 
Hive,WITHOUT_CLASSIFICATION,/*    * If hasNulls is true then this array contains true if the value   * is null otherwise false. The array is always allocated so a batch can be re-used   * later and nulls added.    */
Hive,WITHOUT_CLASSIFICATION,//  Cache has found an old buffer for the key and put it into array instead of our new one. 
Hive,WITHOUT_CLASSIFICATION,//  extract the record type 
Hive,WITHOUT_CLASSIFICATION,//  Initialize all children first 
Hive,WITHOUT_CLASSIFICATION,// This is either the first batch or we've used up the current batch buffer 
Hive,WITHOUT_CLASSIFICATION,/*  Register a running task into the runningTasks structure  */
Hive,WITHOUT_CLASSIFICATION,//  normal close. 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.CLIServiceClient#closeSession(org.apache.hive.service.cli.SessionHandle)    */
Hive,WITHOUT_CLASSIFICATION,//  We decided to treat this collection as regular object. 
Hive,WITHOUT_CLASSIFICATION,//  Clear the other ones. 
Hive,WITHOUT_CLASSIFICATION,//  -c <named url in the beeline-hs2-connection.xml> 
Hive,WITHOUT_CLASSIFICATION,//  We cannot abandon the attempt here; the concurrent operations might have released   all the buffer comprising our buddy block necessitating a merge into a higher   list. That may deadlock with another thread locking its own victims (one can only   take list locks separately or moving DOWN). The alternative would be to release   the free list lock before reserving however iterating the list that way is   difficult (we'd have to keep track of things on the main path to avoid re-trying   the same headers repeatedly - we'd rather keep track of extra things on failure). 
Hive,WITHOUT_CLASSIFICATION,//  metastore schema version is different than Hive distribution needs 
Hive,WITHOUT_CLASSIFICATION,// copied from ErrorMsg.java 
Hive,WITHOUT_CLASSIFICATION,//  MAPPINGS 
Hive,WITHOUT_CLASSIFICATION,//  Check if stats are same no need to update 
Hive,WITHOUT_CLASSIFICATION,//  Task data structures have been initialized 
Hive,WITHOUT_CLASSIFICATION,//  Read via object store 
Hive,WITHOUT_CLASSIFICATION,// List<?> c16Value = (List<?>) rowValues[15];  assertEquals(0 c16Value.size()); 
Hive,WITHOUT_CLASSIFICATION,//  Invalid expression => throw some exception but not incompatible metastore. 
Hive,WITHOUT_CLASSIFICATION,//  if different sign just add up the absolute values 
Hive,WITHOUT_CLASSIFICATION,// this is set by Utilities.copyTablePropertiesToConf() 
Hive,WITHOUT_CLASSIFICATION,//  All good combine the base/original only ETL strategies. 
Hive,WITHOUT_CLASSIFICATION,//  If partitions do not match we currently do not merge 
Hive,WITHOUT_CLASSIFICATION,//  Split -9223372036854775808 into 16 digit middle and lowest longwords by hand. 
Hive,WITHOUT_CLASSIFICATION,//  optional string app_id = 1; 
Hive,WITHOUT_CLASSIFICATION,//  4. Perform a MINOR compaction again. This time it will remove the subdir for aborted transaction. 
Hive,WITHOUT_CLASSIFICATION,//  need this for Jackson to work 
Hive,WITHOUT_CLASSIFICATION,//  used for readFields 
Hive,WITHOUT_CLASSIFICATION,//  Create the mapping for this column with configured encoding 
Hive,WITHOUT_CLASSIFICATION,//  Optimize local fetch does not work with LLAP due to different local directories   used by containers and LLAP 
Hive,WITHOUT_CLASSIFICATION,//  drop table 
Hive,WITHOUT_CLASSIFICATION,/*    * Initiate cancel request to cancel the thread execution and interrupt the thread.   * If thread interruption is not handled by jobExecuteCallable then thread may continue   * running to completion. The cancel call may fail for some scenarios. In that case   * retry the cancel call until it returns true or max retry count is reached.   *   * @param future   *          Future object which has handle to cancel the thread.   *    */
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:TerminateFragmentRequestProto) 
Hive,WITHOUT_CLASSIFICATION,//  Test that listPartitionsByFilter() returns an empty-set if the filter selects no partitions. 
Hive,WITHOUT_CLASSIFICATION,//  Move clock backwards (so that t1 allocation is after t2 allocation) 
Hive,WITHOUT_CLASSIFICATION,//  The partitions are "unknown" if the call says so due to the expression   evaluator returning null for a partition or if we sent a partial expression to 
Hive,WITHOUT_CLASSIFICATION,//  check if any operator had a fatal error or early exit during   execution 
Hive,WITHOUT_CLASSIFICATION,//  do not cache this if its child RDD is intend to be cached. 
Hive,WITHOUT_CLASSIFICATION,//  Get the aggregate function matching the name in the query. 
Hive,WITHOUT_CLASSIFICATION,//  Register that we have visited this operator in this rule 
Hive,WITHOUT_CLASSIFICATION,//  Only the hive catalog should be cached 
Hive,WITHOUT_CLASSIFICATION,//  store the config in system properties 
Hive,WITHOUT_CLASSIFICATION,//  to call getVarcharMaxLength() on every deserialize call. 
Hive,WITHOUT_CLASSIFICATION,//  create the default white list from list of safe config params   and regex list 
Hive,WITHOUT_CLASSIFICATION,//  Stats values for col3 
Hive,WITHOUT_CLASSIFICATION,//  nested complex types trigger Kryo issue #216 in plan deserialization 
Hive,WITHOUT_CLASSIFICATION,//  The offset of the first input does not need to change. 
Hive,WITHOUT_CLASSIFICATION,// partial spec 
Hive,WITHOUT_CLASSIFICATION,//  number of aliases 
Hive,WITHOUT_CLASSIFICATION,//  this avoids extra serialization & deserialization of these objects 
Hive,WITHOUT_CLASSIFICATION,//  POOL_PATH 
Hive,WITHOUT_CLASSIFICATION,//  The key portion of the entry will be the internal column name for the join key expression. 
Hive,WITHOUT_CLASSIFICATION,//  kill server 
Hive,WITHOUT_CLASSIFICATION,//  If it's a leaf add the move task as a child 
Hive,WITHOUT_CLASSIFICATION,//  UNDONE 
Hive,WITHOUT_CLASSIFICATION,//  invoked for test methods 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.CLIServiceClient#getTypeInfo(org.apache.hive.service.cli.SessionHandle)    */
Hive,WITHOUT_CLASSIFICATION,//  schema:   principal_nameprincipal_typegrant_optiongrantorgrantor_typegrant_time 
Hive,WITHOUT_CLASSIFICATION,//  Encountered partitioning column this will be better handled by MetadataOnly optimizer. 
Hive,WITHOUT_CLASSIFICATION,//  Table may not be found when materialization of CTE is on. 
Hive,WITHOUT_CLASSIFICATION,//  then let's check the one we know about 
Hive,WITHOUT_CLASSIFICATION,//  If column type is not specified use a string 
Hive,WITHOUT_CLASSIFICATION,/*  Returns the node currently on the top of the stack.  */
Hive,WITHOUT_CLASSIFICATION,/*    * Job request executor to list job status requests.    */
Hive,WITHOUT_CLASSIFICATION,//  Stats values for col2 
Hive,WITHOUT_CLASSIFICATION,//  Test in mixed case 
Hive,WITHOUT_CLASSIFICATION,//  set hashtable memory usage 
Hive,WITHOUT_CLASSIFICATION,//  Remove the locks we didn't see so we don't look for them again next time 
Hive,WITHOUT_CLASSIFICATION,//  Now get all the one-to-many things. Start with partitions. 
Hive,WITHOUT_CLASSIFICATION,// we are good since subquery is top level expression 
Hive,WITHOUT_CLASSIFICATION,//  Get the following out of the way when you start the session these take a 
Hive,WITHOUT_CLASSIFICATION,//  Try to read the dropped "tbl1" via CachedStore (should throw exception) 
Hive,WITHOUT_CLASSIFICATION,//  If it's not some operator pass it back 
Hive,WITHOUT_CLASSIFICATION,//  If 1) RS has been removed or 2) it does not have a child (for instance it is a   semijoin RS) we can quickly skip this one 
Hive,WITHOUT_CLASSIFICATION,//  We won't do metastore-side PPD for the things we have locally. 
Hive,WITHOUT_CLASSIFICATION,//  Sanity check that for a map we got 2 encodings 
Hive,WITHOUT_CLASSIFICATION,//  null means we cannot wrap; the cause is logged inside. 
Hive,WITHOUT_CLASSIFICATION,//  See method comment. 
Hive,WITHOUT_CLASSIFICATION,//  invalid merge -- smaller register merge to bigger 
Hive,WITHOUT_CLASSIFICATION,//  alpha order PLEASE! 
Hive,WITHOUT_CLASSIFICATION,//  Everything comes from cache. 
Hive,WITHOUT_CLASSIFICATION,//  This mapper class is used for serializaiton/deserializaiton of merge   file work. 
Hive,WITHOUT_CLASSIFICATION,//  HiveStatement#getUpdateCount blocks until the async query is complete 
Hive,WITHOUT_CLASSIFICATION,//  See also: the usage of VectorDeserializeType for binary. For now we only want text. 
Hive,WITHOUT_CLASSIFICATION,//  Disabling rewriting removing from cache 
Hive,WITHOUT_CLASSIFICATION,//  the column must be an aggregate column inserted by GBY. We   don't have to account for this column when computing product   of NDVs 
Hive,WITHOUT_CLASSIFICATION,//  Choose cumulative 
Hive,WITHOUT_CLASSIFICATION,// export works at file level so if you have copy_N in the table dir you'll have those in output 
Hive,WITHOUT_CLASSIFICATION,//  Change the filter condition into a join condition 
Hive,WITHOUT_CLASSIFICATION,//  Can only happen if there's no evictor or if thread is interrupted. 
Hive,WITHOUT_CLASSIFICATION,//  Set null information in the small table results area. 
Hive,WITHOUT_CLASSIFICATION,//  Multiply by 2 to make room for 0 sign bit. 
Hive,WITHOUT_CLASSIFICATION,//  There maybe more than 1 splits in the group however they all have 1 unique path.   Assert that. 
Hive,WITHOUT_CLASSIFICATION,//  Check individual elements of subrecord 
Hive,WITHOUT_CLASSIFICATION,//  Process the batch 
Hive,WITHOUT_CLASSIFICATION,//  left repeats 
Hive,WITHOUT_CLASSIFICATION,//  check the contents of the file 
Hive,WITHOUT_CLASSIFICATION,//  Now HiveDecimal 
Hive,WITHOUT_CLASSIFICATION,//  start offset of each field 
Hive,WITHOUT_CLASSIFICATION,//  String object. 
Hive,WITHOUT_CLASSIFICATION,//  Inject a behavior where REPL LOAD failed when try to load table "t2" and partition "uk". 
Hive,WITHOUT_CLASSIFICATION,//  grammar prohibits more than 1 column so we are guaranteed to have only 1   element in this lists. 
Hive,WITHOUT_CLASSIFICATION,//  The node cannot accept a task at the moment. 
Hive,WITHOUT_CLASSIFICATION,// (1*60*60 + 1*60 + 1) * 10e9 + 1 
Hive,WITHOUT_CLASSIFICATION,//  Most likely this means it's a temp table 
Hive,WITHOUT_CLASSIFICATION,/*  Set double data vector array entries for NULL elements to the correct value.     * Unlike other col-scalar operations this one doesn't benefit from carrying     * over NaN values from the input array.      */
Hive,WITHOUT_CLASSIFICATION,//  FIELD0 
Hive,WITHOUT_CLASSIFICATION,//  If there's no lock manager it essentially means we didn't acquire locks in the first place   thus no need to release locks 
Hive,WITHOUT_CLASSIFICATION,//  For now do not limit this - one RG per split 
Hive,WITHOUT_CLASSIFICATION,//  detect if there are multiple attributes in join key 
Hive,WITHOUT_CLASSIFICATION,//  Do not call mq.getRowCount(join) will trigger CyclicMetadataException 
Hive,WITHOUT_CLASSIFICATION,//  Used by kyro 
Hive,WITHOUT_CLASSIFICATION,/*      *  If there was a pre-existing work generated for the big-table mapjoin side     *  we need to hook the work generated for the RS (associated with the RS-MJ pattern)     *  with the pre-existing work.     *     *  Otherwise we need to associate that the mapjoin op     *  to be linked to the RS work (associated with the RS-MJ pattern).     *      */
Hive,WITHOUT_CLASSIFICATION,//  Recursively remove any of its parent who only have this op as child. 
Hive,WITHOUT_CLASSIFICATION,//  first remove all the grants 
Hive,WITHOUT_CLASSIFICATION,//  Let's make sure we only read the relevant part of the writable in case of reuse 
Hive,WITHOUT_CLASSIFICATION,//  load them into a SetLong 
Hive,WITHOUT_CLASSIFICATION,//  TODO: cache the information from the metastore 
Hive,WITHOUT_CLASSIFICATION,//  2nd pass at removing invalid candidates   If misses so far exceed max tolerable misses 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: The null array is indexed by keyIndex which is not available internally.  The mapping         from a long double etc index to key index is kept once in the separate         VectorColumnSetInfo object. 
Hive,WITHOUT_CLASSIFICATION,//  MRInput is not of interest since it'll always be ready. 
Hive,WITHOUT_CLASSIFICATION,//        out of the request provided that it's signed. 
Hive,WITHOUT_CLASSIFICATION,//  Rule is searching for dynamic pruning expr. There's at least an IN   expression wrapping it. 
Hive,WITHOUT_CLASSIFICATION,// Expecting not to change the size of internal structures 
Hive,WITHOUT_CLASSIFICATION,//  adds the taskId to the fspKey. 
Hive,WITHOUT_CLASSIFICATION,//  check if bucketing in both was done in the same way 
Hive,WITHOUT_CLASSIFICATION,//  Bare cf 
Hive,WITHOUT_CLASSIFICATION,//  the right input to Correlator should produce correlated variables 
Hive,WITHOUT_CLASSIFICATION,//  letter "A" (1 byte)   Latin capital A with grave (2 bytes) 
Hive,WITHOUT_CLASSIFICATION,// throw new IllegalArgumentException("hcatFiledSchema is null; fSchema=" + fSchema + " " +        "(pigSchema tableSchema)=(" + pigSchema + "" + tableSchema + ")"); 
Hive,WITHOUT_CLASSIFICATION,//  total characters = 2; byte length = 4 
Hive,WITHOUT_CLASSIFICATION,//  Ensure counters are set when data has actually been read. 
Hive,WITHOUT_CLASSIFICATION,//  Do this here; normally communicator does this. 
Hive,WITHOUT_CLASSIFICATION,//  Follow the Reducesink operator upstream which is on small table side. 
Hive,WITHOUT_CLASSIFICATION,//  Try the extremes of precision and scale. 
Hive,WITHOUT_CLASSIFICATION,//  Parse and initialize the HBase columns mapping 
Hive,WITHOUT_CLASSIFICATION,//  filters for pushing 
Hive,WITHOUT_CLASSIFICATION,//  needed columns 
Hive,WITHOUT_CLASSIFICATION,//  the name of the function/table 
Hive,WITHOUT_CLASSIFICATION,//  set register value and compute inverse pow of 2 for register value 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) Senum  */
Hive,WITHOUT_CLASSIFICATION,//  Note: Setting these separately is a very hairy issue in certain combinations since we         cannot decide what type of table this becomes without taking both into account and         in many cases the conversion might be illegal.         The only thing we allow is tx = true w/o tx-props for backward compat. 
Hive,WITHOUT_CLASSIFICATION,//  sum of small tables size in this join exceeds configured limit   hence cannot convert. 
Hive,WITHOUT_CLASSIFICATION,//  PART_NAMES 
Hive,WITHOUT_CLASSIFICATION,//  if the object does not exist we want to add it. 
Hive,WITHOUT_CLASSIFICATION,//  total characters = 2; byte length = 3 
Hive,WITHOUT_CLASSIFICATION,//  lookup the specified type and set this nodes type to it. Precludes   forward and self references for now. 
Hive,WITHOUT_CLASSIFICATION,//  retain the original join desc in the map join. 
Hive,WITHOUT_CLASSIFICATION,//  Currently we do not support PTF operator. 
Hive,WITHOUT_CLASSIFICATION,//  get list of selected column IDs 
Hive,WITHOUT_CLASSIFICATION,//  Not supported. 
Hive,WITHOUT_CLASSIFICATION,/*  This method assumes that the IN list has no NULL entries. That is enforced elsewhere     * in the Vectorizer class. If NULL is passed in as a list entry behavior is not defined.     * If in the future NULL values are allowed in the IN list be sure to handle 3-valued     * logic correctly. E.g. NOT (col IN (null)) should be considered UNKNOWN so that would     * become FALSE in the WHERE clause and cause the row in question to be filtered out.     * See the discussion in Jira HIVE-5583.      */
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(outer_class_scope) 
Hive,WITHOUT_CLASSIFICATION,//  Round to even 0. 
Hive,WITHOUT_CLASSIFICATION,//  Parse the first byte of a vint/vlong to determine the number of bytes. 
Hive,WITHOUT_CLASSIFICATION,//  SQL92 comment prefix is "--"   beeline also supports shell-style "#" prefix 
Hive,WITHOUT_CLASSIFICATION,//  Write datum out to a stream 
Hive,WITHOUT_CLASSIFICATION,//  This is to optimize queries of the form:   select count(distinct key) from T   where T is sorted and bucketized by key   Partial aggregation is performed on the mapper and the   reducer gets 1 row (partial result) per mapper. 
Hive,WITHOUT_CLASSIFICATION,//  https://hadoop.apache.org/docs/r2.8.0/hadoop-project-dist/hadoop-common/GroupsMapping.html 
Hive,WITHOUT_CLASSIFICATION,//  what position in the mapjoin the different parent work items will have. 
Hive,WITHOUT_CLASSIFICATION,//  Hopefully this will be helpful in case of NPEs. 
Hive,WITHOUT_CLASSIFICATION,/*  partialSum  */
Hive,WITHOUT_CLASSIFICATION,//  Start concurrent testing 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) DefinitionType  */
Hive,WITHOUT_CLASSIFICATION,//  Merge noMatchs and (match) selected. 
Hive,WITHOUT_CLASSIFICATION,//  it or not. 
Hive,WITHOUT_CLASSIFICATION,//  Expecting only a single instance of a task to be running. 
Hive,WITHOUT_CLASSIFICATION,//  If both categories are primitive return the comparison of type names. 
Hive,WITHOUT_CLASSIFICATION,//  Null out some row column entries.   UNDONE 
Hive,WITHOUT_CLASSIFICATION,//  Should this group by be converted to a map-side group by because the grouping keys for 
Hive,WITHOUT_CLASSIFICATION,//  the ObjectInspector for array<?> and map<? ?> expects an extra layer 
Hive,WITHOUT_CLASSIFICATION,//  canColumnStatsMerge guarantees that it is accurate before we do merge 
Hive,WITHOUT_CLASSIFICATION,//  To make comparisons work properly the "factor" gets the decimal's sign too. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#close()    */
Hive,WITHOUT_CLASSIFICATION,//  Short.MIN_VALUE 
Hive,WITHOUT_CLASSIFICATION,// now we have base_0001 file 
Hive,WITHOUT_CLASSIFICATION,//  key = "database.table/SP/DP/"LB/   Hive store lowercase table name in metastore and Counters is character case sensitive so we 
Hive,WITHOUT_CLASSIFICATION,//  Make a copy of currentMetaVars there is a race condition that   currentMetaVars might be changed during the execution of the method 
Hive,WITHOUT_CLASSIFICATION,//  write a second non-null element 
Hive,WITHOUT_CLASSIFICATION,//  stats from reader 
Hive,WITHOUT_CLASSIFICATION,/* catalog  */
Hive,WITHOUT_CLASSIFICATION,//  PARENT_DB_NAME 
Hive,WITHOUT_CLASSIFICATION,//  If SSL is enabled override the given value of "hadoop.rpc.protection" and set it to "authentication"   This disables any encryption provided by SASL since SSL already provides it 
Hive,WITHOUT_CLASSIFICATION,//  If we can immediately reuse a session there's nothing to wait for - just return. 
Hive,WITHOUT_CLASSIFICATION,//  get column statistics for all output columns 
Hive,WITHOUT_CLASSIFICATION,//  Test "DROP VIEW" 
Hive,WITHOUT_CLASSIFICATION,//  Grouping sets: we need to transform them into ImmutableBitSet   objects for Calcite 
Hive,WITHOUT_CLASSIFICATION,//  Try temporarily adding the RS as a parent 
Hive,WITHOUT_CLASSIFICATION,// will call RecordUpdater.close(boolean abort) 
Hive,WITHOUT_CLASSIFICATION,//  Create the directory 
Hive,WITHOUT_CLASSIFICATION,//  FIELD2 
Hive,WITHOUT_CLASSIFICATION,//  If parent keys are null or empty we bail out 
Hive,WITHOUT_CLASSIFICATION,//  GRANTOR_TYPE 
Hive,WITHOUT_CLASSIFICATION,/*        * add row to chain. except in case of UNB preceding: - only 1 firstVal       * needs to be tracked.        */
Hive,WITHOUT_CLASSIFICATION,// forward as arg   forward as arg   work-dir   llap-daemon-site   llap-daemon-site   forward via config.json   forward as arg   used to localize jars   used to localize jars   used to localize jars   forward via config.json   llap-daemon-site if relevant parameter   forward as arg   forward as arg   forward via config.json   llap-daemon-site 
Hive,WITHOUT_CLASSIFICATION,//  type name should already be set by subclass 
Hive,WITHOUT_CLASSIFICATION,//  MySQL can use INT(n)  
Hive,WITHOUT_CLASSIFICATION,//  n-way: first small table 
Hive,WITHOUT_CLASSIFICATION,//  FIELD3 
Hive,WITHOUT_CLASSIFICATION,//  only returns a subset per call 
Hive,WITHOUT_CLASSIFICATION,//  for computing the autogenerated field ids in thrift 
Hive,WITHOUT_CLASSIFICATION,//  TODO: later we may have a map 
Hive,WITHOUT_CLASSIFICATION,//  Containers are not being tracked for re-use.   This is safe to ignore since a deallocate task will come in. 
Hive,WITHOUT_CLASSIFICATION,//  FIELD1 
Hive,WITHOUT_CLASSIFICATION,//  HIVE-14443 move this fall-back logic to CliConfigs 
Hive,WITHOUT_CLASSIFICATION,//  enable cache and use default strategy 
Hive,WITHOUT_CLASSIFICATION,//  Calcite literal is in millis convert to seconds 
Hive,WITHOUT_CLASSIFICATION,//  The order of the fields in the LazyBinary small table value must be used so 
Hive,WITHOUT_CLASSIFICATION,//  Data structures coming from QBJoinTree 
Hive,WITHOUT_CLASSIFICATION,//  get appropriate object from the string representation of the value in partInfo.getPartitionValues() 
Hive,WITHOUT_CLASSIFICATION,//  if we did not see a skew key in this table continue to next table   we are trying to avoid an extra call of FileSystem.exists() 
Hive,WITHOUT_CLASSIFICATION,/*  * An single long value hash map based on the BytesBytesMultiHashSet. * * We serialize the long key into BinarySortable format into an output buffer accepted by * BytesBytesMultiHashSet.  */
Hive,WITHOUT_CLASSIFICATION,//  5. Insert ReduceSide GB2 
Hive,WITHOUT_CLASSIFICATION,//  dimension 
Hive,WITHOUT_CLASSIFICATION,//  The SchemaEvolution class has added the ACID metadata columns.  Let's update our   readerTypes so PPD code will work correctly. 
Hive,WITHOUT_CLASSIFICATION,/*      * For WindowingTableFunction if:     * a. there is a Rank/DenseRank function: if there are unpushedPred of the form     *    rnkValue < Constant; then use the smallest Constant val as the 'rankLimit'     *    on the WindowingTablFn.     * b. If there are no Wdw Fns with an End Boundary past the current row the     *    condition can be pushed down as a limit pushdown(mapGroupBy=true)     *     * (non-Javadoc)     * @see org.apache.hadoop.hive.ql.ppd.OpProcFactory.ScriptPPD#process(org.apache.hadoop.hive.ql.lib.Node java.util.Stack org.apache.hadoop.hive.ql.lib.NodeProcessorCtx java.lang.Object[])      */
Hive,WITHOUT_CLASSIFICATION,//  optional int64 current_attempt_start_time = 6; 
Hive,WITHOUT_CLASSIFICATION,//  prepends partition spec of input path to candidate file name 
Hive,WITHOUT_CLASSIFICATION,//  2. Setup TableScan 
Hive,WITHOUT_CLASSIFICATION,//  Add the current constant struct to the right hand side of the IN clause. 
Hive,WITHOUT_CLASSIFICATION,//  Define the expected schema. 
Hive,WITHOUT_CLASSIFICATION,/*  Count of number of true values seen so far  */
Hive,WITHOUT_CLASSIFICATION,//  Construct a CASE expression to handle the null indicator.     This also covers the case where a left correlated subquery   projects fields from outer relation. Since LOJ cannot produce   nulls on the LHS the projection now need to make a nullable LHS   reference using a nullability indicator. If this this indicator   is null it means the subquery does not produce any value. As a   result any RHS ref by this usbquery needs to produce null value. 
Hive,WITHOUT_CLASSIFICATION,//  There is no need to add colname again otherwise we will get duplicate colNames. 
Hive,WITHOUT_CLASSIFICATION,//  This has to be called before initializing the instance of HMSHandler   Using the hook on startup ensures that the hook always has priority   over settings in *.xml.  The thread local conf needs to be used because at this point 
Hive,WITHOUT_CLASSIFICATION,//  required by input format. 
Hive,WITHOUT_CLASSIFICATION,//  corresponding 8 struct fields at the same time 
Hive,WITHOUT_CLASSIFICATION,//  End UDFRowSequence.java 
Hive,WITHOUT_CLASSIFICATION,//  map priv being granted to required privileges 
Hive,WITHOUT_CLASSIFICATION,//  If this Filter has correlated reference create value generator 
Hive,WITHOUT_CLASSIFICATION,// Nothing to do 
Hive,WITHOUT_CLASSIFICATION,//  add whether the row is filtered or not. 
Hive,WITHOUT_CLASSIFICATION,//  We bail if there are any changes. Note that we don't care about ABA here - all the   stuff on the left has been taken out already so noone can touch it and all the stuff   on the right is yet to be seen so we don't care if they changed with this - if it's   in the same free list the processing sequence will remain the same going right. 
Hive,WITHOUT_CLASSIFICATION,//  If there are no more active client sessions stop the server 
Hive,WITHOUT_CLASSIFICATION,//  destination in memory   If this is the only partition in memory proceed without check   Destination partition being empty indicates a write buffer   will be allocated thus need to check if memory is full   check periodically 
Hive,WITHOUT_CLASSIFICATION,// if the url does not have a database name add the trailing '/' 
Hive,WITHOUT_CLASSIFICATION,//  A test-specific delay just before the check happens. 
Hive,WITHOUT_CLASSIFICATION,//  TABLE_TYPES 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#execute(java.lang.String java.lang.String[])    */
Hive,WITHOUT_CLASSIFICATION,//  fetch all the hints in qb 
Hive,WITHOUT_CLASSIFICATION,//  set alias to fetch work 
Hive,WITHOUT_CLASSIFICATION,//  Dynamic partition: replace input path (root to dp paths) with dynamic partition 
Hive,WITHOUT_CLASSIFICATION,//  Don't bother validating. 
Hive,WITHOUT_CLASSIFICATION,//  Create a list of top nodes 
Hive,WITHOUT_CLASSIFICATION,//  check if the context matches 
Hive,WITHOUT_CLASSIFICATION,//  User2 privileges:   testdb1: S   testtable1.*: S   testtable2.*: S   testtable3.*: S   testtable4.*: S   testdb2: 
Hive,WITHOUT_CLASSIFICATION,//  make sure miniHS2_2 closes all its connections 
Hive,WITHOUT_CLASSIFICATION,//  If already copied successfully ignore it. 
Hive,WITHOUT_CLASSIFICATION,//  String[] allAliases = joinTree.getAllAliases(); 
Hive,WITHOUT_CLASSIFICATION,//  All of stats variables are visible for testing. 
Hive,WITHOUT_CLASSIFICATION,//  Return the errors that occur the most frequently 
Hive,WITHOUT_CLASSIFICATION,//  Target compression block is in the middle of the range; slice the range in two. 
Hive,WITHOUT_CLASSIFICATION,//  limit length to 20 chars 
Hive,WITHOUT_CLASSIFICATION,// no need to wait in the last iteration 
Hive,WITHOUT_CLASSIFICATION,//  a map to keep track of which child generated with work 
Hive,WITHOUT_CLASSIFICATION,//  anythingElse <= 'foo' 
Hive,WITHOUT_CLASSIFICATION,//  show tables should be faster than that 
Hive,WITHOUT_CLASSIFICATION,//  Update with new values 
Hive,WITHOUT_CLASSIFICATION,//  if this task was added to pre-emption list remove it 
Hive,WITHOUT_CLASSIFICATION,//  VARCHAR NOT BETWEEN 
Hive,WITHOUT_CLASSIFICATION,//  Return a single ArrayList where the first element is the number of bins bins   and subsequent elements represent bins (xy) pairs. 
Hive,WITHOUT_CLASSIFICATION,//  Set the results 
Hive,WITHOUT_CLASSIFICATION,//  We are not allowed to lose digits in multiply to be compatible with OldHiveDecimal   behavior so overflow.   CONSIDER: Does it make sense to be so restrictive.  If we just did repeated addition             it would succeed... 
Hive,WITHOUT_CLASSIFICATION,//  We forwarded the batch in this method. 
Hive,WITHOUT_CLASSIFICATION,// test serialization 
Hive,WITHOUT_CLASSIFICATION,//  Handle both file:// and jar:<url>!{entry} in the case of shaded hive libs 
Hive,WITHOUT_CLASSIFICATION,//  and the operator is a DOT then it's a table column reference. 
Hive,WITHOUT_CLASSIFICATION,//  Max is disabled we can safely return true 
Hive,WITHOUT_CLASSIFICATION,//  append new config params to whitelist 
Hive,WITHOUT_CLASSIFICATION,//  RuntimeErrorException happens when an unexpected failure occurs in getAttribute   for example https://issues.apache.org/jira/browse/DAEMON-120 
Hive,WITHOUT_CLASSIFICATION,// c16Value = (List<?>) rowValues[15];  assertEquals(2 c16Value.size());  listVal = (List<?>) c16Value.get(0);  assertEquals(2 listVal.size());  mapVal = (Map<??>) listVal.get(0);  assertEquals(0 mapVal.size());  assertEquals(Integer.valueOf(1) listVal.get(1));  listVal = (List<?>) c16Value.get(1);  mapVal = (Map<??>) listVal.get(0);  assertEquals(2 mapVal.size());  assertEquals("b" mapVal.get("a"));  assertEquals("d" mapVal.get("c"));  assertEquals(Integer.valueOf(2) listVal.get(1)); 
Hive,WITHOUT_CLASSIFICATION,//  Does not need to be actual time just non-zero distinct value to test against. 
Hive,WITHOUT_CLASSIFICATION,// both "blockedby" are either there or not 
Hive,WITHOUT_CLASSIFICATION,//  dynamic part vals specified 
Hive,WITHOUT_CLASSIFICATION,//  Get the App report from YARN 
Hive,WITHOUT_CLASSIFICATION,//  In the case where agg is count($corVar) it is changed to   count(nullIndicator).   Note:  any non-nullable field from the RHS can be used as   the indicator however a "true" field is added to the   projection list from the RHS for simplicity to avoid   searching for non-null fields.     Project-A' (all gby keys + rewritten nullable ProjExpr)     Aggregate (groupby(all left input refs)                   count(nullIndicator) other aggs...)       Project-B' (all left input refs plus                      the rewritten original projected exprs)         Join(replace corvar to input ref from LeftInputRel)           LeftInputRel           Project (everything from RightInputRel plus                       the nullIndicator "true")             RightInputRel 
Hive,WITHOUT_CLASSIFICATION,//  LAST_HEARTBEAT_TIME 
Hive,WITHOUT_CLASSIFICATION,//  Must produce the same result as MurmurHash.hash with seed = 0. 
Hive,WITHOUT_CLASSIFICATION,//  the first group. 
Hive,WITHOUT_CLASSIFICATION,// insert (1212) creates 000000_0_copy_1 
Hive,WITHOUT_CLASSIFICATION,//  instantiate the metastore server handler directly instead of connecting   through the network 
Hive,WITHOUT_CLASSIFICATION,//  Recursive. 
Hive,WITHOUT_CLASSIFICATION,//  We have finished tree walking (correlation detection).   We will first see if we need to abort (the operator tree has not been changed). 
Hive,WITHOUT_CLASSIFICATION,//  The caller probably created the new session with the old config but update the 
Hive,WITHOUT_CLASSIFICATION,// authorize against the table operation so that location permissions can be checked if any 
Hive,WITHOUT_CLASSIFICATION,/* createReader(FileSystem fs Path path) throws IOException {      */
Hive,WITHOUT_CLASSIFICATION,//  This is needed to prevent the HikariDataSource from trying to connect to the DB 
Hive,WITHOUT_CLASSIFICATION,//  Set data location and input format it must be text 
Hive,WITHOUT_CLASSIFICATION,//  pending change to boolean 
Hive,WITHOUT_CLASSIFICATION,/*    * Convert the work containing to sort-merge join into a work as if it had a regular join.   * Note that the operator tree is not changed - is still contains the SMB join but the   * plan is changed (aliasToWork etc.) to contain all the paths as if it was a regular join.    */
Hive,WITHOUT_CLASSIFICATION,//  bucket 
Hive,WITHOUT_CLASSIFICATION,//  No need to discard the buffer we cannot lock - eviction takes care of that. 
Hive,WITHOUT_CLASSIFICATION,//  increment the min txn id so that heartbeat thread will heartbeat only from the next open transaction.   the current transaction is going to committed or fail so don't need heartbeat for current transaction. 
Hive,WITHOUT_CLASSIFICATION,//  no data left in current page load data from new page 
Hive,WITHOUT_CLASSIFICATION,//  object equality - isSame means that the objects are semantically equal. 
Hive,WITHOUT_CLASSIFICATION,//  currentInputFile will be updated only by inputFileChanged(). If inputFileChanged()   is not called throughout the operator tree currentInputPath won't be used anyways 
Hive,WITHOUT_CLASSIFICATION,//  destination partition if any   the intermediate destination directory   the final destination directory 
Hive,WITHOUT_CLASSIFICATION,//  The left child is not a join or multijoin operator 
Hive,WITHOUT_CLASSIFICATION,//  We must read through fields we do not want. 
Hive,WITHOUT_CLASSIFICATION,//  Ensure PartInfo's TableInfo is initialized. 
Hive,WITHOUT_CLASSIFICATION,//  3. create subquery 
Hive,WITHOUT_CLASSIFICATION,// returns true if statement represented by line is  not complete and needs additional reading from  console. Used in handleMultiLineCmd method 
Hive,WITHOUT_CLASSIFICATION,//  r2 can only start once 1 fragment has completed. the map should be clear at this point. 
Hive,WITHOUT_CLASSIFICATION,//  TODO: we use MetadataTypedColumnsetSerDe for now till DynamicSerDe is ready 
Hive,WITHOUT_CLASSIFICATION,/*    * Same responsibility as initializeOI but for the RawInput.    */
Hive,WITHOUT_CLASSIFICATION,//  hive depends on FileSplits 
Hive,WITHOUT_CLASSIFICATION,//  IMPORTANT NOTE: For Multi-AND the VectorizationContext class will catch cases with 3 or                   more parameters... 
Hive,WITHOUT_CLASSIFICATION,//  Initialization isn't finished until all parents of all operators   are initialized. For broadcast joins that means initializing the   dummy parent operators as well. 
Hive,WITHOUT_CLASSIFICATION,//  mapjoin later 
Hive,WITHOUT_CLASSIFICATION,//                   newState                    -----------------------------------------   columnStatsState | COMPLETE          PARTIAL      NONE    |                    |________________________________________|           COMPLETE | COMPLETE          PARTIAL      PARTIAL |            PARTIAL | PARTIAL           PARTIAL      PARTIAL |               NONE | COMPLETE          PARTIAL      NONE    | 
Hive,WITHOUT_CLASSIFICATION,//  Case 2: If there's delay for the heartbeat but the delay is within the reaper's tolerance           then txt should be able to commit 
Hive,WITHOUT_CLASSIFICATION,//  The number of data columns that the current reader will return.   Only applicable for vector/row deserialization. 
Hive,WITHOUT_CLASSIFICATION,//  Initialize with data type conversion parameters. 
Hive,WITHOUT_CLASSIFICATION,// no validation required.. 
Hive,WITHOUT_CLASSIFICATION,//  Trigger scheduling since a new node became available. 
Hive,WITHOUT_CLASSIFICATION,//  there is nothing to change 
Hive,WITHOUT_CLASSIFICATION,//  Invalid values 
Hive,WITHOUT_CLASSIFICATION,//  DEVENAGARI SIGN VIRAMA U+094D (3 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  Compare the Mapper get at offset method to the list of mappings 
Hive,WITHOUT_CLASSIFICATION,//  Store the previous value for the path specification 
Hive,WITHOUT_CLASSIFICATION,//  All good no such partition exists move on. 
Hive,WITHOUT_CLASSIFICATION,//  posMap is an unfortunate consequence of batching/iterating thru MS results. 
Hive,WITHOUT_CLASSIFICATION,//  In case of viewfs we need to lookup where the actual file is to know the filesystem in use.   resolvePath is a sure shot way of knowing which file system the file is. 
Hive,WITHOUT_CLASSIFICATION,//  6. Construct SetOp Rel 
Hive,WITHOUT_CLASSIFICATION,//  localTmpPath is the root of all the stats.   Under it there will be SEL_1/statsfiles SEL_2/statsfiles etc where SEL_1 and SEL_2 are the op ids. 
Hive,WITHOUT_CLASSIFICATION,//  apply schema evolution by adding some columns 
Hive,WITHOUT_CLASSIFICATION,//  no more data 
Hive,WITHOUT_CLASSIFICATION,//  ROLE_PRIVILEGES 
Hive,WITHOUT_CLASSIFICATION,//  Format a clustered by statement 
Hive,WITHOUT_CLASSIFICATION,//  Drop one function see what remains 
Hive,WITHOUT_CLASSIFICATION,//  To compute seconds we first subtract the milliseconds stored in the nanos field of the   Timestamp from the result of getTime(). 
Hive,WITHOUT_CLASSIFICATION,//  Avoid allocating temporary variables for special cases: signum or scale is zero 
Hive,WITHOUT_CLASSIFICATION,//  We don't expect missing buckets from mere (actually there should be no buckets)   so just pass null as bucketing context. Union suffix should also be accounted for. 
Hive,WITHOUT_CLASSIFICATION,//  optional .QueryIdentifierProto query_identifier = 3; 
Hive,WITHOUT_CLASSIFICATION,//  TABLES_USED 
Hive,WITHOUT_CLASSIFICATION,// There should be one argument that is a array of struct 
Hive,WITHOUT_CLASSIFICATION,//  The join filters out the nulls.  So it's ok if there are 
Hive,WITHOUT_CLASSIFICATION,//  convert seconds to milliseconds 
Hive,WITHOUT_CLASSIFICATION,//  Native vectorization not supported. 
Hive,WITHOUT_CLASSIFICATION,//  Loop through all the inputs to determine the appropriate return type/length.   Return type:    All CHAR inputs: return CHAR    All VARCHAR inputs: return VARCHAR    All CHAR/VARCHAR inputs: return VARCHAR    All BINARY inputs: return BINARY    Otherwise return STRING 
Hive,WITHOUT_CLASSIFICATION,//  do error checking later and detect just a dot. 
Hive,WITHOUT_CLASSIFICATION,// explicitly close ZKDatabase since ZookeeperServer does not close them 
Hive,WITHOUT_CLASSIFICATION,//  Required for insertion into a TreeMap 
Hive,WITHOUT_CLASSIFICATION,// no op 
Hive,WITHOUT_CLASSIFICATION,//  There can never be more concurrent takers than uncommitted ones. 
Hive,WITHOUT_CLASSIFICATION,//  Also add ZK settings to clusterSpecificConf to make sure these get picked up by whoever started this. 
Hive,WITHOUT_CLASSIFICATION,// Any preexisting datanucleus property should be passed along 
Hive,WITHOUT_CLASSIFICATION,//  Struct value is simply a list of values.   The schema can be used to map the field name to the position in the list. 
Hive,WITHOUT_CLASSIFICATION,//  an IntWritable so we can just sum in the reduce 
Hive,WITHOUT_CLASSIFICATION,//  Walk over the input row resolver and copy in the output 
Hive,WITHOUT_CLASSIFICATION,//  ^(TOK_RESOURCE_URI $resType $resPath) 
Hive,WITHOUT_CLASSIFICATION,//  ==== Hive command operations ends here ==== // 
Hive,WITHOUT_CLASSIFICATION,//  We can be pretty sure that an entire line can be processed as a single command since   we always add a line separator at the end while calling dbCommandParser.buildCommand. 
Hive,WITHOUT_CLASSIFICATION,//  Prevent construction outside the get() method. 
Hive,WITHOUT_CLASSIFICATION,//  note the sync marker "seen" in the header 
Hive,WITHOUT_CLASSIFICATION,//  If data was moved from original location to cache directory we need to move it back! 
Hive,WITHOUT_CLASSIFICATION,//  now add the tables and columns from the current connection 
Hive,WITHOUT_CLASSIFICATION,// not block each other since they are part of the same txn 
Hive,WITHOUT_CLASSIFICATION,//  If there is a current unread chunk read from that or else get the next chunk. 
Hive,WITHOUT_CLASSIFICATION,//  deserialize split 
Hive,WITHOUT_CLASSIFICATION,//  multiple means of lookup 
Hive,WITHOUT_CLASSIFICATION,//  make sure if there is subquery it is top level expression 
Hive,WITHOUT_CLASSIFICATION,//  use existing location 
Hive,WITHOUT_CLASSIFICATION,//  this is where we set the sort columns that we will be using for KeyValueInputMerge 
Hive,WITHOUT_CLASSIFICATION,//  If we cache helper data for deserialization we could avoid having 
Hive,WITHOUT_CLASSIFICATION,//  whatever we have 
Hive,WITHOUT_CLASSIFICATION,//  final long roundMultiplyFactor = powerOfTenTable[LONGWORD_DECIMAL_DIGITS - absRoundPower]; 
Hive,WITHOUT_CLASSIFICATION,//  reset data container to prevent it being added again. 
Hive,WITHOUT_CLASSIFICATION,//  Not a lot you can do here. 
Hive,WITHOUT_CLASSIFICATION,//  if we are dealing with a bag or tuple column - need to worry about subschema 
Hive,WITHOUT_CLASSIFICATION,//  Are we forcing the usage of VectorUDFAdaptor for test purposes? 
Hive,WITHOUT_CLASSIFICATION,//  Update field collations 
Hive,WITHOUT_CLASSIFICATION,//  regex of the form: ${column name}. Following characters are not allowed in column name: 
Hive,WITHOUT_CLASSIFICATION,//  For non-vectorized operator case wrap the reader if possible. 
Hive,WITHOUT_CLASSIFICATION,//  String storage type overrides table level default of binary storage 
Hive,WITHOUT_CLASSIFICATION,//  Alas we crossed some DST boundary. If the time of day doesn't matter to the caller we'll 
Hive,WITHOUT_CLASSIFICATION,//  NULLS 
Hive,WITHOUT_CLASSIFICATION,//  clear JoinTree and OP Parse Context 
Hive,WITHOUT_CLASSIFICATION,//  We might generate a Select operator on top of the join operator for   semijoin 
Hive,WITHOUT_CLASSIFICATION,// serialize path offset length using FileSplit 
Hive,WITHOUT_CLASSIFICATION,//  Big case: write the length as a VInt and then the value bytes. 
Hive,WITHOUT_CLASSIFICATION,//  let's validate that the serde exists 
Hive,WITHOUT_CLASSIFICATION,//  Find the immediate parent possible.   For eg: for a query like 'select * from V3' where V3 -> V2 V2 -> V1 V1 -> T   -> implies depends on.   T's parent would be V1   do not check last alias in the array for parent can not be itself. 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: tableAlias must be a valid non-ambiguous table alias   because we've checked that in TOK_TABLE_OR_COL's process method. 
Hive,WITHOUT_CLASSIFICATION,//  Compute the keys 
Hive,WITHOUT_CLASSIFICATION,//  Can't use toArray here because Java is dumb when it comes to   generics + arrays. 
Hive,WITHOUT_CLASSIFICATION,/*    * Initialize using data type names.   * No projection -- the column range 0 .. types.size()-1    */
Hive,WITHOUT_CLASSIFICATION,// User specified a row limit set it on the Query 
Hive,WITHOUT_CLASSIFICATION,//  whether this vertex is dummy (which does not really exists but is created) 
Hive,WITHOUT_CLASSIFICATION,//  The set of join operators which can be converted to a bucketed map join 
Hive,WITHOUT_CLASSIFICATION,// simulate Update of 1 partitions; depending on causeConflict choose one of the partitions 
Hive,WITHOUT_CLASSIFICATION,// replace column references in checkExprAST with corresponding columns in input 
Hive,WITHOUT_CLASSIFICATION,//  UTC has no such adjustment 
Hive,WITHOUT_CLASSIFICATION,//  The first input of a Correlator is always the rel defining 
Hive,WITHOUT_CLASSIFICATION,//  tests not setting maxRows (return all)   tests setting maxRows to 0 (return all) 
Hive,WITHOUT_CLASSIFICATION,//  Nothing to do bail out 
Hive,WITHOUT_CLASSIFICATION,//  Nothing to do if there is no operator tree associated with   sourceAlias in source or there is not operator tree associated   with targetAlias in target. 
Hive,WITHOUT_CLASSIFICATION,//  events for the source. #colums X #tasks 
Hive,WITHOUT_CLASSIFICATION,//  One of the params is null then expected is null. 
Hive,WITHOUT_CLASSIFICATION,//  A TS can have multiple branches due to DPP Or Semijoin Opt. 
Hive,WITHOUT_CLASSIFICATION,//  Throw an exception if the user is trying to truncate a column which doesn't exist 
Hive,WITHOUT_CLASSIFICATION,//  Use the object we already have. 
Hive,WITHOUT_CLASSIFICATION,//  This is a new key keep writing the first record. 
Hive,WITHOUT_CLASSIFICATION,// since this is inside a delta dir created by Hive 2.x or earlier it can only contain  bucket_x or bucket_x__flush_length 
Hive,WITHOUT_CLASSIFICATION,// add the archive file to distributed cache 
Hive,WITHOUT_CLASSIFICATION,// new table 
Hive,WITHOUT_CLASSIFICATION,//  Intermediate key - anything between /key= and the following / 
Hive,WITHOUT_CLASSIFICATION,//  User specified fraction always takes precedence 
Hive,WITHOUT_CLASSIFICATION,//  clone the column stats and return 
Hive,WITHOUT_CLASSIFICATION,//  Replacement is allowed as the existing table is older than event 
Hive,WITHOUT_CLASSIFICATION,//  Now add to the projUniqueKeySet the child keys that are fully   projected. 
Hive,WITHOUT_CLASSIFICATION,//  If the Gby key is a constant 
Hive,WITHOUT_CLASSIFICATION,//  A limit on the number of threads that can be launched 
Hive,WITHOUT_CLASSIFICATION,//  If all BigTable input columns to key expressions are isRepeating then 
Hive,WITHOUT_CLASSIFICATION,//  Substitution option -d --define 
Hive,WITHOUT_CLASSIFICATION,//  Make sure metastore doesn't mess with our bogus stats updates. 
Hive,WITHOUT_CLASSIFICATION,//  enforce a minimum precision factor 
Hive,WITHOUT_CLASSIFICATION,//  Just examine the lower word. 
Hive,WITHOUT_CLASSIFICATION,//  Position of the *single* native vector map join small table. 
Hive,WITHOUT_CLASSIFICATION,//  Test that database and table don't coalesce. 
Hive,WITHOUT_CLASSIFICATION,//  Not a HS2 generated cookie continue. 
Hive,WITHOUT_CLASSIFICATION,//  Serialize the value 
Hive,WITHOUT_CLASSIFICATION,//  URLDecoder is a misnamed class since it actually decodes   x-www-form-urlencoded MIME type rather than actual   URL encoding (which the file path has). Therefore it would   decode +s to ' 's which is incorrect (spaces are actually   either unencoded or encoded as "%20"). Replace +s first so   that they are kept sacred during the decoding process. 
Hive,WITHOUT_CLASSIFICATION,//  Granularity (partition) column 
Hive,WITHOUT_CLASSIFICATION,//  Bucket 0 should be small and bucket 1 should be large make sure that's the case 
Hive,WITHOUT_CLASSIFICATION,//  a list of leaves that weren't under AND expressions 
Hive,WITHOUT_CLASSIFICATION,//  Note: due to TEZ-3846 the session may actually be invalid in case of some errors.         Currently reopen on an attempted reuse will take care of that; we cannot tell         if the session is usable until we try.   We return this to the pool even if it's unusable; reopen is supposed to handle this. 
Hive,WITHOUT_CLASSIFICATION,//  A udf which sleeps for 100ms to simulate a long running query 
Hive,WITHOUT_CLASSIFICATION,//  Pass. 
Hive,WITHOUT_CLASSIFICATION,//  just return 
Hive,WITHOUT_CLASSIFICATION,//  Update the state to removed-from-list so that parallel notifyUnlock doesn't modify us. 
Hive,WITHOUT_CLASSIFICATION,//  We need a input object inspector that is for the row we will extract out of the   vectorized row batch not for example an original inspector for an ORC table etc. 
Hive,WITHOUT_CLASSIFICATION,//  Since subtraction is not commutative we can must subtract in the order passed in. 
Hive,WITHOUT_CLASSIFICATION,//  Set tez execution summary to false. 
Hive,WITHOUT_CLASSIFICATION,// length file count directory count 
Hive,WITHOUT_CLASSIFICATION,//  The column is partition column skip the optimization. 
Hive,WITHOUT_CLASSIFICATION,//  right's signum wins (notice the negation because we are   subtracting right) 
Hive,WITHOUT_CLASSIFICATION,//  --failover <workerIdentity> 
Hive,WITHOUT_CLASSIFICATION,//  create tables 
Hive,WITHOUT_CLASSIFICATION,//  Best effort 
Hive,WITHOUT_CLASSIFICATION,//  Skip the counting if the values are the same for windowing COUNT(DISTINCT) case 
Hive,WITHOUT_CLASSIFICATION,//  There is only one blank in UTF-8. 
Hive,WITHOUT_CLASSIFICATION,//  get the tables for the desired pattern - populate the output stream 
Hive,WITHOUT_CLASSIFICATION,//  This may change after every setMapJoinKey call 
Hive,WITHOUT_CLASSIFICATION,//  return static variable with results if it is set to some set of   values 
Hive,WITHOUT_CLASSIFICATION,//  optional int32 physical_edge_count = 3; 
Hive,WITHOUT_CLASSIFICATION,//  Verify mergeAndMoveTask is NOT optimized 
Hive,WITHOUT_CLASSIFICATION,//  This was added during plan generation. 
Hive,WITHOUT_CLASSIFICATION,//  No GROUP BY / DISTRIBUTE BY / SORT BY / CLUSTER BY 
Hive,WITHOUT_CLASSIFICATION,//  race protection 
Hive,WITHOUT_CLASSIFICATION,//  "ready for cleaning" state in this case. 
Hive,WITHOUT_CLASSIFICATION,//  Simple trims. 
Hive,WITHOUT_CLASSIFICATION,//  do not split 
Hive,WITHOUT_CLASSIFICATION,//  The last key column is the dummy grouping set id.     Figure out which (scratch) column was used so we can overwrite the dummy id. 
Hive,WITHOUT_CLASSIFICATION,//  Non-encrypted path (or equals strength) 
Hive,WITHOUT_CLASSIFICATION,//  -f <script file> 
Hive,WITHOUT_CLASSIFICATION,/*      * Ignore any predicates on partition columns because we have already     * accounted for these in the Table row count.      */
Hive,WITHOUT_CLASSIFICATION,//  Thread name for reporter thread 
Hive,WITHOUT_CLASSIFICATION,//  do not overwrite if there are duplicate keys 
Hive,WITHOUT_CLASSIFICATION,//  Partition keys can not be set but getTableWithAllParametersSet is added one so remove for 
Hive,WITHOUT_CLASSIFICATION,//  Note: this may just block to wait for a session based on parallelism. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#setMaxFieldSize(int)    */
Hive,WITHOUT_CLASSIFICATION,//  Because we append the cq prefix when serializing the column 
Hive,WITHOUT_CLASSIFICATION,//  Stats values for col1 
Hive,WITHOUT_CLASSIFICATION,//  set up the client 
Hive,WITHOUT_CLASSIFICATION,//  stats of the big input 
Hive,WITHOUT_CLASSIFICATION,//  no-op for default output file 
Hive,WITHOUT_CLASSIFICATION,//  generate a ReduceSink operator for the join 
Hive,WITHOUT_CLASSIFICATION,// enables ORC PPD  create delta_0001_0001_0000 (should push predicate here) 
Hive,WITHOUT_CLASSIFICATION,//  string is 2 chars long (a 3 byte and a 4 byte char) 
Hive,WITHOUT_CLASSIFICATION,//  Merge stats from cache with metastore cache 
Hive,WITHOUT_CLASSIFICATION,//  Unique keys for this test. 
Hive,WITHOUT_CLASSIFICATION,//  protected boolean useMinMax; 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:QueryCompleteResponseProto) 
Hive,WITHOUT_CLASSIFICATION,//  remove the candidate filter ops 
Hive,WITHOUT_CLASSIFICATION,//  dictates which operator is allowed 
Hive,WITHOUT_CLASSIFICATION,//  if buffer is already allocated keep using it don't re-allocate 
Hive,WITHOUT_CLASSIFICATION,//  Finally put it in the ranges list for future use (if shared between RGs). 
Hive,WITHOUT_CLASSIFICATION,//  isatty system call will return 1 if the file descriptor is terminal else 0 
Hive,WITHOUT_CLASSIFICATION,//  add shutdown hook to flush the history to history file and it also close all open connections 
Hive,WITHOUT_CLASSIFICATION,//  Get the actual converted schema. 
Hive,WITHOUT_CLASSIFICATION,// TEST FAILED 
Hive,WITHOUT_CLASSIFICATION,//  fastIsShort returns false. 
Hive,WITHOUT_CLASSIFICATION,//  Dynamic value which will be determined during query runtime 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hadoop.mapreduce.RecordReader#getProgress()    */
Hive,WITHOUT_CLASSIFICATION,// this should not vectorize at all 
Hive,WITHOUT_CLASSIFICATION,//  Nothing to localize. 
Hive,WITHOUT_CLASSIFICATION,/*  Restore the hashmap from disk by deserializing it.     * Currently Kryo is used for this purpose.      */
Hive,WITHOUT_CLASSIFICATION,//  has nulls is repeating 
Hive,WITHOUT_CLASSIFICATION,//  Ignore the keys which are local to source warehouse 
Hive,WITHOUT_CLASSIFICATION,//  2.2 Check if GRpSet require additional MR Job 
Hive,WITHOUT_CLASSIFICATION,/*    * CHAR.    */
Hive,WITHOUT_CLASSIFICATION,//  3 rows 
Hive,WITHOUT_CLASSIFICATION,//  If the configured owner does not own the file throw 
Hive,WITHOUT_CLASSIFICATION,//  optional int32 vertex_index = 7; 
Hive,WITHOUT_CLASSIFICATION,/*    * Called to set the appropriate input format for tasks    */
Hive,WITHOUT_CLASSIFICATION,//  Grouping sets are not allowed   This restriction can be lifted in future. 
Hive,WITHOUT_CLASSIFICATION,//  index of FetchOperator which is providing smallest one 
Hive,WITHOUT_CLASSIFICATION,//  100 is for 2 longs BB and java overheads (semi-arbitrary). 
Hive,WITHOUT_CLASSIFICATION,//  - If the child is an AND operator extract its children 
Hive,WITHOUT_CLASSIFICATION,/*  * An multi-key value hash map optimized for vector map join. * * The key is uninterpreted bytes.  */
Hive,WITHOUT_CLASSIFICATION,//  Modify sourceTable. 
Hive,WITHOUT_CLASSIFICATION,//  Partition droppped after "repl dump" 
Hive,WITHOUT_CLASSIFICATION,//  no conversion needed and not variable-length argument:   just return what is passed in. 
Hive,WITHOUT_CLASSIFICATION,//  c16:array<struct<m:map<stringstring>n:int>>   c17:timestamp   c18:decimal(167)   c19:binary   c20:date   c21:varchar(20)   c22:char(15)   c23:binary 
Hive,WITHOUT_CLASSIFICATION,//  Setup web UI 
Hive,WITHOUT_CLASSIFICATION,// ************************************************************************************************   Decimal String Formatting. 
Hive,WITHOUT_CLASSIFICATION,//  Case 1 - Max in list members: 10; Max query string length: 1KB 
Hive,WITHOUT_CLASSIFICATION,//  15. Notify tests and global async ops. 
Hive,WITHOUT_CLASSIFICATION,//  Only allow integer index for now 
Hive,WITHOUT_CLASSIFICATION,//  test that values that we know are missing are shown to be absent 
Hive,WITHOUT_CLASSIFICATION,//  If reversedMemoryMB is set make memory allocation fraction adjustment as needed 
Hive,WITHOUT_CLASSIFICATION,//  Change query FetchTask to use new location specified in results cache. 
Hive,WITHOUT_CLASSIFICATION,//  ast expression is not a valid column name for table 
Hive,WITHOUT_CLASSIFICATION,//  Only need to run the logic for tables we missed 
Hive,WITHOUT_CLASSIFICATION,//  initialize configuration 
Hive,WITHOUT_CLASSIFICATION,//  Nothing to check 
Hive,WITHOUT_CLASSIFICATION,//  Register the cache-aware path so that Parquet reader would go thru it. 
Hive,WITHOUT_CLASSIFICATION,//  The following tests use serialized ASTs that I generated using Hive from   branch-0.14. 
Hive,WITHOUT_CLASSIFICATION,//  Test that 2 exclusive db locks coalesce to one 
Hive,WITHOUT_CLASSIFICATION,//  reset the bean: 
Hive,WITHOUT_CLASSIFICATION,//  It ends in a character this means they appended a time indicator (e.g. 600s) 
Hive,WITHOUT_CLASSIFICATION,// Running a normal async query with no exceptionsthen no need to close opHandle 
Hive,WITHOUT_CLASSIFICATION,//  rootTasks is the entry point for all generated tasks 
Hive,WITHOUT_CLASSIFICATION,//  called by map operator. propagated recursively to single parented descendants 
Hive,WITHOUT_CLASSIFICATION,//  Someone already allocated this arena; just do the usual thing. 
Hive,WITHOUT_CLASSIFICATION,//  VALUE 
Hive,WITHOUT_CLASSIFICATION,//  - Otherwise take the child itself 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setRowId(java.lang.String java.sql.RowId)    */
Hive,WITHOUT_CLASSIFICATION,//  A vectorized expression that we don't expect will be called due to short-circuit evaluation. 
Hive,WITHOUT_CLASSIFICATION,//  another query referring that property with the conf overlay should fail 
Hive,WITHOUT_CLASSIFICATION,//  fall-through 
Hive,WITHOUT_CLASSIFICATION,//  This check is necessary because for Spark branch the result array from   getInputPaths() above could be empty and therefore numThreads could be 0. 
Hive,WITHOUT_CLASSIFICATION,//  Delete the parent node if all the children have been deleted 
Hive,WITHOUT_CLASSIFICATION,//  no need for grouping and the target #of tasks.   This code path should never be triggered at the moment. If grouping is disabled   DAGUtils uses MRInputAMSplitGenerator. 
Hive,WITHOUT_CLASSIFICATION,//  the list has invalid port update with valid port 
Hive,WITHOUT_CLASSIFICATION,// the handling results 
Hive,WITHOUT_CLASSIFICATION,//  Get splits 
Hive,WITHOUT_CLASSIFICATION,// int 
Hive,WITHOUT_CLASSIFICATION,//  Bad value type. 
Hive,WITHOUT_CLASSIFICATION,//  Since hashCode is not used just put an arbitrary number 
Hive,WITHOUT_CLASSIFICATION,//  UDFOPPositive is a no-op.   However we still create it and then remove it here to make sure we   only allow 
Hive,WITHOUT_CLASSIFICATION,//  Check that constraints have catalog name properly set first 
Hive,WITHOUT_CLASSIFICATION,//  Evaluate ELSE expression (only) and copy all its results.   Second input parameter but 3rd column. 
Hive,WITHOUT_CLASSIFICATION,//  ConfVar overridden in in hive-site.xml 
Hive,WITHOUT_CLASSIFICATION,//  oldInput has the original group by keys in the front. 
Hive,WITHOUT_CLASSIFICATION,//  Don't increment the reader count for explain queries. 
Hive,WITHOUT_CLASSIFICATION,//  position of the biggest small table 
Hive,WITHOUT_CLASSIFICATION,//  Do not invert between result   add column expression here 
Hive,WITHOUT_CLASSIFICATION,//  Compute required mapping. 
Hive,WITHOUT_CLASSIFICATION,//  In the above example TS-1 -> RS-1 and TS-2 -> RS-2 are simple trees 
Hive,WITHOUT_CLASSIFICATION,// DB 
Hive,WITHOUT_CLASSIFICATION,//  Unlock database operation is to release the lock explicitly the   operation itself don't need to be locked. Set the WriteEntity as   WriteType: DDL_NO_LOCK here otherwise it will conflict with   Hive's transaction. 
Hive,WITHOUT_CLASSIFICATION,//  We cannot restart in place because the user might receive a failure and return the   session to the master thread without the "irrelevant" flag set. In fact the query might   have succeeded in the gap and the session might already be returned. Queue restart thru 
Hive,WITHOUT_CLASSIFICATION,/*  Note: In the following section Metadata-only import handling logic is       interleaved with regular repl-import logic. The rule of thumb being       followed here is that MD-only imports are essentially ALTERs. They do       not load data and should not be "creating" any metadata - they should       be replacing instead. The only place it makes sense for a MD-only import       to create is in the case of a table that's been dropped and recreated       or in the case of an unpartitioned table. In all other cases it should       behave like a noop or a pure MD alter.     */
Hive,WITHOUT_CLASSIFICATION,//  BlockingQueue methods 
Hive,WITHOUT_CLASSIFICATION,//  char 
Hive,WITHOUT_CLASSIFICATION,//  filterMode is 1 if condition is always true -1 if always false 
Hive,WITHOUT_CLASSIFICATION,/*  Return a random number with length digits as a string. Results may be   * negative or positive.    */
Hive,WITHOUT_CLASSIFICATION,//  *NON-NATIVE* vector map differences for LEFT OUTER JOIN and Filtered... 
Hive,WITHOUT_CLASSIFICATION,//  Ok no vectorized class available.  No problem -- try to use the VectorUDFAdaptor   when configured.     NOTE: We assume if hiveVectorAdaptorUsageMode has not been set it because we are   executing a test that didn't create a HiveConf etc.  No usage of VectorUDFAdaptor in   that case. 
Hive,WITHOUT_CLASSIFICATION,// Create a Server that doesn't interpret any Kerberos stuff 
Hive,WITHOUT_CLASSIFICATION,//  a maybe will kill the or condition 
Hive,WITHOUT_CLASSIFICATION,// S lock on T7 
Hive,WITHOUT_CLASSIFICATION,//  find available privileges 
Hive,WITHOUT_CLASSIFICATION,//  rootOperators are all the table scan operators in sequence   of traversal 
Hive,WITHOUT_CLASSIFICATION,//  if the move hasn't been made already 
Hive,WITHOUT_CLASSIFICATION,//  Debug/test related methods. 
Hive,WITHOUT_CLASSIFICATION,// create more staging data with copy_N files and do LD+Overwrite 
Hive,WITHOUT_CLASSIFICATION,//  Don't wait for the cluster if not started; this is best-effort. 
Hive,WITHOUT_CLASSIFICATION,//  End MultiJoin.java 
Hive,WITHOUT_CLASSIFICATION,//  Test empty database 
Hive,WITHOUT_CLASSIFICATION,//  In case it was done and noone looked at it. 
Hive,WITHOUT_CLASSIFICATION,/*      * Order columns are used as key columns for constructing     * the ReduceSinkOperator     * Since we do not explicitly add these to outputColumnNames     * we need to set includeKeyCols = false while creating the     * ReduceSinkDesc      */
Hive,WITHOUT_CLASSIFICATION,// This cover the case where hive table may have map<key value> but the data file is   of type array<struct<value1 value2>>  Using index in place of type name. 
Hive,WITHOUT_CLASSIFICATION,//  We must be on some unix variant.. 
Hive,WITHOUT_CLASSIFICATION,//  set the offset and length for the two elements 
Hive,WITHOUT_CLASSIFICATION,//  When deleteRecordId == currRecordIdInBatch this record in the batch has been deleted. 
Hive,WITHOUT_CLASSIFICATION,/*  Test parent references from Statement  */
Hive,WITHOUT_CLASSIFICATION,//  Remember all threads that were running at the time we started line processing.   Hook up the custom Ctrl+C handler while processing this line 
Hive,WITHOUT_CLASSIFICATION,//  this will be populated by MergeFileWork.resolveDynamicPartitionStoredAsSubDirsMerge   in case of dynamic partitioning and list bucketing 
Hive,WITHOUT_CLASSIFICATION,//  Dummy mapping used for all db and table name mappings 
Hive,WITHOUT_CLASSIFICATION,//  create a syntax tree for a function call "testudf(col0 col1 col2)" 
Hive,WITHOUT_CLASSIFICATION,/*    * Determine recursively if the PTF LEAD or LAG function is being used in an expression.    */
Hive,WITHOUT_CLASSIFICATION,//  if we have come this far - either the previous commands   are all successful or this is command line. in either case   this counts as a successful run 
Hive,WITHOUT_CLASSIFICATION,//  untyped nulls 
Hive,WITHOUT_CLASSIFICATION,//  Add partition cols if necessary (see VectorizedOrcInputFormat for details). 
Hive,WITHOUT_CLASSIFICATION,//  Combine 
Hive,WITHOUT_CLASSIFICATION,//  check round-ups before settings values to result. 
Hive,WITHOUT_CLASSIFICATION,//  HIVE-14444: pending refactor to push File forward 
Hive,WITHOUT_CLASSIFICATION,//  Get the RootLogger which if you don't have log4j2-test.properties defined will only log ERRORs 
Hive,WITHOUT_CLASSIFICATION,/*    * Initialize one column's target related arrays.    */
Hive,WITHOUT_CLASSIFICATION,//  Create the queryId appender for the queryId route 
Hive,WITHOUT_CLASSIFICATION,//  Map? 
Hive,WITHOUT_CLASSIFICATION,//  since same thread creates metastore client for streaming connection thread and heartbeat thread we explicitly   disable metastore client cache 
Hive,WITHOUT_CLASSIFICATION,//  Should fail because of the -1 
Hive,WITHOUT_CLASSIFICATION,//  Set during the init phase of HiveServer2 if auth mode is kerberos 
Hive,WITHOUT_CLASSIFICATION,//  Since this is a terminal operator update counters explicitly -   forward is not called 
Hive,WITHOUT_CLASSIFICATION,//  max fraction of errors allowed   throw error only after this many errors 
Hive,WITHOUT_CLASSIFICATION,//  Tez processor needs to configure object registry first. 
Hive,WITHOUT_CLASSIFICATION,//  capture arguments in static 
Hive,WITHOUT_CLASSIFICATION,//  return value as constant in case arg is constant 
Hive,WITHOUT_CLASSIFICATION,//  In beeline mode we need to hook to use connect go in case   the ShowDbInPrompt is set so the database name is needed 
Hive,WITHOUT_CLASSIFICATION,//  serialize using another serde and read out that object repr. 
Hive,WITHOUT_CLASSIFICATION,// There must be at least one column vector 
Hive,WITHOUT_CLASSIFICATION,//  Trim to the size needed 
Hive,WITHOUT_CLASSIFICATION,//  Create all children 
Hive,WITHOUT_CLASSIFICATION,//  order and null order 
Hive,WITHOUT_CLASSIFICATION,//  MAX_CREATE_TIME 
Hive,WITHOUT_CLASSIFICATION,//  Verify result is rounded to 4 digits 
Hive,WITHOUT_CLASSIFICATION,//  puts int in little endian order 
Hive,WITHOUT_CLASSIFICATION,//  Add new rel & its RR to the maps 
Hive,WITHOUT_CLASSIFICATION,//  1st query acquires the lock and takes 20 secs to compile 
Hive,WITHOUT_CLASSIFICATION,//  The operator tree till the sink operator needs to be processed while   fetching the next row to fetch from the priority queue (possibly containing   multiple files in the small table given a file in the big table). The remaining   tree will be processed while processing the join. 
Hive,WITHOUT_CLASSIFICATION,//  For now limit the data types we support for Vectorized Struct IN(). 
Hive,WITHOUT_CLASSIFICATION,//  That is implementation-defined. 
Hive,WITHOUT_CLASSIFICATION,//  Only create the movework for non-MM table. No action needed for a MM table. 
Hive,WITHOUT_CLASSIFICATION,//  file:///tmp/hcat_junit_warehouse/employee/_DYN0.7770480401313761/emp_country=IN/emp_state=KA  ->   file:///tmp/hcat_junit_warehouse/employee/emp_country=IN/emp_state=KA 
Hive,WITHOUT_CLASSIFICATION,//  Probably a view. 
Hive,WITHOUT_CLASSIFICATION,//  make sure create table fails. 
Hive,WITHOUT_CLASSIFICATION,//  initializes current key 
Hive,WITHOUT_CLASSIFICATION,//  We'll pass ThreadLocals in the background thread from the foreground (handler) thread.   1) ThreadLocal Hive object needs to be set in background thread   2) The metastore client in Hive is associated with right user.   3) Current UGI will get used by metastore when metastore is in embedded mode 
Hive,WITHOUT_CLASSIFICATION,// test_param_1 != "yellow" 
Hive,WITHOUT_CLASSIFICATION,//  the bucket to task map should have been setup by the big table. 
Hive,WITHOUT_CLASSIFICATION,/*          * add value to chain if it is not null or if skipNulls is false.          */
Hive,WITHOUT_CLASSIFICATION,//  Known to not have any nulls. 
Hive,WITHOUT_CLASSIFICATION,//  assertEquals(o struct); Cannot do this because types of null lists are   wrong. 
Hive,WITHOUT_CLASSIFICATION,//  Add all unique positions referenced. 
Hive,WITHOUT_CLASSIFICATION,//  Inspect the output type of each key expression. 
Hive,WITHOUT_CLASSIFICATION,//  1. Insert two rows to an MM table 
Hive,WITHOUT_CLASSIFICATION,//  Should go here. 
Hive,WITHOUT_CLASSIFICATION,/*    * todo: handle exclusion list   * Figures out which tables to make Acid MM and (optionally performs the operation)    */
Hive,WITHOUT_CLASSIFICATION,//  longest run of trailing zeroes 
Hive,WITHOUT_CLASSIFICATION,//  Update is included with the submit request; callback is via notifyStarted. 
Hive,WITHOUT_CLASSIFICATION,//  FIELDS 
Hive,WITHOUT_CLASSIFICATION,//  Only run for N milliseconds 
Hive,WITHOUT_CLASSIFICATION,//  first argument is charCount which is consumed in this method below 
Hive,WITHOUT_CLASSIFICATION,//  Invalidate all cache entries using this table. 
Hive,WITHOUT_CLASSIFICATION,//  Verify record was written correctly to Parquet 
Hive,WITHOUT_CLASSIFICATION,//  check metric value: 
Hive,WITHOUT_CLASSIFICATION,// expect to have happened by now since HIVE_TXN_TIMEOUT=1sec 
Hive,WITHOUT_CLASSIFICATION,//  Before anyone else accesses it it would have been allocated and decompressed locally. 
Hive,WITHOUT_CLASSIFICATION,//  TODO: This depends on Tez creating separate threads as it does now. If that changes some         other way to propagate/find out attempt ID would be needed (e.g. see TEZ-2587). 
Hive,WITHOUT_CLASSIFICATION,//  we can't use the cached table because it has spilled. 
Hive,WITHOUT_CLASSIFICATION,//  add tables to outputs 
Hive,WITHOUT_CLASSIFICATION,//  If this is an operator then we need to call the plan generation on the 
Hive,WITHOUT_CLASSIFICATION,//  runtime.getMax() gives a very different number from the actual Xmx sizing.   you can iterate through the   http://docs.oracle.com/javase/7/docs/api/java/lang/management/MemoryPoolMXBean.html   from java.lang.management to figure this out but the hard-coded params in the llap run.sh   result in 89% usable heap (-XX:NewRatio=8) + a survivor region which is technically not   in the usable space. 
Hive,WITHOUT_CLASSIFICATION,//  if custom pattern is set in case of dynamic partitioning configure custom path 
Hive,WITHOUT_CLASSIFICATION,//    <ResultCast> <Cleanup> <VectorExprArgType> 
Hive,WITHOUT_CLASSIFICATION,//  Wait for 1 minute and check again. 
Hive,WITHOUT_CLASSIFICATION,//  If METASTORE_HOME is set use it else use HIVE_HOME for backwards compatibility. 
Hive,WITHOUT_CLASSIFICATION,//  RELATIVE_PATH 
Hive,WITHOUT_CLASSIFICATION,/*    * This method generates the map of bucket to file splits.    */
Hive,WITHOUT_CLASSIFICATION,//  Read the newly added partition via CachedStore 
Hive,WITHOUT_CLASSIFICATION,//  Loop to get all task completion events because getTaskCompletionEvents 
Hive,WITHOUT_CLASSIFICATION,/*   From the hive logs(hive.log) we can also check for the info statement  fgrep "Total Tasks" [location of hive.log]  each line indicates one run of loadTask.    */
Hive,WITHOUT_CLASSIFICATION,//  e.g. ds=2008-04-08/hr=11 
Hive,WITHOUT_CLASSIFICATION,//  The connection was closed so create a new one. 
Hive,WITHOUT_CLASSIFICATION,// Handle table properties 
Hive,WITHOUT_CLASSIFICATION,//  This method takes something like String[] so it only accepts   something like String 
Hive,WITHOUT_CLASSIFICATION,//  the separators array   whether we need to escape the data when writing out   which char to use as the escape char e.g. '\\'   which chars need to be escaped.  
Hive,WITHOUT_CLASSIFICATION,//  Keep track of view alias to view name and read entity   For eg: for a query like 'select * from V3' where V3 -> V2 V2 -> V1 V1 -> T   keeps track of full view name and read entity corresponding to alias V3 V3:V2 V3:V2:V1. 
Hive,WITHOUT_CLASSIFICATION,//  We are not in HS2; always create a new client for now. 
Hive,WITHOUT_CLASSIFICATION,//  this is for artificially added tokens 
Hive,WITHOUT_CLASSIFICATION,//  production: Field()* 
Hive,WITHOUT_CLASSIFICATION,//  Create output directory if not already created. 
Hive,WITHOUT_CLASSIFICATION,//  Might be under the hive name 
Hive,WITHOUT_CLASSIFICATION,//  Hadoop FS ACLs do not work with LocalFileSystem so set up MiniDFS. 
Hive,WITHOUT_CLASSIFICATION,//  It isn't an error if the following returns no rows as the local workers could have died   with  nothing assigned to them. 
Hive,WITHOUT_CLASSIFICATION,//  "+" for numeric types. 
Hive,WITHOUT_CLASSIFICATION,//  Get value element information 
Hive,WITHOUT_CLASSIFICATION,//  Stop HiveServer2 to increase header size 
Hive,WITHOUT_CLASSIFICATION,/*      * Notice the default value for LLAP_IO_ENABLED is overridden to be whether we are     * executing under LLAP.      */
Hive,WITHOUT_CLASSIFICATION,//  create fetchwork for non partitioned table 
Hive,WITHOUT_CLASSIFICATION,/*    * Reduce sink operator is the de-facto operator   * for determining keyCols (emit keys of a map phase)    */
Hive,WITHOUT_CLASSIFICATION,//  Spot check decimal column-column multiply 
Hive,WITHOUT_CLASSIFICATION,//  all columns in cluster and sort are valid columns 
Hive,WITHOUT_CLASSIFICATION,//  If issuing a query for all partitions verify that we need update the same columns. 
Hive,WITHOUT_CLASSIFICATION,//  remember the mapping in case we scan another branch of the 
Hive,WITHOUT_CLASSIFICATION,// Start with size 100 and double when needed. 
Hive,WITHOUT_CLASSIFICATION,//  Test down-casting when greater than 256. 
Hive,WITHOUT_CLASSIFICATION,//  0 is the function name 
Hive,WITHOUT_CLASSIFICATION,//  write bytes to bos ... 
Hive,WITHOUT_CLASSIFICATION,//  operand 
Hive,WITHOUT_CLASSIFICATION,//  Format: "always madvise [never]" 
Hive,WITHOUT_CLASSIFICATION,//  Set to true only when deregistration happens   Web UI 
Hive,WITHOUT_CLASSIFICATION,// may be the db is getting created in this load 
Hive,WITHOUT_CLASSIFICATION,//  threads while the constructor is running. 
Hive,WITHOUT_CLASSIFICATION,//  parenthesis at the end. 
Hive,WITHOUT_CLASSIFICATION,//  Drop table "tbl1" via ObjectStore 
Hive,WITHOUT_CLASSIFICATION,//  blank " " (1 byte) 
Hive,WITHOUT_CLASSIFICATION,//  The grouping set has not yet been processed. Create a new grouping key   Consider the query: select ab count(1) from T group by ab with cube;   where it is being executed in 2 map-reduce jobs   The plan for 1st MR is TableScan -> GroupBy1 -> ReduceSink -> GroupBy2 -> FileSink   GroupBy1/ReduceSink worked as if grouping sets were not present   This function is called for GroupBy2 to create new rows for grouping sets   For each input row (ab) 4 rows are created for the example above:   (ab) (anull) (null b) (null null) 
Hive,WITHOUT_CLASSIFICATION,//  Partnames: [tab1part1...tab1part9] 
Hive,WITHOUT_CLASSIFICATION,//  extract configs for processing by the python fragments in YARN Service 
Hive,WITHOUT_CLASSIFICATION,//  work should be the smallest unit for memory allocation 
Hive,WITHOUT_CLASSIFICATION,// so that we know which version wrote the file 
Hive,WITHOUT_CLASSIFICATION,//  We add Hive keywords including lower-cased versions 
Hive,WITHOUT_CLASSIFICATION,//  we have found the colName. No need to search more exprNodes. 
Hive,WITHOUT_CLASSIFICATION,//  It is assumed isLazy flag is set only for REPL LOAD flow.   IMPORT always do deep copy. So distCpDoAsUser will be null by default in ReplCopyWork. 
Hive,WITHOUT_CLASSIFICATION,//  Set the appropriate key in the map and test that we are able to read it back correctly. 
Hive,WITHOUT_CLASSIFICATION,//  1. Recompose filter possibly by pulling out common elements from DNF   expressions 
Hive,WITHOUT_CLASSIFICATION,//  inline merge join operator in a self-join 
Hive,WITHOUT_CLASSIFICATION,// http://https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2/src/packages/templates/conf/hdfs-site.xml 
Hive,WITHOUT_CLASSIFICATION,//  skewed column names 
Hive,WITHOUT_CLASSIFICATION,//  At this point if we haven't found it screw it we don't know where it is 
Hive,WITHOUT_CLASSIFICATION,//  alias to key mapping 
Hive,WITHOUT_CLASSIFICATION,//  Unsigned 64 max. 
Hive,WITHOUT_CLASSIFICATION,/*    * Job state of job request. Changes to the state are synchronized using   * setStateAndResult. This is required due to two different threads   * main thread and job execute thread tries to change state and organize   * clean up tasks.    */
Hive,WITHOUT_CLASSIFICATION,//  Decimal point. 
Hive,WITHOUT_CLASSIFICATION,// perform some Update/Delete 
Hive,WITHOUT_CLASSIFICATION,//  6. Finally put uncompressed data to cache. 
Hive,WITHOUT_CLASSIFICATION,//  Object inspector hasn't been cached for this type/params yet create now 
Hive,WITHOUT_CLASSIFICATION,//  print dependent vertexs 
Hive,WITHOUT_CLASSIFICATION,//  insiderView will tell this TableScan is inside a view or not. 
Hive,WITHOUT_CLASSIFICATION,/*    *  Pre-allocated members for storing information equal key series for small-table matches.   *   *  ~HashMapResultIndices   *                Index into the hashMapResults array for the match.   *  ~AllMatchIndices   *                (Logical) indices into allMatchs to the first row of a match of a   *                possible series of duplicate keys.   *  ~IsSingleValue   *                Whether there is 1 or multiple small table values.   *  ~DuplicateCounts   *                The duplicate count for each matched key.   *    */
Hive,WITHOUT_CLASSIFICATION,//  If checksum does not match likely the file is changed/removed retry from CM path 
Hive,WITHOUT_CLASSIFICATION,//  Safety check for postconditions 
Hive,WITHOUT_CLASSIFICATION,//  required   required   optional   optional   required   required   optional   required   optional   required   required   optional   optional   optional   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  This will throw NoSuchLockException (even though it's the   transaction we've closed) because that will have deleted the lock. 
Hive,WITHOUT_CLASSIFICATION,//  Doesn't clear underlying hashtable 
Hive,WITHOUT_CLASSIFICATION,//  1. Simulate emitting all records in closeRecordProcessor(). 
Hive,WITHOUT_CLASSIFICATION,//  initialize the integer values 
Hive,WITHOUT_CLASSIFICATION,//  PARENT_TABLE_NAME 
Hive,WITHOUT_CLASSIFICATION,//  Check whether we are replicating 
Hive,WITHOUT_CLASSIFICATION,// this is a checked expression use a different template for checked expressions 
Hive,WITHOUT_CLASSIFICATION,//  CombinedSplit. 
Hive,WITHOUT_CLASSIFICATION,//  If there are no new segments we can just bail out 
Hive,WITHOUT_CLASSIFICATION,//  Suppress headers and all objects below. 
Hive,WITHOUT_CLASSIFICATION,//  process join filters 
Hive,WITHOUT_CLASSIFICATION,//  The lock for ZK updates. 
Hive,WITHOUT_CLASSIFICATION,//  This is solely for testing.  It checks if the test has set the looped value to false   and if so remembers that and then sets it to true at the end.  We have to check here 
Hive,WITHOUT_CLASSIFICATION,//  replace original VAR_SAMP(x) with       (SUM(x * x) - SUM(x) * SUM(x) / COUNT(x))       / CASE COUNT(x) WHEN 1 THEN NULL ELSE COUNT(x) - 1 END 
Hive,WITHOUT_CLASSIFICATION,// "delete from tab1" txn 
Hive,WITHOUT_CLASSIFICATION,//  This is the last RG for which this buffer will be used. Remove the initial refcount 
Hive,WITHOUT_CLASSIFICATION,//  one of the tables that is not in memory 
Hive,WITHOUT_CLASSIFICATION,//  should not be happened. ignore remaining 
Hive,WITHOUT_CLASSIFICATION,//  Don't want to attempt to grab more memory than we have available .. percentage is a bit arbitrary 
Hive,WITHOUT_CLASSIFICATION,//  could be the min_uncommitted_txnid if lesser than NEXT_TXN_ID.ntxn_next. 
Hive,WITHOUT_CLASSIFICATION,//  then we throw an exception 
Hive,WITHOUT_CLASSIFICATION,//  This is not bulletproof but should allow us to close session in most cases. 
Hive,WITHOUT_CLASSIFICATION,//  Create random test string 
Hive,WITHOUT_CLASSIFICATION,//  Arithmetic operations reset the results. 
Hive,WITHOUT_CLASSIFICATION,//  Set up the session for driver. 
Hive,WITHOUT_CLASSIFICATION,//  Create the corresponding hive expression to filter on partition columns. 
Hive,WITHOUT_CLASSIFICATION,//  bit packing disabled 
Hive,WITHOUT_CLASSIFICATION,//  If a single quote is seen and the index is not inside a double quoted string and the previous character   was not an escape then update the hasUnterminatedSingleQuote flag 
Hive,WITHOUT_CLASSIFICATION,//  No compatible MapWork. 
Hive,WITHOUT_CLASSIFICATION,//  on top. We will add it. 
Hive,WITHOUT_CLASSIFICATION,//  use deep hashcode for arrays 
Hive,WITHOUT_CLASSIFICATION,//  nothing to do - we are not running in local mode - only submitting   the job via a child process. in this case it's appropriate that the   child jvm use the same memory as the parent jvm 
Hive,WITHOUT_CLASSIFICATION,//  introducing explicit aliases for tbl. 
Hive,WITHOUT_CLASSIFICATION,//  10000000....000 
Hive,WITHOUT_CLASSIFICATION,//  check if all parent statistics are available 
Hive,WITHOUT_CLASSIFICATION,// Environment Variables short values 
Hive,WITHOUT_CLASSIFICATION,//  mergeable in next loop iteration. 
Hive,WITHOUT_CLASSIFICATION,//  Mark a fragment as completing but don't actually complete it yet.   The wait queue should now have capacity to accept one more fragment. 
Hive,WITHOUT_CLASSIFICATION,//  Add the support for read variations in Vectorized Text. 
Hive,WITHOUT_CLASSIFICATION,//  second batch to last but one batch will be actualBatchSize   actualBatchSize is same as batchSize when no exceptions are expected 
Hive,WITHOUT_CLASSIFICATION,//  big tables that should be streamed 
Hive,WITHOUT_CLASSIFICATION,//  1. Get alias from topOps 
Hive,WITHOUT_CLASSIFICATION,//  End HiveRemoveGBYSemiJoinRule 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   required   optional 
Hive,WITHOUT_CLASSIFICATION,//  get all the dependencies to delete 
Hive,WITHOUT_CLASSIFICATION,//  this is the constructor to use for SMB. 
Hive,WITHOUT_CLASSIFICATION,//  mGby1 ---already contains group by key we need to remove distinct column 
Hive,WITHOUT_CLASSIFICATION,//  check if the join operator encountered is a candidate for being converted 
Hive,WITHOUT_CLASSIFICATION,//  if all children are done this operator is also done 
Hive,WITHOUT_CLASSIFICATION,//  test with null or empty randomly 
Hive,WITHOUT_CLASSIFICATION,//  VectorDeserializeRow produces "sparse" VRB when includes are used; we need to write the   "dense" VRB to ORC. Ideally we'd use projection columns but ORC writer doesn't use them.   In any case we would also need to build a new OI for OrcWriter config.   This is why OrcWriter is created after this writer by the way. 
Hive,WITHOUT_CLASSIFICATION,//  used to store each value's length 
Hive,WITHOUT_CLASSIFICATION,//  Assumes no ranges passed to cache to read have data. 
Hive,WITHOUT_CLASSIFICATION,//  We will split the block at headerIx [splitWays] ways and take [toTake] blocks   which will leave [lastSplitBlocksRemaining] free blocks of target size. 
Hive,WITHOUT_CLASSIFICATION,//  create a new InputFormat instance if this is the first time to see 
Hive,WITHOUT_CLASSIFICATION,//  new connections goes to miniHS2_1 now 
Hive,WITHOUT_CLASSIFICATION,//  Convert integer related types because converters are not sufficient 
Hive,WITHOUT_CLASSIFICATION,//  the session hook should set the property 
Hive,WITHOUT_CLASSIFICATION,//  STRING_STATS 
Hive,WITHOUT_CLASSIFICATION,//  end of month behavior 
Hive,WITHOUT_CLASSIFICATION,//  FULL_RESOURCE_PLAN 
Hive,WITHOUT_CLASSIFICATION,/*    * Waits for other threads to join and returns with its Id.    */
Hive,WITHOUT_CLASSIFICATION,//  refer paper 
Hive,WITHOUT_CLASSIFICATION,//  for ExprNodeGenericFuncDesc it should be deterministic and stateless 
Hive,WITHOUT_CLASSIFICATION,//  Setting a non important configuration should return the same client only 
Hive,WITHOUT_CLASSIFICATION,//  Load to an empty database 
Hive,WITHOUT_CLASSIFICATION,// null server url means local mode 
Hive,WITHOUT_CLASSIFICATION,/*      * Setup the overflow batch.      */
Hive,WITHOUT_CLASSIFICATION,//  get list of dynamic partitions 
Hive,WITHOUT_CLASSIFICATION,// 1. get the ColumnStatsSemanticAnalyzer 
Hive,WITHOUT_CLASSIFICATION,//  Only two elements expected in partExprParts partition column name and partition value 
Hive,WITHOUT_CLASSIFICATION,//  Optimize revoke/grant list remove the overlapping 
Hive,WITHOUT_CLASSIFICATION,//  A TS can have multiple branches due to DPP Or Semijoin Opt.   USe DFS to traverse all the branches until RS is hit. 
Hive,WITHOUT_CLASSIFICATION,//  2. Collect child projection indexes used 
Hive,WITHOUT_CLASSIFICATION,//  n != batch.size when isRepeating 
Hive,WITHOUT_CLASSIFICATION,//  no col names in parent 
Hive,WITHOUT_CLASSIFICATION,//  be a CM uri in the from path. 
Hive,WITHOUT_CLASSIFICATION,//  We don't want to check types already checked 
Hive,WITHOUT_CLASSIFICATION,//  optional .EntityDescriptorProto io_descriptor = 2; 
Hive,WITHOUT_CLASSIFICATION,//  End SubQueryRemoveRule.java 
Hive,WITHOUT_CLASSIFICATION,//  service not started yet 
Hive,WITHOUT_CLASSIFICATION,//  Set host 
Hive,WITHOUT_CLASSIFICATION,//  The first argument just set the return to be the standard   writable version of this OI. 
Hive,WITHOUT_CLASSIFICATION,//  Handle hint based semijoin 
Hive,WITHOUT_CLASSIFICATION,//  Evict all blocks. 
Hive,WITHOUT_CLASSIFICATION,//  2) Copy and fixup the parent list of the original child instead of just assuming a 1:1 
Hive,WITHOUT_CLASSIFICATION,//  minimum required. 
Hive,WITHOUT_CLASSIFICATION,//  Not used value. 
Hive,WITHOUT_CLASSIFICATION,//  This will also take care of the queries if query parallelism changed. 
Hive,WITHOUT_CLASSIFICATION,/*    * The current kinds of column vectors.    */
Hive,WITHOUT_CLASSIFICATION,//  One row per value. 
Hive,WITHOUT_CLASSIFICATION,//  check this project only projects one expression i.e. scalar 
Hive,WITHOUT_CLASSIFICATION,//  If null is returned then help message was displayed in parseCommandLine method 
Hive,WITHOUT_CLASSIFICATION,//  4. Same as 2. Also emit extra records from a separate thread. 
Hive,WITHOUT_CLASSIFICATION,//  Create an environment variable that uniquely identifies this script 
Hive,WITHOUT_CLASSIFICATION,//  we print the vertex that has more rs before the vertex that has fewer rs. 
Hive,WITHOUT_CLASSIFICATION,/*  Creates an empty union object.  */
Hive,WITHOUT_CLASSIFICATION,//  For non-generic UDF type info isn't available. This poses a problem for Hive Decimal. 
Hive,WITHOUT_CLASSIFICATION,//  constant map projection of known length 
Hive,WITHOUT_CLASSIFICATION,//  LOG.info("getJobTrackerDelegationToken("+conf+""+userName+")"); 
Hive,WITHOUT_CLASSIFICATION,//  VectorizedBatchUtil.debugDisplayOneRow(batch batchIndex CLASS_NAME + " MATCH isSingleValue " + equalKeySeriesIsSingleValue[equalKeySeriesCount] + " currentKey " + currentKey); 
Hive,WITHOUT_CLASSIFICATION,//  converts partNamespartVals into "partName1=val1 partName2=val2" 
Hive,WITHOUT_CLASSIFICATION,//  Marker to track if there is starting single quote without an ending double quote 
Hive,WITHOUT_CLASSIFICATION,//  Register Plain SASL server provider 
Hive,WITHOUT_CLASSIFICATION,//  Currently 3 known tasks. 1 2 5 
Hive,WITHOUT_CLASSIFICATION,//  This happens when the ReduceSink's edge has been removed by cycle   detection logic. Nothing to do here. 
Hive,WITHOUT_CLASSIFICATION,//  the MapJoin's parents may have been replaced by dummy operator. 
Hive,WITHOUT_CLASSIFICATION,//  Blindly add this as a non settable list of list of integers   should be sufficient for the test case.   Use the standard list object inspector. 
Hive,WITHOUT_CLASSIFICATION,//  roundPower < 0     Negative scale means we start rounding integer digits.     The result will integer result will have at least abs(roundPower) trailing digits.     Examples where the 'r's show the rounding digits:          round(12500 -3) = 13000           // BigDecimal.ROUND_HALF_UP                rrr     Or  ceiling(12400.8302 -2) = 12500     // BigDecimal.ROUND_CEILING                   rr rrrr     Notice that any fractional digits will be gone in the result. 
Hive,WITHOUT_CLASSIFICATION,//  Fake dead session 
Hive,WITHOUT_CLASSIFICATION,//  EmptyBuckets = false 
Hive,WITHOUT_CLASSIFICATION,//  if we have records left in the group we push one of those 
Hive,WITHOUT_CLASSIFICATION,//  the location string will be of the form:   <database name>.<table name> - parse it and   communicate the information to HCatInputFormat 
Hive,WITHOUT_CLASSIFICATION,//  We cannot merge 
Hive,WITHOUT_CLASSIFICATION,//  This is not an actual list; see intermList. 
Hive,WITHOUT_CLASSIFICATION,//  serialize again 
Hive,WITHOUT_CLASSIFICATION,//  Only publish stats if this operator's flag was set to gather stats 
Hive,WITHOUT_CLASSIFICATION,//  3. Prepare for next iteration (if any) 
Hive,WITHOUT_CLASSIFICATION,//  Dates are stored as long so convert and compare 
Hive,WITHOUT_CLASSIFICATION,//  broken configuration from mapred-default.xml 
Hive,WITHOUT_CLASSIFICATION,//  else fall through and add this condition as nonEqui condition 
Hive,WITHOUT_CLASSIFICATION,//  reset exec context so that initialization of the map operator happens   properly 
Hive,WITHOUT_CLASSIFICATION,//  Determine distKeyLength (w/o distincts) and then add the first if present. 
Hive,WITHOUT_CLASSIFICATION,//  No truncate (ASCII) -- same maximum length. 
Hive,WITHOUT_CLASSIFICATION,//  Create new value 
Hive,WITHOUT_CLASSIFICATION,//  let it create 57 partitions without any triggers 
Hive,WITHOUT_CLASSIFICATION,//  Turns out partition columns get marked as virtual in ColumnInfo so we need to 
Hive,WITHOUT_CLASSIFICATION,// Create the metastore client as the clientUgi. Doing so this  way will give the client access to the token that was added earlier 
Hive,WITHOUT_CLASSIFICATION,//  Remove the directories for aborted transactions only 
Hive,WITHOUT_CLASSIFICATION,// test will be in local mode 
Hive,WITHOUT_CLASSIFICATION,//  all the insane DST variations where we actually end up is anyone's guess. 
Hive,WITHOUT_CLASSIFICATION,//  using reflection and update the MDC. 
Hive,WITHOUT_CLASSIFICATION,//  Random column name to reduce the chance of conflict 
Hive,WITHOUT_CLASSIFICATION,//  Determine the partition columns using the first partition descriptor. 
Hive,WITHOUT_CLASSIFICATION,//  Partitions do not exist for this table 
Hive,WITHOUT_CLASSIFICATION,//  We pass all the checks we can rewrite 
Hive,WITHOUT_CLASSIFICATION,//  Table is valid 
Hive,WITHOUT_CLASSIFICATION,//  NOT NULL constraint could be enforced/enabled 
Hive,WITHOUT_CLASSIFICATION,//  1.2. We extract the information that we need 
Hive,WITHOUT_CLASSIFICATION,//  new hs2 instance session 
Hive,WITHOUT_CLASSIFICATION,//  no replacement the existing database state is newer than our update. 
Hive,WITHOUT_CLASSIFICATION,/*        * Trigger kill threads and verify we get InterruptedException and expected Message.        */
Hive,WITHOUT_CLASSIFICATION,/*        * Validate and vectorize the Map operator tree.        */
Hive,WITHOUT_CLASSIFICATION,//  Don't wait if empty - go to take() above that will wait for us. 
Hive,WITHOUT_CLASSIFICATION,//  Operator with single child 
Hive,WITHOUT_CLASSIFICATION,//  Skip header lines. 
Hive,WITHOUT_CLASSIFICATION,//  There should still now be 6 directories in the location 
Hive,WITHOUT_CLASSIFICATION,//  if cbo is enabled orderby position will be processed in genPlan 
Hive,WITHOUT_CLASSIFICATION,//  Should never happen... ctor is just assignments. 
Hive,WITHOUT_CLASSIFICATION,//  Already consistent. Can happen w/null lSG. 
Hive,WITHOUT_CLASSIFICATION,//  for NULL 
Hive,WITHOUT_CLASSIFICATION,//  GroupBy generates a new vectorized row batch... 
Hive,WITHOUT_CLASSIFICATION,//  We made sure the references are for different join inputs 
Hive,WITHOUT_CLASSIFICATION,/*    * Helper function to create Vertex for given ReduceWork.    */
Hive,WITHOUT_CLASSIFICATION,//  Counters with vertex name as suffix   desiredCounter = INPUT_FILES   counters: {INPUT_FILES_Map_1 : 5 INPUT_FILES_Map_4 : 10}   outcome: INPUT_FILE : 15 
Hive,WITHOUT_CLASSIFICATION,//  Add file paths of the files that will be moved to the destination if the caller needs it 
Hive,WITHOUT_CLASSIFICATION,//  Need to preserve enabled flag 
Hive,WITHOUT_CLASSIFICATION,//  get service host 
Hive,WITHOUT_CLASSIFICATION,// this simulates the completion of "Update tab2" txn 
Hive,WITHOUT_CLASSIFICATION,//  Get the cookie name 
Hive,WITHOUT_CLASSIFICATION,//  Register information about pushed predicates 
Hive,WITHOUT_CLASSIFICATION,//  the pruning needs to preserve the order of columns in the input schema 
Hive,WITHOUT_CLASSIFICATION,/*          * push filters only for this QBJoinTree. Child QBJoinTrees have already been handled.          */
Hive,WITHOUT_CLASSIFICATION,/*      * if the user has specified a queue name themselves we create a new session.     * also a new session is created if the user tries to submit to a queue using     * their own credentials. We expect that with the new security model things will     * run as user hive in most cases.      */
Hive,WITHOUT_CLASSIFICATION,//  Hadoop Configuration Properties   Properties with null values are ignored and exist only for the purpose of giving us   a symbolic name to reference in the Hive source code. Properties with non-null 
Hive,WITHOUT_CLASSIFICATION,//  it is not a terrible thing even if the data is not deleted 
Hive,WITHOUT_CLASSIFICATION,//  "length" of sync entries   number of bytes in hash   escape + hash 
Hive,WITHOUT_CLASSIFICATION,//  Don't set lineage on delete as we don't have all the columns 
Hive,WITHOUT_CLASSIFICATION,//  Now take the serialized keys we just wrote into our scratch column and look them   up in the IN list. 
Hive,WITHOUT_CLASSIFICATION,/*        * substitute OutputFormat name based on HiveFileFormatUtils.outputFormatSubstituteMap        */
Hive,WITHOUT_CLASSIFICATION,//  string. 
Hive,WITHOUT_CLASSIFICATION,//  no 0-sized block 
Hive,WITHOUT_CLASSIFICATION,//  Tests for the List<Partition> exchange_partitions(Map<String String> partitionSpecs String   sourceDb String sourceTable String destdb String destTableName) method 
Hive,WITHOUT_CLASSIFICATION,//  that recognizes parenthesis as a delimiter. 
Hive,WITHOUT_CLASSIFICATION,//  TTL check 
Hive,WITHOUT_CLASSIFICATION,//  Attempt to find maxAppendAttempts possible alternatives to a filename by   appending _a_N and seeing if that destination also clashes. If we're   still clashing after that give up. 
Hive,WITHOUT_CLASSIFICATION,// now we have delta_0003_0003_0000 with inserts only (ok to push predicate) 
Hive,WITHOUT_CLASSIFICATION,//  Ignore error just return the valid tables that are found. 
Hive,WITHOUT_CLASSIFICATION,//  Wait queue could have been re-ordered in the mean time because of concurrent task   submission. So remove the specific task instead of the head task. 
Hive,WITHOUT_CLASSIFICATION,//  First handle the actual thing we found. 
Hive,WITHOUT_CLASSIFICATION,//  look for matches in file system counters 
Hive,WITHOUT_CLASSIFICATION,//  Check fast0. 
Hive,WITHOUT_CLASSIFICATION,//  Verify if both groupset and aggrfunction are empty) 
Hive,WITHOUT_CLASSIFICATION,//  reset temp list index 
Hive,WITHOUT_CLASSIFICATION,//  The toDigitsOnlyBytes stores digits at the end of the scratch buffer. 
Hive,WITHOUT_CLASSIFICATION,//  Give the caller context for future errors. 
Hive,WITHOUT_CLASSIFICATION,//  If value is not a constant we bail out 
Hive,WITHOUT_CLASSIFICATION,//  Display all non-vectorized leaf objects unless ONLY. 
Hive,WITHOUT_CLASSIFICATION,//  Separate client to create the catalog 
Hive,WITHOUT_CLASSIFICATION,//     conf.setVar(HiveConf.ConfVars.METASTORE_CONNECTION_DRIVER "com.mysql.jdbc.Driver");      conf.setVar(HiveConf.ConfVars.METASTORECONNECTURLKEY          "jdbc:mysql://localhost:3306/metastore_db");      conf.setVar(HiveConf.ConfVars.METASTORE_CONNECTION_USER_NAME "");      conf.setVar(HiveConf.ConfVars.METASTOREPWD ""); 
Hive,WITHOUT_CLASSIFICATION,//  If there are no txns which are open for the given ValidTxnList snapshot then just return it. 
Hive,WITHOUT_CLASSIFICATION,//  All rows should be in the in-memory hashmap 
Hive,WITHOUT_CLASSIFICATION,/*      * Determine the 3 binary words like what SerializationUtils.readBigInteger does.      */
Hive,WITHOUT_CLASSIFICATION,//  Test that fetching a non-existent partition yields ObjectNotFound. 
Hive,WITHOUT_CLASSIFICATION,//  For caching column stats for an unpartitioned table 
Hive,WITHOUT_CLASSIFICATION,//  test repeating on right 
Hive,WITHOUT_CLASSIFICATION,//  grouping id should be pruned which is the last of key columns 
Hive,WITHOUT_CLASSIFICATION,//  use sub-dir as inputpath. 
Hive,WITHOUT_CLASSIFICATION,//  We should expect a semantic exception being throw as this partition   should not be present. 
Hive,WITHOUT_CLASSIFICATION,//  dfs is AutoCloseable 
Hive,WITHOUT_CLASSIFICATION,//  RO     LEFT\RIGHT   skip  filtered   valid   skip        --(1)     -+(1)   -+(1)   filtered    --(1)     -+(1)   -+(4*)   valid       --(1)     -+(1)   ++(2)     * If left alias has any pair for right alias continue (3) 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: pig-0.8 sets client system properties by actually getting the client   system properties. Starting in pig-0.9 you must pass the properties in.   When updating our pig dependency this will need updated. 
Hive,WITHOUT_CLASSIFICATION,//  run the script using Beeline 
Hive,WITHOUT_CLASSIFICATION,//  The ptned table should be there in both source and target as rename was not successful 
Hive,WITHOUT_CLASSIFICATION,//  this indicates if corr var is left operand of rex call or not   this is used in decorrelate(logical correlate) to appropriately   create Rex node expression 
Hive,WITHOUT_CLASSIFICATION,//  this is the data copy 
Hive,WITHOUT_CLASSIFICATION,//  Picks topN K:V pairs from input. 
Hive,WITHOUT_CLASSIFICATION,//  This is the old logic which assumes that the filenames are sorted in   alphanumeric order and mapped to appropriate bucket number. 
Hive,WITHOUT_CLASSIFICATION,/*    * Job status request executor to get status of a job.    */
Hive,WITHOUT_CLASSIFICATION,//  list of dynamic partitions 
Hive,WITHOUT_CLASSIFICATION,//  Add partitions with new schema. 
Hive,WITHOUT_CLASSIFICATION,/*    * Set the buffer that will receive the serialized data.  The output buffer will NOT be reset.    */
Hive,WITHOUT_CLASSIFICATION,//  Introduce top project operator to remove additional column(s) that have   been introduced 
Hive,WITHOUT_CLASSIFICATION,//  make the new aggRel 
Hive,WITHOUT_CLASSIFICATION,//  We could have multiple sources restrict the same column need to take   the union of the values in that case. 
Hive,WITHOUT_CLASSIFICATION,//  such as "%abc%" 
Hive,WITHOUT_CLASSIFICATION,//  prepare plan for submission (building DAG adding resources creating scratch dirs etc.) 
Hive,WITHOUT_CLASSIFICATION,//  1 - check that the table is Acid 
Hive,WITHOUT_CLASSIFICATION,//  Don't load defaults.   NOTE: hive-site.xml is only available on client not AM. 
Hive,WITHOUT_CLASSIFICATION,//  Its a new column 
Hive,WITHOUT_CLASSIFICATION,//  Calculate the number of bytes in the split that are local to each 
Hive,WITHOUT_CLASSIFICATION,//  neg-infinity to start exclusive 
Hive,WITHOUT_CLASSIFICATION,//  Initial MM write ID for CTAS and import. 
Hive,WITHOUT_CLASSIFICATION,//  UDFs 
Hive,WITHOUT_CLASSIFICATION,//  max number of threads we can use to check non-combinable paths 
Hive,WITHOUT_CLASSIFICATION,// note that originalFiles are all original files recursively not dirs 
Hive,WITHOUT_CLASSIFICATION,//  Note: totalDeleteEventCount can actually be higher than real value. 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * In order to update a Decimal128 fast (w/o allocation) we need to expose access to the   * internal storage bytes and scale.    */
Hive,WITHOUT_CLASSIFICATION,//  netty4  netty3  arrow-vector  arrow-memory  arrow-format  flatbuffers  hppc 
Hive,WITHOUT_CLASSIFICATION,//  Another special case because timestamp is not implicitly convertible to numeric types. 
Hive,WITHOUT_CLASSIFICATION,// perform simple checksum here; make sure nothing got turned to NULL 
Hive,WITHOUT_CLASSIFICATION,//  and must have locations outside the table directory. 
Hive,WITHOUT_CLASSIFICATION,//  Add the grouping set key to the group by operator.   This is not the first group by operator but it is a subsequent group by operator   which is forwarding the grouping keys introduced by the grouping sets.   For eg: consider: select key value count(1) from T group by key value with rollup.   Assuming map-side aggregation and no skew the plan would look like:     TableScan --> Select --> GroupBy1 --> ReduceSink --> GroupBy2 --> Select --> FileSink     This function is called for GroupBy2 to pass the additional grouping keys introduced by 
Hive,WITHOUT_CLASSIFICATION,//  5. hold a lock file in HDFS session dir to indicate the it is in use 
Hive,WITHOUT_CLASSIFICATION,//  rs is semijoin optimization branch which should look like <Parent>-SEL-GB1-RS1-GB2-RS2 
Hive,WITHOUT_CLASSIFICATION,//  Run a reverse DNS lookup on the URL 
Hive,WITHOUT_CLASSIFICATION,//  AM can not do Kerberos Auth so will do the input split generation in the HS2 
Hive,WITHOUT_CLASSIFICATION,//  First drop all the dependencies. 
Hive,WITHOUT_CLASSIFICATION,//  we just use view name as location. 
Hive,WITHOUT_CLASSIFICATION,//  We only apply this rule if Union.all is true.   And Sort.fetch is not null and it is more than 0. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure that if the session is returned to the pool it doesn't live in the global. 
Hive,WITHOUT_CLASSIFICATION,//  Handle to cancel loop 
Hive,WITHOUT_CLASSIFICATION,//  Regardless of the following exception 
Hive,WITHOUT_CLASSIFICATION,//  There may be speculative tasks waiting. 
Hive,WITHOUT_CLASSIFICATION,//  need to do the work to detangle this 
Hive,WITHOUT_CLASSIFICATION,//  If the task hasn't started and it is killed - report back to the AM that the task has been killed. 
Hive,WITHOUT_CLASSIFICATION,//  We do mnot test this 
Hive,WITHOUT_CLASSIFICATION,//  Possible since either container / task can be unregistered. 
Hive,WITHOUT_CLASSIFICATION,//  A value of 0 for n indicates that the mapper processed data that does not meet   filter criteria so merge() should be NO-OP. 
Hive,WITHOUT_CLASSIFICATION,//  Spend at most HIVE_PREWARM_SPARK_TIMEOUT to wait for executors to come up. 
Hive,WITHOUT_CLASSIFICATION,// tries to get S lock on T7 S on T7.p=1 and S on T7.p=2 
Hive,WITHOUT_CLASSIFICATION,//  Currently returned bootDumpBeginReplId as we don't consolidate the events after bootstrap 
Hive,WITHOUT_CLASSIFICATION,// tezJsonParser 
Hive,WITHOUT_CLASSIFICATION,//     want query level fairness and don't want the get in queue to hold up a session. 
Hive,WITHOUT_CLASSIFICATION,//  For PARTIAL2 and FINAL 
Hive,WITHOUT_CLASSIFICATION,//  ID 5 committed no open IDs 
Hive,WITHOUT_CLASSIFICATION,// and do a Load Data into the same table which should now land in a delta_x_x. 
Hive,WITHOUT_CLASSIFICATION,//  3. We try to merge the join with the right child 
Hive,WITHOUT_CLASSIFICATION,//  Read db via ObjectStore 
Hive,WITHOUT_CLASSIFICATION,//  Create the object inspector for the input columns and initialize the UDTF 
Hive,WITHOUT_CLASSIFICATION,//  the hmsc is not shared across threads. So the only way it could get closed while we are doing healthcheck   is if removalListener closes it. The synchronization takes care that removalListener won't do it 
Hive,WITHOUT_CLASSIFICATION,// create a table with bad avro uri 
Hive,WITHOUT_CLASSIFICATION,//  PASSWORD 
Hive,WITHOUT_CLASSIFICATION,//  No transaction for the compaction for now. 
Hive,WITHOUT_CLASSIFICATION,//  If existing table is valid but the partition spec is different then ignore partition   validation and create new partition. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getNCharacterStream(int)    */
Hive,WITHOUT_CLASSIFICATION,//  convert to equivalent time in UTC then get day offset 
Hive,WITHOUT_CLASSIFICATION,//  Input record iterator not used 
Hive,WITHOUT_CLASSIFICATION,//  Setup the bloom filter once 
Hive,WITHOUT_CLASSIFICATION,//  we store big keys in one table into one dir and same keys in other   tables into corresponding different dirs (one dir per table).   this map stores mapping from "big key dir" to its corresponding mapjoin   task. 
Hive,WITHOUT_CLASSIFICATION,//  Process --hiveconf   Get hiveconf param values and set the System property values 
Hive,WITHOUT_CLASSIFICATION,//  Combo 3: url set literal set to none 
Hive,WITHOUT_CLASSIFICATION,/*  * The interface for a single long key hash multi-set contains method.  */
Hive,WITHOUT_CLASSIFICATION,//  filter disabled injection disabled exception not expected 
Hive,WITHOUT_CLASSIFICATION,//  16 
Hive,WITHOUT_CLASSIFICATION,//  Set sasl qop 
Hive,WITHOUT_CLASSIFICATION,//  print the results 
Hive,WITHOUT_CLASSIFICATION,//  The THEN expression is either IdentityExpression (a column) or a ConstantVectorExpression 
Hive,WITHOUT_CLASSIFICATION,//  Test that timestamp arithmetic is done in UTC and then converted back to local timezone   matching Oracle behavior. 
Hive,WITHOUT_CLASSIFICATION,//  No additional data type specific setting. 
Hive,WITHOUT_CLASSIFICATION,//  Leave requestedHostWillBecomeAvailable as is. If some other host is found - delay   else ends up allocating to a random host immediately. 
Hive,WITHOUT_CLASSIFICATION,//  Constant if operator is deterministic and all operands are   constant. 
Hive,WITHOUT_CLASSIFICATION,//  The metastore shouldn't care what txn manager Hive is running but in various tests it 
Hive,WITHOUT_CLASSIFICATION,//  No point separating IOException vs YarnException vs others 
Hive,WITHOUT_CLASSIFICATION,//  We bypass the OR clause and select the first disjunct 
Hive,WITHOUT_CLASSIFICATION,//  be removed and the size before and after the genRootTableScan will be different. 
Hive,WITHOUT_CLASSIFICATION,//  Process the last byte if necessary. 
Hive,WITHOUT_CLASSIFICATION,//  dummy parent operators as well. 
Hive,WITHOUT_CLASSIFICATION,//  deleteRecord >= firstRecordInBatch or until we exhaust all the delete records. 
Hive,WITHOUT_CLASSIFICATION,// we don't prevent using non-acid resources in a txn but we do lock them 
Hive,WITHOUT_CLASSIFICATION,//  We compare class name/method name using ObjectInspectorUtils.compare(...) to avoid   any object conversion (which may cause object creation) in most cases when the class 
Hive,WITHOUT_CLASSIFICATION,// since TAB2 is empty  update stmt has p=blah thus nothing is actually update and we generate empty dyn part list 
Hive,WITHOUT_CLASSIFICATION,//  no replacement the existing table state is newer than our update. 
Hive,WITHOUT_CLASSIFICATION,//  Build the status message for the /status call. 
Hive,WITHOUT_CLASSIFICATION,//  test if we need partition/global order SHUFFLE_SORT should only be used for global order 
Hive,WITHOUT_CLASSIFICATION,//  This should not happen but we ignore for safety 
Hive,WITHOUT_CLASSIFICATION,//  2 - check if partitionvals are legitimate 
Hive,WITHOUT_CLASSIFICATION,/*  If the function has an explicit name like func(args) then call a   * constructor that explicitly provides the function name in the   * funcText argument.    */
Hive,WITHOUT_CLASSIFICATION,//  Nothing special needs to be done for grouping sets if   this is the final group by operator and multiple rows corresponding to the   grouping sets have been generated upstream.   However if an addition MR job has been created to handle grouping sets 
Hive,WITHOUT_CLASSIFICATION,//  18 
Hive,WITHOUT_CLASSIFICATION,//  if this is the last element 
Hive,WITHOUT_CLASSIFICATION,//  4. Now copy the data into cache buffers. 
Hive,WITHOUT_CLASSIFICATION,//  Per JDBC spec if the connection is closed a SQLException should be thrown. 
Hive,WITHOUT_CLASSIFICATION,// Adding Query specs to be used by org.apache.hadoop.hive.druid.io.DruidQueryBasedInputFormat 
Hive,WITHOUT_CLASSIFICATION,//  'equals' and 'compareTo' are not compatible with HiveDecimals. We want   compareTo which returns true iff the numbers are equal (e.g.: 3.14 is   the same as 3.140). 'Equals' returns true iff equal and the same scale   is set in the decimals (e.g.: 3.14 is not the same as 3.140) 
Hive,WITHOUT_CLASSIFICATION,//  we are translating Calcite operators into Hive operators. 
Hive,WITHOUT_CLASSIFICATION,//  We will not try partial rewriting for rebuild if incremental rebuild is disabled 
Hive,WITHOUT_CLASSIFICATION,//  Update fetchSize if modified by server 
Hive,WITHOUT_CLASSIFICATION,//  We don't create sessions for empty entries. 
Hive,WITHOUT_CLASSIFICATION,//  Estimate that there will be 16 bytes per entry 
Hive,WITHOUT_CLASSIFICATION,//  Run using environment context with cascade 
Hive,WITHOUT_CLASSIFICATION,//  Get the key positions 
Hive,WITHOUT_CLASSIFICATION,//  test for invalid group name 
Hive,WITHOUT_CLASSIFICATION,//  estimate size of key from column statistics 
Hive,WITHOUT_CLASSIFICATION,//  This is the time zone for VM in test. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see javax.sql.CommonDataSource#setLogWriter(java.io.PrintWriter)    */
Hive,WITHOUT_CLASSIFICATION,//  Get the top Nodes for this task 
Hive,WITHOUT_CLASSIFICATION,//  Validation is the same as for map join since the 'small' tables are not vectorized 
Hive,WITHOUT_CLASSIFICATION,//  Check for completed transactions 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:GetTokenResponseProto) 
Hive,WITHOUT_CLASSIFICATION,//  outputs are ready 
Hive,WITHOUT_CLASSIFICATION,//  enable escaping 
Hive,WITHOUT_CLASSIFICATION,//  accept to start dag (schedule wait time resource wait time etc.) 
Hive,WITHOUT_CLASSIFICATION,//  Mapping of reducesink to mapjoin operators 
Hive,WITHOUT_CLASSIFICATION,//  make sure the correlated reference forms a unique key check   that the columns referenced in these comparisons form an 
Hive,WITHOUT_CLASSIFICATION,//  Add list bucketing location mappings. 
Hive,WITHOUT_CLASSIFICATION,// ---------------------------------------------------------------------------   Inner big-table only join specific members.   
Hive,WITHOUT_CLASSIFICATION,//  There will be no DDL task created in case if its CREATE TABLE IF   NOT EXISTS 
Hive,WITHOUT_CLASSIFICATION,//  optional bytes token = 1; 
Hive,WITHOUT_CLASSIFICATION,//  HOST_NAME 
Hive,WITHOUT_CLASSIFICATION,//  left border is the max 
Hive,WITHOUT_CLASSIFICATION,//  close + commit 
Hive,WITHOUT_CLASSIFICATION,//  Check if the value is in bloom filter 
Hive,WITHOUT_CLASSIFICATION,//  large 
Hive,WITHOUT_CLASSIFICATION,// 2)  test reordering 
Hive,WITHOUT_CLASSIFICATION,//  SCHEMA_TEXT 
Hive,WITHOUT_CLASSIFICATION,//  ENTITY_TYPE 
Hive,WITHOUT_CLASSIFICATION,//  The output of FINAL and COMPLETE is a full aggregation which is a   list of DoubleWritable structs that represent the final histogram as   (xy) pairs of bin centers and heights. 
Hive,WITHOUT_CLASSIFICATION,//  this corresponds to a map<string?> 
Hive,WITHOUT_CLASSIFICATION,//  1: 
Hive,WITHOUT_CLASSIFICATION,//  initialize the forward operator 
Hive,WITHOUT_CLASSIFICATION,// Now cancel the delegation token 
Hive,WITHOUT_CLASSIFICATION,//  this offer will be accpeted and r1 evicted 
Hive,WITHOUT_CLASSIFICATION,//  Run without round-off 
Hive,WITHOUT_CLASSIFICATION,//  This is a subquery and must have an alias 
Hive,WITHOUT_CLASSIFICATION,//  no values array 
Hive,WITHOUT_CLASSIFICATION,//  Set of UDF classes for type casting data types in row-mode. 
Hive,WITHOUT_CLASSIFICATION,//  If root object is an array map or collection add estimators as for fields 
Hive,WITHOUT_CLASSIFICATION,//  Register only if the attempt is known. In case an unregister call   came in before the register call. 
Hive,WITHOUT_CLASSIFICATION,//  Define the SerDe Parameters 
Hive,WITHOUT_CLASSIFICATION,//  check the config used very often! 
Hive,WITHOUT_CLASSIFICATION,//  Perform the same URI normalization as create_database_core. 
Hive,WITHOUT_CLASSIFICATION,//  create a new external table 
Hive,WITHOUT_CLASSIFICATION,//  is and continue processing the children 
Hive,WITHOUT_CLASSIFICATION,//  2^(62 + 63) 
Hive,WITHOUT_CLASSIFICATION,//  mr or spark 
Hive,WITHOUT_CLASSIFICATION,//  remove ' 
Hive,WITHOUT_CLASSIFICATION,//  it's easier then because we simply do division and then scale   down. 
Hive,WITHOUT_CLASSIFICATION,//  these aggregations should be updated only once. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getBlob(int)    */
Hive,WITHOUT_CLASSIFICATION,//  delegate back to the "local" serializeRowId method 
Hive,WITHOUT_CLASSIFICATION,//  Bound skip by beginning and end of the source 
Hive,WITHOUT_CLASSIFICATION,//  Not public since we must have the field count and other information. 
Hive,WITHOUT_CLASSIFICATION,//  If help option is requested then display help and exit 
Hive,WITHOUT_CLASSIFICATION,//  VectorReduceSinkOperator is not native vectorized. 
Hive,WITHOUT_CLASSIFICATION,// this was 1/4 acid 
Hive,WITHOUT_CLASSIFICATION,//  way! 
Hive,WITHOUT_CLASSIFICATION,//  need to clone the plan. 
Hive,WITHOUT_CLASSIFICATION,//  should have null for non-specified comments 
Hive,WITHOUT_CLASSIFICATION,//  VectorMapJoinOperator is not native vectorized. 
Hive,WITHOUT_CLASSIFICATION,// insert of merge lands in part (34) - no updates land there 
Hive,WITHOUT_CLASSIFICATION,//  When we have multiple values we save the next value record's offset here. 
Hive,WITHOUT_CLASSIFICATION,//  removed. 
Hive,WITHOUT_CLASSIFICATION,/*      * Output Columns in the following order     * - the columns representing the output from Window Fns     * - the input Rows columns      */
Hive,WITHOUT_CLASSIFICATION,//  How to get config paths and AmInfo 
Hive,WITHOUT_CLASSIFICATION,//  For ORC there is no Tez Job for table stats. 
Hive,WITHOUT_CLASSIFICATION,//  This happens if register calls getMetrics. 
Hive,WITHOUT_CLASSIFICATION,//  1) Obtain input and all related data structures 
Hive,WITHOUT_CLASSIFICATION,//  Text file comparison 
Hive,WITHOUT_CLASSIFICATION,//  initializeOp can be overridden   Initializing data structures for vectorForward 
Hive,WITHOUT_CLASSIFICATION,//  Master node will serialize writercontext and will make it available at slaves. 
Hive,WITHOUT_CLASSIFICATION,//  Transactions 
Hive,WITHOUT_CLASSIFICATION,//  WARNINGS 
Hive,WITHOUT_CLASSIFICATION,// list of last keys for each stripe 
Hive,WITHOUT_CLASSIFICATION,//  If the function is deterministic and the children are constants 
Hive,WITHOUT_CLASSIFICATION,/* String s = "SELECT COLUMN_NAME FROM " + (ci.partName == null ? "TAB_COL_STATS" :          "PART_COL_STATS")         + " WHERE DB_NAME='" + ci.dbname + "' AND TABLE_NAME='" + ci.tableName + "'"        + (ci.partName == null ? "" : " AND PARTITION_NAME='" + ci.partName + "'"); */
Hive,WITHOUT_CLASSIFICATION,//  Default is double but if one of the sides is already in decimal we   complete the operation in that type. 
Hive,WITHOUT_CLASSIFICATION,//  Calcite year-month literal value is months as BigDecimal 
Hive,WITHOUT_CLASSIFICATION,//  verify proper null output data value 
Hive,WITHOUT_CLASSIFICATION,//  Assert class-invariant. 
Hive,WITHOUT_CLASSIFICATION,//  we can tolerate this as this is the previous behavior 
Hive,WITHOUT_CLASSIFICATION,//  Older version of hadoop should have had this field 
Hive,WITHOUT_CLASSIFICATION,//  Eliminate MR plans with more than one TableScanOperator. 
Hive,WITHOUT_CLASSIFICATION,//  7. Convert Hive projections to Calcite 
Hive,WITHOUT_CLASSIFICATION,//  Create callables with different queries. 
Hive,WITHOUT_CLASSIFICATION,//  This constructor appeared in 1.4 and specifies that we do not want to   line-wrap or use any newline separator 
Hive,WITHOUT_CLASSIFICATION,//  no sub-directories 
Hive,WITHOUT_CLASSIFICATION,//  Get the serialized value for the column 
Hive,WITHOUT_CLASSIFICATION,/*  isVectorMapJoin  */
Hive,WITHOUT_CLASSIFICATION,//  Make sure the UGI contains the token too for good measure 
Hive,WITHOUT_CLASSIFICATION,// Update max counter if new value is greater than max seen so far 
Hive,WITHOUT_CLASSIFICATION,//  Do not allow view to be defined on temp table or other materialized view 
Hive,WITHOUT_CLASSIFICATION,//  Evaluate the expression tree. 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) Throws  */
Hive,WITHOUT_CLASSIFICATION,//  It is possible that some operators add records after closing the processor so make sure 
Hive,WITHOUT_CLASSIFICATION,//        query is being killed until both the kill and the user return it. 
Hive,WITHOUT_CLASSIFICATION,//  The uri requested 
Hive,WITHOUT_CLASSIFICATION,//  check if its a simple cast expression. 
Hive,WITHOUT_CLASSIFICATION,//  Last item -- ok to be at end. 
Hive,WITHOUT_CLASSIFICATION,//  (nulls etc.). vice versa. 
Hive,WITHOUT_CLASSIFICATION,//  default is using long types 
Hive,WITHOUT_CLASSIFICATION,//  if top is null then there are multiple parents (RS as well) hence   lets use parent statistics to get data size. Also maxSplitSize should 
Hive,WITHOUT_CLASSIFICATION,//  Need to be in consistent with that VectorizedPrimitiveColumnReader#readBatchHelper 
Hive,WITHOUT_CLASSIFICATION,//  LocalDate must be present 
Hive,WITHOUT_CLASSIFICATION,// now run as if it's a minor Compaction so we don't collapse events 
Hive,WITHOUT_CLASSIFICATION,/*      * The default number of threads will be 0. That means thread pool is not used and     * operation is executed with the current thread.      */
Hive,WITHOUT_CLASSIFICATION,// Reset the PerfLogger 
Hive,WITHOUT_CLASSIFICATION,//  Now make a copy. 
Hive,WITHOUT_CLASSIFICATION,//  check result now 
Hive,WITHOUT_CLASSIFICATION,//  The schedule loop will be triggered again when the deallocateTask request comes in for the   preempted task. 
Hive,WITHOUT_CLASSIFICATION,//  Step 3 : parse the query   Set dynamic partitioning to nonstrict so that queries do not need any partition 
Hive,WITHOUT_CLASSIFICATION,//  test when second argument has nulls 
Hive,WITHOUT_CLASSIFICATION,//  base configuration   active configuration 
Hive,WITHOUT_CLASSIFICATION,//  create table db 
Hive,WITHOUT_CLASSIFICATION,//  property names needed to keep internal structure of serde 
Hive,WITHOUT_CLASSIFICATION,// to allow cross join from 'teeCurMatch' 
Hive,WITHOUT_CLASSIFICATION,//  Get failed attempts 
Hive,WITHOUT_CLASSIFICATION,//  local resources are session based. 
Hive,WITHOUT_CLASSIFICATION,//  Populate the driver context with the scratch dir info from the repl context so that the temp dirs will be cleaned up later 
Hive,WITHOUT_CLASSIFICATION,//  The first entry with accumulated count (lower+1) corresponds to the lower position. 
Hive,WITHOUT_CLASSIFICATION,//  It's difficult to impossible to pass global things to compilation so we have a static cache. 
Hive,WITHOUT_CLASSIFICATION,//  queries like select * from t1 where 'foo';   Calcite's rule PushFilterThroughProject chokes on it. Arguably we   can insert a cast to   boolean in such cases but since Postgres Oracle and MS SQL server   fail on compile time   for such queries its an arcane corner case not worth of adding that   complexity. 
Hive,WITHOUT_CLASSIFICATION,//  optional buffer to use when actually copying in data   next free position in buffer 
Hive,WITHOUT_CLASSIFICATION,//  table name has to be present so min child 1 and max child 4 
Hive,WITHOUT_CLASSIFICATION,//  Cache to use during optimization 
Hive,WITHOUT_CLASSIFICATION,//  convert partition to partition spec string 
Hive,WITHOUT_CLASSIFICATION,//  WRITE_ID_HIGH_WATER_MARK 
Hive,WITHOUT_CLASSIFICATION,//  12 is timeout and 255 is unspecified error 
Hive,WITHOUT_CLASSIFICATION,//  -f <file> 
Hive,WITHOUT_CLASSIFICATION,//  1. Find our bearings in the stream. Normally iter will already point either to where we   want to be or just before. However RGs can overlap due to encoding so we may have 
Hive,WITHOUT_CLASSIFICATION,//  This will only be set if the metastore is being accessed from a metastore Thrift server   not if it is from the CLI. Also only if the TTransport being used to connect is an 
Hive,WITHOUT_CLASSIFICATION,//  Event 2 
Hive,WITHOUT_CLASSIFICATION,//  Test the idempotent behavior of Abort Txn 
Hive,WITHOUT_CLASSIFICATION,//  void boolean byte short int float   long double 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) TypeBool  */
Hive,WITHOUT_CLASSIFICATION,//  Forward any remaining selected rows. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#getMetaData()    */
Hive,WITHOUT_CLASSIFICATION,//  This logic assumes one dag at a time; if it was not the case it'd keep rewriting it. 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   required   required   required   required   required   required   required   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  timestamp - timestamp   interval_day_time +/- interval_day_time 
Hive,WITHOUT_CLASSIFICATION,//  Keys are always primitive respect the binary 
Hive,WITHOUT_CLASSIFICATION,//  Event 1 
Hive,WITHOUT_CLASSIFICATION,//  TODO: add a section like the restricted configs for overrides when there's more than one. 
Hive,WITHOUT_CLASSIFICATION,//  dryRun = true immutable = true 
Hive,WITHOUT_CLASSIFICATION,//  each column's length in the value 
Hive,WITHOUT_CLASSIFICATION,// Query the hbase table and check the key is valid and only 5  are present 
Hive,WITHOUT_CLASSIFICATION,/*  Invalid FileSystem schemes  */
Hive,WITHOUT_CLASSIFICATION,//  Insert some data -> this will again generate only insert deltas and no delete deltas: delta_2_2 
Hive,WITHOUT_CLASSIFICATION,//  If we have some sort of expression tree try JDOQL filter pushdown. 
Hive,WITHOUT_CLASSIFICATION,//  Regression test for defect reported in HIVE-6243 
Hive,WITHOUT_CLASSIFICATION,//  Many old tests depend on this. 
Hive,WITHOUT_CLASSIFICATION,//  List of non-distinct aggrs. 
Hive,WITHOUT_CLASSIFICATION,//  dataSchema can be obtained from partitionInfo.getPartitionSchema() 
Hive,WITHOUT_CLASSIFICATION,//  Gather information about the DPP table scans and store it in the cache 
Hive,WITHOUT_CLASSIFICATION,/*    * Context for reading using the regular partition deserializer to get the row object and   * assigning the row object into the VectorizedRowBatch with VectorAssignRow    */
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setBytes(int byte[])    */
Hive,WITHOUT_CLASSIFICATION,//  Default run 
Hive,WITHOUT_CLASSIFICATION,// This doesn't throw MetaException when setting to high max part count 
Hive,WITHOUT_CLASSIFICATION,//  Project operator we can continue 
Hive,WITHOUT_CLASSIFICATION,//  RESULTS 
Hive,WITHOUT_CLASSIFICATION,//  Insert entries to TXN_TO_WRITE_ID for aborted write ids 
Hive,WITHOUT_CLASSIFICATION,//  Store the user name in the open request in case no non-sasl authentication 
Hive,WITHOUT_CLASSIFICATION,//  i.e. Is the partition outside the table-dir? 
Hive,WITHOUT_CLASSIFICATION,//  can be inherited from a base class. 
Hive,WITHOUT_CLASSIFICATION,//  load them into a set 
Hive,WITHOUT_CLASSIFICATION,//  Clip off seconds portion.   Bring nanoseconds into integer portion. 
Hive,WITHOUT_CLASSIFICATION,// / ALTER TABLE scenarios 
Hive,WITHOUT_CLASSIFICATION,//  even without type params return a default OI for varchar 
Hive,WITHOUT_CLASSIFICATION,//  remember the mapping in case we scan another branch of the mapjoin later 
Hive,WITHOUT_CLASSIFICATION,//  for DENSE encoding use bias table lookup for HLLNoBias algorithm 
Hive,WITHOUT_CLASSIFICATION,//  Void can be converted to any type 
Hive,WITHOUT_CLASSIFICATION,//  Verify that the node is blacklisted 
Hive,WITHOUT_CLASSIFICATION,//  Write the "suffix" of the cq 
Hive,WITHOUT_CLASSIFICATION,//  unequal maps 
Hive,WITHOUT_CLASSIFICATION,//  We're told to use some port but it's occupied fail 
Hive,WITHOUT_CLASSIFICATION,//  remember the branching ops we have visited 
Hive,WITHOUT_CLASSIFICATION,//  Remove the join operator from the query join context   Data structures coming from QBJoinTree 
Hive,WITHOUT_CLASSIFICATION,//  Special handling for decimal because decimal types need scale and precision parameter.   This special handling should be avoided by using returnType uniformly for all cases. 
Hive,WITHOUT_CLASSIFICATION,//  Lookup list bucketing pruner 
Hive,WITHOUT_CLASSIFICATION,//  after some other submission has evicted it. 
Hive,WITHOUT_CLASSIFICATION,//  Once we move to a Hadoop-2.8 dependency the following paramteer can be used.   conf.set(YarnConfiguration.TIMELINE_SERVICE_ENTITYGROUP_FS_STORE_RETRY_POLICY_SPEC); 
Hive,WITHOUT_CLASSIFICATION,//  Buffers at offset 2 & 3 exist; 1 exists and is stale; 4 doesn't 
Hive,WITHOUT_CLASSIFICATION,//  Go through the set of key columns and find their representatives in the values 
Hive,WITHOUT_CLASSIFICATION,//  We need to work a little harder for our comparison.  Note we round down for   integer conversion so anything below the next min/max will work. 
Hive,WITHOUT_CLASSIFICATION,//  Vectorized implementation of Hex(long) that returns string 
Hive,WITHOUT_CLASSIFICATION,//  enable trash so it can be tested 
Hive,WITHOUT_CLASSIFICATION,//  In non-test mode emit to a log file   which can be different from the normal hive.log.   For example using NoDeleteRollingFileAppender to   log to some file with different rolling policy. 
Hive,WITHOUT_CLASSIFICATION,//  Double.compare() treats -0.0 and 0.0 as different 
Hive,WITHOUT_CLASSIFICATION,//  tempTable is only set when load is rewritten. 
Hive,WITHOUT_CLASSIFICATION,//  1. We iterate through all the operators that have candidate FKs and   choose the FK that has the minimum selectivity. We assume that PK and this FK   have the PK-FK relationship. This is heuristic and can be 
Hive,WITHOUT_CLASSIFICATION,// remove the locks in Waiting state 
Hive,WITHOUT_CLASSIFICATION,//  STAT 
Hive,WITHOUT_CLASSIFICATION,//  work.checkFileFormat is set to true only for Load Task so assumption here is   dynamic partition context is null 
Hive,WITHOUT_CLASSIFICATION,//  No need to check catalog for null as parseDbName() will never return null for the catalog. 
Hive,WITHOUT_CLASSIFICATION,//  they are not the same constant. for example union all of 1   and 2. 
Hive,WITHOUT_CLASSIFICATION,//  There should be 1 new base directory: base_0000001   Original bucket files delta directories delete_delta directories and the 
Hive,WITHOUT_CLASSIFICATION,//  Not supported for temp tables. 
Hive,WITHOUT_CLASSIFICATION,//  performance problem: ObjectStore does its own new HiveConf() 
Hive,WITHOUT_CLASSIFICATION,//  required   optional   required   required   optional 
Hive,WITHOUT_CLASSIFICATION,// keep track of corresponding col in partCols 
Hive,WITHOUT_CLASSIFICATION,//  CTAS should NOT create a VOID type 
Hive,WITHOUT_CLASSIFICATION,//  compute the number of tasks 
Hive,WITHOUT_CLASSIFICATION,//  Put it all in the Mutation 
Hive,WITHOUT_CLASSIFICATION,//  Test double 
Hive,WITHOUT_CLASSIFICATION,/*    * Initialize one column's source conversion related arrays.   * Assumes initTargetEntry has already been called.    */
Hive,WITHOUT_CLASSIFICATION,//  It passes the test it is valid 
Hive,WITHOUT_CLASSIFICATION,//  Privilege matrix:                      user1  user2  group_a  group_b  public   testdb1:            S             S     testtable1.*:     SU     S     testtable2.*:                   S     testtable3.*:                                     S     testtable4.*:                            S   testdb2:            S 
Hive,WITHOUT_CLASSIFICATION,//  Register the new dag identifier if that's not the one currently registered. 
Hive,WITHOUT_CLASSIFICATION,//  ACCEPTED 
Hive,WITHOUT_CLASSIFICATION,//  Capture system out and err 
Hive,WITHOUT_CLASSIFICATION,//  Allow implicit String to varchar conversion and vice versa 
Hive,WITHOUT_CLASSIFICATION,//  Set the run frequency low on this test so it doesn't take long 
Hive,WITHOUT_CLASSIFICATION,//  call-1: open to read data - split 1 => mock:/mocktable4/0_0 
Hive,WITHOUT_CLASSIFICATION,/*    * Executes job request operation. If thread pool is not created then job request is   * executed in current thread itself.   *   * @param jobExecuteCallable   *          Callable object to run the job request task.   *    */
Hive,WITHOUT_CLASSIFICATION,//  Keep track of view alias to read entity corresponding to the view   For eg: for a query like 'select * from V3' where V3 -> V2 V2 -> V1 V1 -> T   keeps track of aliases for V3 V3:V2 V3:V2:V1.   This is used when T is added as an input for the query the parents of T is 
Hive,WITHOUT_CLASSIFICATION,//  1. Handle kill query results - part 1 just put them in place. We will resolve what 
Hive,WITHOUT_CLASSIFICATION,//  worth it. 
Hive,WITHOUT_CLASSIFICATION,//  overflow means this is smaller 
Hive,WITHOUT_CLASSIFICATION,//  All zeroes -- we should have handled this earlier. 
Hive,WITHOUT_CLASSIFICATION,//  before any of the other core hive classes are loaded 
Hive,WITHOUT_CLASSIFICATION,/*    * DATE.    */
Hive,WITHOUT_CLASSIFICATION,//  Need to extend the tenancy if we saw a newer file with the same content 
Hive,WITHOUT_CLASSIFICATION,//  Count all rows. 
Hive,WITHOUT_CLASSIFICATION,//  Fix temp path for alter table ... concatenate 
Hive,WITHOUT_CLASSIFICATION,//  conf and then the children 
Hive,WITHOUT_CLASSIFICATION,//  But if hive supports assigning bucket number for each partition this can be vary 
Hive,WITHOUT_CLASSIFICATION,//  new filter; currently we support comparison functions in and between 
Hive,WITHOUT_CLASSIFICATION,//  if both are last day of the month then time part should be ignored 
Hive,WITHOUT_CLASSIFICATION,//  Sort cost 
Hive,WITHOUT_CLASSIFICATION,//  no begin + abort 
Hive,WITHOUT_CLASSIFICATION,//  Legacy file see if it's a bucket file 
Hive,WITHOUT_CLASSIFICATION,//  Call the real method instead of the mock 
Hive,WITHOUT_CLASSIFICATION,//  Replication done we now do the following verifications: 
Hive,WITHOUT_CLASSIFICATION,//  TODO: these would need to be propagated from AM via progress.   @Metric("Number of allocated guaranteed executors in use")   @Metric("Number of speculative executors in use") 
Hive,WITHOUT_CLASSIFICATION,//  6.2 Convert UDAF Params to ExprNodeDesc 
Hive,WITHOUT_CLASSIFICATION,//  generate absolute path relative to home directory 
Hive,WITHOUT_CLASSIFICATION,//  string to encrypt 
Hive,WITHOUT_CLASSIFICATION,//  2: Create an unpartitioned table T1 => 1 event 
Hive,WITHOUT_CLASSIFICATION,//  write addition payload required for orc 
Hive,WITHOUT_CLASSIFICATION,//  such as "a_b"   such as "a%bc" 
Hive,WITHOUT_CLASSIFICATION,//  MY_STRUCTLIST 
Hive,WITHOUT_CLASSIFICATION,//  a db owner can be a user or a role 
Hive,WITHOUT_CLASSIFICATION,//  Whole batch is spilled. 
Hive,WITHOUT_CLASSIFICATION,//  tblProps will be null if user didnt use tblprops in his CREATE   TABLE cmd. 
Hive,WITHOUT_CLASSIFICATION,//  read that many chars 
Hive,WITHOUT_CLASSIFICATION,//  Count zeros until first non-zero digit is encountered. 
Hive,WITHOUT_CLASSIFICATION,//  if this table has an associated index table then attempt to build   index mutations 
Hive,WITHOUT_CLASSIFICATION,//  An update needs to select all of the columns as we rewrite the entire row.  Also   we need to figure out which columns we are going to replace. 
Hive,WITHOUT_CLASSIFICATION,//  holds restored (from disk) big table rows 
Hive,WITHOUT_CLASSIFICATION,//  for the big table we only need to promote the next group to the current group. 
Hive,WITHOUT_CLASSIFICATION,//  now it succeeds. 
Hive,WITHOUT_CLASSIFICATION,//  Convert the fields 
Hive,WITHOUT_CLASSIFICATION,//  try using jdbc metadata api to get column list as user2 - should fail 
Hive,WITHOUT_CLASSIFICATION,//  Data structure to control whether a certain reference is present in every 
Hive,WITHOUT_CLASSIFICATION,//  Find the value object   Update the timestamp of the keyvalue if value matches the criteria 
Hive,WITHOUT_CLASSIFICATION,//  Replace INSERT OVERWRITE by INSERT INTO   AST tree will have this shape:   TOK_QUERY     TOK_FROM        ...     TOK_INSERT        TOK_DESTINATION <- THIS TOKEN IS REPLACED BY 'TOK_INSERT_INTO'           TOK_TAB              TOK_TABNAME                 default.cmv_mat_view        TOK_SELECT           ... 
Hive,WITHOUT_CLASSIFICATION,// if we are waiting for connection for a long time something is really wrong  better raise an error than hang forever  see DefaultConnectionStrategy.getConnectionInternal() 
Hive,WITHOUT_CLASSIFICATION,//  join from multiple relations: 
Hive,WITHOUT_CLASSIFICATION,// Map<??> c7Value = (Map<??>) rowValues[6];  assertEquals(0 c7Value.size()); 
Hive,WITHOUT_CLASSIFICATION,//  key:column output name value:tag 
Hive,WITHOUT_CLASSIFICATION,//  Get the sign of the decimal. 
Hive,WITHOUT_CLASSIFICATION,//  lazy mode => we only list files and expect that the eventual copy will pull data in.   default is that the import mode is insert overwrite   WriteIds snapshot for replicating ACID/MM tables.   DEFAULT means REPL_LOAD or BOOTSTRAP_DUMP or EXPORT 
Hive,WITHOUT_CLASSIFICATION,//    see if the filename matches and we can read it 
Hive,WITHOUT_CLASSIFICATION,//  Create db1/t1/dt=20160101/part                /dt=20160102/part                /dt=20160103/part   Test: recycle single file (dt=20160101/part)         recycle single partition (dt=20160102)         recycle table t1 
Hive,WITHOUT_CLASSIFICATION,//  When union is followed by a multi-table insert 
Hive,WITHOUT_CLASSIFICATION,//  getAllFunctions() 
Hive,WITHOUT_CLASSIFICATION,//  If this operator has been visited already by the rule 
Hive,WITHOUT_CLASSIFICATION,//  When we were inserting the key we would have inserted here; so there's no key. 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.CLIServiceClient#getFunctions(org.apache.hive.service.cli.SessionHandle java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  Don't recheck with next only 2 lists each w/o collisions. 
Hive,WITHOUT_CLASSIFICATION,//  instances is likely incorrect. 
Hive,WITHOUT_CLASSIFICATION,//  1 + 2 + 4 + 8 + 4 + 8 + 5 + 2 + 4 + 3 + 4 + 4 + 4 + 4 + 4 + 3 = 64 
Hive,WITHOUT_CLASSIFICATION,//  Try marking the query as complete if this is an external submission 
Hive,WITHOUT_CLASSIFICATION,//  TODO: UNIQUE JOIN 
Hive,WITHOUT_CLASSIFICATION,//  then it's a dynamic partitioning case and we shouldn't check the table itself. 
Hive,WITHOUT_CLASSIFICATION,//  Simple task registration and un-registration. 
Hive,WITHOUT_CLASSIFICATION,//  #getColumn(2) should return the instance passed in: 
Hive,WITHOUT_CLASSIFICATION,//  AWS settings 
Hive,WITHOUT_CLASSIFICATION,//  Walk through all the source vertices 
Hive,WITHOUT_CLASSIFICATION,// can happen in retrying deleting the zLock after exceptions like InterruptedException  or in a race condition where parent has already been deleted by other process when it  is to be deleted. Both cases should not raise error 
Hive,WITHOUT_CLASSIFICATION,// --------------------------------------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  For now throw away file. 
Hive,WITHOUT_CLASSIFICATION,//  Override to do nothing as the this test is not related with vectorization.   The parent class creates a temporary table in this test and alters its properties.   To not override this test that temporary table needs to be renamed. However as   mentioned this does not serve any purpose as this test does not relate to vectorization. 
Hive,WITHOUT_CLASSIFICATION,// should only get here if retrying this op 
Hive,WITHOUT_CLASSIFICATION,//  if any filters are present in the join tree push them on top of the   table 
Hive,WITHOUT_CLASSIFICATION,//  rFile = new RandomAccessFile(tmpFile "rw"); 
Hive,WITHOUT_CLASSIFICATION,// JSON key is always a String 
Hive,WITHOUT_CLASSIFICATION,//  All the objects must be different. 
Hive,WITHOUT_CLASSIFICATION,/* {"writeid":0"bucketid":536870912"rowid":0}     0       2/000000_0{"writeid":0"bucketid":536870912"rowid":1}     0       4/000000_0{"writeid":1"bucketid":536870912"rowid":0}    4       4/delta_0000001_0000001_0000/000000_0{"writeid":1"bucketid":536870912"rowid":1}    5       5/delta_0000001_0000001_0000/000000_0 */
Hive,WITHOUT_CLASSIFICATION,//  0. Generate a Select Node for Windowing 
Hive,WITHOUT_CLASSIFICATION,//  Empty queue. But no capacity available due to waitQueueSize and additionalElementsAllowed   Return the element. 
Hive,WITHOUT_CLASSIFICATION,//  start_date is Wed full timestamp full day name 
Hive,WITHOUT_CLASSIFICATION,//  The name of this column in the Hive schema 
Hive,WITHOUT_CLASSIFICATION,//  6 highword digits. 
Hive,WITHOUT_CLASSIFICATION,//  moved...this may change 
Hive,WITHOUT_CLASSIFICATION,/*    * Get the index separating the user name from domain name (the user's name up   * to the first '/' or '@').   *   * @param userName full user name.   * @return index of domain match or -1 if not found    */
Hive,WITHOUT_CLASSIFICATION,//  Uses a pattern and specifies a DB 
Hive,WITHOUT_CLASSIFICATION,/*        * b. Build Reduce Sink Details (keyCols valueCols outColNames etc.) for this ptfDesc.        */
Hive,WITHOUT_CLASSIFICATION,//  change it to local 
Hive,WITHOUT_CLASSIFICATION,/*  256 files x 100 size for 9 splits  */
Hive,WITHOUT_CLASSIFICATION,//  Different number of field names 
Hive,WITHOUT_CLASSIFICATION,//  process the second childif exists node to get partition spec(s) 
Hive,WITHOUT_CLASSIFICATION,/*    * Initialize using one target data type info.    */
Hive,WITHOUT_CLASSIFICATION,//  if there are multiple stats for the same scheme (from different NameNode) this   method will squash them together 
Hive,WITHOUT_CLASSIFICATION,//  Can't use CacheLoader because SearchArguments may be built either from Kryo strings 
Hive,WITHOUT_CLASSIFICATION,//  Since EXISTS/NOT EXISTS are not affected by presence of   null keys we do not need to generate count(*) count(c) 
Hive,WITHOUT_CLASSIFICATION,//  move file would require session details (needCopy() invokes SessionState.get) 
Hive,WITHOUT_CLASSIFICATION,//  Check fast1. 
Hive,WITHOUT_CLASSIFICATION,//  We hold one refcount. 
Hive,WITHOUT_CLASSIFICATION,//  Not MM. 
Hive,WITHOUT_CLASSIFICATION,//  Disallow changing temp table location 
Hive,WITHOUT_CLASSIFICATION,//  NULLs are handled by each individual base writer setter   We could handle NULLs centrally here but that would result in spurious allocs 
Hive,WITHOUT_CLASSIFICATION,//  In a simple storage-based auth we have no information about columns   living in different files so we do simple partition-auth and ignore   the columns parameter. 
Hive,WITHOUT_CLASSIFICATION,//  prepare the tmp output directory. The output tmp directory should   exist before jobClose (before renaming after job completion) 
Hive,WITHOUT_CLASSIFICATION,//  Puts gets hits unused unused. 
Hive,WITHOUT_CLASSIFICATION,//  Union type is not supported in Calcite. 
Hive,WITHOUT_CLASSIFICATION,//  TODO: see if we can get rid of this... used in one place to distinguish archived parts 
Hive,WITHOUT_CLASSIFICATION,//  We failed to update this task. Instead of retrying for this task find another.   To change isGuaranteed and modify maps we'd need the epic lock. So we will not 
Hive,WITHOUT_CLASSIFICATION,//  Modify TableScanOperator in-place so it knows to operate vectorized. 
Hive,WITHOUT_CLASSIFICATION,//  strip off the delimiter 
Hive,WITHOUT_CLASSIFICATION,//  A new row is also inserted in the usual delta file for an update event. 
Hive,WITHOUT_CLASSIFICATION,//  Finish the scheduled compaction for ttp2 
Hive,WITHOUT_CLASSIFICATION,//  Current installed Configuration 
Hive,WITHOUT_CLASSIFICATION,//  If config is set table is not temporary and partition being inserted exists capture   the list of files added. For not yet existing partitions (insert overwrite to new partition   or dynamic partition inserts) the add partition event will capture the list of files added.   Generate an insert event only if inserting into an existing partition 
Hive,WITHOUT_CLASSIFICATION,/*    * This is used during translation to decide if the internalName -> alias mapping from the Input to the PTF is carried   * forward when building the Output RR for this PTF.   * This is used by internal PTFs: NOOP WindowingTableFunction to make names in its input available in the Output.   * In general this should be false; and the names used for the Output Columns must be provided by the PTF Writer in the   * function getOutputNames.    */
Hive,WITHOUT_CLASSIFICATION,//  Wait for all writes to finish before we actually close. 
Hive,WITHOUT_CLASSIFICATION,//  type of target column 
Hive,WITHOUT_CLASSIFICATION,//  partitioned table 
Hive,WITHOUT_CLASSIFICATION,//  The dispatcher fires the processor corresponding to the closest matching rule 
Hive,WITHOUT_CLASSIFICATION,//  Host 
Hive,WITHOUT_CLASSIFICATION,//  Floor on date: special handling since function in Hive does   include <time_unit>. Observe that <time_unit> information   is implicit in the function name thus translation will   proceed correctly if we just ignore the <time_unit> 
Hive,WITHOUT_CLASSIFICATION,//  FKTABLE_DB 
Hive,WITHOUT_CLASSIFICATION,//  prefer right most alias 
Hive,WITHOUT_CLASSIFICATION,//  lrfuThreshold is +inf in this case 
Hive,WITHOUT_CLASSIFICATION,// reached End Of Split 
Hive,WITHOUT_CLASSIFICATION,//  if there is any confict then we do not generate it in the new select   otherwise we add it into the calciteColLst and generate the new select 
Hive,WITHOUT_CLASSIFICATION,//  Ignore nullscan-optimized paths. 
Hive,WITHOUT_CLASSIFICATION,/*    * Setup our inner big table only join specific members.    */
Hive,WITHOUT_CLASSIFICATION,//  Always want to re-create pm as we don't know if it were created by the 
Hive,WITHOUT_CLASSIFICATION,//  an blocking operator (e.g. GroupByOperator and JoinOperator) can 
Hive,WITHOUT_CLASSIFICATION,//  FOREIGN_CATALOG_NAME 
Hive,WITHOUT_CLASSIFICATION,/*      * Iterate over the Symbol Functions in the Chain:     * - If we are not at the end of the Iterator (i.e. row != null )     * - match the current componentFn     * - if it returns false then return false     * - otherwise set row to the next row from the Iterator.     * - if we are at the end of the Iterator     * - skip any optional Symbol Fns (star patterns) at the end.     * - but if we come to a non optional Symbol Fn return false.     * - if we match all Fns in the chain return true.      */
Hive,WITHOUT_CLASSIFICATION,//  -Xmx not specified 
Hive,WITHOUT_CLASSIFICATION,//  Set longPollingTimeout to a custom value for different test cases 
Hive,WITHOUT_CLASSIFICATION,//  Note that reset also resets the data buffer for bytes column vectors. 
Hive,WITHOUT_CLASSIFICATION,//  If we're here we'll proceed down the next while loop iteration. 
Hive,WITHOUT_CLASSIFICATION,//  Create data buffers for value bytes column vectors. 
Hive,WITHOUT_CLASSIFICATION,//  compare every groupbyMapAggrInterval rows 
Hive,WITHOUT_CLASSIFICATION,//  Create an object inspector 
Hive,WITHOUT_CLASSIFICATION,//  Lock types 
Hive,WITHOUT_CLASSIFICATION,//  Find the old database id 
Hive,WITHOUT_CLASSIFICATION,//  The sorting order of the parent RS is more specific or they are equal.   We will copy the order from the child RS and then fill in the order   of the rest of columns with the one taken from parent RS. 
Hive,WITHOUT_CLASSIFICATION,/*    * This method is mainly intended for debug display purposes.    */
Hive,WITHOUT_CLASSIFICATION,//  Define summary metrics for each column 
Hive,WITHOUT_CLASSIFICATION,//  in this case we have to scale up _BEFORE_ division. otherwise we   might lose precision. this is costly but inevitable. 
Hive,WITHOUT_CLASSIFICATION,//  but we want it to so just re-set it if it's null. 
Hive,WITHOUT_CLASSIFICATION,//  We optimize performance by only looking up the first key in a series of equal keys. 
Hive,WITHOUT_CLASSIFICATION,//  generic options parser doesn't seem to work! 
Hive,WITHOUT_CLASSIFICATION,//  Allocate t4 at higher priority. t3 should not be allocated 
Hive,WITHOUT_CLASSIFICATION,/*  256 files x 1000 size for 9 splits  */
Hive,WITHOUT_CLASSIFICATION,//  This is done at pre-read stage where there's nothing special w/refcounts. Just release. 
Hive,WITHOUT_CLASSIFICATION,//  set the comparison in the IOContext and the type of the UDF 
Hive,WITHOUT_CLASSIFICATION,//  Create the HFile writer 
Hive,WITHOUT_CLASSIFICATION,//  Try extended deduplication 
Hive,WITHOUT_CLASSIFICATION,//  the name of the field - not optional 
Hive,WITHOUT_CLASSIFICATION,//  Need to preserve authorizer flag 
Hive,WITHOUT_CLASSIFICATION,//  Built-in functions shouldn't go in the session registry   and temp functions shouldn't go in the system registry.   Persistent functions can be in either registry. 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   required   optional   optional   optional   optional   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  force BI to avoid reading footers 
Hive,WITHOUT_CLASSIFICATION,//  If the result is already present in the cache return it. 
Hive,WITHOUT_CLASSIFICATION,/*      * Setup for 3 different kinds of vectorized reading supported:     *     *   1) Read the Vectorized Input File Format which returns VectorizedRowBatch as the row.     *     *   2) Read using VectorDeserializeRow to deserialize each row into the VectorizedRowBatch.     *     *   3) And read using the regular partition deserializer to get the row object and assigning     *      the row object into the VectorizedRowBatch with VectorAssignRow.      */
Hive,WITHOUT_CLASSIFICATION,// "warehouse/t/HIVE_UNION_SUBDIR_15/000000_0" is a meaningful path for nonAcid2acid 
Hive,WITHOUT_CLASSIFICATION,// no records will be emited from Hive 
Hive,WITHOUT_CLASSIFICATION,//  Filter.g cannot parse a quoted date; try to parse date here too. 
Hive,WITHOUT_CLASSIFICATION,//  verify whether the sql operation log is generated and fetch correctly in async mode. 
Hive,WITHOUT_CLASSIFICATION,//  to get access to the queryInfo instance. 
Hive,WITHOUT_CLASSIFICATION,//  Set the row values 
Hive,WITHOUT_CLASSIFICATION,//  Handle MergeJoin specially and check for all its children 
Hive,WITHOUT_CLASSIFICATION,//  Push filter on top of children for discardable 
Hive,WITHOUT_CLASSIFICATION,//  leftFast1 != 0. 
Hive,WITHOUT_CLASSIFICATION,//  Run initiator to clean the row fro the aborted transaction from TXNS. 
Hive,WITHOUT_CLASSIFICATION,//  If there is a single column return the number of distinct values 
Hive,WITHOUT_CLASSIFICATION,//  5/ test serialization and deserialization with different schemas 
Hive,WITHOUT_CLASSIFICATION,//  Use the REWRITTEN AST 
Hive,WITHOUT_CLASSIFICATION,//  for writing out single byte 
Hive,WITHOUT_CLASSIFICATION,//  then search from parent 
Hive,WITHOUT_CLASSIFICATION,//  If the top-level object inspector is non-settable return false 
Hive,WITHOUT_CLASSIFICATION,//  The keyEvaluate reuses storage.  That doesn't work with SMB MapJoin because it   holds references to keys as it is merging. 
Hive,WITHOUT_CLASSIFICATION,//  Event 6 
Hive,WITHOUT_CLASSIFICATION,//  give HMS time to handle close request 
Hive,WITHOUT_CLASSIFICATION,//  Used for showJobFailDebugInfo 
Hive,WITHOUT_CLASSIFICATION,//  cKey is not present in parent 
Hive,WITHOUT_CLASSIFICATION,//  If a replacement exists for this code point emit out the replacement and append it to the 
Hive,WITHOUT_CLASSIFICATION,//  Try scheduling again. 
Hive,WITHOUT_CLASSIFICATION,//  optional string myString = 2; 
Hive,WITHOUT_CLASSIFICATION,//  set bit to 1 if a field is not null 
Hive,WITHOUT_CLASSIFICATION,//  is retried. "20001" means 3 retries - each with 1 retry with a random 2000ms sleep. 
Hive,WITHOUT_CLASSIFICATION,//  Prune partitions 
Hive,WITHOUT_CLASSIFICATION,//  Test that existing exclusive db with new shared_read coalesces to 
Hive,WITHOUT_CLASSIFICATION,//     assertEquals(nullstats.getSum()); 
Hive,WITHOUT_CLASSIFICATION,//  mapjoin should not affected by join reordering 
Hive,WITHOUT_CLASSIFICATION,//  hadoop 2.4 and earlier way of finding the sasl property settings   Initialize the SaslRpcServer to ensure QOP parameters are read from   conf 
Hive,WITHOUT_CLASSIFICATION,//  Drop table with partitions 
Hive,WITHOUT_CLASSIFICATION,//  thus we run the field trimmer again to push them back down 
Hive,WITHOUT_CLASSIFICATION,//  Datanucleus propagates some pointless exceptions and rolls back in the finally. 
Hive,WITHOUT_CLASSIFICATION,//  Get of non-existent key should terminate.. 
Hive,WITHOUT_CLASSIFICATION,//  double scalar/long column IF 
Hive,WITHOUT_CLASSIFICATION,//  If/else chain arranged in likely order of frequency for performance 
Hive,WITHOUT_CLASSIFICATION,//  check if required privileges is subset of available privileges 
Hive,WITHOUT_CLASSIFICATION,//  SettableListObjectInspector 
Hive,WITHOUT_CLASSIFICATION,//  Event 5 
Hive,WITHOUT_CLASSIFICATION,//  print operators 
Hive,WITHOUT_CLASSIFICATION,//  We've already dropped testDbName in constructor & we also drop it in tearDownAfterClass 
Hive,WITHOUT_CLASSIFICATION,//  Multiply by inverse (2^-N) to do the 2^N division. 
Hive,WITHOUT_CLASSIFICATION,//  no data for bucket 3 -- expect 0 length bucket file 
Hive,WITHOUT_CLASSIFICATION,//  Similarly this is map of which vectorized row batch columns are the big table value columns.   Since we may have value expressions that produce new scratch columns we need a mapping. 
Hive,WITHOUT_CLASSIFICATION,//  To detect incorrect lists. 
Hive,WITHOUT_CLASSIFICATION,//  no stripes satisfies the condition 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#isValid(int)    */
Hive,WITHOUT_CLASSIFICATION,//  2: 
Hive,WITHOUT_CLASSIFICATION,//  A user could encounter this if a stored view definition contains   an old SQL construct which has been eliminated in a later Hive   version so we need to provide full debugging info to help   with fixing the view definition. 
Hive,WITHOUT_CLASSIFICATION,//  Restore the old value. 
Hive,WITHOUT_CLASSIFICATION,// now that we are using LEFT OUTER JOIN to join inner count count(*)   with outer table we wouldn't be able to tell if count is zero   for inner table since inner join with correlated values will get rid   of all values where join cond is not true (i.e where actual inner table   will produce zero result). To  handle this case we need to check both   count is zero or count is null 
Hive,WITHOUT_CLASSIFICATION,//  default to -1 means we leave it up to Tez to decide 
Hive,WITHOUT_CLASSIFICATION,//  Restrict the set of columns that we want to read from the Accumulo table 
Hive,WITHOUT_CLASSIFICATION,//  [A: 0 B: 1 B.x: 0 B.y: 0 C: 0] 
Hive,WITHOUT_CLASSIFICATION,// previous insert+union creates 3 data files (0-3) 
Hive,WITHOUT_CLASSIFICATION,//  if rowCnt < 1 than its either empty table or table on which stats are not    computed We assume the worse and don't attempt to optimize. 
Hive,WITHOUT_CLASSIFICATION,//  For CalcitePlanner store qualified name too 
Hive,WITHOUT_CLASSIFICATION,//  list need to be refactored out to be done only once. 
Hive,WITHOUT_CLASSIFICATION,//  Try the base config 
Hive,WITHOUT_CLASSIFICATION,//  affects some less obscure scenario. 
Hive,WITHOUT_CLASSIFICATION,//  For primary keys we retrieve the column descriptors if retrieveCD is true (which means   it is an alter table statement) or if it is a create table statement but we are 
Hive,WITHOUT_CLASSIFICATION,//  Hive jars on the Accumulo classpath which we don't want 
Hive,WITHOUT_CLASSIFICATION,//  The DPP operator/branch are equal 
Hive,WITHOUT_CLASSIFICATION,//  Event 3 
Hive,WITHOUT_CLASSIFICATION,//  Add the input with project on top 
Hive,WITHOUT_CLASSIFICATION,//  Make sure we handle unary + and - correctly. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure that the unwanted key is not present in the map 
Hive,WITHOUT_CLASSIFICATION,//  Setup our hash table specialization.  It will be the first time the process   method is called or after a Hybrid Grace reload. 
Hive,WITHOUT_CLASSIFICATION,//  Create a lock and trigger a heartbeat. With heartbeat the lock won't expire. 
Hive,WITHOUT_CLASSIFICATION,//  For the FetchTask the limit optimization requires we fetch all the rows   in memory and count how many rows we get. It's not practical if the 
Hive,WITHOUT_CLASSIFICATION,//  Create the mapping corresponding to the grouping set 
Hive,WITHOUT_CLASSIFICATION,//  out the escaped byte in the block above already. 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise only order by expressions. 
Hive,WITHOUT_CLASSIFICATION,//  Gosh really both scaling up and down.   unscaledValue = significand * 5**(scale) /   2**(twoScaleDown-scale)   To check overflow while preserving precision we need to do a   real multiplication 
Hive,WITHOUT_CLASSIFICATION,// We may be parsing a delta for Insert-only table which may not even be an ORC file so  cannot have ROW_IDs in it. 
Hive,WITHOUT_CLASSIFICATION,//  if get exception in finding partition   it could be DESCRIBE table key   return null   continue processing for DESCRIBE table key 
Hive,WITHOUT_CLASSIFICATION,//  test the mapping of empty string to all columns 
Hive,WITHOUT_CLASSIFICATION,//  be updated to bytes per reducer (1GB default) 
Hive,WITHOUT_CLASSIFICATION,/*  Two of the optimization rules ConvertJoinMapJoin and RemoveDynamicPruningBySize are put into     stats dependent optimizations and run together in TezCompiler. There's no guarantee which one     runs first but in either case the prior one may have removed a chain which the latter one is     not aware of. So we need to remember the leaf node(s) of that chain so it can be skipped.     For example as ConvertJoinMapJoin is removing the reduce sink it may also have removed a     dynamic partition pruning operator chain. However RemoveDynamicPruningBySize doesn't know this     and still tries to traverse that removed chain which will cause NPE.     This may also happen when RemoveDynamicPruningBySize happens first.     */
Hive,WITHOUT_CLASSIFICATION,//  Db name for materialization to rebuild   Name for materialization to rebuild 
Hive,WITHOUT_CLASSIFICATION,//  3 Convert OB expr (OB Expr is usually an input ref except for top 
Hive,WITHOUT_CLASSIFICATION,//  Create a semantic analyzer for the query 
Hive,WITHOUT_CLASSIFICATION,// which was modified by the T1 update stmt or choose a non-conflicting one 
Hive,WITHOUT_CLASSIFICATION,//  Do not release beyond current stream (we don't know which RGs that buffer is for). 
Hive,WITHOUT_CLASSIFICATION,//  Move offset to point to start of next input. 
Hive,WITHOUT_CLASSIFICATION,//  All are null so all must be selected. 
Hive,WITHOUT_CLASSIFICATION,//  The last char is an escape char read the actual char.   The serialization format escape \0 to \1 and \1 to \2   to make sure the string is null-terminated. 
Hive,WITHOUT_CLASSIFICATION,// assumes bucket_NNNNN format of file name 
Hive,WITHOUT_CLASSIFICATION,//  get column name 
Hive,WITHOUT_CLASSIFICATION,//  This is what the Vectorizer class does. 
Hive,WITHOUT_CLASSIFICATION,//  We transform the BETWEEN clause to AND clause (with NOT on top in invert is true).   This is more straightforward as the evaluateExpression method will deal with 
Hive,WITHOUT_CLASSIFICATION,//  convert to a lazy object and return 
Hive,WITHOUT_CLASSIFICATION,//  used to determined whether the merge can happen 
Hive,WITHOUT_CLASSIFICATION,//  Succeed - trying to set "transactional" to "true" and satisfies bucketing and Input/OutputFormat requirement 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: we should gather stats in MR1 rather than MR2 at merge job since we don't 
Hive,WITHOUT_CLASSIFICATION,// initial state is one connection 
Hive,WITHOUT_CLASSIFICATION,// Inner classes 
Hive,WITHOUT_CLASSIFICATION,//  Should go through in a single process call 
Hive,WITHOUT_CLASSIFICATION,//  either schema literal schema url or serialization class must   be provided 
Hive,WITHOUT_CLASSIFICATION,//  20seconds to wait for app to be visible 
Hive,WITHOUT_CLASSIFICATION,//  given the current input row the mapping for input col info to dp columns and # of dp cols   return the relative path corresponding to the row. 
Hive,WITHOUT_CLASSIFICATION,//  If sort contains a limit operation we bail out 
Hive,WITHOUT_CLASSIFICATION,//  None of the operators is changing the positions 
Hive,WITHOUT_CLASSIFICATION,//  first operator of the reduce task. (not the reducesinkoperator but the 
Hive,WITHOUT_CLASSIFICATION,// This is just a simple way to generate test data 
Hive,WITHOUT_CLASSIFICATION,//  Create enough keyConverters/valueConverters   NOTE: we have to have a separate key/valueConverter for each key/value   because the key/valueConverters can reuse the internal object.   So it's not safe to use the same key/valueConverter to convert multiple   key/values. 
Hive,WITHOUT_CLASSIFICATION,//  We use the trick mentioned in "Less Hashing Same Performance: Building a Better Bloom Filter"   by Kirsch et.al. From abstract 'only two hash functions are necessary to effectively   implement a Bloom filter without any loss in the asymptotic false positive probability' 
Hive,WITHOUT_CLASSIFICATION,//  Validate the metastore client call validatePartitionNameCharacters to ensure it throws   an exception if partition fields contain Unicode characters or commas 
Hive,WITHOUT_CLASSIFICATION,//  first item 
Hive,WITHOUT_CLASSIFICATION,//  Check for DPP and semijoin DPP 
Hive,WITHOUT_CLASSIFICATION,//  any value will become zero. even no possibility of rounding 
Hive,WITHOUT_CLASSIFICATION,//  will cause overflow for result at position 0 must yield NULL 
Hive,WITHOUT_CLASSIFICATION,// This error code should really be produced by Hive 
Hive,WITHOUT_CLASSIFICATION,//  metastore calls timing information 
Hive,WITHOUT_CLASSIFICATION,//  When truncated included is used its length must be at least the number of source type infos.   When longer we assume the caller will default with nulls etc. 
Hive,WITHOUT_CLASSIFICATION,//  if we are in close op phase we have definitely exhausted the big table input 
Hive,WITHOUT_CLASSIFICATION,//  Check if array is null or empty or value is null 
Hive,WITHOUT_CLASSIFICATION,//  Pick the formatter to use to display the results.  Either the   normal human readable output or a json object. 
Hive,WITHOUT_CLASSIFICATION,//  The DecimalColumnVector set method will quickly copy the deserialized decimal writable fields. 
Hive,WITHOUT_CLASSIFICATION,//  find the file on the include path 
Hive,WITHOUT_CLASSIFICATION,//  Primarily to avoid multiple shutdowns. 
Hive,WITHOUT_CLASSIFICATION,//  Temporary tables created during the execution are not the input sources 
Hive,WITHOUT_CLASSIFICATION,//  null principal 
Hive,WITHOUT_CLASSIFICATION,//  replace original VAR_POP(x) with       (SUM(x * x) - SUM(x) * SUM(x) / COUNT(x))       / COUNT(x) 
Hive,WITHOUT_CLASSIFICATION,//  We use a StringBuilder and then call printError only once as   printError will write to both stderr and the error log file. In   situations where both the stderr and the log file output is   simultaneously output to a single stream this will look cleaner. 
Hive,WITHOUT_CLASSIFICATION,//  private boolean isOuterJoin; 
Hive,WITHOUT_CLASSIFICATION,//  We don't send messages to pending tasks with the flags; they should be killed elsewhere. 
Hive,WITHOUT_CLASSIFICATION,//  Recursive flush to flush all the tree operators 
Hive,WITHOUT_CLASSIFICATION,/*    * Test updateCredentialProviders does not corrupt existing values of   * Mapred env configs    */
Hive,WITHOUT_CLASSIFICATION,//  sort the works so that we get consistent query plan for multi executions(for test verification). 
Hive,WITHOUT_CLASSIFICATION,//  Process the report 
Hive,WITHOUT_CLASSIFICATION,//  for wordshift 
Hive,WITHOUT_CLASSIFICATION,//  Thursday 1st August 1985 12:00:00 AM 
Hive,WITHOUT_CLASSIFICATION,//  neither dir should get created. 
Hive,WITHOUT_CLASSIFICATION,//  statistics annotation fetches column statistics for all required columns which can 
Hive,WITHOUT_CLASSIFICATION,//  We just had leading zeroes.   Value is 0. 
Hive,WITHOUT_CLASSIFICATION,//  find the ancestor which exists to check its permissions 
Hive,WITHOUT_CLASSIFICATION,//  load properties from spark-defaults.conf. 
Hive,WITHOUT_CLASSIFICATION,//  Prepare aggs for updating 
Hive,WITHOUT_CLASSIFICATION,/*    * This method updates the input expr changing all the   * ExprNodeColumnDesc in it to refer to columns given by the   * colExprMap.   *   * For instance "col_0 = 1" would become "VALUE.col_0 = 1";   * the execution engine expects filters in the Join operators   * to be expressed that way.    */
Hive,WITHOUT_CLASSIFICATION,//  new n-gram 
Hive,WITHOUT_CLASSIFICATION,//  1. If the input node is not an IN operator we bail out. 
Hive,WITHOUT_CLASSIFICATION,//  We should find an alias of this insert and do (alias).*. This however won't fix e.g.   positional order by alias case cause we'd still have a star on the top level. Bail. 
Hive,WITHOUT_CLASSIFICATION,//  Set to 1 so insert doesn't set it off but update does 
Hive,WITHOUT_CLASSIFICATION,//  First generate the expression for the partition and sort keys   The cluster by clause / distribute by clause has the aliases for   partition function 
Hive,WITHOUT_CLASSIFICATION,//  Because there is a 1-N relationship between CDs and SDs   we must set the SD's CD to null first before dropping the storage descriptor   to satisfy foreign key constraints. 
Hive,WITHOUT_CLASSIFICATION,// see bucket_num_reducers.q bucket_num_reducers2.q 
Hive,WITHOUT_CLASSIFICATION,// we are in CTAS so we know there are no partitions 
Hive,WITHOUT_CLASSIFICATION,//  If the character set for decoding is constant we can optimize that 
Hive,WITHOUT_CLASSIFICATION,//  Retry the next port 
Hive,WITHOUT_CLASSIFICATION,//  deltas and base and leave them up to the cleaner to clean up 
Hive,WITHOUT_CLASSIFICATION,//  We have already locked the table don't lock the partitions. 
Hive,WITHOUT_CLASSIFICATION,//  Root tran it must be MapInput 
Hive,WITHOUT_CLASSIFICATION,//  For dpp case dpp sink will appear in Task1 and the target work of dpp sink will appear in Task2.   Task2 is the child task of Task1. Task2 will be traversed before task1 because TaskGraphWalker will first   put children task in the front of task queue.   If a spark work which is equal to other is found and removed in Task2 the dpp sink can be removed when Task1   is traversed(More detailed see HIVE-16948) 
Hive,WITHOUT_CLASSIFICATION,//  appended once all the session list are added to the url 
Hive,WITHOUT_CLASSIFICATION,//  1. Insert two rows to an ACID table 
Hive,WITHOUT_CLASSIFICATION,//  If left and right aliases are all valid two values will be inner joined 
Hive,WITHOUT_CLASSIFICATION,// doesn't vectorize (uses neither of the Vectorzied Acid readers) 
Hive,WITHOUT_CLASSIFICATION,//  -e 'quoted-query-string' 
Hive,WITHOUT_CLASSIFICATION,/*      * Tracks the last non-OOB heartbeat number at which counters were sent to the AM.       */
Hive,WITHOUT_CLASSIFICATION,//  AggKey in StatsWork is used for stats aggregation while StatsAggPrefix   in FileSinkDesc is used for stats publishing. They should be consistent. 
Hive,WITHOUT_CLASSIFICATION,//  LLAP object cache unlike others does not use globals. Thus get the existing one. 
Hive,WITHOUT_CLASSIFICATION,//  Start HS2 with SSL 
Hive,WITHOUT_CLASSIFICATION,//  No boolean value match for other lengths. 
Hive,WITHOUT_CLASSIFICATION,// cannot be acid 
Hive,WITHOUT_CLASSIFICATION,// if writing to a partitioned table then pigSchema will have more columns than tableSchema  partition columns are not part of tableSchema... e.g. TestHCatStorer#testPartColsInData()          HCatUtil.assertNotNull(hcatFieldSchema "Nothing matching '" + fSchema.alias + "' found " +                  "in target table schema" LOG); 
Hive,WITHOUT_CLASSIFICATION,//  e.g. -(17#).e-###   see http://download.oracle.com/javase/6/docs/api/constant-values.html#java.lang.Double.MAX_EXPONENT 
Hive,WITHOUT_CLASSIFICATION,//  Collect bucket and/or partition information for object hashing. 
Hive,WITHOUT_CLASSIFICATION,//  every slot is a long 
Hive,WITHOUT_CLASSIFICATION,//  We will try to combine multiple clauses into a smaller number with compatible keys. 
Hive,WITHOUT_CLASSIFICATION,//  A flag for each byte to indicate if escape is needed. 
Hive,WITHOUT_CLASSIFICATION,//  check if all of the bit vectors can merge 
Hive,WITHOUT_CLASSIFICATION,//  invalid number 
Hive,WITHOUT_CLASSIFICATION,//  initialize buffer to read the entire stripe 
Hive,WITHOUT_CLASSIFICATION,//  add_partitions(54) : err = duplicate keyvals on mpart4 
Hive,WITHOUT_CLASSIFICATION,//  Dispatch current node 
Hive,WITHOUT_CLASSIFICATION,//  Queries rejected from being cached due to non-deterministic functions temp tables or other conditions. 
Hive,WITHOUT_CLASSIFICATION,/*    * - called during translation.   * - invokes createEvaluator which must be implemented by a subclass   * - sets up the evaluator with references to the TableDef PartitionClass PartitionMemsize and   *   the transformsRawInput boolean.    */
Hive,WITHOUT_CLASSIFICATION,//  Handle rename and other changes. 
Hive,WITHOUT_CLASSIFICATION,//  Rule cannot be applied if there are GroupingId because it will change the   value as the position will be changed. 
Hive,WITHOUT_CLASSIFICATION,//  The length of the long array that needs to be passed to serializationUtilsWrite. 
Hive,WITHOUT_CLASSIFICATION,//  Allow accessing a field of list element structs directly from a list 
Hive,WITHOUT_CLASSIFICATION,//  Print the key 
Hive,WITHOUT_CLASSIFICATION,//  if kill query is null then session might have been released to pool or closed already 
Hive,WITHOUT_CLASSIFICATION,//  This can be easily merged into 1 union 
Hive,WITHOUT_CLASSIFICATION,//  If we have Kerberos credentials we should obtain the delegation token 
Hive,WITHOUT_CLASSIFICATION,//  first we check if we *can* run in llap. If we need to use   user code to do so (script/udf) we don't. 
Hive,WITHOUT_CLASSIFICATION,//  We should always get a different object and cluster fraction should be propagated. 
Hive,WITHOUT_CLASSIFICATION,//  Set isManaged to false as this is not load data operation for which it is needed. 
Hive,WITHOUT_CLASSIFICATION,// check status of compaction job 
Hive,WITHOUT_CLASSIFICATION,//  While there are still nodes to dispatch... 
Hive,WITHOUT_CLASSIFICATION,//     CacheChunks so the list is just CacheChunk-s from that point on. 
Hive,WITHOUT_CLASSIFICATION,//  to have more control. 
Hive,WITHOUT_CLASSIFICATION,//  for rest of the join type we will take min of the reduction. 
Hive,WITHOUT_CLASSIFICATION,//  verify that ptned table rename succeded. 
Hive,WITHOUT_CLASSIFICATION,//  bucket map join the big table's bucketing version is considered. 
Hive,WITHOUT_CLASSIFICATION,// ZK Stuff 
Hive,WITHOUT_CLASSIFICATION,//  Dump and load insert after truncate (1 record) 
Hive,WITHOUT_CLASSIFICATION,// branches. 
Hive,WITHOUT_CLASSIFICATION,//  Copy the digits in the right side of the array 
Hive,WITHOUT_CLASSIFICATION,//  We are replacing the current big table with a new one thus 
Hive,WITHOUT_CLASSIFICATION,//  Set the actual events for the tasks. 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   required   required   required   required   required   required   required   required   required   optional   optional   optional   optional   optional   optional 
Hive,WITHOUT_CLASSIFICATION,// operationManager.closeOperation() is expected to be invoked once 
Hive,WITHOUT_CLASSIFICATION,//  Register taskAttempt unregister container. TaskAttempt should also be unregistered 
Hive,WITHOUT_CLASSIFICATION,//  If neither cred provider or conf have entry return null; 
Hive,WITHOUT_CLASSIFICATION,//  and "skewed columns != skewed keys" in selectOpClone 
Hive,WITHOUT_CLASSIFICATION,//  ditto 
Hive,WITHOUT_CLASSIFICATION,//  free the memory for the column vectors 
Hive,WITHOUT_CLASSIFICATION,//  It is in the cache and up to date 
Hive,WITHOUT_CLASSIFICATION,//  take integer part of it 
Hive,WITHOUT_CLASSIFICATION,// This happens when the code inside the JMX bean (setter?? from the java docs)  threw an exception so log it and skip outputting the attribute 
Hive,WITHOUT_CLASSIFICATION,//  Used to make sure that waiting getSessions don't block update. 
Hive,WITHOUT_CLASSIFICATION,//  Example for using cluster configuration xml-s 
Hive,WITHOUT_CLASSIFICATION,//  If schemas do not match we currently do not merge 
Hive,WITHOUT_CLASSIFICATION,//  Fail the query if the stats are supposed to be reliable 
Hive,WITHOUT_CLASSIFICATION,//  Create a list of topop nodes and walk! 
Hive,WITHOUT_CLASSIFICATION,//  Simulate a 2s delay before finishing the task. 
Hive,WITHOUT_CLASSIFICATION,//  in Operator since we want to individually track the number of rows from different inputs. 
Hive,WITHOUT_CLASSIFICATION,// get actual number of rows from metastore 
Hive,WITHOUT_CLASSIFICATION,//  update no skew task 
Hive,WITHOUT_CLASSIFICATION,//  Make sure the compactor has a chance to run once 
Hive,WITHOUT_CLASSIFICATION,//  which are going to return values from the input batch vector expressions 
Hive,WITHOUT_CLASSIFICATION,//  TEST - repeating NULL & selection 
Hive,WITHOUT_CLASSIFICATION,//  Now delete a node for this key's list 
Hive,WITHOUT_CLASSIFICATION,//  Hash code logic from original calculateLongHashCode 
Hive,WITHOUT_CLASSIFICATION,//  GSS credentials for server 
Hive,WITHOUT_CLASSIFICATION,//  For Hybrid Grace Hash Join during the 1st round processing   we only keep the LEFT side if the row is not spilled 
Hive,WITHOUT_CLASSIFICATION,//  Dump the drop events and check if tables are getting dropped in target as well 
Hive,WITHOUT_CLASSIFICATION,/*  Walk through all found table locations to get the most encrypted table  */
Hive,WITHOUT_CLASSIFICATION,//  This is the adjusted index after nested column pruning.   For instance given the struct type: s:<struct<a:int b:boolean>>   If only 's.b' is used the pruned type is: s:<struct<b:boolean>>.   Here the index of field 'b' is changed from 1 to 0.   When we look up the data from Parquet index needs to be adjusted accordingly.   Note: currently this is only used in the read path. 
Hive,WITHOUT_CLASSIFICATION,//  No matching methods found 
Hive,WITHOUT_CLASSIFICATION,//  optimize for common case - just one row for a key container acts as iterator 
Hive,WITHOUT_CLASSIFICATION,//  since map key for Pig has to be Strings 
Hive,WITHOUT_CLASSIFICATION,//  All data and partition columns. 
Hive,WITHOUT_CLASSIFICATION,//  Runs an instance of DisallowUnicodePreEventListener   Returns whether or not it succeeded 
Hive,WITHOUT_CLASSIFICATION,//  CTRL-D 
Hive,WITHOUT_CLASSIFICATION,//  In this method we must only process non-Decimal64 column vectors.   Convert Decimal64 columns to regular decimal. 
Hive,WITHOUT_CLASSIFICATION,//  construct a mapping of (Partition->bucket file names) and (Partition -> bucket number) 
Hive,WITHOUT_CLASSIFICATION,//  2. Generate tags 
Hive,WITHOUT_CLASSIFICATION,//  A mapping from a directory which a FileSinkOperator writes into to the columns by which that 
Hive,WITHOUT_CLASSIFICATION,//  Create a CuratorFramework instance to be used as the ZooKeeper client   Use the zooKeeperAclProvider to create appropriate ACLs 
Hive,WITHOUT_CLASSIFICATION,//  should share cte contexts 
Hive,WITHOUT_CLASSIFICATION,//  Assumes that the catalog has already been set. 
Hive,WITHOUT_CLASSIFICATION,//  Restart if there's an internal error. 
Hive,WITHOUT_CLASSIFICATION,//  NDV(expr) = max(NDV( expr args)) 
Hive,WITHOUT_CLASSIFICATION,//  an error in creation and we want to delete it anyway. 
Hive,WITHOUT_CLASSIFICATION,//  -w (or) --password-file <file> 
Hive,WITHOUT_CLASSIFICATION,//  Open an accumulo connection 
Hive,WITHOUT_CLASSIFICATION,/*  'greg' < first_name  */
Hive,WITHOUT_CLASSIFICATION,//  required   optional   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  After this the KeyWrappers are properly set and hash code is computed 
Hive,WITHOUT_CLASSIFICATION,//  1. Sum of input cardinalities 
Hive,WITHOUT_CLASSIFICATION,//  the user has specified to ignore mapjoin hint 
Hive,WITHOUT_CLASSIFICATION,//  NEW TAI LUE LETTER HIGH MA U+1996 (3 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  TODO: if using in multiple places e.g. SerDe cache pass this in. 
Hive,WITHOUT_CLASSIFICATION,//  Empty array 
Hive,WITHOUT_CLASSIFICATION,// EK: it's not obvious that this is the right logic if we don't record the 'callback'  for example and never notify the client of job completion 
Hive,WITHOUT_CLASSIFICATION,//  issue warning for missing file and throw exception 
Hive,WITHOUT_CLASSIFICATION,//  in the absence of SORTED BY clause the sorted dynamic partition insert 
Hive,WITHOUT_CLASSIFICATION,//  If timer is null start a new one.   If timer has completed during previous invocation start a new one.   If timer already started and is not completed leaving it running without resetting it. 
Hive,WITHOUT_CLASSIFICATION,//  Test that CliDriver does not strip comments starting with '--' 
Hive,WITHOUT_CLASSIFICATION,//  Create dest table partitions with custom locations 
Hive,WITHOUT_CLASSIFICATION,//  2nd substring index refers to the 6th index (last char in the array) 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:LlapManagementProtocol) 
Hive,WITHOUT_CLASSIFICATION,/*        * a. add Map-side PTF Operator if needed        */
Hive,WITHOUT_CLASSIFICATION,//  Clear integer portion; keep fraction. 
Hive,WITHOUT_CLASSIFICATION,//  0 XOR 1 yields 1 1 XOR 1 yields 0 
Hive,WITHOUT_CLASSIFICATION,//  Temp functions are not allowed to have qualified names. 
Hive,WITHOUT_CLASSIFICATION,//  2. Sanity check 
Hive,WITHOUT_CLASSIFICATION,//  Alter an existing partition ("aaa") via ObjectStore 
Hive,WITHOUT_CLASSIFICATION,//  TYPE_QUALIFIERS 
Hive,WITHOUT_CLASSIFICATION,//  abortedBits should be all true as everything in exceptions are aborted txns 
Hive,WITHOUT_CLASSIFICATION,//  merge work. Else create a merge work add above work to the merge work 
Hive,WITHOUT_CLASSIFICATION,//  Find the writeId high water mark based upon txnId high water mark. If found then need to   traverse through all write Ids less than writeId HWM to make exceptions list. 
Hive,WITHOUT_CLASSIFICATION,// MR stuff 
Hive,WITHOUT_CLASSIFICATION,//  we've already gone beyond the specified range 
Hive,WITHOUT_CLASSIFICATION,//  a state that the driver enters after destroy() is called and it is the end of driver life cycle 
Hive,WITHOUT_CLASSIFICATION,//  For example 2 partitions (1 sequencefile and 1 rcfile) will have 2 different splits 
Hive,WITHOUT_CLASSIFICATION,//  check if all the ColumnStatisticsObjs contain stats and all the ndv are   bitvectors 
Hive,WITHOUT_CLASSIFICATION,//  to find target for fetch task conversion optimizer (not allows subqueries) 
Hive,WITHOUT_CLASSIFICATION,//  Handle date-string common category and numeric-string common category 
Hive,WITHOUT_CLASSIFICATION,// ========================== 10000 range starts here ========================// 
Hive,WITHOUT_CLASSIFICATION,//  LOG.debug("VectorMapJoinFastKeyStore equalKey no match on bytes"); 
Hive,WITHOUT_CLASSIFICATION,//  We are not Throwing an exception since it might be a transient issue that is blocking loading 
Hive,WITHOUT_CLASSIFICATION,//  Consumes whole key. 
Hive,WITHOUT_CLASSIFICATION,//  store table descriptor in map-targetWork 
Hive,WITHOUT_CLASSIFICATION,// this is db.table 
Hive,WITHOUT_CLASSIFICATION,//  check whether substitution is allowed 
Hive,WITHOUT_CLASSIFICATION,//  We have failed to reserve a single header. Do not undo the previous ones here   the caller has to handle this to avoid races. 
Hive,WITHOUT_CLASSIFICATION,/* Future thought: checkForCompaction will check a lot of file metadata and may be expensive.              * Long term we should consider having a thread pool here and running checkForCompactionS              * in parallel */
Hive,WITHOUT_CLASSIFICATION,//  Hardcoded from a private field in ZKDelegationTokenSecretManager.   We need to check the path under what it sets for namespace since the namespace is   created with world ACLs. 
Hive,WITHOUT_CLASSIFICATION,//  Project the big table key into the small table result "area". 
Hive,WITHOUT_CLASSIFICATION,// RecordReader.getRowNumber() produces a file-global row number even with PPD 
Hive,WITHOUT_CLASSIFICATION,//  Subtract the spills to get all match and non-match rows. 
Hive,WITHOUT_CLASSIFICATION,//  Stats bookkeeping 
Hive,WITHOUT_CLASSIFICATION,//  use the specified database if specified 
Hive,WITHOUT_CLASSIFICATION,// Increments one HMS connection 
Hive,WITHOUT_CLASSIFICATION,/* rename(A B) has "interesting" behavior if A and B are directories. If  B doesn't exist        * it does the expected operation and everything that was in A is now in B.  If B exists        * it will make A a child of B...  thus make sure the rename() is done before creating the        * meta files which will create base_x/ (i.e. B)... */
Hive,WITHOUT_CLASSIFICATION,//  middle items in order 
Hive,WITHOUT_CLASSIFICATION,//  1. Sanity check 
Hive,WITHOUT_CLASSIFICATION,// certain queries like select count(*) from table do not have  any projected columns and still have isReadAllColumns as false  in such cases columnReaders are not needed  However if colsToInclude is not empty we should initialize each columnReader 
Hive,WITHOUT_CLASSIFICATION,//  Note: incomplete CBs are always an exact match. 
Hive,WITHOUT_CLASSIFICATION,/*    * Helper function to create an edge property from an edge type.    */
Hive,WITHOUT_CLASSIFICATION,/*  10 files x 1000 size for 111 splits  */
Hive,WITHOUT_CLASSIFICATION,//  Insert time-zone for timestamp type 
Hive,WITHOUT_CLASSIFICATION,//  Handle different types of CREATE TABLE command   Note: each branch must call addDbAndTabToOutputs after finalizing table properties. 
Hive,WITHOUT_CLASSIFICATION,//  LATIN SMALL LETTER GAMMA U+0263 (2 bytes) 
Hive,WITHOUT_CLASSIFICATION,// Is this an expression that should perform a comparison for sorted searches 
Hive,WITHOUT_CLASSIFICATION,//  Skipping because of hint. Mark this info 
Hive,WITHOUT_CLASSIFICATION,//  Divide down just before scaleDown to get round digit. 
Hive,WITHOUT_CLASSIFICATION,//  invalid time part 
Hive,WITHOUT_CLASSIFICATION,//  Project projects the original expressions 
Hive,WITHOUT_CLASSIFICATION,//  default serde for rcfile 
Hive,WITHOUT_CLASSIFICATION,//  JAVA32_META + JAVA32_REF   JAVA32_ARRAY_META + JAVA32_REF 
Hive,WITHOUT_CLASSIFICATION,//  test getTableObjectsByName 
Hive,WITHOUT_CLASSIFICATION,//  We rewrite it 
Hive,WITHOUT_CLASSIFICATION,//  The count of the elements of the above that are set. 
Hive,WITHOUT_CLASSIFICATION,//  create the vertex 
Hive,WITHOUT_CLASSIFICATION,//  init the RNG for breaking ties in histogram merging. A fixed seed is specified here   to aid testing but can be eliminated to use a time-based seed (which would   make the algorithm non-deterministic). 
Hive,WITHOUT_CLASSIFICATION,//  newDir(true) => stats not updated 
Hive,WITHOUT_CLASSIFICATION,//  Do the V1 fields of older and newer match? 
Hive,WITHOUT_CLASSIFICATION,//  Method signature changed in Hadoop 2.7. Cast provider to KeyProvider 
Hive,WITHOUT_CLASSIFICATION,//  decimal 
Hive,WITHOUT_CLASSIFICATION,//  Transaction for which the list of tables valid write Ids are populated 
Hive,WITHOUT_CLASSIFICATION,//  set hive provider path in hiveConf if setHiveProviderPath is true   simulates hive.server2.job.credstore.location property set in hive-site.xml/core-site.xml of 
Hive,WITHOUT_CLASSIFICATION,//  case 1 
Hive,WITHOUT_CLASSIFICATION,//  Set to false to block the next loop. This must be called before draining the lists   otherwise an add/completion after draining the lists but before setting it to false   will not trigger a run. May cause one unnecessary run if an add comes in before drain.   drain list. add request (setTrue). setFalse needs to be avoided. 
Hive,WITHOUT_CLASSIFICATION,//  extract all the inputFormatClass names for each chunk in the 
Hive,WITHOUT_CLASSIFICATION,//  Remove semijoin optimization if SMB join is created. 
Hive,WITHOUT_CLASSIFICATION,// TINYINT 
Hive,WITHOUT_CLASSIFICATION,//  We use a separate metastore client for heartbeat calls to ensure heartbeat RPC calls are 
Hive,WITHOUT_CLASSIFICATION,//  no encoded values we can push directly to row. 
Hive,WITHOUT_CLASSIFICATION,//  4. Construct GB Keys (ExprNode) 
Hive,WITHOUT_CLASSIFICATION,//  "abc"   "abc%"   "%abc"   "%abc%"   all other cases such as "ab%c_de" 
Hive,WITHOUT_CLASSIFICATION,//  key is only string 
Hive,WITHOUT_CLASSIFICATION,//  Drop an existing partition ("bbb") via ObjectStore 
Hive,WITHOUT_CLASSIFICATION,//  The getter should remove the escape character for us 
Hive,WITHOUT_CLASSIFICATION,//  Byte 
Hive,WITHOUT_CLASSIFICATION,//  2nd Txn 
Hive,WITHOUT_CLASSIFICATION,//  3. We populate the filters structure 
Hive,WITHOUT_CLASSIFICATION,//  Multi-byte trims. 
Hive,WITHOUT_CLASSIFICATION,//  option to bypass job setup and cleanup was introduced in hadoop-21 (MAPREDUCE-463) 
Hive,WITHOUT_CLASSIFICATION,//  case 2 
Hive,WITHOUT_CLASSIFICATION,//  LSB p bits 
Hive,WITHOUT_CLASSIFICATION,//  Return value modulo n but always in the positive range (0..n-1).   And with the mask to zero the sign bit to make the input to mod positive   so the output will definitely be positive. 
Hive,WITHOUT_CLASSIFICATION,//  the database directory 
Hive,WITHOUT_CLASSIFICATION,// so that get(i) returns null rather than ArrayOutOfBounds 
Hive,WITHOUT_CLASSIFICATION,//  we need not to do any instanceof checks for following. 
Hive,WITHOUT_CLASSIFICATION,//  Filtering is handled in the input batch processing 
Hive,WITHOUT_CLASSIFICATION,/*  * This class provides support to collect mapreduce stderr/stdout/syslogs * from jobtracker and stored into a hdfs location. The log directory layout is: * <ul compact> * <li>logs/$job_id (directory for $job_id) * <li>logs/$job_id/job.xml.html * <li>logs/$job_id/$attempt_id (directory for $attempt_id) * <li>logs/$job_id/$attempt_id/stderr * <li>logs/$job_id/$attempt_id/stdout * <li>logs/$job_id/$attempt_id/syslog  * Since there is no API to retrieve mapreduce log from jobtracker the code retrieve * it from jobtracker ui and parse the html file. The current parser only works with * Hadoop 1 for Hadoop 2 we would need a different parser  */
Hive,WITHOUT_CLASSIFICATION,//  to take care of. 
Hive,WITHOUT_CLASSIFICATION,//  Also null down.   UNDONE 
Hive,WITHOUT_CLASSIFICATION,//  this is file system counter valid and create counter 
Hive,WITHOUT_CLASSIFICATION,//  We're passing client credentials as null since we want them to be read from the Subject. 
Hive,WITHOUT_CLASSIFICATION,//  This is the case where distinct cols are part of GB Keys in which case   we still need to add it to out put col names 
Hive,WITHOUT_CLASSIFICATION,// important so we get an exception on name collision 
Hive,WITHOUT_CLASSIFICATION,//  validate is true by default if we enable the constraint 
Hive,WITHOUT_CLASSIFICATION,//  Dummy insert into command to mark proper last repl ID after dump 
Hive,WITHOUT_CLASSIFICATION,//  We need to check whether this transaction is valid and open 
Hive,WITHOUT_CLASSIFICATION,//  case 3 
Hive,WITHOUT_CLASSIFICATION,//  Make a random array of longs 
Hive,WITHOUT_CLASSIFICATION,//  Use SourceStateUpdatedRequestProto.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,//  3. Return result 
Hive,WITHOUT_CLASSIFICATION,// the destf. in this case the replaced destf still preserves the original destf's permission 
Hive,WITHOUT_CLASSIFICATION,//  The regexes to look for in the log files 
Hive,WITHOUT_CLASSIFICATION,//  that long to see an abandoned session 
Hive,WITHOUT_CLASSIFICATION,//  This will be null at slaves. 
Hive,WITHOUT_CLASSIFICATION,//  invalid zone 
Hive,WITHOUT_CLASSIFICATION,//  Package permission so that HadoopThriftAuthBridge can construct it but others cannot. 
Hive,WITHOUT_CLASSIFICATION,//  get databases for schema pattern 
Hive,WITHOUT_CLASSIFICATION,// no DP so it's populated from lock info 
Hive,WITHOUT_CLASSIFICATION,//  If the retry logic is reached after copy error then include the copied file as well.   This is needed as we cannot figure out which file is incorrectly copied.   Expecting distcp to skip the properly copied file based on CRC check or copy it if CRC mismatch. 
Hive,WITHOUT_CLASSIFICATION,//  Change the table partition for collecting stats 
Hive,WITHOUT_CLASSIFICATION,//  case 4 
Hive,WITHOUT_CLASSIFICATION,//  Call describe 
Hive,WITHOUT_CLASSIFICATION,//  if the primary isn't done push it back into the readers 
Hive,WITHOUT_CLASSIFICATION,// run Cleaner 
Hive,WITHOUT_CLASSIFICATION,//  The Writable to return in serialize 
Hive,WITHOUT_CLASSIFICATION,/*      * Connect using the delegation token passed via configuration object      */
Hive,WITHOUT_CLASSIFICATION,//  We got an exception that is not IOException   (typically OOM IndexOutOfBounds InternalError).   This is most likely a corruption. 
Hive,WITHOUT_CLASSIFICATION,//  all of the OR branches need to be bucket-leaves 
Hive,WITHOUT_CLASSIFICATION,//  flatten key/value pairs into row object for use in Serde. 
Hive,WITHOUT_CLASSIFICATION,//  TODO: type conversion 
Hive,WITHOUT_CLASSIFICATION,//  No query. Either it is a CTAS or we need to create a Druid meta data Query 
Hive,WITHOUT_CLASSIFICATION,//  Obtain additional information if we should try incremental rewriting / rebuild   We will not try partial rewriting if there were update/delete operations on source tables 
Hive,WITHOUT_CLASSIFICATION,//  Set the range on the deleteEventReaderOptions to 0 to INTEGER_MAX because 
Hive,WITHOUT_CLASSIFICATION,//  All values should pass test 
Hive,WITHOUT_CLASSIFICATION,//  enable/disable bias correction using table lookup 
Hive,WITHOUT_CLASSIFICATION,//  first 2 stripes will satisfy the predicate and merged to single split last two stripe will 
Hive,WITHOUT_CLASSIFICATION,//  2. Finally create PTF 
Hive,WITHOUT_CLASSIFICATION,//  lock manager 
Hive,WITHOUT_CLASSIFICATION,//  Expected number of partitions dropped in each of those calls 
Hive,WITHOUT_CLASSIFICATION,//  Try to find the method 
Hive,WITHOUT_CLASSIFICATION,//  Create query 
Hive,WITHOUT_CLASSIFICATION,//  If this DemuxOperator directly connects to a MuxOperator   that MuxOperator must be the parent of a JoinOperator.   In this case that MuxOperator should be initialized   by multiple parents (of that MuxOperator). 
Hive,WITHOUT_CLASSIFICATION,//  loop over all the tasks recursively 
Hive,WITHOUT_CLASSIFICATION,/*    * Tests with queries which cannot be executed with directSQL because of type mismatch. The type   * of the num column is string but the parameters used in the where clause are numbers. After   * falling back to ORM the number of partitions can be fetched by the   * ObjectStore.getNumPartitionsViaOrmFilter method.    */
Hive,WITHOUT_CLASSIFICATION,// This means hive type doesn't refer this field that comes from file schema.  i.e. the field is not required for hive table. It can occur due to schema  evolution where some field is deleted. 
Hive,WITHOUT_CLASSIFICATION,/*  code copied over from UDFWeekOfYear implementation  */
Hive,WITHOUT_CLASSIFICATION,//  We must parse to get the escape count. 
Hive,WITHOUT_CLASSIFICATION,//  need to make sure names are set for tez to connect things right 
Hive,WITHOUT_CLASSIFICATION,//  set data column count as 1. 
Hive,WITHOUT_CLASSIFICATION,//  None of the cases above matched and everything is selected. Hence we will use the   same values for the selected and selectedInUse. 
Hive,WITHOUT_CLASSIFICATION,//  write ids 
Hive,WITHOUT_CLASSIFICATION,//  unfortunately the metastore api revokes all privileges that match on   principal privilege object type it does not filter on the grator   username.   So this will revoke privileges that are granted by other users.This is   not SQL compliant behavior. Need to change/add a metastore api   that has desired behavior. 
Hive,WITHOUT_CLASSIFICATION,// ~ Methods ---------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  Now make sure that we can re-use the re-encoder against a completely   different record to save resources 
Hive,WITHOUT_CLASSIFICATION,//  All others 
Hive,WITHOUT_CLASSIFICATION,//  target exists 
Hive,WITHOUT_CLASSIFICATION,//  assign values in vector 
Hive,WITHOUT_CLASSIFICATION,//  session creation should fail since the schema didn't get created 
Hive,WITHOUT_CLASSIFICATION,//  Likely a malformed query eg select hash(distinct c1) from t1; 
Hive,WITHOUT_CLASSIFICATION,//  Reject default partitions if we couldn't determine whether we should include it or not.   Note that predicate would only contains partition column parts of original predicate. 
Hive,WITHOUT_CLASSIFICATION,//  always should be in this order (see PTFDeserializer#initializeWindowing) 
Hive,WITHOUT_CLASSIFICATION,//  ensure if destination is not empty only for regular import 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hadoop.io.Writable#readFields(java.io.DataInput)    */
Hive,WITHOUT_CLASSIFICATION,/*  Is any operator present which prevents the conversion  */
Hive,WITHOUT_CLASSIFICATION,//  db exists 
Hive,WITHOUT_CLASSIFICATION,//  Logger the lineage info 
Hive,WITHOUT_CLASSIFICATION,//  Two known tasks left. r2 and r5. (r1 complete r3 evicted r4 rejected) 
Hive,WITHOUT_CLASSIFICATION,//  final vertices need to have at least one output 
Hive,WITHOUT_CLASSIFICATION,//  the qualified table aliases etc. 
Hive,WITHOUT_CLASSIFICATION,//  Add implicit type conversion if necessary 
Hive,WITHOUT_CLASSIFICATION,//  remove the entries so we don't get confused later and think we should 
Hive,WITHOUT_CLASSIFICATION,// TODO: No Of buckets is not same as no of splits 
Hive,WITHOUT_CLASSIFICATION,//  save logging message for log4j output latter after log4j initialize properly 
Hive,WITHOUT_CLASSIFICATION,//  rowId >= 'h' 
Hive,WITHOUT_CLASSIFICATION,//  Format <txnId>$<table_name>:<hwm>:<minOpenWriteId>:<open_writeids>:<abort_writeids>$<table_name>... 
Hive,WITHOUT_CLASSIFICATION,//  STARTED 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setClob(int java.sql.Clob)    */
Hive,WITHOUT_CLASSIFICATION,//  DROP TABLE [IF EXISTS] table_name; 
Hive,WITHOUT_CLASSIFICATION,//  For grouping sets add a dummy grouping key   This dummy key needs to be added as a reduce key   For eg: consider: select key value count(1) from T group by key value with rollup.   Assuming map-side aggregation and no skew the plan would look like:     TableScan --> Select --> GroupBy1 --> ReduceSink --> GroupBy2 --> Select --> FileSink     This function is called for GroupBy1 to create an additional grouping key 
Hive,WITHOUT_CLASSIFICATION,//  Note: the first and last element of the byte[] are NOT used 
Hive,WITHOUT_CLASSIFICATION,// now actually write to table to generate some partitions 
Hive,WITHOUT_CLASSIFICATION,//  compare data header with signature 
Hive,WITHOUT_CLASSIFICATION,//  join(left join.getRight) 
Hive,WITHOUT_CLASSIFICATION,//  Might be from before the new resource plan. 
Hive,WITHOUT_CLASSIFICATION,//  optional bytes vertexBinary = 2; 
Hive,WITHOUT_CLASSIFICATION,//  STAGE_TYPE 
Hive,WITHOUT_CLASSIFICATION,//  Either a non-MM query or a load into MM table from an external source. 
Hive,WITHOUT_CLASSIFICATION,//  Retrieve job conf into logDir 
Hive,WITHOUT_CLASSIFICATION,//  insertIntoTables/insertOverwriteTables map a table's fullName to its ast; 
Hive,WITHOUT_CLASSIFICATION,//  synthetic conditions there. 
Hive,WITHOUT_CLASSIFICATION,//  TYPES 
Hive,WITHOUT_CLASSIFICATION,//  [-trace|--trace] 
Hive,WITHOUT_CLASSIFICATION,//  swap x and t2[h2(x)] 
Hive,WITHOUT_CLASSIFICATION,//  T | F | F 
Hive,WITHOUT_CLASSIFICATION,//  next byte is a null byte if there are more bytes to go 
Hive,WITHOUT_CLASSIFICATION,//  When there is no explicit foreign key name associated with the constraint and the key is composite   we expect the foreign keys to be send in order in the input list.   Otherwise the below code will break.   If this is the first column of the FK constraint generate the foreign key name   NB: The below code can result in race condition where duplicate names can be generated (in theory).   However this scenario can be ignored for practical purposes because of   the uniqueness of the generated constraint name. 
Hive,WITHOUT_CLASSIFICATION,//  a skew key now. 
Hive,WITHOUT_CLASSIFICATION,//  Last row starting at the end of the split would be read. 
Hive,WITHOUT_CLASSIFICATION,//  disable memory checking 
Hive,WITHOUT_CLASSIFICATION,// check if the rest command specified explicitly to use hcatalog 
Hive,WITHOUT_CLASSIFICATION,// these must be after non-partition cols 
Hive,WITHOUT_CLASSIFICATION,/*    * Connects using the command line arguments. There are two   * possible ways to connect here 1. using the cmd line arguments like -u   * or using !properties <property-file>    */
Hive,WITHOUT_CLASSIFICATION,//  Restore everything to default setup to avoid discrepancy between junit test runs 
Hive,WITHOUT_CLASSIFICATION,//  If numAttr is 1 this means we join on one single key column. 
Hive,WITHOUT_CLASSIFICATION,//  allocate memory for the histogram bins 
Hive,WITHOUT_CLASSIFICATION,//  Add an empty checksum string for filesystems that don't generate one 
Hive,WITHOUT_CLASSIFICATION,//  Remove cyclic dependencies for DPP 
Hive,WITHOUT_CLASSIFICATION,//  there is no distinct aggregation   update all aggregations 
Hive,WITHOUT_CLASSIFICATION,//  we have created an HBase table so we delete it to roll back; 
Hive,WITHOUT_CLASSIFICATION,//  Locked for defrag 
Hive,WITHOUT_CLASSIFICATION,//  Put each check in a separate try/catch so if that particular   cycle fails it'll try again on the next cycle. 
Hive,WITHOUT_CLASSIFICATION,//  Create two input paths so that two map tasks get triggered. There could be other ways   to trigger two map tasks. 
Hive,WITHOUT_CLASSIFICATION,//  We'll count misses as we iterate 
Hive,WITHOUT_CLASSIFICATION,//  IS_TRANSACTIONAL 
Hive,WITHOUT_CLASSIFICATION,//  SW.SR.wait Lock we are examining is waiting.  In this case we keep   looking as it's possible that something in front is blocking it or 
Hive,WITHOUT_CLASSIFICATION,//  Can't do remainder on NULL. 
Hive,WITHOUT_CLASSIFICATION,//  build the routing table. 
Hive,WITHOUT_CLASSIFICATION,//  Therefore the maximum total size of a serialized timestamp is 4 + 5 + 4 = 13. 
Hive,WITHOUT_CLASSIFICATION,//  avoid intial spike when using multiple HS2 
Hive,WITHOUT_CLASSIFICATION,//  we only need to calculate it once it'll be the same for other partitions in this job. 
Hive,WITHOUT_CLASSIFICATION,/*        * checkif current row belongs to the current accumulated Partition:       * - If not:       *  - process the current Partition       *  - reset input Partition       * - set currentKey to the newKey if it is null or has changed.        */
Hive,WITHOUT_CLASSIFICATION,//  We don't expect any nesting in most cases or a lot of it if it is present; union and LB   are some examples where we would have 1 or few levels respectively. 
Hive,WITHOUT_CLASSIFICATION,//  The value is before the list record offset.  Make byte segment reference absolute. 
Hive,WITHOUT_CLASSIFICATION,//  BI strategy requested through config 
Hive,WITHOUT_CLASSIFICATION,//  If the id is a generated unique ID then this could affect .q file golden files for tests that run EXPLAIN queries. 
Hive,WITHOUT_CLASSIFICATION,// if here then there are no Open txns and  highestAllocatedTxnId must be  resolved (i.e. committed or aborted) either way  there are no open txns with id <= highestAllocatedTxnId  the +1 is there because "delete ..." below has < (which is correct for the case when  there is an open txn  Concurrency: even if new txn starts (or starts + commits) it is still true that  there are no currently open txns that overlap with any committed txn with   commitId <= commitHighWaterMark (as set on next line).  So plain READ_COMMITTED is enough. 
Hive,WITHOUT_CLASSIFICATION,//  Optimizer 
Hive,WITHOUT_CLASSIFICATION,//  sources represent vertex names 
Hive,WITHOUT_CLASSIFICATION,//  hadoop group mapping that maps user to same group 
Hive,WITHOUT_CLASSIFICATION,//  corresponding with bucket number and hence their OIs 
Hive,WITHOUT_CLASSIFICATION,/*          * for CBO provided orderings don't attempt to reorder joins.         * only convert consecutive joins into n-way joins.          */
Hive,WITHOUT_CLASSIFICATION,//  inbuilt assumption that the testdir has only one output file. 
Hive,WITHOUT_CLASSIFICATION,//  increment/set input counters 
Hive,WITHOUT_CLASSIFICATION,//  Create placeholder entry with PENDING state. 
Hive,WITHOUT_CLASSIFICATION,//  used by PTFs 
Hive,WITHOUT_CLASSIFICATION,// -p with the next argument being for BeeLineOpts 
Hive,WITHOUT_CLASSIFICATION,//  max threshold for CNF conversion. having >8 elements in andList will be   converted to maybe 
Hive,WITHOUT_CLASSIFICATION,//  call-5: open(mock:/mocktable8/delta_0000001_0000001_0000/bucket_00001) 
Hive,WITHOUT_CLASSIFICATION,//  3: 
Hive,WITHOUT_CLASSIFICATION,//  rule and passes the context along 
Hive,WITHOUT_CLASSIFICATION,//  The mapping from a newTag to the index of the corresponding child 
Hive,WITHOUT_CLASSIFICATION,//  First actually give it a duck. 
Hive,WITHOUT_CLASSIFICATION,//  print name 
Hive,WITHOUT_CLASSIFICATION,// checking for delete_delta is only so that this functionality can be exercised by code 3.0  which cannot produce any deltas with mix of update/insert events 
Hive,WITHOUT_CLASSIFICATION,//  Generate the result for the windowing ending at the current row 
Hive,WITHOUT_CLASSIFICATION,//  Pick trust store config from the given path 
Hive,WITHOUT_CLASSIFICATION,//  for updates first column is _rowid 
Hive,WITHOUT_CLASSIFICATION,//  for STRUCTS(multiple-add-calls) and LISTS(single-add-call) 
Hive,WITHOUT_CLASSIFICATION,//  Add NOT NULL constraint check 
Hive,WITHOUT_CLASSIFICATION,//  trim off ending "" if any 
Hive,WITHOUT_CLASSIFICATION,//  call-1: listLocatedStatus - mock:/mocktbl   call-2: check existence of side file for mock:/mocktbl/0_0 
Hive,WITHOUT_CLASSIFICATION,//  there could be more scheme after execution as execution might be accessing a   different filesystem. So if we don't find a matching scheme before execution we   just use the after execution values directly without computing delta difference 
Hive,WITHOUT_CLASSIFICATION,//  Http mode 
Hive,WITHOUT_CLASSIFICATION,//  Currently the algorithm flushes 10% of the entries - this can be   changed in the future 
Hive,WITHOUT_CLASSIFICATION,//  Avro only allows maps with string keys 
Hive,WITHOUT_CLASSIFICATION,//  We support both List<Object> and Object[]   so we have to do differently. 
Hive,WITHOUT_CLASSIFICATION,//  need a map from the reducer to the corresponding ReduceWork 
Hive,WITHOUT_CLASSIFICATION,//  Data prematurely ended. Return start - 1 so we don't move our field position. 
Hive,WITHOUT_CLASSIFICATION,//  looks like a db operation 
Hive,WITHOUT_CLASSIFICATION,//  after decoding we can push to value. 
Hive,WITHOUT_CLASSIFICATION,/*            * Do the {vector|row} deserialization of the one row into the VectorizedRowBatch.            */
Hive,WITHOUT_CLASSIFICATION,//  Add dummy instances to all slots where LLAPs are MIA... I can haz insert_iterator?  
Hive,WITHOUT_CLASSIFICATION,/*    * Update aggregations. If the aggregation is for distinct in case of hash   * aggregation the client tells us whether it is a new entry. For sort-based   * aggregations the last row is compared with the current one to figure out   * whether it has changed. As a cleanup the lastInvoke logic can be pushed in   * the caller and this function can be independent of that. The client should   * always notify whether it is a different row or not.   *   * @param aggs the aggregations to be evaluated   *   * @param row the row being processed   *   * @param rowInspector the inspector for the row   *   * @param hashAggr whether hash aggregation is being performed or not   *   * @param newEntryForHashAggr only valid if it is a hash aggregation whether   * it is a new entry or not    */
Hive,WITHOUT_CLASSIFICATION,//  convert the first methodParameterTypes.length - 1 entries 
Hive,WITHOUT_CLASSIFICATION,//  Some rows have already been assigned values. Assign the remaining.   We cannot use copySelected method here. 
Hive,WITHOUT_CLASSIFICATION,//  SCHEMA_TYPE 
Hive,WITHOUT_CLASSIFICATION,//  setup appropriate UGI for the session 
Hive,WITHOUT_CLASSIFICATION,//  delegate to the group's converters 
Hive,WITHOUT_CLASSIFICATION,//  http://dev.mysql.com/doc/refman/5.1/en/string-functions.html#function_locate 
Hive,WITHOUT_CLASSIFICATION,//  this = this.mag / 10**this.scale   right = right.mag / 10**right.scale   this / right = (this.mag / right.mag) / 10**(this.scale -   right.scale) 
Hive,WITHOUT_CLASSIFICATION,// all other ops using S4U on TXNS row. 
Hive,WITHOUT_CLASSIFICATION,//  The following data should be changed other data should be the same 
Hive,WITHOUT_CLASSIFICATION,//  numeric primitive type. 
Hive,WITHOUT_CLASSIFICATION,//  this.isOuterJoin = isOuterJoin;   PrimitiveTypeInfo[] primitiveTypeInfos = { TypeInfoFactory.stringTypeInfo };   keyBinarySortableDeserializeRead = new BinarySortableDeserializeRead(primitiveTypeInfos);   readStringResults = keyBinarySortableDeserializeRead.createReadStringResults();   bytesWritable = new BytesWritable(); 
Hive,WITHOUT_CLASSIFICATION,/*     The number of writers seems to be based on number of MR jobs for the src query.  todo check number of FileSinks    warehouse/t/.hive-staging_hive_2017-09-13_08-59-28_141_6304543600372946004-1/-ext-10000/000000_0/delta_0000001_0000001_0000/bucket_00000 [length: 648]    {"operation":0"originalTransaction":1"bucket":536870912"rowId":0"currentTransaction":1"row":{"_col0":1"_col1":2}}    {"operation":0"originalTransaction":1"bucket":536870912"rowId":1"currentTransaction":1"row":{"_col0":2"_col1":4}}    ________________________________________________________________________________________________________________________    warehouse/t/.hive-staging_hive_2017-09-13_08-59-28_141_6304543600372946004-1/-ext-10000/000001_0/delta_0000001_0000001_0000/bucket_00001 [length: 658]    {"operation":0"originalTransaction":1"bucket":536936448"rowId":0"currentTransaction":1"row":{"_col0":5"_col1":6}}    {"operation":0"originalTransaction":1"bucket":536936448"rowId":1"currentTransaction":1"row":{"_col0":6"_col1":8}}    {"operation":0"originalTransaction":1"bucket":536936448"rowId":2"currentTransaction":1"row":{"_col0":9"_col1":10}}     */
Hive,WITHOUT_CLASSIFICATION,//  [A: 1 B: 0 B.x: 0 B.y: 0 C: 0] 
Hive,WITHOUT_CLASSIFICATION,/*        * Last group batch.       *       * Take the (non-streaming) group aggregation values and write output columns for all       * rows of every batch of the group.  As each group batch is finished being written they are       * forwarded to the next operator.        */
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:IOSpecProto) 
Hive,WITHOUT_CLASSIFICATION,//  Implementation of List<Object> and assorted methods 
Hive,WITHOUT_CLASSIFICATION,// falling back 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise sleep and try again. 
Hive,WITHOUT_CLASSIFICATION,/*    * do nothing.    */
Hive,WITHOUT_CLASSIFICATION,//  second of three was selected 
Hive,WITHOUT_CLASSIFICATION,//  Not using method column.getIsVirtualCol() because partitioning columns   are also treated as virtual columns in ColumnInfo. 
Hive,WITHOUT_CLASSIFICATION,// show throw 
Hive,WITHOUT_CLASSIFICATION,// if here do the slow path so that we can return info txns which were not in expected state 
Hive,WITHOUT_CLASSIFICATION,//  Print out the sizes if pretty is set print it out in a human friendly format   otherwise print it out as if it were a row 
Hive,WITHOUT_CLASSIFICATION,//  Set up col expressions for the dynamic values using this input 
Hive,WITHOUT_CLASSIFICATION,//   Cached values to save on round trips to database. 
Hive,WITHOUT_CLASSIFICATION,//  of Ranges implies that there are no possible Ranges to lookup. 
Hive,WITHOUT_CLASSIFICATION,// ************************************************************************************************   Decimal Comparison. 
Hive,WITHOUT_CLASSIFICATION,//  append additional virtual columns for storing statistics 
Hive,WITHOUT_CLASSIFICATION,//  When an AND has no children (some conjunction over a field that isn't the column   mapped to the Accumulo rowid) and when a conjunction generates Ranges which are empty   (the children of the conjunction are disjoint) these two cases need to be kept separate.     A null `andRanges` implies that ranges couldn't be computed while an empty List 
Hive,WITHOUT_CLASSIFICATION,//  Make the following condition: all the values match for all the columns 
Hive,WITHOUT_CLASSIFICATION,//  We only initialize once the tasks that need to be run periodically 
Hive,WITHOUT_CLASSIFICATION,//  Testing setting length larger than array length which should cap to the length itself 
Hive,WITHOUT_CLASSIFICATION,//  If newBucketColList had a null value it means that at least one of the input bucket   columns did not have a representative found in the output columns so assume the data   is no longer bucketed 
Hive,WITHOUT_CLASSIFICATION,//  tableNamePattern String columnNamePattern) 
Hive,WITHOUT_CLASSIFICATION,//  The original lists do not contain collisions so only one is 'old'. 
Hive,WITHOUT_CLASSIFICATION,//  Prepare data.  Good for ANY implementation variation. 
Hive,WITHOUT_CLASSIFICATION,//  remove the partition paths we know about 
Hive,WITHOUT_CLASSIFICATION,/*    * This method gets called multiple times by Hive. On some invocations the properties will be empty.   * We need to detect when the properties are not empty to initialise the class variables.   *   * @see org.apache.hadoop.hive.serde2.Deserializer#initialize(org.apache.hadoop.conf.Configuration java.util.Properties)    */
Hive,WITHOUT_CLASSIFICATION,// empty strings are marked by an invalid utf single byte sequence. A valid utf stream cannot 
Hive,WITHOUT_CLASSIFICATION,//  if this is a skew key we need to handle it in a separate map reduce job. 
Hive,WITHOUT_CLASSIFICATION,//  add the merge job 
Hive,WITHOUT_CLASSIFICATION,// should not happen here - this is for replication 
Hive,WITHOUT_CLASSIFICATION,//  We are going to do something useful now. 
Hive,WITHOUT_CLASSIFICATION,//  Create one dummy lock so we can go through the loop below though we only  really need txnId 
Hive,WITHOUT_CLASSIFICATION,//  Test string column to VARCHAR literal comparison 
Hive,WITHOUT_CLASSIFICATION,//  used to log memory usage periodically 
Hive,WITHOUT_CLASSIFICATION,//  get the size of cache BEFORE 
Hive,WITHOUT_CLASSIFICATION,//  rebuild the tree since original is empty 
Hive,WITHOUT_CLASSIFICATION,//  Get the groupby aliases - these are aliased to the entries in the   select list 
Hive,WITHOUT_CLASSIFICATION,//  We assume that since we are joining on the same key all tables would have either   optimized or non-optimized key; hence we can pass any key in any table as reference.   We do it so that MJKB could determine whether it can use optimized keys. 
Hive,WITHOUT_CLASSIFICATION,//  Small table indices has more information (i.e. keys) than retain so use it if it exists... 
Hive,WITHOUT_CLASSIFICATION,//  Set up test data 
Hive,WITHOUT_CLASSIFICATION,//  compute deltas and write the values as varints 
Hive,WITHOUT_CLASSIFICATION,//  change in future. 
Hive,WITHOUT_CLASSIFICATION,//  invalid load path 
Hive,WITHOUT_CLASSIFICATION,//  Used to queue up requests while the SparkContext is being created. 
Hive,WITHOUT_CLASSIFICATION,//  2nd task requested host2 got host3 as host2 is full 
Hive,WITHOUT_CLASSIFICATION,/*            * Multi-Key get key.            */
Hive,WITHOUT_CLASSIFICATION,//  Don't do this optimization with updates or deletes 
Hive,WITHOUT_CLASSIFICATION,//  optional   required   optional 
Hive,WITHOUT_CLASSIFICATION,//  SessionState/Driver needs to be restarted with the Tez conf settings. 
Hive,WITHOUT_CLASSIFICATION,//  Set temp file containing results to be sent to HiveClient 
Hive,WITHOUT_CLASSIFICATION,//  Ignore updates that occured before this cached query was created. 
Hive,WITHOUT_CLASSIFICATION,//  used to determine whether child tasks can be run. 
Hive,WITHOUT_CLASSIFICATION,//  Making sure we treat dynamic partitioning jobs as if they were immutable. 
Hive,WITHOUT_CLASSIFICATION,//  MY_STRING 
Hive,WITHOUT_CLASSIFICATION,//  each element in the array: startPosition[i+1] - startPosition[i] - 1 
Hive,WITHOUT_CLASSIFICATION,//  Remove the reduceSinkOperator. 
Hive,WITHOUT_CLASSIFICATION,//  I32_VAL 
Hive,WITHOUT_CLASSIFICATION,//  Java cruft; pair of long. 
Hive,WITHOUT_CLASSIFICATION,//  For alter table exchange partition we need select & delete on input & insert on output 
Hive,WITHOUT_CLASSIFICATION,//  Traverse through the from string one code point at a time 
Hive,WITHOUT_CLASSIFICATION,//  This record produced a result this time remove it from the storage   as it will not need to produce a result with NULL values anymore 
Hive,WITHOUT_CLASSIFICATION,//  Reduce Sink contains the columns needed - no need to aggregate from   children 
Hive,WITHOUT_CLASSIFICATION,//  setup the new map work 
Hive,WITHOUT_CLASSIFICATION,//  start to generate multiple map join tasks 
Hive,WITHOUT_CLASSIFICATION,//  Connect parent/child work with a brodacast edge. 
Hive,WITHOUT_CLASSIFICATION,//  [A: 1 B: 1] 
Hive,WITHOUT_CLASSIFICATION,//  Create and attach the filesink for the merge. 
Hive,WITHOUT_CLASSIFICATION,// correlated vars across subqueries within same query needs to have different ID 
Hive,WITHOUT_CLASSIFICATION,//  columns which are bucketed/sorted 
Hive,WITHOUT_CLASSIFICATION,//  If we are left with a single child return the child 
Hive,WITHOUT_CLASSIFICATION,//  The array index can't be reserved. 
Hive,WITHOUT_CLASSIFICATION,//  Sending a kill message to the AM right here. Don't need to wait for the task to complete. 
Hive,WITHOUT_CLASSIFICATION,//  KILL always takes priority over MOVE 
Hive,WITHOUT_CLASSIFICATION,//  Remove cast of BOOLEAN NOT NULL to BOOLEAN or vice versa. Filter accepts   nullable and not-nullable conditions but a CAST might get in the way of   other rewrites. 
Hive,WITHOUT_CLASSIFICATION,// above get() doesn't set it 
Hive,WITHOUT_CLASSIFICATION,//  Perform SPNEGO login using the hadoop shim API if the configuration is available 
Hive,WITHOUT_CLASSIFICATION,//  Uninitialized vertices will report count as 0. 
Hive,WITHOUT_CLASSIFICATION,//  We do not need to do anything it is in the OR expression   so probably we pushed previously 
Hive,WITHOUT_CLASSIFICATION,//  n-way join all later small tables   For all later small tables follow the same pattern of the previously loaded tables. 
Hive,WITHOUT_CLASSIFICATION,/*  3-replica ssd  */
Hive,WITHOUT_CLASSIFICATION,// validate noscan 
Hive,WITHOUT_CLASSIFICATION,//  By setting the comparison to equal the search should use the block [0 50] 
Hive,WITHOUT_CLASSIFICATION,//  Grab round digit from lowest word. 
Hive,WITHOUT_CLASSIFICATION,//  [A: 1 B: 2] 
Hive,WITHOUT_CLASSIFICATION,//  adding 16KB constant memory for stringCommon as the rabit hole is deep to implement   MemoryEstimate interface also it is constant overhead 
Hive,WITHOUT_CLASSIFICATION,//  Enable retries to work around BONECP bug. 
Hive,WITHOUT_CLASSIFICATION,//  if this record is larger than maxKey we need to stop 
Hive,WITHOUT_CLASSIFICATION,//  EventConsumer to invalidate cache entries based on metastore notification events (alter table add partition etc). 
Hive,WITHOUT_CLASSIFICATION,//  "cause" was a useless intermediate cause and was replace it   with its own cause. 
Hive,WITHOUT_CLASSIFICATION,//  convert to lazy object 
Hive,WITHOUT_CLASSIFICATION,//  The table is missing either due to drop/rename which follows the operation. 
Hive,WITHOUT_CLASSIFICATION,//  Compare as strings. Char comparison semantics may be different if/when implemented. 
Hive,WITHOUT_CLASSIFICATION,//  A simple thread to wait until the server has started and then signal the other threads to   begin 
Hive,WITHOUT_CLASSIFICATION,//  last resort 
Hive,WITHOUT_CLASSIFICATION,// bail out can not infer unit 
Hive,WITHOUT_CLASSIFICATION,//  If the table is partitioned we need to select the partition columns as well. 
Hive,WITHOUT_CLASSIFICATION,// 5. get the first SEL after TS 
Hive,WITHOUT_CLASSIFICATION,//  Mark the write ids state as per the txn state. 
Hive,WITHOUT_CLASSIFICATION,//  if value is null or not found exception would get thrown 
Hive,WITHOUT_CLASSIFICATION,//  Audience can't exist on its own 
Hive,WITHOUT_CLASSIFICATION,//  Reopen happens even when close fails so there's not much to do here. 
Hive,WITHOUT_CLASSIFICATION,//  Add any required resources 
Hive,WITHOUT_CLASSIFICATION,// I don't think this can have any FileSinkOperatorS - more future proofing 
Hive,WITHOUT_CLASSIFICATION,//  remember the connections between ts and event 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#wasNull()    */
Hive,WITHOUT_CLASSIFICATION,//  draw 1 and replace 
Hive,WITHOUT_CLASSIFICATION,//  10^32 
Hive,WITHOUT_CLASSIFICATION,//  Need to preserve currentTimestamp 
Hive,WITHOUT_CLASSIFICATION,//  For kafka Streaming tables it is mandatory to set a kafka topic. 
Hive,WITHOUT_CLASSIFICATION,//  setString can override this null propagation 
Hive,WITHOUT_CLASSIFICATION,//  Check if the default values are set for all unfilled attributes 
Hive,WITHOUT_CLASSIFICATION,//  for each struct subfield create equivalent ResourceFieldSchema 
Hive,WITHOUT_CLASSIFICATION,//  For MM tables directory structure is   <table-dir>/<partition-dir>/<delta-dir>/ 
Hive,WITHOUT_CLASSIFICATION,//  get sum for all columns to reduce the number of queries 
Hive,WITHOUT_CLASSIFICATION,//  If we have a conflict on the number of reducers we will not optimize   this plan from here. 
Hive,WITHOUT_CLASSIFICATION,//  Checking for status of a db 
Hive,WITHOUT_CLASSIFICATION,/*  Prepare the constant for use when the function is called. To be used   * during initialization.    */
Hive,WITHOUT_CLASSIFICATION,//  there is no overlap between columns and partitioning columns 
Hive,WITHOUT_CLASSIFICATION,//  Ensure Pig can read data correctly. 
Hive,WITHOUT_CLASSIFICATION,// make it an Acid table and make sure we assign ROW__IDs correctly 
Hive,WITHOUT_CLASSIFICATION,//  convert all of the children to CNF 
Hive,WITHOUT_CLASSIFICATION,//  If it is a MapJoin or MergeJoin we make sure that they are on   the reduce side otherwise we bail out 
Hive,WITHOUT_CLASSIFICATION,//  There should already be an instance of the session pool manager.   If not ignoring is fine while stopping HiveServer2. 
Hive,WITHOUT_CLASSIFICATION,//  this operator cannot be converted to mapjoin cause output is expected to be sorted on join key 
Hive,WITHOUT_CLASSIFICATION,/*  there are NULLs in our column  */
Hive,WITHOUT_CLASSIFICATION,/*      * The Vectorizer class enforces that there is only one TableScanOperator so     * we don't need the more complicated multiple root operator mapping that MapOperator has.      */
Hive,WITHOUT_CLASSIFICATION,//  This code is pretty much completely based on Hadoop's   SaslRpcServer.SaslDigestCallbackHandler - the only reason we could not   use that Hadoop class as-is was because it needs a Server.Connection object   which is relevant in hadoop rpc but not here in the metastore - so the 
Hive,WITHOUT_CLASSIFICATION,//  After this the non-initial refcounts are the responsibility of the consumer. 
Hive,WITHOUT_CLASSIFICATION,//  Unpack the output. 
Hive,WITHOUT_CLASSIFICATION,//  setting empty list results in reading none 
Hive,WITHOUT_CLASSIFICATION,//  INT_VALUE 
Hive,WITHOUT_CLASSIFICATION,//  We compress the owids into CompressedOwid data structure that records 
Hive,WITHOUT_CLASSIFICATION,// if here someone must have added new Work object - should it be walked to find FileSinks? 
Hive,WITHOUT_CLASSIFICATION,//  let the schema and version be auto created 
Hive,WITHOUT_CLASSIFICATION,//  all column types 
Hive,WITHOUT_CLASSIFICATION,//  10^31 
Hive,WITHOUT_CLASSIFICATION,//  Check the list of where expressions already added so they aren't duplicated 
Hive,WITHOUT_CLASSIFICATION,//  4/ test serialization and deserialization with different schemas 
Hive,WITHOUT_CLASSIFICATION,//  Only preempt if the task being preempted is "below" us in the dag. 
Hive,WITHOUT_CLASSIFICATION,//  require view ownership for alter/drop view 
Hive,WITHOUT_CLASSIFICATION,//  create map join task for the given big table position 
Hive,WITHOUT_CLASSIFICATION,//  in this case the result will be surely more than 128 bit even   after division 
Hive,WITHOUT_CLASSIFICATION,//  end of loop over pending tasks 
Hive,WITHOUT_CLASSIFICATION,//  get the output schema 
Hive,WITHOUT_CLASSIFICATION,//  we have to check if we receive prefix of partition keys so in table   scheme like table/ds=2011-01-02/hr=13/   ARCHIVE PARTITION (ds='2011-01-02') will work and   ARCHIVE PARTITION(hr='13') won't 
Hive,WITHOUT_CLASSIFICATION,//  parameters == null means the input table/split is empty 
Hive,WITHOUT_CLASSIFICATION,//  Wait for up to 3 seconds before checking if any init error.   Init should be fast if no error no need to make this configurable. 
Hive,WITHOUT_CLASSIFICATION,//  extend any repeating values and noNulls indicator in the input 
Hive,WITHOUT_CLASSIFICATION,//  Matching result for attemptId + input. 
Hive,WITHOUT_CLASSIFICATION,//  URI 
Hive,WITHOUT_CLASSIFICATION,//  Test DROP DATABASE. 
Hive,WITHOUT_CLASSIFICATION,//  We SerDe the Throwable as String parse it for the root cause 
Hive,WITHOUT_CLASSIFICATION,//  Nope so look to see if our conf dir has been explicitly set 
Hive,WITHOUT_CLASSIFICATION,// invalid case 
Hive,WITHOUT_CLASSIFICATION,//  Serialize rest of the field in the AggBuffer 
Hive,WITHOUT_CLASSIFICATION,//  Total number of input rows is needed for hash aggregation only 
Hive,WITHOUT_CLASSIFICATION,//  This probably doesn't need to be sync but nobody calls this so it doesn't matter. 
Hive,WITHOUT_CLASSIFICATION,//  clone joinCond 
Hive,WITHOUT_CLASSIFICATION,//  Note we assume production LLAP always runs under YARN. 
Hive,WITHOUT_CLASSIFICATION,//  if the aggregation type is avg we use the average on the existing ones. 
Hive,WITHOUT_CLASSIFICATION,//  9. Get rid of sq_count_check if group by key is constant (HIVE-) 
Hive,WITHOUT_CLASSIFICATION,//  False positives probability we are ready to tolerate for the underlying bloom filter 
Hive,WITHOUT_CLASSIFICATION,//  replaces the join operator with a new CommonJoinOperator removes the 
Hive,WITHOUT_CLASSIFICATION,//  Ignore for now. HS2 will probably try to send us the count we already have again.   We are assuming here that if we can't talk to ZK we will eventually fail. 
Hive,WITHOUT_CLASSIFICATION,//  get the field out of struct 
Hive,WITHOUT_CLASSIFICATION,//  skip incompatible file files that are missing stripe statistics are set to incompatible 
Hive,WITHOUT_CLASSIFICATION,//  Current Cookie Name Current Cookie Value 
Hive,WITHOUT_CLASSIFICATION,//  Ignore agg calls which are not distinct or have the wrong set   arguments. If we're rewriting aggs whose args are {sal} we will   rewrite COUNT(DISTINCT sal) and SUM(DISTINCT sal) but ignore   COUNT(DISTINCT gender) or SUM(sal). 
Hive,WITHOUT_CLASSIFICATION,// skip the big tables 
Hive,WITHOUT_CLASSIFICATION,//  create partitions 
Hive,WITHOUT_CLASSIFICATION,//  2. Insert Overwrite. 
Hive,WITHOUT_CLASSIFICATION,// e.g. map z->expr for a 
Hive,WITHOUT_CLASSIFICATION,//  Allocate next NULL byte. 
Hive,WITHOUT_CLASSIFICATION,/*              * Common inner big-only join result processing.              */
Hive,WITHOUT_CLASSIFICATION,//  read sync bytes 
Hive,WITHOUT_CLASSIFICATION,//  Batch is full or using too much space. 
Hive,WITHOUT_CLASSIFICATION,//  Test will be in local mode. 
Hive,WITHOUT_CLASSIFICATION,//  Check for overflow 
Hive,WITHOUT_CLASSIFICATION,//  Hash table memory usage allowed; used in case of non-staged mapjoin. 
Hive,WITHOUT_CLASSIFICATION,//  Set up the foreign key constraints properly in the TAB_COL_STATS data 
Hive,WITHOUT_CLASSIFICATION,//  If current state is a final state notify of Spark job IDs before notifying about the   state transition. 
Hive,WITHOUT_CLASSIFICATION,/*  id in (3450)  */
Hive,WITHOUT_CLASSIFICATION,//  set the backup task from curr task 
Hive,WITHOUT_CLASSIFICATION,//  Get all the TS ops. 
Hive,WITHOUT_CLASSIFICATION,/*    * Truncate a slice of a byte array to a maximum number of characters and   * return the new byte length.    */
Hive,WITHOUT_CLASSIFICATION,//  7.convert Join + GBy to semijoin 
Hive,WITHOUT_CLASSIFICATION,// Because LLAP arrow output depends on the ThriftJDBCBinarySerDe code path  this is required for 0 row outputs  i.e. we need to write a 0 size batch to signal EOS to the consumer 
Hive,WITHOUT_CLASSIFICATION,//  1st close:   closing of open scope should be ok. 
Hive,WITHOUT_CLASSIFICATION,//  blocks of a particular size we'll try to split yet larger blocks until we run out. 
Hive,WITHOUT_CLASSIFICATION,//  Parse out the context and 'k' if we haven't already done so and while we're at it   also parse out the precision factor 'pf' if the user has supplied one. 
Hive,WITHOUT_CLASSIFICATION,//  Fill up host1 with p2 tasks.   Leave host2 empty   Try running p1 task on host1 - should preempt   Await preemption request.   Try running another p1 task on host1 - should preempt   Await preemption request. 
Hive,WITHOUT_CLASSIFICATION,//  for development can add   "decision=<<"+nvae.grammarDecisionDescription+">>"   and "(decision="+nvae.decisionNumber+") and   "state "+nvae.stateNumber 
Hive,WITHOUT_CLASSIFICATION,//  not a power of two add one more 
Hive,WITHOUT_CLASSIFICATION,//  The set object containing the IN list. This is optimized for lookup   of the data type of the column. 
Hive,WITHOUT_CLASSIFICATION,// numEntriesSinceCheck is the number of entries added to the hash table   since the last time we checked the average variable size 
Hive,WITHOUT_CLASSIFICATION,// this makes the jars available to Sqoop client 
Hive,WITHOUT_CLASSIFICATION,//  No checks the caller must ensure the offsets are correct. 
Hive,WITHOUT_CLASSIFICATION,//  The class name of the generic UDF being used by the filter 
Hive,WITHOUT_CLASSIFICATION,//  One child 
Hive,WITHOUT_CLASSIFICATION,//  Cleaner would remove the obsolete files. 
Hive,WITHOUT_CLASSIFICATION,// { "comment":"test" "columns": [ { "name": "col1" "type": "string" } ] "format": { "storedAs": "rcfile" } } 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) Header  */
Hive,WITHOUT_CLASSIFICATION,//  Given that we do not delete an empty slot means no match. 
Hive,WITHOUT_CLASSIFICATION,//  If stats are already present and forceRecompute isn't set nothing to do 
Hive,WITHOUT_CLASSIFICATION,/*    * @throws HCatException   *   * @see org.apache.hive.hcatalog.api.HCatClient#closeClient()    */
Hive,WITHOUT_CLASSIFICATION,//  If either argument is a string we convert to a double or decimal because a number   in string form should always be convertible into either of those 
Hive,WITHOUT_CLASSIFICATION,//  T | F | T 
Hive,WITHOUT_CLASSIFICATION,//  1st level GB: create a GB (col0 col1 count(1) as c) for each branch 
Hive,WITHOUT_CLASSIFICATION,//  check for max input size 
Hive,WITHOUT_CLASSIFICATION,// INSERT [OVERWRITE] path 
Hive,WITHOUT_CLASSIFICATION,// HIVE-17322: remove parallelism to check if the BeeLine test flakyness gets fixed  int numThreads = Runtime.getRuntime().availableProcessors(); 
Hive,WITHOUT_CLASSIFICATION,//  enable extended nesting levels 
Hive,WITHOUT_CLASSIFICATION,//  BIGINT 
Hive,WITHOUT_CLASSIFICATION,//  F | unknown | F 
Hive,WITHOUT_CLASSIFICATION,//  If there is a sort-merge join followed by a regular join the SMBJoinOperator may not   get initialized at all. Consider the following query:   A SMB B JOIN C 
Hive,WITHOUT_CLASSIFICATION,//  This means the DB name is empty 
Hive,WITHOUT_CLASSIFICATION,//  Ensure child size. 
Hive,WITHOUT_CLASSIFICATION,//  this is the constructor to use for the Bucket map join case. 
Hive,WITHOUT_CLASSIFICATION,//  Text string 
Hive,WITHOUT_CLASSIFICATION,//  We need to use the current cluster for the scan operator on views 
Hive,WITHOUT_CLASSIFICATION,//  tagToInput for reduce work 
Hive,WITHOUT_CLASSIFICATION,//  Merge the files in the destination table/partitions by creating Map-only merge job   If underlying data is RCFile or OrcFile RCFileBlockMerge task or   OrcFileStripeMerge task would be created. 
Hive,WITHOUT_CLASSIFICATION,//  4) Transform first INSERT branch into an UPDATE 
Hive,WITHOUT_CLASSIFICATION,//  nothing to do soft references will clean themselves up 
Hive,WITHOUT_CLASSIFICATION,//  set the output record by fiddling with the pointers so that we can 
Hive,WITHOUT_CLASSIFICATION,//  and finally we're ready to create and start the session 
Hive,WITHOUT_CLASSIFICATION,//  Check if the partitions don't exist in the sourceTable 
Hive,WITHOUT_CLASSIFICATION,//  Verify fields were altered during the alterTable operation 
Hive,WITHOUT_CLASSIFICATION,// In UpdateDeleteSemanticAnalyzer after super analyze   3 ReadEntity: [default@acidtblpart default@acidtblpart@p=p1 default@acidtblpart@p=p2]   1 WriteEntity: [default@acidtblpart TABLE/INSERT]  after UDSA   Read [default@acidtblpart default@acidtblpart@p=p1 default@acidtblpart@p=p2]   Write [default@acidtblpart@p=p1 default@acidtblpart@p=p2] - PARTITION/UPDATE PARTITION/UPDATE  todo: Why acquire per partition locks - if you have many partitions that's hugely inefficient. 
Hive,WITHOUT_CLASSIFICATION,//  Serialize keyRow into key bytes. 
Hive,WITHOUT_CLASSIFICATION,//  Read the fields. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getNCharacterStream(java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  need to enforce nullability by applying an additional   cast operator over the transformed expression. 
Hive,WITHOUT_CLASSIFICATION,//  cursor for the "inList" array.   cursor for an element list per an 'IN'/'NOT IN'-clause.   cursor for in-clause lists per a query. 
Hive,WITHOUT_CLASSIFICATION,//  If maps recursively compare the key and value types 
Hive,WITHOUT_CLASSIFICATION,//  decimal_1_1.txt 
Hive,WITHOUT_CLASSIFICATION,//  something is preventing metastore from starting 
Hive,WITHOUT_CLASSIFICATION,//  Test select named_struct from named_struct:struct<a:booleanb:double> 
Hive,WITHOUT_CLASSIFICATION,//  create partition key schema 
Hive,WITHOUT_CLASSIFICATION,//  list of map join 
Hive,WITHOUT_CLASSIFICATION,//  for a while 
Hive,WITHOUT_CLASSIFICATION,//  authorize drops if there was a drop privilege requirement 
Hive,WITHOUT_CLASSIFICATION,//  to set this multiple times. 
Hive,WITHOUT_CLASSIFICATION,//  Call the corresponding handler to evaluate this row and   forward the result 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hadoop.hive.ql.exec.tez.LlapPluginEndpointClient#sendUpdateQuery(org.apache.hadoop.hive.llap.plugin.rpc.LlapPluginProtocolProtos.UpdateQueryRequestProto java.lang.String int org.apache.hadoop.security.token.Token org.apache.hadoop.hive.llap.AsyncPbRpcProxy.ExecuteRequestCallback)    */
Hive,WITHOUT_CLASSIFICATION,//  current code version   data's version   data's FC version   No exceptions expected 
Hive,WITHOUT_CLASSIFICATION,//  the big table; 
Hive,WITHOUT_CLASSIFICATION,//  a map to keep track of what reduce sinks have to be hooked up to 
Hive,WITHOUT_CLASSIFICATION,//  If all child expressions of deterministic function are constants evaluate such UDF immediately 
Hive,WITHOUT_CLASSIFICATION,//  Must be deterministic order map - see HIVE-8707 
Hive,WITHOUT_CLASSIFICATION,//  Some part of the requested range is not cached - the cached offset is past the requested. 
Hive,WITHOUT_CLASSIFICATION,//  to decide whether to rewrite RR of subquery 
Hive,WITHOUT_CLASSIFICATION,//  Get own Kerberos credentials for accepting connection 
Hive,WITHOUT_CLASSIFICATION,//  True when the (random access) readField method of DeserializeRead are being used. 
Hive,WITHOUT_CLASSIFICATION,//  Next we do this for tables and partitions 
Hive,WITHOUT_CLASSIFICATION,//  If create view has LIMIT operator this can happen   Fetch parent operator 
Hive,WITHOUT_CLASSIFICATION,//  Throws InvalidOperationException if the new column types are not   compatible with the current column types. 
Hive,WITHOUT_CLASSIFICATION,//  In this case we have to find out which columns can be merged. 
Hive,WITHOUT_CLASSIFICATION,//  Mock inputs 
Hive,WITHOUT_CLASSIFICATION,//  Update the partitions for a table in cache 
Hive,WITHOUT_CLASSIFICATION,//  If partial is NULL then there was an overflow and myagg.sum will be marked as not set. 
Hive,WITHOUT_CLASSIFICATION,//  session already has a violation 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getObject(int)    */
Hive,WITHOUT_CLASSIFICATION,//  Might have been deleted already 
Hive,WITHOUT_CLASSIFICATION,//  This is FS only mode just initialize the dfs root directory. 
Hive,WITHOUT_CLASSIFICATION,//  Replicate all the events happened so far 
Hive,WITHOUT_CLASSIFICATION,//  Default case 
Hive,WITHOUT_CLASSIFICATION,//  Couldn't find the parent insert; replace with ALLCOLREF. 
Hive,WITHOUT_CLASSIFICATION,//  add to path set 
Hive,WITHOUT_CLASSIFICATION,//  test that underflow produces null 
Hive,WITHOUT_CLASSIFICATION,//  execution mode not set null is returned 
Hive,WITHOUT_CLASSIFICATION,//  timestamp column/scalar IF where scalar is really a CAST of a constant to timestamp. 
Hive,WITHOUT_CLASSIFICATION,//  begin + write + commit 
Hive,WITHOUT_CLASSIFICATION,//  Encountered a numeric value; Extract out the entire number 
Hive,WITHOUT_CLASSIFICATION,//  0. Recreate cluster 
Hive,WITHOUT_CLASSIFICATION,//  Only ">" predicate is supported right now this has to be extended to support   expression tree when multiple conditions are required. HIVE-17622 
Hive,WITHOUT_CLASSIFICATION,//  The mapping from a newTag to its corresponding oldTag.   oldTag is the tag assigned to ReduceSinkOperators BEFORE Correlation Optimizer   optimizes the operator tree. newTag is the tag assigned to ReduceSinkOperators   AFTER Correlation Optimizer optimizes the operator tree.   Example: we have an operator tree shown below ...          JOIN2         /     \     GBY1       JOIN1      |         /    \     RS1       RS2   RS3   If GBY1 JOIN1 and JOIN2 are executed in the same Reducer   (optimized by Correlation Optimizer) we will have ...   oldTag: RS1:0 RS2:0 RS3:1   newTag: RS1:0 RS2:1 RS3:2   We need to know the mapping from the newTag to oldTag and revert   the newTag to oldTag to make operators in the operator tree 
Hive,WITHOUT_CLASSIFICATION,//  we allow multiple foreign keys (snowflake schema)   csfKs.size() + 1 == parents.size() means we have a single PK and all 
Hive,WITHOUT_CLASSIFICATION,//  in the absence of column statistics the estimated number of rows/data size that will 
Hive,WITHOUT_CLASSIFICATION,//  populate pathToPartitionInfo and pathToAliases w/ DP paths 
Hive,WITHOUT_CLASSIFICATION,//  disruptor   log4j-api   log4j-core   log4j-slf4j   log4j-1.2-API needed for NDC 
Hive,WITHOUT_CLASSIFICATION,//  Ensure there's no more invocations. 
Hive,WITHOUT_CLASSIFICATION,//  Some version upgrades often don't change schema. So they are equivalent to   a version   that has a corresponding schema. eg "0.13.1" is equivalent to "0.13.0" 
Hive,WITHOUT_CLASSIFICATION,//  PRIVILEGE 
Hive,WITHOUT_CLASSIFICATION,//  The set routine enforces precision and scale. 
Hive,WITHOUT_CLASSIFICATION,//  test that setting read all resets column ids 
Hive,WITHOUT_CLASSIFICATION,//  add the expr to reduceKeys if it is not present 
Hive,WITHOUT_CLASSIFICATION,//  must be inside tx together with queries 
Hive,WITHOUT_CLASSIFICATION,//  still exist 
Hive,WITHOUT_CLASSIFICATION,//  set to ADMIN role if user belongs there. 
Hive,WITHOUT_CLASSIFICATION,/*    * Forwarding.    */
Hive,WITHOUT_CLASSIFICATION,//  The response will have one entry per table and hence we get only one OpenWriteIds 
Hive,WITHOUT_CLASSIFICATION,//  None of the expressions are constant. Nothing to do. 
Hive,WITHOUT_CLASSIFICATION,//  Create scratch dir without lock files 
Hive,WITHOUT_CLASSIFICATION,//  falling off and the executor service being ready to schedule a new task. 
Hive,WITHOUT_CLASSIFICATION,//  LlapIoImpl.LOG.info(prefix(ix) + " removing " + header(log[ix + 2]) + " from "     + getSecondInt(log[ix]) + " head " + log[ix + 3]); 
Hive,WITHOUT_CLASSIFICATION,// To change body of implemented methods use File | Settings | File Templates. 
Hive,WITHOUT_CLASSIFICATION,//  Already contains stats => stats not updated when forceRecompute isn't set 
Hive,WITHOUT_CLASSIFICATION,//  Just check name/type for equality don't compare comment 
Hive,WITHOUT_CLASSIFICATION,//  TOK_TABLE_PARTITION 
Hive,WITHOUT_CLASSIFICATION,//  Just loop through all values. We do not need to store anything though.   This is just for test purposes 
Hive,WITHOUT_CLASSIFICATION,//  stats from writer 
Hive,WITHOUT_CLASSIFICATION,//  Configuration for async thread pool in SessionManager 
Hive,WITHOUT_CLASSIFICATION,//  We successfully converted agg calls into projects. 
Hive,WITHOUT_CLASSIFICATION,//  We go by RG and not by column because that is how data is processed. 
Hive,WITHOUT_CLASSIFICATION,//  FileSystem.CACHE.map 
Hive,WITHOUT_CLASSIFICATION,//  If the same size. Sort on file name followed by startPosition. 
Hive,WITHOUT_CLASSIFICATION,//  If older committed state is equivalent to newer state then there should be no committed IDs   between oldHWM and newHWM and newInvalidIds should have exactly (newHWM - oldHWM) 
Hive,WITHOUT_CLASSIFICATION,//  Non-hash aggregation 
Hive,WITHOUT_CLASSIFICATION,//  then we return immediately. 
Hive,WITHOUT_CLASSIFICATION,// should not happen since the input were verified before passed in 
Hive,WITHOUT_CLASSIFICATION,// ----------------------------------------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  Created using hint skip it 
Hive,WITHOUT_CLASSIFICATION,//  It is not at all clear how to flatten these last two out in a useful way and no one uses 
Hive,WITHOUT_CLASSIFICATION,/*    * Allocate the various arrays.    */
Hive,WITHOUT_CLASSIFICATION,//  update max register value 
Hive,WITHOUT_CLASSIFICATION,//  The user has already been notified of completion by SessionInitContext. 
Hive,WITHOUT_CLASSIFICATION,//  drop view. ignore error. 
Hive,WITHOUT_CLASSIFICATION,//  Need to also push projections by calling setOutputSchema on   HCatInputFormat - we have to get the RequiredFields information   from the UdfContext translate it to an Schema and then pass it   The reason we do this here is because setLocation() is called by   Pig runtime at InputFormat.getSplits() and   InputFormat.createRecordReader() time - we are not sure when   HCatInputFormat needs to know about pruned projections - so doing it   here will ensure we communicate to HCatInputFormat about pruned   projections at getSplits() and createRecordReader() time 
Hive,WITHOUT_CLASSIFICATION,//  add metric with a non-null value: 
Hive,WITHOUT_CLASSIFICATION,//  Get all the failure execution hooks and execute them. 
Hive,WITHOUT_CLASSIFICATION,//  Note this is a "real" query that depends on one of the metastore tables 
Hive,WITHOUT_CLASSIFICATION,//  statistics not implemented currently 
Hive,WITHOUT_CLASSIFICATION,//  Binary mode 
Hive,WITHOUT_CLASSIFICATION,//  First entry. 
Hive,WITHOUT_CLASSIFICATION,/* at this point we have 2 delta files 1 for insert 1 for update      * we should push predicate into 1st one but not 2nd.  If the following 'select' were to      * push into the 'update' delta we'd filter out {35} before doing merge and thus     * produce {34} as the value for 2nd row.  The right result is 0-rows. */
Hive,WITHOUT_CLASSIFICATION,//  Remaining column expressions would be a candidate for an RS value 
Hive,WITHOUT_CLASSIFICATION,//  3) Sort columns 
Hive,WITHOUT_CLASSIFICATION,//  Only one of the tasks should ever be added to resTsks 
Hive,WITHOUT_CLASSIFICATION,//  Completion notifier vars 
Hive,WITHOUT_CLASSIFICATION,//  Now set the response headers. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure non-null-valued ConfVar properties *do* override the Hadoop Configuration 
Hive,WITHOUT_CLASSIFICATION,//  Used by kryo 
Hive,WITHOUT_CLASSIFICATION,//  Mark this entry as being in use. Caller will need to release later. 
Hive,WITHOUT_CLASSIFICATION,//  Requires conditional evaluation for good performance. 
Hive,WITHOUT_CLASSIFICATION,//  In case of LB we might get called repeatedly. 
Hive,WITHOUT_CLASSIFICATION,//  validate the second parameter which is the number of histogram bins 
Hive,WITHOUT_CLASSIFICATION,//  Test that write blocks two writes 
Hive,WITHOUT_CLASSIFICATION,//  Note: this assumes that the pattern where the same session object is reset with a different         Tez client is not used. It was used a lot in the past but appears to be gone from most         HS2 session pool paths and this patch removes the last one (reopen). 
Hive,WITHOUT_CLASSIFICATION,//  Assert class invariant. 
Hive,WITHOUT_CLASSIFICATION,//  Disable dictionary encoding for the writer. 
Hive,WITHOUT_CLASSIFICATION,//  Verify dirs 
Hive,WITHOUT_CLASSIFICATION,//  Why are we still using writables in 2017? 
Hive,WITHOUT_CLASSIFICATION,// some query attempted to lock (thus LOCK_WAITING state) but is giving up due to timeout for example 
Hive,WITHOUT_CLASSIFICATION,//  Current getInputSummary() returns -1 for each file found   Current getInputSummary() returns -1 for each file found 
Hive,WITHOUT_CLASSIFICATION,//  For testing only. 
Hive,WITHOUT_CLASSIFICATION,//  Some of the conversion methods throw this exception on numeric parsing errors. 
Hive,WITHOUT_CLASSIFICATION,//  Currently we only optimized the query the content of the FROM clause 
Hive,WITHOUT_CLASSIFICATION,//  After compaction/cleanup all entries from TXN_TO_WRITE_ID should be cleaned up as all txns are committed. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setObject(int java.lang.Object int)    */
Hive,WITHOUT_CLASSIFICATION,/*    * Parse a string as a query hint.    */
Hive,WITHOUT_CLASSIFICATION,/*  0 is false and 1 is true in the input vector so a simple dictionary is used     * with two entries. 0 references FALSE and 1 references TRUE in the dictionary.      */
Hive,WITHOUT_CLASSIFICATION,//  subtract out the bits we just added 
Hive,WITHOUT_CLASSIFICATION,//  The expected number of distinct values when choosing p values   with replacement from n integers is n . (1 - ((n - 1) / n) ^ p).     If we have several uniformly distributed attributes A1 ... Am   with N1 ... Nm distinct values they behave as one uniformly 
Hive,WITHOUT_CLASSIFICATION,/*      * We are "committing" this vertex to be vectorized.      */
Hive,WITHOUT_CLASSIFICATION,//  RUNAS 
Hive,WITHOUT_CLASSIFICATION,//  Setup a scratch batch that will be used to play back big table rows that were spilled 
Hive,WITHOUT_CLASSIFICATION,//  we have correlated column build data type from outer rr 
Hive,WITHOUT_CLASSIFICATION,//  LOG.info("Reading offset " + prevHeadOffset + " at " + lrPtrOffset); 
Hive,WITHOUT_CLASSIFICATION,//  We killed something. 
Hive,WITHOUT_CLASSIFICATION,//  We need to deserialize and serialize query so intervals are written in the JSON   Druid query with user timezone as this is default Hive time semantics. 
Hive,WITHOUT_CLASSIFICATION,//  Spot check only. null & repeating behavior are checked elsewhere for the same template. 
Hive,WITHOUT_CLASSIFICATION,//  Have to register this up front right now. Otherwise it's possible for the task to start 
Hive,WITHOUT_CLASSIFICATION,//  NumHashFunctions (1 byte) + NumBits (4 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  hdfs warehouse 
Hive,WITHOUT_CLASSIFICATION,//  We only get here if we could map all join keys to source table columns 
Hive,WITHOUT_CLASSIFICATION,// ---------------------------------------------------------------------------   Process Single-Column Long Inner Join on a vectorized row batch.   
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.PurgeCacheResponseProto.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,//  required for deserialization 
Hive,WITHOUT_CLASSIFICATION,//  Since we allow write operations on cache while prewarm is happening:   1. Don't add databases that were deleted while we were preparing list for prewarm   2. Skip overwriting exisiting db object   (which is present because it was added after prewarm started) 
Hive,WITHOUT_CLASSIFICATION,//  remove ending ';' and starting '@' 
Hive,WITHOUT_CLASSIFICATION,//  Change the query to use part_vals instead of the name which is 
Hive,WITHOUT_CLASSIFICATION,// If the DateFormat is not provided by the user or is invalid use the default format YYYY-MM-dd 
Hive,WITHOUT_CLASSIFICATION,//  Ignore the interrupt status while returning the session but set it back   on the thread in case anything else needs to deal with it. 
Hive,WITHOUT_CLASSIFICATION,/*    * Once we have decided on the map join the tree would transform from   *   *        |                   |   *       Join               MapJoin   *       / \                /   \   *     RS   RS   --->     RS    TS (big table)   *    /      \           /   *   TS       TS        TS (small table)   *   * for tez.    */
Hive,WITHOUT_CLASSIFICATION,// check that delta dir has a version file with expected value 
Hive,WITHOUT_CLASSIFICATION,//  defer 
Hive,WITHOUT_CLASSIFICATION,//  Pretend it's vectorized if the non-vector wrapped is enabled. 
Hive,WITHOUT_CLASSIFICATION,//  Thanks HBase Storage handler 
Hive,WITHOUT_CLASSIFICATION,//  TYPE2 
Hive,WITHOUT_CLASSIFICATION,//  for tables other than the big table we need to fetch more data until reach a new group or   done. 
Hive,WITHOUT_CLASSIFICATION,//  Start the heartbeat after a delay which exceeds the HIVE_TXN_TIMEOUT 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) TypeDefinition  */
Hive,WITHOUT_CLASSIFICATION,/*  * This hook is used for verifying the table access key information * that is generated and maintained in the QueryPlan object by the * TableAccessAnalyer. All the hook does is print out the table/keys * per operator recorded in the TableAccessInfo in the QueryPlan.  */
Hive,WITHOUT_CLASSIFICATION,//  Launch hadoop command file on windows. 
Hive,WITHOUT_CLASSIFICATION,// updates (21) -> (20)  deletes (43)  inserts (1111) 
Hive,WITHOUT_CLASSIFICATION,//  startRow is inclusive while stopRow is exclusive   this util method returns very next bytearray which will occur after the current one   by padding current one with a trailing 0 byte. 
Hive,WITHOUT_CLASSIFICATION,//  The hash map for this specialized class. 
Hive,WITHOUT_CLASSIFICATION,//  e.g. INSERT OVERWRITE TABLE temp1 SELECT  c0  c0 FROM temp2;   In such a case Select Op will only have one instance of c0 and RS would have two.   So locating bucketCol in such cases will generate error. So bail out. 
Hive,WITHOUT_CLASSIFICATION,//  whether this RS is deduplicated 
Hive,WITHOUT_CLASSIFICATION,//  Try to infer possible sort columns in the query   i.e. the sequence must be pRS-SEL*-fsParent 
Hive,WITHOUT_CLASSIFICATION,//  we also need the expr for the partitioned table 
Hive,WITHOUT_CLASSIFICATION,//  With the high message size limit this connection should work 
Hive,WITHOUT_CLASSIFICATION,//  In the SEL operator of the semijoin branch there should be only one column in the operator 
Hive,WITHOUT_CLASSIFICATION,//  set up the operator plan. (after generating splits - that changes configs) 
Hive,WITHOUT_CLASSIFICATION,//  in a set so we can add them to the list of input cols to check. 
Hive,WITHOUT_CLASSIFICATION,/*               This will happen only when loading tables and we reach the limit of number of tasks we can create;              hence we know here that the table should exist and there should be a lastPartitionName           */
Hive,WITHOUT_CLASSIFICATION,//  This does not work hence opening and closing file for every event.   writer.hflush(); 
Hive,WITHOUT_CLASSIFICATION,//  order of overlapping keys should be exactly the same 
Hive,WITHOUT_CLASSIFICATION,//  At this entry point we are going to assume that these are logical table columns.   Perhaps we should go thru the code and clean this up to be more explicit; for now we   will start with this single assumption and maintain clear semantics from here. 
Hive,WITHOUT_CLASSIFICATION,//  If we are dropping from unmanaged unset the flag; and vice versa 
Hive,WITHOUT_CLASSIFICATION,//  Register information about created predicates 
Hive,WITHOUT_CLASSIFICATION,//  PARTITION_SPECS 
Hive,WITHOUT_CLASSIFICATION,//  Set up backup task 
Hive,WITHOUT_CLASSIFICATION,//  Need to verify that when reading a datum with an updated reader schema   that the datum then returns the reader schema as its own since we   depend on this behavior in order to avoid re-encoding the datum 
Hive,WITHOUT_CLASSIFICATION,//  set the first one to be active ZK; Others are backups 
Hive,WITHOUT_CLASSIFICATION,// exceptions including InterruptException and other KeeperException 
Hive,WITHOUT_CLASSIFICATION,//  required   optional 
Hive,WITHOUT_CLASSIFICATION,//  Normal case the last parameter is a normal parameter.   ConversionHelper can be called without method parameter length   checkings   for terminatePartial() and merge() calls. 
Hive,WITHOUT_CLASSIFICATION,//  mocked session starts with default queue 
Hive,WITHOUT_CLASSIFICATION,//  Is bucketJoin possible? We need correct bucketing 
Hive,WITHOUT_CLASSIFICATION,//  Trigger the creation of LLAP registry client if in use. Clients may be using a different 
Hive,WITHOUT_CLASSIFICATION,//  meta store check command - equivalent to add partition command   no input objects are passed to it currently but keeping admin priv   requirement on inputs just in case some input object like file 
Hive,WITHOUT_CLASSIFICATION,//  Create a default socket factory based on standard JSSE trust material 
Hive,WITHOUT_CLASSIFICATION,//  if database is not the one currently using 
Hive,WITHOUT_CLASSIFICATION,//  Verify if no create table/function calls. Only add partitions. 
Hive,WITHOUT_CLASSIFICATION,//  Max is disabled we can safely return false 
Hive,WITHOUT_CLASSIFICATION,/*      * Implemented as a navigable set protected by a     * single lock and using conditions to manage blocking.      */
Hive,WITHOUT_CLASSIFICATION,//  ignored 
Hive,WITHOUT_CLASSIFICATION,//  Create a file sink operator for this file name 
Hive,WITHOUT_CLASSIFICATION,//  as RS will be required. 
Hive,WITHOUT_CLASSIFICATION,//  add partition in metastore for dynamic partition. We make a metastore call for every new partition value that   we encounter even if partition already exists (exists check require a metastore call anyways). 
Hive,WITHOUT_CLASSIFICATION,/*  * Directly serialize field-by-field the LazyBinary format.* * This is an alternative way to serialize than what is provided by LazyBinarySerDe.   */
Hive,WITHOUT_CLASSIFICATION,//  We should not remove the dynamic partition pruner generated synthetic predicates. 
Hive,WITHOUT_CLASSIFICATION,//  Created 5 tables under "db1" 
Hive,WITHOUT_CLASSIFICATION,//  Create a new ColumnInfo replacing STRUCT.COLUMN with STRUCT_COLUMN 
Hive,WITHOUT_CLASSIFICATION,/*      * The order of the join condition expressions don't matter.     * A merge can happen:     * - if every target condition is present in some position of the node condition list.     * - there is no node condition which is not equal to any target condition.      */
Hive,WITHOUT_CLASSIFICATION,//  Always show an array. 
Hive,WITHOUT_CLASSIFICATION,//  need to localize the additional jars and files 
Hive,WITHOUT_CLASSIFICATION,/*  alternate2 = unused  */
Hive,WITHOUT_CLASSIFICATION,//  TYPE1 
Hive,WITHOUT_CLASSIFICATION,//  Int 
Hive,WITHOUT_CLASSIFICATION,//  4. address the colExp colList etc for the SEL 
Hive,WITHOUT_CLASSIFICATION,//  Assign all remaining rows. 
Hive,WITHOUT_CLASSIFICATION,/*  Add a new request to be executed  */
Hive,WITHOUT_CLASSIFICATION,//  The ptned table should miss in target as the table was marked virtually as dropped 
Hive,WITHOUT_CLASSIFICATION,//  This may happen for schema-less tables where columns are dynamically   supplied by serdes. 
Hive,WITHOUT_CLASSIFICATION,//  If cache is disabled don't use it. 
Hive,WITHOUT_CLASSIFICATION,//  STAGE_ATTRIBUTES 
Hive,WITHOUT_CLASSIFICATION,//  Metastore stuff. Be sure to update HiveConf.metaVars when you add something here! 
Hive,WITHOUT_CLASSIFICATION,/*    * Simulates the set <command>;    */
Hive,WITHOUT_CLASSIFICATION,/*  100 files x 100 size for 11 splits  */
Hive,WITHOUT_CLASSIFICATION,//  These methods are required by serialization 
Hive,WITHOUT_CLASSIFICATION,//  Use both args to ease development.  Delete this one on   May 1. 
Hive,WITHOUT_CLASSIFICATION,//  -p <password> 
Hive,WITHOUT_CLASSIFICATION,//  check entries beyond first 2 
Hive,WITHOUT_CLASSIFICATION,//  Successfully perform compaction on a table/partition so that we have successful records in COMPLETED_COMPACTIONS 
Hive,WITHOUT_CLASSIFICATION,//  Do not change the initial bytes which contain NumHashFunctions/NumBits! 
Hive,WITHOUT_CLASSIFICATION,//  Merge the two partials 
Hive,WITHOUT_CLASSIFICATION,//  threshold to switch from SPARSE to DENSE encoding 
Hive,WITHOUT_CLASSIFICATION,//  thread local conf from HMS 
Hive,WITHOUT_CLASSIFICATION,/* trivially retry-able */
Hive,WITHOUT_CLASSIFICATION,//  Casts to exact types including long to double etc. are needed in some special cases. 
Hive,WITHOUT_CLASSIFICATION,//  This test assumes the hive-contrib JAR has been built as part of the Hive build.   Also dependent on the UDFExampleAdd class within that JAR. 
Hive,WITHOUT_CLASSIFICATION,//  this is what allows the UI to do cross-domain reads of the contents   only apply to idempotent GET ops (all others need crumbs) 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: The default value for null fields in vectorization is 1 for int types NaN for 
Hive,WITHOUT_CLASSIFICATION,//  The pruning needs to preserve the order of columns in the input schema 
Hive,WITHOUT_CLASSIFICATION,//  make in Path to ensure no slash at the end 
Hive,WITHOUT_CLASSIFICATION,//  left key only needs to be adjusted if there are system 
Hive,WITHOUT_CLASSIFICATION,//  Allocated by caller. 
Hive,WITHOUT_CLASSIFICATION,//  Add a shutdown hook for catching SIGTERM & SIGINT 
Hive,WITHOUT_CLASSIFICATION,//  object overhead + 4 bytes for bitCount + 4 bytes for bitLength   + 4 bytes for firstNonzeroByteNum + 4 bytes for firstNonzeroIntNum +   + 4 bytes for lowestSetBit + 5 bytes for size of magnitude (since max precision   is only 38 for HiveDecimal) + 7 bytes of padding (since java memory allocations   are 8 byte aligned) 
Hive,WITHOUT_CLASSIFICATION,//  Get the column names and their corresponding types 
Hive,WITHOUT_CLASSIFICATION,//  ======= VARIOUS UTILITY METHOD 
Hive,WITHOUT_CLASSIFICATION,//  2. Walk through UDAF and add them to GB 
Hive,WITHOUT_CLASSIFICATION,//  different tasks. 
Hive,WITHOUT_CLASSIFICATION,//  optional int32 guaranteed_task_count = 1; 
Hive,WITHOUT_CLASSIFICATION,//  Verify that getNextNotification(last) returns events after a specified event 
Hive,WITHOUT_CLASSIFICATION,// this proves data is written in Acid layout so T was made Acid 
Hive,WITHOUT_CLASSIFICATION,// to handle map can read list of struct data (i.e. list<struct<key value>> --> map<key 
Hive,WITHOUT_CLASSIFICATION,/*       * Failed to set job status as COMPLETED which mean the main thread would have      * exited and not waiting for the result. Call cleanup() to execute any cleanup.       */
Hive,WITHOUT_CLASSIFICATION,// map hue/foo.bar@something.com->hue since user group checks   and config files are in terms of short name 
Hive,WITHOUT_CLASSIFICATION,/*  * An multi-key hash map based on the BytesBytesMultiHashMultiSet.  */
Hive,WITHOUT_CLASSIFICATION,//  Create the route objects based on the Nodes 
Hive,WITHOUT_CLASSIFICATION,//  Backtrack partition columns of cRS to pRS 
Hive,WITHOUT_CLASSIFICATION,//  stored as directories 
Hive,WITHOUT_CLASSIFICATION,//  construct column name list for reference by filter push down 
Hive,WITHOUT_CLASSIFICATION,// 1 split since we only have 1 bucket file in base/.  delta is not flushed (committed) yet i.e. empty 
Hive,WITHOUT_CLASSIFICATION,//  test get stats on a column for which stats doesn't exist 
Hive,WITHOUT_CLASSIFICATION,//  use the original bytes in case decoding should fail 
Hive,WITHOUT_CLASSIFICATION,//  2019-01-02 00:00:00 GMT is 2019-01-01 16:00:00 in zone GMT-0800 (PST) 
Hive,WITHOUT_CLASSIFICATION,//  Bootstrap Repl A -> B and then export table t1 
Hive,WITHOUT_CLASSIFICATION,//  exact numbers (power of 2) can do the same 
Hive,WITHOUT_CLASSIFICATION,//  join 
Hive,WITHOUT_CLASSIFICATION,//  This must be a final map reduce task (the task containing the file sink   operator that writes the final output) 
Hive,WITHOUT_CLASSIFICATION,//  10^38 
Hive,WITHOUT_CLASSIFICATION,//  Note: sessions in toRestart are always in use so they cannot expire in parallel. 
Hive,WITHOUT_CLASSIFICATION,/*  Count of number of null values seen so far  */
Hive,WITHOUT_CLASSIFICATION,//  DEFAULT_VALUE 
Hive,WITHOUT_CLASSIFICATION,//  vars that are not used in the join key. 
Hive,WITHOUT_CLASSIFICATION,//  Explicit avro serialization not supported yet. Revert to default 
Hive,WITHOUT_CLASSIFICATION,//  TODO: Split count is not the same as no of buckets 
Hive,WITHOUT_CLASSIFICATION,//  write the base 
Hive,WITHOUT_CLASSIFICATION,//  If the first child is directory then rest would be directory too according to HCatalog dir structure   recurse in that case 
Hive,WITHOUT_CLASSIFICATION,//  if there is no path element other than "/" report it but not fail 
Hive,WITHOUT_CLASSIFICATION,//  since maxDepth is not yet reached we are missing partition   columns in currentPath 
Hive,WITHOUT_CLASSIFICATION,// so update has 1 writer but which creates buckets where the new rows land 
Hive,WITHOUT_CLASSIFICATION,//  user from TestPamAuthenticator 
Hive,WITHOUT_CLASSIFICATION,//  LOG.debug("VectorMapJoinFastKeyStore equalKey no match big length"); 
Hive,WITHOUT_CLASSIFICATION,//  10^39 
Hive,WITHOUT_CLASSIFICATION,/*  This function determines whether sparkpruningsink is with mapjoin.  This will be called     to check whether the tree should be split for dpp.  For mapjoin it won't be.  Also called     to determine whether dpp should be enabled for anything other than mapjoin.    */
Hive,WITHOUT_CLASSIFICATION,//     tests.put(new String[]{"%jdbcdriver\\_table%" "under\\_COL"} 1); 
Hive,WITHOUT_CLASSIFICATION,// happen since IO layer either knows how to produce ROW__ID or not - but to be safe 
Hive,WITHOUT_CLASSIFICATION,//  We have to unset the env workarounds so they don't confuse each other between tests. 
Hive,WITHOUT_CLASSIFICATION,//  setup some helper config variables. 
Hive,WITHOUT_CLASSIFICATION,//  Create payload 
Hive,WITHOUT_CLASSIFICATION,//  OPERATION_STARTED 
Hive,WITHOUT_CLASSIFICATION,//  write the number of elements in sparse map (required for   reconstruction) 
Hive,WITHOUT_CLASSIFICATION,//  For deserialization. 
Hive,WITHOUT_CLASSIFICATION,// verify that there is data in the resultset 
Hive,WITHOUT_CLASSIFICATION,//  perform casting using Hive rules 
Hive,WITHOUT_CLASSIFICATION,//  we found all the operators that we are supposed to process. 
Hive,WITHOUT_CLASSIFICATION,//  response is written (i.e response headers + mapOutput). 
Hive,WITHOUT_CLASSIFICATION,//  Hand reset the big table columns. 
Hive,WITHOUT_CLASSIFICATION,//  Day granularity 
Hive,WITHOUT_CLASSIFICATION,//  Process global init file: .hiverc 
Hive,WITHOUT_CLASSIFICATION,//  Drop all tables 
Hive,WITHOUT_CLASSIFICATION,//  creates the static cache 
Hive,WITHOUT_CLASSIFICATION,//               cost of transferring map outputs to GBy operator 
Hive,WITHOUT_CLASSIFICATION,//  MySQL returns 0 if the string is not a well-formed numeric value.   return Byte.valueOf(0);   But we decided to return NULL instead which is more conservative. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure negative numbers comes before positive numbers 
Hive,WITHOUT_CLASSIFICATION,//  1. Figure out what we have to read. 
Hive,WITHOUT_CLASSIFICATION,//  Partial aggregation is not done for distincts on the mapper   However if the data is bucketed/sorted on the distinct key partial aggregation   can be performed on the mapper. 
Hive,WITHOUT_CLASSIFICATION,//  compare to must compare with scaling up/down. 
Hive,WITHOUT_CLASSIFICATION,//  The write count does not matter as the map will fail in its first 
Hive,WITHOUT_CLASSIFICATION,//  version of Guava on the classpath depending on the deploy mode). 
Hive,WITHOUT_CLASSIFICATION,//  End RelBuilder.java 
Hive,WITHOUT_CLASSIFICATION,//  10^37 
Hive,WITHOUT_CLASSIFICATION,/*      * Sum input and output are DECIMAL.     *     * Any mode (PARTIAL1 PARTIAL2 FINAL COMPLETE).      */
Hive,WITHOUT_CLASSIFICATION,//  add our base to the list of directories to search for files in. 
Hive,WITHOUT_CLASSIFICATION,//  The output of a partial aggregation is a struct containing 
Hive,WITHOUT_CLASSIFICATION,//  Or session is being killed need to coordinate between that and the user.   These two cases don't need to be distinguished for now. 
Hive,WITHOUT_CLASSIFICATION,//  will update current number of open txns to 3 
Hive,WITHOUT_CLASSIFICATION,//  We shouldn't cast strings to other types because that can break original data in cases of   leading zeros or zeros trailing after decimal point. 
Hive,WITHOUT_CLASSIFICATION,//  source table spec -- for TableScanOperator   same as MoveWork.loadTableDesc -- for FileSinkOperator   same as MoveWork.loadFileDesc -- for FileSinkOperator   aggregation key prefix   are stats completely reliable 
Hive,WITHOUT_CLASSIFICATION,//  First row determines isGroupResultNull and double firstValue; stream fill result as repeated. 
Hive,WITHOUT_CLASSIFICATION,// check result now 
Hive,WITHOUT_CLASSIFICATION,//  Open a new client session 
Hive,WITHOUT_CLASSIFICATION,//  now we've got a table check that it works 
Hive,WITHOUT_CLASSIFICATION,//  previous base directory should stay until Cleaner kicks in. 
Hive,WITHOUT_CLASSIFICATION,//  allow SET and DFS commands to be used during testing 
Hive,WITHOUT_CLASSIFICATION,//  When we've buffered the max allowed spill the oldest one to make space. 
Hive,WITHOUT_CLASSIFICATION,/*      * let function decide if it can handle this special case.      */
Hive,WITHOUT_CLASSIFICATION,//  Remove backlink. 
Hive,WITHOUT_CLASSIFICATION,//  For complex object serialize to JSON format 
Hive,WITHOUT_CLASSIFICATION,//  struct<col1:struct<a:booleanb:double> col2:double>); 
Hive,WITHOUT_CLASSIFICATION,//  We only expect 5 here because we'll get whichever of the partitions published its stats   last. 
Hive,WITHOUT_CLASSIFICATION,//  long column/scalar IF 
Hive,WITHOUT_CLASSIFICATION,//  Check result 
Hive,WITHOUT_CLASSIFICATION,// Convert to object types used by the authorization plugin interface 
Hive,WITHOUT_CLASSIFICATION,//  Handle overflow precision issue. 
Hive,WITHOUT_CLASSIFICATION,//  collect the dynamic pruning conditions 
Hive,WITHOUT_CLASSIFICATION,//  requested logger not found. Add the new logger with the requested level 
Hive,WITHOUT_CLASSIFICATION,//  TODO: the way we add hash fns does exhibit some irregularities.         Seems like the 3rd iter has a better distribution in many cases even better         that the original hash. That trips the "above MA" criteria even if the rest is flat. 
Hive,WITHOUT_CLASSIFICATION,//  todo: nested LV 
Hive,WITHOUT_CLASSIFICATION,//  Not specified. 
Hive,WITHOUT_CLASSIFICATION,//  Skip the child unique key if part of it is not   projected. 
Hive,WITHOUT_CLASSIFICATION,//  At this point no one will take the write lock and update so we can do the last check. 
Hive,WITHOUT_CLASSIFICATION,//  initialize record writer with connection and write id info 
Hive,WITHOUT_CLASSIFICATION,// boolean keysAreEqual = (currentKeys != null && newKeys != null)?    newKeyStructEqualComparer.areEqual(currentKeys newKeys) : false; 
Hive,WITHOUT_CLASSIFICATION,//  2048 MB memory for compaction map job   minor compaction if more than 4 delta dirs   major compaction if more than 47% 
Hive,WITHOUT_CLASSIFICATION,//  LSB 3 bits is used to locate offset within the block 
Hive,WITHOUT_CLASSIFICATION,/*        * Same reason as above. This is the case when we have the main work item after the merge work       * has been created for the small table side.        */
Hive,WITHOUT_CLASSIFICATION,//  Add all input columns 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:GetTokenRequestProto) 
Hive,WITHOUT_CLASSIFICATION,//  in a preserved table 
Hive,WITHOUT_CLASSIFICATION,//  y event to truncate last repl ID: replDumpId+2x+y 
Hive,WITHOUT_CLASSIFICATION,//  satisfying precondition means column statistics is available 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getSQLXML(int)    */
Hive,WITHOUT_CLASSIFICATION,//  see comment at "Dumping rows via SQL..." for why this doesn't work   assertEquals("Comparing Pig to Hive" t.get(0) l.get(0)); 
Hive,WITHOUT_CLASSIFICATION,//  query qualify for the optimization 
Hive,WITHOUT_CLASSIFICATION,//  Open files 
Hive,WITHOUT_CLASSIFICATION,//  add Hive operator level statistics. - e.g. RECORDS_IN RECORDS_OUT 
Hive,WITHOUT_CLASSIFICATION,//  Check that all the jars are added to the classpath 
Hive,WITHOUT_CLASSIFICATION,//  Schema should be same 
Hive,WITHOUT_CLASSIFICATION,//  This indicates there is a second VInt containing the additional bits of the seconds   field. 
Hive,WITHOUT_CLASSIFICATION,//  union keys 
Hive,WITHOUT_CLASSIFICATION,//  We translate the grouping set bit field into a boolean arrays. 
Hive,WITHOUT_CLASSIFICATION,//  1. Get valid Window Function Spec 
Hive,WITHOUT_CLASSIFICATION,// for the big table we only need to promote the next group to the current group. 
Hive,WITHOUT_CLASSIFICATION,//  Lock the buffer validate it and add to results. 
Hive,WITHOUT_CLASSIFICATION,//  this is not a join condition. 
Hive,WITHOUT_CLASSIFICATION,//  We do not want to modify the writable provided by the object o since it is not a copy. 
Hive,WITHOUT_CLASSIFICATION,//  This is where we cut the tree as described above. We also remember that 
Hive,WITHOUT_CLASSIFICATION,// 1 partitions updated 
Hive,WITHOUT_CLASSIFICATION,//  2nd query's session has compile lock timeout of 1 sec so it should 
Hive,WITHOUT_CLASSIFICATION,//  CONSTRAINTNAME 
Hive,WITHOUT_CLASSIFICATION,//  Insert overwrite on one partition with multiple files 
Hive,WITHOUT_CLASSIFICATION,//  LOCK_ID_INTERNAL 
Hive,WITHOUT_CLASSIFICATION,//  Allow TCP Keep alive socket option for for HiveServer or a maximum timeout for the socket. 
Hive,WITHOUT_CLASSIFICATION,//  UNDONE: Convert byte 0 or 1 to character. 
Hive,WITHOUT_CLASSIFICATION,// now we have the rootTasks set up for Insert ... Select 
Hive,WITHOUT_CLASSIFICATION,//  Try with parameterized varchar types 
Hive,WITHOUT_CLASSIFICATION,//  Taken care of on higher level. 
Hive,WITHOUT_CLASSIFICATION,//  If we are seeing this mapjoin for the first time initialize the plan.   If we are seeing this mapjoin for the second or later time then atleast one of the   branches for this mapjoin have been encounered. Join the plan with the plan created 
Hive,WITHOUT_CLASSIFICATION,// but the writeEntity is complete in DDL operations instead DDL sets the writeType so  we use it to determine its lockMode and first we check if the writeType was set 
Hive,WITHOUT_CLASSIFICATION,//  there should be 2 calls to create partitions with batch sizes of 5 4 
Hive,WITHOUT_CLASSIFICATION,//  to a single node may fail. 
Hive,WITHOUT_CLASSIFICATION,//  not authorized by this implementation ie operation is allowed by it 
Hive,WITHOUT_CLASSIFICATION,//  From java.util.Calendar 
Hive,WITHOUT_CLASSIFICATION,//  check config properties expected with embedded metastore client 
Hive,WITHOUT_CLASSIFICATION,//  this could be replaced by bucketing on RS + bucketed fetcher for next MR 
Hive,WITHOUT_CLASSIFICATION,//  TODO: extract interface when needed 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setBlob(int java.io.InputStream long)    */
Hive,WITHOUT_CLASSIFICATION,//  Find the common class for type conversion 
Hive,WITHOUT_CLASSIFICATION,//  Rename unpartitioned table 
Hive,WITHOUT_CLASSIFICATION,//  Initialize 
Hive,WITHOUT_CLASSIFICATION,// stepTracker should now be 2 which indicates t2 has started 
Hive,WITHOUT_CLASSIFICATION,// make the partition in Target not empty 
Hive,WITHOUT_CLASSIFICATION,//  Drop cascade functions dropped by cascade 
Hive,WITHOUT_CLASSIFICATION,//  these will become v0-v3 
Hive,WITHOUT_CLASSIFICATION,//  If destination file is present and checksum of source mismatch then retry copy. 
Hive,WITHOUT_CLASSIFICATION,//  we're cloning the operator plan but we're retaining the original work. That means   that root operators have to be replaced with the cloned ops. The replacement map 
Hive,WITHOUT_CLASSIFICATION,//  Column doesn't appear to be a partition column for the table. 
Hive,WITHOUT_CLASSIFICATION,//  This is not a mistake catName is in the where clause twice 
Hive,WITHOUT_CLASSIFICATION,//  Found UDF in metastore - now add it to the function registry. 
Hive,WITHOUT_CLASSIFICATION,//  Rewrite CASE into NVL 
Hive,WITHOUT_CLASSIFICATION,//  get the first record 
Hive,WITHOUT_CLASSIFICATION,// return the CompressionCodec used for this file 
Hive,WITHOUT_CLASSIFICATION,//  User might have only specified partial list of partition keys in which case add other partition keys in partSpec 
Hive,WITHOUT_CLASSIFICATION,//  The entire storage is 0x00s or 0xFFs   0x00s means is 0   0xFFs means is -1 
Hive,WITHOUT_CLASSIFICATION,//  Add a new table via CachedStore 
Hive,WITHOUT_CLASSIFICATION,//  copy with 8K buffer not close 
Hive,WITHOUT_CLASSIFICATION,//  test february of leap year 2/31 is viewed as 3/2 due to 2 days diff from 
Hive,WITHOUT_CLASSIFICATION,//  Restore original values 
Hive,WITHOUT_CLASSIFICATION,//  Release this shared timer resource 
Hive,WITHOUT_CLASSIFICATION,//  this is a mapjoin but not suited for a sort merge bucket map join. check outer joins 
Hive,WITHOUT_CLASSIFICATION,//  remove old parents 
Hive,WITHOUT_CLASSIFICATION,//  all partitions are altered atomically   all prehooks are fired together followed by all post hooks 
Hive,WITHOUT_CLASSIFICATION,//  No op 
Hive,WITHOUT_CLASSIFICATION,//  create table must fail. 
Hive,WITHOUT_CLASSIFICATION,// fetchTransactionBatch() was never called we want to start with first txn 
Hive,WITHOUT_CLASSIFICATION,//  Create the column stats table 
Hive,WITHOUT_CLASSIFICATION,//  nothing to do here silently return. 
Hive,WITHOUT_CLASSIFICATION,//  The copyToBuffer will reposition and re-read the input buffer. 
Hive,WITHOUT_CLASSIFICATION,//  In case of test do just close the log files do not remove them. 
Hive,WITHOUT_CLASSIFICATION,//  if our dbName is equal but tableName is blank we're interested in this db-level event 
Hive,WITHOUT_CLASSIFICATION,//  if doAs is not enabled we pass the principal/keypad to spark-submit in order to   support the possible delegation token renewal in Spark 
Hive,WITHOUT_CLASSIFICATION,//  max we allow tez to pick 
Hive,WITHOUT_CLASSIFICATION,/*    * Setup our 2nd batch with the same "column schema" as the output columns plus any scratch   * columns since the overflow batch will get forwarded to children operators.    */
Hive,WITHOUT_CLASSIFICATION,//  MY_STRING_ENUM_MAP 
Hive,WITHOUT_CLASSIFICATION,// this is to handle syn(pos) where pos < headerEnd. 
Hive,WITHOUT_CLASSIFICATION,// cut prefix from hive's map key 
Hive,WITHOUT_CLASSIFICATION,//  Tarjan's algo 
Hive,WITHOUT_CLASSIFICATION,//  Reset just the value columns and value buffer. 
Hive,WITHOUT_CLASSIFICATION,//  Retrieve settings in HiveConf that aren't also set in the JobConf. 
Hive,WITHOUT_CLASSIFICATION,//  Setup VectorizationContext 
Hive,WITHOUT_CLASSIFICATION,//  Must be spark branch 
Hive,WITHOUT_CLASSIFICATION,//  Share the same write buffers with our value store. 
Hive,WITHOUT_CLASSIFICATION,// set inner schema for dtype 
Hive,WITHOUT_CLASSIFICATION,//  Either initialCapacity is too large or nextHighestPowerOfTwo overflows 
Hive,WITHOUT_CLASSIFICATION,//  replace the current task with the new generated conditional task 
Hive,WITHOUT_CLASSIFICATION,//  security property names 
Hive,WITHOUT_CLASSIFICATION,//  Case 3.2 - Max in list members: 1000 Max query string length: 10KB and exact 1000 members in a single IN clause 
Hive,WITHOUT_CLASSIFICATION,//  Non-empty java opts with bad -Xmx specification 
Hive,WITHOUT_CLASSIFICATION,//  COUNT(*) 
Hive,WITHOUT_CLASSIFICATION,//  If partition columns occur in data we want to remove them.   So find out positions of partition columns in schema provided by user.   We also need to update the output Schema with these deletions. 
Hive,WITHOUT_CLASSIFICATION,//  merge work only needs input and output. 
Hive,WITHOUT_CLASSIFICATION,//  Replace the task with the new task. Copy the children and parents of the old 
Hive,WITHOUT_CLASSIFICATION,//  ie we are running 1.3   In 1.3 this constructor has the same behavior but in 1.4 the default   was changed to add wrapping and newlines. 
Hive,WITHOUT_CLASSIFICATION,//  At this point the task has been added into the queue. It may have caused an eviction for   some other task. 
Hive,WITHOUT_CLASSIFICATION,//  if we're visiting a terminal we've created ourselves   just skip and keep going 
Hive,WITHOUT_CLASSIFICATION,//  there could be interval where desired counter value is not populated by the time we make this check 
Hive,WITHOUT_CLASSIFICATION,//  In test mode print the logs to the output 
Hive,WITHOUT_CLASSIFICATION,//  After that a heuristic is used to decide. 
Hive,WITHOUT_CLASSIFICATION,//  Max tolerable variance for matches 
Hive,WITHOUT_CLASSIFICATION,//  Used for sending information for scheduling priority. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#setTypeMap(java.util.Map)    */
Hive,WITHOUT_CLASSIFICATION,//  already encoded to thrift-able object in ThriftFormatter 
Hive,WITHOUT_CLASSIFICATION,/*  * JavaCC - OriginalChecksum=7edd3e61472739e9fede55c18a336638 (do not edit this * line)  */
Hive,WITHOUT_CLASSIFICATION,//  ACTION_EXPRESSION 
Hive,WITHOUT_CLASSIFICATION,//  sorting the keys from the properties helps to create   a deterministic url which is tested for various configuration in 
Hive,WITHOUT_CLASSIFICATION,//  The list is being drained cannot increase the delta anymore. 
Hive,WITHOUT_CLASSIFICATION,//  SERIALIZATION_LIB 
Hive,WITHOUT_CLASSIFICATION,//  map-side work 
Hive,WITHOUT_CLASSIFICATION,//  The alias may not be present in case of a sub-query 
Hive,WITHOUT_CLASSIFICATION,//  This is for runtime min/max pushdown - don't need to do NOT BETWEEN 
Hive,WITHOUT_CLASSIFICATION,//  Sigh... 
Hive,WITHOUT_CLASSIFICATION,//  to appropriate locations 
Hive,WITHOUT_CLASSIFICATION,//  See the comment in the other isSameKey 
Hive,WITHOUT_CLASSIFICATION,//  second group 
Hive,WITHOUT_CLASSIFICATION,//  Verify that when stats are already present and forceRecompute is specified they are recomputed 
Hive,WITHOUT_CLASSIFICATION,//  Close the inner output stream before closing the outer output stream.   For chunked output this means we don't write end-of-data indicator. 
Hive,WITHOUT_CLASSIFICATION,//  Include type name for precision/scale. 
Hive,WITHOUT_CLASSIFICATION,//  This inspector is initialized we still need 
Hive,WITHOUT_CLASSIFICATION,//  This is SQL standard - average of zero items should be null. 
Hive,WITHOUT_CLASSIFICATION,//  Key index can be null/"null" if there is only a single stripe. Just start fresh. 
Hive,WITHOUT_CLASSIFICATION,//  set VertexManagerPlugin if whether it's a cross product destination vertex 
Hive,WITHOUT_CLASSIFICATION,//  This is not transactional 
Hive,WITHOUT_CLASSIFICATION,//  Negative number. 
Hive,WITHOUT_CLASSIFICATION,//  Cannot slice compressed files. 
Hive,WITHOUT_CLASSIFICATION,//  notifies when memory usage is 70% after GC 
Hive,WITHOUT_CLASSIFICATION,//  Accumulate the counts. 
Hive,WITHOUT_CLASSIFICATION,//  Set primary key name if null before sending to listener 
Hive,WITHOUT_CLASSIFICATION,//  Unlike in MR we may call this method multiple times for each 
Hive,WITHOUT_CLASSIFICATION,//  Our input is repeating (i.e. inputColNumber = 0). 
Hive,WITHOUT_CLASSIFICATION,//  column authorization is checked through table scan operators. 
Hive,WITHOUT_CLASSIFICATION,//  nothing needs to be done 
Hive,WITHOUT_CLASSIFICATION,//  5. Run Cleaner. It should remove the 2 delta dirs and 1 old base dir. 
Hive,WITHOUT_CLASSIFICATION,//  the local batch has been consumed entirely reset it 
Hive,WITHOUT_CLASSIFICATION,//  Try to eat trailing blank padding. 
Hive,WITHOUT_CLASSIFICATION,//  Set up a common id hash for this job so that when we create any temporary directory   later on it is guaranteed to be unique. 
Hive,WITHOUT_CLASSIFICATION,//  optional int64 signatureKeyId = 2; 
Hive,WITHOUT_CLASSIFICATION,/*    * construct the ASTNode for the SQ column that will join with the OuterQuery Expression.   * So for 'select ... from R1 where A in (select B from R2...)'   * this will build (. (TOK_TABLE_OR_COL Identifier[SQ_1]) Identifier[B])   * where 'SQ_1' is the alias generated for the SubQuery.    */
Hive,WITHOUT_CLASSIFICATION,//  make sure it isn't 0 
Hive,WITHOUT_CLASSIFICATION,//  int hadoopMem = conf.getIntVar(HiveConf.ConfVars.HIVEHADOOPMAXMEM); 
Hive,WITHOUT_CLASSIFICATION,//  Delete data.   Ignore unknownDB.   Cascade. 
Hive,WITHOUT_CLASSIFICATION,//  These two are used to indicate that we are running tests 
Hive,WITHOUT_CLASSIFICATION,// here each batch has written data and committed (to bucket0 since table only has 1 bucket)  so each of 2 deltas has 1 bucket0 and 1 bucket0_flush_length.  Furthermore each bucket0  has now received more data(logically - it's buffered) but it is not yet committed. 
Hive,WITHOUT_CLASSIFICATION,//  if last batch is successful remove it from partsNotInMs 
Hive,WITHOUT_CLASSIFICATION,//  UNDONE: Copied from VectorMapJoinOuterGenerateResultOperator. 
Hive,WITHOUT_CLASSIFICATION,/*        * Validate and vectorize the Reduce operator tree.        */
Hive,WITHOUT_CLASSIFICATION,//  any log specific settings via hiveconf will be ignored 
Hive,WITHOUT_CLASSIFICATION,//  buffer2 is now in the heap buffer1 is in the list. "Use" buffer1 again; 
Hive,WITHOUT_CLASSIFICATION,// must be old client talking i.e. we don't know if it's DP so be conservative 
Hive,WITHOUT_CLASSIFICATION,//  Forward; reset key and value columns. 
Hive,WITHOUT_CLASSIFICATION,//  No existing shard present in the database use the current version. 
Hive,WITHOUT_CLASSIFICATION,//  This method is reached when error occurs while sending msg so the session must be bad 
Hive,WITHOUT_CLASSIFICATION,// 2 partitions updated 
Hive,WITHOUT_CLASSIFICATION,//  No need to release memory - cache eviction. 
Hive,WITHOUT_CLASSIFICATION,//  Move the files back to original data location 
Hive,WITHOUT_CLASSIFICATION,//  Throw an HiveSqlException when do async calls 
Hive,WITHOUT_CLASSIFICATION,//  We need to patch the dest back to original into new query.   This makes assumptions about the structure of the AST. 
Hive,WITHOUT_CLASSIFICATION,// Round with default decimal places 
Hive,WITHOUT_CLASSIFICATION,//  a map to keep track of which root generated which work 
Hive,WITHOUT_CLASSIFICATION,//  May need to merge with list of temp tables 
Hive,WITHOUT_CLASSIFICATION,/*        * If the user didn't specify a SerDe we use the default.        */
Hive,WITHOUT_CLASSIFICATION,//  may be do some retry logic here. 
Hive,WITHOUT_CLASSIFICATION,//           LOG.info(e.getKey() + "=>" +e.getValue());          }        } 
Hive,WITHOUT_CLASSIFICATION,//  skip this as validateColumnName always returns true 
Hive,WITHOUT_CLASSIFICATION,//  the settings in conf overlay should not be part of session config 
Hive,WITHOUT_CLASSIFICATION,//  Select true fields child none as 2nd child and none as 3rd. 
Hive,WITHOUT_CLASSIFICATION,//  Do nothing by default. 
Hive,WITHOUT_CLASSIFICATION,//  Checks the status of the RPC call throws an exception in case of error 
Hive,WITHOUT_CLASSIFICATION,//  Set Checkpoint task as dependant to add partition tasks. So if same dump is retried for   bootstrap we skip current partition update. 
Hive,WITHOUT_CLASSIFICATION,//  Return false for null 
Hive,WITHOUT_CLASSIFICATION,//  Error should not be a timeout. 
Hive,WITHOUT_CLASSIFICATION,//  From metastore (for security) 
Hive,WITHOUT_CLASSIFICATION,//  Hive doesn't support primary keys   using local schema with empty resultset 
Hive,WITHOUT_CLASSIFICATION,//  Compaction doesn't work under a transaction and hence pass null for validTxnList 
Hive,WITHOUT_CLASSIFICATION,//  01000 -> warning 
Hive,WITHOUT_CLASSIFICATION,//  DOUBLE_VAL 
Hive,WITHOUT_CLASSIFICATION,//  Note that pathToAlias will behave as if the original plan was a join plan 
Hive,WITHOUT_CLASSIFICATION,/*   * (non-Javadoc)  *  * @see  * org.apache.hadoop.hive.ql.security.authorization.HiveAuthorizationProvider  * #authorize(org.apache.hadoop.hive.ql.metadata.Table  * org.apache.hadoop.hive.ql.metadata.Partition java.util.List  * org.apache.hadoop.hive.ql.security.authorization.Privilege[]  * org.apache.hadoop.hive.ql.security.authorization.Privilege[])   */
Hive,WITHOUT_CLASSIFICATION,//  No reduction but let's still test the original   predicate to see if it was already a constant   in which case we don't need any runtime decision   about filtering. 
Hive,WITHOUT_CLASSIFICATION,//  Must be deterministic order maps - see HIVE-8707 
Hive,WITHOUT_CLASSIFICATION,/*          * Vectorize this parent's children.  Plug them into vectorParent's children list.         *         * Add those children / vector children to nextParentList / nextVectorParentList.          */
Hive,WITHOUT_CLASSIFICATION,//  Put parameters to aggregations in reduceValues 
Hive,WITHOUT_CLASSIFICATION,//  the overflow batch. 
Hive,WITHOUT_CLASSIFICATION,//  ^A ^B ^C ^D \t 
Hive,WITHOUT_CLASSIFICATION,//  No timestamp patterns should default to normal timestamp format 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   required   required   required 
Hive,WITHOUT_CLASSIFICATION,//  Extra bytes at the end? 
Hive,WITHOUT_CLASSIFICATION,//  Note: we assume that batchSize will be consistent with vectors passed in.   This is rather brittle; same in other readers. 
Hive,WITHOUT_CLASSIFICATION,//  Default 
Hive,WITHOUT_CLASSIFICATION,//  Allocate 1-1-1-1; free 0&2; allocate 2 
Hive,WITHOUT_CLASSIFICATION,//  List the new files in destination path which gets copied from source. 
Hive,WITHOUT_CLASSIFICATION,//  Argument handling 
Hive,WITHOUT_CLASSIFICATION,//  if all the elements are representing null then return true 
Hive,WITHOUT_CLASSIFICATION,// ?? 
Hive,WITHOUT_CLASSIFICATION,//  reset the log buffer verify new dump without any api call does not contain func 
Hive,WITHOUT_CLASSIFICATION,//  All are filtered 
Hive,WITHOUT_CLASSIFICATION,//  Put session into the pool. 
Hive,WITHOUT_CLASSIFICATION,//  First authorize the call 
Hive,WITHOUT_CLASSIFICATION,//  child isn't flattened because parent is repeating null 
Hive,WITHOUT_CLASSIFICATION,//  rowId >= 'f' 
Hive,WITHOUT_CLASSIFICATION,//  column statistics at index 0 contains only the number of rows 
Hive,WITHOUT_CLASSIFICATION,//  from TextMetaDataFormatter 
Hive,WITHOUT_CLASSIFICATION,//  Everyone has permission to write but with sticky set so that delete is restricted.   This is required since the path is same for all users and everyone writes into it. 
Hive,WITHOUT_CLASSIFICATION,//  delimiters for SQL statements are any   non-letter-or-number characters except   underscore and characters that are specified   by the database to be valid name identifiers. 
Hive,WITHOUT_CLASSIFICATION,/*    * Favor Broad Plans over Deep Plans.    */
Hive,WITHOUT_CLASSIFICATION,//  we need to keep the original list of operators in the map join to know 
Hive,WITHOUT_CLASSIFICATION,//  Map from PrimitiveTypeInfo to AbstractPrimitiveJavaObjectInspector. 
Hive,WITHOUT_CLASSIFICATION,//  Irrelevant from eventIds. This can be tracked in the AM itself instead of polluting the task.   Also since we have all the MRInput events here - they'll all be sent in together. 
Hive,WITHOUT_CLASSIFICATION,//  If input has not been rewritten do not rewrite this rel. 
Hive,WITHOUT_CLASSIFICATION,//  right's signum wins 
Hive,WITHOUT_CLASSIFICATION,//  Read all to the world 
Hive,WITHOUT_CLASSIFICATION,//  this means correated value generator wasn't generated 
Hive,WITHOUT_CLASSIFICATION,//  we are done since there are no keys to check for 
Hive,WITHOUT_CLASSIFICATION,//  If the start of the split points into the middle of the cached slice we cannot   use the cached block - it's encoded and columnar so we cannot map the file 
Hive,WITHOUT_CLASSIFICATION,//  this is to keep track if a subquery is correlated and contains aggregate   this is computed in CalcitePlanner while planning and is later required by subuery remove rule   hence this is passed using HivePlannerContext 
Hive,WITHOUT_CLASSIFICATION,//  to finish for it to execute 
Hive,WITHOUT_CLASSIFICATION,//  4. Convert Agg Fn args to Calcite 
Hive,WITHOUT_CLASSIFICATION,//  Entire response is written out. Safe to enable timeout handling. 
Hive,WITHOUT_CLASSIFICATION,//  See comment in ObjectStore.getDataSourceProps 
Hive,WITHOUT_CLASSIFICATION,//  Lookup the delegation token. First in the connection URL then Configuration 
Hive,WITHOUT_CLASSIFICATION,//  Ensures all params are indented. 
Hive,WITHOUT_CLASSIFICATION,//  1.20 * 3.30 
Hive,WITHOUT_CLASSIFICATION,//  return the number of columns recorded in this file's header 
Hive,WITHOUT_CLASSIFICATION,//  Substitution is only supported in non-beeline mode. 
Hive,WITHOUT_CLASSIFICATION,//  e.g. the output columns does not contains the input table 
Hive,WITHOUT_CLASSIFICATION,//  We need to disable join emit interval since for outer joins with post conditions   we need to have the full view on the right matching rows to know whether we need   to produce a row with NULL values or not 
Hive,WITHOUT_CLASSIFICATION,//  2 hosts. 2 per host. 5 requests at the same priority.   First 3 on host1 Next at host2 Last with no host.   Third should allocate on host2 4th on host2 5th will wait. 
Hive,WITHOUT_CLASSIFICATION,// Mocks HS2 publishing logic. 
Hive,WITHOUT_CLASSIFICATION,/*              * Multi-Key outer get key.              */
Hive,WITHOUT_CLASSIFICATION,//  sqlState errorCode should be set 
Hive,WITHOUT_CLASSIFICATION,//  First need to find the min_uncommitted_txnid which is currently seen by any open transactions.   If there are no txns which are currently open or aborted in the system then current value of 
Hive,WITHOUT_CLASSIFICATION,// Acid LM doesn't maintain getOutputLockObjects(); this 'if' just makes logic more explicit 
Hive,WITHOUT_CLASSIFICATION,//  Don't use FieldSchema.equals() since it also compares comments   which is unnecessary for this method. 
Hive,WITHOUT_CLASSIFICATION,//  Create the required command line options 
Hive,WITHOUT_CLASSIFICATION,//  Parse out the individual parts 
Hive,WITHOUT_CLASSIFICATION,//  we are aborting all txns in the current batch so no need to heartbeat 
Hive,WITHOUT_CLASSIFICATION,//  remove the existing partition columns from the field schema 
Hive,WITHOUT_CLASSIFICATION,// test major compaction 
Hive,WITHOUT_CLASSIFICATION,//  PartitionView does not have SD. We do not need update its column stats 
Hive,WITHOUT_CLASSIFICATION,//  HLL algorithm shows stronger bias for values in (2.5 * m) range.   To compensate for this short range bias linear counting is used   for values before this short range. The original paper also says   similar bias is seen for long range values due to hash collisions   in range >1/30*(2^32). For the default case we do not have to   worry about this long range bias as the paper used 32-bit hashing   and we use 64-bit hashing as default. 2^64 values are too high to   observe long range bias (hash collisions). 
Hive,WITHOUT_CLASSIFICATION,//  let the dummy op be the parent of mapjoin op 
Hive,WITHOUT_CLASSIFICATION,//  We have extracted the count from the hash multi-set result so we don't keep it. 
Hive,WITHOUT_CLASSIFICATION,//  c1-c10   c11-c20 
Hive,WITHOUT_CLASSIFICATION,//  all columns (select * for example) 
Hive,WITHOUT_CLASSIFICATION,//  Assuming the used memory is equally divided among all executors. 
Hive,WITHOUT_CLASSIFICATION,//  turn bytes back into identifier for cache lookup 
Hive,WITHOUT_CLASSIFICATION,/*    * fastSerializationUtilsRead high word multiplier:   *   *    Multiply by 2^(62 + 63)                      -- 38 digits or 3 decimal words.   *   *    (2^62)*(2^63) =   *      42535295865117307932921825928971026432 or   *     (12345678901234567890123456789012345678)   *     (         1         2         3        )   *      42535295865117307932921825928971026432 or   *      42535295865117307932921825928971026432  (16 digit comma'd)    */
Hive,WITHOUT_CLASSIFICATION,//  Create expressions for Project operators before and after the Union 
Hive,WITHOUT_CLASSIFICATION,//  Make sure semijoin is not enabled. If it is then do not remove the dynamic partition pruning predicates. 
Hive,WITHOUT_CLASSIFICATION,//  Find databases which name contains _to_find_ or _hidden_ 
Hive,WITHOUT_CLASSIFICATION,//  retain output column number from parent 
Hive,WITHOUT_CLASSIFICATION,//  result grantor principal 
Hive,WITHOUT_CLASSIFICATION,//  Create a database with a view 
Hive,WITHOUT_CLASSIFICATION,//  Ensure partition is present 
Hive,WITHOUT_CLASSIFICATION,//  Check if we already have initiated or are working on a compaction for this partition   or table.  If so skip it.  If we are just waiting on cleaning we can still check   as it may be time to compact again even though we haven't cleaned.  todo: this is not robust.  You can easily run Alter Table to start a compaction between 
Hive,WITHOUT_CLASSIFICATION,//  set r.returnType 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) TypeByte  */
Hive,WITHOUT_CLASSIFICATION,//  Interval year month comparisons 
Hive,WITHOUT_CLASSIFICATION,//  Semantic error not possible. Must be a bug. Convert to   internal error. 
Hive,WITHOUT_CLASSIFICATION,//  if value too large should also be null 
Hive,WITHOUT_CLASSIFICATION,//  create a valid table 
Hive,WITHOUT_CLASSIFICATION,//  For use from HCatClient.addPartitions() to construct from user-input. 
Hive,WITHOUT_CLASSIFICATION,//  record info   metrics 
Hive,WITHOUT_CLASSIFICATION,//  StatsSetupConst.StatDB 
Hive,WITHOUT_CLASSIFICATION,//  If the last line didn't match the patterns either the stack trace is definitely   over 
Hive,WITHOUT_CLASSIFICATION,//  For PARTIAL2 and FINAL: ObjectInspectors for partial aggregations (list 
Hive,WITHOUT_CLASSIFICATION,//  Buffers in test are fakes not linked to cache; notify cache policy explicitly. 
Hive,WITHOUT_CLASSIFICATION,//  If we did not change the DB location there is no need to move the table directories. 
Hive,WITHOUT_CLASSIFICATION,// Check if ExprNodeColumnDesc is wrapped in expr. 
Hive,WITHOUT_CLASSIFICATION,/*  in specific order  */
Hive,WITHOUT_CLASSIFICATION,//  Get table details from tabNameToTabObject cache 
Hive,WITHOUT_CLASSIFICATION,// this should fail because txn aborted due to timeout 
Hive,WITHOUT_CLASSIFICATION,// this will abort the txn 
Hive,WITHOUT_CLASSIFICATION,//  For each task set the key descriptor for the reducer 
Hive,WITHOUT_CLASSIFICATION,//  dynamic partitions   If no dynamic partitions are generated dpPartSpecs may not be initialized 
Hive,WITHOUT_CLASSIFICATION,//  Alternate between returning deleted and not.  This is easier than actually   tracking operations. We test that this is getting properly called by checking that only   half the records show up in base files after major compactions. 
Hive,WITHOUT_CLASSIFICATION,//  Above decimal. 
Hive,WITHOUT_CLASSIFICATION,//  Test that existing shared_write partition with new exclusive coalesces to 
Hive,WITHOUT_CLASSIFICATION,//  Initialize constant arguments 
Hive,WITHOUT_CLASSIFICATION,/*  TODO: determine the progress.  */
Hive,WITHOUT_CLASSIFICATION,//  multiply by p 
Hive,WITHOUT_CLASSIFICATION,/*    * num rows whose output is evaluated.    */
Hive,WITHOUT_CLASSIFICATION,//  if it is a dot operator remember the field name of the rhs of the   left semijoin 
Hive,WITHOUT_CLASSIFICATION,//  Use UDF in query 
Hive,WITHOUT_CLASSIFICATION,//  We can now create a multijoin operator 
Hive,WITHOUT_CLASSIFICATION,//  If this is a non-local warehouse then adding resources from the local filesystem   may mean that other clients will not be able to access the resources.   So disallow resources from local filesystem in this case. 
Hive,WITHOUT_CLASSIFICATION,// insert overwrite not supported for ACID tables 
Hive,WITHOUT_CLASSIFICATION,//  Perform alters in A for incremental replication 
Hive,WITHOUT_CLASSIFICATION,//  this is now a LIFO operation 
Hive,WITHOUT_CLASSIFICATION,// get the current batch size 
Hive,WITHOUT_CLASSIFICATION,//  class static variables 
Hive,WITHOUT_CLASSIFICATION,//  The batchIndex for the rows that are for the THEN/ELSE rows respectively. 
Hive,WITHOUT_CLASSIFICATION,//  COLUMNS 
Hive,WITHOUT_CLASSIFICATION,//  These are only used for tests. 
Hive,WITHOUT_CLASSIFICATION,// now we have an archive with 3 partitions 
Hive,WITHOUT_CLASSIFICATION,//  Get the partition specs 
Hive,WITHOUT_CLASSIFICATION,//  Validate the function name 
Hive,WITHOUT_CLASSIFICATION,//  Prepare buffers 
Hive,WITHOUT_CLASSIFICATION,/*  (first_name < 'owen' or 'foobar' = substr(last_name 4)) and    first_name between 'david' and 'greg'  */
Hive,WITHOUT_CLASSIFICATION,//  If the lock id is 0 then there are no locks in this heartbeat 
Hive,WITHOUT_CLASSIFICATION,//  -Xmx specified in bytes 
Hive,WITHOUT_CLASSIFICATION,//  The input to the select does not matter. Go over the expressions 
Hive,WITHOUT_CLASSIFICATION,//  initialize the object inspectors 
Hive,WITHOUT_CLASSIFICATION,//  production is: Async() FunctionType() NAME FieldList() Throws()   [CommaOrSemicolon] 
Hive,WITHOUT_CLASSIFICATION,//  Wrap the client with a thread-safe proxy to serialize the RPC calls 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see javax.sql.DataSource#getConnection(java.lang.String java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#getFetchSize()    */
Hive,WITHOUT_CLASSIFICATION,//  colExprMap.size() == size of cols from SEL(*) branch 
Hive,WITHOUT_CLASSIFICATION,/*    * Whether root tasks after materialized CTE linkage have been resolved    */
Hive,WITHOUT_CLASSIFICATION,//  inside our own so that we can also store requested quantile values between calls 
Hive,WITHOUT_CLASSIFICATION,//  loop for middles 
Hive,WITHOUT_CLASSIFICATION,//  go through each event and dump out each event to a event-level dump dir inside dumproot 
Hive,WITHOUT_CLASSIFICATION,//  End HiveAggregateProjectMergeRule.java 
Hive,WITHOUT_CLASSIFICATION,//           debugStackTrace = e.getStackTrace(); 
Hive,WITHOUT_CLASSIFICATION,//  Simple container registration and un-registration without any task attempt being involved. 
Hive,WITHOUT_CLASSIFICATION,//  Test with null args 
Hive,WITHOUT_CLASSIFICATION,//  The column number for this one column join specialization. 
Hive,WITHOUT_CLASSIFICATION,//  check if any left pair exists for right objects 
Hive,WITHOUT_CLASSIFICATION,//                 newInput 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#executeUpdate(java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,/*  * HiveCommand is non-SQL statement such as setting a property or * adding a resource. * */
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#setQueryTimeout(int)    */
Hive,WITHOUT_CLASSIFICATION,//  For all the source tables that have a lateral view attach the 
Hive,WITHOUT_CLASSIFICATION,//  by default partition and bucket columns are sorted in ascending order 
Hive,WITHOUT_CLASSIFICATION,//  when creating the reader below there are 2 read ops per bucket file (listStatus and open). 
Hive,WITHOUT_CLASSIFICATION,//  Create new Project-Union-Project sequences 
Hive,WITHOUT_CLASSIFICATION,// find operators which are the children of specified filterOp and there are SparkPartitionPruningSink in these 
Hive,WITHOUT_CLASSIFICATION,//  And one partition 
Hive,WITHOUT_CLASSIFICATION,//  Now allow the users to specify any pools. 
Hive,WITHOUT_CLASSIFICATION,//  Update the object. 
Hive,WITHOUT_CLASSIFICATION,//  10^-39  (rounds) 
Hive,WITHOUT_CLASSIFICATION,//  Now vary isRepeating   nulls possible on left right 
Hive,WITHOUT_CLASSIFICATION,//  anything else including boolean and string is null 
Hive,WITHOUT_CLASSIFICATION,//  The task has been terminated and the duck accounted for based on local state.   Whatever we were doing is irrelevant. The metrics have also been updated. 
Hive,WITHOUT_CLASSIFICATION,//  This test case currently fails since add partitions don't inherit anything from tables. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setNull(int int)    */
Hive,WITHOUT_CLASSIFICATION,//  get the lowValue 
Hive,WITHOUT_CLASSIFICATION,//  we should cancel hcat token if it was acquired by hcat   and not if it was supplied (ie Oozie). In the latter 
Hive,WITHOUT_CLASSIFICATION,//  in 2 longs) produces a interval_day_time. 
Hive,WITHOUT_CLASSIFICATION,/*        End of additional steps     */
Hive,WITHOUT_CLASSIFICATION,/*    * The fix up is delayed so that the parent operators aren't modified until the entire operator   * tree has been vectorized.    */
Hive,WITHOUT_CLASSIFICATION,/*    * represents the schema exposed by a QueryBlock.    */
Hive,WITHOUT_CLASSIFICATION,//  block 
Hive,WITHOUT_CLASSIFICATION,//  If it's a move task get the path the files were moved from this is what any   preceding map reduce task inferred information about and moving does not invalidate   those assumptions   This can happen when a conditional merge is added before the final MoveTask but the 
Hive,WITHOUT_CLASSIFICATION,//  But for native tables we need to do a prefix match for   subdirectories.  (Unlike non-native tables prefix mixups don't seem   to be a potential problem here since we are always dealing with the   path to something deeper than the table location.) 
Hive,WITHOUT_CLASSIFICATION,//  Data Type Conversion Needed?     VECTORIZED_INPUT_FILE_FORMAT:      No data type conversion check?  Assume ALTER TABLE prevented conversions that      VectorizedInputFileFormat cannot handle...     VECTOR_DESERIALIZE:      LAZY_SIMPLE:          Capable of converting on its own.      LAZY_BINARY          Partition schema assumed to match file contents.          Conversion necessary from partition field values to vector columns.   ROW_DESERIALIZE      Partition schema assumed to match file contents.      Conversion necessary from partition field values to vector columns.   
Hive,WITHOUT_CLASSIFICATION,//  Use non-settable struct object inspector. 
Hive,WITHOUT_CLASSIFICATION,// can handle only case trunc date type 
Hive,WITHOUT_CLASSIFICATION,//  Raw splits 
Hive,WITHOUT_CLASSIFICATION,//     of an aggregate expression from the rest of nodes 
Hive,WITHOUT_CLASSIFICATION,//  We are also not supposed to call setDone since we are only part of the operation. 
Hive,WITHOUT_CLASSIFICATION,//  PKTABLE_DB 
Hive,WITHOUT_CLASSIFICATION,//  This should never happen with linked list queue. 
Hive,WITHOUT_CLASSIFICATION,// need to create the table "manually" rather than creating a task since it has to exist to   compile the insert into T... 
Hive,WITHOUT_CLASSIFICATION,//  repeated string tablesRead = 10; 
Hive,WITHOUT_CLASSIFICATION,// JDOException wrapped in MetaException wrapped in InvocationException 
Hive,WITHOUT_CLASSIFICATION,//  get tmp file URI 
Hive,WITHOUT_CLASSIFICATION,//  only one HS2 instance available (cannot failover) 
Hive,WITHOUT_CLASSIFICATION,//     Trigger moveTrigger1 = new ExecutionTrigger("move_big_read" moveExpression1        new Action(Action.Type.MOVE_TO_POOL "ETL"));      Trigger killTrigger = new ExecutionTrigger("big_write_kill" moveExpression2        new Action(Action.Type.KILL_QUERY));      setupTriggers(Lists.newArrayList(moveTrigger1) Lists.newArrayList(killTrigger));      String query = "select t1.under_col t1.value from " + tableName + " t1 join " + tableName +        " t2 on t1.under_col>=t2.under_col order by t1.under_col t1.value";      List<String> setCmds = new ArrayList<>();      setCmds.add("set hive.tez.session.events.print.summary=json");      setCmds.add("set hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecWMEventsSummaryPrinter");      setCmds.add("set hive.exec.failure.hooks=org.apache.hadoop.hive.ql.hooks.PostExecWMEventsSummaryPrinter");      List<String> errCaptureExpect = new ArrayList<>();      errCaptureExpect.add("Workload Manager Events Summary");      errCaptureExpect.add("\"eventType\" : \"GET\"");      errCaptureExpect.add("\"eventType\" : \"MOVE\"");      errCaptureExpect.add("\"eventType\" : \"KILL\"");      errCaptureExpect.add("\"eventType\" : \"RETURN\"");      errCaptureExpect.add("\"name\" : \"move_big_read\"");      errCaptureExpect.add("\"name\" : \"big_write_kill\"");      // violation in BI queue      errCaptureExpect.add("\"violationMsg\" : \"Trigger " + moveTrigger1 + " violated");      // violation in ETL queue      errCaptureExpect.add("\"violationMsg\" : \"Trigger " + killTrigger + " violated");      errCaptureExpect.add("\"subscribedCounters\" : [ \"HDFS_BYTES_READ\" \"HDFS_BYTES_WRITTEN\" ]");      errCaptureExpect.add("Event: GET Pool: BI Cluster %: 80.00");      errCaptureExpect.add("Event: MOVE Pool: ETL Cluster %: 20.00");      errCaptureExpect.add("Event: KILL Pool: null Cluster %: 0.00");      errCaptureExpect.add("Event: RETURN Pool: null Cluster %: 0.00");      runQueryWithTrigger(query setCmds killTrigger + " violated" errCaptureExpect);    } 
Hive,WITHOUT_CLASSIFICATION,//  in recent hadoop versions use deleteOnExit to clean tmp files. 
Hive,WITHOUT_CLASSIFICATION,//  the remainder. 
Hive,WITHOUT_CLASSIFICATION,//  Generate all expressions from lateral view 
Hive,WITHOUT_CLASSIFICATION,//  STATUS 
Hive,WITHOUT_CLASSIFICATION,//  should be either SELECT or SELECT DISTINCT 
Hive,WITHOUT_CLASSIFICATION,//  jc is effectively final but it has to be volatile since it's accessed by different 
Hive,WITHOUT_CLASSIFICATION,//  a concatenation of dbname tablename and partition keyvalues. 
Hive,WITHOUT_CLASSIFICATION,//  production is: struct this.name { FieldList() } 
Hive,WITHOUT_CLASSIFICATION,//  Ensure task1 is preempted based on time (match it's allocated containerId) 
Hive,WITHOUT_CLASSIFICATION,//  using init(..) instead of this(..) because the EventUtils.getDbTblNotificationFilter   is an operation that needs to run before delegating to the other ctor and this messes up chaining   ctors 
Hive,WITHOUT_CLASSIFICATION,//  if UDAFs are present new columns needs to be added 
Hive,WITHOUT_CLASSIFICATION,//  Signature restriction to NSOE and NSOE being a flat exception prevents us from   setting the cause of the NSOE as the MetaException. We should not lose the info   we got here but it's very likely that the MetaException is irrelevant and is   actually an NSOE message so we should log it and throw an NSOE with the msg. 
Hive,WITHOUT_CLASSIFICATION,// use the UGI object that got added 
Hive,WITHOUT_CLASSIFICATION,//  NUM_NULLS 
Hive,WITHOUT_CLASSIFICATION,//  Lets try to store original column name if this column got folded   This is useful for optimizations like GroupByOptimizer 
Hive,WITHOUT_CLASSIFICATION,//  set the new hive-site.xml 
Hive,WITHOUT_CLASSIFICATION,//  1. Insert MapSide GB 
Hive,WITHOUT_CLASSIFICATION,//  Drain any calls which may have come in during the last execution of the loop. 
Hive,WITHOUT_CLASSIFICATION,/*      * Handling of SubQuery Expressions:     * if "Where clause contains no SubQuery expressions" then     *   -->[true] ===CONTINUE_FILTER_PROCESSING===     * else     *   -->[false] "extract SubQuery expressions\n from Where clause"     *   if "this is a nested SubQuery or \nthere are more than 1 SubQuery expressions" then     *     -->[yes] "throw Unsupported Error"     *   else     *     --> "Rewrite Search condition to \nremove SubQuery predicate"     *      --> "build QBSubQuery"     *        --> "extract correlated predicates \nfrom Where Clause"     *        --> "add correlated Items to \nSelect List and Group By"     *        --> "construct Join Predicate \nfrom correlation predicates"     *     --> "Generate Plan for\n modified SubQuery"     *     --> "Build the Join Condition\n for Parent Query to SubQuery join"     *     --> "Build the QBJoinTree from the Join condition"     *     --> "Update Parent Query Filter\n with any Post Join conditions"     *     --> ===CONTINUE_FILTER_PROCESSING===     *   endif     * endif     *     * Support for Sub Queries in Having Clause:     * - By and large this works the same way as SubQueries in the Where Clause.     * - The one addum is the handling of aggregation expressions from the Outer Query     *   appearing in correlation clauses.     *   - So such correlating predicates are allowed:     *        min(OuterQuert.x) = SubQuery.y     *   - this requires special handling when converting to joins. See QBSubQuery.rewrite     *     method method for detailed comments.      */
Hive,WITHOUT_CLASSIFICATION,//  Operator with 2 children 
Hive,WITHOUT_CLASSIFICATION,//  No CRLF substitution -- return original line. 
Hive,WITHOUT_CLASSIFICATION,//  task is processed. 
Hive,WITHOUT_CLASSIFICATION,//  Copied from AcidUtils so we don't have to put the code using this into ql. 
Hive,WITHOUT_CLASSIFICATION,//  Tracks existing requests which are cycled through. 
Hive,WITHOUT_CLASSIFICATION,//  If a partition has been spilled to disk its size will be 0 i.e. it won't be picked 
Hive,WITHOUT_CLASSIFICATION,//  Evaluate the function result for each row in the partition 
Hive,WITHOUT_CLASSIFICATION,// TException 
Hive,WITHOUT_CLASSIFICATION,//  Create LFD even for MM CTAS - it's a no-op move but it still seems to be used for stats. 
Hive,WITHOUT_CLASSIFICATION,//  remove ending ';' 
Hive,WITHOUT_CLASSIFICATION,//  Create the reduce sink operator 
Hive,WITHOUT_CLASSIFICATION,//  column index stream type buffers 
Hive,WITHOUT_CLASSIFICATION,//  column is interpreted as the row key. 
Hive,WITHOUT_CLASSIFICATION,//  SortBy ASC 
Hive,WITHOUT_CLASSIFICATION,//  call-1: listLocatedStatus - mock:/mocktbl   call-2: check existence of side file for mock:/mocktbl/0_0   call-3: open - mock:/mocktbl/0_0   call-4: check existence of side file for  mock:/mocktbl/0_1 
Hive,WITHOUT_CLASSIFICATION,//  optional int32 app_attempt_number = 3; 
Hive,WITHOUT_CLASSIFICATION,//  make a clone of existing hive conf 
Hive,WITHOUT_CLASSIFICATION,//  supportsKeyTypes 
Hive,WITHOUT_CLASSIFICATION,//  Necessary to clean up the transaction in the db. 
Hive,WITHOUT_CLASSIFICATION,//  Use the UnparseTranslator to resolve unqualified table names. 
Hive,WITHOUT_CLASSIFICATION,//  No op. Shouldn't actually be called if it is the test will fail. 
Hive,WITHOUT_CLASSIFICATION,//  SSL support 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getClob(int)    */
Hive,WITHOUT_CLASSIFICATION,//  This is the initial state for a lock 
Hive,WITHOUT_CLASSIFICATION,//  See the class comment - HIF handles MM for all input formats so if we try to handle it   again in particular for the non-recursive originals-only getSplits call we will just   get confused. This bypass was not necessary when MM tables didn't support originals. Now   that they do we use this path for anything MM table related although everything except   the originals could still be handled by AcidUtils like a regular non-txn table. 
Hive,WITHOUT_CLASSIFICATION,//  CTAS; make the movetask's destination directory the table's destination. 
Hive,WITHOUT_CLASSIFICATION,//  check the root expression for final candidates 
Hive,WITHOUT_CLASSIFICATION,//  4. Now decompress (or copy) the data into cache buffers. 
Hive,WITHOUT_CLASSIFICATION,//  Step 2: Merge mapJoinTask into the Map-side of its child. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#executeQuery()    */
Hive,WITHOUT_CLASSIFICATION,//  Initializing a stats publisher 
Hive,WITHOUT_CLASSIFICATION,//  not come from the local branch 
Hive,WITHOUT_CLASSIFICATION,//  file for local 
Hive,WITHOUT_CLASSIFICATION,//  Verify the next write id 
Hive,WITHOUT_CLASSIFICATION,//  Repeating with other as nullable 
Hive,WITHOUT_CLASSIFICATION,//  the output of the CommonJoinOperator to the input columnInfo. 
Hive,WITHOUT_CLASSIFICATION,//  Our limit is max precision integer digits + "leading" zeros below the dot.   E.g. 0.00021 has 3 zeroes below the dot.   
Hive,WITHOUT_CLASSIFICATION,//  Re-run constant propagation so we fold any new constants introduced by the operator optimizers 
Hive,WITHOUT_CLASSIFICATION,//  Request task2 (task1 already started at previously set time) 
Hive,WITHOUT_CLASSIFICATION,//  Run the cleaner thread when the cache is maxFull% full 
Hive,WITHOUT_CLASSIFICATION,//  trim the trailing "" 
Hive,WITHOUT_CLASSIFICATION,//  no locality-requested randomly pick a node containing free slots 
Hive,WITHOUT_CLASSIFICATION,//  And UDF 
Hive,WITHOUT_CLASSIFICATION,//  default return the urlParam passed in as-is. 
Hive,WITHOUT_CLASSIFICATION,//  ORC files can be converted to full acid transactional tables 
Hive,WITHOUT_CLASSIFICATION,//  Tests for dropPartition(String db_name String tbl_name List<String> part_vals   boolean deleteData) method 
Hive,WITHOUT_CLASSIFICATION,//  LATIN SMALL LETTER S WITH HOOK U+0282 (2 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  remove the table folder 
Hive,WITHOUT_CLASSIFICATION,//  point (old releases) 
Hive,WITHOUT_CLASSIFICATION,//  Add root Tasks to runnable 
Hive,WITHOUT_CLASSIFICATION,//  2^(56 + 56) 
Hive,WITHOUT_CLASSIFICATION,//  Remains to copy from current read buffer. Less than wbSize by def. 
Hive,WITHOUT_CLASSIFICATION,//  LOCATION 
Hive,WITHOUT_CLASSIFICATION,//  To make sure host/port pair is valid the status of the location   does not matter 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#executeQuery(java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  Here we just reuse the THREAD_COUNT configuration for   METASTORE_FS_HANDLER_THREADS_COUNT since this results in better performance   The number of missing partitions discovered are later added by metastore using a   threadpool of size METASTORE_FS_HANDLER_THREADS_COUNT. If we have different sized   pool here the smaller sized pool of the two becomes a bottleneck 
Hive,WITHOUT_CLASSIFICATION,//  You can blame this on Owen. 
Hive,WITHOUT_CLASSIFICATION,//  If the table could not cached due to memory limit stop prewarm 
Hive,WITHOUT_CLASSIFICATION,//  Create the batch we will use to return data for this RG. 
Hive,WITHOUT_CLASSIFICATION,//  foo >= 'f' 
Hive,WITHOUT_CLASSIFICATION,//  The master thread and various workers. 
Hive,WITHOUT_CLASSIFICATION,//  long colulmn   text column 
Hive,WITHOUT_CLASSIFICATION,//  has NOT keyword 
Hive,WITHOUT_CLASSIFICATION,//  Avoid "/tmp" directories closer to "/" 
Hive,WITHOUT_CLASSIFICATION,//  And got a duck. 
Hive,WITHOUT_CLASSIFICATION,//  Create the work for moving the table 
Hive,WITHOUT_CLASSIFICATION,//  efficiently add computed values to the last batch of a group key. 
Hive,WITHOUT_CLASSIFICATION,//  how many jobs have been started 
Hive,WITHOUT_CLASSIFICATION,//  We don't do proper overlap checking because it would cost cycles and we   think it will never happen. We do perform the most basic check here. 
Hive,WITHOUT_CLASSIFICATION,//  by default assume no filter tag so we are good 
Hive,WITHOUT_CLASSIFICATION,//  Reset database location. 
Hive,WITHOUT_CLASSIFICATION,/*          * The partition columns are set once for the partition and are marked repeating.          */
Hive,WITHOUT_CLASSIFICATION,//  Align the THEN/ELSE types. 
Hive,WITHOUT_CLASSIFICATION,/*    * A task and its child task has been converted from join to mapjoin.   * See if the two tasks can be merged.    */
Hive,WITHOUT_CLASSIFICATION,//  test double->double version 
Hive,WITHOUT_CLASSIFICATION,// these 2 values are equal when TXN entry is made.  Should never be equal after 1st heartbeat which we 
Hive,WITHOUT_CLASSIFICATION,/*  But that will be specific to hdfs. Through storagehandler mechanism    */
Hive,WITHOUT_CLASSIFICATION,//  Methods to set/reset getNextNotification modifier 
Hive,WITHOUT_CLASSIFICATION,//  construct value table Desc 
Hive,WITHOUT_CLASSIFICATION,//  any exact match? 
Hive,WITHOUT_CLASSIFICATION,//  Repl policy should be created based on the table name in context. 
Hive,WITHOUT_CLASSIFICATION,//  this depends on o 
Hive,WITHOUT_CLASSIFICATION,//  6. Add Schema(RR) to RelNode-Schema map 
Hive,WITHOUT_CLASSIFICATION,//  We don't check explicit pool match for apps; both are specified on the jdbc string 
Hive,WITHOUT_CLASSIFICATION,//  We always return something from getAclForPath so this should not happen. 
Hive,WITHOUT_CLASSIFICATION,//  No boolean value match for 5 char field. 
Hive,WITHOUT_CLASSIFICATION,//  3. Insert RS on reduce side with Reduce side GB as input 
Hive,WITHOUT_CLASSIFICATION,//  if it is a dynamic partition throw the exception 
Hive,WITHOUT_CLASSIFICATION,//  add the move task for those partitions that do not need merging 
Hive,WITHOUT_CLASSIFICATION,//  Extract partition desc from sorted map (ascending order of part dir) 
Hive,WITHOUT_CLASSIFICATION,//  1) The timestamp column 
Hive,WITHOUT_CLASSIFICATION,//  split[0] = DP split[1] = LB 
Hive,WITHOUT_CLASSIFICATION,//  Class variables 
Hive,WITHOUT_CLASSIFICATION,//  container 
Hive,WITHOUT_CLASSIFICATION,//  Use only 1 reducer in case of cartesian product 
Hive,WITHOUT_CLASSIFICATION,//  add jars as we find them to a map of contents jar name so that we can   avoid 
Hive,WITHOUT_CLASSIFICATION,//  generate a DDL task and make it a dependent task of the leaf 
Hive,WITHOUT_CLASSIFICATION,//  Limit to milliseconds only... 
Hive,WITHOUT_CLASSIFICATION,//  MapJoinOperator 
Hive,WITHOUT_CLASSIFICATION,//  Make sure it doesn't already exist 
Hive,WITHOUT_CLASSIFICATION,//  Convert non-skewed table to skewed table. 
Hive,WITHOUT_CLASSIFICATION,//  The last field:       single_value(true) 
Hive,WITHOUT_CLASSIFICATION,//  Remove table entry from SessionState 
Hive,WITHOUT_CLASSIFICATION,//  ////// 2. Generate GroupbyOperator 
Hive,WITHOUT_CLASSIFICATION,//  Test that listPartitionsByFilter() throws HCatException if the partition-key is incorrect. 
Hive,WITHOUT_CLASSIFICATION,//  COMPLEX pattern 
Hive,WITHOUT_CLASSIFICATION,//  4. Construct AggInfo 
Hive,WITHOUT_CLASSIFICATION,// We use partition schema properties to set the partition descriptor properties   if usePartSchemaProperties is set to true. 
Hive,WITHOUT_CLASSIFICATION,//  get the semijoin rhs table name and field name 
Hive,WITHOUT_CLASSIFICATION,//  all column names referenced including virtual columns. used in ColumnAccessAnalyzer 
Hive,WITHOUT_CLASSIFICATION,//  See FastHiveDecimalImpl for more details on these fields. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure nothing escapes this run method and kills the metastore at large 
Hive,WITHOUT_CLASSIFICATION,//  The update fails because the task has terminated on the node. 
Hive,WITHOUT_CLASSIFICATION,//  Some Spark plans cause Hash and other modes to get this.  So ignore it. 
Hive,WITHOUT_CLASSIFICATION,//  inputSplitInfo = MRInputHelpers.generateInputSplitsToMem(jobConf false 0); 
Hive,WITHOUT_CLASSIFICATION,//  sending out status/DONE/KILLED/FAILED messages before TAImpl knows how to handle them. 
Hive,WITHOUT_CLASSIFICATION,//  (will need to handle an alternate work-dir as well in this case - derive from branch?) 
Hive,WITHOUT_CLASSIFICATION,// since we have an open transaction only 4 values above are expected  
Hive,WITHOUT_CLASSIFICATION,//  Just the primitive types. 
Hive,WITHOUT_CLASSIFICATION,//  Cannot simplify we bail out 
Hive,WITHOUT_CLASSIFICATION,//  Evaluator results are first. 
Hive,WITHOUT_CLASSIFICATION,//  Get the column / table aliases from the expression. Start from 1 as   0 is the TOK_FUNCTION 
Hive,WITHOUT_CLASSIFICATION,//  1. Gather GB Expressions (AST) (GB + Aggregations) 
Hive,WITHOUT_CLASSIFICATION,/*  * Directly deserialize with the caller reading field-by-field the LazyBinary serialization format. * * The caller is responsible for calling the read method for the right type of each field * (after calling readNextField). * * Reading some fields require a results object to receive value information.  A separate * results object is created by the caller at initialization per different field even for the same * type. * * Some type values are by reference to either bytes in the deserialization buffer or to * other type specific buffers.  So those references are only valid until the next time set is * called.  */
Hive,WITHOUT_CLASSIFICATION,//  if the columns in row schema is not contained in column   expression map then those are the aggregate columns that   are added GBY operator. we will estimate the column statistics   for those newly added columns 
Hive,WITHOUT_CLASSIFICATION,//  Check that the correlated variables referenced in these 
Hive,WITHOUT_CLASSIFICATION,//  This ensures the incremental dump doesn't get all events for replication. 
Hive,WITHOUT_CLASSIFICATION,// not relevant - creating new partition 
Hive,WITHOUT_CLASSIFICATION,//  For outer join remember our input rows before ON expression filtering or before   hash table matching so we can generate results for all rows (matching and non matching) 
Hive,WITHOUT_CLASSIFICATION,//  dummyOps is a reference to all the HashTableDummy operators in the   plan. These have to be separately initialized when we setup a task.   Their function is mainly as root ops to give the mapjoin the correct 
Hive,WITHOUT_CLASSIFICATION,//  and if necessary load the JARs in this thread. 
Hive,WITHOUT_CLASSIFICATION,//  NEW TAI LUE LETTER HIGH LA U+199C (3 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  determine which input rel oldOrdinal references and adjust   oldOrdinal to be relative to that input rel 
Hive,WITHOUT_CLASSIFICATION,//  not selected 
Hive,WITHOUT_CLASSIFICATION,//  expected exception due to lexer error 
Hive,WITHOUT_CLASSIFICATION,//  Jump to the field we want and read it. 
Hive,WITHOUT_CLASSIFICATION,//  used by Windowing 
Hive,WITHOUT_CLASSIFICATION,//  Look for hive-site.xml on the CLASSPATH and log its location if found. 
Hive,WITHOUT_CLASSIFICATION,//  Want to start sufficiently "high" enough in the iterator stack 
Hive,WITHOUT_CLASSIFICATION,//  an array of partitions holding the triplets   total number of small table rows in memory   the max memory limit that can be allocated   the actual memory used   row size of the small table   whether there's any spilled partition   the partition into which to spill the big table row; 
Hive,WITHOUT_CLASSIFICATION,//  remove filterMap for outer alias if filter is not exist on that 
Hive,WITHOUT_CLASSIFICATION,/*    * Check that SubQuery is a top level conjuncts.   * Remove it from the Where Clause AST.    */
Hive,WITHOUT_CLASSIFICATION,//  Check if the parent is coming from a table scan if so what is the version of it. 
Hive,WITHOUT_CLASSIFICATION,//  for each joining table set dir for big key and small keys properly 
Hive,WITHOUT_CLASSIFICATION,//  Figure out who we should run the file operations as 
Hive,WITHOUT_CLASSIFICATION,//  Calcite literal is in millis we need to convert to seconds 
Hive,WITHOUT_CLASSIFICATION,//  create a new  MapredLocalWork 
Hive,WITHOUT_CLASSIFICATION,//  -1 indicates malformed version. 
Hive,WITHOUT_CLASSIFICATION,//  To support nested column pruning we need to track the path from the top to the nested 
Hive,WITHOUT_CLASSIFICATION,//  hash-based aggregations 
Hive,WITHOUT_CLASSIFICATION,/*        * Restriction.1.h :: SubQueries only supported in the SQL Where Clause.        */
Hive,WITHOUT_CLASSIFICATION,//  if the table is in a different dfs than the partition   replace the partition's dfs with the table's dfs. 
Hive,WITHOUT_CLASSIFICATION,// Class.forName().newInstance() does not work if the underlying  InputSplit has package visibility 
Hive,WITHOUT_CLASSIFICATION,//  common class between char/varchar is string? 
Hive,WITHOUT_CLASSIFICATION,// We don't want to not exit because of an issue with logging 
Hive,WITHOUT_CLASSIFICATION,// updates p=1/q=3  deletes from p=1/q=2 p=2/q=2  insert p=1/q=2 p=1/q=3 and new part 1/1 
Hive,WITHOUT_CLASSIFICATION,//  v[2] 
Hive,WITHOUT_CLASSIFICATION,//  Http transport mode.   We set the thread local proxy username in ThriftHttpServlet. 
Hive,WITHOUT_CLASSIFICATION,//  hive native 
Hive,WITHOUT_CLASSIFICATION,//  Infer sort columns from operator tree 
Hive,WITHOUT_CLASSIFICATION,//  long IN 
Hive,WITHOUT_CLASSIFICATION,// complete 1st txn 
Hive,WITHOUT_CLASSIFICATION,//  Leading spaces 
Hive,WITHOUT_CLASSIFICATION,//  one VInt without nanos 
Hive,WITHOUT_CLASSIFICATION,/*  Routines for stubbing into Writables  */
Hive,WITHOUT_CLASSIFICATION,//  ExecDriver has no plan path so we cannot derive VRB stuff for the wrapper. 
Hive,WITHOUT_CLASSIFICATION,//  copy the properties from storageHandler to jobProperties 
Hive,WITHOUT_CLASSIFICATION,//  should never be executed 
Hive,WITHOUT_CLASSIFICATION,//  1) Replace INSERT OVERWRITE by INSERT 
Hive,WITHOUT_CLASSIFICATION,//  I32_VALUE 
Hive,WITHOUT_CLASSIFICATION,//  For example in the case of "select * from V join T ..." T would be direct dependency 
Hive,WITHOUT_CLASSIFICATION,//  check compatibility with subsequent files 
Hive,WITHOUT_CLASSIFICATION,//  Return false otherwise 
Hive,WITHOUT_CLASSIFICATION,//  We killed something but still got rejected. Wait a bit to give a chance to our   previous victim to actually die. 
Hive,WITHOUT_CLASSIFICATION,/*      * Setup the OI based on the:     * - Input TableDef's columns     * - the Window Functions.      */
Hive,WITHOUT_CLASSIFICATION,//  If we reached here we did not find a replication   spec in the node or its immediate children. Defaults   are to pretend replication is not happening and the   statement above is running as-is. 
Hive,WITHOUT_CLASSIFICATION,//  Change to new table and append stats for the new table 
Hive,WITHOUT_CLASSIFICATION,//  Kryo will set this; or so we hope. 
Hive,WITHOUT_CLASSIFICATION,//  If the newPosition is the same as the previousPosition we've reached the end of the   binary search if the new position at least as big as the size of the split any 
Hive,WITHOUT_CLASSIFICATION,// origPathStr="hdfs://host:99" for example 
Hive,WITHOUT_CLASSIFICATION,//  select is UDTF 
Hive,WITHOUT_CLASSIFICATION,//  delete the parent temp directory of all custom dynamic partitions 
Hive,WITHOUT_CLASSIFICATION,//  this is best effort optimization bail out in error conditions and   try generate and execute slower plan 
Hive,WITHOUT_CLASSIFICATION,//  Column Types of all partitioned columns.  Used for generating partition specification 
Hive,WITHOUT_CLASSIFICATION,//  The fifth could be combined again. 
Hive,WITHOUT_CLASSIFICATION,//  12. Save state for future iterations. 
Hive,WITHOUT_CLASSIFICATION,//  The buffer can only be removed after the removed flag has been set. If we are able to   lock it here noone can set the removed flag and thus remove it. That would also mean   that the header is not free and noone will touch the header either. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setBlob(int java.sql.Blob)    */
Hive,WITHOUT_CLASSIFICATION,//               partitionCols.add(schema.getName()); 
Hive,WITHOUT_CLASSIFICATION,//  Don't log the exception people just get confused. 
Hive,WITHOUT_CLASSIFICATION,//  if its not an internal name this is what we want. 
Hive,WITHOUT_CLASSIFICATION,//  We will adjust start and end so that we could record the metrics; save the originals. 
Hive,WITHOUT_CLASSIFICATION,//  Prevent excessive logging in case of deadlocks or slowness. 
Hive,WITHOUT_CLASSIFICATION,//  Allow implicit String to Date conversion 
Hive,WITHOUT_CLASSIFICATION,//  close the underlying connection pool to avoid leaks 
Hive,WITHOUT_CLASSIFICATION,//  v[8] -- since left integer #5 is always 0 some products here are not included. 
Hive,WITHOUT_CLASSIFICATION,//  write byte to say whether to skip pruning or not 
Hive,WITHOUT_CLASSIFICATION,//  That Union[T NULL] is converted to just T within a Map 
Hive,WITHOUT_CLASSIFICATION,//  Tracks HiveQueryId by QueryIdentifier. This can only be set when config is parsed in TezProcessor.   all the other existing code passes queryId equal to 0 everywhere.   If we switch the runtime and move to parsing the payload in the AM - the actual hive queryId could 
Hive,WITHOUT_CLASSIFICATION,//  make right a child of left 
Hive,WITHOUT_CLASSIFICATION,//  Tests for Partition appendPartition(String tableName String dbName List<String> partVals) method 
Hive,WITHOUT_CLASSIFICATION,//  SCHEMA_GROUP 
Hive,WITHOUT_CLASSIFICATION,//  locality information before those without locality information 
Hive,WITHOUT_CLASSIFICATION,//  Test basic right trim and truncate to vector. 
Hive,WITHOUT_CLASSIFICATION,//  check if map side aggregation is possible or not based on column stats 
Hive,WITHOUT_CLASSIFICATION,//  Vectorization enabled 
Hive,WITHOUT_CLASSIFICATION,//  Collect operator to observe the output of the script 
Hive,WITHOUT_CLASSIFICATION,//  UDTF 
Hive,WITHOUT_CLASSIFICATION,//  we've already set this one up. Need to clone for the next work. 
Hive,WITHOUT_CLASSIFICATION,//  ZooKeeper property name to pick the correct JAAS conf section 
Hive,WITHOUT_CLASSIFICATION,//  body 
Hive,WITHOUT_CLASSIFICATION,//  newOutput is the index of the cor var in the referenced   position list plus the offset of referenced position list of 
Hive,WITHOUT_CLASSIFICATION,/*  Convert an integer value representing a timestamp in nanoseconds to one   * that represents a timestamp in seconds with fraction since the epoch.    */
Hive,WITHOUT_CLASSIFICATION,//  position in file where the first row in this block starts 
Hive,WITHOUT_CLASSIFICATION,//  there should be no adjustments for leap seconds 
Hive,WITHOUT_CLASSIFICATION,//  FIFO policy doesn't care. 
Hive,WITHOUT_CLASSIFICATION,//  Note this behavior may have to change if we ever implement a vectorized merge join 
Hive,WITHOUT_CLASSIFICATION,//  LOG.debug("VectorMapJoinFastLongHashTable add key " + key + " slot " + slot + " pairIndex " + pairIndex + " empty slot (i = " + i + ")"); 
Hive,WITHOUT_CLASSIFICATION,//  We keep the columns only the columns that are part of the final output 
Hive,WITHOUT_CLASSIFICATION,//  Verify mergeOnlyTask is NOT optimized 
Hive,WITHOUT_CLASSIFICATION,//  Bail out nothing to do 
Hive,WITHOUT_CLASSIFICATION,//  if it is not an external table then create one 
Hive,WITHOUT_CLASSIFICATION,//  2.1 Construct JoinLeafPredicateInfo 
Hive,WITHOUT_CLASSIFICATION,//  first change the filter condition into a join condition 
Hive,WITHOUT_CLASSIFICATION,//  no need to make a metastore call 
Hive,WITHOUT_CLASSIFICATION,/*          * Don't drop NOTIFICATION_LOG SEQUENCE_TABLE and NOTIFICATION_SEQUENCE as its used by other         * table which are not txn related to generate primary key. So if these tables are dropped         *  and other tables are not dropped then it will create key duplicate error while inserting         *  to other table.          */
Hive,WITHOUT_CLASSIFICATION,//  Division with overflow/zero-divide check. Error produces NULL output. 
Hive,WITHOUT_CLASSIFICATION,//  Create a FileSinkOperator for the file name of taskTmpDir 
Hive,WITHOUT_CLASSIFICATION,/*    *    VectorAggregateExpression()   *    VectorAggregateExpression(VectorAggregationDesc vecAggrDesc)   *   *    AggregationBuffer getNewAggregationBuffer()   *    void aggregateInput(AggregationBuffer agg VectorizedRowBatch unit)   *    void aggregateInputSelection(VectorAggregationBufferRow[] aggregationBufferSets   *                int aggregateIndex VectorizedRowBatch vrg)   *    void reset(AggregationBuffer agg)   *    long getAggregationBufferFixedSize()   *   *    boolean matches(String name ColumnVector.Type inputColVectorType   *                ColumnVector.Type outputColVectorType Mode mode)   *    assignRowColumn(VectorizedRowBatch batch int batchIndex int columnNum   *                AggregationBuffer agg)   *    */
Hive,WITHOUT_CLASSIFICATION,//  This is called either with an error that was queued or an error that was set into the   atomic reference in this class. The latter is best-effort and is used to opportunistically   skip processing of a long queue when the error happens. 
Hive,WITHOUT_CLASSIFICATION,//  Check for aborted txns 
Hive,WITHOUT_CLASSIFICATION,// make sure they are the same before and after compaction 
Hive,WITHOUT_CLASSIFICATION,//  NOTE:      and power = -3 is multiply by 10^-3 
Hive,WITHOUT_CLASSIFICATION,//  Setting success to false to make sure that if the listener fails rollback happens. 
Hive,WITHOUT_CLASSIFICATION,//  TODO factor security manager into pipeline   TODO factor out encode/decode to permit binary shuffle   TODO factor out decode of index to permit alt. models 
Hive,WITHOUT_CLASSIFICATION,//  Check for a nested message. If found set the schema else return. 
Hive,WITHOUT_CLASSIFICATION,//  ANALYZE TABLE T [PARTITION (...)] COMPUTE STATISTICS;   The plan consists of a simple MapRedTask followed by a StatsTask.   The MR task is just a simple TableScanOperator 
Hive,WITHOUT_CLASSIFICATION,//  Refering to SQLOperation.java there is no chance that a HiveSQLException throws and the   async background operation submits to thread pool successfully at the same time. So Cleanup   opHandle directly when got HiveSQLException 
Hive,WITHOUT_CLASSIFICATION,// todo: define groups in regex and use parseInt(Matcher.group(2)).... 
Hive,WITHOUT_CLASSIFICATION,//  2) We propagate 
Hive,WITHOUT_CLASSIFICATION,//  usually controlled by bucketing 
Hive,WITHOUT_CLASSIFICATION,/*  Private constructor  */
Hive,WITHOUT_CLASSIFICATION,/*  * The interface adds the single long key hash multi-set contains method.  */
Hive,WITHOUT_CLASSIFICATION,//  write the plan out 
Hive,WITHOUT_CLASSIFICATION,//  test for CHAR type 
Hive,WITHOUT_CLASSIFICATION,//  request and validate the request cookies. 
Hive,WITHOUT_CLASSIFICATION,// Test that changing column data type fails 
Hive,WITHOUT_CLASSIFICATION,//  References to external fields for async SplitInfo generation. 
Hive,WITHOUT_CLASSIFICATION,//  1. Get Select Expression List 
Hive,WITHOUT_CLASSIFICATION,//  Case when this is an expression 
Hive,WITHOUT_CLASSIFICATION,//  outputRel is the generated augmented select with extra unselected 
Hive,WITHOUT_CLASSIFICATION,/*      * initialize Event Processor and dispatcher.      */
Hive,WITHOUT_CLASSIFICATION,//  1. Get the constant value associated with the current element in the struct. 
Hive,WITHOUT_CLASSIFICATION,//  "successful". 
Hive,WITHOUT_CLASSIFICATION,//  for HashMap 
Hive,WITHOUT_CLASSIFICATION,//  Some of the columns' stats are missing   This implies partition schema has changed. We will merge columns   present in both overwrite stats for columns absent in metastore and   leave alone columns stats missing from stats task. This last case may   leave stats in stale state. This will be addressed later. 
Hive,WITHOUT_CLASSIFICATION,//  Clone all the operators between union and filescan and push them above   the union. Remove the union (the tree below union gets delinked after that) 
Hive,WITHOUT_CLASSIFICATION,//  The wait queue should be able to fit at least (waitQueue + currentFreeExecutor slots) 
Hive,WITHOUT_CLASSIFICATION,// no point making an acid table if these other props are not set since it will just throw  exceptions when someone tries to use the table. 
Hive,WITHOUT_CLASSIFICATION,//  mGby3 is a follow up of mGby2. Here we start to count(key). 
Hive,WITHOUT_CLASSIFICATION,//  Not registered for this node.   Register and send state if it is successful. 
Hive,WITHOUT_CLASSIFICATION,// give me more 
Hive,WITHOUT_CLASSIFICATION,//  Create partition 
Hive,WITHOUT_CLASSIFICATION,//  collect the newly added partitions. connection.commitTransaction() will report the dynamically added   partitions to TxnHandler 
Hive,WITHOUT_CLASSIFICATION,//  2. Based on the statement generate the selectOperator 
Hive,WITHOUT_CLASSIFICATION,// found parent mapjoin operator.  Its size should already reflect any other mapjoins connected to it. 
Hive,WITHOUT_CLASSIFICATION,//  Total rows to emit during the whole iteration   excluding the rows emitted by the separate thread. 
Hive,WITHOUT_CLASSIFICATION,//  DELETE_DATA 
Hive,WITHOUT_CLASSIFICATION,//  This test assumes the hive-contrib JAR has been built as part of the Hive build. 
Hive,WITHOUT_CLASSIFICATION,//  Collect table access keys information for operators that can benefit from bucketing 
Hive,WITHOUT_CLASSIFICATION,// Verify 
Hive,WITHOUT_CLASSIFICATION,//  If the predicate matches then return true.   Otherwise visit the next set of nodes that haven't been seen. 
Hive,WITHOUT_CLASSIFICATION,//  We require the use of recursive input dirs for union processing 
Hive,WITHOUT_CLASSIFICATION,//  should have severed the ties 
Hive,WITHOUT_CLASSIFICATION,//  Multiply by 1/2^56 or 1.387778780781445675529539585113525390625e-17 to divide by 2^56.   As 16 digit comma'd 1387778780781445675529539585113525390625     Scale down: 56 = 39 fraction digits + 17 (negative exponent or number of zeros after dot).     3*16 (48) + 8 --> 56 down shift. 
Hive,WITHOUT_CLASSIFICATION,//  Log and ignore 
Hive,WITHOUT_CLASSIFICATION,//  verify that the number of events since we began is at least 25 more 
Hive,WITHOUT_CLASSIFICATION,//  the master thread. 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: The current implementation does not allow importing to an "EXTERNAL" location.   This is intentional since we want the destination tables to be "managed" tables.   If this assumption should change at some point in the future ImportSemanticAnalyzer   will need some of its checks changed to allow for "replacing" external tables. 
Hive,WITHOUT_CLASSIFICATION,//  Don't worry about setting raw data size diff.  I have no idea how to calculate that   without finding the row we are updating or deleting which would be a mess. 
Hive,WITHOUT_CLASSIFICATION,//  change the newly created map-red plan as if it was a join operator 
Hive,WITHOUT_CLASSIFICATION,//  check physical path 
Hive,WITHOUT_CLASSIFICATION,//  partition columns   virtual columns 
Hive,WITHOUT_CLASSIFICATION,//  Select all with the first expression and expect the other 2 children to not be invoked. 
Hive,WITHOUT_CLASSIFICATION,//  Read the record with the same record reader ID 
Hive,WITHOUT_CLASSIFICATION,//  If the group by expression is anything other than a list of columns 
Hive,WITHOUT_CLASSIFICATION,// if another thread adds an entry before the check in this one 
Hive,WITHOUT_CLASSIFICATION,//  This is required for writing null as key for file based tables. 
Hive,WITHOUT_CLASSIFICATION,//  struct<a:booleanb:double> 
Hive,WITHOUT_CLASSIFICATION,//  Do all checks on short names 
Hive,WITHOUT_CLASSIFICATION,//  Update sum length with the new length 
Hive,WITHOUT_CLASSIFICATION,//  if this is a replication spec then replace-mode semantics might apply.   if we're already asking for a table replacement then we can skip this check.   however otherwise if in replication scope and we've not been explicitly asked   to replace we should check if the object we're looking at exists and if so   trigger replace-mode semantics. 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: The reason we use a string name of the hive hbase handler here is   because we do not want to introduce a compile-dependency on the hive-hbase-handler   module from within hive-hcatalog.   This parameter was added due to the requirement in HIVE-7072 
Hive,WITHOUT_CLASSIFICATION,//  original path and not available in CM as well. 
Hive,WITHOUT_CLASSIFICATION,//  by the original MapredTask and this new generated MapredLocalTask. 
Hive,WITHOUT_CLASSIFICATION,//  Check the ndv/rows from the SEL vs the destination tablescan the semijoin opt is going to. 
Hive,WITHOUT_CLASSIFICATION,//  positive numbers flip just the first bit 
Hive,WITHOUT_CLASSIFICATION,//  build error message 
Hive,WITHOUT_CLASSIFICATION,/*      * input      */
Hive,WITHOUT_CLASSIFICATION,//  Schedule 3 tasks. Give out two ducks - two higher pri tasks get them. Give out 2 more   - the last task gets it and one duck is unused. Give out 2 more - goes to unused.   Then revoke similarly in steps (1 4 1) with the opposite effect. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#setTransactionIsolation(int)    */
Hive,WITHOUT_CLASSIFICATION,//  Drop table will clean the table entry from the compaction queue and hence worker have no effect 
Hive,WITHOUT_CLASSIFICATION,//  and finally we hook up any events that need to be sent to the tez AM 
Hive,WITHOUT_CLASSIFICATION,//                                12345678901234567890123456789012345678 
Hive,WITHOUT_CLASSIFICATION,//  merge 
Hive,WITHOUT_CLASSIFICATION,//  Tracks appMasters to which heartbeats are being sent. This should not be used for any other   messages like taskKilled etc. 
Hive,WITHOUT_CLASSIFICATION,// the jars in libJars will be localized to CWD of the launcher task; then -libjars will 
Hive,WITHOUT_CLASSIFICATION,//  Locks newRequestList   Locks completedNodes 
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.GetTokenResponseProto.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,//  If this is an insert update or delete on an ACID table then mark that so the 
Hive,WITHOUT_CLASSIFICATION,// since there is no tx we only have locks for current query (if any) 
Hive,WITHOUT_CLASSIFICATION,//  Set the mapjoin hint if it needs to be disabled. 
Hive,WITHOUT_CLASSIFICATION,//  Ignore. Not required as this will be never   serialized/deserialized. 
Hive,WITHOUT_CLASSIFICATION,//  user provided configs 
Hive,WITHOUT_CLASSIFICATION,//  this test 
Hive,WITHOUT_CLASSIFICATION,//  Ignore closing quote 
Hive,WITHOUT_CLASSIFICATION,//  Create the equality condition 
Hive,WITHOUT_CLASSIFICATION,//  add spark job metrics. - e.g. metrics collected by Spark itself (JvmGCTime 
Hive,WITHOUT_CLASSIFICATION,//  Boring scenario #2 - two concurrent revokes. Same as above. 
Hive,WITHOUT_CLASSIFICATION,/*  delete_delta_21_23 and delete_delta_25_33 which are created as a result of compacting */
Hive,WITHOUT_CLASSIFICATION,//  TODO: Now we assume the key Object supports hashCode and equals functions. 
Hive,WITHOUT_CLASSIFICATION,//  For information only. 
Hive,WITHOUT_CLASSIFICATION,//  Verify the accumulated logs 
Hive,WITHOUT_CLASSIFICATION,//  Get completed attempts 
Hive,WITHOUT_CLASSIFICATION,//  Update credential provider location   the password to the credential provider in already set in the sparkConf 
Hive,WITHOUT_CLASSIFICATION,//  Count the number of tasks and kill application if it goes beyond the limit. 
Hive,WITHOUT_CLASSIFICATION,//  create a the context for walking operators 
Hive,WITHOUT_CLASSIFICATION,/*  virtualColumnCount  */
Hive,WITHOUT_CLASSIFICATION,//  don't break old callers that are trying to reuse storages 
Hive,WITHOUT_CLASSIFICATION,// create 4 rows in a file 000000_0_copy_1 
Hive,WITHOUT_CLASSIFICATION,//  MY_ENUM 
Hive,WITHOUT_CLASSIFICATION,//  if there are no nulls then the iteration is the same on all cases 
Hive,WITHOUT_CLASSIFICATION,//  Add embedded rawstore so we can cleanup later to avoid memory leak 
Hive,WITHOUT_CLASSIFICATION,//  HIVE-19061 introduces UPDATE event which will capture changes to allocation % after GET 
Hive,WITHOUT_CLASSIFICATION,//  (if any) 
Hive,WITHOUT_CLASSIFICATION,//  Add a new table via ObjectStore 
Hive,WITHOUT_CLASSIFICATION,//  Try next available server in zookeeper or retry all the servers again if retry is enabled 
Hive,WITHOUT_CLASSIFICATION,//  Double 
Hive,WITHOUT_CLASSIFICATION,//  Drop a foreign key 
Hive,WITHOUT_CLASSIFICATION,//  Set if partition sorted or partition bucket sorted 
Hive,WITHOUT_CLASSIFICATION,//  Verbose Logs should contain everything including execution and performance 
Hive,WITHOUT_CLASSIFICATION,// so we don't accidentally cache the value; shouldn't 
Hive,WITHOUT_CLASSIFICATION,//  check most significant part first 
Hive,WITHOUT_CLASSIFICATION,//  Update value 
Hive,WITHOUT_CLASSIFICATION,//  number n of elements   average of x elements   average of y elements   n times the variance of x elements   n times the variance of y elements   n times the covariance 
Hive,WITHOUT_CLASSIFICATION,//  internal input format used by CombineHiveInputFormat 
Hive,WITHOUT_CLASSIFICATION,//  Test select pow(root.col1.b root.col2) from table test(root 
Hive,WITHOUT_CLASSIFICATION,//  If the code point from from string already has a replacement or is to be deleted we   don't need to do anything just move on to the next code point 
Hive,WITHOUT_CLASSIFICATION,// return true; 
Hive,WITHOUT_CLASSIFICATION,//  boolean to signal whether tagging will be used (e.g.: join) or 
Hive,WITHOUT_CLASSIFICATION,//  right repeats and is null 
Hive,WITHOUT_CLASSIFICATION,//  VRB was created from VrbCtx so we already have pre-allocated column vectors.   Return old CVs (if any) to caller. We assume these things all have the same schema. 
Hive,WITHOUT_CLASSIFICATION,//  handle the logical operators 
Hive,WITHOUT_CLASSIFICATION,//  no begin + commit 
Hive,WITHOUT_CLASSIFICATION,//  Use context.mapJoinParentMap to get the original RS parents because 
Hive,WITHOUT_CLASSIFICATION,//  There are some elements that were cached in parallel take care of them. 
Hive,WITHOUT_CLASSIFICATION,//  TABLE_NAME 
Hive,WITHOUT_CLASSIFICATION,//  which case stats need not be updated 
Hive,WITHOUT_CLASSIFICATION,// do not support task level progress do nothing here. 
Hive,WITHOUT_CLASSIFICATION,//  to hold output if needed   to hold boolean output 
Hive,WITHOUT_CLASSIFICATION,//  we are here either unpartitioned table or partitioned table with no   predicates 
Hive,WITHOUT_CLASSIFICATION,//  The arg is part of another list. 
Hive,WITHOUT_CLASSIFICATION,/*  Test decimal column to decimal scalar addition. This is used to cover all the   * cases used in the source code template ColumnArithmeticScalarDecimal.txt.    */
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   required   required   required   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  StorageDescriptor has an empty list of fields - SerDe will report them. 
Hive,WITHOUT_CLASSIFICATION,//  update service registry configs - caveat: this has nothing to do with the actual settings   as read by the AM   if needed use --hiveconf llap.daemon.service.hosts=@llap0 to dynamically switch between   instances 
Hive,WITHOUT_CLASSIFICATION,//  file dump should write to session state console's error stream 
Hive,WITHOUT_CLASSIFICATION,//  We need to obtain an intersection of all the privileges 
Hive,WITHOUT_CLASSIFICATION,//  min txn id is incremented linearly within a transaction batch. 
Hive,WITHOUT_CLASSIFICATION,/*  major version number should match for backward compatibility  */
Hive,WITHOUT_CLASSIFICATION,//  We need to check that datasource was not specified by user 
Hive,WITHOUT_CLASSIFICATION,//  add added files 
Hive,WITHOUT_CLASSIFICATION,//  5. Get Calcite Agg Fn 
Hive,WITHOUT_CLASSIFICATION,//  FOOTER_SUMMARY 
Hive,WITHOUT_CLASSIFICATION,//  http://svn.apache.org/viewvc/commons/proper/dbcp/branches/DBCP_1_4_x_BRANCH/doc/ManualPoolingDataSourceExample.java?view=markup 
Hive,WITHOUT_CLASSIFICATION,//  we always serialize the String type using the escaped algorithm for LazyString 
Hive,WITHOUT_CLASSIFICATION,// ---------------------------------------------------------------------------   Pass-thru constructors.   
Hive,WITHOUT_CLASSIFICATION,//  Should not be treated like it needs data. 
Hive,WITHOUT_CLASSIFICATION,//  skip one 
Hive,WITHOUT_CLASSIFICATION,//  The "most preemptable" task is still too important for us to kill. Put it back. 
Hive,WITHOUT_CLASSIFICATION,//  itself is missing then throw error. 
Hive,WITHOUT_CLASSIFICATION,//  Duplicate to avoid modification. 
Hive,WITHOUT_CLASSIFICATION,//  from IndexPredicateAnalyzer 
Hive,WITHOUT_CLASSIFICATION,/*        * Single-Column Long check for repeating.        */
Hive,WITHOUT_CLASSIFICATION,//  Use GLOBAL when no key for Reduce. 
Hive,WITHOUT_CLASSIFICATION,//  Uses all 3 decimal longs. 
Hive,WITHOUT_CLASSIFICATION,//  Handle MapJoin specially and check for all its children 
Hive,WITHOUT_CLASSIFICATION,//  setEntryValid() already increments the reader count. Set usedCacheEntry so it gets released. 
Hive,WITHOUT_CLASSIFICATION,//  is it a partitioned table ? 
Hive,WITHOUT_CLASSIFICATION,//  Not present 
Hive,WITHOUT_CLASSIFICATION,//  If partition already exists and we aren't overwriting it then respect   its current location info rather than picking it from the parent TableDesc 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:UpdateQueryRequestProto) 
Hive,WITHOUT_CLASSIFICATION,//  Must be a class. 
Hive,WITHOUT_CLASSIFICATION,//  Process partition pruning sinks 
Hive,WITHOUT_CLASSIFICATION,//  Get should fail now (since TTL is 2s) and we've snoozed for 3 seconds 
Hive,WITHOUT_CLASSIFICATION,//  Move the original parent directory to the intermediate original directory 
Hive,WITHOUT_CLASSIFICATION,//  This initializes currentFileRead. 
Hive,WITHOUT_CLASSIFICATION,//  Read single value. 
Hive,WITHOUT_CLASSIFICATION,//  handle repeating 
Hive,WITHOUT_CLASSIFICATION,//  If in test mod create a test log file which will contain only logs which are supposed to   be written to the qtest output 
Hive,WITHOUT_CLASSIFICATION,//  a new vertex. 
Hive,WITHOUT_CLASSIFICATION,//  While threads are blocked on A we should still be able to get and return a B session. 
Hive,WITHOUT_CLASSIFICATION,//  0 implies no limit 
Hive,WITHOUT_CLASSIFICATION,//  Choosing the 2nd function since the 1st one is duplicated in the dummy database 
Hive,WITHOUT_CLASSIFICATION,//  used by spark mode to decide whether global order is needed 
Hive,WITHOUT_CLASSIFICATION,//  Conf for non-llap 
Hive,WITHOUT_CLASSIFICATION,//  Location 
Hive,WITHOUT_CLASSIFICATION,//  convert constant back to RexNode 
Hive,WITHOUT_CLASSIFICATION,//  ACLs for znodes on a non-kerberized cluster   Create/Read/Delete/Write/Admin to the world 
Hive,WITHOUT_CLASSIFICATION,//  get all parents 
Hive,WITHOUT_CLASSIFICATION,/*  Valid FileSystem schemes  */
Hive,WITHOUT_CLASSIFICATION,//  now diff the lists 
Hive,WITHOUT_CLASSIFICATION,//  Is this a union type? 
Hive,WITHOUT_CLASSIFICATION,//  Project projects the original expressions 
Hive,WITHOUT_CLASSIFICATION,//  In non-strict mode and there is no predicates at all - get everything. 
Hive,WITHOUT_CLASSIFICATION,/*    * Creates a job request object and sets up execution environment. Creates a thread pool   * to execute job requests.   *   * @param requestType   *          Job request type   *   * @param concurrentRequestsConfigName   *          Config name to be used to extract number of concurrent requests to be serviced.   *   * @param jobTimeoutConfigName   *          Config name to be used to extract maximum time a task can execute a request.   *    */
Hive,WITHOUT_CLASSIFICATION,//    throw new HiveException("selected1 is not in sort order and unique");   } 
Hive,WITHOUT_CLASSIFICATION,//  don't visit multiple times 
Hive,WITHOUT_CLASSIFICATION,//  Remove old table object's sd hash 
Hive,WITHOUT_CLASSIFICATION,//  Don't attempt scheduling for additional priorities 
Hive,WITHOUT_CLASSIFICATION,//  Verify if entries added in COMPACTION_QUEUE for each table/partition 
Hive,WITHOUT_CLASSIFICATION,//  Specifically necessary for DPP because we might have created lots of "and true and true" conditions 
Hive,WITHOUT_CLASSIFICATION,//  6. Local session path 
Hive,WITHOUT_CLASSIFICATION,//  the sort and bucket cols have to match on both sides for this 
Hive,WITHOUT_CLASSIFICATION,//  with this root operator. 
Hive,WITHOUT_CLASSIFICATION,//  If the table is bucketed and bucketing is enforced do the following:   If the number of buckets is smaller than the number of maximum reducers   create those many reducers.   If not create a multiFileSink instead of FileSink - the multiFileSink will   spray the data into multiple buckets. That way we can support a very large   number of buckets without needing a very large number of reducers. 
Hive,WITHOUT_CLASSIFICATION,// keys.add(key);  would need a list of (stmtrs) pairs - 1 for each key 
Hive,WITHOUT_CLASSIFICATION,//  When the first buffer is loaded ResultSet.next() should be called "incrementalBufferRows" times 
Hive,WITHOUT_CLASSIFICATION,// 123 
Hive,WITHOUT_CLASSIFICATION,//  Groups the clause names into lists so that any two clauses in the same list has the same   group by and distinct keys and no clause appears in more than one list. Returns a list of the 
Hive,WITHOUT_CLASSIFICATION,//  We should be having a tree which looks like this    TS -> * -> RS -                    \                     -> JOIN -> ..                    /    TS -> * -> RS -     We are in the join operator now. 
Hive,WITHOUT_CLASSIFICATION,//  By the time either success / failed are called the task itself knows that it has terminated   and will ignore subsequent kill requests if they go out. 
Hive,WITHOUT_CLASSIFICATION,//  Close the session which should free up the TxnHandler/locks held by the session.   Done in the finally block to make sure we free up the locks; otherwise   the cleanup in tearDown() will get stuck waiting on the lock held here on ACIDTBL. 
Hive,WITHOUT_CLASSIFICATION,//  Spark property.   for now we don't support changing spark app name on the fly 
Hive,WITHOUT_CLASSIFICATION,//  if last batch is successful remove it from partsNotInFs 
Hive,WITHOUT_CLASSIFICATION,// update runtime 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#registerOutParameter(java.lang.String int   * int)    */
Hive,WITHOUT_CLASSIFICATION,//  one of the branches is definitely a bucket-leaf 
Hive,WITHOUT_CLASSIFICATION,//  open till limit but not exceed 
Hive,WITHOUT_CLASSIFICATION,//  Find the biggest small table; also calculate total data size of all small tables 
Hive,WITHOUT_CLASSIFICATION,/*    * Initialize using an StructObjectInspector and a column projection list.    */
Hive,WITHOUT_CLASSIFICATION,//  Avoids creating Tez Client sessions internally as it takes much longer currently 
Hive,WITHOUT_CLASSIFICATION,//  Handle the rejection outside of the lock 
Hive,WITHOUT_CLASSIFICATION,//  What we need is a way to get buckets not splits 
Hive,WITHOUT_CLASSIFICATION,//  WHERE clause and pick up the second disjunct from the OR operation. 
Hive,WITHOUT_CLASSIFICATION,//  object overhead + 8 bytes for intCompact + 4 bytes for precision   + 4 bytes for scale + size of BigInteger 
Hive,WITHOUT_CLASSIFICATION,//  Should initialize the value for createValue 
Hive,WITHOUT_CLASSIFICATION,//  more entries than oldInvalidIds. 
Hive,WITHOUT_CLASSIFICATION,//  separator 
Hive,WITHOUT_CLASSIFICATION,//  There will not be any Tez job above this task 
Hive,WITHOUT_CLASSIFICATION,//  forward as arg   forward as arg   forward as arg 
Hive,WITHOUT_CLASSIFICATION,//  enable assertion 
Hive,WITHOUT_CLASSIFICATION,// No big table candidates. 
Hive,WITHOUT_CLASSIFICATION,//  Invoke the InputFormat entrypoint 
Hive,WITHOUT_CLASSIFICATION,//  Not using expressions. 
Hive,WITHOUT_CLASSIFICATION,//  OR(=($0 1) AND(=($0 0) =($1 8)))   transformation creates 7 nodes AND(OR(=($0 1) =($0 0)) OR(=($0 1) =($1 8)))   thus it is triggered 
Hive,WITHOUT_CLASSIFICATION,//  from the original SparkWork 
Hive,WITHOUT_CLASSIFICATION,/*          * If this is a Not In SubQuery Predicate then Join in the Null Check SubQuery.         * See QBSubQuery.NotInCheck for details on why and how this is constructed.          */
Hive,WITHOUT_CLASSIFICATION,//  Vector reduce key (i.e. partition) columns are repeated -- so we test element 0. 
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.VertexOrBinary.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,//  If there's no memory available fail 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: Calling last flush length below is more for future-proofing when we have   streaming deletes. But currently we don't support streaming deletes and this can 
Hive,WITHOUT_CLASSIFICATION,//  use the columnNames to initialize the reusable row object and the columnBuffers. reason this is being done is if buffer is full we should reinitialize the 
Hive,WITHOUT_CLASSIFICATION,//  IndexStore is trying to tell us something. 
Hive,WITHOUT_CLASSIFICATION,//  MSD and SD should be same objects. Not sure how to make then same right now 
Hive,WITHOUT_CLASSIFICATION,//  "<expr>.FIELD" is constant iff "<expr>" is constant. 
Hive,WITHOUT_CLASSIFICATION,//  TODO HIVE-12255. Make use of SplitSizeEstimator.   The actual task computation needs to be looked at as well. 
Hive,WITHOUT_CLASSIFICATION,//  Failover didn't succeed - log error and exit 
Hive,WITHOUT_CLASSIFICATION,//  execute the setup queries 
Hive,WITHOUT_CLASSIFICATION,//  Try the output as a primitive object 
Hive,WITHOUT_CLASSIFICATION,//  Verify the buffer was reset (real output doesn't happen because it was mocked) 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#prepareCall(java.lang.String int int)    */
Hive,WITHOUT_CLASSIFICATION,//  double BETWEEN 
Hive,WITHOUT_CLASSIFICATION,//  for keeping track of the number of elements read. just for debugging 
Hive,WITHOUT_CLASSIFICATION,//    Special handling is needed at times for DATE TIMESTAMP (STRING) CHAR and VARCHAR so they can   be named specifically as argument types.     LongColumnVector -->      INT_FAMILY      DATE      INTERVAL_FAMILY     DoubleColumnVector -->      FLOAT_FAMILY     DecimalColumnVector -->      DECIMAL     BytesColumnVector -->      STRING      CHAR      VARCHAR     TimestampColumnVector -->      TIMESTAMP     IntervalDayTimeColumnVector -->      INTERVAL_DAY_TIME   
Hive,WITHOUT_CLASSIFICATION,//        created when the task is executed. So we don't care about the correct MM state here. 
Hive,WITHOUT_CLASSIFICATION,//  
Hive,WITHOUT_CLASSIFICATION,/*    * AddSplitsForGroup collects separate calls to setInputPaths into one where possible.   * The reason for this is that this is faster on some InputFormats. E.g.: Orc will start   * a threadpool to do the work and calling it multiple times unnecessarily will create a lot   * of unnecessary thread pools.    */
Hive,WITHOUT_CLASSIFICATION,//  Check if the table should be skipped. 
Hive,WITHOUT_CLASSIFICATION,// this is a leaf so add exportTask to follow it 
Hive,WITHOUT_CLASSIFICATION,//  use the same filesystem as input file if backup-path is not explicitly specified 
Hive,WITHOUT_CLASSIFICATION,//  Initialization fails with retry no resource plan change. 
Hive,WITHOUT_CLASSIFICATION,//  TODO: Key and Values are Object[] which can be eagerly deserialized or lazily deserialized. To accurately   estimate the entry size every possible Objects in Key Value should implement MemoryEstimate interface which   is very intrusive. So assuming default entry size here. 
Hive,WITHOUT_CLASSIFICATION,//  In tez we use a different way of transmitting the hash table.   We basically use ReduceSinkOperators and set the transfer to   be broadcast (instead of partitioned). As a consequence we use   a different SerDe than in the MR mapjoin case. 
Hive,WITHOUT_CLASSIFICATION,//  BEGIN pattern 
Hive,WITHOUT_CLASSIFICATION,//  an unique key of the filterInputRel 
Hive,WITHOUT_CLASSIFICATION,//  lookup the field corresponding to the given field ID and return 
Hive,WITHOUT_CLASSIFICATION,//  The dependencies should include V at depth 0 and T at depth 1 (inferred). 
Hive,WITHOUT_CLASSIFICATION,//  Locked by someone to move or force-evict.   Evicted. This is cache-specific.   Removed from allocator structures. The final state.   The memory was released to memory manager.   New allocation before the first use; cannot force-evict. 
Hive,WITHOUT_CLASSIFICATION,//  Only used in ACID writer. 
Hive,WITHOUT_CLASSIFICATION,/*    * The current version of jetty server doesn't have the status   * HttpStatus.TOO_MANY_REQUESTS_429. Hence passing this as constant.    */
Hive,WITHOUT_CLASSIFICATION,//  In milliseconds 
Hive,WITHOUT_CLASSIFICATION,//  not allocated yet 
Hive,WITHOUT_CLASSIFICATION,//  The following data members are only required to support the deprecated constructor (and builder). 
Hive,WITHOUT_CLASSIFICATION,//  for partial specifications we need partitions to follow the scheme 
Hive,WITHOUT_CLASSIFICATION,// we create FILTER (sq_count_check(count()) <= 1) instead of PROJECT because RelFieldTrimmer 
Hive,WITHOUT_CLASSIFICATION,//  assertEquals("course"Kfields.get(3).schema.getFields().get(0).schema.getFields().get(0).alias.toLowerCase());   commented out because the name becomes "innerfield" by default - we call it "course" in pig   but in the metadata it'd be anonymous so this would be autogenerated which is fine 
Hive,WITHOUT_CLASSIFICATION,/*    * In case of outer joins we need to push records through even if one of the sides is done   * sending records. For e.g. In the case of full outer join the right side needs to send in data   * for the join even after the left side has completed sending all the records on its side. This   * can be done once at initialize time and at close these tags will still forward records until   * they have no more to send. Also subsequent joins need to fetch their data as well since   * any join following the outer join could produce results with one of the outer sides depending on   * the join condition. We could optimize for the case of inner joins in the future here.    */
Hive,WITHOUT_CLASSIFICATION,// byte 
Hive,WITHOUT_CLASSIFICATION,//  required   required   optional   required 
Hive,WITHOUT_CLASSIFICATION,//  Full table name of format <db_name>.<table_name> 
Hive,WITHOUT_CLASSIFICATION,//  adding same property key twice should throw unique key constraint violation exception 
Hive,WITHOUT_CLASSIFICATION,//  Assume it is almost always a performance win to fill all of isNull so we can   safely reset noNulls. 
Hive,WITHOUT_CLASSIFICATION,//  if subquery is in FILTER 
Hive,WITHOUT_CLASSIFICATION,//  If pool didn't exist checkAndRemoveSessionFromItsPool wouldn't have returned OK. 
Hive,WITHOUT_CLASSIFICATION,//  and table the table is not sorted 
Hive,WITHOUT_CLASSIFICATION,//  ignore client only queries 
Hive,WITHOUT_CLASSIFICATION,//  Optimization: if the first child is file we have reached the leaf directory move the parent directory itself   instead of moving each file under the directory. See HCATALOG-538   Note for future Append implementation : This optimization is another reason dynamic   partitioning is currently incompatible with append on mutable tables. 
Hive,WITHOUT_CLASSIFICATION,//  For caching partition objects 
Hive,WITHOUT_CLASSIFICATION,//  change SerDe to LazySimpleSerDe if it is columnsetSerDe 
Hive,WITHOUT_CLASSIFICATION,//  Add uncovered ACID delta splits. 
Hive,WITHOUT_CLASSIFICATION,//  Use the basic STRING bytes read to get access then use our optimal truncate/trim method   that does not use Java String objects. 
Hive,WITHOUT_CLASSIFICATION,//  should be set by child class 
Hive,WITHOUT_CLASSIFICATION,//  Restore original state 
Hive,WITHOUT_CLASSIFICATION,//  Could not resolve all of the function children fail 
Hive,WITHOUT_CLASSIFICATION,//  everything ok. try normal shutdown 
Hive,WITHOUT_CLASSIFICATION,//  discard possibly type related sorting order and replace with alphabetical 
Hive,WITHOUT_CLASSIFICATION,//  all calls fail 
Hive,WITHOUT_CLASSIFICATION,//  validate the plan 
Hive,WITHOUT_CLASSIFICATION,//  NULLABLE   REMARKS   COLUMN_DEF   SQL_DATA_TYPE   SQL_DATETIME_SUB   CHAR_OCTET_LENGTH   ORDINAL_POSITION   IS_NULLABLE   SCOPE_CATALOG   SCOPE_SCHEMA   SCOPE_TABLE   SOURCE_DATA_TYPE   IS_AUTO_INCREMENT 
Hive,WITHOUT_CLASSIFICATION,//  handle the isNull array first in tight loops 
Hive,WITHOUT_CLASSIFICATION,// verify all scopes are closed. 
Hive,WITHOUT_CLASSIFICATION,//  ignore dummy inputs 
Hive,WITHOUT_CLASSIFICATION,//  Test if both are not configured 
Hive,WITHOUT_CLASSIFICATION,// add new column with no cascade option 
Hive,WITHOUT_CLASSIFICATION,//  -create- should not return a ResultSet 
Hive,WITHOUT_CLASSIFICATION,// DFS Stuff 
Hive,WITHOUT_CLASSIFICATION,//  queryTimeout == 0 means no timeout 
Hive,WITHOUT_CLASSIFICATION,//  generate a full partition specification 
Hive,WITHOUT_CLASSIFICATION,//  We store some hash bits in ref; for every expansion we need to add one bit to hash.   If we have enough bits we'll do that; if we don't we'll rehash.   LOG.info("Expanding the hashtable to " + capacity + " capacity"); 
Hive,WITHOUT_CLASSIFICATION,//  1. Build Rel For Src (SubQuery TS Join) 
Hive,WITHOUT_CLASSIFICATION,//  We expect that there's only one field schema. 
Hive,WITHOUT_CLASSIFICATION,//  Lag on the whole partition not the iterator range 
Hive,WITHOUT_CLASSIFICATION,//  Replace the buffer in our big range list as well as in current results. 
Hive,WITHOUT_CLASSIFICATION,//  Categorize the partitions returned and confirm that all partitions are accounted for. 
Hive,WITHOUT_CLASSIFICATION,//  The manner in which the values in this column are de/serialized from/to Accumulo 
Hive,WITHOUT_CLASSIFICATION,//  1 1 
Hive,WITHOUT_CLASSIFICATION,//  We allow decimals and will return a truncated integer in that case.   Therefore we won't throw an exception here (checking the fractional   part happens below.) 
Hive,WITHOUT_CLASSIFICATION,//  opening allowed after closing: 
Hive,WITHOUT_CLASSIFICATION,//  The encoding method is simple e.g. replace   all the special characters with the corresponding number in ASCII.   Note that unicode is not supported in table names. And we have explicit   checks for it. 
Hive,WITHOUT_CLASSIFICATION,// http://www.postgresql.org/docs/7.3/static/queries-limit.html 
Hive,WITHOUT_CLASSIFICATION,//  Set columns list for temp table. 
Hive,WITHOUT_CLASSIFICATION,//  Try pulling directly from URL 
Hive,WITHOUT_CLASSIFICATION,//  diffAfterSleep < total sleepTime 
Hive,WITHOUT_CLASSIFICATION,//  Scale down left and compare. 
Hive,WITHOUT_CLASSIFICATION,// In UpdateDeleteSemanticAnalyzer after super analyze   Read [default@acidtblpart default@acidtblpart@p=p1]   Write default@acidtblpart TABLE/INSERT  after UDSA   Read [default@acidtblpart default@acidtblpart@p=p1]   Write [default@acidtblpart@p=p1] PARTITION/UPDATE  todo: this causes a Read lock on the whole table - clearly overkill 
Hive,WITHOUT_CLASSIFICATION,//  table is partitioned   user did NOT specify partition 
Hive,WITHOUT_CLASSIFICATION,//  Multiply by 10^(-scale) to normalize.  We do not use negative scale in our representation.     Example:      4.172529E+20 has a negative scale -20 since scale is number of digits below the dot.      417252900000000000000 normalized as scale 0.   
Hive,WITHOUT_CLASSIFICATION,//  All field names are of the form "key." or "value." 
Hive,WITHOUT_CLASSIFICATION,//  Only evaluate +ve/-ve or cast on constant or recursive casting. 
Hive,WITHOUT_CLASSIFICATION,//  Permissions for metric directory 
Hive,WITHOUT_CLASSIFICATION,//  to marshal/unmarshal znode data 
Hive,WITHOUT_CLASSIFICATION,//  Replication destination will not be external 
Hive,WITHOUT_CLASSIFICATION,/*  * An multi-key hash set optimized for vector map join. * * The key is stored as the provided bytes (uninterpreted).  */
Hive,WITHOUT_CLASSIFICATION,//  1 0 
Hive,WITHOUT_CLASSIFICATION,//  find the number of reducers such that it is a divisor of totalFiles 
Hive,WITHOUT_CLASSIFICATION,//  Node1 has free capacity but is disabled. Node 2 has capcaity. Delay > re-enable tiemout 
Hive,WITHOUT_CLASSIFICATION,//  Assume that for an MM table or if there's only the base directory we are good. 
Hive,WITHOUT_CLASSIFICATION,//  This is not called by ConsecutiveChunk stuff in Parquet.   If this were used it might make sense to make it faster. 
Hive,WITHOUT_CLASSIFICATION,//  Note that we create the cluster name from user conf (hence a user can target a cluster)   but then we create the signer using hiveConf (hence we control the ZK config and stuff). 
Hive,WITHOUT_CLASSIFICATION,//  validate 
Hive,WITHOUT_CLASSIFICATION,//  omit nulls 
Hive,WITHOUT_CLASSIFICATION,//  4. Create encoded data reader. 
Hive,WITHOUT_CLASSIFICATION,//  check whether the part exists or not in fs 
Hive,WITHOUT_CLASSIFICATION,//  interim row count can not be less due to containment   assumption in join cardinality computation 
Hive,WITHOUT_CLASSIFICATION,//  Make a MockInstance here by setting the instance name to be the same as this mock instance 
Hive,WITHOUT_CLASSIFICATION,//  Inner join specific. 
Hive,WITHOUT_CLASSIFICATION,// creates more files in that partition 
Hive,WITHOUT_CLASSIFICATION,//  No match for entire batch. 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: Originally we named this isEmpty but that name conflicted with another interface. 
Hive,WITHOUT_CLASSIFICATION,//  add all dependencies (i.e.: edges) to the graph 
Hive,WITHOUT_CLASSIFICATION,//  TODO: expose non-primitive as a structured object while maintaining JDBC compliance 
Hive,WITHOUT_CLASSIFICATION,// Environment Variables name 
Hive,WITHOUT_CLASSIFICATION,//  Calculate the expected timeout based on the elapsed time between waiting start time and polling start time 
Hive,WITHOUT_CLASSIFICATION,//  3.3 Add column info corresponding to virtual columns 
Hive,WITHOUT_CLASSIFICATION,//  Test that exclusive lock blocks read and write 
Hive,WITHOUT_CLASSIFICATION,//  null in tests 
Hive,WITHOUT_CLASSIFICATION,//  Create initialize and test 
Hive,WITHOUT_CLASSIFICATION,//  This test will make sure that every entry in hive.conf.restricted.list has a test here 
Hive,WITHOUT_CLASSIFICATION,//  remove the previous renewable jars 
Hive,WITHOUT_CLASSIFICATION,//  the 30TB TPCDS scale set. This way the optimizer will generate plans for a 30 TB set. 
Hive,WITHOUT_CLASSIFICATION,//  As of Hadoop 2.8 - this timeout spec behaves in a strnage manner. "20001" means 2000s with 1 retry.   However it does this - but does it thrice. Essentially - #retries+2 is the number of times the entire config 
Hive,WITHOUT_CLASSIFICATION,//  Test inputformat with column prune 
Hive,WITHOUT_CLASSIFICATION,//  Stub OutputFormat actions 
Hive,WITHOUT_CLASSIFICATION,//  For now only alter name owner parameters cols bucketcols are allowed 
Hive,WITHOUT_CLASSIFICATION,//  fetch the counters 
Hive,WITHOUT_CLASSIFICATION,//  We don't know the acceptable size for Java array so we'll use 1Gb boundary. 
Hive,WITHOUT_CLASSIFICATION,//  Check if the file format of the file matches that of the partition 
Hive,WITHOUT_CLASSIFICATION,//  Ensure we find the single row which matches our timestamp (where field 1 has value 1) 
Hive,WITHOUT_CLASSIFICATION,//  if at least a partition does not contain row count then mark basic stats state as PARTIAL 
Hive,WITHOUT_CLASSIFICATION,// Read should get 10 + 20 + 10 + 10 + 20 rows 
Hive,WITHOUT_CLASSIFICATION,/*    * This code that creates the result for the granularity functions has been brought from Druid    */
Hive,WITHOUT_CLASSIFICATION,//  Last row of last batch determines isGroupResultNull and double lastValue. 
Hive,WITHOUT_CLASSIFICATION,//  If partition level statistics is requested add predicate and group by as needed to rewritten   query 
Hive,WITHOUT_CLASSIFICATION,//  Insert overwrite MM table from source table 
Hive,WITHOUT_CLASSIFICATION,// https://issues.apache.org/jira/browse/HIVE-13212 
Hive,WITHOUT_CLASSIFICATION,//  We should send a message to undo what we just did. 
Hive,WITHOUT_CLASSIFICATION,//  Do not clean up the writers - the callback should do it. 
Hive,WITHOUT_CLASSIFICATION,//  Only INLINE followed by ARRAY supported in CBO 
Hive,WITHOUT_CLASSIFICATION,//  We only store longs in our LongColumnVector. 
Hive,WITHOUT_CLASSIFICATION,/*    * Captures how an Input should be Partitioned. This is captured as a   * list of ASTNodes that are the expressions in the Distribute/Cluster   * by clause specifying the partitioning applied for a PTF invocation.    */
Hive,WITHOUT_CLASSIFICATION,//  it is possible that nullscan can fire we skip this rule. 
Hive,WITHOUT_CLASSIFICATION,//  localize llap client jars 
Hive,WITHOUT_CLASSIFICATION,//  The next byte should be the marker 
Hive,WITHOUT_CLASSIFICATION,//  v[3] 
Hive,WITHOUT_CLASSIFICATION,//  no nulls not repeating 
Hive,WITHOUT_CLASSIFICATION,//  Partitions to be dropped 
Hive,WITHOUT_CLASSIFICATION,//  All tables are to be cached - this is not possible. In future we can   support this by randomly 
Hive,WITHOUT_CLASSIFICATION,//  -help 
Hive,WITHOUT_CLASSIFICATION,/*    * TODO: use TableSnapshotRegionSplit HBASE-11555 is fixed.    */
Hive,WITHOUT_CLASSIFICATION,//  Reconnect was successful 
Hive,WITHOUT_CLASSIFICATION,//  cut the operator tree so as to not retain connections from the parent RS downstream 
Hive,WITHOUT_CLASSIFICATION,//  The second one should be combined into the first. 
Hive,WITHOUT_CLASSIFICATION,//  Fill high long from lower long. 
Hive,WITHOUT_CLASSIFICATION,/*      * @param Tuple /* @return null /* @throws IOException     *     * @see org.apache.pig.EvalFunc#exec(org.apache.pig.data.Tuple)      */
Hive,WITHOUT_CLASSIFICATION,//  We start here with at least one byte. 
Hive,WITHOUT_CLASSIFICATION,//  Throw a special exception since it's usually a well-known misconfiguration. 
Hive,WITHOUT_CLASSIFICATION,//  char text value is already stripped of trailing space 
Hive,WITHOUT_CLASSIFICATION,//  Constants for 32 bit variant 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#execute(java.lang.String int[])    */
Hive,WITHOUT_CLASSIFICATION,//  Set parameters in the n-gram estimator object 
Hive,WITHOUT_CLASSIFICATION,//  Compare long value with HiveDecimal#longValue 
Hive,WITHOUT_CLASSIFICATION,//  temp tables exempted from checks. 
Hive,WITHOUT_CLASSIFICATION,//  If the optimization has been stopped for the reasons like being not qualified   or lack of the stats data. we do not continue this process. For an example   for a query select max(value) from src1 union all select max(value) from src2   if it has been union remove optimized the AST tree will become   TS[0]->SEL[1]->GBY[2]-RS[3]->GBY[4]->FS[17]   TS[6]->SEL[7]->GBY[8]-RS[9]->GBY[10]->FS[18]   if TS[0] branch for src1 is not optimized because src1 does not have column stats 
Hive,WITHOUT_CLASSIFICATION,//  key & value are already read. 
Hive,WITHOUT_CLASSIFICATION,//  clear most members 
Hive,WITHOUT_CLASSIFICATION,//  all the parent SparkTasks that this new task is depend on if they don't already exists. 
Hive,WITHOUT_CLASSIFICATION,//  [-h|--help] 
Hive,WITHOUT_CLASSIFICATION,// 0123456789012345678901234567890 
Hive,WITHOUT_CLASSIFICATION,// delete output file on exit 
Hive,WITHOUT_CLASSIFICATION,/*    * Copy the current object contents into the output. Only copy selected entries   * as indicated by selectedInUse and the sel array.    */
Hive,WITHOUT_CLASSIFICATION,//  Use different separator values. 
Hive,WITHOUT_CLASSIFICATION,// but preserve table name in SQL 
Hive,WITHOUT_CLASSIFICATION,//  It is already verified that the join can be converted to a bucket map join 
Hive,WITHOUT_CLASSIFICATION,//  Clear rounding portion in lower longword and add 1 at right scale (roundMultiplyFactor). 
Hive,WITHOUT_CLASSIFICATION,//  if zk is disabled or if HA service discovery is enabled we return the already populated params.   in HA mode params is already populated with Active server host info. 
Hive,WITHOUT_CLASSIFICATION,//  nonFinalCandidates predicates should be empty 
Hive,WITHOUT_CLASSIFICATION,// default version is -1 
Hive,WITHOUT_CLASSIFICATION,//  version of schema for this version of hive 
Hive,WITHOUT_CLASSIFICATION,//  Create HiveConf once since this is expensive. 
Hive,WITHOUT_CLASSIFICATION,//  Already called in doAs so no need to doAs here. 
Hive,WITHOUT_CLASSIFICATION,//  there should be 1 call to create partitions with batch sizes of 13 
Hive,WITHOUT_CLASSIFICATION,//  we have just ensured the item is not in the list so we have a definite state now. 
Hive,WITHOUT_CLASSIFICATION,//  Test class to write a series of values to the designated output stream 
Hive,WITHOUT_CLASSIFICATION,//  Move the data files of this newly created partition to a temp location 
Hive,WITHOUT_CLASSIFICATION,//  Note: we're not creating a copy of the list for saving memory 
Hive,WITHOUT_CLASSIFICATION,//  There are original format files 
Hive,WITHOUT_CLASSIFICATION,//  Returns whether or not two lists contain the same elements independent of order 
Hive,WITHOUT_CLASSIFICATION,//  no hook by default 
Hive,WITHOUT_CLASSIFICATION,//  sort is pushed we bail out 
Hive,WITHOUT_CLASSIFICATION,//  TODO: return createNullLiteral(literal); 
Hive,WITHOUT_CLASSIFICATION,//  check that the defaults did not remain. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see   * org.apache.hadoop.hive.ql.security.authorization.plugin.HiveAuthorizer#   * getHivePolicyProvider()    */
Hive,WITHOUT_CLASSIFICATION,//  If any operator in the stack does not support a auto-conversion this join should   not be converted. 
Hive,WITHOUT_CLASSIFICATION,//  This is min number of reducer for deduped RS to avoid query executed on   too small number of reducers. For example queries GroupBy+OrderBy can be executed by 
Hive,WITHOUT_CLASSIFICATION,//                    12345678.901234567890123456789012345678 
Hive,WITHOUT_CLASSIFICATION,//  No room for optimization since we cannot create an empty   Project operator. 
Hive,WITHOUT_CLASSIFICATION,//  We need to support field names like KEY.0 VALUE.1 between   map-reduce boundary. 
Hive,WITHOUT_CLASSIFICATION,/*  Run distcp if source file/dir is too big  */
Hive,WITHOUT_CLASSIFICATION,//  If table is already transactional no migration needed. 
Hive,WITHOUT_CLASSIFICATION,//  string char varchar 
Hive,WITHOUT_CLASSIFICATION,//  configured limit for reducers 
Hive,WITHOUT_CLASSIFICATION,/*  id < 15 or  */
Hive,WITHOUT_CLASSIFICATION,//  If we have no space in the cache run cleaner thread 
Hive,WITHOUT_CLASSIFICATION,//  4 * grouping(c1) + 2 * grouping(c2) + grouping(c3) 
Hive,WITHOUT_CLASSIFICATION,//  write stmt + ";" + System.getProperty("line.separator") 
Hive,WITHOUT_CLASSIFICATION,//  2. Check if the input is an IN operator with struct children 
Hive,WITHOUT_CLASSIFICATION,//  collect all DPP sinks 
Hive,WITHOUT_CLASSIFICATION,/*      * Use common binary to decimal conversion method we share with fastSetFromBigIntegerBytes.      */
Hive,WITHOUT_CLASSIFICATION,//  Aggregate functions 
Hive,WITHOUT_CLASSIFICATION,//  3. Transform if we have created a new filter operator 
Hive,WITHOUT_CLASSIFICATION,//  If we reached here then we were successful at finding an alternate internal   column mapping and we're about to proceed. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#getResultSetType()    */
Hive,WITHOUT_CLASSIFICATION,//  count 
Hive,WITHOUT_CLASSIFICATION,//  used by external cache   used by local cache 
Hive,WITHOUT_CLASSIFICATION,//  return the row only if it's not corrupted 
Hive,WITHOUT_CLASSIFICATION,//  TODO: Embedded MetaStore changes the table object when client.createTable is called  Assert.assertNull("Original table storage descriptor location should be null"      table.getSd().getLocation()); 
Hive,WITHOUT_CLASSIFICATION,//  violation in BI queue 
Hive,WITHOUT_CLASSIFICATION,/*      * Add the support of the VectorizedInputFileFormatInterface.      */
Hive,WITHOUT_CLASSIFICATION,/*      * Bloom filter *any* input and output is BYTES.     *     * Just modes (PARTIAL1 COMPLETE).      */
Hive,WITHOUT_CLASSIFICATION,//  Ref 
Hive,WITHOUT_CLASSIFICATION,//  Allows mocking in testing. 
Hive,WITHOUT_CLASSIFICATION,//  set all child tasks 
Hive,WITHOUT_CLASSIFICATION,//  if alias to CTE contains the table name we do not do the translation because 
Hive,WITHOUT_CLASSIFICATION,//  Find all of the agg expressions. We use a LinkedHashSet to ensure determinism. 
Hive,WITHOUT_CLASSIFICATION,//  spaces at the end of the line. 
Hive,WITHOUT_CLASSIFICATION,//  This node will likely be activated after the task timeout expires. 
Hive,WITHOUT_CLASSIFICATION,//  CONCERN : the way this mapping goes the order *needs* to be   preserved for table.getPartitionKeys() and ptn.getValues() 
Hive,WITHOUT_CLASSIFICATION,//  releasing the locks. 
Hive,WITHOUT_CLASSIFICATION,//  Must reset the isNull could be set from prev batch use 
Hive,WITHOUT_CLASSIFICATION,//  aggregation columns (HIVE-10627) 
Hive,WITHOUT_CLASSIFICATION,/*   these are sessionState objects that are copied over to work to allow for parallel execution.  based on the current use case the methods are selectively synchronized which might need to be  taken care when using other methods.   */
Hive,WITHOUT_CLASSIFICATION,//  Set the size of the struct 
Hive,WITHOUT_CLASSIFICATION,//  delete sample jars 
Hive,WITHOUT_CLASSIFICATION,//  Code Sections:     Initialize (fastSetFrom*).     Take Integer or Fractional Portion.     Binary to Decimal Conversion.     Decimal to Binary Conversion.r     Emulate SerializationUtils Deserialization used by ORC.     Emulate SerializationUtils Serialization used by ORC.     Emulate BigInteger Deserialization used by LazyBinary and others.     Emulate BigInteger Serialization used by LazyBinary and others.     Decimal to Integer Conversion.     Decimal to Non-Integer Conversion.     Decimal Comparison.     Decimal Rounding.     Decimal Scale Up/Down.     Decimal Precision / Trailing Zeroes.     Decimal Addition / Subtraction.     Decimal Multiply.     Decimal Division / Remainder.     Decimal String Formatting.     Decimal Validation.     Decimal Debugging. 
Hive,WITHOUT_CLASSIFICATION,//  if specified generate alias using func name 
Hive,WITHOUT_CLASSIFICATION,//  Group mapping:   group_a: user1 user2 
Hive,WITHOUT_CLASSIFICATION,// SqlStdOperatorTable.SUM 
Hive,WITHOUT_CLASSIFICATION,//  Call AppMasterEventOperator with new input inspector. 
Hive,WITHOUT_CLASSIFICATION,//  work.removePathToPartitionInfo(p); 
Hive,WITHOUT_CLASSIFICATION,//  create map 
Hive,WITHOUT_CLASSIFICATION,//  verify that there are two calls because of two instances of the authorization provider 
Hive,WITHOUT_CLASSIFICATION,//  Testing using != is good enough because we use ObjectInspectorFactory   to   create ObjectInspectors. 
Hive,WITHOUT_CLASSIFICATION,//  If filter condition is NULL transform to FALSE 
Hive,WITHOUT_CLASSIFICATION,//  Removing job credential entry/ cannot be set on the tasks 
Hive,WITHOUT_CLASSIFICATION,//  For PARTIAL1 and COMPLETE 
Hive,WITHOUT_CLASSIFICATION,//  Return the new list 
Hive,WITHOUT_CLASSIFICATION,//  Allow the user to set the ORC properties without getting an error. 
Hive,WITHOUT_CLASSIFICATION,//  High word gets integer rounding. 
Hive,WITHOUT_CLASSIFICATION,//  Do some changes (optional) 
Hive,WITHOUT_CLASSIFICATION,//  Use the hive table name ignoring the default database 
Hive,WITHOUT_CLASSIFICATION,//  returns the bucket number to which the record belongs to 
Hive,WITHOUT_CLASSIFICATION,/*  * The interface for a single byte array key hash map lookup method.  */
Hive,WITHOUT_CLASSIFICATION,//  Update catalogs 
Hive,WITHOUT_CLASSIFICATION,//  Test that exclusive blocks exclusive and read 
Hive,WITHOUT_CLASSIFICATION,//  2. Add TOK_WINDOW as child of UDAF 
Hive,WITHOUT_CLASSIFICATION,//  Get scheme from FileSystem 
Hive,WITHOUT_CLASSIFICATION,//  assert cvb.cols.length == batch.getColumnIxs().length; // Must be constant per split. 
Hive,WITHOUT_CLASSIFICATION,// this should use VectorizedOrcAcidRowReader 
Hive,WITHOUT_CLASSIFICATION,//  Process the records in the input iterator until    - new output records are available for serving downstream operator    - input records are exhausted or 
Hive,WITHOUT_CLASSIFICATION,//  Return the new expression containing only partition columns 
Hive,WITHOUT_CLASSIFICATION,/*    * Helper method to create a yarn local resource.    */
Hive,WITHOUT_CLASSIFICATION,//  field present in both. validate type has not changed 
Hive,WITHOUT_CLASSIFICATION,//  Get one top level TS Op directly from the stack 
Hive,WITHOUT_CLASSIFICATION,//  Iterate through the children nodes of the IN clauses starting from index 1   which corresponds to the right hand side of the IN list. 
Hive,WITHOUT_CLASSIFICATION,//  if table is being modified to be external we need to make sure existing table   doesn't have enabled constraint since constraints are disallowed with such tables 
Hive,WITHOUT_CLASSIFICATION,//  requested host died or unknown host requested fallback to random selection. 
Hive,WITHOUT_CLASSIFICATION,//  Old logic. 
Hive,WITHOUT_CLASSIFICATION,//  initialize and evaluate 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   optional   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  Null-safe isSame for lists of ExprNodeDesc 
Hive,WITHOUT_CLASSIFICATION,//  we choose to keep the invalid stats and only change the setting. 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise convert t to RawType so we will fall into the following if 
Hive,WITHOUT_CLASSIFICATION,//  date/timestamp is higher precedence than String_GROUP 
Hive,WITHOUT_CLASSIFICATION,//  com.esotericsoftware.kryo.io.Output getHybridBigTableSpillOutput(int partitionId); 
Hive,WITHOUT_CLASSIFICATION,//  make the offset non-zero to keep things interesting. 
Hive,WITHOUT_CLASSIFICATION,//  ID 8 was committed all others open 
Hive,WITHOUT_CLASSIFICATION,//  Negative number 
Hive,WITHOUT_CLASSIFICATION,//  Check for empty partitions 
Hive,WITHOUT_CLASSIFICATION,//  update only the basic statistics in the absence of column statistics 
Hive,WITHOUT_CLASSIFICATION,//  prepare output buffer to accept results 
Hive,WITHOUT_CLASSIFICATION,//  to the conf using the connection hook 
Hive,WITHOUT_CLASSIFICATION,/*      * Restriction 17.s :: SubQuery cannot use the same table alias as one used in     * the Outer Query.      */
Hive,WITHOUT_CLASSIFICATION,//  The lock may have been released. Ignore and continue 
Hive,WITHOUT_CLASSIFICATION,//  A little strange that we forget the dummy row on read. 
Hive,WITHOUT_CLASSIFICATION,//  ask default fs first 
Hive,WITHOUT_CLASSIFICATION,// now start concurrent txn 
Hive,WITHOUT_CLASSIFICATION,//  First look in the classpath 
Hive,WITHOUT_CLASSIFICATION,//  metastore schema only allows maximum 255 for constraint name column 
Hive,WITHOUT_CLASSIFICATION,// process records until done 
Hive,WITHOUT_CLASSIFICATION,//  We've prewarmed this database continue with the next one 
Hive,WITHOUT_CLASSIFICATION,//  This method will scale down and round to fit if necessary. 
Hive,WITHOUT_CLASSIFICATION,//  We will use decimal if all else fails. 
Hive,WITHOUT_CLASSIFICATION,//  maps from a work to the DPPs it contains 
Hive,WITHOUT_CLASSIFICATION,//  4. We create the join operator with its descriptor 
Hive,WITHOUT_CLASSIFICATION,//  execute in child jvm 
Hive,WITHOUT_CLASSIFICATION,/*    * - invoked during FROM AST tree processing on encountering a PTF invocation.   * - tree form is   *   ^(TOK_PTBLFUNCTION name partitionTableFunctionSource partitioningSpec? arguments*)   * - setup a PTFInvocationSpec for this top level PTF invocation.    */
Hive,WITHOUT_CLASSIFICATION,//  Add the attemptDir to the watch set scan it and add to the list of found files 
Hive,WITHOUT_CLASSIFICATION,//  Now copy missing chunks (and parts of chunks) into cache buffers. 
Hive,WITHOUT_CLASSIFICATION,//  If the partitions were not added due to memory limit return false 
Hive,WITHOUT_CLASSIFICATION,//  If the input is sorted and we are executing a search based on the arguments to this filter 
Hive,WITHOUT_CLASSIFICATION,//  joined with multiple small tables on different keys 
Hive,WITHOUT_CLASSIFICATION,//  add tez counters for task execution and llap io 
Hive,WITHOUT_CLASSIFICATION,//  We are revoking from an updating task. 
Hive,WITHOUT_CLASSIFICATION,//  Project everything from the LHS and then those from the original 
Hive,WITHOUT_CLASSIFICATION,//  test without nulls 
Hive,WITHOUT_CLASSIFICATION,//  empty string delim 
Hive,WITHOUT_CLASSIFICATION,//  getFunction() 
Hive,WITHOUT_CLASSIFICATION,//  Reserve blocks in this arena that would empty the sections of requisite size. 
Hive,WITHOUT_CLASSIFICATION,//  Looks like it doesn't exist.  Lock so that two threads don't create it at once. 
Hive,WITHOUT_CLASSIFICATION,//  3. Materialized view based rewriting   We disable it for CTAS and MV creation queries (trying to avoid any problem 
Hive,WITHOUT_CLASSIFICATION,//  I expect we'll only see NOT_ACQUIRED here? 
Hive,WITHOUT_CLASSIFICATION,/*  * Root interface for a vector map join hash table (which could be a hash map hash multi-set or * hash set).  */
Hive,WITHOUT_CLASSIFICATION,//  empty HSchema construct 
Hive,WITHOUT_CLASSIFICATION,//  go through all small tables and get the mapping from bucket file name 
Hive,WITHOUT_CLASSIFICATION,//  No room above for rounding. 
Hive,WITHOUT_CLASSIFICATION,//  Get explain plan for the query. 
Hive,WITHOUT_CLASSIFICATION,//  Modify Table schema at the source. 
Hive,WITHOUT_CLASSIFICATION,//  the valueList will save all data for ListColumnVector temporary. 
Hive,WITHOUT_CLASSIFICATION,//  Use TerminateFragmentResponseProto.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,//  supposed to get 500 rows if maxRows isn't set 
Hive,WITHOUT_CLASSIFICATION,//  Report the row if its the first time 
Hive,WITHOUT_CLASSIFICATION,//  Select one in 1st child none as 2nd child and none as 3rd. 
Hive,WITHOUT_CLASSIFICATION,//  For a non-list (i.e. single value) the offset is for the variable length long (VLong)   holding the value length (followed by the key length). 
Hive,WITHOUT_CLASSIFICATION,//  Slice before the start of the split. 
Hive,WITHOUT_CLASSIFICATION,//  in case of an overflow return -1 
Hive,WITHOUT_CLASSIFICATION,//  If both schema information are provided they should be the same. 
Hive,WITHOUT_CLASSIFICATION,//  narrow down the possible choices based on type affinity 
Hive,WITHOUT_CLASSIFICATION,//  break loop on equal comparator 
Hive,WITHOUT_CLASSIFICATION,//  s.getLength() and will never resize the buffer down. 
Hive,WITHOUT_CLASSIFICATION,//  TODO: if this method is ever called on more than one jar getting the dir and the 
Hive,WITHOUT_CLASSIFICATION,//  JoinOperator assumes the key is backed by an list.   To be consistent the value array is also converted 
Hive,WITHOUT_CLASSIFICATION,//  Test with just high water mark 
Hive,WITHOUT_CLASSIFICATION,//  Already registered to send updates to this node for the specific source.   Nothing to do for now unless tracking tasks at a later point. 
Hive,WITHOUT_CLASSIFICATION,//  Without the round this conversion fails. 
Hive,WITHOUT_CLASSIFICATION,/*  Partial aggregation result returned by TerminatePartial. Partial result is a struct     * containing a long field named "count".      */
Hive,WITHOUT_CLASSIFICATION,// since now we have scalar subqueries we can get subquery expression in having   we don't want to include aggregate from within subquery 
Hive,WITHOUT_CLASSIFICATION,//  Allow analyze the whole table and dynamic partitions 
Hive,WITHOUT_CLASSIFICATION,//  This is a negative because we want the positive to be the default when nothing is specified. 
Hive,WITHOUT_CLASSIFICATION,//  It should also be possible to calculate this based on ts.getTime() only. 
Hive,WITHOUT_CLASSIFICATION,//  summary of aliasBucketFileNameMapping for test result 
Hive,WITHOUT_CLASSIFICATION,// Base time 
Hive,WITHOUT_CLASSIFICATION,//  Union 
Hive,WITHOUT_CLASSIFICATION,//  Repeat the expression on the same batch   the result must be unchanged. 
Hive,WITHOUT_CLASSIFICATION,//  args as child of func? 
Hive,WITHOUT_CLASSIFICATION,//  we need a constant on one side. 
Hive,WITHOUT_CLASSIFICATION,//  Return if either of the arguments is null 
Hive,WITHOUT_CLASSIFICATION,//  because HIVE doesn't support null type it is appropriately typed boolean 
Hive,WITHOUT_CLASSIFICATION,/*    * Called to generate the taks tree from the parse context/operator tree    */
Hive,WITHOUT_CLASSIFICATION,//  Verify resulting dirs. 
Hive,WITHOUT_CLASSIFICATION,//  create a walker which walks the tree in a DFS manner while maintaining   the operator stack. 
Hive,WITHOUT_CLASSIFICATION,/*    * hasAllFieldsSettable without any caching.    */
Hive,WITHOUT_CLASSIFICATION,//  instead fall back to default behavior for determining input records. 
Hive,WITHOUT_CLASSIFICATION,//  very small heap 14 elements 
Hive,WITHOUT_CLASSIFICATION,//  only tasks that cannot finish immediately are pre-emptable. In other words if all inputs 
Hive,WITHOUT_CLASSIFICATION,//  in the serde. 
Hive,WITHOUT_CLASSIFICATION,/*        * this 'if' is pretty lame - QTestUtil.QTestUtil() uses hiveSiteURL to load a specific       * hive-site.xml from data/conf/<subdir> so this makes it follow the same logic - otherwise       * HiveConf and MetastoreConf may load different hive-site.xml  ( For example       * HiveConf uses data/conf/spark/hive-site.xml and MetastoreConf data/conf/hive-site.xml)        */
Hive,WITHOUT_CLASSIFICATION,//  make current task depends on this new generated localMapJoinTask 
Hive,WITHOUT_CLASSIFICATION,//  case the statement is a CREATE MATERIALIZED VIEW AS 
Hive,WITHOUT_CLASSIFICATION,//  interim row count can not be less due to containment   assumption in join cardinality computation   interimNumRows represent number of matches for join keys on two sides.   newNumRows-interimNumRows represent number of non-matches. 
Hive,WITHOUT_CLASSIFICATION,//  for ex: count(*) 
Hive,WITHOUT_CLASSIFICATION,//  result principal 
Hive,WITHOUT_CLASSIFICATION,//  in case all files in locations do not exist 
Hive,WITHOUT_CLASSIFICATION,//  may be the table is getting created in this load 
Hive,WITHOUT_CLASSIFICATION,//  0 seconds for first retry assuming fs object was closed and open will fix it. 
Hive,WITHOUT_CLASSIFICATION,//  As we read we can unlock initial refcounts for the buffers that end before 
Hive,WITHOUT_CLASSIFICATION,//  test for VARCHAR type 
Hive,WITHOUT_CLASSIFICATION,/*          * Single value.          */
Hive,WITHOUT_CLASSIFICATION,/*    * Serializes decimal64 up to the maximum 64-bit precision (18 decimal digits).   *   * NOTE: Major assumption: the fast decimal has already been bounds checked and a least   * has a precision <= DECIMAL64_DECIMAL_DIGITS.  We do not bounds check here for better   * performance.    */
Hive,WITHOUT_CLASSIFICATION,//  for persistent function 
Hive,WITHOUT_CLASSIFICATION,//  Last chance look in the old Hive config value.  Still avoiding defaults. 
Hive,WITHOUT_CLASSIFICATION,//  Rename the event directories such a way that the length varies.   We will encounter create_table truncate followed by insert.   For the insert set the event ID longer such that old comparator picks insert before truncate   Eg: Event IDs CREATE_TABLE - 5 TRUNCATE - 9 INSERT - 12 changed to   CREATE_TABLE - 5 TRUNCATE - 9 INSERT - 100   But if TRUNCATE have ID-10 then having INSERT-100 won't be sufficient to test the scenario.   So we set any event comes after CREATE_TABLE starts with 20.   Eg: Event IDs CREATE_TABLE - 5 TRUNCATE - 10 INSERT - 12 changed to 
Hive,WITHOUT_CLASSIFICATION,//  Set the destination for the SELECT query inside the CTAS 
Hive,WITHOUT_CLASSIFICATION,/*    * We cannot use a base file if its range contains an open write id.   * @param writeId from base_xxxx    */
Hive,WITHOUT_CLASSIFICATION,//  No includes - use the standard batch. 
Hive,WITHOUT_CLASSIFICATION,//  To get vertex status we can use DAGClient.getVertexStatus() but it will be expensive to   get status from AM for every refresh of the UI. Lets infer the state from task counts. 
Hive,WITHOUT_CLASSIFICATION,//  Select DISTINCT + windowing; GBy handled by genSelectForWindowing 
Hive,WITHOUT_CLASSIFICATION,//  Secondly we extract information about the part of the tree that can be merged   as well as some structural information (memory consumption) that needs to be 
Hive,WITHOUT_CLASSIFICATION,// this will also handle copy_N files if any 
Hive,WITHOUT_CLASSIFICATION,//  we just negate it to get the size. 
Hive,WITHOUT_CLASSIFICATION,// both commit & rollback clear ALL locks for this tx 
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.GroupInputSpecProto.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,//  Only for char/varchar return types 
Hive,WITHOUT_CLASSIFICATION,//  Open txn 
Hive,WITHOUT_CLASSIFICATION,//  PRINCIPAL_TYPE 
Hive,WITHOUT_CLASSIFICATION,//  handle the close up 
Hive,WITHOUT_CLASSIFICATION,//  else skip this one 
Hive,WITHOUT_CLASSIFICATION,//  Invalidate 
Hive,WITHOUT_CLASSIFICATION,//  3. Perform a delete. 
Hive,WITHOUT_CLASSIFICATION,//  Retrieve log from task tracker 
Hive,WITHOUT_CLASSIFICATION,//  Wait for the events to be processed. 
Hive,WITHOUT_CLASSIFICATION,//  if not the first put a blank separator in 
Hive,WITHOUT_CLASSIFICATION,//  Get the result in leftInspectableObject 
Hive,WITHOUT_CLASSIFICATION,//  disable auto parallelism for bucket map joins 
Hive,WITHOUT_CLASSIFICATION,//  2. Trigger transformation 
Hive,WITHOUT_CLASSIFICATION,//  First request for host. 
Hive,WITHOUT_CLASSIFICATION,//  Round using the "half-even" method used in Hive. 
Hive,WITHOUT_CLASSIFICATION,//  unsupported if null 
Hive,WITHOUT_CLASSIFICATION,//  Should generate [f+inf) 
Hive,WITHOUT_CLASSIFICATION,//  We only need to update the work with the hashtable   sink operator with the same mapjoin desc. We can tell   that by comparing the bucket file name mapping map   instance. They should be exactly the same one due to   the way how the bucket mapjoin context is constructed. 
Hive,WITHOUT_CLASSIFICATION,//  No tasks should have been started yet. Checked by initial state 
Hive,WITHOUT_CLASSIFICATION,//  Test a set of random adds at high precision. 
Hive,WITHOUT_CLASSIFICATION,// writing both acid and non-acid resources in the same txn  txnid:1 
Hive,WITHOUT_CLASSIFICATION,// request came from old version of the client  this matches old behavior 
Hive,WITHOUT_CLASSIFICATION,//  If a partition value is not there then it is dynamic partition key. 
Hive,WITHOUT_CLASSIFICATION,/*    * Utility to visit all nodes in an AST tree.    */
Hive,WITHOUT_CLASSIFICATION,//  getFunctions(String catalog String schemaPattern String functionNamePattern)   getSchemas()   getTables(String catalog String schemaPattern String tableNamePattern String[] types)   getTableTypes()   getTypeInfo() 
Hive,WITHOUT_CLASSIFICATION,//  Conf for llap 
Hive,WITHOUT_CLASSIFICATION,/*    * Get detailed read position information to help diagnose exceptions.    */
Hive,WITHOUT_CLASSIFICATION,//  We query for minimum values in all the queries and they can only increase by any concurrent 
Hive,WITHOUT_CLASSIFICATION,//  dummy impl 
Hive,WITHOUT_CLASSIFICATION,/* may not be Idempotent but is safe to retry */
Hive,WITHOUT_CLASSIFICATION,//  Trailing spaces are not significant 
Hive,WITHOUT_CLASSIFICATION,//  Results cache directory should be cleaned up at process termination. 
Hive,WITHOUT_CLASSIFICATION,//  sorting the list in the descending order so that deletes happen back-to-front 
Hive,WITHOUT_CLASSIFICATION,//  create a new columnstatistics desc to represent partition level column stats 
Hive,WITHOUT_CLASSIFICATION,//  Validate there the new insertions for column c. 
Hive,WITHOUT_CLASSIFICATION,//  We were combining SS-es and the time has expired. 
Hive,WITHOUT_CLASSIFICATION,//  Compute value and hashcode - we'd either store or forward them. 
Hive,WITHOUT_CLASSIFICATION,//  add udtf aliases to QB 
Hive,WITHOUT_CLASSIFICATION,//  find out all equivalent works in the Set. 
Hive,WITHOUT_CLASSIFICATION,//  PARENT_SCHEMA_NAME 
Hive,WITHOUT_CLASSIFICATION,//  Handle case with nulls. Don't do function if the value is null to save time   because calling the function can be expensive. 
Hive,WITHOUT_CLASSIFICATION,//  3. Translate projection indexes to join schema by adding offset. 
Hive,WITHOUT_CLASSIFICATION,//  Evaluate the result given a partition 
Hive,WITHOUT_CLASSIFICATION,//  Denominator is zero convert the batch to nulls 
Hive,WITHOUT_CLASSIFICATION,//  Disabled in HIVE-19509 
Hive,WITHOUT_CLASSIFICATION,//  Add back to the queue for the next heartbeat and schedule the actual heartbeat 
Hive,WITHOUT_CLASSIFICATION,//  Check if materialization defined its own invalidation time window 
Hive,WITHOUT_CLASSIFICATION,// this ensures that "SHOW LOCKS" prints the locks in the same order as they are examined 
Hive,WITHOUT_CLASSIFICATION,//  Test basic right trim of bytes slice. 
Hive,WITHOUT_CLASSIFICATION,//  reach beginning of the row group. This is required for IS_PRESENT stream. 
Hive,WITHOUT_CLASSIFICATION,//  Also check hashCode() 
Hive,WITHOUT_CLASSIFICATION,//  By default allow only ADDPROPS and DROPPROPS.   alterOpType is null in case of stats update. 
Hive,WITHOUT_CLASSIFICATION,//  already initialized 
Hive,WITHOUT_CLASSIFICATION,//  Semijoin created using hint or marked useful skip it 
Hive,WITHOUT_CLASSIFICATION,//  Doing String comps here as value objects in Hive in Pig are different so equals()   doesn't work. 
Hive,WITHOUT_CLASSIFICATION,//  getWindowFunctionInfo() cannot be called during map/reduce tasks. So cache necessary   values during query compilation and rely on plan serialization to bring this info   to the object during the map/reduce tasks. 
Hive,WITHOUT_CLASSIFICATION,//  read the stopping point for the first flush and make sure we only see 
Hive,WITHOUT_CLASSIFICATION,//  Add it to the list of work to decompress. 
Hive,WITHOUT_CLASSIFICATION,//  the next item will be a new root. 
Hive,WITHOUT_CLASSIFICATION,//  optional string class_name = 1; 
Hive,WITHOUT_CLASSIFICATION,// this contains base_xxx or delta_xxx_yyy 
Hive,WITHOUT_CLASSIFICATION,//  Use the original fsOp path here in case of MM - while the new FSOP merges files inside the   MM directory the original MoveTask still commits based on the parent. Note that this path   can only be triggered for a merge that's part of insert for now; MM tables do not support 
Hive,WITHOUT_CLASSIFICATION,//  non-partitioned 
Hive,WITHOUT_CLASSIFICATION,//  ENVIRONMENT_CONTEXT 
Hive,WITHOUT_CLASSIFICATION,//  Initialize acidOperationalProperties based on table properties and   if they are not available see if we can find it in the job configuration.   We have to look at these two places instead of just the conf because Streaming Ingest   uses table properties while normal Hive SQL inserts/updates/deletes will place this 
Hive,WITHOUT_CLASSIFICATION,//  Complete fractional digits shear off.  Zero result. 
Hive,WITHOUT_CLASSIFICATION,//  NDV of the join can not exceed the cardinality of cross join. 
Hive,WITHOUT_CLASSIFICATION,//  this test is done 
Hive,WITHOUT_CLASSIFICATION,//  Select none in 1st child one as 2nd child and none as 3rd. 
Hive,WITHOUT_CLASSIFICATION,/*          * Multi-Key specific variables.          */
Hive,WITHOUT_CLASSIFICATION,//  change the parent of the original SMBjoin operator to point to the map 
Hive,WITHOUT_CLASSIFICATION,//  We need to check if the other input branches for union is following the first branch   We may need to cast the data types for specific columns. 
Hive,WITHOUT_CLASSIFICATION,//  Specifying username/password/driver explicitly will override the values from the url;   make sure we don't override the values present in the url with empty values. 
Hive,WITHOUT_CLASSIFICATION,//  3. Add Part Spec & Range Spec as child of TOK_WINDOW 
Hive,WITHOUT_CLASSIFICATION,//  This test checks that if we have a minor compacted delta for the txn range [4060]   then it will make any delete delta in that range as obsolete. 
Hive,WITHOUT_CLASSIFICATION,//  Note: rarely called (unless buffers are very large or we evict a lot or in LFU case). 
Hive,WITHOUT_CLASSIFICATION,//  Check that in the path between cRS and pRS there are only Select operators 
Hive,WITHOUT_CLASSIFICATION,//  Generate special repeated case. 
Hive,WITHOUT_CLASSIFICATION,//  Does this make sense? 
Hive,WITHOUT_CLASSIFICATION,//  But the registry was fully initialized thus we need to add it 
Hive,WITHOUT_CLASSIFICATION,//  For TypeInfoFactory use only 
Hive,WITHOUT_CLASSIFICATION,//  Get the key column names and check if the keys are all constants 
Hive,WITHOUT_CLASSIFICATION,//  only explain uses it 
Hive,WITHOUT_CLASSIFICATION,//  DP in the form of T partition (ds hr) 
Hive,WITHOUT_CLASSIFICATION,//  get columns for SEL(*) from LVJ 
Hive,WITHOUT_CLASSIFICATION,//  test date string 
Hive,WITHOUT_CLASSIFICATION,//  INSERT OVERWRITE command 
Hive,WITHOUT_CLASSIFICATION,//  Non-partition expressions are converted to nulls. 
Hive,WITHOUT_CLASSIFICATION,//  Verify if Rename after bootstrap is successful 
Hive,WITHOUT_CLASSIFICATION,//  open record reader to read next split 
Hive,WITHOUT_CLASSIFICATION,/*  side files are only created by streaming ingest.  If this is a compaction we may          * have an insert delta/ here with side files there because the original writer died. */
Hive,WITHOUT_CLASSIFICATION,//  If the user asked for a formatted output dump the json output   in the output stream 
Hive,WITHOUT_CLASSIFICATION,// adds delta and delete_delta 
Hive,WITHOUT_CLASSIFICATION,//  Test 0 is nul character 
Hive,WITHOUT_CLASSIFICATION,//  We do the cross product of the N big table equal key row's values against the   small table matching key which has M value rows into overflow batch. 
Hive,WITHOUT_CLASSIFICATION,//  The encoding name/codes don't contain pound signs 
Hive,WITHOUT_CLASSIFICATION,// for cases where different Rel nodes are referring to   same correlation var (e.g. in case of NOT IN)   avoid generating another correlation var   and record the 'rel' is using the same correlation 
Hive,WITHOUT_CLASSIFICATION,//  openTransactionCalls > 1 means this is an interior transaction   We should already have a transaction created that is active. 
Hive,WITHOUT_CLASSIFICATION,//  if the specified path is directory iterate through all files 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getURL(int)    */
Hive,WITHOUT_CLASSIFICATION,//  although technically its unbounded its unlikely we will ever see ndv > 20 
Hive,WITHOUT_CLASSIFICATION,//  Need to necessarily override this method since default impl assumes HDFS   based location string. 
Hive,WITHOUT_CLASSIFICATION,//  ObjectStore methods to be overridden with injected behavior 
Hive,WITHOUT_CLASSIFICATION,//  TableScan will also be followed by a Select Operator. Find the expressions for the 
Hive,WITHOUT_CLASSIFICATION,//  resolve futures used for testing 
Hive,WITHOUT_CLASSIFICATION,//  Call the regular method since it does error checking. 
Hive,WITHOUT_CLASSIFICATION,//  The column number and type information for this one column string reduce key. 
Hive,WITHOUT_CLASSIFICATION,//  is the registry dynamic (i.e refreshes?) 
Hive,WITHOUT_CLASSIFICATION,//  The number of times eh has returned non-null errors 
Hive,WITHOUT_CLASSIFICATION,//  only process partition which is skewed and list bucketed 
Hive,WITHOUT_CLASSIFICATION,// builds partition spec so we can build suitable WHERE clause 
Hive,WITHOUT_CLASSIFICATION,//  iterator the reducer operator tree 
Hive,WITHOUT_CLASSIFICATION,//  Initialize to satisfy compiler finals. 
Hive,WITHOUT_CLASSIFICATION,//  As setNumDistributionKeys is a subset of keycols the size should   be 0 too. This condition maybe too strict. We may extend it in the   future. 
Hive,WITHOUT_CLASSIFICATION,//  All inserts are committed and hence would expect in TXN_TO_WRITE_ID 3 entries for acidTbl   and 2 entries for acidTblPart as each insert would have allocated a writeid. 
Hive,WITHOUT_CLASSIFICATION,//  temporary functions don't have any database 'namespace' associated with it 
Hive,WITHOUT_CLASSIFICATION,//  check equivalent versions should be compatible 
Hive,WITHOUT_CLASSIFICATION,//  The startTime may not be set if the sparkTask finished too fast   because SparkJobMonitor will sleep for 1 second then check the state   right after sleep the spark job may be already completed.   In this case set startTime the same as submitTime. 
Hive,WITHOUT_CLASSIFICATION,//  /////////////////////////////   Exception handling routines   ///////////////////////////// 
Hive,WITHOUT_CLASSIFICATION,//  v[0] 
Hive,WITHOUT_CLASSIFICATION,//  More required. 
Hive,WITHOUT_CLASSIFICATION,// Comments are separated by "\0" in columnCommentProperty see method getSchema  in MetaStoreUtils where this string columns.comments is generated 
Hive,WITHOUT_CLASSIFICATION,//  -----------------------------------------------------------------------------------------------     ----------------------------------------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  Initially no children or inputs; set later with setInput* methods. 
Hive,WITHOUT_CLASSIFICATION,//  Now try to evict with locked buffer still in the list. 
Hive,WITHOUT_CLASSIFICATION,//  Identical strings should be equal 
Hive,WITHOUT_CLASSIFICATION,//  The SIMD optimized form of "a <= b" is "((b - a) >>> 63) ^ 1" 
Hive,WITHOUT_CLASSIFICATION,//  Find databases which name contains _to_find_ 
Hive,WITHOUT_CLASSIFICATION,// Unicode case. 
Hive,WITHOUT_CLASSIFICATION,//  To find if a given (owid rowId) pair is deleted or not we perform   two binary searches at most. The first binary search is on the   compressed owids. If a match is found only then we do the next   binary search in the larger rowId vector between the given toIndex & fromIndex. 
Hive,WITHOUT_CLASSIFICATION,//  Stolen from Hive's MetricsTestUtils.  Probably should break it out into it's own class. 
Hive,WITHOUT_CLASSIFICATION,//  doesn't have a notion of small and saves the full value as an int so no overflow   expected:<null> but was:<32768> 
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.llap.plugin.rpc.LlapPluginProtocolProtos.UpdateQueryRequestProto.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,//  Run initialization statements on the connection 
Hive,WITHOUT_CLASSIFICATION,//  Avro should always use the table properties for initialization (see HIVE-6835). 
Hive,WITHOUT_CLASSIFICATION,//  there is more than one FK 
Hive,WITHOUT_CLASSIFICATION,//  MY_STRUCTSET 
Hive,WITHOUT_CLASSIFICATION,//  8 bytes per long in the refs assume data will be empty. This is just a sanity check. 
Hive,WITHOUT_CLASSIFICATION,//  The bucket value should be same for all the records. 
Hive,WITHOUT_CLASSIFICATION,//  NONE pattern 
Hive,WITHOUT_CLASSIFICATION,//  We want to have only one auth bridge.  In the past this was handled by ShimLoader but since   we're no longer using that we'll do it here. 
Hive,WITHOUT_CLASSIFICATION,//  Check that the data is removed 
Hive,WITHOUT_CLASSIFICATION,//  partition 
Hive,WITHOUT_CLASSIFICATION,//  Write any remaining bytes to the out stream. 
Hive,WITHOUT_CLASSIFICATION,//  test getMaterializedViewsForRewriting 
Hive,WITHOUT_CLASSIFICATION,//  If isExternalQuery -> the call is from within hte daemon so no permission check required 
Hive,WITHOUT_CLASSIFICATION,//  The output of a partial aggregation is a struct containing   a long count two double averages two double variances   and a double covariance. 
Hive,WITHOUT_CLASSIFICATION,//  We will cache if we have the entire part. 
Hive,WITHOUT_CLASSIFICATION,//  Parse until union separator (currentLevel). 
Hive,WITHOUT_CLASSIFICATION,//  The query should be completed by now 
Hive,WITHOUT_CLASSIFICATION,//  No input parameters. 
Hive,WITHOUT_CLASSIFICATION,//  This is our way of documenting that we are MUTATING the contents of   this writable's internal timestamp. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see org.apache.hadoop.hive.ql.exec.Operator#processOp(java.lang.Object   * int) this processor has a push-pull model. First call to this method is a   * push but the rest is pulled until we run out of records.    */
Hive,WITHOUT_CLASSIFICATION,//  Backward-compatibility interfaces for functions without a user-visible name. 
Hive,WITHOUT_CLASSIFICATION,// when last txn finished (abort/commit) the currentTxnIndex is pointing at that txn  so we need to start from next one if any.  Also if batch was created but  fetchTransactionBatch() was never called we want to start with first txn 
Hive,WITHOUT_CLASSIFICATION,//  Statistics 
Hive,WITHOUT_CLASSIFICATION,//  sum(c) 
Hive,WITHOUT_CLASSIFICATION,//  No need to check guaranteed here; if it was false we would already be in the queue. 
Hive,WITHOUT_CLASSIFICATION,//  SHARED_SDPARTITION_SPEC 
Hive,WITHOUT_CLASSIFICATION,//  For ORC and Parquet all the following statements are the same   ANALYZE TABLE T [PARTITION (...)] COMPUTE STATISTICS   ANALYZE TABLE T [PARTITION (...)] COMPUTE STATISTICS noscan; 
Hive,WITHOUT_CLASSIFICATION,//  Create limit desc with limit value 
Hive,WITHOUT_CLASSIFICATION,//  become available. 
Hive,WITHOUT_CLASSIFICATION,//  Call the real preCreateTable method 
Hive,WITHOUT_CLASSIFICATION,//  the general column statistics 
Hive,WITHOUT_CLASSIFICATION,//  test that schema was loaded correctly 
Hive,WITHOUT_CLASSIFICATION,// assertEquals(expected row); 
Hive,WITHOUT_CLASSIFICATION,//  This should make the search linear sync to the beginning of the block being searched   [50 100] set the comparison to be null and the flag to reset the range should be unset 
Hive,WITHOUT_CLASSIFICATION,//  All columns of the expression must be partitioned columns 
Hive,WITHOUT_CLASSIFICATION,//  Iterate over all expression (either after SELECT or in SELECT TRANSFORM) 
Hive,WITHOUT_CLASSIFICATION,//  If the values are equal the queue limit is fixed. 
Hive,WITHOUT_CLASSIFICATION,//  Only store the latest error if there are multiple. 
Hive,WITHOUT_CLASSIFICATION,// check if admin option has been specified 
Hive,WITHOUT_CLASSIFICATION,//  Stack methods 
Hive,WITHOUT_CLASSIFICATION,//  Test that existing shared_write db with new shared_write coalesces to 
Hive,WITHOUT_CLASSIFICATION,//  verify that udf in whitelist can be executed 
Hive,WITHOUT_CLASSIFICATION,//  error with driver 
Hive,WITHOUT_CLASSIFICATION,//  In case of lateral views followed by a join the same tree   can be traversed more than one 
Hive,WITHOUT_CLASSIFICATION,//  Operator allPath = op; 
Hive,WITHOUT_CLASSIFICATION,//  store post-exec hooks calls so we can look at them later 
Hive,WITHOUT_CLASSIFICATION,//  Only meant for use by the QueryTracker 
Hive,WITHOUT_CLASSIFICATION,//  We have to add this bit of exception handling here because Function.apply does not allow us to throw   the actual exception that might be a checked exception so we wind up needing to throw a RuntimeException   with the previously thrown exception as its cause. However since RuntimeException.getCause() returns   a throwable instead of an Exception we have to account for the possibility that the underlying code   might have thrown a Throwable that we wrapped instead in which case continuing to throw the   RuntimeException is the best thing we can do. 
Hive,WITHOUT_CLASSIFICATION,// List<String> rs = runStatementOnDriver("select ab from " + Table.ACIDTBL + " order by ab");  Assert.assertEquals("Data didn't match in autocommit=true (rs)" stringifyValues(rows1) rs); 
Hive,WITHOUT_CLASSIFICATION,//  Add the rest of the metadata keys. 
Hive,WITHOUT_CLASSIFICATION,//  [path2 shared] 
Hive,WITHOUT_CLASSIFICATION,//  For getDetailedReadPositionString. 
Hive,WITHOUT_CLASSIFICATION,//  Originally the mvTask and the child move task of the mrAndMvTask contain the same   MoveWork object.   If the blobstore optimizations are on and the input/output paths are merged   in the move only MoveWork the mvTask and the child move task of the mrAndMvTask   will contain different MoveWork objects which causes problems.   Not just in this case but also in general the child move task of the mrAndMvTask should 
Hive,WITHOUT_CLASSIFICATION,//  2. analyze create table command 
Hive,WITHOUT_CLASSIFICATION,// now copy over the data when isNull[index] is false 
Hive,WITHOUT_CLASSIFICATION,/*    * Tests if LOCATION_3 is returned when the first file is found is later in lookup order    */
Hive,WITHOUT_CLASSIFICATION,//  convert the rest and put into the last entry 
Hive,WITHOUT_CLASSIFICATION,//  retrieved from object cache 
Hive,WITHOUT_CLASSIFICATION,//  add virtual columns for ANALYZE TABLE 
Hive,WITHOUT_CLASSIFICATION,//  The "not vectorized" information has been stored in the MapWork vertex. 
Hive,WITHOUT_CLASSIFICATION,/*      * Count null input which is for COUNT(*) and output is LONG.     *     * Just modes (PARTIAL1 COMPLETE).      */
Hive,WITHOUT_CLASSIFICATION,//  Then if the buffer was in the list remove it. 
Hive,WITHOUT_CLASSIFICATION,//  cast on single column 
Hive,WITHOUT_CLASSIFICATION,//  Remove semijoin optimization if it creates a cycle with mapside joins 
Hive,WITHOUT_CLASSIFICATION,//  we need to first join and flush out data left by the previous file. 
Hive,WITHOUT_CLASSIFICATION,//  local mode 
Hive,WITHOUT_CLASSIFICATION,//  REPL LOAD is not partition level. It is always DB or table level. So passing null for partition specs.   Also REPL LOAD doesn't support external table and hence no location set as well. 
Hive,WITHOUT_CLASSIFICATION,//  The token file location and mapreduce job tag should be right after the tool argument 
Hive,WITHOUT_CLASSIFICATION,//  Fail - trying to set "transactional" to "false" is not allowed 
Hive,WITHOUT_CLASSIFICATION,//  Global used when setting errors etc. 
Hive,WITHOUT_CLASSIFICATION,//  long BETWEEN 
Hive,WITHOUT_CLASSIFICATION,//  Not closing this at the moment at shutdown since this could be a shared instance. 
Hive,WITHOUT_CLASSIFICATION,/*    * findRoots returns all root operators (in ops) that result in operator op    */
Hive,WITHOUT_CLASSIFICATION,//  Not really much we can do here. 
Hive,WITHOUT_CLASSIFICATION,//  Always use localhost for hostname as some tests like SSL CN validation ones   are tied to localhost being present in the certificate name 
Hive,WITHOUT_CLASSIFICATION,/*  256 files x 1000 size for 11 splits  */
Hive,WITHOUT_CLASSIFICATION,//  Schedule outside of the scheduleLock - which should only be used to wait on the condition. 
Hive,WITHOUT_CLASSIFICATION,//  Since we store references to HiveDecimalWritable instances we must use the update method instead   of plain assignment. 
Hive,WITHOUT_CLASSIFICATION,//  todo: invalid + valid = invalid 
Hive,WITHOUT_CLASSIFICATION,//  If there is an end node that not the limit0/wherefalse.. 
Hive,WITHOUT_CLASSIFICATION,//  We need to fetch the table before it is dropped so that it can be passed to   post-execution hook 
Hive,WITHOUT_CLASSIFICATION,//  This can happen if all values in stream are nulls or last row group values are all null. 
Hive,WITHOUT_CLASSIFICATION,//  float/double. String types have no default value for null. 
Hive,WITHOUT_CLASSIFICATION,/*    * Dependency is a class used for explain    */
Hive,WITHOUT_CLASSIFICATION,//  Note that this uses short user name without consideration for Kerberos realm.   This seems to be the common approach (e.g. for HDFS permissions) but it may be   better to consider the realm (although not the host so not the full name). 
Hive,WITHOUT_CLASSIFICATION,//  First we need to check if it is valid to convert to MERGE/INSERT INTO.   If we succeed we modify the plan and afterwards the AST.   MV should be an acid table. 
Hive,WITHOUT_CLASSIFICATION,//  hcat.py will become the first argument pass to command "python" 
Hive,WITHOUT_CLASSIFICATION,//  modify it in the middle for view rewrite. 
Hive,WITHOUT_CLASSIFICATION,//  Check if the status of all the columns of all the partitions exists 
Hive,WITHOUT_CLASSIFICATION,//  De-serialization code 
Hive,WITHOUT_CLASSIFICATION,//  +20 from the duplicate publish 
Hive,WITHOUT_CLASSIFICATION,// x=y 
Hive,WITHOUT_CLASSIFICATION,//  It cannot contain a non-deterministic function 
Hive,WITHOUT_CLASSIFICATION,//  Inherit Java system variables 
Hive,WITHOUT_CLASSIFICATION,//  Note: we could just do what we already do above from disk data except for the validation   that is not strictly necessary and knownTornStart which is an optimization. 
Hive,WITHOUT_CLASSIFICATION,//  [null null] not allowed so this check is ok. 
Hive,WITHOUT_CLASSIFICATION,//  Drop all the tables 
Hive,WITHOUT_CLASSIFICATION,//  Do not set an environment context. 
Hive,WITHOUT_CLASSIFICATION,//  we have to set ndv 
Hive,WITHOUT_CLASSIFICATION,//  column exprmap. 
Hive,WITHOUT_CLASSIFICATION,//  GRANT_TIME 
Hive,WITHOUT_CLASSIFICATION,/*  * An single LONG key hash set optimized for vector map join.  */
Hive,WITHOUT_CLASSIFICATION,//  Literal decimal 
Hive,WITHOUT_CLASSIFICATION,//  For current schema evolution. 
Hive,WITHOUT_CLASSIFICATION,// method in HiveMetaStoreClient 
Hive,WITHOUT_CLASSIFICATION,//  Compare timestamp to integer seconds or double seconds with fractional nanoseonds. 
Hive,WITHOUT_CLASSIFICATION,//  ignore it will be generated by SEL op 
Hive,WITHOUT_CLASSIFICATION,//  v[1] v[0] 
Hive,WITHOUT_CLASSIFICATION,//  Generate sortCols and order 
Hive,WITHOUT_CLASSIFICATION,//  Create a dummy task if no move is needed. 
Hive,WITHOUT_CLASSIFICATION,//  This correlator was generated by a previous invocation of   this rule. No further work to do. 
Hive,WITHOUT_CLASSIFICATION,// volatile because heartbeat() may be in a "different" thread 
Hive,WITHOUT_CLASSIFICATION,//  Lock entire heap; heap is still full; we should not be able to evict or insert. 
Hive,WITHOUT_CLASSIFICATION,//  of the nullable side of the OJ. 
Hive,WITHOUT_CLASSIFICATION,//  Check if the database location is in the default location based on the old warehouse root.   If so then change the database location to the default based on the current warehouse root. 
Hive,WITHOUT_CLASSIFICATION,//  Time zone file was written in from metadata 
Hive,WITHOUT_CLASSIFICATION,//  changes the value of a variable the corresponding change will be made in this mapping. 
Hive,WITHOUT_CLASSIFICATION,// Constructor used by HiveRexExecutorImpl 
Hive,WITHOUT_CLASSIFICATION,//        This only lives for the duration of the service init. 
Hive,WITHOUT_CLASSIFICATION,//  There could be races here e.g. heartbeat delivered us the old value just after we have   received a successful confirmation from the API so we are about to overwrite the latter.   We could solve this by adding a version or smth like that; or by ignoring discrepancies   unless we have previously received an update error for this task; however the only effect 
Hive,WITHOUT_CLASSIFICATION,//  Don't clear the attempt ID or the stuff will be cleared. 
Hive,WITHOUT_CLASSIFICATION,/*          * Single-Column Long specific variables.          */
Hive,WITHOUT_CLASSIFICATION,//  projections from child? 
Hive,WITHOUT_CLASSIFICATION,//  first group 
Hive,WITHOUT_CLASSIFICATION,//  get [local time at toZone] 
Hive,WITHOUT_CLASSIFICATION,//  If retrieveCD is false we do not need to do a deep retrieval of the Table Column Descriptor. 
Hive,WITHOUT_CLASSIFICATION,//  execute cli driver work 
Hive,WITHOUT_CLASSIFICATION,//  Construct a column statistics object from the result 
Hive,WITHOUT_CLASSIFICATION,//  If there are more than 1 children at any level don't do anything 
Hive,WITHOUT_CLASSIFICATION,//  Now do a general lookup 
Hive,WITHOUT_CLASSIFICATION,//  nothing to do when the optimization is off 
Hive,WITHOUT_CLASSIFICATION,//  LAST_ACCESS_TIME 
Hive,WITHOUT_CLASSIFICATION,//  The underlying SSLSocket object is bound to host:port with the given SO_TIMEOUT and   SSLContext created with the given params 
Hive,WITHOUT_CLASSIFICATION,// Given jar to add is stored as key  and all its transitive dependencies as value. Used for deleting transitive dependencies. 
Hive,WITHOUT_CLASSIFICATION,//  Test from server to client too. 
Hive,WITHOUT_CLASSIFICATION,// This can be set for old behavior of nulls printed as empty strings 
Hive,WITHOUT_CLASSIFICATION,//  SESSION_HANDLE 
Hive,WITHOUT_CLASSIFICATION,// make non-blocking 
Hive,WITHOUT_CLASSIFICATION,/*    * - A Window Frame that has only the start boundary then it is interpreted as:   *     BETWEEN <start boundary> AND CURRENT ROW   * - A Window Specification with an Order Specification and no Window Frame is   *   interpreted as: RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW   * - A Window Specification with no Order and no Window Frame is interpreted as:   *     ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING    */
Hive,WITHOUT_CLASSIFICATION,//  separate split 
Hive,WITHOUT_CLASSIFICATION,//  add -s and --scratchdir to specify a non-default scratch dir 
Hive,WITHOUT_CLASSIFICATION,//  We handle TableScanOperator here as we can safely ignore table alias   and the current comparator implementation does not. 
Hive,WITHOUT_CLASSIFICATION,/*    * Check if the input line is a multi-line command which needs to read further    */
Hive,WITHOUT_CLASSIFICATION,//  2) We extract the collation for this operator and the collations 
Hive,WITHOUT_CLASSIFICATION,//  set output format parameters (these are not supported by QL but only 
Hive,WITHOUT_CLASSIFICATION,//  See if a custom CompositeKey class was provided 
Hive,WITHOUT_CLASSIFICATION,//  Doing characters comparison directly instead of regular expression   matching for simple patterns like "%abc%". 
Hive,WITHOUT_CLASSIFICATION,//  anything but a " in "" 
Hive,WITHOUT_CLASSIFICATION,//  Swap column vectors but keep selected vector unchanged 
Hive,WITHOUT_CLASSIFICATION,//  These members are used as out-of-band params   for the inner-loop supper.processOp callbacks 
Hive,WITHOUT_CLASSIFICATION,//  - There cannot exist any (distinct) aggregate. 
Hive,WITHOUT_CLASSIFICATION,//  Don't actually create the key 
Hive,WITHOUT_CLASSIFICATION,//  Can the join operator be converted to a sort-merge join operator ? 
Hive,WITHOUT_CLASSIFICATION,//  can retrieve it later. 
Hive,WITHOUT_CLASSIFICATION,//  Ignore files eliminated by PPD or of 0 length. 
Hive,WITHOUT_CLASSIFICATION,//  Above should have thrown NoSuchObjectException if there is no such catalog 
Hive,WITHOUT_CLASSIFICATION,//  idempotent case for destdb db 
Hive,WITHOUT_CLASSIFICATION,//  There may be a race for this slot so re-query after a delay with some probability. 
Hive,WITHOUT_CLASSIFICATION,//  serialize the row as BytesWritable 
Hive,WITHOUT_CLASSIFICATION,//  Don't propagate errors from close() since this will lose the original error above. 
Hive,WITHOUT_CLASSIFICATION,//  There are not enough failed compactions yet so checkFailedCompactions() should return false. 
Hive,WITHOUT_CLASSIFICATION,//  so figure out if we can lock it too. 
Hive,WITHOUT_CLASSIFICATION,//  optional bytes user_payload = 1; 
Hive,WITHOUT_CLASSIFICATION,//  calculate key once; lookup once. 
Hive,WITHOUT_CLASSIFICATION,//  Invoke the method 
Hive,WITHOUT_CLASSIFICATION,//  JDBC 1 driver error 
Hive,WITHOUT_CLASSIFICATION,//  Check whether this is a list or a map 
Hive,WITHOUT_CLASSIFICATION,//  Augment conf with the settings from the started llap configuration. 
Hive,WITHOUT_CLASSIFICATION,//  map of original column id -> index among selected columns 
Hive,WITHOUT_CLASSIFICATION,//  1.2 Now generate RS operator 
Hive,WITHOUT_CLASSIFICATION,//  Update out_rwsch 
Hive,WITHOUT_CLASSIFICATION,//  make new generated task depends on all the parent tasks of current task. 
Hive,WITHOUT_CLASSIFICATION,// convert the table to Acid  //todo: remove trans_prop after HIVE-17089 
Hive,WITHOUT_CLASSIFICATION,// random md5 
Hive,WITHOUT_CLASSIFICATION,/*  Patterns that are included in performance logging level.     * In performance mode show execution and performance logger messages.      */
Hive,WITHOUT_CLASSIFICATION,/*      * Now determine the small table results.      */
Hive,WITHOUT_CLASSIFICATION,//  loop over all the operators recursively 
Hive,WITHOUT_CLASSIFICATION,//  TODO: use fileId right from the list after HDFS-7878; or get dfs client and do it 
Hive,WITHOUT_CLASSIFICATION,/*    * Generate the ReduceSinkOperator for the Group By Query Block   * (qb.getPartInfo().getXXX(dest)). The new ReduceSinkOperator will be a child   * of inputOperatorInfo.   *   * It will put all Group By keys and the distinct field (if any) in the   * map-reduce sort key and all other fields in the map-reduce value.   *   * @param numPartitionFields   *          the number of fields for map-reduce partitioning. This is usually   *          the number of fields in the Group By keys.   * @return the new ReduceSinkOperator.   * @throws SemanticException    */
Hive,WITHOUT_CLASSIFICATION,//  data should not be visible 
Hive,WITHOUT_CLASSIFICATION,//  Drop two files so they are moved to CM 
Hive,WITHOUT_CLASSIFICATION,//  current map join is null means it has been handled by CurrentMapJoin   process. 
Hive,WITHOUT_CLASSIFICATION,//  It is a cartesian product row count is easy to infer 
Hive,WITHOUT_CLASSIFICATION,//  max of numBitVectors = 1024 2 bytes is enough. 
Hive,WITHOUT_CLASSIFICATION,//  This will be null at master. 
Hive,WITHOUT_CLASSIFICATION,// since LM is using non strict mode we get shared lock 
Hive,WITHOUT_CLASSIFICATION,//  6. Set synthetic flag so that we would push filter below this one 
Hive,WITHOUT_CLASSIFICATION,//  check if argument is a string or an array of strings 
Hive,WITHOUT_CLASSIFICATION,// remove trailing comma 
Hive,WITHOUT_CLASSIFICATION,//  Workaround for HIVE_DEFAULT_PARTITION - ignore it like JDO does for now. 
Hive,WITHOUT_CLASSIFICATION,//  If sizes of at least n-1 tables in a n-way join is known and their sum is smaller than 
Hive,WITHOUT_CLASSIFICATION,//  Get the return ObjectInspector. 
Hive,WITHOUT_CLASSIFICATION,// since this is on conversion from non-acid to acid NEXT_WRITE_ID should not have an entry  for this table.  It also has a unique index in case 'should not' is violated 
Hive,WITHOUT_CLASSIFICATION,//  Recheck to make sure someone didn't create it while we waited. 
Hive,WITHOUT_CLASSIFICATION,//  assert that the table created has no hcat instrumentation and that we're still able to read it. 
Hive,WITHOUT_CLASSIFICATION,//  Check if table is transactional 
Hive,WITHOUT_CLASSIFICATION,//  We have to manually re-set it in the JobConf to make sure it gets picked up. 
Hive,WITHOUT_CLASSIFICATION,//  Property defined in hive-site.xml only 
Hive,WITHOUT_CLASSIFICATION,//  for now this should be true... 
Hive,WITHOUT_CLASSIFICATION,// currently multi-insrt doesn't allow same table/partition in > 1 output branch 
Hive,WITHOUT_CLASSIFICATION,//  TYPE_CLASS_NAME 
Hive,WITHOUT_CLASSIFICATION,//  Timestamp is represented as long internally no need to any thing here 
Hive,WITHOUT_CLASSIFICATION,/*  RandomAccessFileManager.DEFAULT_BUFFER_SIZE  */
Hive,WITHOUT_CLASSIFICATION,//  We are now "sending" a message... update again "return" both callbacks. 
Hive,WITHOUT_CLASSIFICATION,//  Mark this task as a final map reduce task (ignoring the optional merge task) 
Hive,WITHOUT_CLASSIFICATION,//  intermediate outputs of joins/groupbys 
Hive,WITHOUT_CLASSIFICATION,//  Used by all flavors. 
Hive,WITHOUT_CLASSIFICATION,//  construct column name list and types for reference by filter push down 
Hive,WITHOUT_CLASSIFICATION,//  For partition-less table initialize partValue to empty string.   We can have partition-less table even if we have partition keys   when there is only only partition selected and the partition key is not   part of the projection/include list. 
Hive,WITHOUT_CLASSIFICATION,//  Magic value usage is invalid with nanoTime so once in a 1000 years we may log extra. 
Hive,WITHOUT_CLASSIFICATION,//  close writer 
Hive,WITHOUT_CLASSIFICATION,//  call-6: file stat - split 2 => mock:/mocktable6/0_0 
Hive,WITHOUT_CLASSIFICATION,//  if exception happens after doCopyOnce then need to call getFilesToRetry with copy error as false in retry. 
Hive,WITHOUT_CLASSIFICATION,//  these many values to reach beginning of the row group 
Hive,WITHOUT_CLASSIFICATION,//  write the blob 
Hive,WITHOUT_CLASSIFICATION,//  simple tree with single parent 
Hive,WITHOUT_CLASSIFICATION,//  this session should never be a default session unless something has messed up. 
Hive,WITHOUT_CLASSIFICATION,//  When done handleUpdate.. may break the iterator so the order of these checks is important. 
Hive,WITHOUT_CLASSIFICATION,//  Load the hash table 
Hive,WITHOUT_CLASSIFICATION,//  Get rid of spills before we start modifying the batch. 
Hive,WITHOUT_CLASSIFICATION,//  violating which can cause data loss 
Hive,WITHOUT_CLASSIFICATION,//  2 elements: "key" "value" 
Hive,WITHOUT_CLASSIFICATION,/*    * Compare the two map objects for equality.    */
Hive,WITHOUT_CLASSIFICATION,//  if database itself is null then we can not filter out anything. 
Hive,WITHOUT_CLASSIFICATION,//  parameter value is still false in 1st connection.  The alter still goes through. 
Hive,WITHOUT_CLASSIFICATION,//  Can be null since the task may have completed meanwhile. 
Hive,WITHOUT_CLASSIFICATION,//  The SIMD optimized form of "a > b" is "(b - a) >>> 63" 
Hive,WITHOUT_CLASSIFICATION,//  Test setter for configuration object. 
Hive,WITHOUT_CLASSIFICATION,//  Unless at least one of '/' or '@' was not found in 
Hive,WITHOUT_CLASSIFICATION,//  Remove DPP based on expected size of the output data 
Hive,WITHOUT_CLASSIFICATION,//  extract stage plans 
Hive,WITHOUT_CLASSIFICATION,//  Verify that session wasn't closed on transport close. 
Hive,WITHOUT_CLASSIFICATION,//  Move data from temp directory the actual table directory   No metastore operation required. 
Hive,WITHOUT_CLASSIFICATION,//  Constants for 128 bit variant 
Hive,WITHOUT_CLASSIFICATION,//  Need to check the original schema to see if this is actually a Fixed. 
Hive,WITHOUT_CLASSIFICATION,//  Get all the driver run hooks and pre-execute them. 
Hive,WITHOUT_CLASSIFICATION,//  tab1 tab2 
Hive,WITHOUT_CLASSIFICATION,//  check aggOutputProj projects only one expression 
Hive,WITHOUT_CLASSIFICATION,// run("CREATE MATERIALIZED VIEW " + dbName + ".mat_view2 AS SELECT * FROM " + dbName + ".unptned" driver);  verifySetup("SELECT * from " + dbName + ".mat_view2" unptn_data driver); 
Hive,WITHOUT_CLASSIFICATION,//  This should never happen at least for now. Throw? 
Hive,WITHOUT_CLASSIFICATION,//          FilterInputRel 
Hive,WITHOUT_CLASSIFICATION,/*    * a subclass must indicate whether it will transform the raw input before it is fed through the   * partitioning mechanics.    */
Hive,WITHOUT_CLASSIFICATION,//  Tracks instances known by both YARN Service and llap. 
Hive,WITHOUT_CLASSIFICATION,//  let's don't fail on future timeout since we have a timeout for pre-warm 
Hive,WITHOUT_CLASSIFICATION,//  the join 
Hive,WITHOUT_CLASSIFICATION,/*  10 files x 100 size for 111 splits  */
Hive,WITHOUT_CLASSIFICATION,//  DummyMataStoreInitListener's onInit will be called at HMSHandler   initialization and set this to true 
Hive,WITHOUT_CLASSIFICATION,//  This method will return only after the cache has updated once 
Hive,WITHOUT_CLASSIFICATION,//  Test basic truncate of bytes slice. 
Hive,WITHOUT_CLASSIFICATION,//  task (typically a task gets re-run up to 4 times if it fails. 
Hive,WITHOUT_CLASSIFICATION,// http://hadoop.apache.org/docs/r1.1.1/api/org/apache/hadoop/security/authentication/server/AuthenticationFilter.html 
Hive,WITHOUT_CLASSIFICATION,//  not null constraint name   default constraint name 
Hive,WITHOUT_CLASSIFICATION,//  we need extrapolation 
Hive,WITHOUT_CLASSIFICATION,//  also match for this to be converted to a map-only job. 
Hive,WITHOUT_CLASSIFICATION,//  Test with open transactions 
Hive,WITHOUT_CLASSIFICATION,//  Event 12 13 14 
Hive,WITHOUT_CLASSIFICATION,//  For all other kinds of operators assume the output is as big as the 
Hive,WITHOUT_CLASSIFICATION,//  set min NDV value to both columns involved in join 
Hive,WITHOUT_CLASSIFICATION,//  indicating that the previous cookie has expired. 
Hive,WITHOUT_CLASSIFICATION,//  HIVE-19096 - disable for explain analyze 
Hive,WITHOUT_CLASSIFICATION,//  We have a class-level annotation that says whether the UDF's vectorization expressions 
Hive,WITHOUT_CLASSIFICATION,//  Read database table partition via CachedStore 
Hive,WITHOUT_CLASSIFICATION,//  No support for DECIMAL_64 input.  We must convert. 
Hive,WITHOUT_CLASSIFICATION,//  we use the basic or the extended version of the optimizer. 
Hive,WITHOUT_CLASSIFICATION,/*    * Setup our 2nd batch with the same "column schema" as the big table batch that can be used to   * build join output results in.    */
Hive,WITHOUT_CLASSIFICATION,//  make sure we initialize if necessary 
Hive,WITHOUT_CLASSIFICATION,//  In 2 cases out of 3 we could pass the path and type directly to metastore... 
Hive,WITHOUT_CLASSIFICATION,//  create a new conf file using contents from current one 
Hive,WITHOUT_CLASSIFICATION,//  A mapping from a tableName to a table object in metastore. 
Hive,WITHOUT_CLASSIFICATION,// change the table name back 
Hive,WITHOUT_CLASSIFICATION,/*    * Job callable task for job list operation. Overrides behavior of execute() to list jobs.   * No need to override behavior of cleanup() as there is nothing to be done if list jobs   * operation is timed out or interrupted.    */
Hive,WITHOUT_CLASSIFICATION,//  write the orc file to the mock file system 
Hive,WITHOUT_CLASSIFICATION,//  reset keyValueSeparatorPosition 
Hive,WITHOUT_CLASSIFICATION,//  Unlock the previous lock 
Hive,WITHOUT_CLASSIFICATION,// test WritableBinaryObjectInspector 
Hive,WITHOUT_CLASSIFICATION,//  Create warehouse with 777 so that user impersonation has no issues. 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:UserPayloadProto) 
Hive,WITHOUT_CLASSIFICATION,//  touch the next file 
Hive,WITHOUT_CLASSIFICATION,//  Step 2 : create the Insert query 
Hive,WITHOUT_CLASSIFICATION,//  Now calculate which rows were filtered out (they are logically no matches). 
Hive,WITHOUT_CLASSIFICATION,//  PATTERN 
Hive,WITHOUT_CLASSIFICATION,//  Write key to buffer to compute hashcode and compare; if it's a new key it will 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:GetTokenRequestProto) 
Hive,WITHOUT_CLASSIFICATION,//  If this function is called the parent should only include constant 
Hive,WITHOUT_CLASSIFICATION,//  Method to get the Valid write ids list for the given table 
Hive,WITHOUT_CLASSIFICATION,//  Worker threads stuff 
Hive,WITHOUT_CLASSIFICATION,//  Create a test table 
Hive,WITHOUT_CLASSIFICATION,//  to no_auto_compact we need to check it in both cases. 
Hive,WITHOUT_CLASSIFICATION,//  We will touch all blocks in random order. 
Hive,WITHOUT_CLASSIFICATION,//  updates key with sequence number 
Hive,WITHOUT_CLASSIFICATION,//  This thread should throw an exception 
Hive,WITHOUT_CLASSIFICATION,/*  2*3 =  */
Hive,WITHOUT_CLASSIFICATION,//  Successfully insert some data into ACID tables so that we have records in COMPLETED_TXN_COMPONENTS 
Hive,WITHOUT_CLASSIFICATION,// delta_xxxx_yyyy format 
Hive,WITHOUT_CLASSIFICATION,//  Real column name - on which the operation is being performed 
Hive,WITHOUT_CLASSIFICATION,//  IGNORE 
Hive,WITHOUT_CLASSIFICATION,//  partition spec is not specified but column schema can have partitions specified 
Hive,WITHOUT_CLASSIFICATION,//  expression for the table. 
Hive,WITHOUT_CLASSIFICATION,// Ignored the mbean itself was not found which should never happen because we  just accessed it (perhaps something unregistered in-between) but if this  happens just don't output the attribute. 
Hive,WITHOUT_CLASSIFICATION,//  For local src file copy to hdfs 
Hive,WITHOUT_CLASSIFICATION,//  GroupBy1 into the reduce keys. 
Hive,WITHOUT_CLASSIFICATION,//  EncodedColumnBatch is already decompressed we don't really need to pass codec.   But we need to know if the original data is compressed or not. This is used to skip   positions in row index properly. If the file is originally compressed   then 1st position (compressed offset) in row index should be skipped to get   uncompressed offset else 1st position should not be skipped. 
Hive,WITHOUT_CLASSIFICATION,//  add all except the right side to the bad positions 
Hive,WITHOUT_CLASSIFICATION,//  The else clause 
Hive,WITHOUT_CLASSIFICATION,//  Perform compaction. Join result after compaction should still be the same 
Hive,WITHOUT_CLASSIFICATION,/*        * Multi-Key Long check for repeating.        */
Hive,WITHOUT_CLASSIFICATION,//  Write the escaped byte. 
Hive,WITHOUT_CLASSIFICATION,//  6.4 Build ExprNode corresponding to colums 
Hive,WITHOUT_CLASSIFICATION,//  3. If the new conjuncts are already present in the plan we bail out 
Hive,WITHOUT_CLASSIFICATION,//  The value doesn't matter 
Hive,WITHOUT_CLASSIFICATION,//  Regardless whether it was removed successfully or after failing to remove restart it.   Since we just restart this from under the user mark it so we handle it properly when 
Hive,WITHOUT_CLASSIFICATION,//  Mark one of the transactions as an exception to test that invalid transactions   are being handled properly.   Exclude transaction 5 
Hive,WITHOUT_CLASSIFICATION,//  Commit the txn under HWM. 
Hive,WITHOUT_CLASSIFICATION,//  Spot check decimal column modulo decimal column 
Hive,WITHOUT_CLASSIFICATION,//  special char 
Hive,WITHOUT_CLASSIFICATION,//  We cannot obtain a better estimate without CustomPartitionVertex providing it   to us somehow; in which case using statistics would be completely unnecessary. 
Hive,WITHOUT_CLASSIFICATION,//  The target data is in TextInputFormat. 
Hive,WITHOUT_CLASSIFICATION,//  Definitely not a byte. 
Hive,WITHOUT_CLASSIFICATION,//  Fits in two longwords. 
Hive,WITHOUT_CLASSIFICATION,//  Hint to disable runtime filtering. 
Hive,WITHOUT_CLASSIFICATION,//   we need to evaluate result for every pruned partition 
Hive,WITHOUT_CLASSIFICATION,//  Not a transactional op nothing more to do 
Hive,WITHOUT_CLASSIFICATION,//  Go through the argClasses and for any string void or date time start   looking for doubles 
Hive,WITHOUT_CLASSIFICATION,//  out   of   range   due   to   time!=0 
Hive,WITHOUT_CLASSIFICATION,//  number of bits to store the number of zero runs 
Hive,WITHOUT_CLASSIFICATION,//  Get the latest timestamp of all the cells as the row timestamp   from hbase-0.96.0 
Hive,WITHOUT_CLASSIFICATION,//  Whether this operator is an outer join. 
Hive,WITHOUT_CLASSIFICATION,// to see it working in UTs 
Hive,WITHOUT_CLASSIFICATION,//  All DML should fail with DummyTxnManager on ACID table 
Hive,WITHOUT_CLASSIFICATION,//  The table alias should exist 
Hive,WITHOUT_CLASSIFICATION,//  Second INSERT round with new inserts into previously existing partition 'yesterday'. 
Hive,WITHOUT_CLASSIFICATION,//  Override external stuff. These could also be injected as extra classes. 
Hive,WITHOUT_CLASSIFICATION,//  set a small time unit as cookie max age so that the server sends a 401 
Hive,WITHOUT_CLASSIFICATION,// no need to pass virtual columns to reader. 
Hive,WITHOUT_CLASSIFICATION,//  This is intentionally duplicated because of HIVE-3179 
Hive,WITHOUT_CLASSIFICATION,//  in the future could allow users to specify a quote character that doesn't   need escaping but for now ... 
Hive,WITHOUT_CLASSIFICATION,//  if we did not see a skew key in this table continue to next   table 
Hive,WITHOUT_CLASSIFICATION,//  Assumption: top portion of tree could only be   (limit)?(OB)?(Project).... 
Hive,WITHOUT_CLASSIFICATION,//  for now expose non-primitive as a string 
Hive,WITHOUT_CLASSIFICATION,//  reallocate only if any filters pruned 
Hive,WITHOUT_CLASSIFICATION,//  1. get all the stats for colNames in partNames; 
Hive,WITHOUT_CLASSIFICATION,//  3rd close: 
Hive,WITHOUT_CLASSIFICATION,//  EVENT_ID 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#rollback(java.sql.Savepoint)    */
Hive,WITHOUT_CLASSIFICATION,//  Read enough data for just the first message to be decoded. 
Hive,WITHOUT_CLASSIFICATION,//  MAX_DECIMAL 9's WITH NO ROUND (longer than 38 digits) 
Hive,WITHOUT_CLASSIFICATION,//  Validate the first parameter which is the expression to compute over. This should be a 
Hive,WITHOUT_CLASSIFICATION,//  verify that non whitelist params can't be set 
Hive,WITHOUT_CLASSIFICATION,//  Hadoop 1 doesn't support credential merging so this will fail. 
Hive,WITHOUT_CLASSIFICATION,//  Initialize the rowId array when we have some delete events. 
Hive,WITHOUT_CLASSIFICATION,//  TODO RS+JOIN 
Hive,WITHOUT_CLASSIFICATION,//  Find the index of the least significant bit that is 1 
Hive,WITHOUT_CLASSIFICATION,//  Testing with nulls 
Hive,WITHOUT_CLASSIFICATION,//  SR.SW: Lock we are examining is shared write 
Hive,WITHOUT_CLASSIFICATION,//  Use the remapped arguments for the (non)distinct aggregate calls 
Hive,WITHOUT_CLASSIFICATION,//  Caching instances only in case of the YARN registry. Each host based list will get it's own copy. 
Hive,WITHOUT_CLASSIFICATION,//  overflow batchs... 
Hive,WITHOUT_CLASSIFICATION,//  Write json to the temp file 
Hive,WITHOUT_CLASSIFICATION,//  left border is the min 
Hive,WITHOUT_CLASSIFICATION,/*      * If we have more than one group key batch we will buffer their contents.     * We don't buffer the key columns since they are a constant for the group key.     *     * We buffer the non-key input columns.  And we buffer any streaming columns that will already     * have their output values.      */
Hive,WITHOUT_CLASSIFICATION,//  There are some txns in the list which does not have write id allocated and hence go ahead and do it.   Get the next write id for the given table and update it with new next write id. 
Hive,WITHOUT_CLASSIFICATION,//  get the databases for the desired pattern - populate the output stream 
Hive,WITHOUT_CLASSIFICATION,//  FLAG 
Hive,WITHOUT_CLASSIFICATION,//  we're dealing with an array of strings 
Hive,WITHOUT_CLASSIFICATION,/*    * - a partitionTableFunctionSource can be a tableReference a SubQuery or another   *   PTF invocation.   * - For a TABLEREF: set the source to the alias returned by processTable   * - For a SubQuery: set the source to the alias returned by processSubQuery   * - For a PTF invocation: recursively call processPTFChain.    */
Hive,WITHOUT_CLASSIFICATION,//  Implement if needed. 
Hive,WITHOUT_CLASSIFICATION,//  walk through existing map to truncate path so that test won't mask it   then we can verify location is right 
Hive,WITHOUT_CLASSIFICATION,//  Should we propagate the error message properly? 
Hive,WITHOUT_CLASSIFICATION,/*    * Where in the inverse multiplication result to find the quotient integer decimal portion.   *   * Please see comments for doDecimalToBinaryDivisionRemainder.    */
Hive,WITHOUT_CLASSIFICATION,//  revert back to local fs 
Hive,WITHOUT_CLASSIFICATION,//  Resolve for the method based on argument types 
Hive,WITHOUT_CLASSIFICATION,//  "CREATE DATABASE" is specifically not replicated across per design since if a user   drops a database and recreates another with the same one we want to distinguish   between the two. We will replicate the drop across but after that the goal is   that if a new db is created a new replication definition should be created in   the replication implementer above this. Thus we extend NoopReplicationTask and   the only additional thing we do is validate event type. 
Hive,WITHOUT_CLASSIFICATION,//  Order of KEY columns   1) Partition columns   2) Bucket number column 
Hive,WITHOUT_CLASSIFICATION,/*         * Job request got interrupted. Job kill should have started. Return to client with        * with QueueException.         */
Hive,WITHOUT_CLASSIFICATION,//  verify that udf in default whitelist can be executed 
Hive,WITHOUT_CLASSIFICATION,//  Simply create 
Hive,WITHOUT_CLASSIFICATION,//  restore state of repeating and non nulls indicators 
Hive,WITHOUT_CLASSIFICATION,//  For now - decrement the count to avoid accounting errors. 
Hive,WITHOUT_CLASSIFICATION,//  So the starting position of grouping set need to be known 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:LlapPluginProtocol) 
Hive,WITHOUT_CLASSIFICATION,//  Additional conf settings specified on the command line 
Hive,WITHOUT_CLASSIFICATION,//  we need to translate the ExprNodeFieldDesc too e.g. identifiers in   struct<>. 
Hive,WITHOUT_CLASSIFICATION,//  Let the VectorAssignRow class do the conversion. 
Hive,WITHOUT_CLASSIFICATION,//  The call succeeded so presumably the API is there. 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:UpdateFragmentRequestProto) 
Hive,WITHOUT_CLASSIFICATION,//  Insert some data -> this will generate only insert deltas and no delete deltas: delta_3_3 
Hive,WITHOUT_CLASSIFICATION,//  Because we need to revert the tag of a row to its old tag and   we cannot pass new tag to this method which is used to get   the old tag from the mapping of newTagToOldTag we bypass   this method in MuxOperator and directly call process on children   in process() method.. 
Hive,WITHOUT_CLASSIFICATION,//  Should not be getting invoked configureInputJobProperties or configureOutputJobProperties   should be invoked instead. 
Hive,WITHOUT_CLASSIFICATION,//  we want to have project after join since sq_count_check's count() expression wouldn't   be needed further up 
Hive,WITHOUT_CLASSIFICATION,//  Called by LazyMap 
Hive,WITHOUT_CLASSIFICATION,/*  Print the per Vertex summary  */
Hive,WITHOUT_CLASSIFICATION,/*   * (non-Javadoc)  *  * @see  * org.apache.hadoop.hive.ql.security.authorization.HiveAuthorizationProvider  * #authorize(org.apache.hadoop.hive.ql.metadata.Table  * org.apache.hadoop.hive.ql.security.authorization.Privilege[]  * org.apache.hadoop.hive.ql.security.authorization.Privilege[])   */
Hive,WITHOUT_CLASSIFICATION,//  has nothing to be cached 
Hive,WITHOUT_CLASSIFICATION,//  Implementation of AbstractRowContainer and assorted methods 
Hive,WITHOUT_CLASSIFICATION,//  check if left is valid 
Hive,WITHOUT_CLASSIFICATION,//  stateful implies non-deterministic regardless of whatever   the deterministic annotation declares 
Hive,WITHOUT_CLASSIFICATION,//  Convert the elements 
Hive,WITHOUT_CLASSIFICATION,//  delete db and all tables in it 
Hive,WITHOUT_CLASSIFICATION,//  Thread cancelling the query 
Hive,WITHOUT_CLASSIFICATION,//  beginning with distcp.options. should be honoured 
Hive,WITHOUT_CLASSIFICATION,//  Create the object inspector for the input columns and initialize the 
Hive,WITHOUT_CLASSIFICATION,//  remember the JobConf cloned for each MapWork so we won't clone for it again 
Hive,WITHOUT_CLASSIFICATION,//  Values of accumulators can only be read on the SparkContext side. This field is used when   creating a snapshot to be sent to the RSC client. 
Hive,WITHOUT_CLASSIFICATION,//  Don't create context for the 0-s column. 
Hive,WITHOUT_CLASSIFICATION,//  table1 and view1 as second read entity 
Hive,WITHOUT_CLASSIFICATION,//  Serialize as time 0 
Hive,WITHOUT_CLASSIFICATION,//  Set on the server side.   @see org.apache.hive.service.cli.operation.SQLOperation#prepare 
Hive,WITHOUT_CLASSIFICATION,//  Initially zero. 
Hive,WITHOUT_CLASSIFICATION,//  For every field 
Hive,WITHOUT_CLASSIFICATION,//  For constructing HCatPartitions afresh as an argument to HCatClient.addPartitions(). 
Hive,WITHOUT_CLASSIFICATION,//  but whether the table itself is partitioned is not know. 
Hive,WITHOUT_CLASSIFICATION,//  try again with a null value 
Hive,WITHOUT_CLASSIFICATION,//  Implicit -- use batchIndex. 
Hive,WITHOUT_CLASSIFICATION,//  check partitioning column order and types 
Hive,WITHOUT_CLASSIFICATION,//  log exception but ignore inability to start 
Hive,WITHOUT_CLASSIFICATION,//  Requires schema change 
Hive,WITHOUT_CLASSIFICATION,/*      * Small table information.      */
Hive,WITHOUT_CLASSIFICATION,//  binary mode   For embedded mode the JDBC uri is of the form:   jdbc:hive2:///dbName;sess_var_list?hive_conf_list#hive_var_list   and does not contain host:port string.   As a result port is parsed to '-1' per the Java URI conventions 
Hive,WITHOUT_CLASSIFICATION,//  Carefully handle NULLs... 
Hive,WITHOUT_CLASSIFICATION,//  Not null constraint should reference a single column 
Hive,WITHOUT_CLASSIFICATION,//  we're dealing with an array of arrays of strings 
Hive,WITHOUT_CLASSIFICATION,/*  check the forward and backward compatibility  */
Hive,WITHOUT_CLASSIFICATION,//  op is not a DemuxOperator so it should have   a single child. 
Hive,WITHOUT_CLASSIFICATION,//  0 is function name 
Hive,WITHOUT_CLASSIFICATION,//  Irrelevant. See comment above.  Irrelevant. See comment above. 
Hive,WITHOUT_CLASSIFICATION,//  For primitive type add directly. 
Hive,WITHOUT_CLASSIFICATION,//  create new mapping 
Hive,WITHOUT_CLASSIFICATION,//  Try to make something reasonable to pass up to the base class 
Hive,WITHOUT_CLASSIFICATION,//  Prepare updated partition columns for small table(s).   Get the positions of bucketed columns 
Hive,WITHOUT_CLASSIFICATION,//       LOG.info("Returning final parent : "+ptnRootLocation); 
Hive,WITHOUT_CLASSIFICATION,/*                * Single-Column String specific save key.                */
Hive,WITHOUT_CLASSIFICATION,//  Test dryrun of schema initialization 
Hive,WITHOUT_CLASSIFICATION,//  Set them back 
Hive,WITHOUT_CLASSIFICATION,//  don't save maxwidth: it is automatically set based on   the terminal configuration 
Hive,WITHOUT_CLASSIFICATION,//  will not be deleted. The user will run ARCHIVE again to clear this up 
Hive,WITHOUT_CLASSIFICATION,//  Find out the segment with latest version and maximum partition number 
Hive,WITHOUT_CLASSIFICATION,//  set num of threads to 0 so that single-threaded checkMetastore is called 
Hive,WITHOUT_CLASSIFICATION,//  bucket 0   bucket 1   bucket 2 
Hive,WITHOUT_CLASSIFICATION,//  We always call init because the hook name in the configuration could   have changed. 
Hive,WITHOUT_CLASSIFICATION,//  TRUNCATE_TABLE EVENT on unpartitioned table 
Hive,WITHOUT_CLASSIFICATION,//  For the filtered out rows that didn't (logically) get looked up in the hash table   we need to generate no match results for those too... 
Hive,WITHOUT_CLASSIFICATION,//  If we have not added to this column desc before we bail out 
Hive,WITHOUT_CLASSIFICATION,//  HIVE_SUPPORT_SPECICAL_CHARACTERS_IN_TABLE_NAMES in HiveConf as well. 
Hive,WITHOUT_CLASSIFICATION,//  the "work" needs to know about the dummy operators. They have to be separately initialized 
Hive,WITHOUT_CLASSIFICATION,//  find all aggregate calls without distinct 
Hive,WITHOUT_CLASSIFICATION,/*    * this is not a real bloom filter but is a cheap version of the 1-memory   * access bloom filters   *   * In several cases we'll have map-join spills because the value columns are   * a few hundred columns of Text each while there are very few keys in total   * (a few thousand).   *   * This is a cheap exit option to prevent spilling the big-table in such a   * scenario.    */
Hive,WITHOUT_CLASSIFICATION,//  We need to add select since order by schema may have more columns than result schema. 
Hive,WITHOUT_CLASSIFICATION,//  getName 
Hive,WITHOUT_CLASSIFICATION,//  TODO: Remove in Hive 0.16. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure this isn't one of the partitioning columns that's not supported. 
Hive,WITHOUT_CLASSIFICATION,//  Output: get the evaluate method 
Hive,WITHOUT_CLASSIFICATION,//  A second connection should not be able to see the table 
Hive,WITHOUT_CLASSIFICATION,//  result 
Hive,WITHOUT_CLASSIFICATION,/*  Get all locks for a particular object  */
Hive,WITHOUT_CLASSIFICATION,//  no cleanup thread 
Hive,WITHOUT_CLASSIFICATION,//  The client has to wait and retry. 
Hive,WITHOUT_CLASSIFICATION,//  shared to all session functions 
Hive,WITHOUT_CLASSIFICATION,//  after each test 
Hive,WITHOUT_CLASSIFICATION,//  Accurate long value cannot be obtained. 
Hive,WITHOUT_CLASSIFICATION,//  If this is in acid format always read it recursively regardless of what the jobconf says. 
Hive,WITHOUT_CLASSIFICATION,// table is empty so can only lock the table 
Hive,WITHOUT_CLASSIFICATION,//  This basically means stop has been called. 
Hive,WITHOUT_CLASSIFICATION,// string comparisons 
Hive,WITHOUT_CLASSIFICATION,//  1.2 Recurse over all the source tables 
Hive,WITHOUT_CLASSIFICATION,//  read just the first column 
Hive,WITHOUT_CLASSIFICATION,//  first row - the process should only be started if necessary as it may   conflict with some 
Hive,WITHOUT_CLASSIFICATION,/*  Convert a long to a string. The string is output into the argument   * byte array beginning at character 0. The length is returned.    */
Hive,WITHOUT_CLASSIFICATION,//  Execute another query 
Hive,WITHOUT_CLASSIFICATION,//  Check the output of FixAcidKeyIndex - it should indicate nothing required fixing. 
Hive,WITHOUT_CLASSIFICATION,//  The output of a partial aggregation is a struct containing   a long count two double averages and a double covariance. 
Hive,WITHOUT_CLASSIFICATION,//  operator stack. The dispatcher generates the plan from the operator tree 
Hive,WITHOUT_CLASSIFICATION,//  Replace default keystore with keystore for www.example.com 
Hive,WITHOUT_CLASSIFICATION,//  Get the abortedWriteIds which are already sorted in ascending order. 
Hive,WITHOUT_CLASSIFICATION,// -----------------------------------------------------------------------------------------------   Validation methods.  ----------------------------------------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  If we do not need this format of accessor using ObjectNode this is a candidate for removal as well 
Hive,WITHOUT_CLASSIFICATION,// set auth privileges 
Hive,WITHOUT_CLASSIFICATION,// Update partition schema to have 3 fields 
Hive,WITHOUT_CLASSIFICATION,//  The varchar type info need to be set prior to initialization   and must be preserved when the plan serialized to other processes. 
Hive,WITHOUT_CLASSIFICATION,//  hive vars 
Hive,WITHOUT_CLASSIFICATION,//  Since we're reusing the compiled plan we need to update its start time for current run 
Hive,WITHOUT_CLASSIFICATION,//  IMetaStoreClient is needed to access token store if DBTokenStore is to be used. It   will be got via Hive.get(conf).getMSC in a thread where the DelegationTokenStore   is called. To avoid the cyclic reference we pass the Hive class to DBTokenStore where   it is used to get a threadLocal Hive object with a synchronized MetaStoreClient using   Java reflection.   Note: there will be two HS2 life-long opened MSCs one is stored in HS2 thread local   Hive object the other is in a daemon thread spawned in DelegationTokenSecretManager   to remove expired tokens. 
Hive,WITHOUT_CLASSIFICATION,// create a some of delta directories 
Hive,WITHOUT_CLASSIFICATION,/* the implementation of HCatFieldSchema is a bit messy since with the addition of parametrized types (e.g. char(7)) we need to represent something richer than an enum but for backwards compatibility (and effort required to do full refactoring) this class has both 'type' and 'typeInfo';similarly for mapKeyType/mapKeyTypeInfo  */
Hive,WITHOUT_CLASSIFICATION,//  On success but with nothing to return we can return an empty list. 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:SignableVertexSpec) 
Hive,WITHOUT_CLASSIFICATION,//  Remove RS and SEL introduced by enforce bucketing/sorting config 
Hive,WITHOUT_CLASSIFICATION,//  ADD_CONSTRAINT EVENT 
Hive,WITHOUT_CLASSIFICATION,//     our preliminary mapping won't work out. We'll handle that below. 
Hive,WITHOUT_CLASSIFICATION,//  We assume that if put/lock throws in the middle it's ok to treat buffers as not being   locked and to blindly deallocate them since they are not going to be used. Therefore   we don't remove them from the cleanup list - we will do it after sending to consumer.   This relies on sequence of calls to cacheFileData and sendEcb.. 
Hive,WITHOUT_CLASSIFICATION,//  No capacity left on node1. The next task should be allocated to node2 after it times out. 
Hive,WITHOUT_CLASSIFICATION,//  guava stores the hashcodes in little endian order 
Hive,WITHOUT_CLASSIFICATION,//  Resolve column expression to input expression by using expression mapping in current operator 
Hive,WITHOUT_CLASSIFICATION,//  Optimization copied from BigDecimal. 
Hive,WITHOUT_CLASSIFICATION,//  root operator is union (can happen in reducers) 
Hive,WITHOUT_CLASSIFICATION,// UDFYear 
Hive,WITHOUT_CLASSIFICATION,//  remove trailing empty split(s) 
Hive,WITHOUT_CLASSIFICATION,/*    * Right trim and truncate a slice of a byte array to a maximum number of characters and   * return the new byte length.    */
Hive,WITHOUT_CLASSIFICATION,//  create a partitioned table 
Hive,WITHOUT_CLASSIFICATION,//  4. We build the new predicate and return it 
Hive,WITHOUT_CLASSIFICATION,//  the dummy option should not have made it either - only options 
Hive,WITHOUT_CLASSIFICATION,//  1. We try to transform possible candidates 
Hive,WITHOUT_CLASSIFICATION,//  75% for 4 executors 
Hive,WITHOUT_CLASSIFICATION,// if the error message is changed for REPL_EVENTS_MISSING_IN_METASTORE then need modification in getNextNotification 
Hive,WITHOUT_CLASSIFICATION,// ************************************************************************************************   Decimal to Non-Integer conversion. 
Hive,WITHOUT_CLASSIFICATION,//  3. Query Hints 
Hive,WITHOUT_CLASSIFICATION,//  Populating the Empty string bytes. Putting it as static since it should be immutable and can   be shared. 
Hive,WITHOUT_CLASSIFICATION,//  next file in the path 
Hive,WITHOUT_CLASSIFICATION,/*  Byte bit patterns of the form 10xxxxxx are continuation       * bytes. All other bit patterns are the first byte of       * a character.        */
Hive,WITHOUT_CLASSIFICATION,//  Unique rows 
Hive,WITHOUT_CLASSIFICATION,//  Instantiate Driver to compile the query passed in.   This UDF is running as part of an existing query which may already be using the   SessionState TxnManager. If this new Driver also tries to use the same TxnManager   then this may mess up the existing state of the TxnManager.   So initialize the new Driver with a new TxnManager so that it does not use the 
Hive,WITHOUT_CLASSIFICATION,//  shared plan utils for tez 
Hive,WITHOUT_CLASSIFICATION,//  sometimes RowSchema is empty so fetch stats of columns in exprMap 
Hive,WITHOUT_CLASSIFICATION,/*  batchIndex  */
Hive,WITHOUT_CLASSIFICATION,//  The writeHWM = min(NEXT_WRITE_ID.nwi_next-1 max(TXN_TO_WRITE_ID.t2w_writeid under txnHwm)) 
Hive,WITHOUT_CLASSIFICATION,//  I think this is wrong the alter table statement should come on the table topic not the 
Hive,WITHOUT_CLASSIFICATION,//  write partitionInfo into output 
Hive,WITHOUT_CLASSIFICATION,//  Return the MockInstance's Connector 
Hive,WITHOUT_CLASSIFICATION,// make sure it works with nothing to expire 
Hive,WITHOUT_CLASSIFICATION,//  If we reach here we succeed. 
Hive,WITHOUT_CLASSIFICATION,//  this tests the case where older data has an ambiguous structure but the   correct interpretation can be determined from the repeated name 
Hive,WITHOUT_CLASSIFICATION,//  for current query. 
Hive,WITHOUT_CLASSIFICATION,//  the RHS table columns should be not be output from the join 
Hive,WITHOUT_CLASSIFICATION,// copy if across file system or encryption zones. 
Hive,WITHOUT_CLASSIFICATION,/*  We write many records because sometimes the RecordWriter for the format to test     * behaves different with one record than a bunch of records  */
Hive,WITHOUT_CLASSIFICATION,//  GroupBy query 
Hive,WITHOUT_CLASSIFICATION,//  add log links and other diagnostics from YARN Service 
Hive,WITHOUT_CLASSIFICATION,//  the following two are used for join processing 
Hive,WITHOUT_CLASSIFICATION,//  Also reading beyond our byte range produces NULL. 
Hive,WITHOUT_CLASSIFICATION,//  For ACID non-bucketed case the filenames have to be in the format consistent with INSERT/UPDATE/DELETE Ops   i.e like 000000_0 000001_0_copy_1 000002_0.gz etc.   The extension is only maintained for files which are compressed. 
Hive,WITHOUT_CLASSIFICATION,//  if this is a nested sql script then flatten it 
Hive,WITHOUT_CLASSIFICATION,//  ////// Generate GroupbyOperator3 
Hive,WITHOUT_CLASSIFICATION,/*  Indicates a request has completed on a node  */
Hive,WITHOUT_CLASSIFICATION,//  With local spark context all user sessions share the same spark context. 
Hive,WITHOUT_CLASSIFICATION,//  TimestampColumnArithmeticTimestampColumn.txt   TimestampScalarArithmeticTimestampColumn.txt   TimestampColumnArithmeticTimestampScalar.txt 
Hive,WITHOUT_CLASSIFICATION,//  Create a clone of the operator 
Hive,WITHOUT_CLASSIFICATION,//  No input data 
Hive,WITHOUT_CLASSIFICATION,//  copy the src to the destination and create local resource. 
Hive,WITHOUT_CLASSIFICATION,//  the jobtracker setting to its initial value 
Hive,WITHOUT_CLASSIFICATION,//  getRows will call estimateRowCount 
Hive,WITHOUT_CLASSIFICATION,//  List of configurations. Currently the list consists of hadoop version and execution mode only 
Hive,WITHOUT_CLASSIFICATION,//  If the properties does not define any transactional properties we return a default type. 
Hive,WITHOUT_CLASSIFICATION,//  We'll wait for 120s for node creation 
Hive,WITHOUT_CLASSIFICATION,//  At least a single item in project is required. 
Hive,WITHOUT_CLASSIFICATION,//  Get number of partitions by doing count on PART_ID. 
Hive,WITHOUT_CLASSIFICATION,//  Test that existing exclusive table with new shared_read coalesces to 
Hive,WITHOUT_CLASSIFICATION,//  we need to replace the dummy operators in the work with the cloned ones. 
Hive,WITHOUT_CLASSIFICATION,//  Assumes the reader count has been incremented automatically by the results cache by either   lookup or creating the cache entry. 
Hive,WITHOUT_CLASSIFICATION,//  assumes un partitioned table 
Hive,WITHOUT_CLASSIFICATION,//  just set a really small lower bound 
Hive,WITHOUT_CLASSIFICATION,//  admin check 
Hive,WITHOUT_CLASSIFICATION,//  Done grouping partitions within table-dir. 
Hive,WITHOUT_CLASSIFICATION,//  initialize the merge operators first. 
Hive,WITHOUT_CLASSIFICATION,//  This session is bad so don't allow reuse; just convert it to normal get. 
Hive,WITHOUT_CLASSIFICATION,//  no nulls is repeating 
Hive,WITHOUT_CLASSIFICATION,//  Special handling for Druid rules here as otherwise   planner will add Druid rules with logical builder 
Hive,WITHOUT_CLASSIFICATION,//  some of the partitions miss stats. 
Hive,WITHOUT_CLASSIFICATION,//  we know rowSet has only one element 
Hive,WITHOUT_CLASSIFICATION,//  Note: there are so many different onSuccess/onFailure callbacks floating around that         this will probably be called twice for the done state. This is ok given the sync. 
Hive,WITHOUT_CLASSIFICATION,// import static org.apache.hadoop.hive.serde2.avro.AvroSerdeUtils.AVRO_SERDE_SCHEMA;  import static org.apache.hadoop.hive.serde2.avro.AvroSerdeUtils.SCHEMA_LITERAL; 
Hive,WITHOUT_CLASSIFICATION,//  2019-01-02 00:00:00 GMT is 2019-01-01 19:00:00 GMT-0500 (America/New_York / EST) 
Hive,WITHOUT_CLASSIFICATION,//  A symlink file contains first file from first dir and second file from   second dir. 
Hive,WITHOUT_CLASSIFICATION,//  TBL_NAME 
Hive,WITHOUT_CLASSIFICATION,//  Decrement only if an element was removed. 
Hive,WITHOUT_CLASSIFICATION,//  no child map join 
Hive,WITHOUT_CLASSIFICATION,//  This many bytes are necessary to store the reversed nanoseconds. 
Hive,WITHOUT_CLASSIFICATION,//  Not order preserving 
Hive,WITHOUT_CLASSIFICATION,//  2. Gen OP Tree from resolved Parse Tree 
Hive,WITHOUT_CLASSIFICATION,//  pattern 
Hive,WITHOUT_CLASSIFICATION,//  for auto reduce parallelism - max reducers requested 
Hive,WITHOUT_CLASSIFICATION,//  Get locations again and make sure they're the same. 
Hive,WITHOUT_CLASSIFICATION,//  statistics stored in metastore 
Hive,WITHOUT_CLASSIFICATION,//  optional .SourceStateProto state = 3; 
Hive,WITHOUT_CLASSIFICATION,//  We can invalidate the entry now but calling removeEntry() requires a write lock   and we may already have read lock taken now. Add to entriesToRemove to delete later. 
Hive,WITHOUT_CLASSIFICATION,//  limit factor is too big 
Hive,WITHOUT_CLASSIFICATION,/*  useExactBytes  */
Hive,WITHOUT_CLASSIFICATION,//  This is going to be slow... hold on. 
Hive,WITHOUT_CLASSIFICATION,//  optional int32 vertex_parallelism = 13; 
Hive,WITHOUT_CLASSIFICATION,//  column name is the second group from current match 
Hive,WITHOUT_CLASSIFICATION,/*      * Return how the list of columns passed in match.     * Return NO_MATCH if either of the list is empty or null or if there is a mismatch.     * For eg: ([] []) ([] ["a"]) (["a"]["b"]) and (["a" "b"] ["a""c"]) return NO_MATCH     *     * Return COMPLETE_MATCH if both the lists are non-empty and are same     * Return PREFIX_COL1_MATCH if list1 is a strict subset of list2 and     * return PREFIX_COL2_MATCH if list2 is a strict subset of list1     *     * For eg: (["a"] ["a"]) (["a"] ["a" "b"]) and (["a" "b"] ["a"]) return     * COMPLETE_MATCH PREFIX_COL1_MATCH and PREFIX_COL2_MATCH respectively.      */
Hive,WITHOUT_CLASSIFICATION,//  there could be some spilled partitions which needs to be cleaned up 
Hive,WITHOUT_CLASSIFICATION,//  require delete privilege if this is an insert-overwrite 
Hive,WITHOUT_CLASSIFICATION,// test_param_2 = "75" 
Hive,WITHOUT_CLASSIFICATION,//  12.1. Merge join into multijoin operators (if possible) 
Hive,WITHOUT_CLASSIFICATION,//  create a walker which walks the tree in a DFS manner while maintaining   the operator stack. The dispatcher   generates the plan from the operator tree 
Hive,WITHOUT_CLASSIFICATION,// if the partition does not have partition level privilege go to table level. 
Hive,WITHOUT_CLASSIFICATION,//  copy all the properties 
Hive,WITHOUT_CLASSIFICATION,//  The cache entry has just been invalidated no need for the scheduled invalidation. 
Hive,WITHOUT_CLASSIFICATION,//  Also set this to the Thread ContextClassLoader so new threads will   inherit   this class loader and propagate into newly created Configurations by   those 
Hive,WITHOUT_CLASSIFICATION,//  Read configuration for the target path first from jobconf then from table properties 
Hive,WITHOUT_CLASSIFICATION,// empty list non partitioned 
Hive,WITHOUT_CLASSIFICATION,//  mark the MapredWork and FileSinkOperator for gathering stats 
Hive,WITHOUT_CLASSIFICATION,//  Allow numeric to string 
Hive,WITHOUT_CLASSIFICATION,//  valiade 
Hive,WITHOUT_CLASSIFICATION,//  bother about generating a schema only if a schema retriever class wasn't provided 
Hive,WITHOUT_CLASSIFICATION,//  Quarter granularity 
Hive,WITHOUT_CLASSIFICATION,// Read should get 10 rows if immutable 30 if mutable 
Hive,WITHOUT_CLASSIFICATION,//  Prepare the bloom filter 
Hive,WITHOUT_CLASSIFICATION,//  all rows qualify 
Hive,WITHOUT_CLASSIFICATION,/*    * The = sign in the string for TOKEN_FILE_ARG_PLACEHOLDER is required because   * org.apache.hadoop.util.GenericOptionsParser.preProcessForWindows() prepares   * arguments expecting an = sign. It will fail to prepare the arguments correctly   * without the = sign present.    */
Hive,WITHOUT_CLASSIFICATION,//  Now let's load this file into a new Hive table. 
Hive,WITHOUT_CLASSIFICATION,//  end ReadOnlySubList 
Hive,WITHOUT_CLASSIFICATION,//  Initialize UDF which will output the return type for the UDF. 
Hive,WITHOUT_CLASSIFICATION,//  since this is special cased when it is rewritten in SubqueryRemoveRule 
Hive,WITHOUT_CLASSIFICATION,//  Query is the hive query string i.e. "SELECT * FROM src;" associated with   this set of tasks logs 
Hive,WITHOUT_CLASSIFICATION,//  Ignore non-directory files 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.CLIServiceClient#getSchemas(org.apache.hive.service.cli.SessionHandle java.lang.String java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  FK_NAME 
Hive,WITHOUT_CLASSIFICATION,//  Populating the Empty string bytes. Putting it as static since it should be immutable and can be   shared 
Hive,WITHOUT_CLASSIFICATION,/*      * This member has information for data type conversion.     * Not defined if there is no conversion.      */
Hive,WITHOUT_CLASSIFICATION,//  if the destination file exists for some reason delete it 
Hive,WITHOUT_CLASSIFICATION,//  For the file size check. 
Hive,WITHOUT_CLASSIFICATION,//  The reducer contains a groupby which needs to be restored. 
Hive,WITHOUT_CLASSIFICATION,//  Replace pRS with cRS and remove operator sequence from pRS to cRS 
Hive,WITHOUT_CLASSIFICATION,//  Set up periodic progress reporting in case the UDTF doesn't output rows 
Hive,WITHOUT_CLASSIFICATION,//  swap the fields with the passed in orcStruct 
Hive,WITHOUT_CLASSIFICATION,//  No-op for session killed by WM. 
Hive,WITHOUT_CLASSIFICATION,//  First infer the type of object 
Hive,WITHOUT_CLASSIFICATION,//  non-constant or non-primitive constants 
Hive,WITHOUT_CLASSIFICATION,// don't want set autocommit true|false to get mixed with set hive.foo.bar... 
Hive,WITHOUT_CLASSIFICATION,//  Add jar to current thread class loader dynamically and add jar paths to JobConf as Spark   may need to load classes from this jar in other threads. 
Hive,WITHOUT_CLASSIFICATION,//  A pound # statement (IF/ELSE/ENDIF). 
Hive,WITHOUT_CLASSIFICATION,/*  construct one location map if not exists.  */
Hive,WITHOUT_CLASSIFICATION,//  LOG.debug("VectorMapJoinFastBytesHashMap findWriteSlot slot " + slot + " tripleIndex " + tripleIndex + " empty"); 
Hive,WITHOUT_CLASSIFICATION,//  Some other operation in progress using the same lock.   A subsequent fragmentComplete is expected to come in. 
Hive,WITHOUT_CLASSIFICATION,//  But this is tricky to implement and we'll leave it as a future work for now. 
Hive,WITHOUT_CLASSIFICATION,//  key = (key << 15) - key - 1; 
Hive,WITHOUT_CLASSIFICATION,//  A slow way to get the number of decimal digits. 
Hive,WITHOUT_CLASSIFICATION,//  Is an EXTERNAL table 
Hive,WITHOUT_CLASSIFICATION,//  Nothing to do - e.g. two messages have canceled each other before we could react. 
Hive,WITHOUT_CLASSIFICATION,//  Previous row was for a large bytes value ( > MAX_SIZE_FOR_SMALL_BUFFER).   Use smallBuffer if possible. 
Hive,WITHOUT_CLASSIFICATION,//  For use by VectorKeySeriesMulti so that the minimum equal key can be advanced. 
Hive,WITHOUT_CLASSIFICATION,//  Had the put succeeded for our new buffer it would have refcount of 2 - 1 from put   and 1 from notifyReused call above. "Old" buffer now has the 1 from put; new buffer   is not in cache. releaseBuffer will decref the buffer and also deallocate. 
Hive,WITHOUT_CLASSIFICATION,//  Form key object array 
Hive,WITHOUT_CLASSIFICATION,//  Execute the UDF 
Hive,WITHOUT_CLASSIFICATION,//  after column is not null but we did not find it. 
Hive,WITHOUT_CLASSIFICATION,//  Assumes the lists are sorted. 
Hive,WITHOUT_CLASSIFICATION,/*         * Change the current thread name to include parent thread Id if it is executed        * in thread pool. Useful to extract logs specific to a job request and helpful        * to debug job issues.         */
Hive,WITHOUT_CLASSIFICATION,// subject to list of 'exceptions' in 'writeIdList' (not show in above example). 
Hive,WITHOUT_CLASSIFICATION,//  We don't bail on failure - try in detail below. 
Hive,WITHOUT_CLASSIFICATION,//  tez needs its own scratch dir (per session)   TODO: De-link from SessionState. A TezSession can be linked to different Hive Sessions via the pool. 
Hive,WITHOUT_CLASSIFICATION,//  Common name constants for event messages 
Hive,WITHOUT_CLASSIFICATION,//  Used by hash-based GroupBy: Mode = HASH PARTIALS 
Hive,WITHOUT_CLASSIFICATION,//  Even if the cleanup throws some exception it will continue. 
Hive,WITHOUT_CLASSIFICATION,//  The sql should be completed now. 
Hive,WITHOUT_CLASSIFICATION,//  those top layer ReduceSinkOperators. 
Hive,WITHOUT_CLASSIFICATION,//  curr value becomes old and vice-versa 
Hive,WITHOUT_CLASSIFICATION,//  test repeating on left 
Hive,WITHOUT_CLASSIFICATION,//  None of the partitions will be dumped as the partitions list was empty 
Hive,WITHOUT_CLASSIFICATION,//  Does vectorization use stripped char values? 
Hive,WITHOUT_CLASSIFICATION,//  this messageType only has one optional field whose name is mapCol original Type is MAP 
Hive,WITHOUT_CLASSIFICATION,//  Create enough elementConverters   NOTE: we have to have a separate elementConverter for each element   because the elementConverters can reuse the internal object.   So it's not safe to use the same elementConverter to convert multiple   elements. 
Hive,WITHOUT_CLASSIFICATION,//  RemoteException with AlreadyBeingCreatedException will be thrown   if the file is currently held by a writer 
Hive,WITHOUT_CLASSIFICATION,// set new db and verify get 
Hive,WITHOUT_CLASSIFICATION,//  2.1 Convert AST Expr to ExprNode 
Hive,WITHOUT_CLASSIFICATION,//  any name it does not matter. 
Hive,WITHOUT_CLASSIFICATION,// reduce-side join use MR-style shuffle 
Hive,WITHOUT_CLASSIFICATION,//  Do insert overwrite to create some invalid deltas and import into a non-MM table. 
Hive,WITHOUT_CLASSIFICATION,//  Check if we can process it or not by the index of distinct 
Hive,WITHOUT_CLASSIFICATION,//  Preserve partitioning and ordering 
Hive,WITHOUT_CLASSIFICATION,//  row group position within stripe 
Hive,WITHOUT_CLASSIFICATION,//  do nothing. 
Hive,WITHOUT_CLASSIFICATION,//  Read state. 
Hive,WITHOUT_CLASSIFICATION,//  Sort the list as requested 
Hive,WITHOUT_CLASSIFICATION,//  { 100_000_000 } { 1_000_000_000 } 1B passed but is super slow 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   required 
Hive,WITHOUT_CLASSIFICATION,//  Clear gWorkMap 
Hive,WITHOUT_CLASSIFICATION,// convert the table to Acid 
Hive,WITHOUT_CLASSIFICATION,//  Most of the method got skipped but we still need to handle the duck. 
Hive,WITHOUT_CLASSIFICATION,//  Setup serDe. 
Hive,WITHOUT_CLASSIFICATION,//  type is MAJOR since there's no base yet 
Hive,WITHOUT_CLASSIFICATION,//  3. Populate other data structures 
Hive,WITHOUT_CLASSIFICATION,//  A call to increaseBufferSpace() or ensureValPreallocated() will ensure that buffer[] points to   a byte[] with sufficient space for the specified size. 
Hive,WITHOUT_CLASSIFICATION,//  Create the dummy aggregation. 
Hive,WITHOUT_CLASSIFICATION,/*    * used to give a unique name to each SubQuery QB Currently there can be at   * most 2 SubQueries in a Query: 1 in the Where clause and 1 in the Having   * clause.    */
Hive,WITHOUT_CLASSIFICATION,//  Load a BytesColumnVector by copying in large data enough to force   the buffer to expand. 
Hive,WITHOUT_CLASSIFICATION,//  These are suffixes attached to intermediate directory names used in the 
Hive,WITHOUT_CLASSIFICATION,//  configureTableJobProperties shouldn't be getting called by Hive but if it somehow does   we should just set all of the configurations for input and output. 
Hive,WITHOUT_CLASSIFICATION,//  1. Add GB Keys to reduce keys 
Hive,WITHOUT_CLASSIFICATION,// checkTGT calls ugi.relogin only after checking if it is close to tgt expiry  hadoop relogin is actually done only every x minutes (x=10 in hadoop 1.x) 
Hive,WITHOUT_CLASSIFICATION,//  Caches disabled nodes for quicker lookups and ensures a request on a node which was skipped   does not go out of order. 
Hive,WITHOUT_CLASSIFICATION,// rowIdOffset could be 0 if all files before current one are empty 
Hive,WITHOUT_CLASSIFICATION,//  Since enforcing precision and scale can cause a HiveDecimal to become NULL   we must read it enforce it here and either return NULL or buffer the result. 
Hive,WITHOUT_CLASSIFICATION,//  Send only if the state has changed. 
Hive,WITHOUT_CLASSIFICATION,//  Perf times 
Hive,WITHOUT_CLASSIFICATION,//  MSerdeInfo *& SerdeInfo should be same as well 
Hive,WITHOUT_CLASSIFICATION,//  now positions contains all the distinct positions i.e. $5 $4 $6   we need to first sort them as group by set   and then get their position later i.e. $4->1 $5->2 $6->3 
Hive,WITHOUT_CLASSIFICATION,//  The operator tree till the sink operator has already been processed while   fetching the next row to fetch from the priority queue (possibly containing   multiple files in the small table given a file in the big table). Now process   the remaining tree. Look at comments in DummyStoreOperator for additional   explanation. 
Hive,WITHOUT_CLASSIFICATION,//  the event will not be sent to ATS if there are too many outstanding work submissions. 
Hive,WITHOUT_CLASSIFICATION,//  RENEWER_KERBEROS_PRINCIPAL_NAME 
Hive,WITHOUT_CLASSIFICATION,//  The Avro deserializer would deserialize our object and return back a list of object that   hive can operate on. Here we should be getting the same object back. 
Hive,WITHOUT_CLASSIFICATION,//  a susbset of files for the partition are sufficient for the optimization 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: It is critical to do this here so that log4j is reinitialized   before any of the other core hive classes are loaded 
Hive,WITHOUT_CLASSIFICATION,//  nodeMap registration. 
Hive,WITHOUT_CLASSIFICATION,//  Create all the files - this is required because empty files need to be created for   empty buckets   createBucketFiles(fsp); 
Hive,WITHOUT_CLASSIFICATION,//  End HiveRelMdCost.java 
Hive,WITHOUT_CLASSIFICATION,//  if the only difference is numeric types pick the method   with the smallest overall numeric type. 
Hive,WITHOUT_CLASSIFICATION,// An empty batch will appear at the end of the stream 
Hive,WITHOUT_CLASSIFICATION,//  If this is true then there is no data in the batch -- we have hit the end of input. 
Hive,WITHOUT_CLASSIFICATION,//  Now we could get previous and next day figure our how many hours were inserted or removed   and from which of the days etc. But at this point our gun is pointing straight at our foot 
Hive,WITHOUT_CLASSIFICATION,//  Valid range is "range/rows between 10 preceding and 2 preceding" for preceding case 
Hive,WITHOUT_CLASSIFICATION,//  add empty line 
Hive,WITHOUT_CLASSIFICATION,//  all good 
Hive,WITHOUT_CLASSIFICATION,//  Binary 
Hive,WITHOUT_CLASSIFICATION,//  interestingly decimal(2) means decimal(20) 
Hive,WITHOUT_CLASSIFICATION,//  Look for databases without pattern 
Hive,WITHOUT_CLASSIFICATION,//  The sortMerger is a heap data structure that stores a pair of   (deleteRecordKey deleteReaderValue) at each node and is ordered by deleteRecordKey.   The deleteReaderValue is the actual wrapper class that has the reference to the   underlying delta file that is being read and its corresponding deleteRecordKey   is the smallest record id for that file. In each iteration of this loop we extract(poll)   the minimum deleteRecordKey pair. Once we have processed that deleteRecordKey we   advance the pointer for the corresponding deleteReaderValue. If the underlying file   itself has no more records then we remove that pair from the heap or else we   add the updated pair back to the heap. 
Hive,WITHOUT_CLASSIFICATION,//  Multi-Key specific imports. 
Hive,WITHOUT_CLASSIFICATION,//  strictly not required just for consistency 
Hive,WITHOUT_CLASSIFICATION,//  NEW TAI LUE LETTER LOW KVA U+19A8 (3 bytes) 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getObject(int java.util.Map)    */
Hive,WITHOUT_CLASSIFICATION,//  during the tests we run with 100K prealloc in the logs.   on windows systems prealloc of 64M was seen to take ~15seconds   resulting in test failure (client timeout on first session).   set env and directly in order to handle static init/gc issues 
Hive,WITHOUT_CLASSIFICATION,/*  partialCount  */
Hive,WITHOUT_CLASSIFICATION,//  Make a decimal batch with three columns including two for inputs and one for the result. 
Hive,WITHOUT_CLASSIFICATION,//  at this point we've found the fork in the op pipeline that has the pruning as a child plan. 
Hive,WITHOUT_CLASSIFICATION,//  Create the default properties object 
Hive,WITHOUT_CLASSIFICATION,//  Can't be set in constructor due to circular dependency. 
Hive,WITHOUT_CLASSIFICATION,//  Get the distribute by aliases - these are aliased to the entries in   the   select list 
Hive,WITHOUT_CLASSIFICATION,//  process location one-by-one 
Hive,WITHOUT_CLASSIFICATION,//  The planner seems to pull this one out. 
Hive,WITHOUT_CLASSIFICATION,//  Simple pattern: D H:M:S.nnnnnnnnn 
Hive,WITHOUT_CLASSIFICATION,//  signature and generate field expressions for those 
Hive,WITHOUT_CLASSIFICATION,//  Skip if the transaction under evaluation is already committed. 
Hive,WITHOUT_CLASSIFICATION,//  copy loginTimeout from driver manager. Thrift timeout needs to be in millis 
Hive,WITHOUT_CLASSIFICATION,//  all evaluation should be processed here for valid aliasFilterTags     for MapJoin filter tag is pre-calculated in MapredLocalTask and stored with value. 
Hive,WITHOUT_CLASSIFICATION,//  The arg is self. 
Hive,WITHOUT_CLASSIFICATION,//  both sides. 
Hive,WITHOUT_CLASSIFICATION,//  Parse validReaderWriteIdList from creation metadata 
Hive,WITHOUT_CLASSIFICATION,// normal insert 
Hive,WITHOUT_CLASSIFICATION,//  Since a key expression can be a calculation and the key will go into a scratch column   we need the mapping and type information. 
Hive,WITHOUT_CLASSIFICATION,//  we make sure that we do not change anything if there is anything   wrong. 
Hive,WITHOUT_CLASSIFICATION,//  Set the correct last repl id to return to the user 
Hive,WITHOUT_CLASSIFICATION,//  Expand and write result 
Hive,WITHOUT_CLASSIFICATION,//  Now insert the new buffer in its place and restore heap property. 
Hive,WITHOUT_CLASSIFICATION,//  in this case we have to scale up _BEFORE_ division. otherwise we   might lose precision. 
Hive,WITHOUT_CLASSIFICATION,//  Now try to reuse with no other sessions remaining. Should still work. 
Hive,WITHOUT_CLASSIFICATION,//  if verifySetup is set to true all the test setup we do will perform additional   verifications as well which is useful to verify that our setup occurred   correctly when developing and debugging tests. These verifications however   do not test any new functionality for replication and thus are not relevant   for testing replication itself. For steady state we want this to be false. 
Hive,WITHOUT_CLASSIFICATION,//  Test that we are cleaning aborted transactions with no components left in txn_components.   Put one aborted transaction with an entry in txn_components to make sure we don't   accidently clean it too. 
Hive,WITHOUT_CLASSIFICATION,//  copy entire string value 
Hive,WITHOUT_CLASSIFICATION,//  puts long in little endian order 
Hive,WITHOUT_CLASSIFICATION,//  This is the only public constructor of FileSplit 
Hive,WITHOUT_CLASSIFICATION,//  Save prev val of the key on threadLocal 
Hive,WITHOUT_CLASSIFICATION,//  Persist the column statistics object to the metastore   Note this function is shared for both table and partition column stats. 
Hive,WITHOUT_CLASSIFICATION,//  We create a new op if it is the first time we fire the rule 
Hive,WITHOUT_CLASSIFICATION,//  subsequent instances when it's taken off the queue. 
Hive,WITHOUT_CLASSIFICATION,//  First entry.   Count. 
Hive,WITHOUT_CLASSIFICATION,//  age >= '10' 
Hive,WITHOUT_CLASSIFICATION,//  the sorting property is not obeyed 
Hive,WITHOUT_CLASSIFICATION,//  If the code point exists in deletion set no need to emit out anything for this code point. 
Hive,WITHOUT_CLASSIFICATION,//  create tables verify query 
Hive,WITHOUT_CLASSIFICATION,//  Was able to execute something before the last blacklist. Reset the exponent. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getCharacterStream(int)    */
Hive,WITHOUT_CLASSIFICATION,//  Convert to date value (in days) 
Hive,WITHOUT_CLASSIFICATION,//  in hivemetastore-site.xml 
Hive,WITHOUT_CLASSIFICATION,//  Test that the whole things works when there's nothing in the queue.  This is just a   survival test. 
Hive,WITHOUT_CLASSIFICATION,//  No need to propagate to this to the responder 
Hive,WITHOUT_CLASSIFICATION,//  If there is a distinctFuncExp add all parameters to the reduceKeys. 
Hive,WITHOUT_CLASSIFICATION,//  Validate all integer type values are stored correctly 
Hive,WITHOUT_CLASSIFICATION,//  Output record readers 
Hive,WITHOUT_CLASSIFICATION,//  2. Regen OP plan from optimized AST 
Hive,WITHOUT_CLASSIFICATION,//  For each aggregation 
Hive,WITHOUT_CLASSIFICATION,//  Array full? 
Hive,WITHOUT_CLASSIFICATION,//  We have just removed the session from the same pool so don't check concurrency here. 
Hive,WITHOUT_CLASSIFICATION,//  Field node e.g. get a.myfield1 from a 
Hive,WITHOUT_CLASSIFICATION,// add new 'synthetic' columns for projections not provided by Select 
Hive,WITHOUT_CLASSIFICATION,//  Aggregate does not change input ordering so corVars will be 
Hive,WITHOUT_CLASSIFICATION,//  null 
Hive,WITHOUT_CLASSIFICATION,//  Restore broken links between operators and remove the branch from the original tree 
Hive,WITHOUT_CLASSIFICATION,//  compile internal will automatically reset the perf logger 
Hive,WITHOUT_CLASSIFICATION,//  Dump and load only second insert (2 records) 
Hive,WITHOUT_CLASSIFICATION,//  if here we may be checking a DB level lock against a Table level lock.  Alternatively   we could have used Intention locks (for example a request for S lock on table would   cause an IS lock DB that contains the table).  Similarly at partition level. 
Hive,WITHOUT_CLASSIFICATION,/*  id >= 10 and not (10 > id)  */
Hive,WITHOUT_CLASSIFICATION,//  TODO: Handle quoted tablenames 
Hive,WITHOUT_CLASSIFICATION,//  Zero and above numbers indicate a big table key is needed for   small table result "area". 
Hive,WITHOUT_CLASSIFICATION,// TODO 
Hive,WITHOUT_CLASSIFICATION,//  traversing origin find ExprNodeDesc in sources and replaces it with ExprNodeDesc   in targets having same index. 
Hive,WITHOUT_CLASSIFICATION,//  Equivalent aliases for the column 
Hive,WITHOUT_CLASSIFICATION,//  See if we can load all the delete events from all the delete deltas in memory... 
Hive,WITHOUT_CLASSIFICATION,//  from Key and Value TableDesc 
Hive,WITHOUT_CLASSIFICATION,/*      * FLOAT: Min and max.      */
Hive,WITHOUT_CLASSIFICATION,//  In case of cross join we disable hybrid grace hash join 
Hive,WITHOUT_CLASSIFICATION,//  ColumnStatisticsObj with info about its db table partition (if table is partitioned) 
Hive,WITHOUT_CLASSIFICATION,//  Write the terminating NULL byte 
Hive,WITHOUT_CLASSIFICATION,// 42X65/3000 means index doesn't exist 
Hive,WITHOUT_CLASSIFICATION,//  cast 
Hive,WITHOUT_CLASSIFICATION,//  VectorizedBatchUtil.debugDisplayOneRow(overflowBatch overflowBatch.size "generateHashMapResultMultiValue overflow"); 
Hive,WITHOUT_CLASSIFICATION,//  Extract the hex digits of num into value[] from right to left 
Hive,WITHOUT_CLASSIFICATION,/*     explicitly remove the setting of last.repl.id from the db object parameters as loadTask is going    to run multiple times and explicit logic is in place which prevents updates to tables when db level    last repl id is set and we create a AlterDatabaseTask at the end of processing a database.      */
Hive,WITHOUT_CLASSIFICATION,//  2. rewrite into query    TOK_QUERY       TOK_FROM          join       TOK_INSERT          TOK_DESTINATION             TOK_DIR                TOK_TMP_FILE          TOK_SELECT 
Hive,WITHOUT_CLASSIFICATION,//  3. We need to fix it we create the two replacement project 
Hive,WITHOUT_CLASSIFICATION,/*  all tests are identical to the other seek() tests  */
Hive,WITHOUT_CLASSIFICATION,//  batches will be sized 17 8 4 2 1 
Hive,WITHOUT_CLASSIFICATION,// Reuse the re-encoder  Evolved schema?  Create and store new encoder in the map for re-use 
Hive,WITHOUT_CLASSIFICATION,//  40 + 50 
Hive,WITHOUT_CLASSIFICATION,//  Try with chunked streams 
Hive,WITHOUT_CLASSIFICATION,//  keep it as-is 
Hive,WITHOUT_CLASSIFICATION,//  TODO: this boolean flag is set only by RS stats annotation at this point  clone.setRuntimeStats(runtimeStats); 
Hive,WITHOUT_CLASSIFICATION,//  table locks for this db. 
Hive,WITHOUT_CLASSIFICATION,//  The operators specified by depth and removed from the tree. 
Hive,WITHOUT_CLASSIFICATION,//  Key out of range for whole hash table. 
Hive,WITHOUT_CLASSIFICATION,//  is now different from HiveDecimal.precision() 
Hive,WITHOUT_CLASSIFICATION,//  We have to be mindful of order during filtering if we are not returning all partitions. 
Hive,WITHOUT_CLASSIFICATION,//  We add Hive function names   For functions that aren't infix operators we add an open 
Hive,WITHOUT_CLASSIFICATION,//  However these expressions should not be considered as valid expressions for separation. 
Hive,WITHOUT_CLASSIFICATION,// fall through to ACQUIRE 
Hive,WITHOUT_CLASSIFICATION,//  Always re-schedule the next callable - irrespective of task count   in case new tasks come in later. 
Hive,WITHOUT_CLASSIFICATION,//  Since user names need to be valid unix user names per IEEE Std 1003.1-2001 they cannot   contain comma so we can safely split above string on comma. 
Hive,WITHOUT_CLASSIFICATION,//  For all practical purposes a code point is a fancy name for character. A java char data type   can store characters that require 16 bits or less. However the unicode specification has   changed to allow for characters whose representation requires more than 16 bits. Therefore we   need to represent each character (called a code point from hereon) as int. More details at   http://docs.oracle.com/javase/7/docs/api/java/lang/Character.html 
Hive,WITHOUT_CLASSIFICATION,//  This map defines the progression of up casts in numeric types. 
Hive,WITHOUT_CLASSIFICATION,//  Look for tables without pattern 
Hive,WITHOUT_CLASSIFICATION,//  Columns are output from the join from the different reduce sinks in the order of their 
Hive,WITHOUT_CLASSIFICATION,//  Leading space is significant 
Hive,WITHOUT_CLASSIFICATION,//  This appears to leave the remove transaction in an inconsistent state but the heartbeat is now   cancelled and it will eventually time out 
Hive,WITHOUT_CLASSIFICATION,//  if column name is not contained in needed column list then it   is a partition column. We do not need to evaluate partition columns   in filter expression since it will be taken care by partitio pruner 
Hive,WITHOUT_CLASSIFICATION,//  only single subquery expr is supported 
Hive,WITHOUT_CLASSIFICATION,//  CHAR and VARCHAR types can be specified with maximum length. 
Hive,WITHOUT_CLASSIFICATION,//  close the existing ctx etc before compiling a new query but does not destroy driver 
Hive,WITHOUT_CLASSIFICATION,//  ideally we should just call FileInputFormat.setInputPaths() here - but   that won't work since FileInputFormat.setInputPaths() needs   a Job object instead of a JobContext which we are handed here 
Hive,WITHOUT_CLASSIFICATION,//    trim=false 
Hive,WITHOUT_CLASSIFICATION,//  we have checked all the parents for the "index" position. 
Hive,WITHOUT_CLASSIFICATION,//  Note: we get query ID here rather than in the caller where it would be more correct         because we know which exact query we intend to kill. This is valid because we         are not expecting query ID to change - we never reuse the session for which a 
Hive,WITHOUT_CLASSIFICATION,/*      * Calculate the std result when count > 1.  Public so vectorization code can     * use it etc.      */
Hive,WITHOUT_CLASSIFICATION,/*    * make sure Aborted txns don't red-flag a base_xxxx (HIVE-14350)    */
Hive,WITHOUT_CLASSIFICATION,//  Transformation :   Outer Query Left Join (inner query) on correlated predicate 
Hive,WITHOUT_CLASSIFICATION,//  make SSL connection 
Hive,WITHOUT_CLASSIFICATION,//  Previous batch was the last of a group of batches.  Remember the next is the first batch   of a new group of batches. 
Hive,WITHOUT_CLASSIFICATION,//  do nothing because "And" and "Or" and "Not" supports null value   evaluation   NOTE: In the future all UDFs that treats null value as UNKNOWN (both   in parameters and return   values) should derive from a common base class UDFNullAsUnknown so   instead of listing the classes   here we would test whether a class is derived from that base class.   If All childs are null set unknown to true 
Hive,WITHOUT_CLASSIFICATION,//  unix_timestamp(args) -> to_unix_timestamp(args) 
Hive,WITHOUT_CLASSIFICATION,//  Druid only support appending more partitions to Linear and Numbered ShardSpecs. 
Hive,WITHOUT_CLASSIFICATION,//  First we check if the two table scan operators can actually be merged 
Hive,WITHOUT_CLASSIFICATION,//  Create an empty output object which will be populated when convert() is invoked. 
Hive,WITHOUT_CLASSIFICATION,//  Iterative through the children in a DFS manner to see if there is more than 1 table alias 
Hive,WITHOUT_CLASSIFICATION,//  Obtain list of col stats or use default if they are not available 
Hive,WITHOUT_CLASSIFICATION,//  Position doesn't make sense for async reader chunk order is arbitrary. 
Hive,WITHOUT_CLASSIFICATION,//  Pre-allocated member for remembering the big table's selected array at the beginning of   the process method before applying any filter.  For outer join we need to remember which   rows did not match since they will appear the in outer join result with NULLs for the 
Hive,WITHOUT_CLASSIFICATION,//  Validate that we can add partition without escaping. Escaping was originally intended   to avoid creating invalid HDFS paths; however if we escape the HDFS path (that we   deem invalid but HDFS actually supports - it is possible to create HDFS paths with   unprintable characters like ASCII 7) metastore will create another directory instead   of the one we are trying to "repair" here. 
Hive,WITHOUT_CLASSIFICATION,//  it should be the same as the MoveWork's sourceDir. 
Hive,WITHOUT_CLASSIFICATION,//  There is no need for the user to specify mapjoin for it to be 
Hive,WITHOUT_CLASSIFICATION,//  Compaction doesn't work under a transaction and hence pass 0 for current txn Id 
Hive,WITHOUT_CLASSIFICATION,//     Release initial refcounts. 
Hive,WITHOUT_CLASSIFICATION,//  the registers 
Hive,WITHOUT_CLASSIFICATION,//  check the specified partitions 
Hive,WITHOUT_CLASSIFICATION,//  STATS_DESC 
Hive,WITHOUT_CLASSIFICATION,/*    * Use when merging variance and partialCount > 0 and mergeCount > 0.   *   * NOTE: mergeCount and mergeSum do not include partialCount and partialSum yet.    */
Hive,WITHOUT_CLASSIFICATION,//  Evaluate THEN expression (only) and copy all its results. 
Hive,WITHOUT_CLASSIFICATION,/*     use loadTask as dependencyCollection    */
Hive,WITHOUT_CLASSIFICATION,//  If there's no fraction part return immediately to avoid the cost of a divide. 
Hive,WITHOUT_CLASSIFICATION,//  Either the slice comes entirely after the end of split (following a gap in cached   data); or the split ends in the middle of the slice so it's the same as in the   startIx logic w.r.t. the partial match; so we either don't want to or cannot   use this. There's no need to distinguish these two cases for now. 
Hive,WITHOUT_CLASSIFICATION,//  Random 
Hive,WITHOUT_CLASSIFICATION,//  SemanticAnalyzer 
Hive,WITHOUT_CLASSIFICATION,//  This regex is a bit lax in order to compensate for lack of any escaping   done by Amazon S3 ... for example useragent string can have double quotes 
Hive,WITHOUT_CLASSIFICATION,//  Replace the filter expression to reference output of the join 
Hive,WITHOUT_CLASSIFICATION,//  Java Primitive Type? 
Hive,WITHOUT_CLASSIFICATION,//  skipping columns since partition level field schemas are the same as table level's   skipping partition keys since it is the same as table level partition keys 
Hive,WITHOUT_CLASSIFICATION,//  getTable is invoked after fetching the table names 
Hive,WITHOUT_CLASSIFICATION,//  3. Add Child Project Rel if needed Generate Output RR input Sel Rel 
Hive,WITHOUT_CLASSIFICATION,//  Create the new RowSchema for the projected column 
Hive,WITHOUT_CLASSIFICATION,//  create 10 dummy partitions 
Hive,WITHOUT_CLASSIFICATION,//  child 0 is the name of the column 
Hive,WITHOUT_CLASSIFICATION,//  38 * 2 or 76 full decimal maximum - (64 + 8) digits in 4 lower longs (4 digits here). 
Hive,WITHOUT_CLASSIFICATION,/*    * Use this copy method when the source batch is safe and will remain around until the target   * batch is finished.   *   * Any bytes column vector values will be referenced by the target column instead of copying.    */
Hive,WITHOUT_CLASSIFICATION,//  Finally SUBMIT the JOB! 
Hive,WITHOUT_CLASSIFICATION,//  read in the first 1K characters from the URL 
Hive,WITHOUT_CLASSIFICATION,//  and initiates the SASL handshake. 
Hive,WITHOUT_CLASSIFICATION,//  Convert decimal into the scratch buffer without allocating a byte[] each time   for better performance. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#addBatch(java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  if it is two way left outer or right outer join take selectivity only for 
Hive,WITHOUT_CLASSIFICATION,//  column projection 
Hive,WITHOUT_CLASSIFICATION,//  MySQL returns 0 if the string is not a well-formed numeric value.   But we decided to return NULL instead which is more conservative. 
Hive,WITHOUT_CLASSIFICATION,//  REPL STATUS 
Hive,WITHOUT_CLASSIFICATION,//  GBY Operator of the RS Operator. 
Hive,WITHOUT_CLASSIFICATION,//  hash map overhead 
Hive,WITHOUT_CLASSIFICATION,//  No scratch dir initially 
Hive,WITHOUT_CLASSIFICATION,//  Run the Worker explicitly in order to get the reference to the compactor MR job 
Hive,WITHOUT_CLASSIFICATION,//  Now start with everything and test losing stuff. 
Hive,WITHOUT_CLASSIFICATION,//  By default assume we can user directSQL - that's kind of the point. 
Hive,WITHOUT_CLASSIFICATION,//  Only TezTask sets this and then removes when done so we don't expect to see it. 
Hive,WITHOUT_CLASSIFICATION,//  incorrect precision: expected:<0 xxxxx yyy 5.2[]> but was:<0 xxxxx yyy 5.2[0]> 
Hive,WITHOUT_CLASSIFICATION,//  verify when third argument is repeating 
Hive,WITHOUT_CLASSIFICATION,//  Metrics system will get this via reflection 0_o 
Hive,WITHOUT_CLASSIFICATION,//  like type. 
Hive,WITHOUT_CLASSIFICATION,//  Don't clear the hash table - reuse is possible. GC will take care of it. 
Hive,WITHOUT_CLASSIFICATION,//  same but repeating value is null 
Hive,WITHOUT_CLASSIFICATION,//  we should get back the latest reader schema: 
Hive,WITHOUT_CLASSIFICATION,//  drop a table without saving to trash by setting the purge option 
Hive,WITHOUT_CLASSIFICATION,//  SUCCESS 
Hive,WITHOUT_CLASSIFICATION,/*        the currentPartitionDesc cannot be inlined as we need the hasNext() to be evaluated post the       current retrieved lastReplicatedPartition       */
Hive,WITHOUT_CLASSIFICATION,// Test for null partition value map 
Hive,WITHOUT_CLASSIFICATION,// clone to make sure new prop doesn't leak 
Hive,WITHOUT_CLASSIFICATION,//  We put the query user not LLAP user into the message and token. 
Hive,WITHOUT_CLASSIFICATION,//  If we got an error attempting to ss.close then it's not likely that   ss.err is valid. So we're back to System.err. Also we don't change   the return code we simply log a warning and return whatever return   code we expected to do already. 
Hive,WITHOUT_CLASSIFICATION,//  Following sequence of commit-abort-open-abort-commit. 
Hive,WITHOUT_CLASSIFICATION,//  Note: the only sane case where this can happen is the non-pool one. We should get rid         of it in non-pool case perf doesn't matter so we might as well open at get time         and then call update like we do in the else.   Can happen if the user sets the tez flag after the session was established. 
Hive,WITHOUT_CLASSIFICATION,//  tried all back to original code (for error message) 
Hive,WITHOUT_CLASSIFICATION,//  if parents aren't in llap neither should the child 
Hive,WITHOUT_CLASSIFICATION,//  will update current number of open txns back to 0 
Hive,WITHOUT_CLASSIFICATION,//  Omitting zone or time part is allowed 
Hive,WITHOUT_CLASSIFICATION,// no conflicting operations proceed with the rest of commit sequence 
Hive,WITHOUT_CLASSIFICATION,/*    * Returns false if there is a SelectExpr that is not a constant or an aggr.   *    */
Hive,WITHOUT_CLASSIFICATION,//  the subquery 
Hive,WITHOUT_CLASSIFICATION,//  For backward compatibility 
Hive,WITHOUT_CLASSIFICATION,//  Go over all the keys and get the size of the fields of fixed length. Keep 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * This provides a LazyShort like class which can be initialized from data stored in a   * binary format.   *   * @see org.apache.hadoop.hive.serde2.lazy.LazyObject#init   *        (org.apache.hadoop.hive.serde2.lazy.ByteArrayRef int int)    */
Hive,WITHOUT_CLASSIFICATION,//        because it should be impossible to get incompatible outputs. 
Hive,WITHOUT_CLASSIFICATION,//  Collect columns we copy from the big table batch to the overflow batch. 
Hive,WITHOUT_CLASSIFICATION,//  Escaping happened we need to copy byte-by-byte.   1. Set the length first. 
Hive,WITHOUT_CLASSIFICATION,//  it will be used to estimate num nulls 
Hive,WITHOUT_CLASSIFICATION,//  test for null input strings 
Hive,WITHOUT_CLASSIFICATION,//  if IF is self describing no need to send column info per partition since its not used anyway. 
Hive,WITHOUT_CLASSIFICATION,//  Don't emit user/timestamp info in test mode   so that the test golden output file is fixed. 
Hive,WITHOUT_CLASSIFICATION,//  List of SparkWork.Dependency 
Hive,WITHOUT_CLASSIFICATION,//  It could not be renewed return that information 
Hive,WITHOUT_CLASSIFICATION,//  map that keeps track of the last operator of a task to the following work 
Hive,WITHOUT_CLASSIFICATION,//  Test that not changing the database and the function name but only other parameters like 
Hive,WITHOUT_CLASSIFICATION,//  Reset table params 
Hive,WITHOUT_CLASSIFICATION,//  deep copy expr node desc 
Hive,WITHOUT_CLASSIFICATION,//  Use RW not PRIVATE because the copy-on-write is irrelevant for a deleted file 
Hive,WITHOUT_CLASSIFICATION,//  [A: 0 B: 0 B.x: 1 B.y: 0 C: 0] 
Hive,WITHOUT_CLASSIFICATION,//  Virtual trailing zeroes. 
Hive,WITHOUT_CLASSIFICATION,//  Nothing to cleanup 
Hive,WITHOUT_CLASSIFICATION,//  Then scale up with 5 
Hive,WITHOUT_CLASSIFICATION,//  Go through the Reduce keys and find the matching column(s) in the reduce values 
Hive,WITHOUT_CLASSIFICATION,//  nesting not allowed! 
Hive,WITHOUT_CLASSIFICATION,//  LOG.debug("VectorMapJoinFastLongHashTable add key " + key + " slot " + slot + " pairIndex " + pairIndex + " found key (i = " + i + ")"); 
Hive,WITHOUT_CLASSIFICATION,//  For debug tracing: information about the map or reduce task operator operator class etc. 
Hive,WITHOUT_CLASSIFICATION,//  special handling. 
Hive,WITHOUT_CLASSIFICATION,//  create a walker which walks the tree in a DFS manner while maintaining 
Hive,WITHOUT_CLASSIFICATION,//  Cartesian product is not supported in strict mode 
Hive,WITHOUT_CLASSIFICATION,//  The expected tags from the parent operators. See processOp() before 
Hive,WITHOUT_CLASSIFICATION,//  mimicking behaviour in CreateTableDesc tableDesc creation   returning null table description for output. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setNull(java.lang.String int   * java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  call getHCatComparisonString on lhs and rhs and and join the   results with OpType string 
Hive,WITHOUT_CLASSIFICATION,// ---------------------------------------------------------------------------   Process Multi-Key Outer Join on a vectorized row batch.   
Hive,WITHOUT_CLASSIFICATION,//  there should be only one MRInput 
Hive,WITHOUT_CLASSIFICATION,// then check if it is distinct key 
Hive,WITHOUT_CLASSIFICATION,//  Initialize a deleteEventWriter if not yet done. (Lazy initialization) 
Hive,WITHOUT_CLASSIFICATION,//  Don't log exception here. 
Hive,WITHOUT_CLASSIFICATION,//  The root might have changed because of tree modifications.   Compute the new root for this tree and set the astStr. 
Hive,WITHOUT_CLASSIFICATION,//  Apply rest of the configuration only to HiveServer2 
Hive,WITHOUT_CLASSIFICATION,//  Can't divide NULL. 
Hive,WITHOUT_CLASSIFICATION,//  set up a java key provider for encrypted hdfs cluster 
Hive,WITHOUT_CLASSIFICATION,//  try to get default value only if this is DEFAULT constraint 
Hive,WITHOUT_CLASSIFICATION,//  The header to look for. We use "X-XSRF-HEADER" if this is null.   Methods to not filter. By default: "GETOPTIONSHEADTRACE" if null. 
Hive,WITHOUT_CLASSIFICATION,//  VectorMapOperator. 
Hive,WITHOUT_CLASSIFICATION,//  print header   -------------------------------------------------------------------------------           VERTICES     STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED 
Hive,WITHOUT_CLASSIFICATION,//  The eventual goal is to monitor the progress of all the tasks not only the   map reduce task.   The execute() method of the tasks will return immediately and return a   task specific handle to   monitor the progress of that task.   Right now the behavior is kind of broken ExecDriver's execute method   calls progress - instead it should   be invoked by Driver 
Hive,WITHOUT_CLASSIFICATION,//  of Accumulo Ranges 
Hive,WITHOUT_CLASSIFICATION,//  Convert the join operator to a bucket map-join join operator 
Hive,WITHOUT_CLASSIFICATION,//  common comparison class for char/varchar is string? 
Hive,WITHOUT_CLASSIFICATION,//  Skip the same value if avgDistinct is true 
Hive,WITHOUT_CLASSIFICATION,// can safely convert the join to a map join. 
Hive,WITHOUT_CLASSIFICATION,//  We will retrieve stats from the metastore only for columns that are not cached 
Hive,WITHOUT_CLASSIFICATION,//  We could make some assumptions given how the reader currently does the work (consecutive   chunks etc.; blocks and columns stored in offset order in the lists) but we won't -   just save all the chunk boundaries and lengths for now. 
Hive,WITHOUT_CLASSIFICATION,//  assert that there is one partition present and it had hcat instrumentation inserted when it was created. 
Hive,WITHOUT_CLASSIFICATION,//  Source operator to get the number of entries 
Hive,WITHOUT_CLASSIFICATION,//  Use PurgeCacheResponseProto.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,//  Step 2.2: Replace the corresponding part childMRWork's MapWork. 
Hive,WITHOUT_CLASSIFICATION,//  transaction batch size = 1 case 
Hive,WITHOUT_CLASSIFICATION,//  Repeat the same check for dropTable. 
Hive,WITHOUT_CLASSIFICATION,//  table exists 
Hive,WITHOUT_CLASSIFICATION,//  Should not get here. 
Hive,WITHOUT_CLASSIFICATION,//  Conditions. 
Hive,WITHOUT_CLASSIFICATION,//  setRef is used below and this is safe because the reference   is to data owned by this column vector. If this column vector   gets re-used the whole thing is re-used together so there   is no danger of a dangling reference. 
Hive,WITHOUT_CLASSIFICATION,//  Form result from lower middle and middle words. 
Hive,WITHOUT_CLASSIFICATION,//  The new base dir now has two bucket files since the delta dir has two bucket files 
Hive,WITHOUT_CLASSIFICATION,//  we proceed only if we'd actually succeeded anyway otherwise 
Hive,WITHOUT_CLASSIFICATION,// test_param_2 = "50" 
Hive,WITHOUT_CLASSIFICATION,//  excludedProvidedBy Framework vs excludedConfigured 
Hive,WITHOUT_CLASSIFICATION,/*  HCat Output Format related errors 2000 - 2999  */
Hive,WITHOUT_CLASSIFICATION,//  Indicate last batch of current group. 
Hive,WITHOUT_CLASSIFICATION,/*    * Helper function to retrieve the basename of a local resource    */
Hive,WITHOUT_CLASSIFICATION,//  since currentReadBlock may assigned to currentWriteBlock we need to store 
Hive,WITHOUT_CLASSIFICATION,//  This will throw an expected exception since   client is communicating with the wrong http service endpoint 
Hive,WITHOUT_CLASSIFICATION,//  throw a HiveException if the table/partition is archived 
Hive,WITHOUT_CLASSIFICATION,//  find out database name and table name of target table 
Hive,WITHOUT_CLASSIFICATION,//  We need some value that indicates NULL. 
Hive,WITHOUT_CLASSIFICATION,//  Done we have 3 bytes. Continue reading this buffer. 
Hive,WITHOUT_CLASSIFICATION,//  update old data with values for the new schema columns 
Hive,WITHOUT_CLASSIFICATION,//  Get the sort order 
Hive,WITHOUT_CLASSIFICATION,//  We are just a relay; send unpause to encoded data producer. 
Hive,WITHOUT_CLASSIFICATION,/*        * The TableScanOperator's needed columns are just the data columns.        */
Hive,WITHOUT_CLASSIFICATION,//  For non-acid tables (or paths) all data files are in getOriginalFiles() list 
Hive,WITHOUT_CLASSIFICATION,//  verify we found them all 
Hive,WITHOUT_CLASSIFICATION,//  Close output stream if open 
Hive,WITHOUT_CLASSIFICATION,//  TOK_ALTERVIEW_AS 
Hive,WITHOUT_CLASSIFICATION,//  97 
Hive,WITHOUT_CLASSIFICATION,//  the api that finds the jar being used by this class on disk 
Hive,WITHOUT_CLASSIFICATION,//  number of columns pertaining to keys in a vectorized row batch 
Hive,WITHOUT_CLASSIFICATION,//  Because every value will be NULL. 
Hive,WITHOUT_CLASSIFICATION,//  input/output settings 
Hive,WITHOUT_CLASSIFICATION,//  CTE 
Hive,WITHOUT_CLASSIFICATION,//  that QH will not be too far from the correct digit later in D3 
Hive,WITHOUT_CLASSIFICATION,//  INFO_VALUE 
Hive,WITHOUT_CLASSIFICATION,//  Double-check the header under lock. 
Hive,WITHOUT_CLASSIFICATION,//  Now add the corVars from the input starting from   position oldGroupKeyCount. 
Hive,WITHOUT_CLASSIFICATION,//  Use Junit's Assume to skip running this fixture against any storage formats whose   SerDe is in the disabled serdes list. 
Hive,WITHOUT_CLASSIFICATION,//  hive has no max limit for strings 
Hive,WITHOUT_CLASSIFICATION,//  For snapshot isolation we don't care about txns greater than current txn and so stop here.   Also we need not include current txn to exceptions list. 
Hive,WITHOUT_CLASSIFICATION,//  have to emulate "distinct" otherwise tables with the same name may be returned 
Hive,WITHOUT_CLASSIFICATION,//  true if it is insert overwrite. 
Hive,WITHOUT_CLASSIFICATION,//  be able to report progress. 
Hive,WITHOUT_CLASSIFICATION,//  Don't use Assert.fail we are catching assertion errors. 
Hive,WITHOUT_CLASSIFICATION,//  The object that determines equal key series. 
Hive,WITHOUT_CLASSIFICATION,//  Collect column access information 
Hive,WITHOUT_CLASSIFICATION,//  decide whether this is already in hashmap (keys in hashmap are deepcopied   version and we need to use 'currentKeyObjectInspector'). 
Hive,WITHOUT_CLASSIFICATION,//  No task lock. But acquires lock on the scheduler 
Hive,WITHOUT_CLASSIFICATION,// no-op 
Hive,WITHOUT_CLASSIFICATION,//  This is an internal error something odd happened with reflection so   log it and don't output the bean. 
Hive,WITHOUT_CLASSIFICATION,/*  Routines for copying between VectorizedRowBatches  */
Hive,WITHOUT_CLASSIFICATION,/*        * if there are fewer than leadAmt values in leadWindow; start reading from the first position.       * Otherwise the window starts from nextPosInWindow.        */
Hive,WITHOUT_CLASSIFICATION,//  At this point we have seen the exponent letter E or e and have decimal information as:       isNegative precision integerDigitCount nonTrailingZeroScale and       fast0 fast1 fast2.     After we determine the exponent we will do appropriate scaling and fill in fastResult. 
Hive,WITHOUT_CLASSIFICATION,//  Map 1 .......... 
Hive,WITHOUT_CLASSIFICATION,//  create the destination if it does not exist 
Hive,WITHOUT_CLASSIFICATION,//  Special handling for time-zone 
Hive,WITHOUT_CLASSIFICATION,//  LazyBinary seems to work better with an row object array instead of a Java object... 
Hive,WITHOUT_CLASSIFICATION,//  dealing with views 
Hive,WITHOUT_CLASSIFICATION,//  maybe valid - too expensive to check without a parse 
Hive,WITHOUT_CLASSIFICATION,//  Calculate relative offset 
Hive,WITHOUT_CLASSIFICATION,//  Rows are in a combination of the on-disk hashmap and the sidefile 
Hive,WITHOUT_CLASSIFICATION,//  the vertex that this operator belongs to 
Hive,WITHOUT_CLASSIFICATION,//  FUNC_NAME 
Hive,WITHOUT_CLASSIFICATION,//  Since we don't have a non-native or pass-thru version of VectorPTFOperator we do not   have enableConditionsMet / enableConditionsNotMet like we have for VectorReduceSinkOperator   etc. 
Hive,WITHOUT_CLASSIFICATION,//  Stateful? 
Hive,WITHOUT_CLASSIFICATION,//  Check query results cache   In the case that row or column masking/filtering was required we do not support caching. 
Hive,WITHOUT_CLASSIFICATION,//  To handle the case like SUM(LAG(f)) over() aggregation function includes   LAG/LEAD call 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:SubmitWorkRequestProto) 
Hive,WITHOUT_CLASSIFICATION,//  Build not null conditions 
Hive,WITHOUT_CLASSIFICATION,//  2.2 Obtain col stats for partitioned table. 
Hive,WITHOUT_CLASSIFICATION,//  check access columns from ColumnAccessInfo 
Hive,WITHOUT_CLASSIFICATION,//  such as "abc\%" 
Hive,WITHOUT_CLASSIFICATION,//  The key wasn't present in the mapping and the function didn't   return a default value - ignore and use our default. 
Hive,WITHOUT_CLASSIFICATION,//  BINARY_VAL 
Hive,WITHOUT_CLASSIFICATION,//  Wrapper extends ql.metadata.Partition for easy construction syntax 
Hive,WITHOUT_CLASSIFICATION,// subquery either in WHERE <LHS> IN <SUBQUERY> form OR WHERE EXISTS <SUBQUERY> form  in first case LHS should not be bypassed 
Hive,WITHOUT_CLASSIFICATION,// this is just for debug 
Hive,WITHOUT_CLASSIFICATION,//  local path doesn't depend on drone variables 
Hive,WITHOUT_CLASSIFICATION,//  Insert overwrite ACID table from source table 
Hive,WITHOUT_CLASSIFICATION,//  We could not have removed the pool for this session or we would have CANCELED the init. 
Hive,WITHOUT_CLASSIFICATION,//  -e 'query' 
Hive,WITHOUT_CLASSIFICATION,//  this table cannot be big table 
Hive,WITHOUT_CLASSIFICATION,//  Map 1 - 28 splits   Map 3 - 28 splits 
Hive,WITHOUT_CLASSIFICATION,//  Copy JAR to DFS 
Hive,WITHOUT_CLASSIFICATION,//  @VisibleForTesting 
Hive,WITHOUT_CLASSIFICATION,//  Test that jdbc does not allow shell commands starting with "!". 
Hive,WITHOUT_CLASSIFICATION,//  If the join keys matches the skewed keys use the table skewed keys 
Hive,WITHOUT_CLASSIFICATION,//  If the first byte of the VInt is -1 the VInt itself is -1 indicating that there is a   second VInt but the nanoseconds field is actually 0. 
Hive,WITHOUT_CLASSIFICATION,//  This is a test. The parameter hive.test.dummystats.aggregator's value   denotes the method which needs to throw an error. 
Hive,WITHOUT_CLASSIFICATION,//  First read the CB header. Due to ORC estimates ZCR etc. this can be complex. 
Hive,WITHOUT_CLASSIFICATION,//  If you change this function remove the @Ignore from TestTxnHandler.deadlockIsDetected()   to test these changes.   MySQL and MSSQL use 40001 as the state code for rollback.  Postgres uses 40001 and 40P01.   Oracle seems to return different SQLStates and messages each time   so I've tried to capture the different error messages (there appear to be fewer different   error messages than SQL states).   Derby and newer MySQL driver use the new SQLTransactionRollbackException 
Hive,WITHOUT_CLASSIFICATION,//  Now re-initialize batch1 to simulate batch-object re-use. 
Hive,WITHOUT_CLASSIFICATION,//  remove all detached objects from the cache since the transaction is   being rolled back they are no longer relevant and this prevents them   from reattaching in future transactions 
Hive,WITHOUT_CLASSIFICATION,//  We're pretty screwed if we can't load the default conf vars 
Hive,WITHOUT_CLASSIFICATION,//  Current hashMap in use 
Hive,WITHOUT_CLASSIFICATION,//  Call here because at this point the WindowTableFunctionDef has been set 
Hive,WITHOUT_CLASSIFICATION,//  Start: tests that check values from Pig that are out of range for target column 
Hive,WITHOUT_CLASSIFICATION,//  Form the expression node corresponding to column 
Hive,WITHOUT_CLASSIFICATION,//                    123456789012345678901234567890123456789012345 
Hive,WITHOUT_CLASSIFICATION,//  Truncate by re-opening FileOutputStream. 
Hive,WITHOUT_CLASSIFICATION,//  First find the path to be searched 
Hive,WITHOUT_CLASSIFICATION,//  Update the database in cache 
Hive,WITHOUT_CLASSIFICATION,//  present in the child (& hence we add a child Project Rel) 
Hive,WITHOUT_CLASSIFICATION,//  ClusterBy 
Hive,WITHOUT_CLASSIFICATION,//  Add to signature 
Hive,WITHOUT_CLASSIFICATION,/*            * Single-Column String get key.            */
Hive,WITHOUT_CLASSIFICATION,//  parse the string to determine column level storage type for primitive types   's' is for variable length string format storage   'b' is for fixed width binary storage of bytes   '-' is for table storage type which defaults to UTF8 string   string data is always stored in the default escaped storage format; the data types   byte short int long float and double have a binary byte oriented storage option 
Hive,WITHOUT_CLASSIFICATION,//  Append Mode 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.CLIServiceClient#getTables(org.apache.hive.service.cli.SessionHandle java.lang.String java.lang.String java.lang.String java.util.List)    */
Hive,WITHOUT_CLASSIFICATION,//  right now they come from jpox.properties 
Hive,WITHOUT_CLASSIFICATION,//  template <ClassNamePrefix> <ReturnType> <FuncName> 
Hive,WITHOUT_CLASSIFICATION,//  Use only 1 reducer for order by 
Hive,WITHOUT_CLASSIFICATION,//  At this point we don't have to do anything special in this case. Just   run through the regular paces w/o creating a new task. 
Hive,WITHOUT_CLASSIFICATION,//  connection above 
Hive,WITHOUT_CLASSIFICATION,//  Continue on to the next code point 
Hive,WITHOUT_CLASSIFICATION,//  open the client transport 
Hive,WITHOUT_CLASSIFICATION,//  Euro sign (3 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  1. It is an IN operator check if it uses STRUCT 
Hive,WITHOUT_CLASSIFICATION,/*        * Restriction.9.m :: disallow nested SubQuery expressions.        */
Hive,WITHOUT_CLASSIFICATION,//  can safely convert the join to a map join. 
Hive,WITHOUT_CLASSIFICATION,// Extract the partitions keys segments granularity and partition key if any 
Hive,WITHOUT_CLASSIFICATION,//  We do not use the new cache buffers for the actual read given the way read() API is.   Therefore we don't need to handle cache collisions - just decref all the buffers. 
Hive,WITHOUT_CLASSIFICATION,/*          * this happens in case of map join operations.         * The tree looks like this:         *         *        RS <--- we are here perhaps         *        |         *     MapJoin         *     /     \         *   RS       TS         *  /         * TS         *         * If we are at the RS pointed above and we may have already visited the         * RS following the TS we have already generated work for the TS-RS.         * We need to hook the current work to this generated work.          */
Hive,WITHOUT_CLASSIFICATION,//  Suppress useless evaluation. 
Hive,WITHOUT_CLASSIFICATION,//  If Kerberos 
Hive,WITHOUT_CLASSIFICATION,//  there is no predicate on partitioning column we need all partitions   in this case. 
Hive,WITHOUT_CLASSIFICATION,//  Driver not initialized 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:SignableVertexSpec) 
Hive,WITHOUT_CLASSIFICATION,// Hiveserver2 using "-hiveconf hive.hadoop.classpath=%HIVE_LIB%". This is to combine path(s). 
Hive,WITHOUT_CLASSIFICATION,//  Since HiveDecimal now uses FastHiveDecimal which stores 16 decimal digits per long   lets test edge conditions here. 
Hive,WITHOUT_CLASSIFICATION,//  Walk through the projection list and replace the column names with the   expressions from the original update.  Under the TOK_SELECT (see above) the structure   looks like:   TOK_SELECT -> TOK_SELEXPR -> expr             \-> TOK_SELEXPR -> expr ... 
Hive,WITHOUT_CLASSIFICATION,/*        * Clone the Search AST; apply all rewrites on the clone.        */
Hive,WITHOUT_CLASSIFICATION,//  how many times we'll sleep before giving up 
Hive,WITHOUT_CLASSIFICATION,//  A bunch of these are in HiveMetaStoreClient but not IMetaStoreClient.  I have marked these   as deprecated and not updated them for the catalogs.  If we really want to support them we   should add them to IMetaStoreClient. 
Hive,WITHOUT_CLASSIFICATION,//  SELECT * FROM src1 LATERAL VIEW udtf() AS myTable JOIN src2 ...   is not supported. Instead the lateral view must be in a subquery   SELECT * FROM (SELECT * FROM src1 LATERAL VIEW udtf() AS myTable) a   JOIN src2 ... 
Hive,WITHOUT_CLASSIFICATION,//  load jars under the hive.reloadable.aux.jars.path 
Hive,WITHOUT_CLASSIFICATION,//  proper children of the union 
Hive,WITHOUT_CLASSIFICATION,//  change curr ops row resolver's tab aliases to subq alias 
Hive,WITHOUT_CLASSIFICATION,//  nullIndicator after the transformation. 
Hive,WITHOUT_CLASSIFICATION,//  Only seal those partitions that haven't been spilled and cleared   because once a hashMap is cleared it will become unusable 
Hive,WITHOUT_CLASSIFICATION,//  Generate the hiveConfArgs after potentially adding the jars 
Hive,WITHOUT_CLASSIFICATION,//  if the execution engine is MR set the map/reduce env with the credential store password 
Hive,WITHOUT_CLASSIFICATION,//  ReplicationSpec.KEY scopeKey = ReplicationSpec.KEY.REPL_SCOPE; 
Hive,WITHOUT_CLASSIFICATION,//  If a table is in bigTables then its output is big (2) 
Hive,WITHOUT_CLASSIFICATION,//  Try to fold (key <op> 86) and (key is not null) to (key <op> 86)   where <op> can be "=" ">=" "<=" ">" "<".   Note: (key <> 86) and (key is not null) cannot be folded 
Hive,WITHOUT_CLASSIFICATION,//  Server thread pool 
Hive,WITHOUT_CLASSIFICATION,//  Process else statement 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) EnumDefList  */
Hive,WITHOUT_CLASSIFICATION,//  validate reserved values 
Hive,WITHOUT_CLASSIFICATION,//  Handle case with nulls. Don't do function if the value is null   because the data may be undefined for a null value. 
Hive,WITHOUT_CLASSIFICATION,//  This table is not yet loaded in cache   If the prewarm thread is working on this table's database   let's move this table to the top of tblNamesBeingPrewarmed stack   so that it gets loaded to the cache faster and is available for subsequent requests 
Hive,WITHOUT_CLASSIFICATION,//  Copy an intervening non-CRLF characters up to but not including current 'index'. 
Hive,WITHOUT_CLASSIFICATION,//  String.split returns a single empty result for splitting the empty 
Hive,WITHOUT_CLASSIFICATION,/*  alternate1 = unused  */
Hive,WITHOUT_CLASSIFICATION,//  try to get prime number table size to have less dependence on good hash function 
Hive,WITHOUT_CLASSIFICATION,/*    * Represents a PTF Invocation. Captures:   * - function name and alias   * - the Partitioning details about its input   * - its arguments. The ASTNodes representing the arguments are captured here.   * - a reference to its Input    */
Hive,WITHOUT_CLASSIFICATION,//  Remove from cache if it is a materialized view 
Hive,WITHOUT_CLASSIFICATION,//  iF RS is found remove it and its child (EX) and connect its parent 
Hive,WITHOUT_CLASSIFICATION,//  batches will be sized 1131 
Hive,WITHOUT_CLASSIFICATION,//  5. Run Cleaner. Shouldn't impact anything. 
Hive,WITHOUT_CLASSIFICATION,// for case of conversion convert both values to common type and then compare. 
Hive,WITHOUT_CLASSIFICATION,//  each partition maintains a large properties 
Hive,WITHOUT_CLASSIFICATION,//  Since warehouse path is non-qualified the table should be located on second filesystem 
Hive,WITHOUT_CLASSIFICATION,//  Sanity check for overlap with regions already being expanded 
Hive,WITHOUT_CLASSIFICATION,//  Construct a temp table name 
Hive,WITHOUT_CLASSIFICATION,//  subsequent K hashes are used to generate K bits within a block of words 
Hive,WITHOUT_CLASSIFICATION,// 4. because there is only one TS for analyze statement we can get it. 
Hive,WITHOUT_CLASSIFICATION,//  Only for live instances. 
Hive,WITHOUT_CLASSIFICATION,//  to the tasks are not ready yet the task is eligible for pre-emptable. 
Hive,WITHOUT_CLASSIFICATION,//  Hive Variables 
Hive,WITHOUT_CLASSIFICATION,//  This can happen for numbers less than 0.1   For 0.001234: rawPrecision=4 scale=6   In this case we'll set the type to have the same precision as the scale. 
Hive,WITHOUT_CLASSIFICATION,//  The percentage of maximum allocated memory that triggers GC   on job tracker. This could be overridden thru the jobconf. 
Hive,WITHOUT_CLASSIFICATION,//  find the privileges that we are looking for 
Hive,WITHOUT_CLASSIFICATION,//  Lazy binary value serializer. 
Hive,WITHOUT_CLASSIFICATION,//  Test that existing shared_read db with new exclusive coalesces to 
Hive,WITHOUT_CLASSIFICATION,// ok since previously opened txn was killed 
Hive,WITHOUT_CLASSIFICATION,//  We may need to update the conditional task's list. This happens when a common map join   task exists in the task list and has already been processed. In such a case   the current task is the map join task and we need to replace it with   its parent i.e. the small table task. 
Hive,WITHOUT_CLASSIFICATION,// Other fields are skipped for this case 
Hive,WITHOUT_CLASSIFICATION,//  Don't fail execution due to counters - just don't print summary info 
Hive,WITHOUT_CLASSIFICATION,//  Only check host/port pair is valid wheter the file exist or not does not matter 
Hive,WITHOUT_CLASSIFICATION,//  4: Add a partition P1 to T2 => 1 event 
Hive,WITHOUT_CLASSIFICATION,//  Combo 2: Literal set url set to none 
Hive,WITHOUT_CLASSIFICATION,//  return empty string 
Hive,WITHOUT_CLASSIFICATION,//  Bail on an exception - out of the loop. 
Hive,WITHOUT_CLASSIFICATION,//  is called to stop the query if it is running clean query results and release resources. 
Hive,WITHOUT_CLASSIFICATION,//  Find tables which name contains _to_find_ in the default database 
Hive,WITHOUT_CLASSIFICATION,//  Key is aggregate of partition values column name and the value is the col stat object 
Hive,WITHOUT_CLASSIFICATION,//  Try this as a map 
Hive,WITHOUT_CLASSIFICATION,//  String enclosed by single quotes. 
Hive,WITHOUT_CLASSIFICATION,//  Requirements: for SMB sorted by their keys on both sides and bucketed.   Get key columns 
Hive,WITHOUT_CLASSIFICATION,//  Choose array size. We have two hash tables to hold entries so the sum   of the two should have a bit more than twice as much space as the   minimum required. 
Hive,WITHOUT_CLASSIFICATION,//  We do this before checking failedUpdate because that might break the iterator. 
Hive,WITHOUT_CLASSIFICATION,//  the output needed for the qfile results. 
Hive,WITHOUT_CLASSIFICATION,//  The zookeeper connection to use 
Hive,WITHOUT_CLASSIFICATION,//  This version of the loop eliminates a condition check and branch   and is measurably faster (20% or so) 
Hive,WITHOUT_CLASSIFICATION,//  Disable new tasks from being submitted 
Hive,WITHOUT_CLASSIFICATION,//  Create the temporary file its corresponding FileSinkOperaotr and 
Hive,WITHOUT_CLASSIFICATION,//  Remove failures for tasks that succeeded 
Hive,WITHOUT_CLASSIFICATION,//  get the set of all partition columns in custom path 
Hive,WITHOUT_CLASSIFICATION,//  strip the column name of the targetId 
Hive,WITHOUT_CLASSIFICATION,//  Divide down just before round point to get round digit. 
Hive,WITHOUT_CLASSIFICATION,//  if setAutoCommit is called and the auto-commit mode is not changed the call is a no-op. 
Hive,WITHOUT_CLASSIFICATION,//  Log(base Col) is a special case and will be implemented separately from this template 
Hive,WITHOUT_CLASSIFICATION,//  Catch the exceptions so every other metastore could be stopped as well   Log it so at least there is a slight possibility we find out about this :) 
Hive,WITHOUT_CLASSIFICATION,//  is the table already present 
Hive,WITHOUT_CLASSIFICATION,//  Remove additional elements if the list is reused 
Hive,WITHOUT_CLASSIFICATION,//                   of 2 
Hive,WITHOUT_CLASSIFICATION,//  Allocate the bean at the beginning - 
Hive,WITHOUT_CLASSIFICATION,//  set the wrong type parameters for prepared sql. 
Hive,WITHOUT_CLASSIFICATION,// Druid storage timestamp column name 
Hive,WITHOUT_CLASSIFICATION,//  VectorizedBatchUtil.debugDisplayOneRow(batch batchIndex "generateHashMapResultSingleValue big table"); 
Hive,WITHOUT_CLASSIFICATION,//  Use path relative to dataDir directory if it is not specified 
Hive,WITHOUT_CLASSIFICATION,//  check if input pruning is enough 
Hive,WITHOUT_CLASSIFICATION,// columns being updated -> update expressions; "setRCols" (last param) is null because we use actual expressions 
Hive,WITHOUT_CLASSIFICATION,//  Conversion to the target data type requires a "helper" target writable in a   few cases. 
Hive,WITHOUT_CLASSIFICATION,//  If partition is null on either of these then they are claiming to   lock the whole table and we need to check it.  Otherwise 
Hive,WITHOUT_CLASSIFICATION,//  The ColumnEncoding column name and type are all irrelevant at this point just need the   cf:[cq] 
Hive,WITHOUT_CLASSIFICATION,//  If the offset was never added or offset < fileSize. 
Hive,WITHOUT_CLASSIFICATION,//  filter tags for objects 
Hive,WITHOUT_CLASSIFICATION,//  Now the other enum possibility 
Hive,WITHOUT_CLASSIFICATION,//  The list of servers the database/partition/table can locate on   Hive username for use when creating the user not for connecting   Hive password for use when creating the user not for connecting   Hive database for use when creating the user not for connecting 
Hive,WITHOUT_CLASSIFICATION,//  2 we need to connect this cloned parent work with the corresponding child work. 
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.SubmitWorkRequestProto.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,//  if big alias is partitioned table it's partition spec + bucket number 
Hive,WITHOUT_CLASSIFICATION,//  Most accurate domain cardinality would be source column NDV if available. 
Hive,WITHOUT_CLASSIFICATION,//  it will be enabled in the CustomVertex. 
Hive,WITHOUT_CLASSIFICATION,//  From https://msdn.microsoft.com/en-us/library/ms190476.aspx   e1 * e2   Precision: p1 + p2 + 1   Scale: s1 + s2 
Hive,WITHOUT_CLASSIFICATION,// CTAS path or insert into file/directory 
Hive,WITHOUT_CLASSIFICATION,//  The free list level the blocks from which we need to merge. 
Hive,WITHOUT_CLASSIFICATION,//  if task.side.metadata is set rowGroupOffsets is null 
Hive,WITHOUT_CLASSIFICATION,// This is an update statement thus at any Isolation level will take Write locks so will block 
Hive,WITHOUT_CLASSIFICATION,//  In order to convert from integer to float correctly we need to apply the float cast not the double cast (HIVE-13338). 
Hive,WITHOUT_CLASSIFICATION,//  Logger debug message from "oproc" after log4j initialize properly 
Hive,WITHOUT_CLASSIFICATION,//  The planner puts a constant field in for the dummy grouping set id.  We will overwrite it 
Hive,WITHOUT_CLASSIFICATION,/*      * Use common decimal to binary conversion method we share with fastBigIntegerBytes.      */
Hive,WITHOUT_CLASSIFICATION,//  compression buffer size should only be set if compression is enabled 
Hive,WITHOUT_CLASSIFICATION,//  Start an instance of HiveServer2 which uses miniMR 
Hive,WITHOUT_CLASSIFICATION,//  Invalidate the entry. Rely on query cleanup to remove from lookup. 
Hive,WITHOUT_CLASSIFICATION,/*    * List    */
Hive,WITHOUT_CLASSIFICATION,//  Collect the needed columns from all the aliases and create ORed filter 
Hive,WITHOUT_CLASSIFICATION,//  check that a property that begins the same is also hidden 
Hive,WITHOUT_CLASSIFICATION,//  We might not be able to assign all rows because of input NULLs.  Start tracking any   unassigned rows. 
Hive,WITHOUT_CLASSIFICATION,//  For complex types like STRUCT MAP etc we do not support we need a writer that   does nothing.  We assume the Vectorizer class has not validated the query to actually   try and use the complex types.  They do show up in inputObjInspector[0] and need to be 
Hive,WITHOUT_CLASSIFICATION,//  Original scan only 
Hive,WITHOUT_CLASSIFICATION,//  Timestamp column type in Druid is timestamp with local time-zone as it represents   a specific instant in time. Thus we have this value and we need to extract the   granularity to split the data when we are storing it in Druid. However Druid stores   the data in UTC. Thus we need to apply the following logic on the data to extract   the granularity correctly:   1) Read the timestamp with local time-zone value.   2) Extract UTC epoch (millis) from timestamp with local time-zone.   3) Cast the long to a timestamp.   4) Apply the granularity function on the timestamp value.   That way '2010-01-01 00:00:00 UTC' and '2009-12-31 16:00:00 PST' (same instant)   will end up in the same Druid segment. 
Hive,WITHOUT_CLASSIFICATION,//  Generate new cookie and add it to the response 
Hive,WITHOUT_CLASSIFICATION,//  Guard because ASTNode.getChildren.iterator returns null if no children available (bug). 
Hive,WITHOUT_CLASSIFICATION,//  reconstruct join tree 
Hive,WITHOUT_CLASSIFICATION,//  -----------------------------------------------------------------------------------------------     Filter timestamp against timestamp long (seconds) and double (seconds with fractional   nanoseconds).      Filter  TimestampCol         {Equal|Greater|GreaterEqual|Less|LessEqual|NotEqual}   TimestampColumn    Filter  TimestampCol         {Equal|Greater|GreaterEqual|Less|LessEqual|NotEqual}   {Long|Double}Column  * Filter  {Long|Double}Col     {Equal|Greater|GreaterEqual|Less|LessEqual|NotEqual}   TimestampColumn      Filter  TimestampCol         {Equal|Greater|GreaterEqual|Less|LessEqual|NotEqual}   TimestampScalar    Filter  TimestampCol         {Equal|Greater|GreaterEqual|Less|LessEqual|NotEqual}   {Long|Double}Scalar  * Filter  {Long|Double}Col     {Equal|Greater|GreaterEqual|Less|LessEqual|NotEqual}   TimestampScalar      Filter  TimestampScalar      {Equal|Greater|GreaterEqual|Less|LessEqual|NotEqual}   TimestampColumn    Filter  TimestampScalar      {Equal|Greater|GreaterEqual|Less|LessEqual|NotEqual}   {Long|Double}Column  * Filter  {Long|Double}Scalar  {Equal|Greater|GreaterEqual|Less|LessEqual|NotEqual}   TimestampColumn     ----------------------------------------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  Set the required field. 
Hive,WITHOUT_CLASSIFICATION,//  Enable trash so it can be tested 
Hive,WITHOUT_CLASSIFICATION,//  if UNION ALL insert for non-mm tables subquery creates another subdirectory at the end for each union queries   <table-dir>/<staging-dir>/<partition-dir>/<union-dir> 
Hive,WITHOUT_CLASSIFICATION,//  we might have generated a dynamic partition operator chain. Since   we're removing the reduce sink we need do remove that too. 
Hive,WITHOUT_CLASSIFICATION,//  Add the layout to the queryId appender 
Hive,WITHOUT_CLASSIFICATION,//  Note - like vectorizer this assumes partition columns go after data columns. 
Hive,WITHOUT_CLASSIFICATION,//  Put sample data in the columns. 
Hive,WITHOUT_CLASSIFICATION,//  Set the correct position 
Hive,WITHOUT_CLASSIFICATION,//  5. Add the Partition expressions as the Order if there is no Order and validate Order spec. 
Hive,WITHOUT_CLASSIFICATION,//  Use the example from HIVE-13423 where the integer digits of the result exceed the   enforced precision/scale. 
Hive,WITHOUT_CLASSIFICATION,//  Handle cancellation of the promise. 
Hive,WITHOUT_CLASSIFICATION,//  LlapIoImpl.LOG.info("Setting enc " + i + "; " + colIx + " to " + allEnc.get(i)); 
Hive,WITHOUT_CLASSIFICATION,//  Track as you walk up the tree if there is an operator   along the way that changes the rows from the table through   joins or aggregations. Only allowed operators are selects   and filters. 
Hive,WITHOUT_CLASSIFICATION,//  before 1970 or after 2038. 
Hive,WITHOUT_CLASSIFICATION,//  Convert the join operator to a sort-merge join operator 
Hive,WITHOUT_CLASSIFICATION,//  Per the javadocs on Condition do not depend on the condition alone as a start gate   since spurious wake ups are possible. 
Hive,WITHOUT_CLASSIFICATION,//  Set the index table information 
Hive,WITHOUT_CLASSIFICATION,//  Conversion is needed? 
Hive,WITHOUT_CLASSIFICATION,//         createdTable.getParameters().get("numFiles")); 
Hive,WITHOUT_CLASSIFICATION,/*  Hash function should map the long value to 0...2^L-1.     * Hence hash value has to be non-negative.      */
Hive,WITHOUT_CLASSIFICATION,//  explicitly disable bit packing 
Hive,WITHOUT_CLASSIFICATION,//  No such database 
Hive,WITHOUT_CLASSIFICATION,//  Based on user-specified parameters check if the hash table needs to be 
Hive,WITHOUT_CLASSIFICATION,//  For a complex type a helper object that describes elements key/value pairs   or fields. 
Hive,WITHOUT_CLASSIFICATION,//  logs 
Hive,WITHOUT_CLASSIFICATION,//  We don't need to do the check for U[TNull] here because we'll give the real type   at deserialization and the object inspector will never see the actual union. 
Hive,WITHOUT_CLASSIFICATION,//  Ignore the tag passed in which should be 0 not what we want 
Hive,WITHOUT_CLASSIFICATION,//  pRS-pGBY-cRS-cGBY 
Hive,WITHOUT_CLASSIFICATION,// ---------------------------------------------------------------------------   Process Single-Column String Outer Join on a vectorized row batch.   
Hive,WITHOUT_CLASSIFICATION,//  Step 2.3: Fill up stuff in local work 
Hive,WITHOUT_CLASSIFICATION,//  Best-effort check; see the comment in the method. 
Hive,WITHOUT_CLASSIFICATION,/*        * Interrupt all threads and verify we get InterruptedException and expected       * Message. Also raise 2 kill operations and ensure that retries keep the time out       * occupied for 4 sec.        */
Hive,WITHOUT_CLASSIFICATION,//  ConditionalTask 
Hive,WITHOUT_CLASSIFICATION,//  Try with null VOID 
Hive,WITHOUT_CLASSIFICATION,//  This one uses the arcsin method. Involves more multiplications/divisions.   pi=Sum (3 * 2n!/(16^n * (2n+1) * n! * n!))   =Sum (3 * ((n+1)(n+2)...2n)/n!*16^n/(2n+1))   =Sum (3 / (2n+1) * (n+1)/16 * (n+2)/32... * 2n/16(n+1))   (note that it is split so that each term is not overflown) 
Hive,WITHOUT_CLASSIFICATION,//  mix of binary/non-binary args 
Hive,WITHOUT_CLASSIFICATION,//  it's resulted from RS-dedup optimization which removes following RS under some condition 
Hive,WITHOUT_CLASSIFICATION,// doing major compaction - it's possible where full compliment of bucket files is not  required (on Tez) that base_x/ doesn't have a file for 'bucket' 
Hive,WITHOUT_CLASSIFICATION,//  do generic lookup 
Hive,WITHOUT_CLASSIFICATION,//  class Factory; 
Hive,WITHOUT_CLASSIFICATION,//  For reasons I don't understand and am too lazy to debug at the moment the 
Hive,WITHOUT_CLASSIFICATION,//  No partitioned specified for partitioned table lets fetch all. 
Hive,WITHOUT_CLASSIFICATION,//  Remainder := Dividend 
Hive,WITHOUT_CLASSIFICATION,//  there is no need to continue processing TS[6] branch 
Hive,WITHOUT_CLASSIFICATION,//  functions 
Hive,WITHOUT_CLASSIFICATION,//  #1 - Read the column value 
Hive,WITHOUT_CLASSIFICATION,//  If we have split-update turned on for this table then the delta events have already been   split into two directories- delta_x_y/ and delete_delta_x_y/.   When you have split-update turned on the insert events go to delta_x_y/ directory and all   the delete events go to delete_x_y/. An update event will generate two events-   a delete event for the old record that is put into delete_delta_x_y/   followed by an insert event for the updated record put into the usual delta_x_y/.   Therefore everything inside delta_x_y/ is an insert event and all the files in delta_x_y/   can be treated like base files. Hence each of these are added to baseOrOriginalFiles list. 
Hive,WITHOUT_CLASSIFICATION,//  add same jar multiple times and check that dependencies are added only once. 
Hive,WITHOUT_CLASSIFICATION,//  REQUEST 
Hive,WITHOUT_CLASSIFICATION,//  PARTITIONS specified - partitions inside tableSpec 
Hive,WITHOUT_CLASSIFICATION,//  Generated earlier to get possible null(s). 
Hive,WITHOUT_CLASSIFICATION,//  testConvertBooleanToInt() sets HCatConstants.HCAT_DATA_CONVERT_BOOLEAN_TO_INTEGER=true and   might be the last one to call HCatContext.INSTANCE.setConf(). Make sure setting is false. 
Hive,WITHOUT_CLASSIFICATION,//     LOG.info("har file : " + harFile); 
Hive,WITHOUT_CLASSIFICATION,//  and fetch the sql operation log with FETCH_NEXT orientation 
Hive,WITHOUT_CLASSIFICATION,//  get the highValue 
Hive,WITHOUT_CLASSIFICATION,//  We should not get any rows. 
Hive,WITHOUT_CLASSIFICATION,//  scale down 
Hive,WITHOUT_CLASSIFICATION,//  And for Complex Types also leave the children types in place... 
Hive,WITHOUT_CLASSIFICATION,//  The subquery identifier from QB. 
Hive,WITHOUT_CLASSIFICATION,//  test URI with no dbName 
Hive,WITHOUT_CLASSIFICATION,//  Sleep for 5ms and cancel again 
Hive,WITHOUT_CLASSIFICATION,//  3. IO cost = cost of writing intermediary results to local FS +                cost of reading from local FS for transferring to GBy + 
Hive,WITHOUT_CLASSIFICATION,//  If source is local then source files won't be deleted and we have to delete them here 
Hive,WITHOUT_CLASSIFICATION,//  Go through the map and print out the stuff 
Hive,WITHOUT_CLASSIFICATION,//  Null first (default for ascending order) 
Hive,WITHOUT_CLASSIFICATION,//  Adapted from SQLStdHiveAuthorizationValidator only check privileges for LOAD/ADD/DFS/COMPILE and admin privileges 
Hive,WITHOUT_CLASSIFICATION,//  As we always use foreach action to submit RDD graph it would only trigger one job. 
Hive,WITHOUT_CLASSIFICATION,//  SOURCE_DB 
Hive,WITHOUT_CLASSIFICATION,// builder.join(JoinRelType.INNER builder.literal(true) variablesSet); 
Hive,WITHOUT_CLASSIFICATION,//  SER_DE 
Hive,WITHOUT_CLASSIFICATION,//  set union operator as child of each of leftOp and rightOp 
Hive,WITHOUT_CLASSIFICATION,//  internal fields 
Hive,WITHOUT_CLASSIFICATION,//  static partition without list bucketing 
Hive,WITHOUT_CLASSIFICATION,// cast it to long to get rid of periodic decimal 
Hive,WITHOUT_CLASSIFICATION,//  Remove from the list. 
Hive,WITHOUT_CLASSIFICATION,//  Unexpected metric type. 
Hive,WITHOUT_CLASSIFICATION,//  Get non null row count from root column to get max vector batches 
Hive,WITHOUT_CLASSIFICATION,//  comparisons do come from the correlatorRel. 
Hive,WITHOUT_CLASSIFICATION,//  From Tez. Eventually changes over to the LLAP protocol and ProtocolBuffers 
Hive,WITHOUT_CLASSIFICATION,// c6Value = (Map<??>) rowValues[5];  assertEquals(2 c6Value.size());  assertEquals("x" c6Value.get(Integer.valueOf(1)));  assertEquals("y" c6Value.get(Integer.valueOf(2))); 
Hive,WITHOUT_CLASSIFICATION,//  test is executed 3 times in worst case 1 original + 2 retries 
Hive,WITHOUT_CLASSIFICATION,//  3rd char starts at index 3 and with length 2 it is covering the rest of the array. 
Hive,WITHOUT_CLASSIFICATION,//  If HIVE_HOME is not defined or file is not found in HIVE_HOME/conf then load default ivysettings.xml from class loader 
Hive,WITHOUT_CLASSIFICATION,//  there should be 5 calls to create partitions with batch sizes of 17 15 7 3 1 
Hive,WITHOUT_CLASSIFICATION,//  check whether log file is created on test running 
Hive,WITHOUT_CLASSIFICATION,//  Handle skewed value.   if it is skewed value   add directory to path unless value is false 
Hive,WITHOUT_CLASSIFICATION,//  Number of headers (smallest blocks) per target block.   Next free list from which we will be splitting. 
Hive,WITHOUT_CLASSIFICATION,//  Create a default database inside the catalog 
Hive,WITHOUT_CLASSIFICATION,//  Second Row 
Hive,WITHOUT_CLASSIFICATION,/* perfLogger.PerfLogBegin(this.getClass().getName() PerfLogger.OPTIMIZER);      basePlan = hepPlan(basePlan true mdProvider executorProvider SemiJoinJoinTransposeRule.INSTANCE          SemiJoinFilterTransposeRule.INSTANCE SemiJoinProjectTransposeRule.INSTANCE);      perfLogger.PerfLogEnd(this.getClass().getName() PerfLogger.OPTIMIZER        "Calcite: Prejoin ordering transformation Push Down Semi Joins");  */
Hive,WITHOUT_CLASSIFICATION,//  Add a filter to just do a scan on the keys so that we pick up everything 
Hive,WITHOUT_CLASSIFICATION,//  Other counter sources (currently used in LLAP IO). 
Hive,WITHOUT_CLASSIFICATION,//  Now we know where to put row 
Hive,WITHOUT_CLASSIFICATION,//  Mapping from constraint name to list of unique constraints 
Hive,WITHOUT_CLASSIFICATION,//  for managed tables make sure the file formats match 
Hive,WITHOUT_CLASSIFICATION,//  If semijoin is attempted then replace the condition with a min-max filter   and bloom filter else 
Hive,WITHOUT_CLASSIFICATION,//  Break if polling times out 
Hive,WITHOUT_CLASSIFICATION,//  Create a GSSContext for authentication with the service. 
Hive,WITHOUT_CLASSIFICATION,//  Notify to clear pending events if any. 
Hive,WITHOUT_CLASSIFICATION,//  Not a part. 
Hive,WITHOUT_CLASSIFICATION,// assumes line would never be null when this method is called 
Hive,WITHOUT_CLASSIFICATION,/*    * DECIMAL.    */
Hive,WITHOUT_CLASSIFICATION,//  No output type information. 
Hive,WITHOUT_CLASSIFICATION,// 1)  test dropping fields - first middle  & last 
Hive,WITHOUT_CLASSIFICATION,//  Fail - "transactional" property is set to an invalid value 
Hive,WITHOUT_CLASSIFICATION,//  Input metrics. 
Hive,WITHOUT_CLASSIFICATION,//  create the table 
Hive,WITHOUT_CLASSIFICATION,//  called by late-MapJoin processor (hive.auto.convert.join=true for example) 
Hive,WITHOUT_CLASSIFICATION,//     bail out. 
Hive,WITHOUT_CLASSIFICATION,//  FilterCorrelateRule rule mistakenly pushes a FILTER consiting of correlated vars   on top of LogicalCorrelate to within  left input for scalar corr queries   which causes exception during decorrelation. This has been disabled for now.  .addRuleInstance(FilterCorrelateRule.INSTANCE) 
Hive,WITHOUT_CLASSIFICATION,//  Our aggregation buffer has nothing in it so just copy over 'other'   by deserializing the ArrayList of (xy) pairs into an array of Coord objects 
Hive,WITHOUT_CLASSIFICATION,//  do nothing if this property is not specified or empty 
Hive,WITHOUT_CLASSIFICATION,// process each level in parallel 
Hive,WITHOUT_CLASSIFICATION,/*  Determine if there is a match between big table row and the corresponding hashtable     * Three states can be returned:     * MATCH: a match is found     * NOMATCH: no match is found from the specified partition     * SPILL: the specified partition has been spilled to disk and is not available;     *        the evaluation for this big table row will be postponed.      */
Hive,WITHOUT_CLASSIFICATION,//  do nothing for null object 
Hive,WITHOUT_CLASSIFICATION,//  9. Optimize Physical op tree & Translate to target execution engine (MR 
Hive,WITHOUT_CLASSIFICATION,//  Not sequential. 
Hive,WITHOUT_CLASSIFICATION,//  Position at first row. 
Hive,WITHOUT_CLASSIFICATION,// read friendly string: [ETX][STX]ak[EXT]av[STX]bk[ETX]bv[STX]ck[ETX]cv[STX]dk[ETX]dv 
Hive,WITHOUT_CLASSIFICATION,//  A mapping from an operator to the columns by which it's output is sorted 
Hive,WITHOUT_CLASSIFICATION,//  implementing applyRowFilterAndColumnMasking 
Hive,WITHOUT_CLASSIFICATION,//  FUTURE: Decide how to ask an input file format what vectorization features it supports. 
Hive,WITHOUT_CLASSIFICATION,//  It will be a BloomFilter in ByteWritable 
Hive,WITHOUT_CLASSIFICATION,//  run given query and validate expected result 
Hive,WITHOUT_CLASSIFICATION,//  For bytes type it can be mapped to decimal. 
Hive,WITHOUT_CLASSIFICATION,/*          * The transactional listener response will be set already on the event so there is not need         * to pass the response to the non-transactional listener.          */
Hive,WITHOUT_CLASSIFICATION,//  keys[i] -> ArrayList<exprNodeDesc> for the i-th join operator key list 
Hive,WITHOUT_CLASSIFICATION,/*    * default behavior when neither hive.job.credstore location is set nor   * HIVE_JOB_CREDSTORE_PASSWORD is. In this case if hadoop credential provider is configured job   * config should use that else it should remain unset    */
Hive,WITHOUT_CLASSIFICATION,//  Now compact -> Compaction produces a single range for both delta and delete delta   That is both delta and delete_deltas would be compacted into delta_3_5 and delete_delta_3_5 
Hive,WITHOUT_CLASSIFICATION,//  TEST - reset 
Hive,WITHOUT_CLASSIFICATION,//  Noone could have moved it we have the heap lock. 
Hive,WITHOUT_CLASSIFICATION,//  Populate the complete query with provided prefix and suffix 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setCharacterStream(java.lang.String   * java.io.Reader long)    */
Hive,WITHOUT_CLASSIFICATION,//  skip escape 
Hive,WITHOUT_CLASSIFICATION,//  No more places to get the schema from. Give up.  May have to re-encode later. 
Hive,WITHOUT_CLASSIFICATION,/*    * 1. Join condition must be an Equality Predicate.   * 2. both sides must reference 1 column.   * 3. If needed flip the columns.    */
Hive,WITHOUT_CLASSIFICATION,//  These are the output columns for the small table and the outer small table keys. 
Hive,WITHOUT_CLASSIFICATION,//  Shortcut for HDFS. 
Hive,WITHOUT_CLASSIFICATION,//  now we remove all the unions. we throw away any branch that's not reachable from   the current set of roots. The reason is that those branches will be handled in 
Hive,WITHOUT_CLASSIFICATION,//  9. Resolve all the kill query requests in flight. Nothing below can affect them. 
Hive,WITHOUT_CLASSIFICATION,//  tablescan with same alias. 
Hive,WITHOUT_CLASSIFICATION,/*  PaB0  */
Hive,WITHOUT_CLASSIFICATION,//  See if we can use re-encoding to read the format thru IO elevator. 
Hive,WITHOUT_CLASSIFICATION,//  Pass along hashcode to avoid recalculation 
Hive,WITHOUT_CLASSIFICATION,//  base  = JAVA32_OBJECT + PRIMITIVES1 * 2 + JAVA32_FIELDREF;   entry = JAVA32_OBJECT + JAVA32_FIELDREF * 2 
Hive,WITHOUT_CLASSIFICATION,//  Mock out the predicate handler because it's just easier 
Hive,WITHOUT_CLASSIFICATION,//  count(1) 1's position is input.getRowType().getFieldList().size() 
Hive,WITHOUT_CLASSIFICATION,//  retrieve the tables from the metastore in batches to alleviate memory constraints 
Hive,WITHOUT_CLASSIFICATION,//  Remember the condition variables for EXPLAIN regardless. 
Hive,WITHOUT_CLASSIFICATION,//  At this point we've verified the types are correct. 
Hive,WITHOUT_CLASSIFICATION,//  Start small table random generation   from beginning. 
Hive,WITHOUT_CLASSIFICATION,//  create 13 dummy partitions 
Hive,WITHOUT_CLASSIFICATION,//  add empty stats object for each column 
Hive,WITHOUT_CLASSIFICATION,//  use remove instead of get so that it is not parsed again 
Hive,WITHOUT_CLASSIFICATION,//    testLazyBinaryFast(         source rows         serde rowStructObjectInspector         serde_fewer writeRowStructObjectInspector         primitiveTypeInfos         /* useIncludeColumns */ false /* doWriteFewerColumns */ true r); 
Hive,WITHOUT_CLASSIFICATION,//  NOP as there's no caching 
Hive,WITHOUT_CLASSIFICATION,//  Configuration 
Hive,WITHOUT_CLASSIFICATION,//  4) We change the Join operator to reflect this info 
Hive,WITHOUT_CLASSIFICATION,//  Local dirs   ConfVars.LOCALSCRATCHDIR - {test.tmp.dir}/localscratchdir 
Hive,WITHOUT_CLASSIFICATION,//  this will only be available when we are doing table load only in replication not otherwise 
Hive,WITHOUT_CLASSIFICATION,/*  * An multi-key hash map based on the BytesBytesMultiHashSet.  */
Hive,WITHOUT_CLASSIFICATION,//  If it contains a LV 
Hive,WITHOUT_CLASSIFICATION,//  We should never get here. 
Hive,WITHOUT_CLASSIFICATION,//  for future use 
Hive,WITHOUT_CLASSIFICATION,//  Insert transaction entries into MIN_HISTORY_LEVEL. 
Hive,WITHOUT_CLASSIFICATION,//  Find the partition we will be working with if there is one. 
Hive,WITHOUT_CLASSIFICATION,/*  stage is started but not complete  */
Hive,WITHOUT_CLASSIFICATION,//  if the table scan is for big table; then skip it 
Hive,WITHOUT_CLASSIFICATION,//  Print all results for standalone SELECT statement 
Hive,WITHOUT_CLASSIFICATION,//  Just digits. 
Hive,WITHOUT_CLASSIFICATION,//  the number of columns output by the UDTF 
Hive,WITHOUT_CLASSIFICATION,//  Updates the references that are present in every operand up till now 
Hive,WITHOUT_CLASSIFICATION,// Oozie does not change the service field of the token  hence by default token generation will have a value of "new Text("")"  HiveClient will look for a use TokenSelector.selectToken() with service 
Hive,WITHOUT_CLASSIFICATION,//  Make sure we're locking the whole table since this is dynamic partitioning 
Hive,WITHOUT_CLASSIFICATION,//  Must set isNull[i] to false to make sure   it gets initialized in case we set noNulls to true. 
Hive,WITHOUT_CLASSIFICATION,// After catching an OOM java says it is undefined behavior so don't  even try to clean up or we can get stuck on shutdown. 
Hive,WITHOUT_CLASSIFICATION,/*      * Create table related objects      */
Hive,WITHOUT_CLASSIFICATION,//  Max characters when auto generating the column name with func name 
Hive,WITHOUT_CLASSIFICATION,//  DBNAME 
Hive,WITHOUT_CLASSIFICATION,//  6) Now we set some tree properties related to multi-insert 
Hive,WITHOUT_CLASSIFICATION,//  v[5] -- since integer #5 is always 0 some products here are not included. 
Hive,WITHOUT_CLASSIFICATION,//  Assert.assertEquals(21 resultDec.integerDigitCount()); 
Hive,WITHOUT_CLASSIFICATION,//  requires to calculate stats if new and old have different fast stats 
Hive,WITHOUT_CLASSIFICATION,/*      * Create a new vectorization context to create a new projection but keep     * same output column manager must be inherited to track the scratch the columns.      */
Hive,WITHOUT_CLASSIFICATION,//  call further down we rely upon op.abort(). 
Hive,WITHOUT_CLASSIFICATION,//  Value 
Hive,WITHOUT_CLASSIFICATION,/*    * Given a Work descriptor and the TaskName for the work   * this is responsible to check each MapJoinOp for cross products.   * The analyze call returns the warnings list.   * <p>   * For MR the taskname is the StageName for Tez it is the vertex name.    */
Hive,WITHOUT_CLASSIFICATION,//  store this in the udf context so we can get it later 
Hive,WITHOUT_CLASSIFICATION,//  Make sure all of the partitions have the catalog set as well 
Hive,WITHOUT_CLASSIFICATION,//  return if output is null because no additional work is needed 
Hive,WITHOUT_CLASSIFICATION,//  complex types (map list struct union) 
Hive,WITHOUT_CLASSIFICATION,//  make an expression for default value 
Hive,WITHOUT_CLASSIFICATION,/*  * This is a copy of GenericUDFNvl which is built-in. We'll make it a generic * custom UDF for test purposes.  */
Hive,WITHOUT_CLASSIFICATION,//  assertEquals(expectedPartition.getSd().getLocation()       actualPartition.getSd().getLocation());   we don't compare locations because the location can still be empty in   the pre-event listener before it is created. 
Hive,WITHOUT_CLASSIFICATION,//  add_partition 
Hive,WITHOUT_CLASSIFICATION,//  clone configuration before modifying it on per-task basis 
Hive,WITHOUT_CLASSIFICATION,//  isolated from the other transaction related RPC calls. 
Hive,WITHOUT_CLASSIFICATION,//  Run worker to delete aborted transaction's delta directory. 
Hive,WITHOUT_CLASSIFICATION,//  ACQUIREDAT 
Hive,WITHOUT_CLASSIFICATION,//  c.set doesn't reset millis 
Hive,WITHOUT_CLASSIFICATION,//  output is sorted 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getTimestamp(java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,// we expect correlated variables in HiveFilter only for now.   Also check for case where operator has 0 inputs .e.g TableScan 
Hive,WITHOUT_CLASSIFICATION,//  This table has no keys. 
Hive,WITHOUT_CLASSIFICATION,//  Try to read from the cache first 
Hive,WITHOUT_CLASSIFICATION,//  Support for schema evolution 
Hive,WITHOUT_CLASSIFICATION,/*  Constructing the row ObjectInspector:     * The row consists of some set of primitive columns each column will     * be a java object of primitive type.      */
Hive,WITHOUT_CLASSIFICATION,//  2 CHAR test 
Hive,WITHOUT_CLASSIFICATION,//  Generate GroupbyOperator 
Hive,WITHOUT_CLASSIFICATION,//  It is possible that all the async methods returned on the same thread because the   session with registry data and stuff was available in the pool.   If this happens we'll take the session out here and "cancel" the init so we skip 
Hive,WITHOUT_CLASSIFICATION,//  this offer will be accepted and r1 evicted 
Hive,WITHOUT_CLASSIFICATION,//  this test method is here to do an initial call to parsedriver; and prevent any tests with timeouts to be the first. 
Hive,WITHOUT_CLASSIFICATION,//  Insert into appends to old version 
Hive,WITHOUT_CLASSIFICATION,//  Druid query 
Hive,WITHOUT_CLASSIFICATION,//  Substitution option --hivevar 
Hive,WITHOUT_CLASSIFICATION,//  1. Separate required columns to Non Partition and Partition Cols 
Hive,WITHOUT_CLASSIFICATION,//  Update cross size 
Hive,WITHOUT_CLASSIFICATION,//  Send out the actual SubmitWorkRequest 
Hive,WITHOUT_CLASSIFICATION,//  The sort order contains whether the sorting is happening ascending or descending 
Hive,WITHOUT_CLASSIFICATION,//  Evaluate ELSE expression (only) and copy all its results. 
Hive,WITHOUT_CLASSIFICATION,//  Filter may have sensitive information. Do not send to debug. 
Hive,WITHOUT_CLASSIFICATION,//  Now compact   One important thing to note in this test is that minor compaction always produces   delta_x_y and a counterpart delete_delta_x_y even when there are no delete_delta events.   Such a choice has been made to simplify processing of AcidUtils.getAcidState(). 
Hive,WITHOUT_CLASSIFICATION,//  Physical files are resides in local file system in the similar location 
Hive,WITHOUT_CLASSIFICATION,//  7. It may happen that we know we won't use some cache buffers anymore (the alternative      is that we will use the same buffers for other streams in separate calls). 
Hive,WITHOUT_CLASSIFICATION,//  the key is not found in MapColumnVector set the output as null ColumnVector 
Hive,WITHOUT_CLASSIFICATION,//  TXN_IDS 
Hive,WITHOUT_CLASSIFICATION,//  It was deleted during the transaction 
Hive,WITHOUT_CLASSIFICATION,//  No key or no nodes in candidate list 
Hive,WITHOUT_CLASSIFICATION,//  The extra parameters will be added on server side so check that the required ones are   present 
Hive,WITHOUT_CLASSIFICATION,//  Remove semijoin Op if there is any.   The semijoin branch can potentially create a task level cycle   with the hashjoin except when it is dynamically partitioned hash 
Hive,WITHOUT_CLASSIFICATION,//  Search mapping for any strings and return their output columns. 
Hive,WITHOUT_CLASSIFICATION,//  newData.isSetBitVectors() should be true for sure because we   already checked it before. 
Hive,WITHOUT_CLASSIFICATION,//  Put now available buffered batch at end. 
Hive,WITHOUT_CLASSIFICATION,//  Expressions are not supported currently without a alias. 
Hive,WITHOUT_CLASSIFICATION,//  default -> utc   utc 
Hive,WITHOUT_CLASSIFICATION,//  Get any new notification events that have been since the last time we checked   And pass them on to the event handlers. 
Hive,WITHOUT_CLASSIFICATION,//  Iterate over each clause 
Hive,WITHOUT_CLASSIFICATION,//  Check non null 
Hive,WITHOUT_CLASSIFICATION,//  4. return subquery 
Hive,WITHOUT_CLASSIFICATION,//  Class to store necessary information for an attempt to log 
Hive,WITHOUT_CLASSIFICATION,//  remember map joins as we encounter them. 
Hive,WITHOUT_CLASSIFICATION,//  Verify that the table is created successfully. 
Hive,WITHOUT_CLASSIFICATION,//  Set lambda to 1 so the heap size becomes 1 (LRU). 
Hive,WITHOUT_CLASSIFICATION,/*    * All of the fastSetFrom* methods require the caller to pass a fastResult parameter has been   * reset for better performance.    */
Hive,WITHOUT_CLASSIFICATION,//  sequence number is used to name vertices (e.g.: Map 1 Reduce 14 ...) 
Hive,WITHOUT_CLASSIFICATION,//  Overlay hive-site.xml if it exists 
Hive,WITHOUT_CLASSIFICATION,//  Create Remote MetaStore 
Hive,WITHOUT_CLASSIFICATION,//  We may add NO_AND_STOP in future where combine is impossible and other should not be base. 
Hive,WITHOUT_CLASSIFICATION,/*  * Specialized class for native vectorized reduce sink that is reducing on Uniform Hash * multiple key columns (or a single non-long / non-string column).  */
Hive,WITHOUT_CLASSIFICATION,//     relationship. 
Hive,WITHOUT_CLASSIFICATION,//  nulls in the join keys. 
Hive,WITHOUT_CLASSIFICATION,//  add cStatsTask as a dependent of all the nonStatsLeafTasks 
Hive,WITHOUT_CLASSIFICATION,// now 2  this should block until t1 unlocks 
Hive,WITHOUT_CLASSIFICATION,//  put the mapping task to aliases 
Hive,WITHOUT_CLASSIFICATION,//  This is only called for replication that handles MM tables; no need for mmCtx. 
Hive,WITHOUT_CLASSIFICATION,//  Case 2: is repeating has nulls 
Hive,WITHOUT_CLASSIFICATION,//  check file system permission 
Hive,WITHOUT_CLASSIFICATION,//  create a snapshot 
Hive,WITHOUT_CLASSIFICATION,//  should we convert? 
Hive,WITHOUT_CLASSIFICATION,//  Add all the public member classes that implement an evaluator 
Hive,WITHOUT_CLASSIFICATION,//  We need to filter i) those that have been pushed already as stored in the join   and ii) those that were already in the subtree rooted at child 
Hive,WITHOUT_CLASSIFICATION,//  RENEWER 
Hive,WITHOUT_CLASSIFICATION,//  1 running 1 queued. 
Hive,WITHOUT_CLASSIFICATION,//  Important - no sorting here! We retain order it's used to match with values at runtime 
Hive,WITHOUT_CLASSIFICATION,//  fetch across schemas 
Hive,WITHOUT_CLASSIFICATION,//  ensure filters are not set from previous pushFilters 
Hive,WITHOUT_CLASSIFICATION,//  The message from remote exception includes the entire stack.  The error thrown from   hive based on the remote exception needs only the first line. 
Hive,WITHOUT_CLASSIFICATION,//  cluster than the default one but at least for the default case we'd have it covered. 
Hive,WITHOUT_CLASSIFICATION,//  Mapping from column name to Check expr 
Hive,WITHOUT_CLASSIFICATION,//  Our original foo should be in the wrapper 
Hive,WITHOUT_CLASSIFICATION,//  testcase.testWithColumnNumber(count 25 checkCorrect codec); 
Hive,WITHOUT_CLASSIFICATION,//  Reset for filling. 
Hive,WITHOUT_CLASSIFICATION,//  HiveServer2 configs that this instance will publish to ZooKeeper   so that the clients can read these and configure themselves properly. 
Hive,WITHOUT_CLASSIFICATION,//  basic test 
Hive,WITHOUT_CLASSIFICATION,//  for each partition spec get the partition 
Hive,WITHOUT_CLASSIFICATION,//  Next we locate the aggregation buffer set for each key 
Hive,WITHOUT_CLASSIFICATION,// txn started implicitly by previous statement 
Hive,WITHOUT_CLASSIFICATION,// process user groups for which doAs is authorized 
Hive,WITHOUT_CLASSIFICATION,//  The task will either be killed or is already in the process of completing which will   trigger the next scheduling run or result in available slots being higher than 0 
Hive,WITHOUT_CLASSIFICATION,//  normalize label row 
Hive,WITHOUT_CLASSIFICATION,//  VIEW_ORIGINAL_TEXT 
Hive,WITHOUT_CLASSIFICATION,//  Add LIMIT as Order by-s without limit can disabled for safety reasons 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getTimestamp(java.lang.String   * java.util.Calendar)    */
Hive,WITHOUT_CLASSIFICATION,//  Install the JAAS Configuration for the runtime 
Hive,WITHOUT_CLASSIFICATION,//  Create and set MD provider 
Hive,WITHOUT_CLASSIFICATION,//  1st close: 
Hive,WITHOUT_CLASSIFICATION,//  A node became available. Enable the node and try scheduling. 
Hive,WITHOUT_CLASSIFICATION,//  Get all target paths first because the number of total target paths   is used to determine number of splits of each target path. 
Hive,WITHOUT_CLASSIFICATION,//  2 VInt 
Hive,WITHOUT_CLASSIFICATION,//  Handle the special cases here. Perhaps we could have a more general structure or even   a configurable set (like storage handlers) but for now we only have one. 
Hive,WITHOUT_CLASSIFICATION,//  Attempt to make the path in case it does not exist before we check 
Hive,WITHOUT_CLASSIFICATION,//  The values from Timestamp.getNanos(). 
Hive,WITHOUT_CLASSIFICATION,//  function correctly. 
Hive,WITHOUT_CLASSIFICATION,//  outerjoin-pos = other-pos:filter-len other-pos:filter-len ... 
Hive,WITHOUT_CLASSIFICATION,//  hive depends on FileSplits so wrap in HBaseSplit 
Hive,WITHOUT_CLASSIFICATION,//  for AND condition cascadingly update stats 
Hive,WITHOUT_CLASSIFICATION,//  Walk over all the sources (which are guaranteed to be reduce sink   operators).   The join outputs a concatenation of all the inputs. 
Hive,WITHOUT_CLASSIFICATION,//  unknown | T | unknown 
Hive,WITHOUT_CLASSIFICATION,//  If cookie based authentication is allowed generate ticket only when necessary.   The necessary condition is either when there are no server side cookies in the   cookiestore which can be send back or when the server returns a 401 error code 
Hive,WITHOUT_CLASSIFICATION,//  Do not delete for MM tables. We either want the file if we succeed or we must   delete is explicitly before proceeding if the merge fails. 
Hive,WITHOUT_CLASSIFICATION,/*  unpartitioned table + no filters  */
Hive,WITHOUT_CLASSIFICATION,//  Create the delta directory.  Don't worry if it already exists   as that likely means another task got to it first.  Then move each of the buckets.   it would be more efficient to try to move the delta with it's buckets but that is   harder to make race condition proof. 
Hive,WITHOUT_CLASSIFICATION,//  adding this as a child to the Union later 
Hive,WITHOUT_CLASSIFICATION,//  the schema after GB is like this   all keys + sum(c) as a + sum(VCol*c) as b   the column size is the same as unionColumnSize;   (1) for except distinct add a filter (b-a>0 && 2a-b=0)   i.e. a > 0 && 2a = b   then add the project   (2) for except all add a project to change it to   (2b-3a) + all keys   then add the UDTF 
Hive,WITHOUT_CLASSIFICATION,//  use the session or the one supplied in constructor 
Hive,WITHOUT_CLASSIFICATION,//  perform the data read asynchronously 
Hive,WITHOUT_CLASSIFICATION,//  The default unless SerDe overrides it. 
Hive,WITHOUT_CLASSIFICATION,//  Connect after the lifetime there should not be any failures 
Hive,WITHOUT_CLASSIFICATION,//  Actual Batch size that will be used 
Hive,WITHOUT_CLASSIFICATION,// close one connection verify still one left 
Hive,WITHOUT_CLASSIFICATION,//  store into configuration 
Hive,WITHOUT_CLASSIFICATION,//  Change the selected vector 
Hive,WITHOUT_CLASSIFICATION,// no records will be emitted from Hive 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise expect the user is already logged in 
Hive,WITHOUT_CLASSIFICATION,//  If there are any open txns then the minimum of min_open_txnid from MIN_HISTORY_LEVEL table 
Hive,WITHOUT_CLASSIFICATION,//  send task off to another jvm 
Hive,WITHOUT_CLASSIFICATION,// Generate test jar files 
Hive,WITHOUT_CLASSIFICATION,// input job properties 
Hive,WITHOUT_CLASSIFICATION,//  and remember link between event and table scan 
Hive,WITHOUT_CLASSIFICATION,//  we checked if partitions matching specification are marked as archived   in the metadata; if they are and their levels are the same as we would   set it later it means previous run failed and we have to do the recovery; 
Hive,WITHOUT_CLASSIFICATION,//  2. Validate that SetOp is feasible according to Hive (by using type 
Hive,WITHOUT_CLASSIFICATION,//  check same filter exists already 
Hive,WITHOUT_CLASSIFICATION,//  stats publishing/aggregating key prefix 
Hive,WITHOUT_CLASSIFICATION,//  No need to set type name it should always be decimal 
Hive,WITHOUT_CLASSIFICATION,//  The basic idea for CBO support of UDTF is to treat UDTF as a special   project.   In AST return path as we just need to generate a SEL_EXPR we just   need to remember the expressions and the alias.   In OP return path we need to generate a SEL and then a UDTF   following old semantic analyzer. 
Hive,WITHOUT_CLASSIFICATION,//       }        doHarCheck(fsharFile); 
Hive,WITHOUT_CLASSIFICATION,//  The implementation balks when this method is invoked multiple times 
Hive,WITHOUT_CLASSIFICATION,//  TASK_STATUS 
Hive,WITHOUT_CLASSIFICATION,//  Function to create subCache 
Hive,WITHOUT_CLASSIFICATION,//  Once the conversion is done we can set the partitioner to bucket cols on the small table 
Hive,WITHOUT_CLASSIFICATION,//  We can just use setKeyProvider() as it is 
Hive,WITHOUT_CLASSIFICATION,//  index==0 means this is key 
Hive,WITHOUT_CLASSIFICATION,//  Transaction manager the Driver has been initialized with (can be null).   If this is set then this Transaction manager will be used during query   compilation/execution rather than using the current session's transaction manager.   This might be needed in a situation where a Driver is nested within an already   running Driver/query - the nested Driver requires a separate transaction manager   so as not to conflict with the outer Driver/query which is using the session 
Hive,WITHOUT_CLASSIFICATION,//  cancel other tasks 
Hive,WITHOUT_CLASSIFICATION,//  Reserve space for potential future list 
Hive,WITHOUT_CLASSIFICATION,//  SCHEDULING_POLICY 
Hive,WITHOUT_CLASSIFICATION,//  Choose max 
Hive,WITHOUT_CLASSIFICATION,//  This better be a generic struct with constant values as the children. 
Hive,WITHOUT_CLASSIFICATION,//  Vectorized doesn't adjust usage for the keys while processing the batch 
Hive,WITHOUT_CLASSIFICATION,//  required for MDC based routing appender so that child threads can inherit the MDC context 
Hive,WITHOUT_CLASSIFICATION,//  It is an outer join. We are going to add the inspector from the   inner side but the key value will come from the outer side so   we need to create a converter from inputOI to outputOI. 
Hive,WITHOUT_CLASSIFICATION,//  just to be safe about numRows 
Hive,WITHOUT_CLASSIFICATION,//  Hive has no concept of Avro's fixed type.  Fixed -> arrays of bytes 
Hive,WITHOUT_CLASSIFICATION,//  worst-case hash aggregation disabled 
Hive,WITHOUT_CLASSIFICATION,//  because inverse[3] is 
Hive,WITHOUT_CLASSIFICATION,//  partitions 
Hive,WITHOUT_CLASSIFICATION,// { "comment":"Hello there" "location":"file:///tmp/warehouse" "properties":{"a":"b"}} 
Hive,WITHOUT_CLASSIFICATION,// should only have one aggregate 
Hive,WITHOUT_CLASSIFICATION,//  If ACID/MM tables then need to find the valid state wrt to given ValidWriteIdList. 
Hive,WITHOUT_CLASSIFICATION,//  Default to 100000 partitions if hive.metastore.maxpartition is not defined 
Hive,WITHOUT_CLASSIFICATION,//  Include specified but this module is not in the set. 
Hive,WITHOUT_CLASSIFICATION,//  The operator is not of RexCall type   So we fail. Fall through.   Add this condition to the list of non-equi-join conditions. 
Hive,WITHOUT_CLASSIFICATION,//  we use the source ordering flavor for the mapping. 
Hive,WITHOUT_CLASSIFICATION,//  insert current common join task to conditional task 
Hive,WITHOUT_CLASSIFICATION,// equals 
Hive,WITHOUT_CLASSIFICATION,// returns 0 if value is NULL 
Hive,WITHOUT_CLASSIFICATION,//  2. Try factoring out common filter elements & separating deterministic   vs non-deterministic UDF. This needs to run before PPD so that PPD can   add on-clauses for old style Join Syntax   Ex: select * from R1 join R2 where ((R1.x=R2.x) and R1.y<10) or 
Hive,WITHOUT_CLASSIFICATION,//  Test that existing shared_read partition with new exclusive coalesces to 
Hive,WITHOUT_CLASSIFICATION,// COMPACTOR_HISTORY_RETENTION_FAILED failed compacts left (and no other since we only have failed ones here) 
Hive,WITHOUT_CLASSIFICATION,//  Output the exit code 
Hive,WITHOUT_CLASSIFICATION,//  Create a transactional table 
Hive,WITHOUT_CLASSIFICATION,//  Try to allocate memory if we haven't allocated all the way to maxSize yet; very rare. 
Hive,WITHOUT_CLASSIFICATION,//  Multi-byte characters with blank ranges. 
Hive,WITHOUT_CLASSIFICATION,// only expect transactional components to be in COMPLETED_TXN_COMPONENTS 
Hive,WITHOUT_CLASSIFICATION,//  BLOCKED_BY_EXT_ID 
Hive,WITHOUT_CLASSIFICATION,//  Set the memory treshold so that we get 100Kb before we need to flush. 
Hive,WITHOUT_CLASSIFICATION,//  name/method name is constant Java String or constant Text (StringWritable). 
Hive,WITHOUT_CLASSIFICATION,//  List of operation for which we log. 
Hive,WITHOUT_CLASSIFICATION,//  All precision has been lost -- result is 0. 
Hive,WITHOUT_CLASSIFICATION,//  embedded metastore mode 
Hive,WITHOUT_CLASSIFICATION,/*    * Use when calculating intermediate variance and count > 1.   *   * NOTE: count has been incremented; sum included value.    */
Hive,WITHOUT_CLASSIFICATION,// Get the file status up-front for all partitions. Beneficial in cases of blob storage systems 
Hive,WITHOUT_CLASSIFICATION,//  No need to add BucketMapJoinOptimizer twice 
Hive,WITHOUT_CLASSIFICATION,//  Now make sure it's an array of doubles or floats. We don't allow integer types here 
Hive,WITHOUT_CLASSIFICATION,//  Object to receive results of reading a decoded variable length int or long. 
Hive,WITHOUT_CLASSIFICATION,//  We are assuming the update-error AM is bad and just try to kill it. 
Hive,WITHOUT_CLASSIFICATION,//  creating stats table if not exists 
Hive,WITHOUT_CLASSIFICATION,//  generate the temporary file   it must be on the same file system as the current destination 
Hive,WITHOUT_CLASSIFICATION,//  unique id set for operation when run from HS2 base64 encoded value of   TExecuteStatementResp.TOperationHandle.THandleIdentifier.guid 
Hive,WITHOUT_CLASSIFICATION,//  Write the key out 
Hive,WITHOUT_CLASSIFICATION,//  Get 2 different dates 
Hive,WITHOUT_CLASSIFICATION,//  Return the desired VectorExpression if found. Otherwise return null to cause 
Hive,WITHOUT_CLASSIFICATION,//  Stay with multi-key. 
Hive,WITHOUT_CLASSIFICATION,//  3. Perform a major compaction. Nothing should change. Both deltas and base dirs should have the same name. 
Hive,WITHOUT_CLASSIFICATION,//  so we need to scale down (this.scale - right.scale - newScale) 
Hive,WITHOUT_CLASSIFICATION,//  verify - throws exception 
Hive,WITHOUT_CLASSIFICATION,/*      * OI of object constructed from output of Wdw Fns; before it is put     * in the Wdw Processing Partition. Set by Translator/Deserializer.      */
Hive,WITHOUT_CLASSIFICATION,/*    * @return A new hash map result implementation specific object.   *   * The object can be used to access the values when there is a match or   * access spill information when the partition with the key is currently spilled.    */
Hive,WITHOUT_CLASSIFICATION,//  Constructing the row ObjectInspector:   The row consists of some string columns each column will be a java 
Hive,WITHOUT_CLASSIFICATION,//  Get jobids from job status dir 
Hive,WITHOUT_CLASSIFICATION,//  Output header 
Hive,WITHOUT_CLASSIFICATION,//  SQL usage inside a larger transaction (e.g. droptable) may not be desirable because   some databases (e.g. Postgres) abort the entire transaction when any query fails so 
Hive,WITHOUT_CLASSIFICATION,//  Scalar subquery 
Hive,WITHOUT_CLASSIFICATION,//  We have already locked the table in DDLSemanticAnalyzer don't do it again here 
Hive,WITHOUT_CLASSIFICATION,//  the sub-query alias. 
Hive,WITHOUT_CLASSIFICATION,//  Bloom filter false positive probability 
Hive,WITHOUT_CLASSIFICATION,//  If the table exists and we found a valid create table event then need to drop the table first   and then create it. This case is possible if the event sequence is drop_table(t1) -> create_table(t1).   We need to drop here to handle the case where the previous incremental load created the table but 
Hive,WITHOUT_CLASSIFICATION,//  No grant option in revoke remove the whole role. 
Hive,WITHOUT_CLASSIFICATION,//  Operator specific logic goes here 
Hive,WITHOUT_CLASSIFICATION,//  TODO: change type to the one in the table schema 
Hive,WITHOUT_CLASSIFICATION,//  Create new join 
Hive,WITHOUT_CLASSIFICATION,//  operation with INSERT/UPDATE 
Hive,WITHOUT_CLASSIFICATION,//  no-op - SBA does not attempt to authorize auth api call. Allow it 
Hive,WITHOUT_CLASSIFICATION,//  do the same thing as setChildren when there is nothing to read.   the setChildren method initializes the object inspector needed by the operators   based on path and partition information which we don't have in this case. 
Hive,WITHOUT_CLASSIFICATION,//  We are making what we are trying to do more explicit if there's a union alias; so 
Hive,WITHOUT_CLASSIFICATION,// cancel other futures 
Hive,WITHOUT_CLASSIFICATION,//  Cannot call class TestCliDriver since that's the name of the generated   code for the script-based testing 
Hive,WITHOUT_CLASSIFICATION,//  sync   total record length   key portion length 
Hive,WITHOUT_CLASSIFICATION,//  hard to know exactly for decimals 
Hive,WITHOUT_CLASSIFICATION,//  Allow string to double conversion 
Hive,WITHOUT_CLASSIFICATION,//  Check for rounding. 
Hive,WITHOUT_CLASSIFICATION,//  We don't need to lookup order_column_id_by_name because we know it   must be "i". 
Hive,WITHOUT_CLASSIFICATION,//  this will be used in RexNodeConverter to create cor var 
Hive,WITHOUT_CLASSIFICATION,//  Check our config value first.  I'm explicitly avoiding getting the default value for now   as I don't want our default to override a Hive set value. 
Hive,WITHOUT_CLASSIFICATION,//  Append the deserialized standard object row using the current batch size 
Hive,WITHOUT_CLASSIFICATION,//  Ideally these properties should be part of LlapDameonConf rather than HiveConf 
Hive,WITHOUT_CLASSIFICATION,//  3. Create new TS schema that is a subset of original 
Hive,WITHOUT_CLASSIFICATION,//  Type-specific handling done here 
Hive,WITHOUT_CLASSIFICATION,//  for example original it is max 0 dist 1 min 2   rs1's schema is key 0 max 1 min 2 
Hive,WITHOUT_CLASSIFICATION,//  Tracks various maps for dagCompletions. This is setup here since stateChange messages 
Hive,WITHOUT_CLASSIFICATION,//  bugbug somewhat fragile below substring expression 
Hive,WITHOUT_CLASSIFICATION,//  If the dbType is "hive" this is setting up the information schema in Hive.    We will set the default jdbc url and driver.   It is overriden by command line options if passed (-url and -driver 
Hive,WITHOUT_CLASSIFICATION,//  Unlikely but log the actual values in case one of the two was empty/null 
Hive,WITHOUT_CLASSIFICATION,//  If the buffer was pointing to smallBuffer then nextFree keeps track of the current state   of the free index for smallBuffer. We now need to save this value to smallBufferNextFree 
Hive,WITHOUT_CLASSIFICATION,//  insert SparkHashTableSink and Dummy operators 
Hive,WITHOUT_CLASSIFICATION,//  Create identity projection 
Hive,WITHOUT_CLASSIFICATION,//  push first record of group 
Hive,WITHOUT_CLASSIFICATION,//  called explicitly through FileRecordWriterContainer.close() if dynamic - return false by default 
Hive,WITHOUT_CLASSIFICATION,// this simulates the completion of txnid:idTxnUpdate3 
Hive,WITHOUT_CLASSIFICATION,/*    * @param baseDir if not null it's either table/partition root folder or base_xxxx.   *                If it's base_xxxx it's in dirsToSearch else the actual original files   *                (all leaves recursively) are in the dirsToSearch list    */
Hive,WITHOUT_CLASSIFICATION,//  if UDAF present and if column expression map is empty then it must   be full aggregation query like count(*) in which case number of 
Hive,WITHOUT_CLASSIFICATION,//  detecting failed executions by exceptions thrown by the operator tree 
Hive,WITHOUT_CLASSIFICATION,//  create a table with multiple partitions 
Hive,WITHOUT_CLASSIFICATION,//  string tests 
Hive,WITHOUT_CLASSIFICATION,//  There should now be 3 directories in the location 
Hive,WITHOUT_CLASSIFICATION,//  Build the path from bottom up. pick up list bucketing subdirectories 
Hive,WITHOUT_CLASSIFICATION,// 2) obtain metastore clients 
Hive,WITHOUT_CLASSIFICATION,//  Do the V1 methods of older and newer match? 
Hive,WITHOUT_CLASSIFICATION,//  nulls come first; otherwise nulls come last 
Hive,WITHOUT_CLASSIFICATION,//  just access key and value to ensure they are correct 
Hive,WITHOUT_CLASSIFICATION,//  Check if there are enough entries in the tree to constitute a hint. 
Hive,WITHOUT_CLASSIFICATION,//  fix for sf.net bug 879422 
Hive,WITHOUT_CLASSIFICATION,//  length of green is 5 
Hive,WITHOUT_CLASSIFICATION,//  use the min/max instead of the byte range 
Hive,WITHOUT_CLASSIFICATION,//  first 2 qualify 
Hive,WITHOUT_CLASSIFICATION,//  Don't print full exception trace if DEBUG is not on. 
Hive,WITHOUT_CLASSIFICATION,//  and check HDFS before and after. 
Hive,WITHOUT_CLASSIFICATION,//  Decimal classes cannot be converted by printf so convert them to doubles. 
Hive,WITHOUT_CLASSIFICATION,//  If the offsets are the same we assume our initial jump did not cross any DST boundaries 
Hive,WITHOUT_CLASSIFICATION,// create a lot of locks 
Hive,WITHOUT_CLASSIFICATION,//  Collection methods 
Hive,WITHOUT_CLASSIFICATION,// this simulates the completion of txnid:idTxnUpdate1 
Hive,WITHOUT_CLASSIFICATION,//  Expected 
Hive,WITHOUT_CLASSIFICATION,//  for non-MM tables the final destination partition directory is created during move task via rename   for MM tables the final destination partition directory is created by the tasks themselves 
Hive,WITHOUT_CLASSIFICATION,//  move task will create dp final path 
Hive,WITHOUT_CLASSIFICATION,//  Use FragmentRuntimeInfo.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,//  When there are no exceptions this has to be called always to make sure incompatible files   are moved properly to the destination path 
Hive,WITHOUT_CLASSIFICATION,//        Remains here as the legacy of the original higher-level interface (getInstance). 
Hive,WITHOUT_CLASSIFICATION,//  Already processed skip 
Hive,WITHOUT_CLASSIFICATION,//  GROUP_NAMES 
Hive,WITHOUT_CLASSIFICATION,//  Check that the change stuck. 
Hive,WITHOUT_CLASSIFICATION,//  unsupported 
Hive,WITHOUT_CLASSIFICATION,//  test using loadFileWork 
Hive,WITHOUT_CLASSIFICATION,//  schema.setProperty(serdeConstants.SERIALIZATION_FORMAT 
Hive,WITHOUT_CLASSIFICATION,//  Update. 
Hive,WITHOUT_CLASSIFICATION,//  Default type: all string 
Hive,WITHOUT_CLASSIFICATION,//  PLAN 
Hive,WITHOUT_CLASSIFICATION,//  some other task 
Hive,WITHOUT_CLASSIFICATION,//  4. Make location hints. 
Hive,WITHOUT_CLASSIFICATION,//  now grant all privs to admin 
Hive,WITHOUT_CLASSIFICATION,//  Note: this does not work for embedded channels. 
Hive,WITHOUT_CLASSIFICATION,//  Perform kerberos login using the hadoop shim API if the configuration is available 
Hive,WITHOUT_CLASSIFICATION,//  Aggregate itself should not reference cor vars. 
Hive,WITHOUT_CLASSIFICATION,//  Regardless of other criteria ducks are always more important than non-ducks. 
Hive,WITHOUT_CLASSIFICATION,// link queryId to txnId 
Hive,WITHOUT_CLASSIFICATION,//  get the SerDe parameters 
Hive,WITHOUT_CLASSIFICATION,//  Find all root TSs and add up all data sizes   Not adding other stats (e.g. # of rows col stats) since only data size is used here 
Hive,WITHOUT_CLASSIFICATION,//  load the test files into tables 
Hive,WITHOUT_CLASSIFICATION,//  Union expr for distinct keys 
Hive,WITHOUT_CLASSIFICATION,//  avoid calculating modulo 
Hive,WITHOUT_CLASSIFICATION,//  set up the operator plan. (before setting up splits on the AM) 
Hive,WITHOUT_CLASSIFICATION,//  add this filter for deletion if it does not have non-final candidates 
Hive,WITHOUT_CLASSIFICATION,//  2.3 Determine the index of ob expr in child schema   NOTE: Calcite can not take compound exprs in OB without it being 
Hive,WITHOUT_CLASSIFICATION,//  or columns (not expressions). If yes proceed. 
Hive,WITHOUT_CLASSIFICATION,//  Test for only partNames being empty 
Hive,WITHOUT_CLASSIFICATION,//  If the matched field is leaf which means all leaves are required not need to go   deeper. 
Hive,WITHOUT_CLASSIFICATION,//  and return all the dummy parent 
Hive,WITHOUT_CLASSIFICATION,//  we are just converting to a common merge join operator. The shuffle   join in map-reduce case. 
Hive,WITHOUT_CLASSIFICATION,//  a DynamicPartitionCtx to indicate that it needs to dynamically partitioned. 
Hive,WITHOUT_CLASSIFICATION,//  some DDL task that directly executes a TezTask does not setup Context and hence TriggerContext.   Setting queryId is messed up. Some DDL tasks have executionId instead of proper queryId. 
Hive,WITHOUT_CLASSIFICATION,//  date value to boolean doesn't make any sense. 
Hive,WITHOUT_CLASSIFICATION,//  We are not using the key and value contexts nor do we support a MapJoinKey. 
Hive,WITHOUT_CLASSIFICATION,//  should not have more than 1 load file for CTAS. 
Hive,WITHOUT_CLASSIFICATION,//  set input format information if necessary 
Hive,WITHOUT_CLASSIFICATION,//  Set the configuration parameters 
Hive,WITHOUT_CLASSIFICATION,/*  " => " + bb.hashCode() +  */
Hive,WITHOUT_CLASSIFICATION,//  get the list of task 
Hive,WITHOUT_CLASSIFICATION,//  Try qualifying with current db name for permanent functions 
Hive,WITHOUT_CLASSIFICATION,//  Wait before sending another heartbeat. Otherwise consider as an OOB heartbeat 
Hive,WITHOUT_CLASSIFICATION,//  May need to convert to common type to compare 
Hive,WITHOUT_CLASSIFICATION,//  First column empty 
Hive,WITHOUT_CLASSIFICATION,// Partitioned table 
Hive,WITHOUT_CLASSIFICATION,//  If the queue does not have capacity it does not throw a Rejection. Instead it will   return the task with the lowest priority which could be the task which is currently being processed. 
Hive,WITHOUT_CLASSIFICATION,//  Will be true if there are null entries 
Hive,WITHOUT_CLASSIFICATION,//  caller must make sure product of inputs is not too big 
Hive,WITHOUT_CLASSIFICATION,/*  copied over from VectorUDFTimestampFieldLong  */
Hive,WITHOUT_CLASSIFICATION,//  Enforce Hive defaults. 
Hive,WITHOUT_CLASSIFICATION,/*      * Consider a query like:     *     * select -- mapjoin(subq1) --  * from     * (select a.key a.value from tbl1 a) subq1     *   join     * (select a.key a.value from tbl2 a) subq2     * on subq1.key = subq2.key;     *     * aliasToOpInfo contains the SelectOperator for subq1 and subq2.     * We need to traverse the tree (using TableAccessAnalyzer) to get to the base     * table. If the object being map-joined is a base table then aliasToOpInfo     * contains the TableScanOperator and TableAccessAnalyzer is a no-op.      */
Hive,WITHOUT_CLASSIFICATION,//  nothing that we can really do about it 
Hive,WITHOUT_CLASSIFICATION,//  since the oldname table is not under its database (See HIVE-15059) the renamed oldname table will keep   its location after HIVE-14909. I changed to check the existence of the newname table and its name instead   of verifying its location   assertTrue(tbl.getSd().getLocation().contains("newname")); 
Hive,WITHOUT_CLASSIFICATION,//  iterate through each token and create appropriate object here. 
Hive,WITHOUT_CLASSIFICATION,//  Assumes the query has already been compiled 
Hive,WITHOUT_CLASSIFICATION,//  CASE CTAS statement 
Hive,WITHOUT_CLASSIFICATION,//  -(2^32) 
Hive,WITHOUT_CLASSIFICATION,//     "TOTAL" "COMPLETED" "RUNNING" "PENDING" "FAILED" "KILLED" 
Hive,WITHOUT_CLASSIFICATION,//  Allow lookup by query string 
Hive,WITHOUT_CLASSIFICATION,/*    * Right trim and truncate a byte array to a maximum number of characters and   * return a byte array with only the trimmed and truncated bytes.    */
Hive,WITHOUT_CLASSIFICATION,//  Minimum 5000 rows per stripe. 
Hive,WITHOUT_CLASSIFICATION,//  container prewarming. tell the am how many containers we need 
Hive,WITHOUT_CLASSIFICATION,//  Ignore the exception this may be caused by external jars 
Hive,WITHOUT_CLASSIFICATION,// bucket count for test tables; set it to 1 for easier debugging 
Hive,WITHOUT_CLASSIFICATION,//  This function serves as the wrapper of handleInsertStatementSpec in 
Hive,WITHOUT_CLASSIFICATION,//  verify that we can create a table with IF/OF to some custom non-existent format 
Hive,WITHOUT_CLASSIFICATION,//  When doWriteFewerColumns try to read more fields than exist in buffer. 
Hive,WITHOUT_CLASSIFICATION,//  If IDs 678 were all aborted and the metadata cleaned up we would lose the record   of the aborted IDs. In this case we are not able to determine the new WriteIDList has   an equivalent commit state compared to the previous WriteIDLists. 
Hive,WITHOUT_CLASSIFICATION,//  Add the checkpoint key to the Database binding it to current dump directory.   So if retry using same dump we shall skip Database object update. 
Hive,WITHOUT_CLASSIFICATION,//  recurse into memoized decorator 
Hive,WITHOUT_CLASSIFICATION,// this deletes the side file 
Hive,WITHOUT_CLASSIFICATION,//  Insert them all before the get requests from this iteration. 
Hive,WITHOUT_CLASSIFICATION,//           The first query has 2 full batches and the second query only has 1 batch which only contains 1 member 
Hive,WITHOUT_CLASSIFICATION,//  Scratch column information. 
Hive,WITHOUT_CLASSIFICATION,//  If there is any unknown partition create a map-reduce job for   the filter to prune correctly 
Hive,WITHOUT_CLASSIFICATION,//  MUX operator with 1 parent 
Hive,WITHOUT_CLASSIFICATION,//  Don't override ConfVars with null values 
Hive,WITHOUT_CLASSIFICATION,//  At least one mr/tez/spark job 
Hive,WITHOUT_CLASSIFICATION,//  number of objects in the block before it is spilled 
Hive,WITHOUT_CLASSIFICATION,//  Filter the partitions to show based on on supplied spec 
Hive,WITHOUT_CLASSIFICATION,//  replace original AVG(x) with SUM(x) / COUNT(x) 
Hive,WITHOUT_CLASSIFICATION,//  Alter table "tbl" via ObjectStore 
Hive,WITHOUT_CLASSIFICATION,//  the set of dynamic partitions 
Hive,WITHOUT_CLASSIFICATION,//  Go on to middle word. 
Hive,WITHOUT_CLASSIFICATION,//  Compare required privileges and available privileges for each hive object 
Hive,WITHOUT_CLASSIFICATION,//  We compose the seconds field from two parts. The lowest 31 bits come from the first four 
Hive,WITHOUT_CLASSIFICATION,//  We are in RecordWriter.close() make sense that the context would be   TaskInputOutput. 
Hive,WITHOUT_CLASSIFICATION,//  existing thrift data 
Hive,WITHOUT_CLASSIFICATION,//  by default the bounds checking for maximum number of   dynamic partitions is disabled (-1) 
Hive,WITHOUT_CLASSIFICATION,//  suffix should be a timestamp 
Hive,WITHOUT_CLASSIFICATION,//  find out the vertex for the big table 
Hive,WITHOUT_CLASSIFICATION,//  This is the only place where isQuery is set to true; it defaults to false. 
Hive,WITHOUT_CLASSIFICATION,//  Assumes serialized DAGs within an AM and a reset of structures after each DAG completes. 
Hive,WITHOUT_CLASSIFICATION,//  Calcite stores timestamp with local time-zone in UTC internally thus   when we bring it back we need to add the UTC suffix. 
Hive,WITHOUT_CLASSIFICATION,//  Create the functions and reload them from the MetaStore 
Hive,WITHOUT_CLASSIFICATION,//  insert into values gets written into insert from select dummy_table   This table is dummy and has no stats 
Hive,WITHOUT_CLASSIFICATION,// "set a=5 b=8" - rhsExp picks up the next char (e.g. '') from the token stream 
Hive,WITHOUT_CLASSIFICATION,//  Non-vectorized regular ACID reader. 
Hive,WITHOUT_CLASSIFICATION,//  Make filter pushdown information available to getSplits. 
Hive,WITHOUT_CLASSIFICATION,//  return true if this is any kind of float 
Hive,WITHOUT_CLASSIFICATION,//  compute locally and assign 
Hive,WITHOUT_CLASSIFICATION,/*  partitionColumnCount  */
Hive,WITHOUT_CLASSIFICATION,//  each row 
Hive,WITHOUT_CLASSIFICATION,//  minimum 3 seconds 
Hive,WITHOUT_CLASSIFICATION,//  check that a change to the hidden list should fail 
Hive,WITHOUT_CLASSIFICATION,//  The same for rolling the key; re-create the fsm with only the key #2. 
Hive,WITHOUT_CLASSIFICATION,//  if we have traits and table info is present in the traits we know the   exact number of buckets. Else choose the largest number of estimated 
Hive,WITHOUT_CLASSIFICATION,//                                                         12345678901234567890123456789 
Hive,WITHOUT_CLASSIFICATION,//  In filter mode the column must be a boolean 
Hive,WITHOUT_CLASSIFICATION,//  for now make sure that serde exists 
Hive,WITHOUT_CLASSIFICATION,//  "NULL" 
Hive,WITHOUT_CLASSIFICATION,//  re-attach all registered listeners 
Hive,WITHOUT_CLASSIFICATION,//  Serialize Table definition. Deserialize using the target HCatClient instance. 
Hive,WITHOUT_CLASSIFICATION,/*    * This method tries to convert a join to an SMB. This is done based on   * traits. If the sorted by columns are the same as the join columns then we   * can convert the join to an SMB. Otherwise retain the bucket map join as it   * is still more efficient than a regular join.    */
Hive,WITHOUT_CLASSIFICATION,/*    * Given a TOK_SELECT this checks IF there is a subquery   *  it is top level expression else it throws an error    */
Hive,WITHOUT_CLASSIFICATION,//  The update is failed and could be retried. 
Hive,WITHOUT_CLASSIFICATION,//  propagate constants 
Hive,WITHOUT_CLASSIFICATION,//  Default: treat the table as a single column "col" 
Hive,WITHOUT_CLASSIFICATION,//  Data types 
Hive,WITHOUT_CLASSIFICATION,//  Set the credential provider passwords if found if there is job specific password   the credential provider location is set directly in the execute method of LocalSparkClient 
Hive,WITHOUT_CLASSIFICATION,//  Generic UDFs 
Hive,WITHOUT_CLASSIFICATION,//  throw new RuntimeException("duplicate?!"); 
Hive,WITHOUT_CLASSIFICATION,//  This may need to change as the implementation changes. 
Hive,WITHOUT_CLASSIFICATION,//  Case 3: If there's delay for the heartbeat and the delay is long enough to trigger the reaper           then the txn will time out and be aborted.           Here we just don't send the heartbeat at all - an infinite delay. 
Hive,WITHOUT_CLASSIFICATION,//  does not support timestamp   TypeInfoToSchema.createAvroPrimitive : UnsupportedOperationException 
Hive,WITHOUT_CLASSIFICATION,//  base  = JAVA32_OBJECT + PRIMITIVES1 * 4 + JAVA32_FIELDREF * 3 + JAVA32_ARRAY;   entry = JAVA32_OBJECT + JAVA32_FIELDREF + PRIMITIVES1 
Hive,WITHOUT_CLASSIFICATION,//  Total: 4/4 running. 
Hive,WITHOUT_CLASSIFICATION,//  the aggregation buffers to use for each key present in the batch 
Hive,WITHOUT_CLASSIFICATION,//  an array of structures containing the n-gram and its estimated frequency. 
Hive,WITHOUT_CLASSIFICATION,//  read authorization does not work with default/legacy authorization mode   It is a chicken and egg problem granting select privilege to database as the   grant statement would invoke get_database which needs select privilege 
Hive,WITHOUT_CLASSIFICATION,//  For each SparkPartitionPruningSinkOperator take the target MapWork and see if it is in a dependent SparkTask 
Hive,WITHOUT_CLASSIFICATION,//  This hook verifies that the location of every partition in the inputs and outputs does not   start with the location of the table.  It is a very simple check to make sure the location is   not a subdirectory. 
Hive,WITHOUT_CLASSIFICATION,//  propagate reporter and output collector to all operators 
Hive,WITHOUT_CLASSIFICATION,//  Verify if the auth should fail 
Hive,WITHOUT_CLASSIFICATION,//  Convert the complex LazyBinary objects to standard (Java) objects so downstream   operators like FileSinkOperator can serialize complex objects in the form they expect   (i.e. Java objects). 
Hive,WITHOUT_CLASSIFICATION,//  Converts Date to TimestampTZ. 
Hive,WITHOUT_CLASSIFICATION,//  The BinarySortable serialization of the current key. 
Hive,WITHOUT_CLASSIFICATION,//  each of the ErrorHeuristics. Repeat for all the lines in the log. 
Hive,WITHOUT_CLASSIFICATION,//  the Operator type 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setAsciiStream(int java.io.InputStream)    */
Hive,WITHOUT_CLASSIFICATION,//  When the repeated no match is due to filtering we need to restore the   selected information. 
Hive,WITHOUT_CLASSIFICATION,//  5) Modify INSERT branch condition. In particular we need to modify the 
Hive,WITHOUT_CLASSIFICATION,//  Operation may have been cancelled by another thread 
Hive,WITHOUT_CLASSIFICATION,//  Fetch operator is not vectorized and as such turn vectorization flag off so that 
Hive,WITHOUT_CLASSIFICATION,/*  Convert an integer value in seconds since the epoch to a timestamp value   * for use in a long column vector which is represented in nanoseconds since the epoch.    */
Hive,WITHOUT_CLASSIFICATION,//  UPDATE_RULE 
Hive,WITHOUT_CLASSIFICATION,//  Track if we still have the entire part. 
Hive,WITHOUT_CLASSIFICATION,//  Cookie based authentication when using HTTP Transport 
Hive,WITHOUT_CLASSIFICATION,//  The table does not have any partitions 
Hive,WITHOUT_CLASSIFICATION,//  Setup output stream to redirect output to 
Hive,WITHOUT_CLASSIFICATION,//  Insert some data -> this will generate only insert deltas and no delete deltas: delta_1_1 
Hive,WITHOUT_CLASSIFICATION,//  pick up unknown case and let and operator handle the rest 
Hive,WITHOUT_CLASSIFICATION,//  We don't use this one. 
Hive,WITHOUT_CLASSIFICATION,/*  256 files x 100 size for 1 splits  */
Hive,WITHOUT_CLASSIFICATION,//  3.1 Create structs 
Hive,WITHOUT_CLASSIFICATION,//  If it is not an inner join we do not push the 
Hive,WITHOUT_CLASSIFICATION,//  Make sure small table BytesColumnVectors have room for string values in the big table and 
Hive,WITHOUT_CLASSIFICATION,//  use the positions to only pick the partitionCols which are required   on the small table side. 
Hive,WITHOUT_CLASSIFICATION,//  to test whether that is held. 
Hive,WITHOUT_CLASSIFICATION,//  For other registered patterns find exact matches. 
Hive,WITHOUT_CLASSIFICATION,//  Create a String Appender to capture log output 
Hive,WITHOUT_CLASSIFICATION,//  skip processing has to be done first before continuing 
Hive,WITHOUT_CLASSIFICATION,//  Sorting columns of the parent RS are more specific than those of the   child RS but Sorting order of the child RS is more specific than   that of the parent RS. 
Hive,WITHOUT_CLASSIFICATION,//  instance of TSocket. This is also not set when kerberos is used. 
Hive,WITHOUT_CLASSIFICATION,/*      * 5. Having      */
Hive,WITHOUT_CLASSIFICATION,//  optional string unique_node_id = 2; 
Hive,WITHOUT_CLASSIFICATION,//  We could be here either because its an unpartitioned table or because   there are no pruning predicates on a partitioned table. 
Hive,WITHOUT_CLASSIFICATION,//  TODO: Enable caching for queries with masking/filtering 
Hive,WITHOUT_CLASSIFICATION,//  Publish new segments to metadata storage 
Hive,WITHOUT_CLASSIFICATION,//  Other exceptions which defaults to SPARK_CREATE_CLIENT_ERROR 
Hive,WITHOUT_CLASSIFICATION,//  Not making it configurable for perf reasons (avoid checks) 
Hive,WITHOUT_CLASSIFICATION,//  Prepare children 
Hive,WITHOUT_CLASSIFICATION,//  This creates and publish new segment 
Hive,WITHOUT_CLASSIFICATION,//  Somebody took away our unwanted ducks. 
Hive,WITHOUT_CLASSIFICATION,//  num reduce sinks hardcoded to 0 because TS has no parents 
Hive,WITHOUT_CLASSIFICATION,//  4/ write key-value pairs one by one 
Hive,WITHOUT_CLASSIFICATION,//  WHEN indicator IS NULL 
Hive,WITHOUT_CLASSIFICATION,//  project 
Hive,WITHOUT_CLASSIFICATION,//  The output buffer used to serialize a value into. 
Hive,WITHOUT_CLASSIFICATION,//  Note that db1 and db2 have a table with common name 
Hive,WITHOUT_CLASSIFICATION,//  We collect information in VectorPTFDesc that doesn't need the VectorizationContext.   We use this information for validation.  Later when creating the vector operator   we create an additional object VectorPTFInfo. 
Hive,WITHOUT_CLASSIFICATION,//  Not used 
Hive,WITHOUT_CLASSIFICATION,// test table with db portion 
Hive,WITHOUT_CLASSIFICATION,//  we want to signal an error if the function doesn't exist and we're 
Hive,WITHOUT_CLASSIFICATION,//  mix functions for k1 
Hive,WITHOUT_CLASSIFICATION,//  Now validate transactional_properties for the table. 
Hive,WITHOUT_CLASSIFICATION,//  PTF need a SelectOp. 
Hive,WITHOUT_CLASSIFICATION,//  so as to have their permissions mimic the table permissions 
Hive,WITHOUT_CLASSIFICATION,//  local mode implies that scheme should be "file"   we can change this going forward 
Hive,WITHOUT_CLASSIFICATION,//  if we reach here it means it needs to do a table authorization   check and the table authorization may already happened because of other 
Hive,WITHOUT_CLASSIFICATION,//  modified.     
Hive,WITHOUT_CLASSIFICATION,//  met we are not going to try to merge. 
Hive,WITHOUT_CLASSIFICATION,//  Clean anything from the txns table that has no components left in txn_components. 
Hive,WITHOUT_CLASSIFICATION,/*      * The mapjoin operator will be encountered many times (n times for a n-way join). Since a     * reduceSink operator is not allowed before a mapjoin the task for the mapjoin will always     * be a root task. The task corresponding to the mapjoin is converted to a root task when the     * operator is encountered for the first time. When the operator is encountered subsequently     * the current task is merged with the root task for the mapjoin. Note that it is possible     * that the map-join task may be performed as a bucketized map-side join (or sort-merge join)     * the map join operator is enhanced to contain the bucketing info. when it is encountered.      */
Hive,WITHOUT_CLASSIFICATION,// For partitioned table we always track writes at partition level (never at table)  and for non partitioned - always at table level thus the same table should never  have entries with partition key and w/o 
Hive,WITHOUT_CLASSIFICATION,/*  256Kb in longs  */
Hive,WITHOUT_CLASSIFICATION,/*          * if there is only one destination in Query try to push where predicates         * as Join conditions          */
Hive,WITHOUT_CLASSIFICATION,/*       This is used to get hold of a reference during the current creation of tasks and is initialized      with "0" tasks such that it will be non consequential in any operations done with task tracker      compositions.        */
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) Const  */
Hive,WITHOUT_CLASSIFICATION,// package and compress all the hashtable files to an archive file 
Hive,WITHOUT_CLASSIFICATION,//  No need to iterate more when threshold is reached   (beneficial especially for object stores) 
Hive,WITHOUT_CLASSIFICATION,//  also clone the colExprMap by default   we need a deep copy 
Hive,WITHOUT_CLASSIFICATION,//  This operator has been removed remove it from the list of existing operators 
Hive,WITHOUT_CLASSIFICATION,//  Add a db via ObjectStore 
Hive,WITHOUT_CLASSIFICATION,//  Test that fetching a non-existent table-name yields ObjectNotFound. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *    * @see   * org.apache.hadoop.hive.ql.udf.generic.Collector#collect(java.lang.Object)    */
Hive,WITHOUT_CLASSIFICATION,//  spill tables are 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise we have failed; the callback has taken care of the failure. 
Hive,WITHOUT_CLASSIFICATION,/*    * Returns the node on the top of the stack and remove it from the stack.    */
Hive,WITHOUT_CLASSIFICATION,//  Ignore object fail if not admin succeed if admin. 
Hive,WITHOUT_CLASSIFICATION,//  map that keeps track of the last operator of a task to the work 
Hive,WITHOUT_CLASSIFICATION,//  set columns to read in conf 
Hive,WITHOUT_CLASSIFICATION,//  Preserve the selected reference and size values generated 
Hive,WITHOUT_CLASSIFICATION,//  Use the target directory if it is not specified 
Hive,WITHOUT_CLASSIFICATION,// obtain a token by directly invoking the metastore operation(without going  through the thrift interface). Obtaining a token makes the secret manager  aware of the user and that it gave the token to the user  also set the authentication method explicitly to KERBEROS. Since the  metastore checks whether the authentication method is KERBEROS or not  for getDelegationToken and the testcases don't use  kerberos this needs to be done 
Hive,WITHOUT_CLASSIFICATION,//  fieldIndex becomes so simple   Note that pos starts from 1 while fieldIndex starts from 0; 
Hive,WITHOUT_CLASSIFICATION,//  For small table RS parents that have already been processed we need to   add the tag to the RS work to the reduce work that contains this map join.   This was not being done for normal mapjoins where the small table typically 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: A check for existence of deleteDeltaFile is required because we may not have 
Hive,WITHOUT_CLASSIFICATION,//  Make sure we'll use a different plan path from the original one 
Hive,WITHOUT_CLASSIFICATION,//  testtable1.*: 
Hive,WITHOUT_CLASSIFICATION,//  In case of no partition we have to move each file 
Hive,WITHOUT_CLASSIFICATION,//  Attempt to acquire write resources waiting if they are not available. 
Hive,WITHOUT_CLASSIFICATION,//  You store the materialized view 
Hive,WITHOUT_CLASSIFICATION,// primitive types 
Hive,WITHOUT_CLASSIFICATION,//  If we decided not to reposition and re-read the buffer to copy it with   copyToExternalBuffer we we will still be correctly positioned for the next field. 
Hive,WITHOUT_CLASSIFICATION,//  mix functions for k2 
Hive,WITHOUT_CLASSIFICATION,//  DESCRIPTION 
Hive,WITHOUT_CLASSIFICATION,//  Left child 
Hive,WITHOUT_CLASSIFICATION,//  A BlockMissingException indicates a temporary error   not a corruption. Re-throw this exception. 
Hive,WITHOUT_CLASSIFICATION,//  scale up 
Hive,WITHOUT_CLASSIFICATION,//  with ptfs there maybe more (note for PTFChains: 
Hive,WITHOUT_CLASSIFICATION,//  Add write hooks if needed. 
Hive,WITHOUT_CLASSIFICATION,//  Tolerate repeated use of a big table column. 
Hive,WITHOUT_CLASSIFICATION,//  check configs are hidden 
Hive,WITHOUT_CLASSIFICATION,//  we weren't provided any actual qualifier name. Set these to 
Hive,WITHOUT_CLASSIFICATION,//  ends up getting rid of Project since it is not used further up the tree 
Hive,WITHOUT_CLASSIFICATION,//  Call Hive.closeCurrent() that closes the HMS connection causes   HMS connection leaks otherwise. 
Hive,WITHOUT_CLASSIFICATION,//  12. Run rules to aid in translation from Calcite tree to Hive tree 
Hive,WITHOUT_CLASSIFICATION,//  in the form of T partition (ds="2010-03-03")   Not stripping quotes here as we need to use it as it is while framing PARTITION clause   in INSERT query. 
Hive,WITHOUT_CLASSIFICATION,//  early exit as getting file lengths can be expensive in object stores. 
Hive,WITHOUT_CLASSIFICATION,//  newInstance should always be the same type of object as this 
Hive,WITHOUT_CLASSIFICATION,//  Now notify the executorService that the task has moved to finishable state. 
Hive,WITHOUT_CLASSIFICATION,//  Add some columns 
Hive,WITHOUT_CLASSIFICATION,//  As of Hadoop 2.7 - this is what controls the RM timeout. 
Hive,WITHOUT_CLASSIFICATION,//  implements java.util.Iterator<HCatPartition> { 
Hive,WITHOUT_CLASSIFICATION,//  if the first argument is const then just set the flag and continue 
Hive,WITHOUT_CLASSIFICATION,//  VRB mode - process the VRBs with cache data; the new cache data is coming later. 
Hive,WITHOUT_CLASSIFICATION,//  Replicate the remaining INSERT OVERWRITE operation on the table. 
Hive,WITHOUT_CLASSIFICATION,// creating Path is expensive so cache the corresponding  Path object in normalizedPaths 
Hive,WITHOUT_CLASSIFICATION,//  remove the condition by replacing it with "true" 
Hive,WITHOUT_CLASSIFICATION,//  Catch the exception log it and rethrow it. 
Hive,WITHOUT_CLASSIFICATION,//  We need to enforce precision/scale here. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setAsciiStream(java.lang.String   * java.io.InputStream int)    */
Hive,WITHOUT_CLASSIFICATION,//  We will estimate collection as an object (only if it's a field). 
Hive,WITHOUT_CLASSIFICATION,//  Project any correlated variables the input wants to pass along. 
Hive,WITHOUT_CLASSIFICATION,// 0  1  2  3  4  5  6  7  8  9  10  11  12  13 
Hive,WITHOUT_CLASSIFICATION,//  Empty map case 
Hive,WITHOUT_CLASSIFICATION,//  the owner can change also owner might appear in user grants as well   so keep owner privileges separate from userGrants 
Hive,WITHOUT_CLASSIFICATION,/*    * Whether the HiveConf.ConfVars.HIVE_VECTORIZATION_USE_VECTORIZED_INPUT_FILE_FORMAT variable   * (hive.vectorized.use.vectorized.input.format) was true when the Vectorizer class evaluated   * vectorizing this node.   *   * When Vectorized Input File Format looks at this flag it can determine whether it should   * operate vectorized or not.  In some modes the node can be vectorized but use row   * serialization.    */
Hive,WITHOUT_CLASSIFICATION,//         LOG.warn("No partition found genereated by dynamic partitioning in ["              +loadPath+"] with depth["+jobInfo.getTable().getPartitionKeysSize()              +"] dynSpec["+dynPathSpec+"]"); 
Hive,WITHOUT_CLASSIFICATION,//  called for each partition of big table and populates mapping for each file in the partition 
Hive,WITHOUT_CLASSIFICATION,/*    * As per JDBC 3.0 Spec (section 9.2)   * "If the Driver implementation understands the URL it will return a Connection object;   * otherwise it returns null"    */
Hive,WITHOUT_CLASSIFICATION,//  get substring 
Hive,WITHOUT_CLASSIFICATION,//  map-reduce job 
Hive,WITHOUT_CLASSIFICATION,//  Report failure to the main thread. 
Hive,WITHOUT_CLASSIFICATION,// initialize reporters 
Hive,WITHOUT_CLASSIFICATION,//  the only conf allowed to have the metastore pwd keyname is the hidden list configuration   value 
Hive,WITHOUT_CLASSIFICATION,//  We care only about open/aborted txns below currentTxn and hence the size should be determined   for the exceptions list. The currentTxn will be missing in openTxns list only in rare case like   txn is aborted by AcidHouseKeeperService and compactor actually cleans up the aborted txns.   So for such cases we get negative value for sizeToHwm with found position for currentTxn and so 
Hive,WITHOUT_CLASSIFICATION,//  We need to stay out of the way of any sequences used by the underlying database.   Otherwise the next time the client tries to add a catalog we'll get an error.   There should never be billions of catalogs so we'll shift our sequence number up 
Hive,WITHOUT_CLASSIFICATION,//  No-op: testing events only 
Hive,WITHOUT_CLASSIFICATION,//  Save the vector description for the EXPLAIN. 
Hive,WITHOUT_CLASSIFICATION,//  Handle a table - populate aliases appropriately:   leftAliases should contain the first table rightAliases should   contain all other tables and baseSrc should contain all tables 
Hive,WITHOUT_CLASSIFICATION,//  Compute collations 
Hive,WITHOUT_CLASSIFICATION,//  this is a lossy invert of the function above which produces a hashcode   which collides with the current winner of the register (we lose all higher    bits but we get all bits useful for lesser p-bit options) 
Hive,WITHOUT_CLASSIFICATION,//  Stop tracking the fragment and re-throw the error. 
Hive,WITHOUT_CLASSIFICATION,// Check if different FileSystems 
Hive,WITHOUT_CLASSIFICATION,// -----------------------------------------------------------------------------------------------   Constructors are marked private; use create methods.  ----------------------------------------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  manufacture a StatsAggregator 
Hive,WITHOUT_CLASSIFICATION,//  Only need to write out & close the delete_delta if there have been any. 
Hive,WITHOUT_CLASSIFICATION,//  Deserialize the fields into the *overflow* batch using the buffered batch column map. 
Hive,WITHOUT_CLASSIFICATION,//  Check the table directory. 
Hive,WITHOUT_CLASSIFICATION,//  Some of the data is set on the server side so reset those 
Hive,WITHOUT_CLASSIFICATION,//  session identifier 
Hive,WITHOUT_CLASSIFICATION,//  update mappings:   oldInput ----> newInput                    newProject                     |   oldInput ----> newInput     is transformed to     oldInput ----> newProject                     | 
Hive,WITHOUT_CLASSIFICATION,//  we replace existing table. 
Hive,WITHOUT_CLASSIFICATION,//  First time this is seen. Log it. 
Hive,WITHOUT_CLASSIFICATION,//  ^(TOK_LATERAL_VIEW ^(TOK_SELECT ^(TOK_SELEXPR ^(TOK_FUNCTION Identifier["inline"] valuesClause) identifier* tableAlias))) 
Hive,WITHOUT_CLASSIFICATION,//  linking these two operator declares that they are representing the same thing   currently important because statistincs are actually gather for newOp; but the lookup is done using oldOp 
Hive,WITHOUT_CLASSIFICATION,//  0. Additional data structures needed for the join optimization 
Hive,WITHOUT_CLASSIFICATION,//  template <ClassName> <ValueType> <OperatorSymbol> <DescriptionName> <DescriptionValue> 
Hive,WITHOUT_CLASSIFICATION,//  Successfully scheduled 
Hive,WITHOUT_CLASSIFICATION,//  GroupBy query results as records 
Hive,WITHOUT_CLASSIFICATION,//  Set appropriate owner/perms of the DB dir only no need to recurse 
Hive,WITHOUT_CLASSIFICATION,//  nothing to set 
Hive,WITHOUT_CLASSIFICATION,//  It didn't seem useful to create another Constants class just for these though. 
Hive,WITHOUT_CLASSIFICATION,//  Delete table data 
Hive,WITHOUT_CLASSIFICATION,//  due to the way we use the allocation-free cast from HiveDecimalWriter to decimal128   we do not have the luxury of a ByteBuffer... 
Hive,WITHOUT_CLASSIFICATION,//  The output ObjectInspector is writableStringObjectInspector. 
Hive,WITHOUT_CLASSIFICATION,//  Only print out one task because that's good enough for debugging. 
Hive,WITHOUT_CLASSIFICATION,//  create a row per table name 
Hive,WITHOUT_CLASSIFICATION,/* |  Use | Boundary2.type | Boundary2.amt | Sort Key | Order | Behavior                          || Case |                |               |          |       |                                   ||------+----------------+---------------+----------+-------+-----------------------------------||   1. | PRECEDING      | UNB           | ANY      | ANY   | Error                             ||   2. | PRECEDING      | unsigned int  | NULL     | DESC  | end = partition.size()            ||   3. |                |               |          | ASC   | end = 0                           ||   4. | PRECEDING      | unsigned int  | not null | DESC  | scan backward until row R2        ||      |                |               |          |       | such that R2.sk - R.sk > bnd.amt  ||      |                |               |          |       | end = R2.idx + 1                  ||   5. | PRECEDING      | unsigned int  | not null | ASC   | scan backward until row R2        ||      |                |               |          |       | such that R.sk -  R2.sk > bnd.amt ||      |                |               |          |       | end = R2.idx + 1                  ||   6. | CURRENT ROW    |               | NULL     | ANY   | scan forward until row R2         ||      |                |               |          |       | such that R2.sk is not null       ||      |                |               |          |       | end = R2.idx                      ||   7. | CURRENT ROW    |               | not null | ANY   | scan forward until row R2         ||      |                |               |          |       | such that R2.sk != R.sk           ||      |                |               |          |       | end = R2.idx                      ||   8. | FOLLOWING      | UNB           | ANY      | ANY   | end = partition.size()            ||   9. | FOLLOWING      | unsigned int  | NULL     | DESC  | end = partition.size()            ||  10. |                |               |          | ASC   | scan forward until row R2         ||      |                |               |          |       | such that R2.sk is not null       ||      |                |               |          |       | end = R2.idx                      ||  11. | FOLLOWING      | unsigned int  | not NULL | DESC  | scan forward until row R2         ||      |                |               |          |       | such R.sk - R2.sk > bnd.amt       ||      |                |               |          |       | end = R2.idx                      ||  12. |                |               |          | ASC   | scan forward until row R2         ||      |                |               |          |       | such R2.sk - R2.sk > bnd.amt      ||      |                |               |          |       | end = R2.idx                      ||------+----------------+---------------+----------+-------+-----------------------------------|    */
Hive,WITHOUT_CLASSIFICATION,//  check that the agg is of the following type: 
Hive,WITHOUT_CLASSIFICATION,//  is this a null?   only read the is-null byte for level > 1 because the top-level struct   can never be null. 
Hive,WITHOUT_CLASSIFICATION,//  Variance check 
Hive,WITHOUT_CLASSIFICATION,//  Iterate thru all the filecaches. This is best-effort.   If these super-long-lived iterators affect the map in some bad way 
Hive,WITHOUT_CLASSIFICATION,//  write it to file: 
Hive,WITHOUT_CLASSIFICATION,// add the privileges not supported in V1  The list of privileges supported in V2 is implementation defined 
Hive,WITHOUT_CLASSIFICATION,//  The code inside the attribute getter threw an exception so log it   and fall back on the class name 
Hive,WITHOUT_CLASSIFICATION,//  initialize a complete map reduce configuration 
Hive,WITHOUT_CLASSIFICATION,//  Current Hive parquet timestamp implementation stores timestamps in UTC but other   components do not. In this case we skip timestamp conversion.   If this file is written by a version of hive before HIVE-21290 file metadata will   not contain the writer timezone so we convert the timestamp to the system (reader)   time zone.   If file is written by current Hive implementation we convert timestamps to the writer   time zone in order to emulate time zone agnostic behavior. 
Hive,WITHOUT_CLASSIFICATION,//  If the table is sorted on a partition column not valid for sorting 
Hive,WITHOUT_CLASSIFICATION,//  After committing the initial txns and updating current number of open txns back to 0 
Hive,WITHOUT_CLASSIFICATION,//  3.3.2 Get UDAF Info using UDAF Evaluator 
Hive,WITHOUT_CLASSIFICATION,//  By default don't convert to unix 
Hive,WITHOUT_CLASSIFICATION,//  Timeout for the iteration in case of asynchronous execute 
Hive,WITHOUT_CLASSIFICATION,//  (2^128 - 1) * 10^-39 
Hive,WITHOUT_CLASSIFICATION,//  non-cbo path retries to execute subqueries and throws completely different exception/error   to eclipse the original error message   so avoid executing subqueries on non-cbo 
Hive,WITHOUT_CLASSIFICATION,//  Create an archived version of the partition in a directory ending in   ARCHIVE_INTERMEDIATE_DIR_SUFFIX that's the same level as the partition   if it does not already exist. If it does exist we assume the dir is good 
Hive,WITHOUT_CLASSIFICATION,//  Noticed that we also suffer from the same issue as HIVE-3179   Only want to call a field init'ed when it's non-NULL   Check it twice make sure we get null both times 
Hive,WITHOUT_CLASSIFICATION,//  This can only happen in case of failure - we read some data but didn't decompress   it. Deallocate the buffer directly do not decref. 
Hive,WITHOUT_CLASSIFICATION,//  Flush the print stream so it doesn't include output from the last command 
Hive,WITHOUT_CLASSIFICATION,//  test February of non-leap year 2/31 is viewd as 3/3 due to 3 days diff   from 2/31 to 2/28 
Hive,WITHOUT_CLASSIFICATION,//  Timeouts are bad... mmmkay. 
Hive,WITHOUT_CLASSIFICATION,//  TOKEN_STR_FORM 
Hive,WITHOUT_CLASSIFICATION,// convert the set into list 
Hive,WITHOUT_CLASSIFICATION,//  If HIVE_LOCAL_TASK_CHILD_OPTS is set child VM environment setting   HADOOP_CLIENT_OPTS will be replaced with HIVE_LOCAL_TASK_CHILD_OPTS.   HADOOP_OPTS is updated too since HADOOP_CLIENT_OPTS is appended   to HADOOP_OPTS in most cases. This way the local task JVM can 
Hive,WITHOUT_CLASSIFICATION,//  The channel listener instantiates the Rpc instance when the connection is established 
Hive,WITHOUT_CLASSIFICATION,//  assuming that this closes the underlying streams 
Hive,WITHOUT_CLASSIFICATION,/*      * Restriction.16.s :: Correlated Expression in Outer Query must not contain     * unqualified column references.     * disabled : if it's obvious we allow unqualified refs      */
Hive,WITHOUT_CLASSIFICATION,//  column family is mapped to Map<stringstring> 
Hive,WITHOUT_CLASSIFICATION,//  Nothing we can do here so just proceed normally from now on 
Hive,WITHOUT_CLASSIFICATION,//  verify that hiveserver2 config is not loaded 
Hive,WITHOUT_CLASSIFICATION,//  open transactions. 
Hive,WITHOUT_CLASSIFICATION,//  If we do not reduce the input size we bail out 
Hive,WITHOUT_CLASSIFICATION,//  prevents a task from being processed multiple times 
Hive,WITHOUT_CLASSIFICATION,//  ROOT_PATH 
Hive,WITHOUT_CLASSIFICATION,//  Testing with multiByte String 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) ConstList  */
Hive,WITHOUT_CLASSIFICATION,//  The current non-NULL key position. 
Hive,WITHOUT_CLASSIFICATION,//  No implicit cast needed 
Hive,WITHOUT_CLASSIFICATION,//  conf validator already checks this so it will never trigger usually 
Hive,WITHOUT_CLASSIFICATION,//  Ensure the session is open and has the necessary local resources. 
Hive,WITHOUT_CLASSIFICATION,//  test conversion of long->string 
Hive,WITHOUT_CLASSIFICATION,//  We might be visiting twice because of reutilization of intermediary results.   If that is the case we do not need to do anything because either we have   already connected this RS operator or we will connect it at subsequent pass. 
Hive,WITHOUT_CLASSIFICATION,//  Skip TOK_QUERY. 
Hive,WITHOUT_CLASSIFICATION,//  6. We register both so we do not fire the rule on them again 
Hive,WITHOUT_CLASSIFICATION,//  DAG might have been killed lets try to get vertex state from AM before dying 
Hive,WITHOUT_CLASSIFICATION,//  bigTableFound means we've encountered a table that's bigger than the 
Hive,WITHOUT_CLASSIFICATION,//  has tag => need to set later 
Hive,WITHOUT_CLASSIFICATION,//  mask this digit 
Hive,WITHOUT_CLASSIFICATION,//  First add all children of this work into queue to be processed later. 
Hive,WITHOUT_CLASSIFICATION,//  compare with 5 * 10**-tenScale   example: tenScale=-1. o will be zero after scaling if o>=5. 
Hive,WITHOUT_CLASSIFICATION,//  2a. This is a decoded compression buffer add as is. 
Hive,WITHOUT_CLASSIFICATION,/*  Set total number of rows from all in memory partitions  */
Hive,WITHOUT_CLASSIFICATION,//  In verbose mode print an update per RECORD_PRINT_INTERVAL records 
Hive,WITHOUT_CLASSIFICATION,//  map work starts with table scan operators 
Hive,WITHOUT_CLASSIFICATION,//  At this point everything in the list is going to have a refcount of one. Unless it   failed between the allocation and the incref for a single item we should be ok.  
Hive,WITHOUT_CLASSIFICATION,//  UNDERSCORE_INT 
Hive,WITHOUT_CLASSIFICATION,//  exhausted all delete records return. 
Hive,WITHOUT_CLASSIFICATION,//  Special treatment for Filter operator that ignores the DPP predicates 
Hive,WITHOUT_CLASSIFICATION,//  Create row related objects 
Hive,WITHOUT_CLASSIFICATION,//  re-use existing text member in varchar writable 
Hive,WITHOUT_CLASSIFICATION,//  For native vectorized map join we require the key SerDe to be BinarySortableSerDe   Note: the MJ may not really get natively-vectorized later   but changing SerDe won't hurt correctness 
Hive,WITHOUT_CLASSIFICATION,//  Update the partition columns in small table to ensure correct routing of hash tables. 
Hive,WITHOUT_CLASSIFICATION,//  Escape the escape 
Hive,WITHOUT_CLASSIFICATION,//  Pre-allocated member for storing index into the hashMultiSetResults for each spilled row. 
Hive,WITHOUT_CLASSIFICATION,//  Determine mapping between project input and output fields.    In Hive Sort is always based on RexInputRef   We only need to check if project can contain all the positions that sort needs. 
Hive,WITHOUT_CLASSIFICATION,//  ADJACENCY_LIST 
Hive,WITHOUT_CLASSIFICATION,//  Close client session 
Hive,WITHOUT_CLASSIFICATION,/*    * These parameters controls the maximum number of concurrent job submit/status/list   * operations in templeton service. If more number of concurrent requests comes then   * they will be rejected with BusyException.    */
Hive,WITHOUT_CLASSIFICATION,//  output has noNulls set to false so set the isNull[] to false carefully 
Hive,WITHOUT_CLASSIFICATION,//  recursively call the join the other rhs tables 
Hive,WITHOUT_CLASSIFICATION,//  the actual size will be assigned in setChildrenInfo() after reading complete. 
Hive,WITHOUT_CLASSIFICATION,//  It is not primitive; check if it is a struct and we can infer a common class 
Hive,WITHOUT_CLASSIFICATION,//  Check if any of the txns in the list is committed. If yes throw exception. 
Hive,WITHOUT_CLASSIFICATION,//  Tried scheduling everything that could be scheduled in this loop. 
Hive,WITHOUT_CLASSIFICATION,//  the MR job for compaction 
Hive,WITHOUT_CLASSIFICATION,//  destf 
Hive,WITHOUT_CLASSIFICATION,// Test for duplicate publish -- this will either fail on job creation time   and throw an exception or will fail at runtime and fail the job. 
Hive,WITHOUT_CLASSIFICATION,//  There should be only 1 directory left: base_xxxxxxx. 
Hive,WITHOUT_CLASSIFICATION,//  If the plan for this reducer does not exist initialize the plan 
Hive,WITHOUT_CLASSIFICATION,//  Test replicated drop should drop this time since repl.state.id < evid. 
Hive,WITHOUT_CLASSIFICATION,//  Go on to high word. 
Hive,WITHOUT_CLASSIFICATION,//  2 minutes. 
Hive,WITHOUT_CLASSIFICATION,//  insert a select operator here used by the ColumnPruner to reduce 
Hive,WITHOUT_CLASSIFICATION,//  create split for the previous unfinished stripe 
Hive,WITHOUT_CLASSIFICATION,// could acquire 1 table level Shared_write intead 
Hive,WITHOUT_CLASSIFICATION,//  first one will fail - count it in 
Hive,WITHOUT_CLASSIFICATION,//  Create all nulls key. 
Hive,WITHOUT_CLASSIFICATION,//  ORDERING 
Hive,WITHOUT_CLASSIFICATION,//  struct<operation:intoriginalTransaction:bigintbucket:introwId:bigintcurrentTransaction:bigint 
Hive,WITHOUT_CLASSIFICATION,//  High and middle word must be zero.  Check for overflow digits in lower word. 
Hive,WITHOUT_CLASSIFICATION,//  External LLAP clients would need to set LLAP_ZK_REGISTRY_USER to the LLAP daemon user (hive)   rather than relying on RegistryUtils.currentUser(). 
Hive,WITHOUT_CLASSIFICATION,//  The vertex cannot be configured until all DataEvents are seen - to 
Hive,WITHOUT_CLASSIFICATION,//  Use QueryCompleteResponseProto.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,//  swap debug options in HADOOP_CLIENT_OPTS to those that the child JVM should have 
Hive,WITHOUT_CLASSIFICATION,//  which can affect the working of all downstream transformations. 
Hive,WITHOUT_CLASSIFICATION,//  We estimate the same way for compressed and uncompressed for now. 
Hive,WITHOUT_CLASSIFICATION,//  optional int32 num_self_and_upstream_tasks = 1; 
Hive,WITHOUT_CLASSIFICATION,//  If any child work for this work is already added to the targetWork earlier   we should connect this work with it 
Hive,WITHOUT_CLASSIFICATION,//  Reader creation updates HDFS counters don't do it here. 
Hive,WITHOUT_CLASSIFICATION,//  Second granularity 
Hive,WITHOUT_CLASSIFICATION,//  Try non-chunked stream. There should be no issues assuming we flushed the streams before closing. 
Hive,WITHOUT_CLASSIFICATION,//  compose a query that select transactions containing an update... 
Hive,WITHOUT_CLASSIFICATION,// delegate to the new api 
Hive,WITHOUT_CLASSIFICATION,//  col > 1 
Hive,WITHOUT_CLASSIFICATION,//  We use Spark RDD async action to submit job as it's the only way to get jobId now. 
Hive,WITHOUT_CLASSIFICATION,//  invoke the right unpack method depending on data type of the column 
Hive,WITHOUT_CLASSIFICATION,//  We couldn't do JDOQL filter pushdown. Get names via normal means. 
Hive,WITHOUT_CLASSIFICATION,//  core pool size 
Hive,WITHOUT_CLASSIFICATION,//  End HiveMetaHookLoader.java 
Hive,WITHOUT_CLASSIFICATION,//  prefix used to auto generated column aliases (this should be started with '_') 
Hive,WITHOUT_CLASSIFICATION,//  Nothing to compact update expr with compacted children. 
Hive,WITHOUT_CLASSIFICATION,//  Case when user has not specified any ingestion state in the current command   if there is a kafka supervisor running then keep it last known state is START otherwise STOP. 
Hive,WITHOUT_CLASSIFICATION,//  This is a local file 
Hive,WITHOUT_CLASSIFICATION,//  Not applicable. 
Hive,WITHOUT_CLASSIFICATION,//  This mapping collects all the configuration variables which have been set by the user   explicitly either via SET in the CLI the hiveconf option or a System property.   It is a mapping from the variable name to its value.  Note that if a user repeatedly 
Hive,WITHOUT_CLASSIFICATION,//  avoid traversing the tree later. To save memory this could be an array (of byte arrays?). 
Hive,WITHOUT_CLASSIFICATION,// fetch the row inserted before schema is altered and verify 
Hive,WITHOUT_CLASSIFICATION,//  Call the metastore to get the status of all known compactions (completed get purged eventually) 
Hive,WITHOUT_CLASSIFICATION,// txnId=0 means it's a select or IUD which does not write to ACID table e.g  insert overwrite table T partition(p=1) select ab from T and autoCommit=true 
Hive,WITHOUT_CLASSIFICATION,/*  allowComplex  */
Hive,WITHOUT_CLASSIFICATION,//  Temporarily.... 
Hive,WITHOUT_CLASSIFICATION,// See HCATALOG-499 
Hive,WITHOUT_CLASSIFICATION,//  Casts 
Hive,WITHOUT_CLASSIFICATION,//  Also print out the generic lineage information if there is any 
Hive,WITHOUT_CLASSIFICATION,//  This tells the pending update (if any) that whatever it is doing is irrelevant   and also makes sure we don't take the duck back twice if this is called twice. 
Hive,WITHOUT_CLASSIFICATION,//  Save previous longword. 
Hive,WITHOUT_CLASSIFICATION,//  initialize some variables which used to be initialized in CommonJoinOperator 
Hive,WITHOUT_CLASSIFICATION,//  the default fraction 
Hive,WITHOUT_CLASSIFICATION,//  return the passed in string value 
Hive,WITHOUT_CLASSIFICATION,//  cast int to double. 
Hive,WITHOUT_CLASSIFICATION,//  remove ${ .. } 
Hive,WITHOUT_CLASSIFICATION,//  Prepare output set the projections 
Hive,WITHOUT_CLASSIFICATION,// we don't deal with columns on RHS of SET expression since the whole expr is part of the  rewritten SQL statement and is thus handled by SemanticAnalzyer.  Nor do we have to  figure which cols on RHS are from source and which from target 
Hive,WITHOUT_CLASSIFICATION,//  type interval_day_time (IntervalDayTimeColumnVector). 
Hive,WITHOUT_CLASSIFICATION,//  this function is for internal use only 
Hive,WITHOUT_CLASSIFICATION,//  Cache mkey.group(1) 
Hive,WITHOUT_CLASSIFICATION,//  The current filters we use in ReplicationSemanticAnalyzer is as follows:      IMetaStoreClient.NotificationFilter evFilter = EventUtils.andFilter(          EventUtils.getDbTblNotificationFilter(dbNameOrPattern tblNameOrPattern)          EventUtils.getEventBoundaryFilter(eventFrom eventTo)          EventUtils.restrictByMessageFormat(MessageFactory.getInstance().getMessageFormat()));   So we test each of those three filters and then test andFilter itself. 
Hive,WITHOUT_CLASSIFICATION,//  Define how to pass options to the child process. If launching in client (or local)   mode the driver options need to be passed directly on the command line. Otherwise 
Hive,WITHOUT_CLASSIFICATION,//  cleanup pathToPartitionInfo 
Hive,WITHOUT_CLASSIFICATION,//  adjust noconditional task size threshold for LLAP 
Hive,WITHOUT_CLASSIFICATION,//  direct and not memory mapped 
Hive,WITHOUT_CLASSIFICATION,//  rs1 --- remove distinctColIndices set #reducer as -1 reset keys 
Hive,WITHOUT_CLASSIFICATION,//  Trigger post compilation hook. Note that if the compilation fails here then   before/after execution hook will never be executed. 
Hive,WITHOUT_CLASSIFICATION,//  2 original files 1 delta directory 1 delete_delta directory and 1 base directory 
Hive,WITHOUT_CLASSIFICATION,//  create an new operator: HashTableDummyOperator which share the table desc 
Hive,WITHOUT_CLASSIFICATION,//  finally create the vertex 
Hive,WITHOUT_CLASSIFICATION,//  Do not use datetime in tests to avoid result changes. 
Hive,WITHOUT_CLASSIFICATION,//  We keep track of all the contexts that are created by this query   so we can clear them when we finish execution 
Hive,WITHOUT_CLASSIFICATION,//  contract on EOF differs between DataInput and InputStream 
Hive,WITHOUT_CLASSIFICATION,//  Get the partition columns from the end of derivedSchema. 
Hive,WITHOUT_CLASSIFICATION,//  to a smaller prefix (MD5hash/000000_0) and later will stored as such in staging stats table.   When stats gets aggregated in StatsTask only the keys that starts with "prefix" will be fetched.   Now that (prefix/ds=__HIVE_DEFAULT_PARTITION__) is hashed to a smaller prefix it will   not be retrieved from staging table and hence not aggregated. To avoid this issue   we will remove the taskId from the key which is redundant anyway. 
Hive,WITHOUT_CLASSIFICATION,//  If the file is held by a writer will throw AlreadyBeingCreatedException 
Hive,WITHOUT_CLASSIFICATION,//  Cache uses allocator to allocate and deallocate create allocator and then caches. 
Hive,WITHOUT_CLASSIFICATION,//  This test with HDFS ACLs will only work if FileSystem.access() is available in the   version of hadoop-2 used to build Hive. 
Hive,WITHOUT_CLASSIFICATION,// Block until all semaphore resources are released  by outstanding async writes 
Hive,WITHOUT_CLASSIFICATION,//  try singular 
Hive,WITHOUT_CLASSIFICATION,//  PARENT_TBL_NAME 
Hive,WITHOUT_CLASSIFICATION,//  archiving / un-archiving process. 
Hive,WITHOUT_CLASSIFICATION,//  the epoch 
Hive,WITHOUT_CLASSIFICATION,//  If the V2 api of authorizer in use the session state getAuthorizer return null.   Here we disable authorization if we use V2 api or the DefaultHiveAuthorizationProvider   The additional authorization checks happening in hcatalog are designed to   work with  storage based authorization (on client side). It should not try doing   additional checks if a V2 authorizer or DefaultHiveAuthorizationProvider is in use.   The recommended configuration is to use storage based authorization in metastore server.   However if user define a custom V1 authorization it will be honored. 
Hive,WITHOUT_CLASSIFICATION,//  Don't allow swapping between virtual and materialized view in replace 
Hive,WITHOUT_CLASSIFICATION,//  Server will create new threads up to max as necessary. After an idle   period it will destroy threads to keep the number of threads in the 
Hive,WITHOUT_CLASSIFICATION,// runStatementOnDriver("truncate table Tstage"); 
Hive,WITHOUT_CLASSIFICATION,// we don't use the HadoopJobExecHooks for local tasks 
Hive,WITHOUT_CLASSIFICATION,//  Try pre-empting a task so that a higher priority task can take it's place. 
Hive,WITHOUT_CLASSIFICATION,//  Evaluate the column as a boolean converting if necessary. 
Hive,WITHOUT_CLASSIFICATION,//  We expect the start at 0 and count divisible by step. 
Hive,WITHOUT_CLASSIFICATION,//  repeating case for first (boolean flag) argument to IF 
Hive,WITHOUT_CLASSIFICATION,//  in both cases we move the file under destf 
Hive,WITHOUT_CLASSIFICATION,//  Stream offset in relation to the stripe.   1.1. Figure out which columns have a present stream 
Hive,WITHOUT_CLASSIFICATION,//  Set the fetch formatter to be a no-op for the ListSinkOperator since we'll   write out formatted thrift objects to SequenceFile 
Hive,WITHOUT_CLASSIFICATION,//  IS_EXTENDED 
Hive,WITHOUT_CLASSIFICATION,//  Declare this method as final for performance reasons 
Hive,WITHOUT_CLASSIFICATION,// ---------------------------------------------------------------------------   Multi-Key specific members.   
Hive,WITHOUT_CLASSIFICATION,//  Copy the data to the buffer 
Hive,WITHOUT_CLASSIFICATION,/*    * We use protected for the fields so the FastHiveDecimalImpl class can access them.  Other   * classes including HiveDecimal should not access these fields directly.    */
Hive,WITHOUT_CLASSIFICATION,//  TODO pass on this exception 
Hive,WITHOUT_CLASSIFICATION,//  Use the rowID directly 
Hive,WITHOUT_CLASSIFICATION,//  Finally start the server 
Hive,WITHOUT_CLASSIFICATION,//  Don't record encodings for unneeded columns. 
Hive,WITHOUT_CLASSIFICATION,//  2. Skip overwriting exisiting table object   (which is present because it was added after prewarm started) 
Hive,WITHOUT_CLASSIFICATION,//  sanity checks 
Hive,WITHOUT_CLASSIFICATION,//  ensure there is no operation related object leak 
Hive,WITHOUT_CLASSIFICATION,//  not actually a getter 
Hive,WITHOUT_CLASSIFICATION,//  this correlation to MuxOperators 
Hive,WITHOUT_CLASSIFICATION,//  verify zero-divide result for position 0 
Hive,WITHOUT_CLASSIFICATION,//  Parse until field separator (currentLevel). 
Hive,WITHOUT_CLASSIFICATION,//  In spark local mode we need to search added files in root directory. 
Hive,WITHOUT_CLASSIFICATION,//  The following loop should create 20 stripes in the orc file. 
Hive,WITHOUT_CLASSIFICATION,//  read split 
Hive,WITHOUT_CLASSIFICATION,//  Put the key/value into the map 
Hive,WITHOUT_CLASSIFICATION,//  if not using position alias and it is a number. 
Hive,WITHOUT_CLASSIFICATION,//  Binary sortable key serializer. 
Hive,WITHOUT_CLASSIFICATION,//  Must be deterministic order map for consistent q-test output across Java versions 
Hive,WITHOUT_CLASSIFICATION,//  for unit tests 
Hive,WITHOUT_CLASSIFICATION,//  Pass lineageState when a driver instantiates another Driver to run 
Hive,WITHOUT_CLASSIFICATION,//  still nothing Raise exception 
Hive,WITHOUT_CLASSIFICATION,//  this operation. 
Hive,WITHOUT_CLASSIFICATION,//  Needed to intercept readClassAndObject. 
Hive,WITHOUT_CLASSIFICATION,//  production: this.name | BaseType() | MapType() | SetType() | ListType() 
Hive,WITHOUT_CLASSIFICATION,//  PART_NAME 
Hive,WITHOUT_CLASSIFICATION,//  currently getPrimaryKeys always returns an empty resultset for Hive 
Hive,WITHOUT_CLASSIFICATION,//  ////// Generate GroupbyOperator for a map-side partial aggregation 
Hive,WITHOUT_CLASSIFICATION,//  in the general case. This set restricts automatic type conversion to just these functions. 
Hive,WITHOUT_CLASSIFICATION,// The default org.apache.hadoop.hive.ql.hooks.PreExecutePrinter hook 
Hive,WITHOUT_CLASSIFICATION,//  // Currently avg(distinct) not supported in PartitionEvaluator 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise the registry has not been initialized skip for the time being 
Hive,WITHOUT_CLASSIFICATION,//  Lazy object inspectors for string/char/varchar will all be cached in the same map. 
Hive,WITHOUT_CLASSIFICATION,//  See include/uapi/linux/stat.h 
Hive,WITHOUT_CLASSIFICATION,//  getFunctions() 
Hive,WITHOUT_CLASSIFICATION,//  skip the step to connect to the metastore. 
Hive,WITHOUT_CLASSIFICATION,//  Grab round digit from middle word. 
Hive,WITHOUT_CLASSIFICATION,//  This is a full outer join. This can never be a map-join   of any type. So return false. 
Hive,WITHOUT_CLASSIFICATION,//  We include failedUpdate only after looking at all the tasks at the same priority. 
Hive,WITHOUT_CLASSIFICATION,//  get a evaluator for a string concatenation expression 
Hive,WITHOUT_CLASSIFICATION,//  issue as would happen is there was a tiny delay on the network so we don't care. 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)  * @see org.apache.hadoop.mapreduce.lib.output.FileOutputFormat#getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)   */
Hive,WITHOUT_CLASSIFICATION,// For partitions flag controlling whether the current  table specs are to be used 
Hive,WITHOUT_CLASSIFICATION,//  generate the temporary file 
Hive,WITHOUT_CLASSIFICATION,// All must be selected otherwise size would be zero. Repeating property will not change. 
Hive,WITHOUT_CLASSIFICATION,// reset keyInited[mapSize] flag since it may be set to true in the case of previous empty entry 
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.SourceStateUpdatedRequestProto.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,//  Remove the dummy store operator from the tree 
Hive,WITHOUT_CLASSIFICATION,//  Check if the function is really removed 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see javax.sql.CommonDataSource#getLogWriter()    */
Hive,WITHOUT_CLASSIFICATION,//     addBaseFile(t p 20L 20); 
Hive,WITHOUT_CLASSIFICATION,//  We have to set up the bucketing columns differently for update and deletes 
Hive,WITHOUT_CLASSIFICATION,//  Here are some negative cases as below : 
Hive,WITHOUT_CLASSIFICATION,//  Use LinkedHashSet to give predictable display order. 
Hive,WITHOUT_CLASSIFICATION,//  Note: we could skip creating the table and just add table type stuff directly to the 
Hive,WITHOUT_CLASSIFICATION,/*    * This is the same as the setChildren method below but for empty tables.   * It takes care of the following:   * 1. Create the right object inspector.   * 2. Set up the childrenOpToOI with the object inspector.   * So as to ensure that the initialization happens correctly.    */
Hive,WITHOUT_CLASSIFICATION,//  varchar should take string length into account.   varchar(5) varchar(10) => varchar(10) 
Hive,WITHOUT_CLASSIFICATION,//  confirm the batch sizes were as expected 
Hive,WITHOUT_CLASSIFICATION,//  TXNS 
Hive,WITHOUT_CLASSIFICATION,//  Discard the blocks. 
Hive,WITHOUT_CLASSIFICATION,//  If partition columns occur in data we want to remove them. 
Hive,WITHOUT_CLASSIFICATION,//  Note: we pass in null factory because we allocate objects here. We could also pass a         per-call factory that would set fileKey; or set it after put. 
Hive,WITHOUT_CLASSIFICATION,//  same as in getRecordReader? 
Hive,WITHOUT_CLASSIFICATION,//  Check the cache first 
Hive,WITHOUT_CLASSIFICATION,//  the deserializer is responsible for actually reading each record from   the stream 
Hive,WITHOUT_CLASSIFICATION,//  in case of select(*) the data size does not change 
Hive,WITHOUT_CLASSIFICATION,//  Init parse context 
Hive,WITHOUT_CLASSIFICATION,//  Sort the objects first. You are guaranteed that if a partition is being locked   the table has already been locked 
Hive,WITHOUT_CLASSIFICATION,//  Revoke with grant option - only remove the grant option but keep the role. 
Hive,WITHOUT_CLASSIFICATION,//  create output row ObjectInspector 
Hive,WITHOUT_CLASSIFICATION,//  Generate (possibly get from a cached result) parent SparkTran 
Hive,WITHOUT_CLASSIFICATION,//  SUCCEEDED state 
Hive,WITHOUT_CLASSIFICATION,//  This function returns the grouping sets along with the grouping expressions   Even if rollups and cubes are present in the query they are converted to 
Hive,WITHOUT_CLASSIFICATION,//  Worthwhile only if more than 1 split consistentGroupingEnabled and is a FileSplit 
Hive,WITHOUT_CLASSIFICATION,//  exclude insert queries 
Hive,WITHOUT_CLASSIFICATION,//  Add TINYINT values 
Hive,WITHOUT_CLASSIFICATION,//  "key = 'val'" 
Hive,WITHOUT_CLASSIFICATION,//  verify that the actual action also went through 
Hive,WITHOUT_CLASSIFICATION,//  After one exception everything is expected to run 
Hive,WITHOUT_CLASSIFICATION,//  skip the next child since we already took care of it 
Hive,WITHOUT_CLASSIFICATION,//  Excepted 
Hive,WITHOUT_CLASSIFICATION,//  let's add a lot of constant rows to test the rle 
Hive,WITHOUT_CLASSIFICATION,//  Set the cookie max age to a very low value so that 
Hive,WITHOUT_CLASSIFICATION,//  change the key if need be 
Hive,WITHOUT_CLASSIFICATION,//  nothing to do if there is not a index definition for this table 
Hive,WITHOUT_CLASSIFICATION,//  First breaking up the filter conditions into equality   comparisons between rightJoinKeys(from the original   filterInputRel) and correlatedJoinKeys. correlatedJoinKeys   can be expressions while rightJoinKeys need to be input 
Hive,WITHOUT_CLASSIFICATION,//  Get most of the fields for the IDs provided. 
Hive,WITHOUT_CLASSIFICATION,//  This should be called rarely enough; for now it's ok to just lock every time. 
Hive,WITHOUT_CLASSIFICATION,//  The object [count LongWritable sum ResultType] is reused during evaluating 
Hive,WITHOUT_CLASSIFICATION,//  All parents should be reduce sinks. We pick the one we just walked   to choose the number of reducers. In the join/union case they will   all be -1. In sort/order case where it matters there will be only   one parent. 
Hive,WITHOUT_CLASSIFICATION,//  clear out any parents as reducer is the   root 
Hive,WITHOUT_CLASSIFICATION,//  final string 
Hive,WITHOUT_CLASSIFICATION,//  wait for stream threads to finish 
Hive,WITHOUT_CLASSIFICATION,//  It would be possible to support this but this is such a pointless command. 
Hive,WITHOUT_CLASSIFICATION,//  [-S|--silent] 
Hive,WITHOUT_CLASSIFICATION,//  Release all the locks acquired for this object   This becomes important for multi-table inserts when one branch may take much more   time than the others. It is better to release the lock for this particular insert.   The other option is to wait for all the branches to finish or set   hive.multi.insert.move.tasks.share.dependencies to true which will mean that the   first multi-insert results will be available when all of the branches of multi-table 
Hive,WITHOUT_CLASSIFICATION,//  We replace an earlier element must have lower offset. 
Hive,WITHOUT_CLASSIFICATION,//  validate Unset Non Existed Table Properties 
Hive,WITHOUT_CLASSIFICATION,//  We first do exact match and then do prefix matching. The latter is due to input dir   could be /dir/ds='2001-02-21'/part-03 where part-03 is not part of partition 
Hive,WITHOUT_CLASSIFICATION,//  Set the relevant information in the Configuration for the AccumuloInputFormat 
Hive,WITHOUT_CLASSIFICATION,//  TODO: vcpu settings - possibly when DRFA works right 
Hive,WITHOUT_CLASSIFICATION,//  We allocate triples so we cannot go above highest Integer power of 2 / 6. 
Hive,WITHOUT_CLASSIFICATION,//  Use NumDistinctValues if possible 
Hive,WITHOUT_CLASSIFICATION,//  replace the map join operator to local_map_join operator in the operator tree 
Hive,WITHOUT_CLASSIFICATION,//  path format -- > .../dataSource/interval/version/partitionNum/xxx.zip 
Hive,WITHOUT_CLASSIFICATION,//  Partition columns are repeated -- so we test element 0. 
Hive,WITHOUT_CLASSIFICATION,//  swap x and t1[h1(x)] 
Hive,WITHOUT_CLASSIFICATION,//  Test that existing shared_write table with new shared_write coalesces to 
Hive,WITHOUT_CLASSIFICATION,//  alter partitioned table rename partition 
Hive,WITHOUT_CLASSIFICATION,// 1 row is sufficient to know we have to kill the query 
Hive,WITHOUT_CLASSIFICATION,//  average value size will be sum of all sizes of aggregation buffers 
Hive,WITHOUT_CLASSIFICATION,//  Call addTranslation just to get the assertions for overlap 
Hive,WITHOUT_CLASSIFICATION,//  set up local work 
Hive,WITHOUT_CLASSIFICATION,//  If normalize() was used then day-hour-minute-second-nanos should have the same sign.   This is currently working with that assumption. 
Hive,WITHOUT_CLASSIFICATION,//  Validate the IN items are only constants. 
Hive,WITHOUT_CLASSIFICATION,// -1 indicates malformed version. 
Hive,WITHOUT_CLASSIFICATION,//  For a query of the type:   insert overwrite table T1   select * from (subq1 union all subq2)u;   subQ1 and subQ2 write to directories Parent/Child_1 and   Parent/Child_2 respectively and union is removed.   The movetask that follows subQ1 and subQ2 tasks moves the directory   'Parent' 
Hive,WITHOUT_CLASSIFICATION,// convert to lower case in case we are getting from serde 
Hive,WITHOUT_CLASSIFICATION,/*    * callback method used by subclasses to set the OutputOI on the Evaluator.    */
Hive,WITHOUT_CLASSIFICATION,//  The real implementation for the instanceset... instanceset has its own copy of the   ZK cache yet completely depends on the parent in every other aspect and is thus unneeded. 
Hive,WITHOUT_CLASSIFICATION,// from pre-acid insert 
Hive,WITHOUT_CLASSIFICATION,//  There should be different txn IDs associated with each lock. 
Hive,WITHOUT_CLASSIFICATION,//  ========= Master thread methods 
Hive,WITHOUT_CLASSIFICATION,//  list of columns comma separated 
Hive,WITHOUT_CLASSIFICATION,//  \1 followed by each element 
Hive,WITHOUT_CLASSIFICATION,//  Definitely a byte; most bytes fall here 
Hive,WITHOUT_CLASSIFICATION,//        supports all types 
Hive,WITHOUT_CLASSIFICATION,//  create a standard settable union object inspector 
Hive,WITHOUT_CLASSIFICATION,//  see also - code in CliDriver.java 
Hive,WITHOUT_CLASSIFICATION,//  This chicanery is to get around the fact that the table needs to be final in order to 
Hive,WITHOUT_CLASSIFICATION,//  Nothing special needs to be done for grouping sets if   this is the final group by operator and multiple rows corresponding to   the   grouping sets have been generated upstream.   However if an addition MR job has been created to handle grouping sets   additional rows corresponding to grouping sets need to be created here. 
Hive,WITHOUT_CLASSIFICATION,//  Ignore other types for purposes of authorization 
Hive,WITHOUT_CLASSIFICATION,//  Closed from ORC writer we still need the data. Do not discard anything. 
Hive,WITHOUT_CLASSIFICATION,//  Input #1 is type date (epochDays). 
Hive,WITHOUT_CLASSIFICATION,//  2. CPU cost = sorting cost (for each relation) + 
Hive,WITHOUT_CLASSIFICATION,//  Char 
Hive,WITHOUT_CLASSIFICATION,//  TODO: If the DB name from the creation metadata for any of the tables has changed 
Hive,WITHOUT_CLASSIFICATION,//  This won't usually be called otherwise. 
Hive,WITHOUT_CLASSIFICATION,// 'f' is the file whence this split is 
Hive,WITHOUT_CLASSIFICATION,//  Pop (list map) 
Hive,WITHOUT_CLASSIFICATION,//  call-1: listLocatedStatus - mock:/mocktable   call-2: check side file for mock:/mocktbl1/0_0   call-3: open - mock:/mocktbl1/0_0   call-4: check side file for  mock:/mocktbl1/0_1 
Hive,WITHOUT_CLASSIFICATION,//  find the right op 
Hive,WITHOUT_CLASSIFICATION,//  operations will be lost once owning session is closed. 
Hive,WITHOUT_CLASSIFICATION,//  Then try SERDEPROPERTIES 
Hive,WITHOUT_CLASSIFICATION,//  As of now only used for Bucket MapJoin there is exactly one event in the list. 
Hive,WITHOUT_CLASSIFICATION,//  if any the fields of struct are representing null then return true 
Hive,WITHOUT_CLASSIFICATION,//  class HCatAddPartitionDesc; 
Hive,WITHOUT_CLASSIFICATION,//  AST's are slightly different. 
Hive,WITHOUT_CLASSIFICATION,//  Whether the method takes variable-length arguments   Whether the method takes an array like Object[]   or String[] etc in the last argument. 
Hive,WITHOUT_CLASSIFICATION,// -------------------------------------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  For performance don't check that that the fieldRef isn't recId everytime   just assume that the caller used getAllStructFieldRefs and thus doesn't have that fieldRef 
Hive,WITHOUT_CLASSIFICATION,//  Recheck. 
Hive,WITHOUT_CLASSIFICATION,//  (Currently none)   innerBigOnlyPerBatchSetup(batch); 
Hive,WITHOUT_CLASSIFICATION,//  note that set basic stats false will wipe out column stats too. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setBinaryStream(int java.io.InputStream   * int)    */
Hive,WITHOUT_CLASSIFICATION,//  Subtraction with overflow check. Overflow produces NULL output. 
Hive,WITHOUT_CLASSIFICATION,//  UGI for the hive/_HOST (kerberos) principal 
Hive,WITHOUT_CLASSIFICATION,//  if archiving was done at this or at upper level every matched   partition would be archived so it not being archived means   no archiving was done neither at this nor at upper level 
Hive,WITHOUT_CLASSIFICATION,//  enabled for an ACID case and the file format is ORC. 
Hive,WITHOUT_CLASSIFICATION,// create LazyStruct with serialized string with expected separators 
Hive,WITHOUT_CLASSIFICATION,//  outputStream == null means we need to process it for explain formatted 
Hive,WITHOUT_CLASSIFICATION,//  Prefix used to specify module specific properties. Mainly to avoid conflicts with older unitTests properties 
Hive,WITHOUT_CLASSIFICATION,//  The aggregation buffer already contains a partial histogram. Therefore we need   to merge histograms using Algorithm #2 from the Ben-Haim and Tom-Tov paper. 
Hive,WITHOUT_CLASSIFICATION,//  Incase of ACID the file is ORC so the extension is not relevant and should not be inherited. 
Hive,WITHOUT_CLASSIFICATION,//  New partition for example 
Hive,WITHOUT_CLASSIFICATION,//  COL_VALS 
Hive,WITHOUT_CLASSIFICATION,//     hiveConf.setBoolVar(HiveConf.ConfVars.MERGE_CARDINALITY_VIOLATION_CHECK true); 
Hive,WITHOUT_CLASSIFICATION,//  bucketed mapjoin cannot be performed 
Hive,WITHOUT_CLASSIFICATION,//  constants for SPARSE encoding 
Hive,WITHOUT_CLASSIFICATION,//  Another thread might have already created these tables. 
Hive,WITHOUT_CLASSIFICATION,//  optional int32 version = 2; 
Hive,WITHOUT_CLASSIFICATION,//  There's a bug in ZKDelegationTokenSecretManager ctor where seconds are not converted to ms. 
Hive,WITHOUT_CLASSIFICATION,//  so clear timing in this thread's Hive object before proceeding. 
Hive,WITHOUT_CLASSIFICATION,//  Assign tables without nested column pruning info to the default conf 
Hive,WITHOUT_CLASSIFICATION,//  requires to calculate stats if new partition doesn't have it 
Hive,WITHOUT_CLASSIFICATION,//  test repeating case for null value 
Hive,WITHOUT_CLASSIFICATION,/*                * Single-Column Long specific save key.                */
Hive,WITHOUT_CLASSIFICATION,//  If this table is working with ACID semantics turn off merging 
Hive,WITHOUT_CLASSIFICATION,//  3. Get Right Table Alias 
Hive,WITHOUT_CLASSIFICATION,//  Initialize the list of event handlers 
Hive,WITHOUT_CLASSIFICATION,//  Since a key expression can be a calculation and the key will go into a scratch column 
Hive,WITHOUT_CLASSIFICATION,//  A do nothing vectorized expression that passes all rows through. 
Hive,WITHOUT_CLASSIFICATION,//  Load the current incremental dump and ensure it does nothing and lastReplID remains same 
Hive,WITHOUT_CLASSIFICATION,//  IMPORTANT IMPORTANT IMPORTANT!!!!!  The keys used to store info into the job Configuration.  If any new keys are added the HCatStorer needs to be updated. The HCatStorer  updates the job configuration in the backend to insert these keys to avoid  having to call setOutput from the backend (which would cause a metastore call 
Hive,WITHOUT_CLASSIFICATION,//  if there is an equivalent version return that else return this version 
Hive,WITHOUT_CLASSIFICATION,//  Now set one column nullable 
Hive,WITHOUT_CLASSIFICATION,/*    * Test the unsecure base case when neither hadoop nor job-specific   * credential provider is set    */
Hive,WITHOUT_CLASSIFICATION,//  REGULAR CREATE TABLE DDL 
Hive,WITHOUT_CLASSIFICATION,//  Removing semijoin optimization when it may not be beneficial 
Hive,WITHOUT_CLASSIFICATION,//  more then one part exist 
Hive,WITHOUT_CLASSIFICATION,/* skip cardinality violation clause */
Hive,WITHOUT_CLASSIFICATION,//  and it is not using this privilege mapping but it might make sense to move it here 
Hive,WITHOUT_CLASSIFICATION,//  Nanos converted to millis 
Hive,WITHOUT_CLASSIFICATION,//  If sleep fails we should exit now before things get worse. 
Hive,WITHOUT_CLASSIFICATION,//  Parser enforces that table alias is added but check again 
Hive,WITHOUT_CLASSIFICATION,//  Make sure the basic query properties are initialized 
Hive,WITHOUT_CLASSIFICATION,//  BRound without digits 
Hive,WITHOUT_CLASSIFICATION,//  The hiveJarDir can be determined once per client. 
Hive,WITHOUT_CLASSIFICATION,//  clear the mapredWork output file from outputs for CTAS   DDLWork at the tail of the chain will have the output 
Hive,WITHOUT_CLASSIFICATION,//  3. Allocate the buffers prepare cache keys. 
Hive,WITHOUT_CLASSIFICATION,//  we compress a fastbitset to 4 bytes 
Hive,WITHOUT_CLASSIFICATION,/*  PbB1  */
Hive,WITHOUT_CLASSIFICATION,//  Cannot rebuild not materialized view 
Hive,WITHOUT_CLASSIFICATION,//  Get notifications from metastore 
Hive,WITHOUT_CLASSIFICATION,//  Clean up the cache 
Hive,WITHOUT_CLASSIFICATION,// no need to (re-)initialize the currentUserName currentRoles fields 
Hive,WITHOUT_CLASSIFICATION,//  Cluster 
Hive,WITHOUT_CLASSIFICATION,//  Create a table so we can work against it 
Hive,WITHOUT_CLASSIFICATION,//  Ideally this should never happen and this should be an assert. 
Hive,WITHOUT_CLASSIFICATION,//  but default partition 
Hive,WITHOUT_CLASSIFICATION,//  should not be done for semijoin since it will change the semantics   Invert join inputs; this is done because otherwise the SemanticAnalyzer   methods to merge joins will not kick in 
Hive,WITHOUT_CLASSIFICATION,//  no negative scale decimals 
Hive,WITHOUT_CLASSIFICATION,//  required bytes input_event_proto_bytes = 1; 
Hive,WITHOUT_CLASSIFICATION,//  get the VInt that represents the map size 
Hive,WITHOUT_CLASSIFICATION,//  If SARG is present get relevant stripe metadata from cache or readers. 
Hive,WITHOUT_CLASSIFICATION,//  BytesWritable valueBytesWritable = (BytesWritable) valueWritable;   LOG.info("VectorReduceSinkCommonOperator collect keyWritable " + keyWritable.getLength() + " " +       VectorizedBatchUtil.displayBytes(keyWritable.getBytes() 0 keyWritable.getLength()) +       " valueWritable " + valueBytesWritable.getLength() +       VectorizedBatchUtil.displayBytes(valueBytesWritable.getBytes() 0 valueBytesWritable.getLength())); 
Hive,WITHOUT_CLASSIFICATION,// here means last txn in the batch is resolved but the close() hasn't been called yet so  there is nothing to heartbeat 
Hive,WITHOUT_CLASSIFICATION,//  tolerance to check float equality 
Hive,WITHOUT_CLASSIFICATION,// compute stats before compaction 
Hive,WITHOUT_CLASSIFICATION,//  2. We swap the join 
Hive,WITHOUT_CLASSIFICATION,//  Position before the last written value. 
Hive,WITHOUT_CLASSIFICATION,//  Followed by key and non-key input columns (some may be missing). 
Hive,WITHOUT_CLASSIFICATION,//  non-bean fields needed during compilation 
Hive,WITHOUT_CLASSIFICATION,//  Convert the remainders into a list that are AND'ed together. 
Hive,WITHOUT_CLASSIFICATION,//  0 size means no-pooling case - passthru. 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: It is critical to do this here so that log4j is reinitialized 
Hive,WITHOUT_CLASSIFICATION,//  Note that inputs and outputs can be changed when the query gets executed 
Hive,WITHOUT_CLASSIFICATION,//  output string. If no such replacement exists emit out the original input code point 
Hive,WITHOUT_CLASSIFICATION,//  ignore if it is a constant 
Hive,WITHOUT_CLASSIFICATION,//  100 <= x   start inclusive to infinity 
Hive,WITHOUT_CLASSIFICATION,//  avoid concurrent modification 
Hive,WITHOUT_CLASSIFICATION,//  create "virtual" row type for project only rename fields 
Hive,WITHOUT_CLASSIFICATION,//  Do the removal before we change the element to avoid invalid queue ordering. 
Hive,WITHOUT_CLASSIFICATION,//  second copy of red different object 
Hive,WITHOUT_CLASSIFICATION,// nothing actually hashes to bucket0 so update/delete deltas don't have it 
Hive,WITHOUT_CLASSIFICATION,// this is not likely to do the right thing for Compaction of "original" files when there are copyN files 
Hive,WITHOUT_CLASSIFICATION,//  table is not partitioned 
Hive,WITHOUT_CLASSIFICATION,//  We know we never went that far when we were inserting. 
Hive,WITHOUT_CLASSIFICATION,//  in this case we are actually scaling up.   we don't have to do complicated things because doing scaling-up   after   multiplication doesn't affect overflow (it doesn't happen or   happens anyways). 
Hive,WITHOUT_CLASSIFICATION,//  try to find in this input rel the position of cor var 
Hive,WITHOUT_CLASSIFICATION,// create input BytesWritable. This would have capacity greater than length)  
Hive,WITHOUT_CLASSIFICATION,// check we have right delete delta files after minor compaction 
Hive,WITHOUT_CLASSIFICATION,//  Remove the node if it has expired 
Hive,WITHOUT_CLASSIFICATION,//  If it is bucketing version skip it 
Hive,WITHOUT_CLASSIFICATION,/*  Maximum length seen so far  */
Hive,WITHOUT_CLASSIFICATION,//  convert to List as above Set was created using Sets.union (for reasons   explained there) 
Hive,WITHOUT_CLASSIFICATION,//  FOREIGN_KEYS 
Hive,WITHOUT_CLASSIFICATION,//  provide the path to the field in the error message 
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.PurgeCacheRequestProto.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,//  This is admittedly a bit simple StatsObjectConverter seems to allow   old stats attributes to be kept if the new values do not overwrite them. 
Hive,WITHOUT_CLASSIFICATION,//  Set non-hdfs tables to external unless transactional (should have been checked before this). 
Hive,WITHOUT_CLASSIFICATION,//  set the number of buckets here to ensure creation of empty buckets 
Hive,WITHOUT_CLASSIFICATION,//  see ColumnPrunerGroupByProc 
Hive,WITHOUT_CLASSIFICATION,//  corrupt last entry 
Hive,WITHOUT_CLASSIFICATION,// TODO check whether rowGroupOffSets can be null   then we need to apply the predicate push down filter 
Hive,WITHOUT_CLASSIFICATION,// volatile because heartbeat() may be in a "different" thread; updates of this are "piggybacking" 
Hive,WITHOUT_CLASSIFICATION,//  by position in the row schema of the filesink operator. 
Hive,WITHOUT_CLASSIFICATION,//  we can just stop all the sessions 
Hive,WITHOUT_CLASSIFICATION,//  length of "mixedUp" 
Hive,WITHOUT_CLASSIFICATION,//  Save original values 
Hive,WITHOUT_CLASSIFICATION,/*  Changes the type of the input references to adjust nullability  */
Hive,WITHOUT_CLASSIFICATION,/*  * Specialized class for doing a vectorized map join that is an outer join on a Single-Column Long * using a hash map.  */
Hive,WITHOUT_CLASSIFICATION,//  For multi-insert query currently we only optimize the FROM clause.   Hence introduce multi-insert token on top of it.   However first we need to reset existing token (insert).   Using qbp.getClauseNamesForDest().size() >= 2 would be   equivalent but we use == to avoid setting the property   multiple times 
Hive,WITHOUT_CLASSIFICATION,//  Verify ORC SARG still works. 
Hive,WITHOUT_CLASSIFICATION,//  opening the META table ensures that cluster is running 
Hive,WITHOUT_CLASSIFICATION,//  Simple case - no union.  
Hive,WITHOUT_CLASSIFICATION,/*  * An single STRING key hash multi-set optimized for vector map join. * * The key will be deserialized and just the bytes will be stored.  */
Hive,WITHOUT_CLASSIFICATION,/*      * Determine if there is only one TableScanOperator.  Currently in Map vectorization we do not     * try to vectorize multiple input trees.      */
Hive,WITHOUT_CLASSIFICATION,/*    * Gets new templeton controller objects.    */
Hive,WITHOUT_CLASSIFICATION,//  Set not null constraint name if null before sending to listener 
Hive,WITHOUT_CLASSIFICATION,//  given session i.e. the name can be fixed across all invocations 
Hive,WITHOUT_CLASSIFICATION,//  lets use the remaining space in column 1 as progress bar 
Hive,WITHOUT_CLASSIFICATION,// if mapper can span partitions make sure a splits does not contain multiple   opList + inputFormatClassName + deserializerClassName combination   This is done using the Map of CombinePathInputFormat to PathFilter 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * This provides a LazyHiveDecimal like class which can be initialized from data stored in a   * binary format.   *   * @see org.apache.hadoop.hive.serde2.lazy.LazyObject#init   *        (org.apache.hadoop.hive.serde2.lazy.ByteArrayRef int int)    */
Hive,WITHOUT_CLASSIFICATION,//  --- From here we evaluate the auto mode 
Hive,WITHOUT_CLASSIFICATION,//  Update source info if the state is SUCCEEDED 
Hive,WITHOUT_CLASSIFICATION,//  to these bottom layer ReduceSinkOperators. 
Hive,WITHOUT_CLASSIFICATION,//  delink union 
Hive,WITHOUT_CLASSIFICATION,//  No rounding. 
Hive,WITHOUT_CLASSIFICATION,//  Need to pass all of the columns used in the where clauses as reduce values 
Hive,WITHOUT_CLASSIFICATION,// opening the META table ensures that cluster is running 
Hive,WITHOUT_CLASSIFICATION,//  Now we take a local TZ offset at midnight UTC. Say we are in -4; that means (surprise 
Hive,WITHOUT_CLASSIFICATION,// Reject all paths to force it to continue.  When no more paths should throw an exception. 
Hive,WITHOUT_CLASSIFICATION,//  KERBEROS 
Hive,WITHOUT_CLASSIFICATION,//  that are not in our wordlist (eg. table and column names) 
Hive,WITHOUT_CLASSIFICATION,//  if we have too many results return null for a full scan 
Hive,WITHOUT_CLASSIFICATION,//  Add a NOT operator in the beginning (this is for the cloned operator because we 
Hive,WITHOUT_CLASSIFICATION,//  If start index is 0 in query that is equivalent to using 1 in query.   So internal offset is 0. 
Hive,WITHOUT_CLASSIFICATION,//  This happens when the code inside the JMX bean (setter?? from the   java docs) threw an exception so log it and fall back on the    class name 
Hive,WITHOUT_CLASSIFICATION,/*        * If Imported SerdeFormat is null then set it to "1" just as       * metadata.Table.getEmptyTable        */
Hive,WITHOUT_CLASSIFICATION,//  Bounded queue could be specified here but that will lead to blocking.   ConcurrentLinkedQueue is unbounded and will release soft referenced kryo instances under 
Hive,WITHOUT_CLASSIFICATION,//  1. Build GB Keys grouping set starting position 
Hive,WITHOUT_CLASSIFICATION,//  If there are no sample cols and no bucket cols then throw an error 
Hive,WITHOUT_CLASSIFICATION,//  raise error if we could not find the column 
Hive,WITHOUT_CLASSIFICATION,//  Offset by 4 because the first 4 frames are just calls to get down here. 
Hive,WITHOUT_CLASSIFICATION,/* In each group walk from most recent and count occurences of each state type.  Once you        * have counted enough (for each state) to satisfy retention policy delete all other        * instances of this status. */
Hive,WITHOUT_CLASSIFICATION,//  Case-sensitive string found 
Hive,WITHOUT_CLASSIFICATION,//  is created using field name 
Hive,WITHOUT_CLASSIFICATION,//  Let caller set negative sign if necessary. 
Hive,WITHOUT_CLASSIFICATION,//  Execute SELECT statement and verify the result set (should be two rows). 
Hive,WITHOUT_CLASSIFICATION,//  Delete functions created by the tests   It is enough to remove functions from the default database other databases are dropped 
Hive,WITHOUT_CLASSIFICATION,/*     * Expected result 0th entry is the RecordIdentifier + data.  1st entry file before compact */
Hive,WITHOUT_CLASSIFICATION,//  verify that the beginning entry is the only one that matches 
Hive,WITHOUT_CLASSIFICATION,//  Assumes one instance of this + single-threaded compilation for each query. 
Hive,WITHOUT_CLASSIFICATION,//  System registry should not be used to check persistent functions - see isPermanentFunc() 
Hive,WITHOUT_CLASSIFICATION,//  Estimated number of bytes needed. 
Hive,WITHOUT_CLASSIFICATION,//  Inactive nodes restart every call! 
Hive,WITHOUT_CLASSIFICATION,//  framework 
Hive,WITHOUT_CLASSIFICATION,// Binary arithmetic operator 
Hive,WITHOUT_CLASSIFICATION,//  pick the length of the first ptn we expect all ptns listed to have the same number of   key-vals. 
Hive,WITHOUT_CLASSIFICATION,//  create a new vertex 
Hive,WITHOUT_CLASSIFICATION,//  e.g. delta_0000001_0000001_0000 or base_0000022 
Hive,WITHOUT_CLASSIFICATION,//  Non-skewed value add it to list for later handle on default directory. 
Hive,WITHOUT_CLASSIFICATION,//  Update for next iteration 
Hive,WITHOUT_CLASSIFICATION,//  Copy to Java object because that saves object creation time.   Note that on average the number of copies is log(N) so that's not   very important. 
Hive,WITHOUT_CLASSIFICATION,//  Iterate through the batch and for each (owid rowid) in the batch   check if it is deleted or not. 
Hive,WITHOUT_CLASSIFICATION,//  track of the variable length keys 
Hive,WITHOUT_CLASSIFICATION,//  map from partID -> (statType->value) 
Hive,WITHOUT_CLASSIFICATION,//  Map the newly allocated write ids against the list of txns which doesn't have pre-allocated 
Hive,WITHOUT_CLASSIFICATION,//  round(longCol) returns a long and is a no-op. So it will not be implemented here. 
Hive,WITHOUT_CLASSIFICATION,// ---------------------------------------------------------------------------   Process Multi-Key Left-Semi Join on a vectorized row batch.   
Hive,WITHOUT_CLASSIFICATION,//  RESOURCE_PLAN 
Hive,WITHOUT_CLASSIFICATION,/*  operators for which the optimization will be successful  */
Hive,WITHOUT_CLASSIFICATION,//  For dummy partitions only partition name is needed 
Hive,WITHOUT_CLASSIFICATION,/*    * OI & Serde helper methods    */
Hive,WITHOUT_CLASSIFICATION,//  set some of parameters for prepared sql not all of them. 
Hive,WITHOUT_CLASSIFICATION,//  GROUPBY operator in reducer may not be processed in parallel. Skip optimizing. 
Hive,WITHOUT_CLASSIFICATION,//  parse analyze optimize and compile 
Hive,WITHOUT_CLASSIFICATION,/*      * Again with correct output type...      */
Hive,WITHOUT_CLASSIFICATION,//  specify the default log4j2 properties file. 
Hive,WITHOUT_CLASSIFICATION,//  Loop over the given inList elements. 
Hive,WITHOUT_CLASSIFICATION,//  1.1. Recurse over the subqueries to fill the subquery part of the plan 
Hive,WITHOUT_CLASSIFICATION,//  we are only interested in ExprNodeColumnDesc 
Hive,WITHOUT_CLASSIFICATION,//  Create a znode under the rootNamespace parent for this instance of the server   Znode name: serverUri=host:port;version=versionInfo;sequence=sequenceNumber 
Hive,WITHOUT_CLASSIFICATION,//  Extrapolation is needed for some columns.   In this case at least a column status for a partition is missing. 
Hive,WITHOUT_CLASSIFICATION,//  is there a insert in the subquery 
Hive,WITHOUT_CLASSIFICATION,//  Env interface to mock out dealing with Environment variables   This allows us to interface with Environment vars through   BeeLineOpts while allowing tests to mock out Env setting if needed. 
Hive,WITHOUT_CLASSIFICATION,//  Update the time if it hasn't been specified. 
Hive,WITHOUT_CLASSIFICATION,//  if it is a single item in an IN clause transform A IN (B) to A = B   from IN [AB] => EQUALS [AB]   except complex types 
Hive,WITHOUT_CLASSIFICATION,//  Remember we used this one in the query. 
Hive,WITHOUT_CLASSIFICATION,//  For each dynamic partition check if it needs to be merged. 
Hive,WITHOUT_CLASSIFICATION,/*  If this conversion is frequently used this should be optimized       * e.g. by converting to decimal from the input bytes directly without       * making a new string.        */
Hive,WITHOUT_CLASSIFICATION,//  This should only ever be called in testing scenarios.   There should not be any other users of the cache or its entries or this may mess up cleanup. 
Hive,WITHOUT_CLASSIFICATION,//  If the given value is a type of LazyObject then only try and convert it to that form. 
Hive,WITHOUT_CLASSIFICATION,/*    * Build a Hive-to-X column mapping   *    */
Hive,WITHOUT_CLASSIFICATION,//  Timer that reports every 5 minutes to the jobtracker. This ensures that   even if the operator returning rows for greater than that   duration a progress report is sent to the tracker so that the tracker   does not think that the job is dead. 
Hive,WITHOUT_CLASSIFICATION,//  creating the context can create a bunch of files. So make   sure to clear it out 
Hive,WITHOUT_CLASSIFICATION,//  Get and process the current datum 
Hive,WITHOUT_CLASSIFICATION,//  Keep "toRead" list for future use don't extract(). 
Hive,WITHOUT_CLASSIFICATION,//  3. IO cost = cost of transferring small tables to join node * 
Hive,WITHOUT_CLASSIFICATION,// primitives except binary 
Hive,WITHOUT_CLASSIFICATION,//  same test as above but with 3 jars sharing dependencies 
Hive,WITHOUT_CLASSIFICATION,//  This is where the spilling may happen again 
Hive,WITHOUT_CLASSIFICATION,//  Note: we might want to be smarter if threadId-s are low and there more arenas than threads. 
Hive,WITHOUT_CLASSIFICATION,//  NODE 
Hive,WITHOUT_CLASSIFICATION,//  of this operator. 
Hive,WITHOUT_CLASSIFICATION,//  COL 
Hive,WITHOUT_CLASSIFICATION,//  add children self to the front of the queue in that order 
Hive,WITHOUT_CLASSIFICATION,//  HIVE_SERVER2_SESSION_CHECK_INTERVAL is set to 3 seconds so we have to wait for at least 
Hive,WITHOUT_CLASSIFICATION,//  Note that we cannot allow users to provide app ID since providing somebody else's appId   would give one LLAP token (and splits) for that app ID. If we could verify it somehow   (YARN token? nothing we can do in an UDF) we could get it from client already running on   YARN. As such the clients running on YARN will have two app IDs to be aware of. 
Hive,WITHOUT_CLASSIFICATION,//  Negative max cache size means unbounded. 
Hive,WITHOUT_CLASSIFICATION,//  Switch to iterate foreign keys 
Hive,WITHOUT_CLASSIFICATION,// if there are un-compacted original files they will be included in compaction so 
Hive,WITHOUT_CLASSIFICATION,//  Tests for List<Partition> add_partitions(List<Partition> partitions   boolean ifNotExists boolean needResults) method 
Hive,WITHOUT_CLASSIFICATION,//  3/ test serialization and deserialization with different schemas 
Hive,WITHOUT_CLASSIFICATION,/*            * If we are moving the partition across filesystem boundaries           * inherit from the table properties. Otherwise (same filesystem) use the           * original partition location.           *           * See: HIVE-1707 and HIVE-2117 for background            */
Hive,WITHOUT_CLASSIFICATION,//  mutable thread-safe map to store instances 
Hive,WITHOUT_CLASSIFICATION,//  1.2 Add column info corresponding to partition columns 
Hive,WITHOUT_CLASSIFICATION,// default type is table 
Hive,WITHOUT_CLASSIFICATION,//  Case 3.3 - Now with 2000 entries try the above settings 
Hive,WITHOUT_CLASSIFICATION,//  Blurb list. 
Hive,WITHOUT_CLASSIFICATION,//  Process --deregister 
Hive,WITHOUT_CLASSIFICATION,//  Case 6: column stats NO hash aggregation grouping sets 
Hive,WITHOUT_CLASSIFICATION,//  Prevents throwing exceptions in our raw store calls since we're not using RawStoreProxy 
Hive,WITHOUT_CLASSIFICATION,//  STRING type in Hive is represented as VARCHAR with precision Integer.MAX_VALUE.   In turn the max VARCHAR precision should be 65535. However the value is not   used for validation but rather only internally by the optimizer to know the max   precision supported by the system. Thus no VARCHAR precision should fall between 
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.GetTokenRequestProto.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,//  of column name within regex pattern with its corresponding value if provided 
Hive,WITHOUT_CLASSIFICATION,//  auth has been initialized 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getTime(int java.util.Calendar)    */
Hive,WITHOUT_CLASSIFICATION,//  No such job. 
Hive,WITHOUT_CLASSIFICATION,//  submit the job 
Hive,WITHOUT_CLASSIFICATION,// try to replace a bucket map join with a sorted merge map join 
Hive,WITHOUT_CLASSIFICATION,//  Other formats can be converted to insert-only transactional tables 
Hive,WITHOUT_CLASSIFICATION,//  Do not update metrics - we didn't update on removal. 
Hive,WITHOUT_CLASSIFICATION,//  HADOOP-13155 fixed version: 2.8.0 3.0.0-alpha1 
Hive,WITHOUT_CLASSIFICATION,//  Moving tables/partitions depend on the dependencyTask 
Hive,WITHOUT_CLASSIFICATION,/*  * An single byte array value hash map based on the BytesBytesMultiHashMap. * * Since BytesBytesMultiHashMap does not interpret the key as BinarySortable we optimize * this case and just reference the byte array key directly for the lookup instead of serializing * the byte array into BinarySortable. We rely on it just doing byte array equality comparisons.  */
Hive,WITHOUT_CLASSIFICATION,//  Parse the json map. 
Hive,WITHOUT_CLASSIFICATION,//  Make a copy of the statement's result schema since we may 
Hive,WITHOUT_CLASSIFICATION,//  NOP 
Hive,WITHOUT_CLASSIFICATION,//  the number of children slots used 
Hive,WITHOUT_CLASSIFICATION,//  Remove from the runningTaskList 
Hive,WITHOUT_CLASSIFICATION,//  present 
Hive,WITHOUT_CLASSIFICATION,//  if embedded metastore is to be used as per config so far 
Hive,WITHOUT_CLASSIFICATION,//  Heartbeats on the txn table.  This commits so do not enter it with any state 
Hive,WITHOUT_CLASSIFICATION,// Since the user running the test won't belong to a non-existent group  foo_bar_group the call to getDelegationTokenStr will fail 
Hive,WITHOUT_CLASSIFICATION,//  nothing to do here 
Hive,WITHOUT_CLASSIFICATION,//  this is not a join condition. Will get handled by predicate pushdown. 
Hive,WITHOUT_CLASSIFICATION,// hcatConf.set(ConfVars.SEMANTIC_ANALYZER_HOOK.varname  		HCatSemanticAnalyzer.class.getName()); 
Hive,WITHOUT_CLASSIFICATION,//  A type date (LongColumnVector storing epoch days) minus a type date produces a   type interval_day_time (TimestampColumnVector storing nanosecond interval in 2 longs). 
Hive,WITHOUT_CLASSIFICATION,//  Add procedures as they can be invoked by functions 
Hive,WITHOUT_CLASSIFICATION,/*                * Single-Column Long specific lookup key.                */
Hive,WITHOUT_CLASSIFICATION,//  Here we are disconnecting root with its parents. However we need to save   a few information since in future we may reach the parent operators via a   different path and we may need to connect parent works with the work associated 
Hive,WITHOUT_CLASSIFICATION,//  This is used for tests where there's always just one batch of work and we do the   checks after the batch so the check will only come at the end of queueing. 
Hive,WITHOUT_CLASSIFICATION,//  report or forward 
Hive,WITHOUT_CLASSIFICATION,//  Found a semijoin branch.   There can be more than one semijoin branch coming from the parent 
Hive,WITHOUT_CLASSIFICATION,//  We assume that NO_RGS value is only set from SARG filter and for all columns;   intermediate changes for individual columns will unset values in the array.   Skip this case for 0-column read. We could probably special-case it just like we do   in EncodedReaderImpl but for now it's not that important. 
Hive,WITHOUT_CLASSIFICATION,//  This will be null at slave nodes. 
Hive,WITHOUT_CLASSIFICATION,//  At this point. 2 tasks running - both at priority 2. 
Hive,WITHOUT_CLASSIFICATION,//  Create our vector map join optimized hash table variation *above* the   map join table container. 
Hive,WITHOUT_CLASSIFICATION,//  4. HDFS session path 
Hive,WITHOUT_CLASSIFICATION,//  QUALIFIERS 
Hive,WITHOUT_CLASSIFICATION,//  This isn't really used for anything. 
Hive,WITHOUT_CLASSIFICATION,//  find proxy user if any from query param 
Hive,WITHOUT_CLASSIFICATION,//  Must be a struct 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:UserPayloadProto) 
Hive,WITHOUT_CLASSIFICATION,//  Schedule low pri first. When high pri is scheduled it takes away the duck from the   low pri task. When the high pri finishes low pri gets the duck back. 
Hive,WITHOUT_CLASSIFICATION,//  Compute join keys and store in reduceKeys 
Hive,WITHOUT_CLASSIFICATION,//  add new item to the Spark work 
Hive,WITHOUT_CLASSIFICATION,//  increase the row count 
Hive,WITHOUT_CLASSIFICATION,//  repl export has repl.last.id and repl.scope=all in it   import repl dump table has repl.last.id on it (will likely be 0) 
Hive,WITHOUT_CLASSIFICATION,//  update the log level for the specified logger 
Hive,WITHOUT_CLASSIFICATION,//  * If expression is UDF it is not permanent UDF 
Hive,WITHOUT_CLASSIFICATION,/*     we don't want to put any limits on this task as this is essential before we start    processing new database events.    */
Hive,WITHOUT_CLASSIFICATION,//  Local file system path for spilled hashMap   Status of hashMap. true: on disk false: in memory   When there's no enough memory cannot create hashMap   Used to create an empty BytesBytesMultiHashMap   Same as above   Same as above   How many rows saved to the on-disk hashmap (if on disk) 
Hive,WITHOUT_CLASSIFICATION,//  write the null byte every eight elements or   if this is the last element and serialize the 
Hive,WITHOUT_CLASSIFICATION,//  Traverse the byte buffer containing the input string one code point at a time 
Hive,WITHOUT_CLASSIFICATION,/*  UNDONE: Col Col vs Scalar Col vs Col Scalar    testCodeGen.addColumnColumnOperationTestCases(          className          inputColumnVectorType1          inputColumnVectorType2          "long");     */
Hive,WITHOUT_CLASSIFICATION,//  Convert the key/value pairs 
Hive,WITHOUT_CLASSIFICATION,//  try it again with an include vector 
Hive,WITHOUT_CLASSIFICATION,//  Runs a 'stat' against the servers. 
Hive,WITHOUT_CLASSIFICATION,//  One row (existence). 
Hive,WITHOUT_CLASSIFICATION,//  the one created here will not be added. 
Hive,WITHOUT_CLASSIFICATION,//  At least the header should fit. 
Hive,WITHOUT_CLASSIFICATION,// we have MIN_TXN MAX_TXN and IS_MAJOR in JobConf so we could figure out exactly what the dir  name is that we want to rename; leave it for another day 
Hive,WITHOUT_CLASSIFICATION,//  Unfortunately we cannot directly read a protected field of non-this object 
Hive,WITHOUT_CLASSIFICATION,//  The block is being moved; the move will release memory. 
Hive,WITHOUT_CLASSIFICATION,//  Put partial aggregation results in reduceValues 
Hive,WITHOUT_CLASSIFICATION,//  Stored here only as async operation context. 
Hive,WITHOUT_CLASSIFICATION,//  Use Calcite cost model for view rewriting 
Hive,WITHOUT_CLASSIFICATION,//  cannot optimize any others 
Hive,WITHOUT_CLASSIFICATION,//  BOOLEAN_STATS 
Hive,WITHOUT_CLASSIFICATION,//  This was the only predicate set filter expression to const 
Hive,WITHOUT_CLASSIFICATION,//  Pre-allocated member for storing any non-spills non-matches or merged row indexes during a 
Hive,WITHOUT_CLASSIFICATION,//  This hash function returns the same result as Double.hashCode()   while DoubleWritable.hashCode returns a different result. 
Hive,WITHOUT_CLASSIFICATION,//  Max file num and size used to do a single copy (after that distcp is used) 
Hive,WITHOUT_CLASSIFICATION,//  non-null column alias 
Hive,WITHOUT_CLASSIFICATION,//  Zero result. 
Hive,WITHOUT_CLASSIFICATION,//  Synthetic predicates from semijoin opt should not affect stats. 
Hive,WITHOUT_CLASSIFICATION,//  This is where counters are logged! 
Hive,WITHOUT_CLASSIFICATION,//  See the comment in handleUpdateForSinglePriorityLevel. 
Hive,WITHOUT_CLASSIFICATION,//  opNode's type is always either KW_EXISTS or KW_IN never NOTEXISTS or NOTIN    to figure this out we need to check it's grand parent's parent 
Hive,WITHOUT_CLASSIFICATION,//  Clear rounding portion in high longword and add 1 at right scale (roundMultiplyFactor);   middle and lower longwords result is 0; 
Hive,WITHOUT_CLASSIFICATION,//  If the function is distinct partial aggregation has not been done on   the client side.   If distPartAgg is set the client is letting us know that partial   aggregation has not been done.   For eg: select a count(b+c) count(distinct d+e) group by a   For count(b+c) if partial aggregation has been performed then we   directly look for count(b+c).   Otherwise we look for b+c.   For distincts partial aggregation is never performed on the client   side so always look for the parameters: d+e 
Hive,WITHOUT_CLASSIFICATION,//  Extract the sequence number of this ephemeral-sequential znode. 
Hive,WITHOUT_CLASSIFICATION,//  The extra non existing values will be ignored. 
Hive,WITHOUT_CLASSIFICATION,//  1. Additional data structures needed for the join optimization      through Hive 
Hive,WITHOUT_CLASSIFICATION,//  We could just do toLowerCase here and let SA qualify it but   let's be proper... 
Hive,WITHOUT_CLASSIFICATION,//  if it is not CTAS we don't need to go further and just return 
Hive,WITHOUT_CLASSIFICATION,//  remember which reducesinks we've already connected 
Hive,WITHOUT_CLASSIFICATION,/*   @Override  public com.esotericsoftware.kryo.io.Output getHybridBigTableSpillOutput(int partitionId) {    HybridHashTableContainer ht = (HybridHashTableContainer) mapJoinTableContainer;    HashPartition hp = ht.getHashPartitions()[partitionId];    return hp.getMatchfileOutput();  }   */
Hive,WITHOUT_CLASSIFICATION,//  create a dummy database and a couple of dummy tables 
Hive,WITHOUT_CLASSIFICATION,//  call-3: open - mock:/mocktbl2/0_0 
Hive,WITHOUT_CLASSIFICATION,//  tracks only running portion of the query. 
Hive,WITHOUT_CLASSIFICATION,//  object inspectors for input rows 
Hive,WITHOUT_CLASSIFICATION,//  and finally let's check output sizes 
Hive,WITHOUT_CLASSIFICATION,//  print vertexname 
Hive,WITHOUT_CLASSIFICATION,//  Test "alter table" with schema change 
Hive,WITHOUT_CLASSIFICATION,//  In case when user Ctrl-C twice to kill Hive CLI JVM we want to release locks 
Hive,WITHOUT_CLASSIFICATION,//  only if the column stats is available update the data size from   the column stats 
Hive,WITHOUT_CLASSIFICATION,//  read totalMonths from DataInput 
Hive,WITHOUT_CLASSIFICATION,// spit is marked isOriginal but it's not an immediate child of a partition nor is it in a  base/ or delta/ - this should never happen 
Hive,WITHOUT_CLASSIFICATION,//  is block-compressed? it should be always false. 
Hive,WITHOUT_CLASSIFICATION,// no order by as it's just 1 row 
Hive,WITHOUT_CLASSIFICATION,//  LEN_VALUE 
Hive,WITHOUT_CLASSIFICATION,//  add children to tasksToVisit 
Hive,WITHOUT_CLASSIFICATION,/*  Create a new distinctValueEstimator    */
Hive,WITHOUT_CLASSIFICATION,/*    * Apply the rules in the Spec. to fill in any missing pieces of every Window Specification   * also validate that the effective Specification is valid. The rules applied are:   * - For Wdw Specs that refer to Window Defns inherit missing components.   * - A Window Spec with no Parition Spec is Partitioned on a Constant(number 0)   * - For missing Wdw Frames or for Frames with only a Start Boundary completely specify them   *   by the rules in {@link effectiveWindowFrame}   * - Validate the effective Window Frames with the rules in {@link validateWindowFrame}   * - If there is no Order then add the Partition expressions as the Order.    */
Hive,WITHOUT_CLASSIFICATION,//  We store the chunk indices by split file; that way if several callers are reading   the same file they can separately store and remove the relevant parts of the index. 
Hive,WITHOUT_CLASSIFICATION,//  Invert words. 
Hive,WITHOUT_CLASSIFICATION,//  sort the list to get sorted (deterministic) output (for ease of testing) 
Hive,WITHOUT_CLASSIFICATION,// suppose it's the first Major compaction so we only have deltas 
Hive,WITHOUT_CLASSIFICATION,//  Long masks and values. 
Hive,WITHOUT_CLASSIFICATION,//  Join which are part of join keys 
Hive,WITHOUT_CLASSIFICATION,//  current write ids are not valid. 
Hive,WITHOUT_CLASSIFICATION,//  empty rows for each table 
Hive,WITHOUT_CLASSIFICATION,//  no value for kale 
Hive,WITHOUT_CLASSIFICATION,//  We need Partition-s for firing events and for result; DN needs MPartition-s to drop.   Great... Maybe we could bypass fetching MPartitions by issuing direct SQL deletes. 
Hive,WITHOUT_CLASSIFICATION,//  Change lock manager otherwise unit-test doesn't go through 
Hive,WITHOUT_CLASSIFICATION,//  if not a control character do nothing 
Hive,WITHOUT_CLASSIFICATION,//   - FunctionType 
Hive,WITHOUT_CLASSIFICATION,//  Emit the rest of word0. 
Hive,WITHOUT_CLASSIFICATION,//  Run Cleaner to delete rows for the aborted transaction 
Hive,WITHOUT_CLASSIFICATION,//  4. Add new rel & its RR to the maps 
Hive,WITHOUT_CLASSIFICATION,//  table alias (small) --> input file name (big) --> target file names (small) 
Hive,WITHOUT_CLASSIFICATION,//  This will happen in case of joins. The current plan can be thrown away   after being merged with the original plan 
Hive,WITHOUT_CLASSIFICATION,//  long column/column IF 
Hive,WITHOUT_CLASSIFICATION,//  Write back previous 8 field's NULL byte. 
Hive,WITHOUT_CLASSIFICATION,//  2/ serialize the union 
Hive,WITHOUT_CLASSIFICATION,// -1 is for internal (getAcidState()) purposes and means the delta dir  had no statement ID 
Hive,WITHOUT_CLASSIFICATION,//  load into compressed buf first 
Hive,WITHOUT_CLASSIFICATION,//  stores all the downloaded resources as key and the jars which depend on these resources as values in form of a list. Used for deleting transitive dependencies. 
Hive,WITHOUT_CLASSIFICATION,//  Verify that Hive is caching the object inspectors for us. 
Hive,WITHOUT_CLASSIFICATION,//  Explicitly using only the start offset of a split and not the length. Splits generated on   block boundaries and stripe boundaries can vary slightly. Try hashing both to the same node.   There is the drawback of potentially hashing the same data on multiple nodes though when a   large split is sent to 1 node and a second invocation uses smaller chunks of the previous   large split and send them to different nodes. 
Hive,WITHOUT_CLASSIFICATION,//  blank " " (1 byte)   NEW TAI LUE LETTER LOW BA U+19A5 (3 bytes) 
Hive,WITHOUT_CLASSIFICATION,// ----------------------------------------------------------------------------------------------   VALIDATION  ---------------------------------------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  Create an http client from the configs 
Hive,WITHOUT_CLASSIFICATION,//  Try opportunistically for the common case - the same-sized allocated buddy. 
Hive,WITHOUT_CLASSIFICATION,//  token expiration 
Hive,WITHOUT_CLASSIFICATION,// so that "explain" doesn't "leak" tmp tables 
Hive,WITHOUT_CLASSIFICATION,// if the exception is not 'NODEEXISTS' re-throw it 
Hive,WITHOUT_CLASSIFICATION,//  determine the query qualifies reduce input size for LIMIT   The query only qualifies when there are only one top operator   and there is no transformer or UDTF and no block sampling   is used. 
Hive,WITHOUT_CLASSIFICATION,//  finishes inside 
Hive,WITHOUT_CLASSIFICATION,//  Then write chunk bytes 
Hive,WITHOUT_CLASSIFICATION,//  dropFunction() 
Hive,WITHOUT_CLASSIFICATION,//  number of buckets 
Hive,WITHOUT_CLASSIFICATION,//  We're hijacking the big table evaluators an replace them with our own custom ones 
Hive,WITHOUT_CLASSIFICATION,// not allowed in w/o tx 
Hive,WITHOUT_CLASSIFICATION,//  If we're supporting dynamic service discovery we'll add the service uri for this   HiveServer2 instance to Zookeeper as a znode. 
Hive,WITHOUT_CLASSIFICATION,//  fill in colname 
Hive,WITHOUT_CLASSIFICATION,/*        * Take what all input formats support and eliminate any of them not enabled by       * the Hive variable.        */
Hive,WITHOUT_CLASSIFICATION,//  we always want to read all the delete delta files. 
Hive,WITHOUT_CLASSIFICATION,//  Init input object inspectors 
Hive,WITHOUT_CLASSIFICATION,//  How many blocks of this size comprise an arena. 
Hive,WITHOUT_CLASSIFICATION,//  reset buffer 
Hive,WITHOUT_CLASSIFICATION,//  If the loaded hash table is empty for some conditions we can skip processing the big table rows. 
Hive,WITHOUT_CLASSIFICATION,//  serialize work 
Hive,WITHOUT_CLASSIFICATION,//  fill the temp list before merging to sparse map 
Hive,WITHOUT_CLASSIFICATION,//  Null byte start 
Hive,WITHOUT_CLASSIFICATION,//  the SerDe part is from TestLazySimpleSerDe 
Hive,WITHOUT_CLASSIFICATION,//  At this point hinted semijoin case has been handled already   Check if big table is big enough that runtime filtering is 
Hive,WITHOUT_CLASSIFICATION,//  * NOT IN - always allow but always return true because later subq remove rule will generate diff plan for this case 
Hive,WITHOUT_CLASSIFICATION,//  rowId also found! 
Hive,WITHOUT_CLASSIFICATION,//  this assumes no splitting 
Hive,WITHOUT_CLASSIFICATION,//  6. Translate Window spec 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#getResultSetConcurrency()    */
Hive,WITHOUT_CLASSIFICATION,//  Get length word. 
Hive,WITHOUT_CLASSIFICATION,/*    * True if same value repeats for whole column vector.   * If so vector[0] holds the repeating value.    */
Hive,WITHOUT_CLASSIFICATION,//  default tokenstore is MemoryTokenStore 
Hive,WITHOUT_CLASSIFICATION,//  fetch table alias 
Hive,WITHOUT_CLASSIFICATION,//  Retrieve not null constraints 
Hive,WITHOUT_CLASSIFICATION,//  set output collector for any reduce sink operators in the pipeline. 
Hive,WITHOUT_CLASSIFICATION,//  Preserve the old behavior of failing when we cannot write even w/o deleteData   and even if the table is external. That might not make any sense. 
Hive,WITHOUT_CLASSIFICATION,/*      * Consider a query like:     *     * select count(*) from     *   (     *     select key count(*) from     *       (     *         select --mapjoin(a)-- a.key as key a.value as val1 b.value as val2     *         from tbl1 a join tbl2 b on a.key = b.key     *       ) subq1     *     group by key     *   ) subq2;     *     * The table alias should be subq2:subq1:a which needs to be fetched from topOps.      */
Hive,WITHOUT_CLASSIFICATION,//  But if snapshot is not valid we recompile the query. 
Hive,WITHOUT_CLASSIFICATION,//  using init(..) instead of this(..) because the new HCatReplicationTaskIteratorNotificationFilter   is an operation that needs to run before delegating to the other ctor and this messes up chaining   ctors 
Hive,WITHOUT_CLASSIFICATION,//  Add FSD so that the LoadTask compilation could fix up its path to avoid the move. 
Hive,WITHOUT_CLASSIFICATION,//  map from tablename to task (ColumnStatsTask which includes a BasicStatsTask) 
Hive,WITHOUT_CLASSIFICATION,//  Reset to correct http path 
Hive,WITHOUT_CLASSIFICATION,//  for the following method. 
Hive,WITHOUT_CLASSIFICATION,//  This can change based on new splits. 
Hive,WITHOUT_CLASSIFICATION,/*  dfs.  */
Hive,WITHOUT_CLASSIFICATION,//  Proceed if AST contains partition & If Not Exists 
Hive,WITHOUT_CLASSIFICATION,//  -------------------------------------------------------------------------------   VERTICES: 03/04            [=================>>-----] 86%  ELAPSED TIME: 1.71 s   -------------------------------------------------------------------------------   contains footerSummary  progressedPercentage starTime 
Hive,WITHOUT_CLASSIFICATION,/*     * The below loop may perform bad when the destination file already exists and it has too many _copy_    * files as well. A desired approach was to call listFiles() and get a complete list of files from    * the destination and check whether the file exists or not on that list. However millions of files    * could live on the destination directory and on concurrent situations this can cause OOM problems.    *    * I'll leave the below loop for now until a better approach is found.     */
Hive,WITHOUT_CLASSIFICATION,//  repl-imports are replace-into unless the event is insert-into 
Hive,WITHOUT_CLASSIFICATION,// Hive Date is representable as Pig DATETIME 
Hive,WITHOUT_CLASSIFICATION,//  So table "t1" and "t2" will exist and partition "india" will exist rest failed as operation failed. 
Hive,WITHOUT_CLASSIFICATION,//  In tests. 
Hive,WITHOUT_CLASSIFICATION,//  Use threads to resolve directories into splits. 
Hive,WITHOUT_CLASSIFICATION,//  process group-by pattern 
Hive,WITHOUT_CLASSIFICATION,//  Must be called under the epic lock. 
Hive,WITHOUT_CLASSIFICATION,//  call-2: open to read data - split 2 => mock:/mocktable2/0_1 
Hive,WITHOUT_CLASSIFICATION,//  If we are doing an update or a delete the number of columns in the table will not   match the number of columns in the file sink.  For update there will be one too many   (because of the ROW__ID) and in the case of the delete there will be just the   ROW__ID which we don't need to worry about from a lineage perspective. 
Hive,WITHOUT_CLASSIFICATION,//  Print the results 
Hive,WITHOUT_CLASSIFICATION,//  we don't allow turning on auto parallel once it has been   explicitly turned off. That is to avoid scenarios where   auto parallelism could break assumptions about number of   reducers or hash function. 
Hive,WITHOUT_CLASSIFICATION,//  The bottom layer ReduceSinkOperators. These ReduceSinkOperators are used   to record the boundary of this sub-tree which can be evaluated in a single MR 
Hive,WITHOUT_CLASSIFICATION,//  This shouldn't ever happen 
Hive,WITHOUT_CLASSIFICATION,//  UNION_FIELD1 
Hive,WITHOUT_CLASSIFICATION,//  reevaluate expression on current Row to trigger the Lazy object   caches to be reset to the current row. 
Hive,WITHOUT_CLASSIFICATION,// Reuse record reader ID 
Hive,WITHOUT_CLASSIFICATION,/*  Order by clause  */
Hive,WITHOUT_CLASSIFICATION,//  ~ Instance fields -------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,/*    * Return true or false based on whether a bucketed mapjoin can be converted successfully to   * a sort-merge map join operator. The following checks are performed:   * a. The mapjoin under consideration is a bucketed mapjoin.   * b. All the tables are sorted in same order such that join columns is equal to or a prefix   *    of the sort columns.    */
Hive,WITHOUT_CLASSIFICATION,//  trailing blank field 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getTime(java.lang.String   * java.util.Calendar)    */
Hive,WITHOUT_CLASSIFICATION,//  Convenient constructor for initial batch creation takes 
Hive,WITHOUT_CLASSIFICATION,//  test that zero-divide produces null for all output values 
Hive,WITHOUT_CLASSIFICATION,//  Check that write id is still valid 
Hive,WITHOUT_CLASSIFICATION,//  evaluate the aggregators 
Hive,WITHOUT_CLASSIFICATION,//  Matches only JoinOperators which are reducers rather than map joins SMB map joins etc. 
Hive,WITHOUT_CLASSIFICATION,//  Temp partition input path does not match exist temp path 
Hive,WITHOUT_CLASSIFICATION,//  no munging inner-schemas 
Hive,WITHOUT_CLASSIFICATION,//  approximate 
Hive,WITHOUT_CLASSIFICATION,//  Reset for the new partition 
Hive,WITHOUT_CLASSIFICATION,//  RG filtered. 
Hive,WITHOUT_CLASSIFICATION,//  Fill high long from some of middle long. 
Hive,WITHOUT_CLASSIFICATION,//  store the orc configuration from the first file. All other files should 
Hive,WITHOUT_CLASSIFICATION,//  UNION_FIELD3 
Hive,WITHOUT_CLASSIFICATION,//  1) If join is not a left or right outer we bail out   2) If any sort column is not part of the input where the 
Hive,WITHOUT_CLASSIFICATION,//  If there are no functions it doesn't matter as much whether we   aggregate the inputs before the join because there will not be   any functions experiencing a cartesian product effect.     But finding out whether the input is already unique requires a call   to areColumnsUnique that currently (until [CALCITE-1048] "Make   metadata more robust" is fixed) places a heavy load on   the metadata system.     So we choose to imagine the the input is already unique which is   untrue but harmless.   
Hive,WITHOUT_CLASSIFICATION,//  Export valid directories with a modified name so they don't look like bases/deltas.   We could also dump the delta contents all together and rename the files if names collide. 
Hive,WITHOUT_CLASSIFICATION,//  Overridden and used in ProcessingModeReduceMergePartial mode. 
Hive,WITHOUT_CLASSIFICATION,//  in case the empty grouping set is preset; but no output has done   the "summary row" still needs to be emitted 
Hive,WITHOUT_CLASSIFICATION,//  If aborted - break out of the loop and cancel all subsequent futures. 
Hive,WITHOUT_CLASSIFICATION,//  MAX_COL_LEN 
Hive,WITHOUT_CLASSIFICATION,//  The non-MM path only finds new partitions as it is looking at the temp path.   To produce the same effect we will find all the partitions affected by this txn ID.   Note: we ignore the statement ID here because it's currently irrelevant for MoveTask         where this is used; we always want to load everything; also the only case where         we have multiple statements anyway is union. 
Hive,WITHOUT_CLASSIFICATION,//  We only retrieve the materialization corresponding to the rebuild. In turn   we pass 'true' for the forceMVContentsUpToDate parameter as we cannot allow the   materialization contents to be stale for a rebuild if we want to use it. 
Hive,WITHOUT_CLASSIFICATION,//  The value for the constant does not matter. It is replaced by the grouping set   value for the actual implementation 
Hive,WITHOUT_CLASSIFICATION,//  Do the columns used by the join appear in the output of the aggregate? 
Hive,WITHOUT_CLASSIFICATION,//  Test that locking a database prevents locking of tables in the database 
Hive,WITHOUT_CLASSIFICATION,//  We must ensure the exactness of the double's fractional portion.   0.6 as the fraction part will be converted to 0.59999... and   significantly reduce the savings from binary serialization 
Hive,WITHOUT_CLASSIFICATION,//  outputs is empty which means this create table happens in the current 
Hive,WITHOUT_CLASSIFICATION,// clean the staging table 
Hive,WITHOUT_CLASSIFICATION,// this needs major compaction 
Hive,WITHOUT_CLASSIFICATION,//  Allocate writeId to txn under HWM. This will get Id greater than a txn > HWM. 
Hive,WITHOUT_CLASSIFICATION,// support for authorization on partitions needs to be added 
Hive,WITHOUT_CLASSIFICATION,//  start the creation of znodes 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: We cannot use copySelected below since it is a whole column operation. 
Hive,WITHOUT_CLASSIFICATION,//  Get the output ObjectInspector from the return type. 
Hive,WITHOUT_CLASSIFICATION,//  and put it to WriteEntity for post-exec hook 
Hive,WITHOUT_CLASSIFICATION,//  Derby commandline parser 
Hive,WITHOUT_CLASSIFICATION,//  If destPath directory exists rename call will move the srcPath   into destPath without failing. So check it before renaming. 
Hive,WITHOUT_CLASSIFICATION,//  used for avoid extra byte copy 
Hive,WITHOUT_CLASSIFICATION,//  updated only when a thread has failed. 
Hive,WITHOUT_CLASSIFICATION,//  All columns have to be primitive. 
Hive,WITHOUT_CLASSIFICATION,//  UNION_FIELD2 
Hive,WITHOUT_CLASSIFICATION,//  TBL_VALID_WRITE_IDS 
Hive,WITHOUT_CLASSIFICATION,//  Truncate a table 
Hive,WITHOUT_CLASSIFICATION,//  Interleaved writes to both batches 
Hive,WITHOUT_CLASSIFICATION,//  Governs remote-fetch-input behaviour   If set to true we'll assume that the input has a _files file present which lists     the actual input files to copy and we'll pull each of those on read.   If set to false it'll behave as a traditional CopyTask. 
Hive,WITHOUT_CLASSIFICATION,//  1) We extract the group by positions that are part of the collations and   sort them so they respect it 
Hive,WITHOUT_CLASSIFICATION,//  Try to transform OR predicates in Filter into simpler IN clauses first 
Hive,WITHOUT_CLASSIFICATION,/*  * The equality is implemented fully the greater-than/less-than * values do not implement a transitive relation.   */
Hive,WITHOUT_CLASSIFICATION,//  OUTPUT_FORMAT 
Hive,WITHOUT_CLASSIFICATION,//  This join has already been processed 
Hive,WITHOUT_CLASSIFICATION,//  End HiveReduceExpressionsRule.java 
Hive,WITHOUT_CLASSIFICATION,//  nonblocking execute 
Hive,WITHOUT_CLASSIFICATION,//  Do nothing for other modes 
Hive,WITHOUT_CLASSIFICATION,//  parse a key 
Hive,WITHOUT_CLASSIFICATION,//  the subtree to gather the references 
Hive,WITHOUT_CLASSIFICATION,//  Now for each entry in the queue see if all of the associated locks are clear so we 
Hive,WITHOUT_CLASSIFICATION,//  fully-specified partition 
Hive,WITHOUT_CLASSIFICATION,//  twice or more skip dedup. 
Hive,WITHOUT_CLASSIFICATION,//  For now there's nothing special to return in addedVals. Just return the footer. 
Hive,WITHOUT_CLASSIFICATION,//  now create the new project 
Hive,WITHOUT_CLASSIFICATION,//  for now require select WITH GRANT 
Hive,WITHOUT_CLASSIFICATION,// now test that we don't timeout locks we should not 
Hive,WITHOUT_CLASSIFICATION,//  Implementations may choose to override this 
Hive,WITHOUT_CLASSIFICATION,//  Have to set it for each partition too 
Hive,WITHOUT_CLASSIFICATION,//  output file system information 
Hive,WITHOUT_CLASSIFICATION,//  [A: 0 B: 0 B.x: 0 B.y: 0 C: 0] 
Hive,WITHOUT_CLASSIFICATION,// With nulls 
Hive,WITHOUT_CLASSIFICATION,//  Forward the current keys if needed for sort-based aggregation 
Hive,WITHOUT_CLASSIFICATION,//  Local time zone. Store separately because Calendar would clone it. 
Hive,WITHOUT_CLASSIFICATION,//  Write out the first 63 bits worth of data. 
Hive,WITHOUT_CLASSIFICATION,// should this be escaped string? 
Hive,WITHOUT_CLASSIFICATION,//  Reset member variables so we don't get in a half-constructed state 
Hive,WITHOUT_CLASSIFICATION,//  Note that the state of the failed service is still INITED and not   STARTED. Even though the last service is not started completely still   call stop() on all services including failed service to make sure cleanup   happens. 
Hive,WITHOUT_CLASSIFICATION,//  iterator cursor in the currBlock   size of current read block   append cursor in the lastBlock   serialization/deserialization for the row   object inspector for the row 
Hive,WITHOUT_CLASSIFICATION,// if lock is part of txn heartbeat info is in txn record 
Hive,WITHOUT_CLASSIFICATION,//  make sure the null flag agrees 
Hive,WITHOUT_CLASSIFICATION,//  alert if we already running low on memory (starting with low memory will lead to frequent auto flush) 
Hive,WITHOUT_CLASSIFICATION,//  Add this condition to the list of non-equi-join conditions. 
Hive,WITHOUT_CLASSIFICATION,//  2.1. Backtracking from RS 
Hive,WITHOUT_CLASSIFICATION,//  List of TezWork.Dependency 
Hive,WITHOUT_CLASSIFICATION,//  create the project before GB 
Hive,WITHOUT_CLASSIFICATION,//  Now we have written all information about the next value work on the *new* value. 
Hive,WITHOUT_CLASSIFICATION,//  tez task we're currently processing 
Hive,WITHOUT_CLASSIFICATION,//  Set 'version' 
Hive,WITHOUT_CLASSIFICATION,//  We allow stateful functions in the SELECT list (but nowhere else) 
Hive,WITHOUT_CLASSIFICATION,//  Accurate byte value cannot be obtained. 
Hive,WITHOUT_CLASSIFICATION,//  If we didn't find the Token we can't proceed. Log the tokens for debugging. 
Hive,WITHOUT_CLASSIFICATION,//  The key is missing - shouldn't be able to verify. 
Hive,WITHOUT_CLASSIFICATION,//  Note. If the materialized view does not contain a table that is contained in the query   we do not need to check whether that specific table is outdated or not. If a rewriting   is produced in those cases it is because that additional table is joined with the   existing tables with an append-columns only join i.e. PK-FK + not null. 
Hive,WITHOUT_CLASSIFICATION,//  True if only one value is null 
Hive,WITHOUT_CLASSIFICATION,//  Initialize 1.2.0 schema 
Hive,WITHOUT_CLASSIFICATION,//  Exponent E or e. 
Hive,WITHOUT_CLASSIFICATION,//  Type affinity does not help when multiple methods have the same type affinity. 
Hive,WITHOUT_CLASSIFICATION,//  RETENTION 
Hive,WITHOUT_CLASSIFICATION,//  Convert valueList to array for the ListColumnVector.child 
Hive,WITHOUT_CLASSIFICATION,//  Map needs two separators (key and key/value pair). 
Hive,WITHOUT_CLASSIFICATION,// Save compile-time PerfLogging for WebUI.  Execution-time Perf logs are done by either another thread's PerfLogger  or a reset PerfLogger. 
Hive,WITHOUT_CLASSIFICATION,//  at this point the number of reducers is precisely defined in the plan 
Hive,WITHOUT_CLASSIFICATION,//  Allowed operations:   IntervalYearMonth - IntervalYearMonth = IntervalYearMonth   Date - IntervalYearMonth = Date (operands not reversible)   Timestamp - IntervalYearMonth = Timestamp (operands not reversible)   IntervalDayTime - IntervalDayTime = IntervalDayTime   Date - IntervalYearMonth = Timestamp (operands not reversible)   Timestamp - IntervalYearMonth = Timestamp (operands not reversible)   Timestamp - Timestamp = IntervalDayTime   Date - Date = IntervalDayTime   Timestamp - Date = IntervalDayTime (operands reversible) 
Hive,WITHOUT_CLASSIFICATION,//  For performance reasons we do not want to chase the values to the end to determine   the count.  Use hasRows and isSingleRow instead. 
Hive,WITHOUT_CLASSIFICATION,//  initializeAlpha(DEFAULT_HASH_BITS); 
Hive,WITHOUT_CLASSIFICATION,//  special handling for serde reader (text) in llap IO.   if file format version is null then we are processing text IF in LLAP IO in which case   we get vectors instead of streams. If vectors contain instance of Decimal64ColumnVector we   should use Decimal64StreamReader (which acts as a wrapper around vectors) 
Hive,WITHOUT_CLASSIFICATION,//  Simulate a missing table scenario by renaming a couple of tables 
Hive,WITHOUT_CLASSIFICATION,//  6. Generate table access stats if required 
Hive,WITHOUT_CLASSIFICATION,//  will always excuse the first error. We can decide if single 
Hive,WITHOUT_CLASSIFICATION,//  App never seen or previous dag has been unregistered. 
Hive,WITHOUT_CLASSIFICATION,//  Not affected or the op is not about transactional. 
Hive,WITHOUT_CLASSIFICATION,//  we need the directory on hdfs to which we shall put all these files 
Hive,WITHOUT_CLASSIFICATION,//  set third argument to IF 
Hive,WITHOUT_CLASSIFICATION,//  Pre-allocated member for storing the (physical) batch index of rows that need to be spilled. 
Hive,WITHOUT_CLASSIFICATION,//  Verify if all the aborted write ids are replicated to the replicated DB 
Hive,WITHOUT_CLASSIFICATION,//  compare stats obj to ensure what we get is what we wrote 
Hive,WITHOUT_CLASSIFICATION,//  add Token only if it already doesn't exist 
Hive,WITHOUT_CLASSIFICATION,//  If we allow estimated stats for the columns then we shall set the boolean to true   since otherwise we will throw an exception because columns with stimated stats are   actually added to the list of columns that do not contain stats. 
Hive,WITHOUT_CLASSIFICATION,//  don't make a copy if we don't have to  noinspection unchecked 
Hive,WITHOUT_CLASSIFICATION,//  cannot convert to map join; we've already chosen a big table   on size and there's another one that's bigger. 
Hive,WITHOUT_CLASSIFICATION,// decimal place 
Hive,WITHOUT_CLASSIFICATION,//  optional bool result = 1; 
Hive,WITHOUT_CLASSIFICATION,//  wrapper class for reading and writing metadata about a dump   responsible for _dumpmetadata files 
Hive,WITHOUT_CLASSIFICATION,//  do not throw exception if table does not exist 
Hive,WITHOUT_CLASSIFICATION,//  cannot do delimited split for some commands like "dfs -cat" that prints the contents of file which may have   different delimiter. so we will split only when the resultSchema has more than 1 column 
Hive,WITHOUT_CLASSIFICATION,//  ColumnizedDeleteEventRegistry loads all the delete events from all the delete deltas   into memory. To prevent out-of-memory errors this check is a rough heuristic that   prevents creation of an object of this class if the total number of delete events   exceed this value. By default it has been set to 10 million delete events per bucket. 
Hive,WITHOUT_CLASSIFICATION,//  The id of the job this tracking node represents 
Hive,WITHOUT_CLASSIFICATION,//  keys are the column names. basically this maps the position of the column   in 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setAsciiStream(java.lang.String   * java.io.InputStream long)    */
Hive,WITHOUT_CLASSIFICATION,// get tokens for all other known FSs since Hive tables may result in different ones 
Hive,WITHOUT_CLASSIFICATION,// for some reason this just locks the table; if I alter table to add this partition then  we end up locking both table and partition with share_read.  (Plan has 2 ReadEntities)...?  same for other locks below 
Hive,WITHOUT_CLASSIFICATION,//  LEVEL 
Hive,WITHOUT_CLASSIFICATION,//  If input (GBY) is different than the source of columns find the   same column in input. 
Hive,WITHOUT_CLASSIFICATION,//  (conjuctive elements) 
Hive,WITHOUT_CLASSIFICATION,//  key contains scheme (such as pfile://) and we want only the path portion fix in HIVE-6366 
Hive,WITHOUT_CLASSIFICATION,//  empty array? 
Hive,WITHOUT_CLASSIFICATION,// key is correct 
Hive,WITHOUT_CLASSIFICATION,// lastAccessTime < 90 
Hive,WITHOUT_CLASSIFICATION,//  no support for statistics 
Hive,WITHOUT_CLASSIFICATION,//  With the fast hash table implementation we currently do not support   Hybrid Grace Hash Join. 
Hive,WITHOUT_CLASSIFICATION,//  Llap server depends on Hive execution so the reverse cannot be true. We create the I/O   singleton once (on daemon startup); the said singleton serves as the IO interface. 
Hive,WITHOUT_CLASSIFICATION,//  finally monitor will print progress until the job is done 
Hive,WITHOUT_CLASSIFICATION,//  [0 1 2 0] --> [T1.0 T1.1 T1.2 T2.0] (table columns mapping) 
Hive,WITHOUT_CLASSIFICATION,//  Always generate a list with at least 1 value? 
Hive,WITHOUT_CLASSIFICATION,//  Lock was outdated and it was removed (then maybe another transaction picked it up) 
Hive,WITHOUT_CLASSIFICATION,//  "1234567" => unscaledValue=1234567 negative=false   fractionalDigits=0   "-1234567.89" => unscaledValue=123456789 negative=true   fractionalDigits=2   "12.3E7" => unscaledValue=123 negative=false fractionalDigits=1   exponent=7   ".123E-7" => unscaledValue=123 negative=false fractionalDigits=3 
Hive,WITHOUT_CLASSIFICATION,//  DruidOutputFormat will write segments in an intermediate directory 
Hive,WITHOUT_CLASSIFICATION,//  Get the first valid row in the batch still available. 
Hive,WITHOUT_CLASSIFICATION,//  Create HepPlanner 
Hive,WITHOUT_CLASSIFICATION,//  TODO: if this method is ever called on more than one jar getting the dir   and the 
Hive,WITHOUT_CLASSIFICATION,//  This is based on the existing valid write ID list that was built for a select query;   therefore we assume all the aborted txns etc. were already accounted for.   All we do is adjust the high watermark to only include contiguous txns. 
Hive,WITHOUT_CLASSIFICATION,//  add WriteEntity for each matching partition 
Hive,WITHOUT_CLASSIFICATION,/*  It may happen that there's not enough memory to instantiate a hashmap for the partition.     * In that case we don't create the hashmap but pretend the hashmap is directly "spilled".      */
Hive,WITHOUT_CLASSIFICATION,//  Update the property before offering. 
Hive,WITHOUT_CLASSIFICATION,//  to this plan:     Project-A' (all gby keys + rewritten nullable ProjExpr)     Aggregate (groupby(all left input refs)                   agg0(rewritten expression)                   agg1()...)       Project-B' (rewriten original projected exprs)         Join (LOJ cond = true)           LeftInputRel           RightInputRel   
Hive,WITHOUT_CLASSIFICATION,//  Tests that doing a table-level REPL LOAD updates table repl.last.id but not db-level repl.last.id 
Hive,WITHOUT_CLASSIFICATION,//  required   optional   optional   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  Long and double are handled using descriptors string needs to be specially handled. 
Hive,WITHOUT_CLASSIFICATION,//  preserve the original configuration 
Hive,WITHOUT_CLASSIFICATION,//  Try this as a list 
Hive,WITHOUT_CLASSIFICATION,//  Passed the unparsed DB name here as get_partitions_ps expects to parse it 
Hive,WITHOUT_CLASSIFICATION,//  create a walker which walks the tree in a DFS manner while maintaining   the operator stack. The dispatcher 
Hive,WITHOUT_CLASSIFICATION,// CTAS with ACID target table 
Hive,WITHOUT_CLASSIFICATION,//  copy a null 
Hive,WITHOUT_CLASSIFICATION,//  The current plan can be thrown away after being merged with the union   plan 
Hive,WITHOUT_CLASSIFICATION,//  Update JobConf using MRInput info like filename comes via this 
Hive,WITHOUT_CLASSIFICATION,//  do filtering on the server and have to fall back to client path. 
Hive,WITHOUT_CLASSIFICATION,//  if the logger name is not found root logger is returned. We don't want to change root logger level   since user either requested a new logger or specified invalid input. In which we will add the logger   that user requested. 
Hive,WITHOUT_CLASSIFICATION,//  ..end of conversion 
Hive,WITHOUT_CLASSIFICATION,//  This is a normal insert delta which only has insert events and hence all the files 
Hive,WITHOUT_CLASSIFICATION,// looking for map = 100%  reduce = 100% 
Hive,WITHOUT_CLASSIFICATION,//  Someone else replaced/removed a parallel-added stale value try again. Max confusion. 
Hive,WITHOUT_CLASSIFICATION,// get options from arguments 
Hive,WITHOUT_CLASSIFICATION,//  bd is less than 1 
Hive,WITHOUT_CLASSIFICATION,//  Finally create the outer struct to contain the key value structs 
Hive,WITHOUT_CLASSIFICATION,//  3. Build Rel for GB Clause 
Hive,WITHOUT_CLASSIFICATION,//  for writes (transaction batch not closed yet) 
Hive,WITHOUT_CLASSIFICATION,//  from SQLStdHiveAccessController.applyAuthorizationConfigPolicy() 
Hive,WITHOUT_CLASSIFICATION,//  suffix reduce len 
Hive,WITHOUT_CLASSIFICATION,//  FLOAT_TYPE is treated as DOUBLE_TYPE 
Hive,WITHOUT_CLASSIFICATION,//  There may be more data after the gap. 
Hive,WITHOUT_CLASSIFICATION,// Following fields for displaying queries on WebUI 
Hive,WITHOUT_CLASSIFICATION,//  update them all. 
Hive,WITHOUT_CLASSIFICATION,//  is the current task a root task 
Hive,WITHOUT_CLASSIFICATION,/*        * Walk down expression to see which arguments are actually used.        */
Hive,WITHOUT_CLASSIFICATION,//  set up WriteEntity for replication 
Hive,WITHOUT_CLASSIFICATION,//  We have processed this on the previous run after it has already queued the message. 
Hive,WITHOUT_CLASSIFICATION,//  how much to we have   minimum size of ht completely in memory   blowout factor datasize -> memory size 
Hive,WITHOUT_CLASSIFICATION,// Hadoop property names (set by templeton logic) 
Hive,WITHOUT_CLASSIFICATION,//  do this for reconciling HBaseStorageHandler for use in HCatalog 
Hive,WITHOUT_CLASSIFICATION,//  returns fileId for SMBJoin which consists part of result file name 
Hive,WITHOUT_CLASSIFICATION,//  "-foo bar -blah"  form 
Hive,WITHOUT_CLASSIFICATION,//  In case last row was a large bytes value 
Hive,WITHOUT_CLASSIFICATION,//  ROOTS 
Hive,WITHOUT_CLASSIFICATION,//  3nd char starts from index 3 and total length should be 7 bytes as max is 10 
Hive,WITHOUT_CLASSIFICATION,// "some inputs"; // Will probably never actually happen. 
Hive,WITHOUT_CLASSIFICATION,//  will be KEY._COLx or VALUE._COLx 
Hive,WITHOUT_CLASSIFICATION,//  create 2nd permanent function 
Hive,WITHOUT_CLASSIFICATION,//  Request interceptor for any request pre-processing logic 
Hive,WITHOUT_CLASSIFICATION,/*      * Similarly we need a mapping since a value expression can be a calculation and the value     * will go into a scratch column.      */
Hive,WITHOUT_CLASSIFICATION,//  has the permissions on the table dir 
Hive,WITHOUT_CLASSIFICATION,/*  For UDFs that expect primitive types (like int instead of Integer or IntWritable)         * this will catch the the exception that happens if they are passed a NULL value.         * Then the default NULL handling logic will apply and the result will be NULL.          */
Hive,WITHOUT_CLASSIFICATION,//  entries in the VGBY are flushed. 
Hive,WITHOUT_CLASSIFICATION,//  Next 6 bits are used to locate offset within a long/word 
Hive,WITHOUT_CLASSIFICATION,//  Could we also join with ACID tables to only get tables with outdated stats? 
Hive,WITHOUT_CLASSIFICATION,//  We return a garbage value if metrics haven't been initialized so that callers don't have   to keep checking if the resulting value is null. 
Hive,WITHOUT_CLASSIFICATION,//  remove the comments 
Hive,WITHOUT_CLASSIFICATION,//  check if groupby is empty and there is no other cols in aggr   this should only happen when newParent is constant. 
Hive,WITHOUT_CLASSIFICATION,//  Replicate only one INSERT INTO operation on the table. 
Hive,WITHOUT_CLASSIFICATION,//  We need to check the Druid metadata 
Hive,WITHOUT_CLASSIFICATION,//  Timer that tops rpTimer after a long timeout e.g. 1 hr 
Hive,WITHOUT_CLASSIFICATION,//  Remove entire priority level if it's been emptied. 
Hive,WITHOUT_CLASSIFICATION,//  We don't lock files or directories. We also skip locking temp tables. 
Hive,WITHOUT_CLASSIFICATION,/*          * Initialize Single-Column String members for this specialized class.          */
Hive,WITHOUT_CLASSIFICATION,//  Create a copy of the function descriptor 
Hive,WITHOUT_CLASSIFICATION,//  warn the user if bytes per reducer is much larger than memory per task 
Hive,WITHOUT_CLASSIFICATION,//  Nothing to do here. This is not invoked by the log4j framework. Should likely not be in   the log4j interface 
Hive,WITHOUT_CLASSIFICATION,// Hive only supports primitive map keys:   https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types#LanguageManualTypes-ComplexTypes 
Hive,WITHOUT_CLASSIFICATION,//  parent stats are not populated yet 
Hive,WITHOUT_CLASSIFICATION,//  allocate and initialize a new conf since a test can 
Hive,WITHOUT_CLASSIFICATION,// match if there is filter (sq_count_check) as right input of a join which is left   input of another join 
Hive,WITHOUT_CLASSIFICATION,//  splits are equal to number of files in worst case) 
Hive,WITHOUT_CLASSIFICATION,/*    * A Unit Test convenience method for putting the key into the hash table using the   * actual type.    */
Hive,WITHOUT_CLASSIFICATION,//  We called reserveMemory so we know that there's memory waiting for us somewhere.   However we have a class of rare race conditions related to the order of locking/checking of   different allocation areas. Simple case - say we have 2 arenas 256Kb available in arena 2.   We look at arena 1; someone deallocs 256Kb from arena 1 and allocs the same from arena 2;   we look at arena 2 and find no memory. Or for single arena 2 threads reserve 256k each   and a single 1Mb block is available. When the 1st thread locks the 1Mb freelist the 2nd one   might have already examined the 256k and 512k lists finding nothing. Blocks placed by (1)   into smaller lists after its split is done will not be found by (2); given that freelist   locks don't overlap (2) may even run completely between the time (1) takes out the 1Mb   block and the time it returns the remaining 768Kb.   Two solutions to this are some form of cross-thread helping (threads putting "demand"   into some sort of queues that deallocate and split will examine) or having and "actor"   allocator thread (or threads per arena).   The 2nd one is probably much simpler and will allow us to get rid of a lot of sync code.
Hive,WITHOUT_CLASSIFICATION,/*  1 files x 100 size for 1 splits  */
Hive,WITHOUT_CLASSIFICATION,//  Accurate int value cannot be obtained. 
Hive,WITHOUT_CLASSIFICATION,//  save some positional state 
Hive,WITHOUT_CLASSIFICATION,//  If they gave a value but not a time unit assume the default time unit. 
Hive,WITHOUT_CLASSIFICATION,//  Create the converters 
Hive,WITHOUT_CLASSIFICATION,//  Scale down by a factor of 0.9 to account for approximate values 
Hive,WITHOUT_CLASSIFICATION,//  Plugin interface for storage handler which supports input estimation 
Hive,WITHOUT_CLASSIFICATION,//  We allocate pairs so we cannot go above highest Integer power of 2 / 4. 
Hive,WITHOUT_CLASSIFICATION,//  re-login with kerberos. This makes sure all daemons have the same login user. 
Hive,WITHOUT_CLASSIFICATION,//  with nulls 
Hive,WITHOUT_CLASSIFICATION,//  Assuming grouping enabled always. 
Hive,WITHOUT_CLASSIFICATION,//  on a per split strategy basis and it has to be same for all the files in that strategy. 
Hive,WITHOUT_CLASSIFICATION,/*  We read many records because sometimes the RecordReader for the format to test     * behaves different with one record than a bunch of records  */
Hive,WITHOUT_CLASSIFICATION,//  TODO test dropping non-empty catalog 
Hive,WITHOUT_CLASSIFICATION,//  draw 2 and return in order - further run should return last returned 
Hive,WITHOUT_CLASSIFICATION,//  equal maps 
Hive,WITHOUT_CLASSIFICATION,//  need to reset to true in case previous aggregate/project   has set it to false 
Hive,WITHOUT_CLASSIFICATION,//  Evaluate the result given a partition and the row number to process 
Hive,WITHOUT_CLASSIFICATION,//  error 
Hive,WITHOUT_CLASSIFICATION,//  -d <driver class> 
Hive,WITHOUT_CLASSIFICATION,//  BinarySortableDeserializeRead. 
Hive,WITHOUT_CLASSIFICATION,//  work 
Hive,WITHOUT_CLASSIFICATION,//  Code below shameless borrowed from Hadoop Streaming 
Hive,WITHOUT_CLASSIFICATION,//  Each iteration cleans the file cache as a single unit (unlike the ORC cache). 
Hive,WITHOUT_CLASSIFICATION,//  delimiter to check DOT delimited qualified names 
Hive,WITHOUT_CLASSIFICATION,//  keeping minTxnId atomic as it is shared with heartbeat thread 
Hive,WITHOUT_CLASSIFICATION,//  Setting the default batch size to 1000 makes the memory check at 5000   rows work the same as the row by row writer. (If it was the default 1024   the smallest stripe size would be 5120 rows which changes the output   of some of the tests.) 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:FragmentRuntimeInfo) 
Hive,WITHOUT_CLASSIFICATION,/*    * The hash table slots.  For a long key hash table each slot is 2 longs and the array is   * 2X sized.   *   * The slot pair is 1) a non-zero reference word to the first value bytes and 2) the long value.    */
Hive,WITHOUT_CLASSIFICATION,//  Corresponds to SemAnalyzer genGroupByPlanMapAggr2MR 
Hive,WITHOUT_CLASSIFICATION,//  We have to check it here since invalid decref will overflow. 
Hive,WITHOUT_CLASSIFICATION,//  batches will be sized 10 5 2 1 
Hive,WITHOUT_CLASSIFICATION,//  Found a stale value we cannot incRef; try to replace it with new value. 
Hive,WITHOUT_CLASSIFICATION,//  since renewal is KERBEROS authenticated token may not be cached 
Hive,WITHOUT_CLASSIFICATION,// check if this grant statement will end up creating a cycle 
Hive,WITHOUT_CLASSIFICATION,//  we have to keep at least a branch before we support empty values() in   hive 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) EnumDef  */
Hive,WITHOUT_CLASSIFICATION,//  update statistics based on column statistics.   OR conditions keeps adding the stats independently this may   result in number of rows getting more than the input rows in   which case stats need not be updated 
Hive,WITHOUT_CLASSIFICATION,//  Check that the table is valid under strict managed tables mode. 
Hive,WITHOUT_CLASSIFICATION,//  The application-level name 
Hive,WITHOUT_CLASSIFICATION,//  dedup file list 
Hive,WITHOUT_CLASSIFICATION,//  Table was renamed. 
Hive,WITHOUT_CLASSIFICATION,//  Only need aborted since we don't consider anything above minOpenWriteId 
Hive,WITHOUT_CLASSIFICATION,//  At this point we should add any relevant jars that would be needed for the UDf. 
Hive,WITHOUT_CLASSIFICATION,//  the index of c 
Hive,WITHOUT_CLASSIFICATION,// list of terminal operation states.  We measure only completed counts for operations in these states. 
Hive,WITHOUT_CLASSIFICATION,//  increment the counters only when there are no violations 
Hive,WITHOUT_CLASSIFICATION,//  Varchar or char length 
Hive,WITHOUT_CLASSIFICATION,//  set so we don't repeat this initialization 
Hive,WITHOUT_CLASSIFICATION,//  Should be able to execute without failure in the session whose transport has been closed. 
Hive,WITHOUT_CLASSIFICATION,//  Operation fails as invalid input 
Hive,WITHOUT_CLASSIFICATION,//  handle SQLLine command in beeline which starts with ! and does not end with ; 
Hive,WITHOUT_CLASSIFICATION,// right now only one parent 
Hive,WITHOUT_CLASSIFICATION,//  check here for each dir we're copying out to see if it   already exists error out if so.   Also treat dyn-writes as writes to immutable tables.   dryRun = true immutable = true 
Hive,WITHOUT_CLASSIFICATION,//  Filter operator 
Hive,WITHOUT_CLASSIFICATION,//  Allow for empty string etc. 
Hive,WITHOUT_CLASSIFICATION,//  get metastore/thrift privilege object using metastore api 
Hive,WITHOUT_CLASSIFICATION,//  transitive 
Hive,WITHOUT_CLASSIFICATION,//  The output of a partial aggregation is a struct containing   a long count and doubles sum and variance. 
Hive,WITHOUT_CLASSIFICATION,//  then drop the database 
Hive,WITHOUT_CLASSIFICATION,// The failure occurred before we even made an entry in COMPACTION_QUEUE 
Hive,WITHOUT_CLASSIFICATION,//  2. Add alias to 1) aliasToOpInfo and 2) opToAlias 
Hive,WITHOUT_CLASSIFICATION,//  The old to new output position mapping will be the same as that 
Hive,WITHOUT_CLASSIFICATION,//  Date is an integer internally 
Hive,WITHOUT_CLASSIFICATION,//  A queue to notify separateRowGenerator to generate the next batch of rows. 
Hive,WITHOUT_CLASSIFICATION,/*    * If task execution time out is configured for submit operation then job may need to   * be killed on execution time out. These parameters controls the maximum number of   * retries and retry wait time in seconds for executing the time out task.    */
Hive,WITHOUT_CLASSIFICATION,//  So the next line works. 
Hive,WITHOUT_CLASSIFICATION,//  call-1: open to read data - split 1 => mock:/mocktable8/0_0   call-2: listLocatedFileStatus(mock:/mocktable8)   call-3: getFileStatus(mock:/mocktable8/delta_0000001_0000001_0000/_metadata_acid)   call-4: getFileStatus(mock:/mocktable8/delta_0000001_0000001_0000/_metadata_acid) 
Hive,WITHOUT_CLASSIFICATION,//  Check if an appropriate codec is available 
Hive,WITHOUT_CLASSIFICATION,//  VALUE of SimpleEntry: rowcount 
Hive,WITHOUT_CLASSIFICATION,/*  The random values must be between 0 and 1 distributed uniformly.     * So the average value of a large set should be about 0.5. Verify it is     * close to this value.      */
Hive,WITHOUT_CLASSIFICATION,//  We will only do interrupt checking in the lowest-level operator for multiple joins. 
Hive,WITHOUT_CLASSIFICATION,/*  Test decimal scalar divided column. This tests the primary logic   * for template ScalarDivideColumnDecimal.txt.    */
Hive,WITHOUT_CLASSIFICATION,//  Verify 
Hive,WITHOUT_CLASSIFICATION,//  populate the operator 
Hive,WITHOUT_CLASSIFICATION,//  no metadata should get created. 
Hive,WITHOUT_CLASSIFICATION,//  if the operation on metastore fails we don't do anything in change management but fail   the metastore transaction as having a copy of the jar in change management is not going 
Hive,WITHOUT_CLASSIFICATION,//  Function to setup locks 
Hive,WITHOUT_CLASSIFICATION,//  first argument is hiveVersion it is compatible if 2nd argument - dbVersion is   greater than or equal to it   check the compatible case 
Hive,WITHOUT_CLASSIFICATION,//     not or this is the identity the rule will do nothing 
Hive,WITHOUT_CLASSIFICATION,//  get a synchronized wrapper if the meta store is remote. 
Hive,WITHOUT_CLASSIFICATION,//  Try to "return" stuff that was killed from "under" us. Should be a no-op. 
Hive,WITHOUT_CLASSIFICATION,//  or compile another query 
Hive,WITHOUT_CLASSIFICATION,//  2. It is an OR operator with enough children 
Hive,WITHOUT_CLASSIFICATION,//  Do the work that cannot be done via async calls. 
Hive,WITHOUT_CLASSIFICATION,//  The column has been obtained from cache. 
Hive,WITHOUT_CLASSIFICATION,/*  Let's write more bytes to the files to test that Estimator is actually working returning the file size not from the filesystem  */
Hive,WITHOUT_CLASSIFICATION,// -------------------------------- last block: affect all 32 bits of (c)   all the case statements fall through 
Hive,WITHOUT_CLASSIFICATION,//  Test getTables() with no table name pattern 
Hive,WITHOUT_CLASSIFICATION,//  Now add enough failed compactions to ensure purgeCompactionHistory() will attempt delete;   HiveConf.ConfVars.COMPACTOR_HISTORY_RETENTION_ATTEMPTED is enough for this.   But we also want enough to tickle the code in TxnUtils.buildQueryWithINClauseStrings() 
Hive,WITHOUT_CLASSIFICATION,//  let's wait on the async ops before continuing 
Hive,WITHOUT_CLASSIFICATION,//  sequence file read 
Hive,WITHOUT_CLASSIFICATION,//  Column names 
Hive,WITHOUT_CLASSIFICATION,// we only recompute stats after major compact if they existed before 
Hive,WITHOUT_CLASSIFICATION,//  no need to reload 
Hive,WITHOUT_CLASSIFICATION,//  For Acid table Insert Overwrite shouldn't replace the table content. We keep the old 
Hive,WITHOUT_CLASSIFICATION,//  Toss in timestamp and date. 
Hive,WITHOUT_CLASSIFICATION,//  call dropPartition on each of the table's partitions to follow the   procedure for cleanly dropping partitions. 
Hive,WITHOUT_CLASSIFICATION,//  MetaStoreClient-based impl of NotificationFetcher 
Hive,WITHOUT_CLASSIFICATION,//  extract columns missing in current RS key/value 
Hive,WITHOUT_CLASSIFICATION,//  Create 2 tables one partitioned and other not. Also have both types of full ACID and MM tables. 
Hive,WITHOUT_CLASSIFICATION,//  First compare the length and then compare the directory name 
Hive,WITHOUT_CLASSIFICATION,/* Note that HCatRecordSerDe.serializePrimitiveField() will be called before this thus some    * type promotion/conversion may occur: e.g. Short to Integer.  We should refactor this so    * that it's hapenning in one place per module/product that we are integrating with.    * All Pig conversion should be done here etc. */
Hive,WITHOUT_CLASSIFICATION,//  since it is guaranteed to produce at most one row 
Hive,WITHOUT_CLASSIFICATION,//  without vectorization 
Hive,WITHOUT_CLASSIFICATION,//  Signing is not required for Tez. 
Hive,WITHOUT_CLASSIFICATION,//  In Hive AST right child of join cannot be another join   thus we need to introduce a project on top of it.   But we only need the additional project if the left child   is another join too; if it is not ASTConverter will swap   the join inputs leaving the join operator on the left.   we also do it if parent is HiveSemiJoin since ASTConverter won't   swap inputs then   This will help triggering multijoin recognition methods that   are embedded in SemanticAnalyzer. 
Hive,WITHOUT_CLASSIFICATION,//  Ensures that the list doesn't have dups and keeps track of directories we have created. 
Hive,WITHOUT_CLASSIFICATION,// alter partition 
Hive,WITHOUT_CLASSIFICATION,//  find how much compressed data was added for this column 
Hive,WITHOUT_CLASSIFICATION,/*  * Test the vectorized UDF adaptor to verify that custom legacy and generic * UDFs can be run in vectorized mode.  */
Hive,WITHOUT_CLASSIFICATION,//  2^56 
Hive,WITHOUT_CLASSIFICATION,//  No row was processed 
Hive,WITHOUT_CLASSIFICATION,//  Nothing to do here 
Hive,WITHOUT_CLASSIFICATION,//  First just allocate just the projection columns we will be using. 
Hive,WITHOUT_CLASSIFICATION,//  TableType specified was null we need to figure out what type it was. 
Hive,WITHOUT_CLASSIFICATION,//  hive has no max limit for binary 
Hive,WITHOUT_CLASSIFICATION,//  evaluate union object 
Hive,WITHOUT_CLASSIFICATION,//  this turns on split-update U=D+I 
Hive,WITHOUT_CLASSIFICATION,// split each row (duplicate) which will cause an update into 2 rows and augment with 'op' col which has 0 to insert 1 to update 
Hive,WITHOUT_CLASSIFICATION,//  1. Get Row Resolvers Column map for original left and right input of 
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.ql.hooks.proto.HiveHookEvents.HiveHookEventProto.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,//  CAS race look again. 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.ICLIService#getTypeInfo(org.apache.hive.service.cli.SessionHandle)    */
Hive,WITHOUT_CLASSIFICATION,//  Nothing so far (and shouldn't be called). 
Hive,WITHOUT_CLASSIFICATION,//  Create bloom filter with same number of bits but different # hash functions 
Hive,WITHOUT_CLASSIFICATION,//  One input path would mean only one map task 
Hive,WITHOUT_CLASSIFICATION,//  Copy of TimestampWritable.millisToSeconds 
Hive,WITHOUT_CLASSIFICATION,//  Mark any scratch small table scratch columns that would normally receive a copy of the key   as null too. 
Hive,WITHOUT_CLASSIFICATION,// Single MapReduce job is launched 
Hive,WITHOUT_CLASSIFICATION,/*    * Deserializes 64-bit decimals up to the maximum 64-bit precision (18 decimal digits).   *   * NOTE: Major assumption: the input decimal64 has already been bounds checked and a least   * has a precision <= DECIMAL64_DECIMAL_DIGITS.  We do not bounds check here for better   * performance.  You can bounds check beforehand with:   *     Math.abs(decimal64Long) <= getDecimal64AbsMax(precision)    */
Hive,WITHOUT_CLASSIFICATION,//  Month granularity 
Hive,WITHOUT_CLASSIFICATION,//  rowId >= 'q' 
Hive,WITHOUT_CLASSIFICATION,//  no op 
Hive,WITHOUT_CLASSIFICATION,//  MODIFIER LETTER TRIANGULAR COLON U+02D0 (2 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  If global contains excludes individual modules can only contain additional excludes. 
Hive,WITHOUT_CLASSIFICATION,//  Clean up the database 
Hive,WITHOUT_CLASSIFICATION,//  values colexpmap and rowschema 
Hive,WITHOUT_CLASSIFICATION,//  become part of the record; otherwise we will just write over it later. 
Hive,WITHOUT_CLASSIFICATION,//  Don't compact 4 and 5; 3 is opened. 
Hive,WITHOUT_CLASSIFICATION,//  For RS-SEL-RS case. reducer operator in reducer task cannot be null in task compiler 
Hive,WITHOUT_CLASSIFICATION,//  once the feature is stable 
Hive,WITHOUT_CLASSIFICATION,//  synchronized (lock) 
Hive,WITHOUT_CLASSIFICATION,//  Some other things that could be added here to model cost:   Cost of computing/sending partial BloomFilter results? BloomFilterSize * # mappers   For reduce-side join add the cost of the semijoin table scan/dependent tablescans? 
Hive,WITHOUT_CLASSIFICATION,//  Register for notifications inside the lock. Should avoid races with unregisterForNotifications   happens in a different Submission thread. i.e. Avoid register running for this task 
Hive,WITHOUT_CLASSIFICATION,//             send(lpde.getPartitionName()lpde.getTable().getParameters().get(HCatConstants.HCAT_MSGBUS_TOPIC_NAME)HCatConstants.HCAT_PARTITION_DONE_EVENT); 
Hive,WITHOUT_CLASSIFICATION,// want to avoid expiring locks for a txn w/o expiring the txn itself 
Hive,WITHOUT_CLASSIFICATION,//  Add another value. 
Hive,WITHOUT_CLASSIFICATION,//  Register the shard sub type to be used by the mapper 
Hive,WITHOUT_CLASSIFICATION,//  2. Determine which stripes to read based on the split. 
Hive,WITHOUT_CLASSIFICATION,// Create operation log root directory if operation logging is enabled 
Hive,WITHOUT_CLASSIFICATION,//  longer the wait time for an attempt wrt to its start time higher the priority it gets 
Hive,WITHOUT_CLASSIFICATION,//  First breaking up the filter conditions into equality   comparisons between rightJoinKeys(from the original   filterInputRel) and correlatedJoinKeys. correlatedJoinKeys   can only be RexFieldAccess while rightJoinKeys can be 
Hive,WITHOUT_CLASSIFICATION,//  save the original job tracker 
Hive,WITHOUT_CLASSIFICATION,//  zero. no need to shift/scale 
Hive,WITHOUT_CLASSIFICATION,/*    * Create test input file with specified number of rows    */
Hive,WITHOUT_CLASSIFICATION,//  returning void because we ignore this production. 
Hive,WITHOUT_CLASSIFICATION,//  Currently using fileuri#checksum#cmrooturi#subdirs as the format 
Hive,WITHOUT_CLASSIFICATION,//  No range check needed. 
Hive,WITHOUT_CLASSIFICATION,//  test non-vectorized acid combine 
Hive,WITHOUT_CLASSIFICATION,//  determine bit width for bitpacking and encode it in header 
Hive,WITHOUT_CLASSIFICATION,//  No boolean value match for 4 char field. 
Hive,WITHOUT_CLASSIFICATION,//  to bump its internal version. 
Hive,WITHOUT_CLASSIFICATION,/*       This is removed using a poll because there can be a case where there partitions iterator is empty      but because both the producer and consumer are started simultaneously the while loop will execute      because producer is not terminated but it wont produce anything so queue will be empty and then we      should only wait for a specific time before continuing as the next loop cycle will fail.        */
Hive,WITHOUT_CLASSIFICATION,//  Clear out isNull array. 
Hive,WITHOUT_CLASSIFICATION,//  Adds the missing scheme/authority for the new table location 
Hive,WITHOUT_CLASSIFICATION,//  First child is subquery second child is alias   We set the node of interest and QB to the subquery 
Hive,WITHOUT_CLASSIFICATION,//  return key from any of the readers 
Hive,WITHOUT_CLASSIFICATION,//  the incoming split may not be a file split when we are re-grouping TezGroupedSplits in   the case of SMB join. So in this case we can do an early exit by not doing the   calculation for bucketSizeMap. Each bucket will assume it can fill availableSlots * waves   (preset to 0.5) for SMB join. 
Hive,WITHOUT_CLASSIFICATION,//  (2) getPosition() on 2 different columns should never give the same value. 
Hive,WITHOUT_CLASSIFICATION,//  String group comparison. 
Hive,WITHOUT_CLASSIFICATION,//  fetch task query 
Hive,WITHOUT_CLASSIFICATION,//  Note that delete_delta_3_3 should not be read when a minor compacted   [delete_]delta_2_5 is present. 
Hive,WITHOUT_CLASSIFICATION,//  traverse data and masks array together check for set bits 
Hive,WITHOUT_CLASSIFICATION,//       "set " + SESSION_USER_NAME        "dfs -ls -d ${hiveconf:hive.metastore.warehouse.dir}/" + queryTab 
Hive,WITHOUT_CLASSIFICATION,//  Copy the files from different source file systems to one destination directory 
Hive,WITHOUT_CLASSIFICATION,//  otherwise we didn't understand it so mark it maybe 
Hive,WITHOUT_CLASSIFICATION,//  EXCLUSIVE locks occur before SHARED locks 
Hive,WITHOUT_CLASSIFICATION,// now do Insert from Union here to create data files in sub dirs 
Hive,WITHOUT_CLASSIFICATION,//  we found a map objectinspector. Grab the objectinspector for the value and initialize it   aptly 
Hive,WITHOUT_CLASSIFICATION,//  Need unique IDs to refer to each min/max key value in the DynamicValueRegistry 
Hive,WITHOUT_CLASSIFICATION,//  TOK_FROM subtree 
Hive,WITHOUT_CLASSIFICATION,//  Preserve only partitioning 
Hive,WITHOUT_CLASSIFICATION,//  Drop database everything in all 4 meta tables should disappear 
Hive,WITHOUT_CLASSIFICATION,//  run common join task 
Hive,WITHOUT_CLASSIFICATION,//  replace the node in place 
Hive,WITHOUT_CLASSIFICATION,//  Matches 2 times: one time the original node one time the new node created by the rule 
Hive,WITHOUT_CLASSIFICATION,//  non-MM case 
Hive,WITHOUT_CLASSIFICATION,/*    * Group-by re-orders the keys emitted hence the keyCols would change.    */
Hive,WITHOUT_CLASSIFICATION,//  Shutdown hook to clean up resources at process end. 
Hive,WITHOUT_CLASSIFICATION,/*  * Simple one long key map join benchmarks. * * Build with "mvn clean install -DskipTests -Pdistitests" at main hive directory. * * From itests/hive-jmh directory run: *     java -jar target/benchmarks.jar org.apache.hive.benchmark.vectorization.mapjoin.MapJoinOneStringKeyBench * *  {INNER INNER_BIG_ONLY LEFT_SEMI OUTER} *    X *  {ROW_MODE_HASH_MAP ROW_MODE_OPTIMIZED VECTOR_PASS_THROUGH NATIVE_VECTOR_OPTIMIZED NATIVE_VECTOR_FAST} *  */
Hive,WITHOUT_CLASSIFICATION,//  Filter timestamp against timestamp or interval day time against interval day time. 
Hive,WITHOUT_CLASSIFICATION,//   Disable SARGs for deleteEventReaders as SARGs have no meaning. 
Hive,WITHOUT_CLASSIFICATION,//  for rule: MapJoin%.*MapJoin   have a child mapjoin. if the the current mapjoin is on a local work   will put the current mapjoin in the rejected list. 
Hive,WITHOUT_CLASSIFICATION,//  HiveDecimal suppresses trailing zeroes. 
Hive,WITHOUT_CLASSIFICATION,/*        * 3 different kinds of vectorized reading supported:       *       *   1) Read the Vectorized Input File Format which returns VectorizedRowBatch as the row.       *       *   2) Read using VectorDeserializeRow to deserialize each row into the VectorizedRowBatch.       *       *   3) And read using the regular partition deserializer to get the row object and assigning       *      the row object into the VectorizedRowBatch with VectorAssignRow.        */
Hive,WITHOUT_CLASSIFICATION,//  Set server's idle timeout to a very low value 
Hive,WITHOUT_CLASSIFICATION,/*    * Used to check recursive CTE invocations. Similar to viewsExpanded    */
Hive,WITHOUT_CLASSIFICATION,//  Serialize to bytes 
Hive,WITHOUT_CLASSIFICATION,//  unquoted space 
Hive,WITHOUT_CLASSIFICATION,// so that we know the type of table we are creating: acid/MM to match what was exported 
Hive,WITHOUT_CLASSIFICATION,// Don't add partition data if it already exists 
Hive,WITHOUT_CLASSIFICATION,//  fix up the input column numbers and output column numbers 
Hive,WITHOUT_CLASSIFICATION,//  setObject to the yet unknown type java.util.Date 
Hive,WITHOUT_CLASSIFICATION,//  Truncate the excess chars to fit the character length.   Also make sure we take supplementary chars into account. 
Hive,WITHOUT_CLASSIFICATION,//  If row limit does not match we currently do not merge 
Hive,WITHOUT_CLASSIFICATION,//  pass 
Hive,WITHOUT_CLASSIFICATION,//  3) Build plan 
Hive,WITHOUT_CLASSIFICATION,//  The total size of local tables after we merge localWorks   is larger than the limit set by   HiveConf.ConfVars.HIVECONVERTJOINNOCONDITIONALTASKTHRESHOLD. 
Hive,WITHOUT_CLASSIFICATION,//  There should be 2 original bucket files in the location (000000_0 and 000001_0) 
Hive,WITHOUT_CLASSIFICATION,//  Suppress empty column map. 
Hive,WITHOUT_CLASSIFICATION,//  the data to shuffle 
Hive,WITHOUT_CLASSIFICATION,//  In all other cases throw an exception. Its a white-list of allowed operations. 
Hive,WITHOUT_CLASSIFICATION,//  Create the Hadoop archive 
Hive,WITHOUT_CLASSIFICATION,//  If it contains an aggregate and it is not a full acid table   we do not rewrite it (we need MERGE support) 
Hive,WITHOUT_CLASSIFICATION,//  2. A Window Spec with no Parition Spec is Partitioned on a Constant(number 0) 
Hive,WITHOUT_CLASSIFICATION,//  Minor optimization avoiding creating new objects. 
Hive,WITHOUT_CLASSIFICATION,//  alias is not fully qualified 
Hive,WITHOUT_CLASSIFICATION,//  passing null matches everything 
Hive,WITHOUT_CLASSIFICATION,//  check whether this input operator produces output   If it has residual we do not skip this output   we will add a Select on top of the join 
Hive,WITHOUT_CLASSIFICATION,//  now propagate the constant from the parent to the child 
Hive,WITHOUT_CLASSIFICATION,//  Target path's last component is also the column family name. 
Hive,WITHOUT_CLASSIFICATION,//  Various restrictions. 
Hive,WITHOUT_CLASSIFICATION,//  Handle to stop this process from the outside if needed. 
Hive,WITHOUT_CLASSIFICATION,//  We have no estimator for this type... assume low overhead and hope for the best. 
Hive,WITHOUT_CLASSIFICATION,/* |  Use | Boundary1.type | Boundary1. amt | Sort Key | Order | Behavior                          || Case |                |                |          |       |                                   ||------+----------------+----------------+----------+-------+-----------------------------------||   1. | PRECEDING      | UNB            | ANY      | ANY   | start = 0                         ||   2. | PRECEDING      | unsigned int   | NULL     | ASC   | start = 0                         ||   3. |                |                |          | DESC  | scan backwards to row R2          ||      |                |                |          |       | such that R2.sk is not null       ||      |                |                |          |       | start = R2.idx + 1                ||   4. | PRECEDING      | unsigned int   | not NULL | DESC  | scan backwards until row R2       ||      |                |                |          |       | such that R2.sk - R.sk > amt      ||      |                |                |          |       | start = R2.idx + 1                ||   5. | PRECEDING      | unsigned int   | not NULL | ASC   | scan backward until row R2        ||      |                |                |          |       | such that R.sk - R2.sk > bnd1.amt ||      |                |                |          |       | start = R2.idx + 1                ||   6. | CURRENT ROW    |                | NULL     | ANY   | scan backwards until row R2       ||      |                |                |          |       | such that R2.sk is not null       ||      |                |                |          |       | start = R2.idx + 1                ||   7. | CURRENT ROW    |                | not NULL | ANY   | scan backwards until row R2       ||      |                |                |          |       | such R2.sk != R.sk                ||      |                |                |          |       | start = R2.idx + 1                ||   8. | FOLLOWING      | UNB            | ANY      | ANY   | Error                             ||   9. | FOLLOWING      | unsigned int   | NULL     | DESC  | start = partition.size            ||  10. |                |                |          | ASC   | scan forward until R2             ||      |                |                |          |       | such that R2.sk is not null       ||      |                |                |          |       | start = R2.idx                    ||  11. | FOLLOWING      | unsigned int   | not NULL | DESC  | scan forward until row R2         ||      |                |                |          |       | such that R.sk - R2.sk > amt      ||      |                |                |          |       | start = R2.idx                    ||  12. |                |                |          | ASC   | scan forward until row R2         ||      |                |                |          |       | such that R2.sk - R.sk > amt      ||------+----------------+----------------+----------+-------+-----------------------------------|    */
Hive,WITHOUT_CLASSIFICATION,//  1st task requested host2 got host2 
Hive,WITHOUT_CLASSIFICATION,// Authorize the operation. 
Hive,WITHOUT_CLASSIFICATION,//  that operator writes into to the bucket/sort columns for that data. 
Hive,WITHOUT_CLASSIFICATION,//  projection that casts proj expr to a nullable type. 
Hive,WITHOUT_CLASSIFICATION,/*  ascending  */
Hive,WITHOUT_CLASSIFICATION,//  Partition keys 
Hive,WITHOUT_CLASSIFICATION,//  Add new node to the cache 
Hive,WITHOUT_CLASSIFICATION,//  Relying on the RPC threads to keep the service alive. 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hadoop.hive.ql.optimizer.Transform#transform(org.apache.hadoop.hive.ql.parse.ParseContext)    */
Hive,WITHOUT_CLASSIFICATION,//  Execute a malformed query 
Hive,WITHOUT_CLASSIFICATION,//  PART_STATS 
Hive,WITHOUT_CLASSIFICATION,// TODO: Even listener for check  AddcheckConstraintEvent addcheckConstraintEvent = new AddcheckConstraintEvent(checkConstraintCols true this); 
Hive,WITHOUT_CLASSIFICATION,// 2345 
Hive,WITHOUT_CLASSIFICATION,//  We assume splits will never start in the middle of the stripe. 
Hive,WITHOUT_CLASSIFICATION,//  Reset the buffer we're going to use 
Hive,WITHOUT_CLASSIFICATION,//  Test that existing exclusive table with new shared_write coalesces to 
Hive,WITHOUT_CLASSIFICATION,//  we minimize allocations 
Hive,WITHOUT_CLASSIFICATION,//  Change a column 
Hive,WITHOUT_CLASSIFICATION,// Increments one HMS connection (Hive.get()) 
Hive,WITHOUT_CLASSIFICATION,//  call-1: open to read data - split 1 => mock:/mocktable2/0_0 
Hive,WITHOUT_CLASSIFICATION,//  long scalar/column IF 
Hive,WITHOUT_CLASSIFICATION,//  FileSystem.CACHE 
Hive,WITHOUT_CLASSIFICATION,//  timestamps are not supported both dates were changed to CE. 
Hive,WITHOUT_CLASSIFICATION,//  [A: 0 B: 0 B.x: 0 B.y: 0 C: 1] 
Hive,WITHOUT_CLASSIFICATION,//  is INSERT OVERWRITE TABLE 
Hive,WITHOUT_CLASSIFICATION,//  get HS2 site.xml loaded 
Hive,WITHOUT_CLASSIFICATION,//  containerEnd/taskEnd invocation. 
Hive,WITHOUT_CLASSIFICATION,//  Link the RPC and the promise so that events from one are propagated to the other as   needed. 
Hive,WITHOUT_CLASSIFICATION,//  Note: this will determine the order of columns in the result. For now the columns for each         table will be together; the order of the tables as well as the columns within each         table is deterministic but undefined - RR stores them in the order of addition. 
Hive,WITHOUT_CLASSIFICATION,//  Reorder tags if need be 
Hive,WITHOUT_CLASSIFICATION,//  Keep draining the queue in the same session. 
Hive,WITHOUT_CLASSIFICATION,//  No room for optimization since we cannot convert to an empty   Project operator. 
Hive,WITHOUT_CLASSIFICATION,//  I am the first thread to detect the error cleanup old connection & reconnect 
Hive,WITHOUT_CLASSIFICATION,//  Only BoneCP should return true 
Hive,WITHOUT_CLASSIFICATION,//  Don't add the partition or table created during the execution as the input source 
Hive,WITHOUT_CLASSIFICATION,//  Cancel the watchKey since the output dir has been found. 
Hive,WITHOUT_CLASSIFICATION,//  collect key/values for this row. 
Hive,WITHOUT_CLASSIFICATION,//  Update largest relation 
Hive,WITHOUT_CLASSIFICATION,//  x = p' - p 
Hive,WITHOUT_CLASSIFICATION,//  True if only one date is null 
Hive,WITHOUT_CLASSIFICATION,//  Setup values registry 
Hive,WITHOUT_CLASSIFICATION,//  Ignore and break. 
Hive,WITHOUT_CLASSIFICATION,// mapper can span partitions  combine into as few as one split subject to the PathFilters set   using combine.createPool. 
Hive,WITHOUT_CLASSIFICATION,//  Hint to disable mapjoin. 
Hive,WITHOUT_CLASSIFICATION,//  Just compare the magnitudes (i.e. signums set to 1). 
Hive,WITHOUT_CLASSIFICATION,//  Don't propagate the error - termination was done as part of closing the client. 
Hive,WITHOUT_CLASSIFICATION,// default 80k (runs slightly over 1 day long) 
Hive,WITHOUT_CLASSIFICATION,//  Include the original blank value Long.MIN_VALUE in the negatives to make sure we get 
Hive,WITHOUT_CLASSIFICATION,//  previous record in the write buffers (see writeBuffers javadoc). 
Hive,WITHOUT_CLASSIFICATION,//  Pool is exhausted return a new object 
Hive,WITHOUT_CLASSIFICATION,//  Pattern for key1=value1;key2=value2 
Hive,WITHOUT_CLASSIFICATION,//  Check the output of FixAcidKeyIndex - it should indicate the index was invalid. 
Hive,WITHOUT_CLASSIFICATION,//  now it's time to rewrite the Aggregate 
Hive,WITHOUT_CLASSIFICATION,//  left repeats and is null 
Hive,WITHOUT_CLASSIFICATION,//  Use BucketizedHiveInputFormat so that one mapper processes exactly one file 
Hive,WITHOUT_CLASSIFICATION,//  Iterate through the opHandles and close their operations 
Hive,WITHOUT_CLASSIFICATION,//  Create segment file at the destination location with LinearShardSpec(2) 
Hive,WITHOUT_CLASSIFICATION,//  Return if metadata-only 
Hive,WITHOUT_CLASSIFICATION,//  Unpartitioned table 
Hive,WITHOUT_CLASSIFICATION,//  if subquery is in PROJECT 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required 
Hive,WITHOUT_CLASSIFICATION,//  fetch the first group for all small table aliases 
Hive,WITHOUT_CLASSIFICATION,// Test that partition key is not allowed in data 
Hive,WITHOUT_CLASSIFICATION,//  Grab the tag and the field 
Hive,WITHOUT_CLASSIFICATION,//   If the hadoop cluster is secure do a kerberos login for the service from the keytab 
Hive,WITHOUT_CLASSIFICATION,//  matched HS2 instance is not leader 
Hive,WITHOUT_CLASSIFICATION,//  Try to reconnect to a child job if one is found 
Hive,WITHOUT_CLASSIFICATION,//  GroupBy query results 
Hive,WITHOUT_CLASSIFICATION,//  we lost statistics & opTraits through cloning try to get them back 
Hive,WITHOUT_CLASSIFICATION,//  This is an async method so always launch threads even for a single task. 
Hive,WITHOUT_CLASSIFICATION,//  For now just 2 Decimal64 inputs and a Decimal64 or boolean output. 
Hive,WITHOUT_CLASSIFICATION,//  ExecutorService for sending heartbeat to metastore periodically. 
Hive,WITHOUT_CLASSIFICATION,//  Given a list of partStats this function will give you an aggr stats 
Hive,WITHOUT_CLASSIFICATION,//  This means the column was not included in the projection from the underlying read 
Hive,WITHOUT_CLASSIFICATION,//  1. Generate the token for query user (applies to all splits). 
Hive,WITHOUT_CLASSIFICATION,//  For each source to write to get the appropriate lock type.  If it's   an OVERWRITE we need to get an exclusive lock.  If it's an insert (no   overwrite) than we need a shared.  If it's update or delete then we 
Hive,WITHOUT_CLASSIFICATION,/*  there are filter operators in the pipeline  */
Hive,WITHOUT_CLASSIFICATION,//  check filter input contains no correlation 
Hive,WITHOUT_CLASSIFICATION,//  analyzeCreateView uses this.ast but doPhase1 doesn't so only reset it   here. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure session init gets stuck in init. 
Hive,WITHOUT_CLASSIFICATION,// double wait time until 5min 
Hive,WITHOUT_CLASSIFICATION,//  We want to use the ReturnObjectInspectorResolver because otherwise   ObjectInspectorUtils.compare() will return != for two objects that have   different object inspectors e.g. 238 and "238". The ROIR will help convert   both values to a common type so that they can be compared reasonably. 
Hive,WITHOUT_CLASSIFICATION,// update the nextlevel with newly discovered sub-directories from the above 
Hive,WITHOUT_CLASSIFICATION,//  Create the list if needed 
Hive,WITHOUT_CLASSIFICATION,//  We don't expect cache requests from the middle. 
Hive,WITHOUT_CLASSIFICATION,//  there's some special handling for dummyOps required. Mapjoins won't be properly   initialized if their dummy parents aren't initialized. Since we cloned the plan 
Hive,WITHOUT_CLASSIFICATION,//  Zero. 
Hive,WITHOUT_CLASSIFICATION,//  No message is needed. 
Hive,WITHOUT_CLASSIFICATION,//  http://web.archive.org/web/20071223173210/http://www.concentric.net/~Ttwang/tech/inthash.htm 
Hive,WITHOUT_CLASSIFICATION,//  Enable BlobStore optimizations for the rest of tests 
Hive,WITHOUT_CLASSIFICATION,//  Null HiveConf is passed in jdbc driver side code since driver side is supposed to be   independent of conf object. Create new HiveConf object here in this case. 
Hive,WITHOUT_CLASSIFICATION,//  if the version doesn't exist then create it 
Hive,WITHOUT_CLASSIFICATION,/*  If the counters are missing there is no point trying to print progress  */
Hive,WITHOUT_CLASSIFICATION,//  need to clean data directory to ensure that there is no interference from old runs   Cleaning is happening here to allow debugging in case of tests fail   we don;t have to clean logs since it is an append mode 
Hive,WITHOUT_CLASSIFICATION,//  create a walker which walks the tree in a DFS manner while maintaining the   operator stack. The dispatcher generates the plan from the operator tree 
Hive,WITHOUT_CLASSIFICATION,//  Replicate insert event and verify 
Hive,WITHOUT_CLASSIFICATION,//  Do Decimal64 conversion instead. 
Hive,WITHOUT_CLASSIFICATION,//  Both are non-empty only copy now 
Hive,WITHOUT_CLASSIFICATION,//  The JDOException may be wrapped further in a MetaException 
Hive,WITHOUT_CLASSIFICATION,//  Trigger rewriting to remove UNION branch with MV 
Hive,WITHOUT_CLASSIFICATION,//  As all txns below min_uncommitted_txnid are either committed or empty_aborted we are allowed 
Hive,WITHOUT_CLASSIFICATION,//  Should now have new lock on ACIDTBLPART 
Hive,WITHOUT_CLASSIFICATION,//  non-acid 
Hive,WITHOUT_CLASSIFICATION,//  Check whether the shuffle version is compatible 
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.ql.hooks.proto.HiveHookEvents.MapFieldEntry.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,//  vectorTaskColumnInfo. 
Hive,WITHOUT_CLASSIFICATION,//  Already setup in the create method 
Hive,WITHOUT_CLASSIFICATION,/*      * If the skewedValues contains ((123)(456)) and the user is looking for     * positions (02) the result would be ((13)(46))     * Get the skewed key values that are part of the join key.     * @param skewedValuesList List of all the skewed values     * @param positionSkewedKeys the requested positions     * @return sub-list of skewed values with the positions present      */
Hive,WITHOUT_CLASSIFICATION,//  Queries without a source table currently are not supported by CBO 
Hive,WITHOUT_CLASSIFICATION,//  Start a third batch but don't close it.  this delta will be ignored by compaction since 
Hive,WITHOUT_CLASSIFICATION,//  If the cookie based authentication is already enabled parse the 
Hive,WITHOUT_CLASSIFICATION,//  Nope so look to see if we can find a conf file by finding our jar going up one   directory and looking for a conf directory. 
Hive,WITHOUT_CLASSIFICATION,//  Put the mapping from table scan operator to part-pruner map 
Hive,WITHOUT_CLASSIFICATION,//  Diff against table on target. 
Hive,WITHOUT_CLASSIFICATION,//  location is not shown in test mode 
Hive,WITHOUT_CLASSIFICATION,//  Only database object is updated 
Hive,WITHOUT_CLASSIFICATION,//  CSVReader will throw an exception if any of separator quote or escape is the same but   the CSV format specifies that the escape character and quote char are the same... very weird 
Hive,WITHOUT_CLASSIFICATION,//  we don't have many file formats that implement InputFormatChecker. We won't be holding 
Hive,WITHOUT_CLASSIFICATION,// Move data from temp directory the actual table directory 
Hive,WITHOUT_CLASSIFICATION,//  IS_ALL_PARTS 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   required   required   required   required   required   optional 
Hive,WITHOUT_CLASSIFICATION,//  remote metastore mode 
Hive,WITHOUT_CLASSIFICATION,//  id 
Hive,WITHOUT_CLASSIFICATION,/*  This class should be replaced with org.apache.hadoop.mapred.lib.CombineFileRecordReader class once   * https://issues.apache.org/jira/browse/MAPREDUCE-955 is fixed. This code should be removed - it is a copy   * of org.apache.hadoop.mapred.lib.CombineFileRecordReader    */
Hive,WITHOUT_CLASSIFICATION,//  column statistics from different sources are put together and 
Hive,WITHOUT_CLASSIFICATION,//  Event 9 10 
Hive,WITHOUT_CLASSIFICATION,// should fail because the TransactionBatch timed out 
Hive,WITHOUT_CLASSIFICATION,//  Whether the native vectorized map join operator has performed its common setup. 
Hive,WITHOUT_CLASSIFICATION,// update stmt has p=blah thus nothing is actually update and we generate empty dyn part list 
Hive,WITHOUT_CLASSIFICATION,//  Prewarm CachedStore 
Hive,WITHOUT_CLASSIFICATION,/*          * Check.5.h :: For In and Not In the SubQuery must implicitly or         * explicitly only contain one select item.          */
Hive,WITHOUT_CLASSIFICATION,//  add uncovered ACID delta splits 
Hive,WITHOUT_CLASSIFICATION,// make sure we assign correct Ids 
Hive,WITHOUT_CLASSIFICATION,//  These names/types are the data columns plus partition columns. 
Hive,WITHOUT_CLASSIFICATION,//  Sleep before we send checkLock again but do it with a back off 
Hive,WITHOUT_CLASSIFICATION,// try a valid alter table partition key comment 
Hive,WITHOUT_CLASSIFICATION,//  Add small table result columns. 
Hive,WITHOUT_CLASSIFICATION,//  Validate the update of new column c even in old rows. 
Hive,WITHOUT_CLASSIFICATION,//  If dataStr is not null and dataStr is not a KV pattern 
Hive,WITHOUT_CLASSIFICATION,//  expand the nested script   If the metaDbType is set this is setting up the information   schema in Hive. That specifically means that the sql commands need   to be adjusted for the underlying RDBMS (correct quotation   strings etc). 
Hive,WITHOUT_CLASSIFICATION,// populate source 
Hive,WITHOUT_CLASSIFICATION,//  all of the joins fit into half the memory. Let's be safe and scale them out. 
Hive,WITHOUT_CLASSIFICATION,/*        * parse ResultExpr Str and setup OI.        */
Hive,WITHOUT_CLASSIFICATION,//  creat default dir 
Hive,WITHOUT_CLASSIFICATION,/*  * This class is the payload for custom vertex. It serializes and de-serializes * @numBuckets: the number of buckets of the "big table" * @vertexType: this is the type of vertex and differentiates between bucket map join and SMB joins * @numInputs: The number of inputs that are directly connected to the vertex (MRInput/MultiMRInput). *             In case of bucket map join it is always 1. * @inputName: This is the name of the input. Used in case of SMB joins. Empty in case of BucketMapJoin  */
Hive,WITHOUT_CLASSIFICATION,//  Repl imports are replace-imports and thus are idempotent.   Note that this assumes that this ImportCommand is running on an export dump   created using EXPORT ... FOR REPLICATION. If the scope of ImportCommand   were to eventually expand to importing dumps created by regular exports   then this needs updating. 
Hive,WITHOUT_CLASSIFICATION,//  Test if rpc_server_address is not configured but HS2 server host is configured 
Hive,WITHOUT_CLASSIFICATION,//  Make the list of transactional tables list which are getting read or written by current txn 
Hive,WITHOUT_CLASSIFICATION,//  Note: given that we return pool sessions to the pool in the finally block below and that 
Hive,WITHOUT_CLASSIFICATION,//  End of input. Confirm we got end of stream indicator from server   as well as DONE status from fragment execution. 
Hive,WITHOUT_CLASSIFICATION,/*     We are testing for both type of modes always so not passing that as a parameter for now   */
Hive,WITHOUT_CLASSIFICATION,//  Serialize the result struct 
Hive,WITHOUT_CLASSIFICATION,//  retain this digit 
Hive,WITHOUT_CLASSIFICATION,//  Tracks tasks which are running. Useful for selecting a task to preempt based on when it started. 
Hive,WITHOUT_CLASSIFICATION,//  maxCapacity should be calculated based on a percentage of memoryThreshold which is to divide   row size using long size 
Hive,WITHOUT_CLASSIFICATION,// delete clause 
Hive,WITHOUT_CLASSIFICATION,//  unique key of the leftInputRel 
Hive,WITHOUT_CLASSIFICATION,/*    * Validation:   * 1) Substitute class name for "ThisClass".   * 2) Only public fields and methods are versioned.   * 3) Methods compare on [non-]static return type name parameter types exceptions thrown.   * 4) Fields compare on [non-]static type name value when static    */
Hive,WITHOUT_CLASSIFICATION,//  decimal means decimal(100) 
Hive,WITHOUT_CLASSIFICATION,//  Note: the normalize() call with rounding in HiveDecimal will currently reduce the         precision and scale of the value by throwing away trailing zeroes. This may or may         not be desirable for the literals; however this used to be the default behavior         for explicit decimal literals (e.g. 1.0BD) so we keep this behavior for now. 
Hive,WITHOUT_CLASSIFICATION,//  This field is not a null. 
Hive,WITHOUT_CLASSIFICATION,//  regular single-partition write into a partitioned table. 
Hive,WITHOUT_CLASSIFICATION,//  Safety check 
Hive,WITHOUT_CLASSIFICATION,//  Save the conf variable values so that they can be restored later. 
Hive,WITHOUT_CLASSIFICATION,/*      * Initialization here is adapted from MapOperator.MapOpCtx.initObjectInspector method.      */
Hive,WITHOUT_CLASSIFICATION,//  Validate there is an added NULL for column c. 
Hive,WITHOUT_CLASSIFICATION,//  Get Output Committer 
Hive,WITHOUT_CLASSIFICATION,//  call-5: open - mock:/mocktbl2/0_1 
Hive,WITHOUT_CLASSIFICATION,//  No data to read. 
Hive,WITHOUT_CLASSIFICATION,//  Third row 
Hive,WITHOUT_CLASSIFICATION,//  If fatal errors happen we should kill the job immediately rather than 
Hive,WITHOUT_CLASSIFICATION,//  Test basic right trim to vector. 
Hive,WITHOUT_CLASSIFICATION,//  add unique element to list per occurrence order in skewed value.   occurrence order in skewed value doesn't matter. 
Hive,WITHOUT_CLASSIFICATION,//  We store CHAR in vector row batch with padding stripped. 
Hive,WITHOUT_CLASSIFICATION,//  RPC already handles retries so we will just try to kill the session here.   This will cause the current query to fail. We could instead keep retrying. 
Hive,WITHOUT_CLASSIFICATION,//  Serialize numDistinctValue Estimator 
Hive,WITHOUT_CLASSIFICATION,//  Run hive metastore server 
Hive,WITHOUT_CLASSIFICATION,// mock operationManager for session 
Hive,WITHOUT_CLASSIFICATION,/*         Case data is sorted by time and an extra hashing dimension see DRUID_SHARD_KEY_COL_NAME        Thus use DRUID_SHARD_KEY_COL_NAME as segment partition in addition to time dimension        Data with the same DRUID_SHARD_KEY_COL_NAME and Time interval will end in the same segment         */
Hive,WITHOUT_CLASSIFICATION,//  Check that writeid#5 has been excluded.   Check that the data is in sorted order. 
Hive,WITHOUT_CLASSIFICATION,// should never happen since we are reading bucket_x written by acid write 
Hive,WITHOUT_CLASSIFICATION,//  do not do any blocking IO ops on this thread. 
Hive,WITHOUT_CLASSIFICATION,//  However it can be a constant too. In that case we need to track   the column that it originated from in the input operator so we can   propagate the aliases. 
Hive,WITHOUT_CLASSIFICATION,/*    * This batch is only used by vector/row deserializer readers.    */
Hive,WITHOUT_CLASSIFICATION,// special handling for SQL "delete from <table> where..." 
Hive,WITHOUT_CLASSIFICATION,//  show database level privileges 
Hive,WITHOUT_CLASSIFICATION,//  Add in hive-site.xml.  We add this first so that it gets overridden by the new metastore 
Hive,WITHOUT_CLASSIFICATION,//  HiveServer2 specific configs 
Hive,WITHOUT_CLASSIFICATION,//  Create a new outgoing vectorization context because column name map will change. 
Hive,WITHOUT_CLASSIFICATION,// 12 chars - try to keep cols aligned 
Hive,WITHOUT_CLASSIFICATION,//  set current user in session conf 
Hive,WITHOUT_CLASSIFICATION,//   file pattern that is set in PROPERTIES_FILE 
Hive,WITHOUT_CLASSIFICATION,//  pRS-pGBY-cRS 
Hive,WITHOUT_CLASSIFICATION,//  Ensure Pig can write correctly to smallint/tinyint columns. This means values within the 
Hive,WITHOUT_CLASSIFICATION,//  Alter all partitions 
Hive,WITHOUT_CLASSIFICATION,//  Create the row object 
Hive,WITHOUT_CLASSIFICATION,//  Final result 
Hive,WITHOUT_CLASSIFICATION,//  We deserialize the result 
Hive,WITHOUT_CLASSIFICATION,//  Temp tables that do not go through SemanticAnalyzer may not have location set - do it here.   For example export of acid tables generates a query plan that creates a temp table. 
Hive,WITHOUT_CLASSIFICATION,//  Find which columns we need to update for this partition if any. 
Hive,WITHOUT_CLASSIFICATION,//       and preserve rows only from left side. 
Hive,WITHOUT_CLASSIFICATION,//  Create root scratchdir with write all so that user impersonation has no issues. 
Hive,WITHOUT_CLASSIFICATION,//  if unionWork is null it means it is the first time. we need to   create a union work object and add this work to it. Subsequent   work should reference the union and not the actual work. 
Hive,WITHOUT_CLASSIFICATION,//  aggregation result null? 
Hive,WITHOUT_CLASSIFICATION,//  from TXN_COMPONENTS. 
Hive,WITHOUT_CLASSIFICATION,//  process the first node to extract tablename 
Hive,WITHOUT_CLASSIFICATION,// now we have a table with data files at multiple different levels. 
Hive,WITHOUT_CLASSIFICATION,//  CHECK_EXPRESSION 
Hive,WITHOUT_CLASSIFICATION,//  no need to add for the default supported local jar driver 
Hive,WITHOUT_CLASSIFICATION,//  Set the thread local ip address 
Hive,WITHOUT_CLASSIFICATION,//  Reimplemented to use PrimitiveCategory rather than TypeInfo because   2 TypeInfos from the same qualified type (varchar decimal) should still be   seen as equivalent. 
Hive,WITHOUT_CLASSIFICATION,//  init output 
Hive,WITHOUT_CLASSIFICATION,//  func may be null when GBY op is closing.   see mvn test -Dtest=TestMiniTezCliDriver -Dqfile=explainuser_3.q   original behavior is to create FMSketch 
Hive,WITHOUT_CLASSIFICATION,//  We need to make sure that all the field associated with the union are settable. 
Hive,WITHOUT_CLASSIFICATION,//  can't use the current table as the big table but it's too   big for the map side. 
Hive,WITHOUT_CLASSIFICATION,//  Cycle consists of atleast one dynamic partition pruning(DPP)   optimization and atleast one min/max optimization.   DPP is a better optimization unless it ends up scanning the   bigger table for keys instead of the smaller table. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setObject(java.lang.String   * java.lang.Object int)    */
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hadoop.mapreduce.InputSplit#getLocations()    */
Hive,WITHOUT_CLASSIFICATION,//  If partitioning columns of the child RS are assigned   assign these to the partitioning columns of the parent RS. 
Hive,WITHOUT_CLASSIFICATION,//  LOG.info("Found list record at " + writeBuffers.getReadPoint());   Assumes we are here after key compare. 
Hive,WITHOUT_CLASSIFICATION,// AddNotNullConstraintEvent addCheckConstraintEvent = new AddNotNullConstraintEvent(checkConstraintCols true this);  listener.onAddCheckConstraint(addCheckConstraintEvent); 
Hive,WITHOUT_CLASSIFICATION,//  5. If the product of the topPermutation and bottomPermutation yields      the identity then we can swap the join and remove the project on 
Hive,WITHOUT_CLASSIFICATION,//  Synchronized by locking on itself. 
Hive,WITHOUT_CLASSIFICATION,//  when we make a new connection we should get it from miniHS2_2 this time 
Hive,WITHOUT_CLASSIFICATION,//  tablename and pattern 
Hive,WITHOUT_CLASSIFICATION,//  After we set originalData to null we incref the buffer and the cleanup would decref it.   Note that this assumes the failure during incref means incref didn't occur. 
Hive,WITHOUT_CLASSIFICATION,//  data for HLL++ bias correction 
Hive,WITHOUT_CLASSIFICATION,//  f is a directory 
Hive,WITHOUT_CLASSIFICATION,// base_n cannot contain update/delete.  Original files are all 'insert' and we need to compact  only if there are update/delete events. 
Hive,WITHOUT_CLASSIFICATION,//  Create an aggregate on top with the new aggregate list. 
Hive,WITHOUT_CLASSIFICATION,//  Should generate (-inf+inf) 
Hive,WITHOUT_CLASSIFICATION,//  move onto the next null byte 
Hive,WITHOUT_CLASSIFICATION,//  is marked as being read.  Defaults to true as that is the most common case. 
Hive,WITHOUT_CLASSIFICATION,//  extend any repeating values and noNulls indicator in the inputs 
Hive,WITHOUT_CLASSIFICATION,// return genConvertCol(dest qb tab table_desc input Arrays.asList(0) convert);   In the case of update and delete the bucketing column is always the first column   and it isn't in the table info.  So rather than asking the table for it   we'll construct it ourself and send it back.  This is based on the work done in   genConvertCol below. 
Hive,WITHOUT_CLASSIFICATION,//  These are global since ORC reuses objects between stripes. 
Hive,WITHOUT_CLASSIFICATION,//  Steps:   1. Create the archive in a temporary folder   2. Move the archive dir to an intermediate dir that is in at the same      dir as the original partition dir. Call the new dir      intermediate-archive.   3. Rename the original partition dir to an intermediate dir. Call the      renamed dir intermediate-original   4. Rename intermediate-archive to the original partition dir   5. Change the metadata   6. Delete the original partition files in intermediate-original 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getBlob(java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  remove `` 
Hive,WITHOUT_CLASSIFICATION,//  Parse the configuration parameters 
Hive,WITHOUT_CLASSIFICATION,//  Number of reducers is set to default (-1) 
Hive,WITHOUT_CLASSIFICATION,//  each bucket. 
Hive,WITHOUT_CLASSIFICATION,//  If do not match ignore the line return a row with all nulls. 
Hive,WITHOUT_CLASSIFICATION,//  In effect the input is NULL because of out-of-range precision/scale. 
Hive,WITHOUT_CLASSIFICATION,//  ID 1 has been committed all others open 
Hive,WITHOUT_CLASSIFICATION,//  whether it contains a sort merge join operator 
Hive,WITHOUT_CLASSIFICATION,//  Always choose the function with least implicit conversions. 
Hive,WITHOUT_CLASSIFICATION,// Join operators which may be converted by CommonJoinResolver; 
Hive,WITHOUT_CLASSIFICATION,//  CONF_OVERLAY 
Hive,WITHOUT_CLASSIFICATION,//  In order to facilitate partition pruning or the where clauses together and put them at the 
Hive,WITHOUT_CLASSIFICATION,//  2. rewrite the AST replace TABREF with masking/filtering 
Hive,WITHOUT_CLASSIFICATION,//  T | T | T 
Hive,WITHOUT_CLASSIFICATION,//  1. Insert MapSide RS 
Hive,WITHOUT_CLASSIFICATION,//  End the pools array. 
Hive,WITHOUT_CLASSIFICATION,//  send failover request again to miniHS2_1 and get a failure 
Hive,WITHOUT_CLASSIFICATION,//  We got the expr for one full partition spec. Determine the prefix length. 
Hive,WITHOUT_CLASSIFICATION,//  So save old values... 
Hive,WITHOUT_CLASSIFICATION,//  See https://blogs.msdn.microsoft.com/sqlprogrammability/2006/03/29/multiplication-and-division-with-numerics/ 
Hive,WITHOUT_CLASSIFICATION,//  we need staging directories as long as a single partition needed addition 
Hive,WITHOUT_CLASSIFICATION,//  paths = bucket files of small table for current bucket file of big table   initializes a FetchOperator for each file in paths reuses FetchOperator if possible   currently number of paths is always the same (bucket numbers are all the same over   all partitions in a table). 
Hive,WITHOUT_CLASSIFICATION,//  initialize export path 
Hive,WITHOUT_CLASSIFICATION,//  Validate that the multi-join is a valid star join before returning it. 
Hive,WITHOUT_CLASSIFICATION,//  Unequal strings 
Hive,WITHOUT_CLASSIFICATION,// verifyRun("SELECT a from " + replDbName + ".mat_view" ptn_data_1 driverMirror); 
Hive,WITHOUT_CLASSIFICATION,//  caches objects before constructing forward cache 
Hive,WITHOUT_CLASSIFICATION,//  Add the rest to the memory consumption 
Hive,WITHOUT_CLASSIFICATION,//  Verify the fetched log (incrementally) 
Hive,WITHOUT_CLASSIFICATION,//  What we are trying to get is the equivalent of new Date(ymd).getTime() in the local tz   where ymd is whatever d represents. How it "works" is this. 
Hive,WITHOUT_CLASSIFICATION,//  We can create Calcite IS_DISTINCT_FROM operator for this. But since our   join reordering algo cant handle this anyway there is no advantage of   this.So bail out for now. 
Hive,WITHOUT_CLASSIFICATION,//  test when two jars with shared dependencies are added the classloader contains union of the dependencies 
Hive,WITHOUT_CLASSIFICATION,//  intersperse getAt and next calls 
Hive,WITHOUT_CLASSIFICATION,//  Make sure the referenced schema exists 
Hive,WITHOUT_CLASSIFICATION,//  It will only throw JSONException when stats.put(BASIC_STATS TRUE)   has duplicate key which is not possible 
Hive,WITHOUT_CLASSIFICATION,//  only mechanical data retrieval should remain here. 
Hive,WITHOUT_CLASSIFICATION,//  only a column family 
Hive,WITHOUT_CLASSIFICATION,//     conf.setVar(HiveConf.ConfVars.SEMANTIC_ANALYZER_HOOK CheckInputReadEntityDirect.class.getName()); 
Hive,WITHOUT_CLASSIFICATION,//  This is an unsupported operator 
Hive,WITHOUT_CLASSIFICATION,//  create a walker which walks the tree in a BFS manner while maintaining the 
Hive,WITHOUT_CLASSIFICATION,//  The target column list has the format "TargetWork -> [colName:colType(expression) ...] ..." 
Hive,WITHOUT_CLASSIFICATION,//  note we use col[1] -- the key is provided again as col[0] 
Hive,WITHOUT_CLASSIFICATION,//  class to read (and re-read) the values. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *    * @see   * org.apache.hadoop.hive.ql.exec.UDAFMethodResolver#getEvaluatorClass(java   * .util.List)    */
Hive,WITHOUT_CLASSIFICATION,//  We need to make sure that the underlying fields are settable as well.   Hence the recursive call for each field.   Note that equalsCheck is false while invoking getConvertedOI() because   we need to bypass the initial inputOI.equals(outputOI) check. 
Hive,WITHOUT_CLASSIFICATION,//  reuse super renewal logic 
Hive,WITHOUT_CLASSIFICATION,//  The application-level name   Component name   Component description   Name for each metric record 
Hive,WITHOUT_CLASSIFICATION,//  serialized sizes after serialization and deserialization should be equal 
Hive,WITHOUT_CLASSIFICATION,//  Variables to hold state from before flattening so it can be easily restored. 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   optional   optional   optional   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  First check the local cache. 
Hive,WITHOUT_CLASSIFICATION,//  Do nothing. 
Hive,WITHOUT_CLASSIFICATION,//  we'd have thrown an exception 
Hive,WITHOUT_CLASSIFICATION,//  Need to hive.server2.session.hook to SessionHookTest in hive-site 
Hive,WITHOUT_CLASSIFICATION,//  duplicate of the value. Merging should remove duplicates 
Hive,WITHOUT_CLASSIFICATION,//  sleep for expiry time and then fetch again 
Hive,WITHOUT_CLASSIFICATION,//  Upgrade schema from 0.7.0 to latest 
Hive,WITHOUT_CLASSIFICATION,//  Apply comparison rules 
Hive,WITHOUT_CLASSIFICATION,// for close the local work 
Hive,WITHOUT_CLASSIFICATION,//  output is also big so the output size is 1 (medium) 
Hive,WITHOUT_CLASSIFICATION,//  for left outer joins left alias is sorted but right alias might be not 
Hive,WITHOUT_CLASSIFICATION,//  No errors 
Hive,WITHOUT_CLASSIFICATION,//  Grow. 
Hive,WITHOUT_CLASSIFICATION,//  Try to roll the key if none is found. 
Hive,WITHOUT_CLASSIFICATION,//  Don't construct an illegal cache key 
Hive,WITHOUT_CLASSIFICATION,//  Try to fold (key = 86) and (key is not null) to (key = 86) 
Hive,WITHOUT_CLASSIFICATION,//  initializes them. 
Hive,WITHOUT_CLASSIFICATION,//  Finishes the vectorization context after all the initial 
Hive,WITHOUT_CLASSIFICATION,//  All the locks are created under this parent 
Hive,WITHOUT_CLASSIFICATION,//  such as "a%bc" 
Hive,WITHOUT_CLASSIFICATION,//  preserve precision. 
Hive,WITHOUT_CLASSIFICATION,//  Create a single child representing the scratch column where we will 
Hive,WITHOUT_CLASSIFICATION,//  Test strict locking mode i.e. backward compatible locking mode for non-ACID resources.   With non-strict mode INSERT got SHARED_READ lock instead of EXCLUSIVE with ACID semantics 
Hive,WITHOUT_CLASSIFICATION,//  since we are running the mapred task in the same jvm we should update the job conf 
Hive,WITHOUT_CLASSIFICATION,//  the big table can be divided by no of buckets in small tables. 
Hive,WITHOUT_CLASSIFICATION,//  Update max if max is greater than the largest value seen so far 
Hive,WITHOUT_CLASSIFICATION,//  Disable ansi sql arithmetic changes 
Hive,WITHOUT_CLASSIFICATION,//  setting these 2 parameters here just in case that if the code got   changed in future these 2 are not missing. 
Hive,WITHOUT_CLASSIFICATION,//  Boolean is purposely excluded. 
Hive,WITHOUT_CLASSIFICATION,// now run another compaction make sure empty dirs don't cause issues 
Hive,WITHOUT_CLASSIFICATION,//  check if it is potential to trigger nullscan 
Hive,WITHOUT_CLASSIFICATION,// compress key and write key out 
Hive,WITHOUT_CLASSIFICATION,//  of gathering stats 
Hive,WITHOUT_CLASSIFICATION,//  Set READ_ALL_COLUMNS to false 
Hive,WITHOUT_CLASSIFICATION,//  Update file sink descriptor 
Hive,WITHOUT_CLASSIFICATION,//  is usually called after close() to commit or rollback a query and end the driver life cycle. 
Hive,WITHOUT_CLASSIFICATION,//  Display Error Message for tasks with the highest failure count 
Hive,WITHOUT_CLASSIFICATION,//  We DO NOT set a bit in the NULL byte when we are writing a NULL. 
Hive,WITHOUT_CLASSIFICATION,//  reasons. Roots are data sources leaves are data sinks. I know. 
Hive,WITHOUT_CLASSIFICATION,//  For each path do getSplits(). 
Hive,WITHOUT_CLASSIFICATION,//  If fop2 exists (i.e this is not the top level filter and fop2 is not 
Hive,WITHOUT_CLASSIFICATION,//  Create the required temporary file in the HDFS location if the destination 
Hive,WITHOUT_CLASSIFICATION,//  Set stats config for FileSinkOperators which are cloned from the fileSink 
Hive,WITHOUT_CLASSIFICATION,//  all its parents operators are in state CLOSE and called close()   to children. Note: close() being called and its state being CLOSE is   difference since close() could be called but state is not CLOSE if   one of its parent is not in state CLOSE.. 
Hive,WITHOUT_CLASSIFICATION,// start "delete from tab1" txn 
Hive,WITHOUT_CLASSIFICATION,//  this is an invalid decimal value getting HiveDecimal from it will return null 
Hive,WITHOUT_CLASSIFICATION,//  Rows we looked up as one repeated key are a match.  But filtered out rows   need to be generated as non-matches too. 
Hive,WITHOUT_CLASSIFICATION,/*      * Connect via kerberos and get delegation token      */
Hive,WITHOUT_CLASSIFICATION,// at lest for now Load Data w/Overwrite is not allowed in a txn: HIVE-18154 
Hive,WITHOUT_CLASSIFICATION,//  Adding postgres jdbc driver if exists 
Hive,WITHOUT_CLASSIFICATION,//  Note that partitioning fields dont need to change since it is either   partitioned randomly or by all grouping keys + distinct keys 
Hive,WITHOUT_CLASSIFICATION,//  remote metastore situation. 
Hive,WITHOUT_CLASSIFICATION,//  authorization error is not really expected in a filter call   the impl should have just filtered out everything. A checkPrivileges call   would have already been made to authorize this action 
Hive,WITHOUT_CLASSIFICATION,//  The split doesn't exclusively serve one alias 
Hive,WITHOUT_CLASSIFICATION,//  No outer join involved 
Hive,WITHOUT_CLASSIFICATION,//  only left input repeating and has no nulls 
Hive,WITHOUT_CLASSIFICATION,//  search for match in the rhs table 
Hive,WITHOUT_CLASSIFICATION,/*  10 files x 1000 size for 10 splits  */
Hive,WITHOUT_CLASSIFICATION,// this should block behind the X lock on  T7.p=1 
Hive,WITHOUT_CLASSIFICATION,/*  Sum of lengths of all values seen so far  */
Hive,WITHOUT_CLASSIFICATION,//  The join operation in the child is not on the same keys 
Hive,WITHOUT_CLASSIFICATION,//  Per ListObjectInpsector.getListLength() -1 length means null list. 
Hive,WITHOUT_CLASSIFICATION,//  Add an all-null record 
Hive,WITHOUT_CLASSIFICATION,//  Handle leading/trailing whitespace 
Hive,WITHOUT_CLASSIFICATION,//  Format the stored by statement 
Hive,WITHOUT_CLASSIFICATION,//  TODO: if more writers are added separate out an EncodingWriterFactory 
Hive,WITHOUT_CLASSIFICATION,//  condition for merging is not met see GenMRFileSink1. 
Hive,WITHOUT_CLASSIFICATION,//  validate response 
Hive,WITHOUT_CLASSIFICATION,//  SessionState is null this is unlikely to happen just in case 
Hive,WITHOUT_CLASSIFICATION,//  keys from FetchSampler are collected here 
Hive,WITHOUT_CLASSIFICATION,//  Note: we cache slices one by one since we need to lock them before sending to consumer.         We could lock here then cache them together then unlock here and in return 
Hive,WITHOUT_CLASSIFICATION,//  The state only changes from true->false   Once set to false it may not change back to true 
Hive,WITHOUT_CLASSIFICATION,//  uncaught exception handler that will be set for all threads before execution 
Hive,WITHOUT_CLASSIFICATION,// expect 1 base or delta dir in this list 
Hive,WITHOUT_CLASSIFICATION,//  By default no children or inputs. 
Hive,WITHOUT_CLASSIFICATION,//  Exchange partition is not allowed with transactional tables.   If only source is transactional table then target will see deleted rows too as no snapshot   isolation applicable for non-acid tables.   If only target is transactional table then data would be visible to all ongoing transactions   affecting the snapshot isolation.   If both source and targets are transactional tables then target partition may have delta/base 
Hive,WITHOUT_CLASSIFICATION,//  The dispatcher fires the processor corresponding to the closest matching   rule and passes the context along 
Hive,WITHOUT_CLASSIFICATION,//  An optional group containing multiple elements 
Hive,WITHOUT_CLASSIFICATION,//  We are done with the buffers; unlike data blocks we are also the consumer. Release. 
Hive,WITHOUT_CLASSIFICATION,//  small table. 
Hive,WITHOUT_CLASSIFICATION,//  two parts of kerberos principal 
Hive,WITHOUT_CLASSIFICATION,//  cte is actually a subquery. 
Hive,WITHOUT_CLASSIFICATION,//  Execute SELECT and verify that aborted operation is not counted for MM table. 
Hive,WITHOUT_CLASSIFICATION,//  This should eventually hang in the delay code.   From the background thread. 
Hive,WITHOUT_CLASSIFICATION,//  We reuse the same hashmap to reduce new object allocation.   This means counts can be empty when there is no input data. 
Hive,WITHOUT_CLASSIFICATION,//  while 
Hive,WITHOUT_CLASSIFICATION,//  18 9's -- quite reliable! 
Hive,WITHOUT_CLASSIFICATION,//  MetaException here really means ClassNotFound (see the utility method).   So if any of these happen that means we can never succeed. 
Hive,WITHOUT_CLASSIFICATION,//  getHiveDefaultLocation(). 
Hive,WITHOUT_CLASSIFICATION,//  Initialize fetch work such that operator tree will be constructed. 
Hive,WITHOUT_CLASSIFICATION,//  get the values of repetition and definitionLevel 
Hive,WITHOUT_CLASSIFICATION,//  instead of maintaining complex state for the fetch of the next group   we know for sure that at the end of all the values for a given key   we will definitely reach the next key group. 
Hive,WITHOUT_CLASSIFICATION,//  write a base 
Hive,WITHOUT_CLASSIFICATION,//  spread k-1 bits to adjacent longs default is 8   spreading hash bits within blockSize * longs will make bloom filter L1 cache friendly 
Hive,WITHOUT_CLASSIFICATION,//  in DB is set to bootstrap dump location used in C but for table/partition it is missing. 
Hive,WITHOUT_CLASSIFICATION,//  Collect column stats which need to be rewritten and remove old stats 
Hive,WITHOUT_CLASSIFICATION,//  Setup Local Dirs 
Hive,WITHOUT_CLASSIFICATION,//  End of entry reached? 
Hive,WITHOUT_CLASSIFICATION,// make sure we know we saw an error that we don't recognize 
Hive,WITHOUT_CLASSIFICATION,/*                * Multi-Key specific save key and lookup.                */
Hive,WITHOUT_CLASSIFICATION,//  For WebUI.  Kept alive after queryPlan is freed. 
Hive,WITHOUT_CLASSIFICATION,//  Note that enableBitVector does not apply here because ColumnStatisticsObj   itself will tell whether bitvector is null or not and aggr logic can automatically apply. 
Hive,WITHOUT_CLASSIFICATION,// Pig script was successful 
Hive,WITHOUT_CLASSIFICATION,//  Repeat the procedure for the new select. 
Hive,WITHOUT_CLASSIFICATION,//  WRITE_ID 
Hive,WITHOUT_CLASSIFICATION,//  reducer 
Hive,WITHOUT_CLASSIFICATION,//  Try some time zone boundaries 
Hive,WITHOUT_CLASSIFICATION,//  removes any union operator and clones the plan 
Hive,WITHOUT_CLASSIFICATION,//  there's no key to return 
Hive,WITHOUT_CLASSIFICATION,//  if init file contains incorrect row 
Hive,WITHOUT_CLASSIFICATION,//  reset and add counters. This can happen during start of query or a session being moved to another pool with its   own set of triggers 
Hive,WITHOUT_CLASSIFICATION,//  %% is folded in the .*?.*? regex usually into .*? 
Hive,WITHOUT_CLASSIFICATION,//  3. Build new Table 
Hive,WITHOUT_CLASSIFICATION,//  Make sure that the user doesn't happen to be in the super group 
Hive,WITHOUT_CLASSIFICATION,//  The cache buffer comprises the tail of the requested range (and possibly overshoots it).   The same as above applies - may throw if cache buffer is larger than the requested range   and there's another range after this that starts in the middle of this cache buffer.   Currently we cache at exact offsets so the latter should never happen. 
Hive,WITHOUT_CLASSIFICATION,//  set data to empty explicitly 
Hive,WITHOUT_CLASSIFICATION,//  We are trying to check ACLs on the "workers" directory which noone except us should be   able to write to. Higher-level directories shouldn't matter - we don't read them. 
Hive,WITHOUT_CLASSIFICATION,//  show create table is more sensitive information includes table properties etc 
Hive,WITHOUT_CLASSIFICATION,//  non-transient field used at runtime to kill a task if it exceeded memory limits when running in LLAP 
Hive,WITHOUT_CLASSIFICATION,/*    * Patterns of isRepeating columns   * For boolean: tri-state: null 0 1   * For others: null some-value   * noNulls: sometimes false and there are no NULLs.   * Random selectedInUse too.    */
Hive,WITHOUT_CLASSIFICATION,//  use the table default storage specification 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) Typei16  */
Hive,WITHOUT_CLASSIFICATION,//  make sure the arguments make sense 
Hive,WITHOUT_CLASSIFICATION,//  Valid schemes 
Hive,WITHOUT_CLASSIFICATION,//  this is backward compatible for non-ACID resources w/o ACID semantics 
Hive,WITHOUT_CLASSIFICATION,//  We have ensured that the keys are columns 
Hive,WITHOUT_CLASSIFICATION,//  Use EntityDescriptorProto.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,//  a delete delta file with 25000 delete events. 
Hive,WITHOUT_CLASSIFICATION,//  This is one of the columns we're setting record it's position so we can come back   later and patch it up.   Add one to the index because the select has the ROW__ID as the first column. 
Hive,WITHOUT_CLASSIFICATION,//  Add stuff here as WM is implemented. 
Hive,WITHOUT_CLASSIFICATION,//  Special case for root parent 
Hive,WITHOUT_CLASSIFICATION,//  Make sure that each session has its own UDFClassloader. For details see {@link UDFClassLoader} 
Hive,WITHOUT_CLASSIFICATION,//  Currently this method only sets    - Database    - FunctionName    - OwnerName    - OwnerType    - ClassName 
Hive,WITHOUT_CLASSIFICATION,//  First try selecting methods based on the type affinity of the arguments passed   to the candidate method arguments. 
Hive,WITHOUT_CLASSIFICATION,//  2. Validate that join condition is legal (i.e no function refering to   both sides of join only equi join)   TODO: Join filter handling (only supported for OJ by runtime or is it   supported for IJ as well) 
Hive,WITHOUT_CLASSIFICATION,// now save stats for partition we won't modify 
Hive,WITHOUT_CLASSIFICATION,//  Check that the tables used do not resolve to temp tables. 
Hive,WITHOUT_CLASSIFICATION,//  The collect method override for TopNHash.BinaryCollector 
Hive,WITHOUT_CLASSIFICATION,//  create the merge file work 
Hive,WITHOUT_CLASSIFICATION,//  put all virtual columns in RowResolver. 
Hive,WITHOUT_CLASSIFICATION,//  PKCOLUMN_NAME 
Hive,WITHOUT_CLASSIFICATION,//  Fix needed due to dependency for hbase-mapreduce module 
Hive,WITHOUT_CLASSIFICATION,//  Return the mapping for table descriptor to the expected table OI 
Hive,WITHOUT_CLASSIFICATION,//  This is a mapping of which keys will be copied from the big table (input and key expressions) 
Hive,WITHOUT_CLASSIFICATION,//  Obtain filter for shared TS operator 
Hive,WITHOUT_CLASSIFICATION,//  Verify that driver works fine with latest schema 
Hive,WITHOUT_CLASSIFICATION,//  Shouldn't happen 
Hive,WITHOUT_CLASSIFICATION,// no exception thrown so looks good 
Hive,WITHOUT_CLASSIFICATION,//  Expected error: should throw javax.net.ssl.SSLPeerUnverifiedException 
Hive,WITHOUT_CLASSIFICATION,//  Code borrowed from VectorReduceSinkOperator.initializeOp 
Hive,WITHOUT_CLASSIFICATION,//         LOG.info("Partition "+ spec.getKey()); 
Hive,WITHOUT_CLASSIFICATION,//  Write directly into our BytesColumnVector value buffer. 
Hive,WITHOUT_CLASSIFICATION,//  Case 2- find rows which have been deleted. 
Hive,WITHOUT_CLASSIFICATION,//  Add sign byte since high bit is on. 
Hive,WITHOUT_CLASSIFICATION,//     When using only HBase2 then we could change to this 
Hive,WITHOUT_CLASSIFICATION,//  this is safe because o0 is positive 
Hive,WITHOUT_CLASSIFICATION,//  Key is stored in text format. Get bytes representation of constant also of   text format. 
Hive,WITHOUT_CLASSIFICATION,//  to avoid https://bugs.openjdk.java.net/browse/JDK-7122142 
Hive,WITHOUT_CLASSIFICATION,//  Once we are done processing the line restore the old handler 
Hive,WITHOUT_CLASSIFICATION,//  We acquired all of the locks so commit and return acquired. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure getting table in the wrong catalog does not work 
Hive,WITHOUT_CLASSIFICATION,//  We don't expect conflicts from bad estimates. 
Hive,WITHOUT_CLASSIFICATION,//  No need to acquire a lock twice on the same object   It is ensured that EXCLUSIVE locks occur before SHARED locks on the same object 
Hive,WITHOUT_CLASSIFICATION,//  Try with 0 row file. 
Hive,WITHOUT_CLASSIFICATION,//  batch size of 5 and decaying factor of 2 
Hive,WITHOUT_CLASSIFICATION,//  generate the dummy driver by using txt file 
Hive,WITHOUT_CLASSIFICATION,//  There should still be one request as the locks still held. 
Hive,WITHOUT_CLASSIFICATION,//  For all the existing partitions check if the value can be type casted to a non-null object 
Hive,WITHOUT_CLASSIFICATION,//  before we notify though lock the list so lock cannot remove it from the list. 
Hive,WITHOUT_CLASSIFICATION,//  For type casts 
Hive,WITHOUT_CLASSIFICATION,//  need not be traversed again 
Hive,WITHOUT_CLASSIFICATION,//  this will insert FS and TS between the RS and its parent 
Hive,WITHOUT_CLASSIFICATION,//  We're faking out Hive to work through a type system impedence mismatch.   Pull out the backing array and convert to a list. 
Hive,WITHOUT_CLASSIFICATION,//  Get the reflection methods from ue 
Hive,WITHOUT_CLASSIFICATION,//  if tablePropKey that was passed in lead to a valid URI resolution update it if  parts of it match the old-NN-loc else add to badRecords 
Hive,WITHOUT_CLASSIFICATION,//  One session will be running the other will be queued in "A" 
Hive,WITHOUT_CLASSIFICATION,//  check out the statistics 
Hive,WITHOUT_CLASSIFICATION,/*  Get the big table row container  */
Hive,WITHOUT_CLASSIFICATION,//  Don't acquire locks for any of these we have already asked for them in DDLSemanticAnalyzer. 
Hive,WITHOUT_CLASSIFICATION,//  Verify that an attempt was made to schedule the task but the decision was to skip scheduling 
Hive,WITHOUT_CLASSIFICATION,//  in mapreduce case we need to always clear up as mapreduce doesn't have object registry. 
Hive,WITHOUT_CLASSIFICATION,//  vertex's children vertex. 
Hive,WITHOUT_CLASSIFICATION,/*    * Set the buffer that will receive the serialized data.  The output buffer will be reset.    */
Hive,WITHOUT_CLASSIFICATION,//  retry on any other exception 
Hive,WITHOUT_CLASSIFICATION,//  Catalogs cannot be parsed as part of the query. Seems to be a bug. 
Hive,WITHOUT_CLASSIFICATION,//        DagClient as such should have no bearing on jobClose. 
Hive,WITHOUT_CLASSIFICATION,//  Get colstats for the original table column for selCol if possible this would have 
Hive,WITHOUT_CLASSIFICATION,//  clear all ThreadLocal cached MapWork/ReduceWork after plan generation   as this may executed in a pool thread. 
Hive,WITHOUT_CLASSIFICATION,//  we want to signal an error if the function doesn't exist and we're   configured not to ignore this 
Hive,WITHOUT_CLASSIFICATION,// add the columns in join filters 
Hive,WITHOUT_CLASSIFICATION,//  used for create joinOutputObjectInspector 
Hive,WITHOUT_CLASSIFICATION,//  ANALYZE TABLE T [PARTITION (...)] COMPUTE STATISTICS;   The plan consists of a simple SparkTask followed by a StatsTask.   The Spark task is just a simple TableScanOperator 
Hive,WITHOUT_CLASSIFICATION,//  Compute the pseudo-random position from the above then derive the actual header. 
Hive,WITHOUT_CLASSIFICATION,//  partitions' locations which might need to be deleted 
Hive,WITHOUT_CLASSIFICATION,//  The stack contains either ... TS Filter or   ... TS Filter Filter with the head of the stack being the rightmost   symbol. So we just pop out the two elements from the top and if the   second one of them is not a table scan then the operator on the top of 
Hive,WITHOUT_CLASSIFICATION,//  The default is such that there is no throttling. 
Hive,WITHOUT_CLASSIFICATION,//  Report suspicious gaps in writeBuffers 
Hive,WITHOUT_CLASSIFICATION,//  otherwise replace parent by sibling. 
Hive,WITHOUT_CLASSIFICATION,//  The ObjectInspector for the current column 
Hive,WITHOUT_CLASSIFICATION,// check other parts 
Hive,WITHOUT_CLASSIFICATION,//  Get total size and individual alias's size 
Hive,WITHOUT_CLASSIFICATION,//  Run partition pruner to get partitions 
Hive,WITHOUT_CLASSIFICATION,//  get all cols 
Hive,WITHOUT_CLASSIFICATION,//  FS_TRASH_CHECKPOINT_INTERVAL_KEY   FS_TRASH_INTERVAL_KEY (hadoop-2) 
Hive,WITHOUT_CLASSIFICATION,//  Can't multiply NULL. 
Hive,WITHOUT_CLASSIFICATION,//  Make the list of transactional tables list which are getting written by current txn 
Hive,WITHOUT_CLASSIFICATION,//  to check the lastRecordOutput 
Hive,WITHOUT_CLASSIFICATION,//  Open default connections which will be used throughout the tests 
Hive,WITHOUT_CLASSIFICATION,// tbl.getPath() is null for views 
Hive,WITHOUT_CLASSIFICATION,//  no table specified check all tables and all partitions. 
Hive,WITHOUT_CLASSIFICATION,// 2nd match is not supposed to be there 
Hive,WITHOUT_CLASSIFICATION,//  this is a constant (or null) 
Hive,WITHOUT_CLASSIFICATION,//  (the old instance has not been unregistered) and the new instances has not registered yet. 
Hive,WITHOUT_CLASSIFICATION,//  If the table is in the pending prewarm list move it to the top 
Hive,WITHOUT_CLASSIFICATION,//  cross-product - no keys really 
Hive,WITHOUT_CLASSIFICATION,//  update the FileSinkOperator to include partition columns 
Hive,WITHOUT_CLASSIFICATION,//  values will override any values set in the underlying Hadoop configuration. 
Hive,WITHOUT_CLASSIFICATION,//  It is possible for some request to be queued after a main thread has decided to kill this   session; on the next iteration we'd be processing that request with an irrelevant session. 
Hive,WITHOUT_CLASSIFICATION,// there is no point trying to validate further if we have no type info about target field 
Hive,WITHOUT_CLASSIFICATION,/*          * setup OI for input to resultExpr select list          */
Hive,WITHOUT_CLASSIFICATION,//  Is not an EXTERNAL table 
Hive,WITHOUT_CLASSIFICATION,/*    * ============================== HOW TO RUN THIS TEST: ====================================   *   * You can run this test:   *   * a) Via the command line:   *    $ mvn clean install   *    $ java -jar target/benchmarks.jar VectorSelectOperatorBench -prof perf     -f 1 (Linux)   *    $ java -jar target/benchmarks.jar VectorSelectOperatorBench -prof perfnorm -f 3 (Linux)   *    $ java -jar target/benchmarks.jar VectorSelectOperatorBench -prof perfasm  -f 1 (Linux)   *    $ java -jar target/benchmarks.jar VectorSelectOperatorBench -prof gc  -f 1 (allocation counting via gc)    */
Hive,WITHOUT_CLASSIFICATION,//  null. 
Hive,WITHOUT_CLASSIFICATION,//  INFO_MESSAGES 
Hive,WITHOUT_CLASSIFICATION,/*            * With a repeating value we can finish all remaining rows.            */
Hive,WITHOUT_CLASSIFICATION,//  Views derive the column type from the base table definition.  So the view definition   can be altered to change the column types.  The column type compatibility checks should 
Hive,WITHOUT_CLASSIFICATION,//  When people forget to quote a string op1/op2 is null.   For example select * from some_table where not ds > 2012-12-1 . 
Hive,WITHOUT_CLASSIFICATION,// close() should just do nothing 
Hive,WITHOUT_CLASSIFICATION,//  get the 'available privileges' from file system 
Hive,WITHOUT_CLASSIFICATION,//  executor is single thread so we can guarantee   domain created before any ATS entries 
Hive,WITHOUT_CLASSIFICATION,/*    * - Called on functions that transform the raw input.   * - this method is invoked during translation and also when the Operator is initialized during runtime.   * - a subclass must use this call to setup the shape of the raw input that is fed to the partitioning mechanics.   * - subsequent to this call a call to getRawInputOI call on the {@link TableFunctionEvaluator} must return the OI   *   of the output of this function.    */
Hive,WITHOUT_CLASSIFICATION,//  See if this node is a TOK_TABLE_OR_COL.  If so find the value and put it in the list.  If   not recurse on any children 
Hive,WITHOUT_CLASSIFICATION,// Down the semaphore or block until available 
Hive,WITHOUT_CLASSIFICATION,//  Update the count of the number of values seen so far 
Hive,WITHOUT_CLASSIFICATION,//  read type of encoding 
Hive,WITHOUT_CLASSIFICATION,//  These two structures track the list of known nodes and the list of nodes which are sending in keep-alive heartbeats. 
Hive,WITHOUT_CLASSIFICATION,//  If cred provider doesn't have entry fall back to conf 
Hive,WITHOUT_CLASSIFICATION,//  Add type params 
Hive,WITHOUT_CLASSIFICATION,//  overwrite a value 
Hive,WITHOUT_CLASSIFICATION,//  aggregateData already has the ndv of the max of all 
Hive,WITHOUT_CLASSIFICATION,//  Thread-safe. 
Hive,WITHOUT_CLASSIFICATION,//  Seed with the buddy of this block (so the first iteration would target this block). 
Hive,WITHOUT_CLASSIFICATION,//  Null check because in some test cases we get a null from ms.getCatalog. 
Hive,WITHOUT_CLASSIFICATION,//  matching rule and passes the context along 
Hive,WITHOUT_CLASSIFICATION,//  Fraction digits continue into middle longword. 
Hive,WITHOUT_CLASSIFICATION,//  to slow down the reducer so that SHUFFLE_BYTES publishing and validation can happen adding sleep between   multiple reduce stages 
Hive,WITHOUT_CLASSIFICATION,//  Thomas Wang's integer hash function 
Hive,WITHOUT_CLASSIFICATION,//  create resolver 
Hive,WITHOUT_CLASSIFICATION,//  2. Build Aggregations 
Hive,WITHOUT_CLASSIFICATION,//  It's possible that a parition column may have NULL value in which case the row belongs   to the special partition __HIVE_DEFAULT_PARTITION__. 
Hive,WITHOUT_CLASSIFICATION,//  Order on sourceColumn. 
Hive,WITHOUT_CLASSIFICATION,//  the threshold size convert the join into map-join and don't create a conditional task 
Hive,WITHOUT_CLASSIFICATION,//  Add views to planner 
Hive,WITHOUT_CLASSIFICATION,//  The id of the actual Spark job 
Hive,WITHOUT_CLASSIFICATION,//  ClassNotFoundException InstantiationException IllegalAccessException   Class could not be init-ed use our local copy 
Hive,WITHOUT_CLASSIFICATION,//  Test string literal to string column comparison 
Hive,WITHOUT_CLASSIFICATION,//  query info is created by SQLOperation which will have start time of the operation. When JDBC Statement is not   used queryInfo will be null in which case we take creation of Driver instance as query start time (which is also   the time when query display object is created) 
Hive,WITHOUT_CLASSIFICATION,//  Reset the interrupt status. 
Hive,WITHOUT_CLASSIFICATION,//  inputSplitNum that contains the first row in this block. 
Hive,WITHOUT_CLASSIFICATION,//  Run with cascade 
Hive,WITHOUT_CLASSIFICATION,//  Restricted to text for now as this is a new feature; only text files can be sliced. 
Hive,WITHOUT_CLASSIFICATION,//  We provide a faster way to write a date without a Date object. 
Hive,WITHOUT_CLASSIFICATION,//  Whether any error occurred during query compilation. Used for query lifetime hook. 
Hive,WITHOUT_CLASSIFICATION,//  No preemption with ducks reversed. 
Hive,WITHOUT_CLASSIFICATION,//  This would be an attempt directory. Add a watch and track it. 
Hive,WITHOUT_CLASSIFICATION,//  Add in our conf file 
Hive,WITHOUT_CLASSIFICATION,//  optimize for common case - just one row for a key container acts as row 
Hive,WITHOUT_CLASSIFICATION,//  When minor compacting write delete events to a separate file when split-update is   turned on. 
Hive,WITHOUT_CLASSIFICATION,//  convert RexNode to ExprNodeGenericFuncDesc 
Hive,WITHOUT_CLASSIFICATION,//  These aren't real column refs; instead they are special   internal expressions used in the representation of aggregation. 
Hive,WITHOUT_CLASSIFICATION,//  Should not happen. 
Hive,WITHOUT_CLASSIFICATION,//  help 
Hive,WITHOUT_CLASSIFICATION,//  This has already been inspected and rejected 
Hive,WITHOUT_CLASSIFICATION,// binary type should not be seen. 
Hive,WITHOUT_CLASSIFICATION,//  If it is not created by HiveSortJoinReduceRule we cannot remove it 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:TerminateFragmentResponseProto) 
Hive,WITHOUT_CLASSIFICATION,//  Cant overwrite existing keys 
Hive,WITHOUT_CLASSIFICATION,//  deleted. The user will need to call unarchive again to clear those up. 
Hive,WITHOUT_CLASSIFICATION,//  this is expected as these mock files are not valid orc file 
Hive,WITHOUT_CLASSIFICATION,//  Restore interrupt won't handle here. 
Hive,WITHOUT_CLASSIFICATION,//  In a map-side join exactly one table is not present in memory.   The client provides the list of tables which can be cached in memory 
Hive,WITHOUT_CLASSIFICATION,//  collect all branching operators 
Hive,WITHOUT_CLASSIFICATION,// create a fake directory to throw exception 
Hive,WITHOUT_CLASSIFICATION,//  Known? 
Hive,WITHOUT_CLASSIFICATION,//  map _col0 to KEY._col0 etc 
Hive,WITHOUT_CLASSIFICATION,//  Whether the cycle is running 
Hive,WITHOUT_CLASSIFICATION,//  event operators point to table scan operators. When cloning these we   need to restore the original scan. 
Hive,WITHOUT_CLASSIFICATION,//  we found at least one children with mismatch 
Hive,WITHOUT_CLASSIFICATION,//  If unable to find stats for a column return null so we can build stats 
Hive,WITHOUT_CLASSIFICATION,//  DECIMAL_STATS 
Hive,WITHOUT_CLASSIFICATION,//  Data structures coming originally from QBJoinTree 
Hive,WITHOUT_CLASSIFICATION,//  Cancel the heartbeat 
Hive,WITHOUT_CLASSIFICATION,/* append */
Hive,WITHOUT_CLASSIFICATION,//  10^-32 + 1 
Hive,WITHOUT_CLASSIFICATION,//  The state has changed during the update. Let's undo what we just did. 
Hive,WITHOUT_CLASSIFICATION,//  This should never happen - we only schedule one attempt once. 
Hive,WITHOUT_CLASSIFICATION,//  we need to get state transition updates for the vertices that will send   events to us. once we have received all events and a vertex has succeeded   we can move to do the pruning. 
Hive,WITHOUT_CLASSIFICATION,//  10^-38 + 1 
Hive,WITHOUT_CLASSIFICATION,//  Allow implicit Numeric to String conversion 
Hive,WITHOUT_CLASSIFICATION,//  the registrator jar should already be in CP when not in test mode 
Hive,WITHOUT_CLASSIFICATION,//  WRITEID 
Hive,WITHOUT_CLASSIFICATION,//  Create one input split for each segment 
Hive,WITHOUT_CLASSIFICATION,//  no special char 
Hive,WITHOUT_CLASSIFICATION,// (23*60*60 + 59*60 + 59)*10e9 + 999999999 
Hive,WITHOUT_CLASSIFICATION,//  Second data dir contains 2 files. 
Hive,WITHOUT_CLASSIFICATION,//  We've killed something and may want to wait for it to die. 
Hive,WITHOUT_CLASSIFICATION,//  Size surpasses limit we cannot convert 
Hive,WITHOUT_CLASSIFICATION,//  By default 
Hive,WITHOUT_CLASSIFICATION,//  Copy the first methodParameterTypes.length - 1 entries 
Hive,WITHOUT_CLASSIFICATION,//  test month diff with fraction considering time components 
Hive,WITHOUT_CLASSIFICATION,//  we replace existing view. 
Hive,WITHOUT_CLASSIFICATION,//  On Tez only: The hash map might already be cached in the container we run 
Hive,WITHOUT_CLASSIFICATION,//  UNDONE: Presumption of *append* 
Hive,WITHOUT_CLASSIFICATION,/*    * Element for Key: Long x Hash Table: HashMultiSet    */
Hive,WITHOUT_CLASSIFICATION,//  Data 
Hive,WITHOUT_CLASSIFICATION,//  The destination table 
Hive,WITHOUT_CLASSIFICATION,//  get close enough 
Hive,WITHOUT_CLASSIFICATION,//  We look at all methods that generate values for explain 
Hive,WITHOUT_CLASSIFICATION,//  check for fatal error again in case it occurred after   the last check before the job is completed 
Hive,WITHOUT_CLASSIFICATION,//  set correct scheme and authority 
Hive,WITHOUT_CLASSIFICATION,//  Reverse in place 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   required   required   required   required   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  Generate group-by operator 
Hive,WITHOUT_CLASSIFICATION,//  Abstract function to add HttpAuth Header 
Hive,WITHOUT_CLASSIFICATION,//  TOKEN_OWNER 
Hive,WITHOUT_CLASSIFICATION,//  MY_BOOL 
Hive,WITHOUT_CLASSIFICATION,//  mapreduce.tez.input.initializer.serialize.event.payload should be set to false when using 
Hive,WITHOUT_CLASSIFICATION,//  Build the path from bottom up 
Hive,WITHOUT_CLASSIFICATION,// start explicit txn so that txnMgr knows it 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#createStruct(java.lang.String java.lang.Object[])    */
Hive,WITHOUT_CLASSIFICATION,//  Create joinTree structures to fill them up later 
Hive,WITHOUT_CLASSIFICATION,//  Called once on the client. 
Hive,WITHOUT_CLASSIFICATION,//  4. Decompress the data. 
Hive,WITHOUT_CLASSIFICATION,//  see if expr is already present in reduceKeys.   get index of expr in reduceKeys 
Hive,WITHOUT_CLASSIFICATION,//  If we are here then we have established that firstRecordInBatch <= deleteRecord.   Now continue marking records which have been deleted until we reach the end of the batch   or we exhaust all the delete records. 
Hive,WITHOUT_CLASSIFICATION,//  more queries can be added here in the future to test acid joins 
Hive,WITHOUT_CLASSIFICATION,//  Table names with schema name if necessary 
Hive,WITHOUT_CLASSIFICATION,//  When Dynamic partitioning is used the RecordWriter instance initialized here isn't used. Can use null.   (That's because records can't be written until the values of the dynamic partitions are deduced.   By that time a new local instance of RecordWriter with the correct output-path will be constructed.) 
Hive,WITHOUT_CLASSIFICATION,//  Generate dummy pre-upgrade script with errors 
Hive,WITHOUT_CLASSIFICATION,//  user sets default queue now 
Hive,WITHOUT_CLASSIFICATION,//  if same sign just add up the absolute values 
Hive,WITHOUT_CLASSIFICATION,//  Recreate to refresh jobConf of currTask context. 
Hive,WITHOUT_CLASSIFICATION,//  class PartitionDropSwitches; 
Hive,WITHOUT_CLASSIFICATION,//  which is the Correlator. 
Hive,WITHOUT_CLASSIFICATION,//  Materialization is allowed if it is not a view definition 
Hive,WITHOUT_CLASSIFICATION,//  STATUS_CODE 
Hive,WITHOUT_CLASSIFICATION,//  Find the first non-zero digit or the last digits if all are zero. 
Hive,WITHOUT_CLASSIFICATION,//  we get a text input format here we can not determine a file is text   according to its content so we can do is to test if other file   format can accept it. If one other file format can accept this file   we treat this file as text file although it maybe not. 
Hive,WITHOUT_CLASSIFICATION,//  Invalid if table is not partitioned but endPoint's partitionVals is not empty 
Hive,WITHOUT_CLASSIFICATION,//  Bloom filter rest 
Hive,WITHOUT_CLASSIFICATION,//  Need a separate table for ACID testing since it has to be bucketed and it has to be Acid 
Hive,WITHOUT_CLASSIFICATION,//  Move to next valid index. 
Hive,WITHOUT_CLASSIFICATION,//  EXPORT TABLE tablename [PARTITION (part_column="value"[ ...])]   TO 'export_target_path' 
Hive,WITHOUT_CLASSIFICATION,//  First look up the column from the source against which * is to be   resolved.   We'd later translated this into the column from proper input if   it's valid.   TODO: excludeCols may be possible to remove using the same 
Hive,WITHOUT_CLASSIFICATION,//  For Druid storage handler 
Hive,WITHOUT_CLASSIFICATION,//  count characters forward and watch for final run of pads 
Hive,WITHOUT_CLASSIFICATION,//  call-3: open - mock:/mocktbl2/0_1 
Hive,WITHOUT_CLASSIFICATION,//  HAS_UNKNOWN_PARTITIONS 
Hive,WITHOUT_CLASSIFICATION,//  Original method used deepCopy() do the same here. 
Hive,WITHOUT_CLASSIFICATION,//  constant or null just return it 
Hive,WITHOUT_CLASSIFICATION,//  buildV9Directly - use druid default no need to be configured by user 
Hive,WITHOUT_CLASSIFICATION,// --------------------------- PTF handling: PTFInvocationSpec to PTFDesc -------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  test for string type 
Hive,WITHOUT_CLASSIFICATION,//  As hive conf is changed need to get the Hive DB again with it. 
Hive,WITHOUT_CLASSIFICATION,//  HIVE-3508 has been filed for this 
Hive,WITHOUT_CLASSIFICATION,//  default partition key 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   required   required   required   required   required 
Hive,WITHOUT_CLASSIFICATION,/*  If all input columns are repeating just evaluate function     * for row 0 in the batch and set output repeating.      */
Hive,WITHOUT_CLASSIFICATION,//  Unsupported aggregation. 
Hive,WITHOUT_CLASSIFICATION,//  UDF 
Hive,WITHOUT_CLASSIFICATION,//  each side better have 0 or more RS. if either side is unbalanced cannot convert.   This is a workaround for now. Right fix would be to refactor code in the   MapRecordProcessor and ReduceRecordProcessor with respect to the sources. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure matching name but wrong type doesn't return 
Hive,WITHOUT_CLASSIFICATION,//  The delete_delta_110_110 should not be read because it is greater than the high watermark. 
Hive,WITHOUT_CLASSIFICATION,//  task3 not allocated 
Hive,WITHOUT_CLASSIFICATION,//  add hive-exec jar 
Hive,WITHOUT_CLASSIFICATION,//  smallBuffer might still be out of space 
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.FragmentRuntimeInfo.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,//  SHOW LOCKS db2 
Hive,WITHOUT_CLASSIFICATION,//  ReducerTraits.UNIFORM 
Hive,WITHOUT_CLASSIFICATION,//  Deserialize and check... 
Hive,WITHOUT_CLASSIFICATION,//  Track the dependencies for the view. Consider a query like: select * from V;   where V is a view of the form: select * from T 
Hive,WITHOUT_CLASSIFICATION,//  Hostname:port 
Hive,WITHOUT_CLASSIFICATION,/*    * This class is used to read one field at a time.  Simple fields like long double int are read   * into to primitive current* members; the non-simple field types like Date Timestamp etc are   * read into a current object that this method will allocate.   *   * This method handles complex type fields by recursively calling this method.    */
Hive,WITHOUT_CLASSIFICATION,//  Generate the map of the input->output column name for the keys   we are about 
Hive,WITHOUT_CLASSIFICATION,//  how many records already buffered 
Hive,WITHOUT_CLASSIFICATION,//  output privileges and asks for select-no-grant on input. 
Hive,WITHOUT_CLASSIFICATION,//  What we were reading from disk originally. 
Hive,WITHOUT_CLASSIFICATION,/*    * Specify the columns to deserialize into as an array.    */
Hive,WITHOUT_CLASSIFICATION,//  Try to allocate using base-buffer approach from each arena. 
Hive,WITHOUT_CLASSIFICATION,// When file system cache is disabled you get different FileSystem objects   for same file system so '==' can't be used in such cases  FileSystem api doesn't have a .equals() function implemented so using  the uri for comparison. FileSystem already uses uri+Configuration for  equality in its CACHE .  Once equality has been added in HDFS-9159 we should make use of it 
Hive,WITHOUT_CLASSIFICATION,//  Verify that we can drain the pool then cycle it i.e. the state is not corrupted. 
Hive,WITHOUT_CLASSIFICATION,//  Bring up the server only after all other components have started. 
Hive,WITHOUT_CLASSIFICATION,//  Check if this is a MapJoin. If so do not split. 
Hive,WITHOUT_CLASSIFICATION,//  Add the new operator as child of each of the passed in operators 
Hive,WITHOUT_CLASSIFICATION,//  Logical loop over the rows in the batch since the batch may have selected in use. 
Hive,WITHOUT_CLASSIFICATION,/*          * For tez to route data from an up-stream vertex correctly to the following vertex the         * output name in the reduce sink needs to be setup appropriately. In the case of reduce         * side merge work we need to ensure that the parent work that provides data to this merge         * work is setup to point to the right vertex name - the main work name.         *         * In this case if the big table work has already been created we can hook up the merge         * work items for the small table correctly.          */
Hive,WITHOUT_CLASSIFICATION,//  Http transport mode.   We set the thread local ip address in ThriftHttpServlet. 
Hive,WITHOUT_CLASSIFICATION,//  The sixth will not be combined because of delete delta files.  Is that desired? HIVE-18110 
Hive,WITHOUT_CLASSIFICATION,//  Potentially wait on the cache entry if entry is in PENDING status   Blocking here can potentially be dangerous - for example if the global compile lock   is used this will block all subsequent queries that try to acquire the compile lock   so it should not be done unless parallel compilation is enabled.   We might not want to block for explain queries as well. 
Hive,WITHOUT_CLASSIFICATION,//  There's a fixed number of partition cols that we might have filters on. To avoid   joining multiple times for one column (if there are several filters on it) we will   keep numCols elements in the list one for each column; we will fill it with nulls   put each join at a corresponding index when necessary and remove nulls in the end. 
Hive,WITHOUT_CLASSIFICATION,//  No need to handle MM tables - unsupported path. 
Hive,WITHOUT_CLASSIFICATION,//  If any of the partition requests are null then I need to pull all   partition locks for this table. 
Hive,WITHOUT_CLASSIFICATION,//  PURGE 
Hive,WITHOUT_CLASSIFICATION,//  UNDONE: For now... 
Hive,WITHOUT_CLASSIFICATION,//  disable trash   FS_TRASH_CHECKPOINT_INTERVAL_KEY (hadoop-2)   FS_TRASH_INTERVAL_KEY (hadoop-2) 
Hive,WITHOUT_CLASSIFICATION,/*    * Table scan has the table object and pruned partitions that has information   * such as bucketing sorting etc. that is used later for optimization.    */
Hive,WITHOUT_CLASSIFICATION,// don't overwrite user choice if transactional attribute is explicitly set 
Hive,WITHOUT_CLASSIFICATION,//  output entry should not be null for null input for this particular generic UDF 
Hive,WITHOUT_CLASSIFICATION,//  Then we determine the local TZ offset at that magical time. 
Hive,WITHOUT_CLASSIFICATION,//  write the results in the file 
Hive,WITHOUT_CLASSIFICATION,/*            This API changed from 2.x to 3.0.  so this won't even compile with 3.0           but it doesn't need to since we only run this preUpgrade           */
Hive,WITHOUT_CLASSIFICATION,//  one single call to get all column stats 
Hive,WITHOUT_CLASSIFICATION,//  Project only the correlated fields out of each inputRel   and join the projectRel together.   To make sure the plan does not change in terms of join order   join these rels based on their occurrence in cor var list which 
Hive,WITHOUT_CLASSIFICATION,//  Null first/last 
Hive,WITHOUT_CLASSIFICATION,//  Normally I'd worry about the blanket false being passed in here and that   it'd need to be integrated into an abort call for an OutputCommitter but the   underlying recordwriter ignores it and throws it away so it's irrelevant. 
Hive,WITHOUT_CLASSIFICATION,//  Important: Restore the batch's selected array. 
Hive,WITHOUT_CLASSIFICATION,//  Pig's schema contain no type information about map's keys and   values. So if its a new column assume <stringstring> if its existing   return whatever is contained in the existing column. 
Hive,WITHOUT_CLASSIFICATION,//  Remove col stats 
Hive,WITHOUT_CLASSIFICATION,//  LOG.debug(CLASS_NAME + " logical " + logical + " batchIndex " + batchIndex + " New Key " + currentKey + " " + saveJoinResult.name()); 
Hive,WITHOUT_CLASSIFICATION,//  Send done event which LlapRecordReader is expecting upon end of input 
Hive,WITHOUT_CLASSIFICATION,//  Check if owner has write permission else it will have to copy 
Hive,WITHOUT_CLASSIFICATION,// create more staging data and test Load Data Overwrite 
Hive,WITHOUT_CLASSIFICATION,//  be very expensive sometimes 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.CLIServiceClient#cancelOperation(org.apache.hive.service.cli.OperationHandle)    */
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setBlob(int java.io.InputStream)    */
Hive,WITHOUT_CLASSIFICATION,//  check if it is no scan. grammar prevents coexit noscan/columns 
Hive,WITHOUT_CLASSIFICATION,//  Shift the remaining bins left one position 
Hive,WITHOUT_CLASSIFICATION,//  Stop the CachedStore cache update service. We'll start it explicitly to control the test 
Hive,WITHOUT_CLASSIFICATION,//  see discussion in YARN-5551 for the memory accounting discussion 
Hive,WITHOUT_CLASSIFICATION,//  does any result need to be emitted 
Hive,WITHOUT_CLASSIFICATION,//  enabling this will cause test failures in Mac OS X 
Hive,WITHOUT_CLASSIFICATION,//  file is required parameter 
Hive,WITHOUT_CLASSIFICATION,//  Check for PARTITION BY key change when we have ORDER BY keys. 
Hive,WITHOUT_CLASSIFICATION,//  write value to object that can be inspected 
Hive,WITHOUT_CLASSIFICATION,//  We need to drop the table. 
Hive,WITHOUT_CLASSIFICATION,//  staging area for results to avoid new() calls 
Hive,WITHOUT_CLASSIFICATION,// should this close updaters[]? 
Hive,WITHOUT_CLASSIFICATION,//  6/ test serialization and deserialization with different schemas 
Hive,WITHOUT_CLASSIFICATION,//  A candidate. 
Hive,WITHOUT_CLASSIFICATION,//  1.1. If it is not a RexCall we continue 
Hive,WITHOUT_CLASSIFICATION,//  Size of stdout buffer in bytes 
Hive,WITHOUT_CLASSIFICATION,/*     todo: parse    target/tmp/org.apache.hadoop.hive.upgrade.acid.TestUpgradeTool-1527286256834/compacts_1527286277624.sql    make sure it's the only 'compacts' file and contains    ALTER TABLE default.tacid COMPACT 'major';ALTER TABLE default.tacidpart PARTITION(p=10Y) COMPACT 'major';    *  */
Hive,WITHOUT_CLASSIFICATION,//  Username must be present 
Hive,WITHOUT_CLASSIFICATION,// should not happen as we have accounted for all types 
Hive,WITHOUT_CLASSIFICATION,//  Long 
Hive,WITHOUT_CLASSIFICATION,//  Given a key find the corresponding column name. 
Hive,WITHOUT_CLASSIFICATION,//  If we are rounding we may introduce one more integer digit. 
Hive,WITHOUT_CLASSIFICATION,//  No static partitions specified and hence all are dynamic partition keys and need to be part   of temp table (input data file). 
Hive,WITHOUT_CLASSIFICATION,//  The op may not be a TableScan for mapjoins   Consider the query: select /*+MAPJOIN(a)*/ count(*) FROM T1 a JOIN T2 b ON a.key = b.key; 
Hive,WITHOUT_CLASSIFICATION,//  Add view-based rewriting rules to planner 
Hive,WITHOUT_CLASSIFICATION,/*    * Inner big table only join (hash multi-set).    */
Hive,WITHOUT_CLASSIFICATION,//  Case 4 - NOT IN list 
Hive,WITHOUT_CLASSIFICATION,//  earlier version of Hive. 
Hive,WITHOUT_CLASSIFICATION,//  remove incomplete outputs.   Some incomplete outputs may be added at the beginning for eg: for dynamic partitions. 
Hive,WITHOUT_CLASSIFICATION,//  Get the registry 
Hive,WITHOUT_CLASSIFICATION,//  Write buffer is full   Read buffer isn't used switch buffer 
Hive,WITHOUT_CLASSIFICATION,/*      * Since we componentize Windowing no need to translate     * the Partition & Order specs of individual WFns.      */
Hive,WITHOUT_CLASSIFICATION,// decimal(ab) type 
Hive,WITHOUT_CLASSIFICATION,//  getColumns(String catalog String schemaPattern String 
Hive,WITHOUT_CLASSIFICATION,//  evaluate filter expression and update statistics 
Hive,WITHOUT_CLASSIFICATION,//  LLAP IO is off don't output. 
Hive,WITHOUT_CLASSIFICATION,//  LOG.debug("VectorMapJoinFastKeyStore equalKey match on bytes"); 
Hive,WITHOUT_CLASSIFICATION,//  Note: for now LLAP is only supported in Tez tasks. Will never come to MR; others may   be added here although this is only necessary to have extra debug information. 
Hive,WITHOUT_CLASSIFICATION,/*  Check if hashmap is on disk or in memory  */
Hive,WITHOUT_CLASSIFICATION,// by default if user hasn't provided any optional constraint properties 
Hive,WITHOUT_CLASSIFICATION,// 2627 is unique constaint violation incl PK 2601 - unique key 
Hive,WITHOUT_CLASSIFICATION,//  and accepts the first one clazz.getMethods() returns 
Hive,WITHOUT_CLASSIFICATION,//  To handle the case of - select * from (select * from V1) A;   the currentInput != null check above is needed.   the alias list that case would be A:V1:T. Lookup on A would return null   we need to go further to find the view inside it. 
Hive,WITHOUT_CLASSIFICATION,//  Need to close the dummyOps as well. The operator pipeline   is not considered "closed/done" unless all operators are 
Hive,WITHOUT_CLASSIFICATION,//  Open a base txn which allocates write ID and then committed. 
Hive,WITHOUT_CLASSIFICATION,//  The 'it' data source will produce data w/o ever ending   We want to see that memory pressure kicks in and some 
Hive,WITHOUT_CLASSIFICATION,//  The queue should be ignored. 
Hive,WITHOUT_CLASSIFICATION,//  child 2 is the optional comment of the column 
Hive,WITHOUT_CLASSIFICATION,//  do this only if there is a pre event listener registered (avoid unnecessary   metastore api call) 
Hive,WITHOUT_CLASSIFICATION,//  Have to reset the conf when we change it so that the change takes affect 
Hive,WITHOUT_CLASSIFICATION,//  hive compiler is going to remove inner order by. disable that optimization until then. 
Hive,WITHOUT_CLASSIFICATION,//  We could also allow cutting off versions and other stuff provided that SHA matches... 
Hive,WITHOUT_CLASSIFICATION,//  requested host is still alive but cannot accept task pick the next available host in consistent order 
Hive,WITHOUT_CLASSIFICATION,//  The query materialization validation check only occurs in CBO. Thus only cache results if CBO was used. 
Hive,WITHOUT_CLASSIFICATION,//  Verify we handle the key column types for an optimized table.  This is the effectively the   same check used in HashTableLoader. 
Hive,WITHOUT_CLASSIFICATION,//  Remove the DDL_TIME so it gets refreshed 
Hive,WITHOUT_CLASSIFICATION,//  Testing with repeating and no nulls 
Hive,WITHOUT_CLASSIFICATION,//  set the bit to 1 if a value is not null 
Hive,WITHOUT_CLASSIFICATION,//  read keys from token store 
Hive,WITHOUT_CLASSIFICATION,//  Now register as permanent function 
Hive,WITHOUT_CLASSIFICATION,// make sure we are checking the right (latest) compaction entry 
Hive,WITHOUT_CLASSIFICATION,//  returns first one matches all of the params 
Hive,WITHOUT_CLASSIFICATION,//  Select algorithm with min cost 
Hive,WITHOUT_CLASSIFICATION,//  Check if it is possible to drop default database 
Hive,WITHOUT_CLASSIFICATION,/*  write byte size of the string which is a vint  */
Hive,WITHOUT_CLASSIFICATION,//  Get the row structure 
Hive,WITHOUT_CLASSIFICATION,//  +1 for 
Hive,WITHOUT_CLASSIFICATION,//  Separate the base files into acid schema and non-acid(original) schema files. 
Hive,WITHOUT_CLASSIFICATION,//  we already added this column in select list. 
Hive,WITHOUT_CLASSIFICATION,//  equals() 
Hive,WITHOUT_CLASSIFICATION,//  Should not happen? 
Hive,WITHOUT_CLASSIFICATION,//  bags always contain tuples 
Hive,WITHOUT_CLASSIFICATION,//  IN(STRUCT(..)..) ExprNodeDesc list for the current table alias. 
Hive,WITHOUT_CLASSIFICATION,//  Look at getting rid of fractional digits that will now be below HiveDecimal.MAX_SCALE. 
Hive,WITHOUT_CLASSIFICATION,//  each evaluator has constant java object overhead 
Hive,WITHOUT_CLASSIFICATION,//  Test and/or more... 
Hive,WITHOUT_CLASSIFICATION,//  masks for quicker extraction of p pPrime qPrime values 
Hive,WITHOUT_CLASSIFICATION,//  We don't need the buffer anymore. 
Hive,WITHOUT_CLASSIFICATION,//  looks like a subq plan.   todo we can collapse this part of tree into single TS 
Hive,WITHOUT_CLASSIFICATION,// compactions are not happening. 
Hive,WITHOUT_CLASSIFICATION,//  JDO 
Hive,WITHOUT_CLASSIFICATION,// this method also initializes the consoleReader which is 
Hive,WITHOUT_CLASSIFICATION,//  Preserved at initialization time to have a session to use during resize. 
Hive,WITHOUT_CLASSIFICATION,//  No more data. 
Hive,WITHOUT_CLASSIFICATION,//  append colnum to make it unique 
Hive,WITHOUT_CLASSIFICATION,// so that it can be cancelled later from CompleteDelegator 
Hive,WITHOUT_CLASSIFICATION,//  Not sequential with next. 
Hive,WITHOUT_CLASSIFICATION,//  The same thing that WriterImpl does when writing the footer but w/o the footer. 
Hive,WITHOUT_CLASSIFICATION,//  start the mr input and wait for ready event. number of MRInput is expected to be 1 
Hive,WITHOUT_CLASSIFICATION,// create reader look at footer  no need to check side file since it can only be in a streaming ingest delta 
Hive,WITHOUT_CLASSIFICATION,//  Initialize table properties from the table parameters. This is required because the table   may define certain table parameters that may be required while writing. The table parameter   'transactional_properties' is one such example. 
Hive,WITHOUT_CLASSIFICATION,//  Empty maybe because CBO did not run; we fall back to   full Select query 
Hive,WITHOUT_CLASSIFICATION,//  bounds of the column type are written and values outside throw an exception. 
Hive,WITHOUT_CLASSIFICATION,//    2. Constructing a conditional task consisting of a move task and a map reduce task 
Hive,WITHOUT_CLASSIFICATION,//  has dynamic as well as static partitions 
Hive,WITHOUT_CLASSIFICATION,//  Check if it's '\r' or '\n' 
Hive,WITHOUT_CLASSIFICATION,//  initialize() has not been called   initialize() has been called and close() has not been called   or close() has been called but one of its parent is not closed. 
Hive,WITHOUT_CLASSIFICATION,//  since it is noscan it is true table name in command 
Hive,WITHOUT_CLASSIFICATION,//  Retry with different dump should fail. 
Hive,WITHOUT_CLASSIFICATION,//  Get a deterministic count of number of tasks for the vertex. 
Hive,WITHOUT_CLASSIFICATION,//                join cost 
Hive,WITHOUT_CLASSIFICATION,//  test basic operation 
Hive,WITHOUT_CLASSIFICATION,/*  * Specialized class for doing a vectorized map join that is an outer join on Multi-Key * using a hash map.  */
Hive,WITHOUT_CLASSIFICATION,//  If we fell through to here this is not a valid type conversion 
Hive,WITHOUT_CLASSIFICATION,//  Assumptions:   precision >= scale   scale >= 0 
Hive,WITHOUT_CLASSIFICATION,//  If statsObjOld is found we can merge. 
Hive,WITHOUT_CLASSIFICATION,//  test add_partitions 
Hive,WITHOUT_CLASSIFICATION,//  -1 special case.  Unsigned magnitude 1 - two's compliment adjustment 1 = 0. 
Hive,WITHOUT_CLASSIFICATION,//  remove all non alphanumeric letters replace whitespace spans with underscore 
Hive,WITHOUT_CLASSIFICATION,// Pre-analyze hook is fired in the middle of these calls 
Hive,WITHOUT_CLASSIFICATION,//  Fail with a good message 
Hive,WITHOUT_CLASSIFICATION,//  Check if size of data to shuffle (larger table) is less than given max size 
Hive,WITHOUT_CLASSIFICATION,// here we need X lock on p=1 partition to write and S lock on 'table' to read which should 
Hive,WITHOUT_CLASSIFICATION,//  If the cq prefix is non-empty add it to the CQ before we set the mutation 
Hive,WITHOUT_CLASSIFICATION,//  Note: isRawFormat is invalid for non-ORC tables. It will always return true so we're good. 
Hive,WITHOUT_CLASSIFICATION,/*            * Single-Column Long outer null detection.            */
Hive,WITHOUT_CLASSIFICATION,//  Set up conf 
Hive,WITHOUT_CLASSIFICATION,/*  This is a test function that takes three different kinds * of arguments for use to verify vectorized UDF invocation.  */
Hive,WITHOUT_CLASSIFICATION,//  Default values 
Hive,WITHOUT_CLASSIFICATION,//  exact type conversion or get out 
Hive,WITHOUT_CLASSIFICATION,//  create and load the input data into the hbase table 
Hive,WITHOUT_CLASSIFICATION,//  output) minus the distinct aggCall's input. 
Hive,WITHOUT_CLASSIFICATION,//  If authorizer is not set check for metastore authorizer (eg. StorageBasedAuthorizationProvider) 
Hive,WITHOUT_CLASSIFICATION,//  keep the small table alias to avoid concurrent modification exception 
Hive,WITHOUT_CLASSIFICATION,/*    * Tests with queries which can be pushed down and executed with directSQL but the number of   * partitions which should be fetched is bigger than the maximum set by the   * hive.metastore.limit.partition.request parameter.    */
Hive,WITHOUT_CLASSIFICATION,//  need a new run of the constant folding because we might have created lots   of "and true and true" conditions.   Rather than run the full constant folding just need to shortcut AND/OR expressions 
Hive,WITHOUT_CLASSIFICATION,//  FetchTask should not depend on the plan. 
Hive,WITHOUT_CLASSIFICATION,// https://db.apache.org/derby/docs/10.1/ref/rrefsqlj31783.html  sadly in Derby FOR UPDATE doesn't meant what it should 
Hive,WITHOUT_CLASSIFICATION,/*  Keeps track of all events that need to be processed - irrespective of the source  */
Hive,WITHOUT_CLASSIFICATION,//  not zero 
Hive,WITHOUT_CLASSIFICATION,//  a0 a2 should be empty 
Hive,WITHOUT_CLASSIFICATION,//  non default session nothing changes. The user can continue to use the existing   session in the SessionState 
Hive,WITHOUT_CLASSIFICATION,//  Now the left join 
Hive,WITHOUT_CLASSIFICATION,// with feature on multiple tasks may get into conflict creating/using TMP_LOCATION and if we were  to generate the target dir in the Map task there is no easy way to pass it to OutputCommitter 
Hive,WITHOUT_CLASSIFICATION,//  c13:array<array<string>> 
Hive,WITHOUT_CLASSIFICATION,//  Create a input stream of given name.ext  and write sql statements to to it 
Hive,WITHOUT_CLASSIFICATION,//  hashCode() 
Hive,WITHOUT_CLASSIFICATION,//  ingest size bytes gets resetted on flush() whereas connection stats is not 
Hive,WITHOUT_CLASSIFICATION,//  Account for maximum cache buffer size. 
Hive,WITHOUT_CLASSIFICATION,//  Validate inputs and outputs have right protectmode to execute the query 
Hive,WITHOUT_CLASSIFICATION,//  we have to close in the processor's run method because tez closes inputs   before calling close (TEZ-955) and we might need to read inputs   when we flush the pipeline. 
Hive,WITHOUT_CLASSIFICATION,//  Only consider range operators if we haven't already seen one 
Hive,WITHOUT_CLASSIFICATION,//  all divides are by 0.50 so the result column is 2 times col 0. 
Hive,WITHOUT_CLASSIFICATION,//  Map Type 
Hive,WITHOUT_CLASSIFICATION,//  Merge the target works of the second DPP sink into the first DPP sink. 
Hive,WITHOUT_CLASSIFICATION,//  table   exists 
Hive,WITHOUT_CLASSIFICATION,//  flag to indicate if it's the first time to read parquet data page with this instance 
Hive,WITHOUT_CLASSIFICATION,//  The fractional digits are gone; clear remaining round digits. 
Hive,WITHOUT_CLASSIFICATION,//  alter partitioned table's partition set partition property 
Hive,WITHOUT_CLASSIFICATION,//  If already a file with same checksum exists in cmPath just ignore the copy/move   Also mark the operation is unsuccessful to notify that file with same name already   exist which will ensure the timestamp of cmPath is updated to avoid clean-up by   CM cleaner. 
Hive,WITHOUT_CLASSIFICATION,//  Check mapreduce path 
Hive,WITHOUT_CLASSIFICATION,//  Not included in the input collations but can be propagated as this Aggregate   will enforce it 
Hive,WITHOUT_CLASSIFICATION,//  3rd task requested host3 got host1 since host3 is dead and host4 is full 
Hive,WITHOUT_CLASSIFICATION,//  verify that the whitlelist params can be set 
Hive,WITHOUT_CLASSIFICATION,//  Find the positions of the bucketed columns in the table corresponding   to the select list.   Consider the following scenario:   T1(key value1 value2) bucketed/sorted by key into 2 buckets   T2(dummy key value1 value2) bucketed/sorted by key into 2 buckets   A query like: insert overwrite table T2 select 1 key value1 value2 from T1   should be optimized. 
Hive,WITHOUT_CLASSIFICATION,//  -database database 
Hive,WITHOUT_CLASSIFICATION,// TODO Duplicated code for init method since vectorization reader path doesn't support Nested   column pruning so far. See HIVE-15156 
Hive,WITHOUT_CLASSIFICATION,//  VectorPTFOperator is native vectorized. 
Hive,WITHOUT_CLASSIFICATION,//  Get all files from the src directory 
Hive,WITHOUT_CLASSIFICATION,//  NEW_CAT 
Hive,WITHOUT_CLASSIFICATION,//  set the log stream 
Hive,WITHOUT_CLASSIFICATION,//  This will happen for count(*) in such cases we arbitarily pick   first element from srcRel 
Hive,WITHOUT_CLASSIFICATION,/* ekoifman:apache-hive-3.0.0-SNAPSHOT-bin ekoifman$ tree  ~/dev/hiverwgit/itests/hive-unit/target/tmp/org.apache.hadoop.hive.ql.TestAcidOnTez-1505502329802/warehouse/t/.hive-staging_hive_2017-09-15_12-07-33_224_7717909516029836949-1//Users/ekoifman/dev/hiverwgit/itests/hive-unit/target/tmp/org.apache.hadoop.hive.ql.TestAcidOnTez-1505502329802/warehouse/t/.hive-staging_hive_2017-09-15_12-07-33_224_7717909516029836949-1/└── -ext-10000    ├── HIVE_UNION_SUBDIR_1    │   └── 000000_0    ├── HIVE_UNION_SUBDIR_2    │   └── 000000_0    └── HIVE_UNION_SUBDIR_3        └── 000000_04 directories 3 files      */
Hive,WITHOUT_CLASSIFICATION,//  Case 2: NO column stats NO hash aggregation grouping sets 
Hive,WITHOUT_CLASSIFICATION,//  count characters 
Hive,WITHOUT_CLASSIFICATION,//  for outer joins it should not exceed 16 aliases (short type) 
Hive,WITHOUT_CLASSIFICATION,//  Using volatile instead of locking updates to this variable 
Hive,WITHOUT_CLASSIFICATION,//  -f <query-file> 
Hive,WITHOUT_CLASSIFICATION,//  Remove the reduce sink operator 
Hive,WITHOUT_CLASSIFICATION,//  VALUE_TYPE_PTR 
Hive,WITHOUT_CLASSIFICATION,//  v[1] where (product % MULTIPLER_INTWORD_DECIMAL) is the carry from v[0].  
Hive,WITHOUT_CLASSIFICATION,// get a partition 
Hive,WITHOUT_CLASSIFICATION,//  Test that exclusive blocks read and exclusive 
Hive,WITHOUT_CLASSIFICATION,//  set vector[2] to null to verify correct null handling 
Hive,WITHOUT_CLASSIFICATION,//  Delayed tasks will not kick in right now. That will happen in the scheduling loop. 
Hive,WITHOUT_CLASSIFICATION,//  total size of the composite object 
Hive,WITHOUT_CLASSIFICATION,//  UNDONE: Method is still under development. 
Hive,WITHOUT_CLASSIFICATION,//    Rewrite logic:     1. Pass along any correlated variables coming from the input.   
Hive,WITHOUT_CLASSIFICATION,//  By definition this session is not in use and can no longer be in use so it only   affects the session pool. We can handle this inline. 
Hive,WITHOUT_CLASSIFICATION,//  required for jackson 
Hive,WITHOUT_CLASSIFICATION,// Create test dbs and tables 
Hive,WITHOUT_CLASSIFICATION,//  transactionalListener.onAddNotNullConstraint(addDefaultConstraintEvent);  } 
Hive,WITHOUT_CLASSIFICATION,//  If statsObjOld is not found we just use statsObjNew as it is accurate. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure location string is in proper format 
Hive,WITHOUT_CLASSIFICATION,//  This should be really close to zero. 
Hive,WITHOUT_CLASSIFICATION,//  Normal case. 
Hive,WITHOUT_CLASSIFICATION,// do not need the lock for partitions since they are covered by the table lock 
Hive,WITHOUT_CLASSIFICATION,//  Do some logging and force log rollover 
Hive,WITHOUT_CLASSIFICATION,//  The logical indices for reading with readField. 
Hive,WITHOUT_CLASSIFICATION,//  We must have the duck still; it should just go to the other task. 
Hive,WITHOUT_CLASSIFICATION,//  Note: we may add an async option in future. For now let the task fail for the user. 
Hive,WITHOUT_CLASSIFICATION,//  ABORTED_BITS 
Hive,WITHOUT_CLASSIFICATION,//  all children are done or no need to walk the children 
Hive,WITHOUT_CLASSIFICATION,//  The row consists of string columns double columns some union<int double> columns only. 
Hive,WITHOUT_CLASSIFICATION,// Repeating null 
Hive,WITHOUT_CLASSIFICATION,//  the event else noop. 
Hive,WITHOUT_CLASSIFICATION,//  give a sequence number for all the partitions 
Hive,WITHOUT_CLASSIFICATION,//  arbitrary 
Hive,WITHOUT_CLASSIFICATION,//  object overhead + 8 bytes for long (fastTime) + 16 bytes for cdate 
Hive,WITHOUT_CLASSIFICATION,//  Create the filter Operator and update the parents and children appropriately 
Hive,WITHOUT_CLASSIFICATION,//  Test ALTER DATABASE SET LOCATION. 
Hive,WITHOUT_CLASSIFICATION,// because row 8 was updated and thus has a different RecordIdentifier now 
Hive,WITHOUT_CLASSIFICATION,//  time   != 0 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#setClientInfo(java.lang.String java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  recreate 
Hive,WITHOUT_CLASSIFICATION,//  show all privileges 
Hive,WITHOUT_CLASSIFICATION,// @formatter:off 
Hive,WITHOUT_CLASSIFICATION,//  Caching is disabled for MapInput due to HIVE-8920 
Hive,WITHOUT_CLASSIFICATION,//  derivedSchema ArrayList.) 
Hive,WITHOUT_CLASSIFICATION,//  Password may no longer be in the conf use getPassword() 
Hive,WITHOUT_CLASSIFICATION,//  use the serialization option switch to write primitive values as either a variable 
Hive,WITHOUT_CLASSIFICATION,//  Make sure the node got deleted. 
Hive,WITHOUT_CLASSIFICATION,//  see javadoc of HBaseCompositeKey 
Hive,WITHOUT_CLASSIFICATION,//  remainder 
Hive,WITHOUT_CLASSIFICATION,//  Non-static methods to wrap the static AccumuloOutputFormat methods to enable testing 
Hive,WITHOUT_CLASSIFICATION,//  No match was found so create new entries 
Hive,WITHOUT_CLASSIFICATION,//  Insert a globally unique 16-byte value every few entries so that one   can seek into the middle of a file and then synchronize with record   starts and ends by scanning for this value. 
Hive,WITHOUT_CLASSIFICATION,//  History file name 
Hive,WITHOUT_CLASSIFICATION,//  This shows the relevant bits of the original hash value   and how the conversion is moving bits from the index value   over to the leading zero computation 
Hive,WITHOUT_CLASSIFICATION,//  A new connection should be able to call describe/use function without issue 
Hive,WITHOUT_CLASSIFICATION,//  A partition must have at least sdId and serdeId set or nothing set if it's a view. 
Hive,WITHOUT_CLASSIFICATION,//  Whether a series key is NULL. 
Hive,WITHOUT_CLASSIFICATION,//  update number of columns from sel(*) 
Hive,WITHOUT_CLASSIFICATION,//  Get the union value. 
Hive,WITHOUT_CLASSIFICATION,//  returns the location on disc of the jar of this class. 
Hive,WITHOUT_CLASSIFICATION,//  No more. 
Hive,WITHOUT_CLASSIFICATION,//  skip trailing blank characters 
Hive,WITHOUT_CLASSIFICATION,//  Get binary service port # 
Hive,WITHOUT_CLASSIFICATION,//  No truncation needed 
Hive,WITHOUT_CLASSIFICATION,/* since ROW_IDs are not needed we didn't create the ColumnVectors to hold them but we        * still have to check if the data being read is committed as far as current        * reader (transactions) is concerned.  Since here we are reading 'original' schema file        * all rows in it have been created by the same txn namely 'syntheticProps.syntheticWriteId'         */
Hive,WITHOUT_CLASSIFICATION,//  Not found in the cache. Must be parameterized types. Create it. 
Hive,WITHOUT_CLASSIFICATION,//  > 50 
Hive,WITHOUT_CLASSIFICATION,// Open matches Metastore state 
Hive,WITHOUT_CLASSIFICATION,//  The original record was lost in the deserialization so just go the   correct way through objectinspectors 
Hive,WITHOUT_CLASSIFICATION,//  isEmptyPartition = false 
Hive,WITHOUT_CLASSIFICATION,//  store table descriptor in map-work 
Hive,WITHOUT_CLASSIFICATION,//  prepare empty routing table 
Hive,WITHOUT_CLASSIFICATION,//  Add partitions for the partitioned table 
Hive,WITHOUT_CLASSIFICATION,/*  PbB0  */
Hive,WITHOUT_CLASSIFICATION,//  check if we are already at current schema level 
Hive,WITHOUT_CLASSIFICATION,//  The database name is not changed during alter 
Hive,WITHOUT_CLASSIFICATION,//  Expected number of dropPartitions call 
Hive,WITHOUT_CLASSIFICATION,//  We get the cost of the operator 
Hive,WITHOUT_CLASSIFICATION,// also ensures that heartbeat() is no-op since client is likely doing it async 
Hive,WITHOUT_CLASSIFICATION,//  Set an upper bound how much we're willing to push before it should flush   we've set the memory treshold at 100kb each key is distinct   It should not go beyond 100k/16 (key+data) 
Hive,WITHOUT_CLASSIFICATION,//  Check streaming side 
Hive,WITHOUT_CLASSIFICATION,//  source filesystem 
Hive,WITHOUT_CLASSIFICATION,//  Note that this depends on the fact that no-one in this class calls anything but   getConnection.  If you want to use any of the Logger or wrap calls you'll have to   implement them. 
Hive,WITHOUT_CLASSIFICATION,//  remove pwd from conf file so that job tracker doesn't show this logs 
Hive,WITHOUT_CLASSIFICATION,//  Random test string 
Hive,WITHOUT_CLASSIFICATION,//  Check if this is a subquery / lateral view 
Hive,WITHOUT_CLASSIFICATION,//  This is for a special case to ensure unit tests pass 
Hive,WITHOUT_CLASSIFICATION,// If its a FileSink to bucketed files also use MR-style shuffle to 
Hive,WITHOUT_CLASSIFICATION,//  Don't do constant folding here.  Wait until the optimizer is changed to do it.   Family of related JIRAs: HIVE-7421 HIVE-7422 and HIVE-7424. 
Hive,WITHOUT_CLASSIFICATION,//  create dumpfile prefix needed to create descriptor 
Hive,WITHOUT_CLASSIFICATION,//  already deleted 
Hive,WITHOUT_CLASSIFICATION,//  MY_ENUMLIST 
Hive,WITHOUT_CLASSIFICATION,// create temp dir 
Hive,WITHOUT_CLASSIFICATION,// Get first level array 
Hive,WITHOUT_CLASSIFICATION,//  and does not call the real method so explicitly unset the queue name here 
Hive,WITHOUT_CLASSIFICATION,//  Remember the input file formats we validated and why. 
Hive,WITHOUT_CLASSIFICATION,//  Add scale. 
Hive,WITHOUT_CLASSIFICATION,//  If the kill failed and the user also thinks the session is invalid restart it. 
Hive,WITHOUT_CLASSIFICATION,//  epoch days since epoch 
Hive,WITHOUT_CLASSIFICATION,//  Working directory. 
Hive,WITHOUT_CLASSIFICATION,//  Build the filter and add parameters linearly; we are traversing leaf nodes LTR. 
Hive,WITHOUT_CLASSIFICATION,//  Identifier 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#createSQLXML()    */
Hive,WITHOUT_CLASSIFICATION,//  In Tez TEZ_AM_VIEW_ACLS/TEZ_AM_MODIFY_ACLS is used as the base for Tez ATS ACLS   so if exists honor it. So we get the same ACLS for Tez ATS entries and   Hive entries 
Hive,WITHOUT_CLASSIFICATION,//  For group type we need to build the projected group type with required leaves 
Hive,WITHOUT_CLASSIFICATION,//  Verify that the property has been properly set while creating the 
Hive,WITHOUT_CLASSIFICATION,/*  Class private variables  */
Hive,WITHOUT_CLASSIFICATION,//  stream buffers are arranged in enum order of stream kind 
Hive,WITHOUT_CLASSIFICATION,//  LastAnalyzed is stored per column but thrift has it per several;   get the lowest for now as nobody actually uses this field. 
Hive,WITHOUT_CLASSIFICATION,//  add in what we found to our type and table tables. 
Hive,WITHOUT_CLASSIFICATION,//  column name can be anything since it will be named by UDTF as clause 
Hive,WITHOUT_CLASSIFICATION,//  noop for now 
Hive,WITHOUT_CLASSIFICATION,//  append the first group within pattern: "${" 
Hive,WITHOUT_CLASSIFICATION,// create two connections 
Hive,WITHOUT_CLASSIFICATION,//  Multiplication with overflow check. Overflow produces NULL output. 
Hive,WITHOUT_CLASSIFICATION,//  also include the still-in-memory sidefile before it has been truely spilled 
Hive,WITHOUT_CLASSIFICATION,//  Meets all requirements 
Hive,WITHOUT_CLASSIFICATION,//  Test invalid case 
Hive,WITHOUT_CLASSIFICATION,//  try the repeating null case 
Hive,WITHOUT_CLASSIFICATION,//  operator list 
Hive,WITHOUT_CLASSIFICATION,//  TODO: this assumes indexes in getRowIndexes would match column IDs 
Hive,WITHOUT_CLASSIFICATION,//  clean prep 
Hive,WITHOUT_CLASSIFICATION,//  Check if there segments to load 
Hive,WITHOUT_CLASSIFICATION,//  We already have a struct node for the current index. Insert the constant value   into the corresponding struct node. 
Hive,WITHOUT_CLASSIFICATION,//  call-1: listLocatedStatus - mock:/mocktbl2   call-2: check side file for  mock:/mocktbl2/0_1 
Hive,WITHOUT_CLASSIFICATION,/*         * Job request got timed out. Job kill should have started. Return to client with        * QueueException.         */
Hive,WITHOUT_CLASSIFICATION,//  estimated count 
Hive,WITHOUT_CLASSIFICATION,//  adjust the data bytes according to any possible offset that was provided 
Hive,WITHOUT_CLASSIFICATION,//  Use UpdateQueryRequestProto.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,//  rules on how to recurse the ObjectInspector based on its type 
Hive,WITHOUT_CLASSIFICATION,//  (Currently none)   leftSemiPerBatchSetup(batch); 
Hive,WITHOUT_CLASSIFICATION,//  can be null for void type 
Hive,WITHOUT_CLASSIFICATION,//  Poll on the operation status till the query is completed 
Hive,WITHOUT_CLASSIFICATION,//  Locks not associated with a txn 
Hive,WITHOUT_CLASSIFICATION,/*      * The highWaterMark should be min(currentTxntxns.getTxn_high_water_mark()) assuming currentTxn>0     * otherwise if currentTxn=7 and 8 commits before 7 then 7 will see result of 8 which     * doesn't make sense for Snapshot Isolation. Of course for Read Committed the list should     * include the latest committed set.      */
Hive,WITHOUT_CLASSIFICATION,//  un/compressed sizes of file and no. of rows 
Hive,WITHOUT_CLASSIFICATION,//  we have found a merge work corresponding to this closing operator. Hook up this work. 
Hive,WITHOUT_CLASSIFICATION,//  addPartitionDesc already has the right partition location 
Hive,WITHOUT_CLASSIFICATION,//  check parts of the error not the whole string so as not to tightly   couple the error message with test 
Hive,WITHOUT_CLASSIFICATION,//  Task state is unkown 
Hive,WITHOUT_CLASSIFICATION,//  call-1: listLocatedStatus - mock:/mocktbl2   call-2: check side file for  mock:/mocktbl2/0_0 
Hive,WITHOUT_CLASSIFICATION,/*  * Specialized class for doing a vectorized map join that is an outer join on a Single-Column String * using a hash map.  */
Hive,WITHOUT_CLASSIFICATION,//  For FINAL and COMPLETE 
Hive,WITHOUT_CLASSIFICATION,//  Alters and replacements are not undoable if they've taken effect already. They are retriable though.   Creates are undoable but we cannot differentiate between creates alters and replacements from a Command level. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#setCursorName(java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  Mode 
Hive,WITHOUT_CLASSIFICATION,//  align on multiples from origin 
Hive,WITHOUT_CLASSIFICATION,//  Allocate/Map one txn per aborted writeId and abort the txn to mark writeid as aborted. 
Hive,WITHOUT_CLASSIFICATION,//  init udf 
Hive,WITHOUT_CLASSIFICATION,//  Check if forcing the location is required. 
Hive,WITHOUT_CLASSIFICATION,//  No pattern or DB 
Hive,WITHOUT_CLASSIFICATION,//  2. Partially contained   topOffset + topLimit > bottomLimit && topOffset < bottomLimit 
Hive,WITHOUT_CLASSIFICATION,//  scope opened/closed 10 times 
Hive,WITHOUT_CLASSIFICATION,//  partitionname ==>  (key=value/)*(key=value) 
Hive,WITHOUT_CLASSIFICATION,// create 1 row in a file 000001_0 (and an empty 000000_0) 
Hive,WITHOUT_CLASSIFICATION,//  three array   two int array 
Hive,WITHOUT_CLASSIFICATION,// are variables from IN(...) constant 
Hive,WITHOUT_CLASSIFICATION,//  All protocols 
Hive,WITHOUT_CLASSIFICATION,//  TODO: expose all WMContext's via /jmx to use in UI 
Hive,WITHOUT_CLASSIFICATION,//  Time doesn't matter. 
Hive,WITHOUT_CLASSIFICATION,//  NO COLUMN STATS 
Hive,WITHOUT_CLASSIFICATION,//  No data for the split or it fits in the middle of one or two slices. 
Hive,WITHOUT_CLASSIFICATION,//  Try to split bigger blocks. 
Hive,WITHOUT_CLASSIFICATION,//  TODO: can we pass custom things thru the progress? 
Hive,WITHOUT_CLASSIFICATION,//  This is impossible to read from this chunk. 
Hive,WITHOUT_CLASSIFICATION,//  2) to unpartitioned table 
Hive,WITHOUT_CLASSIFICATION,//  Used for legacy HiveDecimalV1 setScale compatibility for binary / display serialization of 
Hive,WITHOUT_CLASSIFICATION,//  Read the template into a string expand it and write it. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#clearParameters()    */
Hive,WITHOUT_CLASSIFICATION,/*    * Job callable task for job status operation. Overrides behavior of execute() to get   * status of a job. No need to override behavior of cleanup() as there is nothing to be   * done if job sttaus operation is timed out or interrupted.    */
Hive,WITHOUT_CLASSIFICATION,/*        * on firstRow invoke underlying evaluator to initialize skipNulls flag.        */
Hive,WITHOUT_CLASSIFICATION,//  Enum class? 
Hive,WITHOUT_CLASSIFICATION,//  creates connection to HMS and thus *must* occur after kerberos login above 
Hive,WITHOUT_CLASSIFICATION,//  start 1st server again 
Hive,WITHOUT_CLASSIFICATION,//  Create map for tracking gauges 
Hive,WITHOUT_CLASSIFICATION,//  If the time is in seconds converts it to milliseconds first. 
Hive,WITHOUT_CLASSIFICATION,//  either schema literal or serialization class must be provided 
Hive,WITHOUT_CLASSIFICATION,//  Get the relevant information for this column 
Hive,WITHOUT_CLASSIFICATION,//  Pass the ValidTxnList and ValidTxnWriteIdList snapshot configurations corresponding to the input query 
Hive,WITHOUT_CLASSIFICATION,// we didn't see this lock when running DELETE stmt above but now it showed up  so should "should never happen" happened... 
Hive,WITHOUT_CLASSIFICATION,//  we should get back null 
Hive,WITHOUT_CLASSIFICATION,//  Operation log configuration 
Hive,WITHOUT_CLASSIFICATION,//  Reserved as much as we needed. 
Hive,WITHOUT_CLASSIFICATION,//  read prompt configuration and substitute variables. 
Hive,WITHOUT_CLASSIFICATION,/*    * Returns true if the readField method is supported;    */
Hive,WITHOUT_CLASSIFICATION,//  Integer parsing move to next lower longword. 
Hive,WITHOUT_CLASSIFICATION,//   private final Helper helper; 
Hive,WITHOUT_CLASSIFICATION,//  Grimacing Face U+1F62C (4 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  Return our known table name 
Hive,WITHOUT_CLASSIFICATION,//  remove this backup zk server 
Hive,WITHOUT_CLASSIFICATION,//  The planner will not include unneeded columns for reading but other parts of execution   may ask for them.. 
Hive,WITHOUT_CLASSIFICATION,//  FOREIGN_TBL_NAME 
Hive,WITHOUT_CLASSIFICATION,//  after constant folding of child expression the return type of UDFCase might have changed   so recreate the expression 
Hive,WITHOUT_CLASSIFICATION,//  Value can be anything use the obj inspector and respect binary 
Hive,WITHOUT_CLASSIFICATION,//  divided by max split size 
Hive,WITHOUT_CLASSIFICATION,//  drop table. ignore error. 
Hive,WITHOUT_CLASSIFICATION,//  generate the data 
Hive,WITHOUT_CLASSIFICATION,// The actual check should be the compare of the connection string of the external tables 
Hive,WITHOUT_CLASSIFICATION,//  columns from SEL(*) branch only and append all columns from UDTF branch to it 
Hive,WITHOUT_CLASSIFICATION,// ~ Inner Classes ---------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  Trim additional bytes 
Hive,WITHOUT_CLASSIFICATION,//  4. Generate Parse Context for Optimizer & Physical compiler 
Hive,WITHOUT_CLASSIFICATION,//  batch size of 20 and decaying factor of 2 
Hive,WITHOUT_CLASSIFICATION,//  Do not update metrics we'd immediately add the session back if we are able to remove. 
Hive,WITHOUT_CLASSIFICATION,// return all the dependency urls 
Hive,WITHOUT_CLASSIFICATION,//  OUTER AND INNER JOINS 
Hive,WITHOUT_CLASSIFICATION,//  Noop: orcDataReaderRef is owned by the parent object 
Hive,WITHOUT_CLASSIFICATION,/*        * setup OI for input to resultExpr select list        */
Hive,WITHOUT_CLASSIFICATION,/*    * Test routines to exercise VectorizedRowBatch   * by filling column vectors with data and null values.    */
Hive,WITHOUT_CLASSIFICATION,//  Check whether the mapjoin is a bucketed mapjoin.   The above can be ascertained by checking the big table bucket -> small table buckets   mapping in the mapjoin descriptor.   First check if this map-join operator is already a BucketMapJoin or not. If not give up 
Hive,WITHOUT_CLASSIFICATION,//  RUN_ASYNC 
Hive,WITHOUT_CLASSIFICATION,// http://sqoop.apache.org/docs/1.4.5/SqoopUserGuide.html#_using_generic_and_specific_arguments 
Hive,WITHOUT_CLASSIFICATION,//  56 bit mask to generate positive 56 bit longs   from random signed longs 
Hive,WITHOUT_CLASSIFICATION,//  We have 3 cases here:   1) All the data is in the cache. Always a single slice no disk read no cache puts.   2) Some data is in the cache. Always a single slice disk read and a single cache put.   3) No data is in the cache. Multiple slices disk read and multiple cache puts. 
Hive,WITHOUT_CLASSIFICATION,//  Can this happen? Delta cannot exceed 0.5. 
Hive,WITHOUT_CLASSIFICATION,// the partition did not change   so the new partition should be similar to the original partition 
Hive,WITHOUT_CLASSIFICATION,//  Streaming evaluators fill in their results during the evaluate call. 
Hive,WITHOUT_CLASSIFICATION,//  TODO Track stats of rejections etc per host 
Hive,WITHOUT_CLASSIFICATION,//  Right now we only support one special character '/'.   More special characters can be added accordingly in the future.   NOTE:   If the following array is updated please also be sure to update the   configuration parameter documentation 
Hive,WITHOUT_CLASSIFICATION,//  1. Build GB Keys grouping set starting position   1.1 First Add original GB Keys 
Hive,WITHOUT_CLASSIFICATION,//  Inspect the test data 
Hive,WITHOUT_CLASSIFICATION,//  if this ast has only one child then no column name specified. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getNClob(java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  End of synchronized (ti) 
Hive,WITHOUT_CLASSIFICATION,//  6 : Drop table T1 => 1 event 
Hive,WITHOUT_CLASSIFICATION,//  Wrapper extends ql.metadata.Table for easy construction syntax 
Hive,WITHOUT_CLASSIFICATION,//  drop the table 
Hive,WITHOUT_CLASSIFICATION,//  Accumulo token already in Configuration but the Token isn't in the Job credentials like the 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#createStatement(int int)    */
Hive,WITHOUT_CLASSIFICATION,/*    * Specify the columns to deserialize into as a list.    */
Hive,WITHOUT_CLASSIFICATION,//  tag the original file name so we know where the file comes from   Note we currently only track the last known trace as   xattr has limited capacity. We shall revisit and store all original 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:SubmitWorkResponseProto) 
Hive,WITHOUT_CLASSIFICATION,//  create some data 
Hive,WITHOUT_CLASSIFICATION,//  right repeats 
Hive,WITHOUT_CLASSIFICATION,//  Use current for now. 
Hive,WITHOUT_CLASSIFICATION,//  processing will decref once and the last one will unlock the buffers. 
Hive,WITHOUT_CLASSIFICATION,//  Don't support changing name or type 
Hive,WITHOUT_CLASSIFICATION,//  Connection.getMetaData().getTableTypes() when type config is set to "CLASSIC" 
Hive,WITHOUT_CLASSIFICATION,//  does the conversion to String by itself. 
Hive,WITHOUT_CLASSIFICATION,//  End JoinExtractFilterRule.java 
Hive,WITHOUT_CLASSIFICATION,//  This one can be used to deny permission for performing the operation 
Hive,WITHOUT_CLASSIFICATION,// ---------------------------------------------------------------------------   Process Multi-Key Inner Join on a vectorized row batch.   
Hive,WITHOUT_CLASSIFICATION,/*  dataColumnNums  */
Hive,WITHOUT_CLASSIFICATION,//  Compare input 
Hive,WITHOUT_CLASSIFICATION,/*    * Setup a QBJoinTree between a SubQuery and its Parent Query. The Parent Query   * is the lhs of the Join.   *   * The Parent Query is represented by the last Operator needed to process its From Clause.   * In case of a single table Query this will be a TableScan but it can be a Join Operator   * if the Parent Query contains Join clauses or in case of a single source from clause   * the source could be a SubQuery or a PTF invocation.   *   * We setup the QBJoinTree with the above constrains in place. So:   * - the lhs of the QBJoinTree can be a another QBJoinTree if the Parent Query operator   *   is a JoinOperator. In this case we get its QBJoinTree from the 'joinContext'   * - the rhs is always a reference to the SubQuery. Its alias is obtained from the   *   QBSubQuery object.   *   * The QBSubQuery also provides the Joining Condition AST. The Joining Condition has been   * transformed in QBSubQuery setup before this call. The Joining condition has any correlated   * predicates and a predicate for joining the Parent Query expression with the SubQuery.   *   * The QBSubQuery also specifies what kind of Join to construct.   *   * Given this information once we initialize the QBJoinTree we call the 'parseJoinCondition'   * method to validate and parse Join conditions.    */
Hive,WITHOUT_CLASSIFICATION,//  and grand child 
Hive,WITHOUT_CLASSIFICATION,//  This is SQL standard - return state.MaxNArray or null if the size is zero. 
Hive,WITHOUT_CLASSIFICATION,//  Test that existing shared_write partition with new shared_write coalesces to 
Hive,WITHOUT_CLASSIFICATION,//  This two functions are for use only in the planner. It will fail in a task. 
Hive,WITHOUT_CLASSIFICATION,//  Simple pattern: Y-M 
Hive,WITHOUT_CLASSIFICATION,//  we cannot convert to bucket map join we cannot convert to   map join either based on the size. Check if we can convert to SMB join. 
Hive,WITHOUT_CLASSIFICATION,//  create the map-join operator 
Hive,WITHOUT_CLASSIFICATION,//  TEST - repeating non-NULL & selection 
Hive,WITHOUT_CLASSIFICATION,//  cardinality estimate from normalized bias corrected harmonic mean on 
Hive,WITHOUT_CLASSIFICATION,//  Get the counters for the input vertex. 
Hive,WITHOUT_CLASSIFICATION,//  both classes access by subclasses 
Hive,WITHOUT_CLASSIFICATION,//  Timeseries query results as records (types defined by metastore) 
Hive,WITHOUT_CLASSIFICATION,//  private ReadStringResults readStringResults; 
Hive,WITHOUT_CLASSIFICATION,//  Even if the user isn't doing schema evolution cut the schema   to the desired size. 
Hive,WITHOUT_CLASSIFICATION,//  Insert two rows into the table. 
Hive,WITHOUT_CLASSIFICATION,// see HIVE-6194 
Hive,WITHOUT_CLASSIFICATION,//  Set base to the location so that the input format reads the original files. 
Hive,WITHOUT_CLASSIFICATION,// locks from different transactions detected (or from transaction and read-only query in autocommit) 
Hive,WITHOUT_CLASSIFICATION,//  If a operator wants to do some work at the beginning of a group   the first group 
Hive,WITHOUT_CLASSIFICATION,//  Convert all NaN values in vector v to NULL. Should only be used if n > 0. 
Hive,WITHOUT_CLASSIFICATION,//  in filter expression since it will be taken care by partitio pruner 
Hive,WITHOUT_CLASSIFICATION,//  Don't store too many items; if the queue is full we'll block the checker thread.   Since the worker count determines how many queries can be running in parallel it makes   no sense to produce more work if the backlog is getting too long. 
Hive,WITHOUT_CLASSIFICATION,//  checking. 
Hive,WITHOUT_CLASSIFICATION,//  String query = SessionState.get().getCmd(); 
Hive,WITHOUT_CLASSIFICATION,//  Session handle should not be null 
Hive,WITHOUT_CLASSIFICATION,//  Nothing will be added to the expression 
Hive,WITHOUT_CLASSIFICATION,//  2.1.1. If semijoin... 
Hive,WITHOUT_CLASSIFICATION,/*      * Acending.      */
Hive,WITHOUT_CLASSIFICATION,//  print foreign key containing parents 
Hive,WITHOUT_CLASSIFICATION,//  iterate through children and push down not for each one 
Hive,WITHOUT_CLASSIFICATION,//  realm is ignored 
Hive,WITHOUT_CLASSIFICATION,//  Walk the operator tree to the TableScan and build the mapping 
Hive,WITHOUT_CLASSIFICATION,//  Make one's complement masked only for the bytes read 
Hive,WITHOUT_CLASSIFICATION,//  nothing to be done for filters - the output schema does not change. 
Hive,WITHOUT_CLASSIFICATION,/* make initialDelay a random number in [0 0.75*heartbeatInterval] so that if a lot      of queries land on the server at the same time and all get blocked on lack of      resources that they all don't start heartbeating at the same time */
Hive,WITHOUT_CLASSIFICATION,//  Arithmetic operations (re)set the results. 
Hive,WITHOUT_CLASSIFICATION,//  Rewrite projects to replace column references by constants when possible 
Hive,WITHOUT_CLASSIFICATION,//  RESOURCE_PLANS 
Hive,WITHOUT_CLASSIFICATION,//  +-------------|-------------+   |xxxx100000000|1000000000000|  (lr=9 + idx=1024)   +-------------|-------------+                  \   +---------------|-----------+   |xxxx10000000010|00000000000|  (lr=2 + idx=0)   +---------------|-----------+ 
Hive,WITHOUT_CLASSIFICATION,//  Is this a primitive type? 
Hive,WITHOUT_CLASSIFICATION,//  add it to the log processor: 
Hive,WITHOUT_CLASSIFICATION,//  If the alias is already there then we have a conflict 
Hive,WITHOUT_CLASSIFICATION,//  Create MD provider 
Hive,WITHOUT_CLASSIFICATION,/*    * This operator only process small tables Read the key/value pairs Load them into hashtable    */
Hive,WITHOUT_CLASSIFICATION,//  reset the BufferReader if fetching from the beginning of the file 
Hive,WITHOUT_CLASSIFICATION,//  extract any drop privileges out of required privileges 
Hive,WITHOUT_CLASSIFICATION,//  Without this 2020-20-20 becomes 2021-08-20. 
Hive,WITHOUT_CLASSIFICATION,//  No change for multiply by 10^0 or value 0. 
Hive,WITHOUT_CLASSIFICATION,//  Query should have a fetch task. 
Hive,WITHOUT_CLASSIFICATION,//  cause we cannot prune columns from UDTF branch currently extract 
Hive,WITHOUT_CLASSIFICATION,//  substituted 
Hive,WITHOUT_CLASSIFICATION,// count distinct with more that one argument is not supported 
Hive,WITHOUT_CLASSIFICATION,/*      * Custom build arguments.      */
Hive,WITHOUT_CLASSIFICATION,//  get node type 
Hive,WITHOUT_CLASSIFICATION,//  has to use LinkedHashMap to enforce order 
Hive,WITHOUT_CLASSIFICATION,//  ??? 
Hive,WITHOUT_CLASSIFICATION,//  Will be superceded by credential provider   Will not be superceded 
Hive,WITHOUT_CLASSIFICATION,//  The bucketing and sorting positions should exactly match 
Hive,WITHOUT_CLASSIFICATION,//  distinct is at lost position. 
Hive,WITHOUT_CLASSIFICATION,//  Subquery: no rewriting needed 
Hive,WITHOUT_CLASSIFICATION,//  VectorMapJoinOperator 
Hive,WITHOUT_CLASSIFICATION,//  call function 
Hive,WITHOUT_CLASSIFICATION,//  Create StructObjectInspector 
Hive,WITHOUT_CLASSIFICATION,//  String type is never stored as anything other than an escaped string 
Hive,WITHOUT_CLASSIFICATION,//  Test sd params - we check that all the parameters in an empty table   are retained as-is. We may add beyond it but not change values for   any parameters that hive defines for an empty table. 
Hive,WITHOUT_CLASSIFICATION,//  1st task requested host1 got host1 
Hive,WITHOUT_CLASSIFICATION,//  clear work from ThreadLocal after splits generated in case of thread is reused in pool. 
Hive,WITHOUT_CLASSIFICATION,//  we can not use "split" function directly as ";" may be quoted 
Hive,WITHOUT_CLASSIFICATION,//  disabling vectorization as this test yields incorrect results with vectorization 
Hive,WITHOUT_CLASSIFICATION,//  Do the per-batch setup for an left semi join. 
Hive,WITHOUT_CLASSIFICATION,//  Get a timestamp from a string constant or cast 
Hive,WITHOUT_CLASSIFICATION,// completion of "delete from tab1" txn 
Hive,WITHOUT_CLASSIFICATION,//  construct a map join and set it as the child operator of tblScan_op 
Hive,WITHOUT_CLASSIFICATION,//  finished writing array contents 
Hive,WITHOUT_CLASSIFICATION,// for dynamic uris re-lookup if there are new metastore locations 
Hive,WITHOUT_CLASSIFICATION,//  T | unknown | unknown 
Hive,WITHOUT_CLASSIFICATION,//  Cause Timestamp object to be replaced (in buggy code) with ZERO_TIMESTAMP. 
Hive,WITHOUT_CLASSIFICATION,//  GBy for DISTINCT after windowing 
Hive,WITHOUT_CLASSIFICATION,//  this = this.mag / 10**this.scale   right = right.mag / 10**right.scale   this * right = this.mag * right.mag / 10**(this.scale + right.scale)   so we need to scale down (this.scale + right.scale - newScale) 
Hive,WITHOUT_CLASSIFICATION,//  Both children in the expression should not be literal 
Hive,WITHOUT_CLASSIFICATION,//  empty c'tor to make jackson happy 
Hive,WITHOUT_CLASSIFICATION,//  verify the directories in table location 
Hive,WITHOUT_CLASSIFICATION,//  Try ISO-8601 format 
Hive,WITHOUT_CLASSIFICATION,/*  This method converts from the String representation of Druid type   * to the corresponding Hive type  */
Hive,WITHOUT_CLASSIFICATION,//  Indicates the maximum capacity of the cache. Minimum value should be the number of threads. 
Hive,WITHOUT_CLASSIFICATION,//  Note: doesn't check for overflow. Could AND with max refcount mask but the caller checks. 
Hive,WITHOUT_CLASSIFICATION,//  One time update issue.  When the new 'hive' catalog is created in an upgrade the   script does not know the location of the warehouse.  So we need to update it. 
Hive,WITHOUT_CLASSIFICATION,//  Build the schema for this table which is slightly different than the   schema for the input table 
Hive,WITHOUT_CLASSIFICATION,/*      * Propagate null values for a two-input operator and set isRepeating and noNulls appropriately.      */
Hive,WITHOUT_CLASSIFICATION,/*          * Positioned to first.          */
Hive,WITHOUT_CLASSIFICATION,//  append a leading 0 if needed 
Hive,WITHOUT_CLASSIFICATION,//  Long.MIN_VALUE 
Hive,WITHOUT_CLASSIFICATION,/*        * Currently in tez the flow of events is thus:       * "Generate Splits -> Initialize Vertex" (with parallelism info obtained       * from the generate splits phase). The generate splits phase groups       * splits using the TezGroupedSplitsInputFormat. However for bucket map       * joins the grouping done by this input format results in incorrect       * results as the grouper has no knowledge of buckets. So we initially       * set the input format to be HiveInputFormat (in DagUtils) for the case       * of bucket map joins so as to obtain un-grouped splits. We then group       * the splits corresponding to buckets using the tez grouper which returns       * TezGroupedSplits.        */
Hive,WITHOUT_CLASSIFICATION,//  stores each cell's length of a column in one DataOutputBuffer element 
Hive,WITHOUT_CLASSIFICATION,//  Pairwise: InitOuputColHasNulls InitOuputColIsRepeating Column1HasNulls   Column1IsRepeating Column2HasNulls Column2IsRepeating 
Hive,WITHOUT_CLASSIFICATION,//  7. If GroupingSets Cube Rollup were used we account grouping__id 
Hive,WITHOUT_CLASSIFICATION,//  only need flip the MSB? 
Hive,WITHOUT_CLASSIFICATION,//  service a fresh conf for every testMethod 
Hive,WITHOUT_CLASSIFICATION,//  Note that the calls below will throw an exception if a Java SecurityManager   is installed and configured to forbid invoking setAccessible(). In practice   this is not a problem in Hive. 
Hive,WITHOUT_CLASSIFICATION,//  reset the execContext for each new row 
Hive,WITHOUT_CLASSIFICATION,//  The read field of the Union gives us its tag. 
Hive,WITHOUT_CLASSIFICATION,//  disable expensive operations on the metastore 
Hive,WITHOUT_CLASSIFICATION,//  Something else holds the lock at the moment. Don't bother cleaning up. 
Hive,WITHOUT_CLASSIFICATION,//  test null input 
Hive,WITHOUT_CLASSIFICATION,//  Read length 
Hive,WITHOUT_CLASSIFICATION,//  adjacency list 
Hive,WITHOUT_CLASSIFICATION,//  CLUSTER / WORKER END     Job submitted to the cluster    
Hive,WITHOUT_CLASSIFICATION,//  Shutdown the current active one 
Hive,WITHOUT_CLASSIFICATION,/*             get the operation logs once and print it then wait till progress bar update is complete            before printing the remaining logs.           */
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getRef(int)    */
Hive,WITHOUT_CLASSIFICATION,/*    * Get the CPU & GC   *   * counters org.apache.tez.common.counters.TaskCounter   *  GC_TIME_MILLIS=37712   *  CPU_MILLISECONDS=2774230    */
Hive,WITHOUT_CLASSIFICATION,//  Shutdown the timeout thread if any while closing this operation 
Hive,WITHOUT_CLASSIFICATION,//  evaluate on row 
Hive,WITHOUT_CLASSIFICATION,//  out   of   range   due   to   time 
Hive,WITHOUT_CLASSIFICATION,//  sort before comparing with expected results 
Hive,WITHOUT_CLASSIFICATION,//  Clearing this before sending a kill is OK since canFinish will change to false.   Ideally this should be a state machine where kills are issued to the executor   and the structures are cleaned up once all tasks complete. New requests however 
Hive,WITHOUT_CLASSIFICATION,//  UNDONE: We need to get the table schema inspector from self-describing Input File           Formats like ORC.  Modify the ORC serde instead?  For now this works. 
Hive,WITHOUT_CLASSIFICATION,//  38 9's digits. 
Hive,WITHOUT_CLASSIFICATION,//  Fall back to regular API and create statuses without ID. 
Hive,WITHOUT_CLASSIFICATION,//  If the table does not define any transactional properties we return a default type. 
Hive,WITHOUT_CLASSIFICATION,//  Trigger query hook before compilation 
Hive,WITHOUT_CLASSIFICATION,//  update columnar lineage for each partition 
Hive,WITHOUT_CLASSIFICATION,//  This node was in previous union inputs but it is not in this one 
Hive,WITHOUT_CLASSIFICATION,//  e.g broadcast data 
Hive,WITHOUT_CLASSIFICATION,//  stores Explain output 
Hive,WITHOUT_CLASSIFICATION,/*  100 files x 1000 size for 99 splits  */
Hive,WITHOUT_CLASSIFICATION,/*    * A different batch for vectorized Input File Format readers so they can do their work   * overlapped with work of the row collection that vector/row deserialization does.  This allows   * the partitions to mix modes (e.g. for us to flush the previously batched rows on file change).    */
Hive,WITHOUT_CLASSIFICATION,//  Not always there is a SessionState. Sometimes ExeDriver is directly invoked 
Hive,WITHOUT_CLASSIFICATION,//  table level event that matches us 
Hive,WITHOUT_CLASSIFICATION,//  SW.SW: Lock we are examining is shared write 
Hive,WITHOUT_CLASSIFICATION,//  avoid a copy. 
Hive,WITHOUT_CLASSIFICATION,//  Last row of last batch determines isGroupResultNull and decimal lastValue. 
Hive,WITHOUT_CLASSIFICATION,//  Now that we have found real data emit sign byte if necessary. 
Hive,WITHOUT_CLASSIFICATION,//  Create executor 
Hive,WITHOUT_CLASSIFICATION,//  the existing entry already has grant or new priv does not have   grant   no update needs to be done. 
Hive,WITHOUT_CLASSIFICATION,//  skip some piece of data: 
Hive,WITHOUT_CLASSIFICATION,//  Useful for class generation via templates. 
Hive,WITHOUT_CLASSIFICATION,//  normally statsKeyPref will be the same as dirName but the latter 
Hive,WITHOUT_CLASSIFICATION,//  TODO Make sure to cleanup created dirs. 
Hive,WITHOUT_CLASSIFICATION,// ------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  CAST(expr AS COLTYPE) AS COLNAME 
Hive,WITHOUT_CLASSIFICATION,//  Full ACID export goes thru UpdateDelete analyzer. 
Hive,WITHOUT_CLASSIFICATION,//  tests the missing element layer detected by a multi-field group 
Hive,WITHOUT_CLASSIFICATION,//  Only done when it is a bucket map join only no SMB. 
Hive,WITHOUT_CLASSIFICATION,//  Friday 30th August 1985 12:00:00 AM 
Hive,WITHOUT_CLASSIFICATION,//  Generate split strategy for acid schema files if any. 
Hive,WITHOUT_CLASSIFICATION,//  replace-mode creates are really alters using CreateTableDesc. 
Hive,WITHOUT_CLASSIFICATION,//  Create an export task and add it as a root task 
Hive,WITHOUT_CLASSIFICATION,//  core pool size   max pool size   direct hand-off 
Hive,WITHOUT_CLASSIFICATION,// New record reader ID 
Hive,WITHOUT_CLASSIFICATION,//  If we've already satisfied the number of events we were supposed to deliver we end it. 
Hive,WITHOUT_CLASSIFICATION,//  Create environment for AM. 
Hive,WITHOUT_CLASSIFICATION,//  If the first argument is null return null. (It's okay for other arguments to be null in   which case "null" will be printed.) 
Hive,WITHOUT_CLASSIFICATION,//  create _SUCCESS FILE if so requested. 
Hive,WITHOUT_CLASSIFICATION,//  Get the top operator and it's child all operators have a single parent 
Hive,WITHOUT_CLASSIFICATION,/*    * TODO: Handle 1) cast 2) Windowing Agg Call    */
Hive,WITHOUT_CLASSIFICATION,//  if archiving was done at this or at upper level its level   would be lesser or equal to specification size   it is not which means no archiving at this or upper level 
Hive,WITHOUT_CLASSIFICATION,//  Need to iterate twice since BytesWritable doesn't support append. 
Hive,WITHOUT_CLASSIFICATION,//  processing the message that the successful init has queued for us. 
Hive,WITHOUT_CLASSIFICATION,//  get too crazy 
Hive,WITHOUT_CLASSIFICATION,// the lazy struct object inspector 
Hive,WITHOUT_CLASSIFICATION,//  call-3: check existence of side file for  mock:/mocktbl/0_1 
Hive,WITHOUT_CLASSIFICATION,//  String including '\000' style literal characters. 
Hive,WITHOUT_CLASSIFICATION,//  always mark as llap 
Hive,WITHOUT_CLASSIFICATION,// test that new columns gets added to table schema 
Hive,WITHOUT_CLASSIFICATION,//  Verify proxy user privilege of the realUser for the proxyUser 
Hive,WITHOUT_CLASSIFICATION,//  If both sides are constants there is nothing to propagate 
Hive,WITHOUT_CLASSIFICATION,//  Add this node to the parent node. 
Hive,WITHOUT_CLASSIFICATION,//  todo use final fields 
Hive,WITHOUT_CLASSIFICATION,//  Check if the score for this method is any better relative to others 
Hive,WITHOUT_CLASSIFICATION,//  The operator is not of RexCall type   So we fail. Fall through. 
Hive,WITHOUT_CLASSIFICATION,//  check out the types 
Hive,WITHOUT_CLASSIFICATION,/*  * Specialized class for doing a vectorized map join that is an inner join on a Single-Column String * and only big table columns appear in the join result so a hash multi-set is used.  */
Hive,WITHOUT_CLASSIFICATION,//  When truncated included is used its length must be at least the number of source type infos. 
Hive,WITHOUT_CLASSIFICATION,//  we cannot proceed and need to tell the hive client that retries won't succeed either 
Hive,WITHOUT_CLASSIFICATION,//  Add new information from source to target 
Hive,WITHOUT_CLASSIFICATION,/*    * Remove the SubQuery from the Where Clause Tree.   * return the remaining WhereClause.    */
Hive,WITHOUT_CLASSIFICATION,//  Now deserialize it. 
Hive,WITHOUT_CLASSIFICATION,// here we assume that upstream code may have parametrized the msg from ErrorMsg  so we want to keep it 
Hive,WITHOUT_CLASSIFICATION,//  last value should be present 
Hive,WITHOUT_CLASSIFICATION,// For each matching partition call getSplits on the underlying InputFormat 
Hive,WITHOUT_CLASSIFICATION,//  from 64-bit linear congruential generator 
Hive,WITHOUT_CLASSIFICATION,//  constant propagation constant folding 
Hive,WITHOUT_CLASSIFICATION,//  Verify moveOnlyTask is NOT optimized 
Hive,WITHOUT_CLASSIFICATION,//  Create or add node for current pool. 
Hive,WITHOUT_CLASSIFICATION,//  c1 c2 and c3 are sorted in the same order. 
Hive,WITHOUT_CLASSIFICATION,//  get splits from Accumulo 
Hive,WITHOUT_CLASSIFICATION,/*  Determine if two strings are equal from two byte arrays each   * with their own start position and length.   * Use lexicographic unsigned byte value order.   * This is what's used for UTF-8 sort order.    */
Hive,WITHOUT_CLASSIFICATION,// if a table is using some custom I/O format and it's not in the classpath we won't mark  the table for Acid but today (Hive 3.1 and earlier) OrcInput/OutputFormat is the only  Acid format 
Hive,WITHOUT_CLASSIFICATION,/*  neededVirtualColumns  */
Hive,WITHOUT_CLASSIFICATION,//  Launch it in the parallel mode as a separate thread only for MR tasks 
Hive,WITHOUT_CLASSIFICATION,//  7. Build Rel for Limit Clause 
Hive,WITHOUT_CLASSIFICATION,//  L_STRING 
Hive,WITHOUT_CLASSIFICATION,//  Convert from Java to Writable 
Hive,WITHOUT_CLASSIFICATION,//  save it to the current script if any 
Hive,WITHOUT_CLASSIFICATION,//  MESSAGE_FORMAT 
Hive,WITHOUT_CLASSIFICATION,//  A column family or qualifier we don't want to include in the map 
Hive,WITHOUT_CLASSIFICATION,//  in case the sizes match preference is   given to the table with fewer partitions 
Hive,WITHOUT_CLASSIFICATION,//  The HiveServer2 instance running this service 
Hive,WITHOUT_CLASSIFICATION,//  iterate through the index so that if we add more children   they don't get re-visited 
Hive,WITHOUT_CLASSIFICATION,//  Write json to the temp file. 
Hive,WITHOUT_CLASSIFICATION,//  Should produce JSON 
Hive,WITHOUT_CLASSIFICATION,//  skip not the one we are looking for. 
Hive,WITHOUT_CLASSIFICATION,//  If script preserves alias and value for columns related to keys user can set this true 
Hive,WITHOUT_CLASSIFICATION,//  Deactivate currently active resource plan. 
Hive,WITHOUT_CLASSIFICATION,// extra heartbeat is logically harmless but ... 
Hive,WITHOUT_CLASSIFICATION,//  otherwise write to the file system implied by the directory   no copy is required. we may want to revisit this policy in future 
Hive,WITHOUT_CLASSIFICATION,// new MockFile("mock:/tmp/base_000123/bucket_00001" 500 new byte[0]) 
Hive,WITHOUT_CLASSIFICATION,//  make the MoveTask as the child of the MR Task 
Hive,WITHOUT_CLASSIFICATION,//  MESSAGE 
Hive,WITHOUT_CLASSIFICATION,//  Test getter for map object. 
Hive,WITHOUT_CLASSIFICATION,//  Plug verifying metastore in for testing DirectSQL. 
Hive,WITHOUT_CLASSIFICATION,//  Special-case for ORC. 
Hive,WITHOUT_CLASSIFICATION,//  The node should always be known by this point. Log occasionally if it is not known. 
Hive,WITHOUT_CLASSIFICATION,//  Currently sum(distinct) not supported in PartitionEvaluator 
Hive,WITHOUT_CLASSIFICATION,/*    * Assign a row from an array of objects.    */
Hive,WITHOUT_CLASSIFICATION,//  Base path for REPL LOAD 
Hive,WITHOUT_CLASSIFICATION,//  This vectorized code pattern says:       If the input batch has no nulls at all (noNulls is true) OR      the input row is NOT NULL copy the value.        Otherwise we have a NULL input value.  The standard way to mark a NULL in the      output batch is: turn off noNulls indicating there is at least one NULL in the batch      and mark that row as NULL.        When a vectorized row batch is reset noNulls is set to true and the isNull array      is zeroed.     We grab the key at index 0.  We don't care about selected or repeating since all keys   in the input batch are suppose to be the same.   
Hive,WITHOUT_CLASSIFICATION,//  DAYS_SINCE_EPOCH 
Hive,WITHOUT_CLASSIFICATION,//  test left input repeating 
Hive,WITHOUT_CLASSIFICATION,//  If this map task has a FileSinkOperator and bucketing/sorting metadata can be   inferred about the data being written by that operator these are mappings from the directory 
Hive,WITHOUT_CLASSIFICATION,//  single table alias reference ignore it and move to the next expression node. 
Hive,WITHOUT_CLASSIFICATION,//  Currently we only support these no-precision-loss or promotion data type conversions:      TinyInt --> SmallInt    TinyInt --> Int    TinyInt --> BigInt      SmallInt -> Int    SmallInt -> BigInt      Int --> BigInt      Float -> Double      Since we stare Char without padding it can become a String implicitly.    (Char | VarChar) -> String   
Hive,WITHOUT_CLASSIFICATION,//  3rd task requested host2 got host1 as host2 and host3 are full 
Hive,WITHOUT_CLASSIFICATION,//  Test that only the fixed property (...ForQueue) is used in order determination not the dynamic call. 
Hive,WITHOUT_CLASSIFICATION,//  Add support for configurable threads however 1 should always be enough. 
Hive,WITHOUT_CLASSIFICATION,//  ConfVars.SCRATCHDIR - {test.tmp.dir}/scratchdir 
Hive,WITHOUT_CLASSIFICATION,//  Map that contains the rows for each alias 
Hive,WITHOUT_CLASSIFICATION,//  We might still be able to push the limit 
Hive,WITHOUT_CLASSIFICATION,//  A mapper can span multiple files/partitions.   The VectorPartitionContext need to be changed if the input file changed 
Hive,WITHOUT_CLASSIFICATION,//  if all files are needed to meet the size limit we disable   optimization. It usually happens for empty table/partition or   table/partition with only one file. By disabling this   optimization we can avoid retrying the query if there is   not sufficient rows. 
Hive,WITHOUT_CLASSIFICATION,//  Find the parsed delta files. 
Hive,WITHOUT_CLASSIFICATION,//  add fake entries 
Hive,WITHOUT_CLASSIFICATION,//  trigger clean errors for anyone who mixes up identity with hosts 
Hive,WITHOUT_CLASSIFICATION,//  Same algorithm as TimestampWritable (not currently import-able here). 
Hive,WITHOUT_CLASSIFICATION,//  write a non-null element 
Hive,WITHOUT_CLASSIFICATION,//  5. Run Cleaner. It should remove the 2 delta dirs. 
Hive,WITHOUT_CLASSIFICATION,//  overflow checks 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.ICLIService#getTableTypes(org.apache.hive.service.cli.SessionHandle)    */
Hive,WITHOUT_CLASSIFICATION,//  3. Obtain Stats for Partition Cols 
Hive,WITHOUT_CLASSIFICATION,//  to a list. 
Hive,WITHOUT_CLASSIFICATION,//  fallback to default 
Hive,WITHOUT_CLASSIFICATION,//  Are we using the fact the input is sorted 
Hive,WITHOUT_CLASSIFICATION,// writing both acid and non-acid resources in the same txn  tab1 write is a dynamic partition insert 
Hive,WITHOUT_CLASSIFICATION,//  If it is an external table we are done 
Hive,WITHOUT_CLASSIFICATION,// create an empty (invalid) side file - make sure getLogicalLength() throws 
Hive,WITHOUT_CLASSIFICATION,//  Specify that the results of this query can be cached. 
Hive,WITHOUT_CLASSIFICATION,// test if null dbName works ("default" is used) 
Hive,WITHOUT_CLASSIFICATION,//  we are aborting only the current transaction so move the min range for heartbeat or disable heartbeat   if the current txn is last in the batch. 
Hive,WITHOUT_CLASSIFICATION,//  Return mocked SerDeInfo 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getDate(int java.util.Calendar)    */
Hive,WITHOUT_CLASSIFICATION,//  Copy over the mandatory configs for the package. 
Hive,WITHOUT_CLASSIFICATION,//  Generate row values. 
Hive,WITHOUT_CLASSIFICATION,//  6.2.2 Update Output Row Schema 
Hive,WITHOUT_CLASSIFICATION,//  Map from type name (such as int or varchar(40) to the corresponding PrimitiveTypeInfo 
Hive,WITHOUT_CLASSIFICATION,//  everything qualifies (4 rows all with value -1) 
Hive,WITHOUT_CLASSIFICATION,//  if there's no RexInputRef in the projected expressions   return empty set. 
Hive,WITHOUT_CLASSIFICATION,//  Check object. 
Hive,WITHOUT_CLASSIFICATION,// Expecting to change the size of internal structures 
Hive,WITHOUT_CLASSIFICATION,//  Proxy class within the tez.api package to access package private methods. 
Hive,WITHOUT_CLASSIFICATION,/*          * sz Estimate = sz needed by underlying AggBuffer + sz for results + sz         * for maxChain + 3 * JavaDataModel.PRIMITIVES1 sz of results = sz of         * underlying * wdwSz sz of maxChain = sz of underlying * wdwSz          */
Hive,WITHOUT_CLASSIFICATION,//  we need to create the merge join work 
Hive,WITHOUT_CLASSIFICATION,//  Sort the splits so that subsequent grouping is consistent. 
Hive,WITHOUT_CLASSIFICATION,//  max length for varchar and char cases 
Hive,WITHOUT_CLASSIFICATION,//  All are selected; 
Hive,WITHOUT_CLASSIFICATION,//        "insert overwrite directory" command if there were no bucketing or list bucketing. 
Hive,WITHOUT_CLASSIFICATION,// statementId = 1 
Hive,WITHOUT_CLASSIFICATION,//  Save char/varchar as string 
Hive,WITHOUT_CLASSIFICATION,//  For NULL fields make up a valid max length. 
Hive,WITHOUT_CLASSIFICATION,//  trigger failover on miniHS2_1 without authorization header 
Hive,WITHOUT_CLASSIFICATION,// normilize table name for mapping 
Hive,WITHOUT_CLASSIFICATION,//  We don't currently allow imposition of a type 
Hive,WITHOUT_CLASSIFICATION,//  Array should have ListTypeInfo   Within the list we extract types 
Hive,WITHOUT_CLASSIFICATION,//  No locks no txn we outta here. 
Hive,WITHOUT_CLASSIFICATION,//  Does the logger config look correct? 
Hive,WITHOUT_CLASSIFICATION,// verifyRun("SELECT * from " + replDbName + ".mat_view2" unptn_data driverMirror); 
Hive,WITHOUT_CLASSIFICATION,//  delete remaining jars 
Hive,WITHOUT_CLASSIFICATION,//  lock a table as in dynamic partitions 
Hive,WITHOUT_CLASSIFICATION,//  Correlating variables are a means for other relational expressions to use   fields. 
Hive,WITHOUT_CLASSIFICATION,//  serialize the row as a struct 
Hive,WITHOUT_CLASSIFICATION,//  is under the limit. 
Hive,WITHOUT_CLASSIFICATION,//  build partition strings 
Hive,WITHOUT_CLASSIFICATION,//  Not in VRB mode - the new cache data is (partially) ready we should use it.   Force the rest of the data thru. 
Hive,WITHOUT_CLASSIFICATION,//  Column is not a partition column for the table   as we do not allow partitions based on complex   list or struct fields. 
Hive,WITHOUT_CLASSIFICATION,//  parse out n-grams update frequency counts 
Hive,WITHOUT_CLASSIFICATION,//  remove the tag from key coming out of reducer   and store it in separate variable.   make a copy for multi-insert with join case as Spark re-uses input key from same parent 
Hive,WITHOUT_CLASSIFICATION,//  this will take care of mapping between input column names and output column names. The   returned column stats will have the output column names. 
Hive,WITHOUT_CLASSIFICATION,/*        * Check.12.h :: SubQuery predicates cannot only refer to Outer Query columns.        */
Hive,WITHOUT_CLASSIFICATION,//  Show we cannot create a child of a file 
Hive,WITHOUT_CLASSIFICATION,//  Iterate over the map and remove semijoin optimizations if needed. 
Hive,WITHOUT_CLASSIFICATION,//  1 more than capacity. 
Hive,WITHOUT_CLASSIFICATION,//  Check if this UDF has been provided with type params for the output varchar type 
Hive,WITHOUT_CLASSIFICATION,//  execute final aggregation stage for simple fetch query on fetch task 
Hive,WITHOUT_CLASSIFICATION,//  1. We try to merge this join with the left child 
Hive,WITHOUT_CLASSIFICATION,//  create the adaptor for this function call to work in vector mode 
Hive,WITHOUT_CLASSIFICATION,//  get the vlong that represents the map size 
Hive,WITHOUT_CLASSIFICATION,//  switch to hive-site.xml with remote metastore 
Hive,WITHOUT_CLASSIFICATION,//  Our one time process method initialization. 
Hive,WITHOUT_CLASSIFICATION,//  start_date is Sun 2 letters day name 
Hive,WITHOUT_CLASSIFICATION,//  Delay with exponential backoff 
Hive,WITHOUT_CLASSIFICATION,//  done with the row 
Hive,WITHOUT_CLASSIFICATION,//  Sleep for 3 seconds 
Hive,WITHOUT_CLASSIFICATION,/*  A UDF like one a user would create implementing the UDF interface. * This is to be used to test the vectorized UDF adaptor for legacy-style UDFs.  */
Hive,WITHOUT_CLASSIFICATION,//  f is a file 
Hive,WITHOUT_CLASSIFICATION,//  For table level load need not update replication state for the database 
Hive,WITHOUT_CLASSIFICATION,// I don't think this can happen... but just in case 
Hive,WITHOUT_CLASSIFICATION,//  This a 2nd batch with the same "column schema" as the big table batch that can be used to   build join output results in.  If we can create some join output results in the big table   batch we will for better efficiency (i.e. avoiding copying).  Otherwise we will use the 
Hive,WITHOUT_CLASSIFICATION,//  Perform some operations 
Hive,WITHOUT_CLASSIFICATION,//  load the partition 
Hive,WITHOUT_CLASSIFICATION,//  Try with null args 
Hive,WITHOUT_CLASSIFICATION,//  The FSOP configuration for the FSOP that is going to write initial data during ctas. 
Hive,WITHOUT_CLASSIFICATION,//  Add all columns to make a vectorization context for   the TableScan operator. 
Hive,WITHOUT_CLASSIFICATION,//  Do rounding of fractional digits. 
Hive,WITHOUT_CLASSIFICATION,//  During map/reduce tasks there may not be a valid HiveConf from the SessionState.   So lookup and save any needed conf information during query compilation in the Hive conf   (where there should be valid HiveConf from SessionState).  Plan serialization will ensure   we have access to these values in the map/reduce tasks. 
Hive,WITHOUT_CLASSIFICATION,//  Leave the client to time out. 
Hive,WITHOUT_CLASSIFICATION,// http://db.apache.org/derby/docs/10.7/ref/rrefsqljoffsetfetch.html 
Hive,WITHOUT_CLASSIFICATION,//  Generate the right hand side of the IN clause 
Hive,WITHOUT_CLASSIFICATION,/*    * the WindowingSpec used for windowing clauses in this QB.    */
Hive,WITHOUT_CLASSIFICATION,//  We trigger the transform 
Hive,WITHOUT_CLASSIFICATION,//   - processing is completed. 
Hive,WITHOUT_CLASSIFICATION,//  Multiple stripes 
Hive,WITHOUT_CLASSIFICATION,//  insert the dummy store operator here 
Hive,WITHOUT_CLASSIFICATION,/*      * load entire archive     * There is some parallelism going on if you load more than 1 partition     * The file name changes from run to run between 000000_0 and 000001_0 and 000002_0     * The data is correct but this causes ROW__ID.bucketId/file names to change      */
Hive,WITHOUT_CLASSIFICATION,// if here checked all parts and they are Acid compatible - make it acid 
Hive,WITHOUT_CLASSIFICATION,//  Test behavior with non-chunked streams 
Hive,WITHOUT_CLASSIFICATION,//  If there are aborted txns then the minimum aborted txnid could be the min_uncommitted_txnid 
Hive,WITHOUT_CLASSIFICATION,//  END_TIME 
Hive,WITHOUT_CLASSIFICATION,//  The children type should be converted to return type 
Hive,WITHOUT_CLASSIFICATION,//  unit tests can overwrite this to affect default dump behaviour 
Hive,WITHOUT_CLASSIFICATION,//  lower case roleName 
Hive,WITHOUT_CLASSIFICATION,//  Set it on our inputformat 
Hive,WITHOUT_CLASSIFICATION,//  Column types 
Hive,WITHOUT_CLASSIFICATION,//  TODO: if a side of the union has 2 columns with the same name noone on the higher         level can refer to them. We could change the alias in the original node. 
Hive,WITHOUT_CLASSIFICATION,//  then we make sure the file sink operators are set up right 
Hive,WITHOUT_CLASSIFICATION,//  There is a kryo which after serialize/deserialize   Timestamp becomes Date. We get around this issue in   SearchArgumentImpl.getLiteral. Once kryo fixed the issue   We can simplify SearchArgumentImpl.getLiteral 
Hive,WITHOUT_CLASSIFICATION,// no insert schema was specified 
Hive,WITHOUT_CLASSIFICATION,//  Describe how to deserialize data back from user script 
Hive,WITHOUT_CLASSIFICATION,/*    * Sets the job state and result. Returns true if status and result are set.   * Otherwise it returns false.    */
Hive,WITHOUT_CLASSIFICATION,//  Table existed and is okay to replicate into not dropping and re-creating. 
Hive,WITHOUT_CLASSIFICATION,//  LOCATION_URI 
Hive,WITHOUT_CLASSIFICATION,//  at most one alias is unknown. we can safely regard it as a big alias 
Hive,WITHOUT_CLASSIFICATION,//  this GenericUDF can't be pushed down 
Hive,WITHOUT_CLASSIFICATION,//  only first stripe will satisfy condition and hence single split 
Hive,WITHOUT_CLASSIFICATION,//  Used for value registry 
Hive,WITHOUT_CLASSIFICATION,//  view is referring to old database so no data 
Hive,WITHOUT_CLASSIFICATION,//  For each table reference get the table name   and the alias (if alias is not present the table name 
Hive,WITHOUT_CLASSIFICATION,//  hive so this is a no-op 
Hive,WITHOUT_CLASSIFICATION,//  Generate the service ticket for sending to the server.   Locking ensures the tokens are unique in case of concurrent requests 
Hive,WITHOUT_CLASSIFICATION,//  Make data consistent with encodings don't store useless information. 
Hive,WITHOUT_CLASSIFICATION,//  merges sampling data from previous MR and make partition keys for total sort 
Hive,WITHOUT_CLASSIFICATION,//  Resend existing value if necessary. 
Hive,WITHOUT_CLASSIFICATION,//  only the admin is allowed to list privileges for any user 
Hive,WITHOUT_CLASSIFICATION,/*          * Nothing to do. Just retry.          */
Hive,WITHOUT_CLASSIFICATION,//  create a Map to capture object privileges corresponding to privilege 
Hive,WITHOUT_CLASSIFICATION,//  The getPrimitiveWritableObject method returns a new writable. 
Hive,WITHOUT_CLASSIFICATION,// include same hl_last_heartbeat condition in case someone heartbeated since the select 
Hive,WITHOUT_CLASSIFICATION,//  there can be multiple instances per node 
Hive,WITHOUT_CLASSIFICATION,//       int pos = context.currentMergeJoinOperator.getTagForOperator(parentOp); 
Hive,WITHOUT_CLASSIFICATION,// check to make sure there are no duplicate ROW__IDs - HIVE-16832 
Hive,WITHOUT_CLASSIFICATION,//  If oldReplState is less-than newReplState allow. 
Hive,WITHOUT_CLASSIFICATION,//  Fixup numbers to limit the range to 0 ... N-1. 
Hive,WITHOUT_CLASSIFICATION,// the first group. 
Hive,WITHOUT_CLASSIFICATION,//  check to see if this an input job or an outputjob 
Hive,WITHOUT_CLASSIFICATION,//  serialize the configuration once .. 
Hive,WITHOUT_CLASSIFICATION,//  Change correlator rel into a join.   Join all the correlated variables produced by this correlator rel 
Hive,WITHOUT_CLASSIFICATION,//  If this is a secured cookie and the current connection is non-secured   then skip this cookie. We need to skip this cookie because the cookie   replay will not be transmitted to the server. 
Hive,WITHOUT_CLASSIFICATION,//  Avro requires NULLable types to be defined as unions of some type T   and NULL.  This is annoying and we're going to hide it from the user. 
Hive,WITHOUT_CLASSIFICATION,//  Drop partition after dump 
Hive,WITHOUT_CLASSIFICATION,//  the max is good the min is too low 
Hive,WITHOUT_CLASSIFICATION,//  list the loggers and their levels 
Hive,WITHOUT_CLASSIFICATION,//  Then create splits with the Druid queries. 
Hive,WITHOUT_CLASSIFICATION,//  sort will try to open the output file in write mode on windows. We need to   close it first. 
Hive,WITHOUT_CLASSIFICATION,//  detect correlations 
Hive,WITHOUT_CLASSIFICATION,//  Now we check if the partition already exists. If not we go ahead.   If so we error out if immutable and if mutable check that the partition's IF   matches our current job's IF (table's IF) to check for compatibility. If compatible we   ignore and do not add. If incompatible we error out again. 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise try default timestamp parsing 
Hive,WITHOUT_CLASSIFICATION,//  ROW__ID: struct<transactionid:bigintbucketid:introwid:bigint> 
Hive,WITHOUT_CLASSIFICATION,//  Try to reduce 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) TypeMap  */
Hive,WITHOUT_CLASSIFICATION,//  The structure of the AST for the rewritten insert statement is:   TOK_QUERY -> TOK_FROM            \-> TOK_INSERT -> TOK_INSERT_INTO                          \-> TOK_SELECT                          \-> TOK_SORTBY   The following adds the TOK_WHERE and its subtree from the original query as a child of   TOK_INSERT which is where it would have landed if it had been there originally in the   string.  We do it this way because it's easy then turning the original AST back into a   string and reparsing it.  We have to move the SORT_BY over one   so grab it and then push it to the second slot and put the where in the first slot 
Hive,WITHOUT_CLASSIFICATION,//  Determine if the user would need to sign fragments. 
Hive,WITHOUT_CLASSIFICATION,//  Write a couple of batches 
Hive,WITHOUT_CLASSIFICATION,/* this constant is a bit of a misnomer since we now always have a txn context.  It                   just means the operation is such that we don't care what tables/partitions it                   affected as it doesn't trigger a compaction or conflict detection.  A better name                   would be NON_TRANSACTIONAL. */
Hive,WITHOUT_CLASSIFICATION,//  DATA 
Hive,WITHOUT_CLASSIFICATION,//  an integer. 
Hive,WITHOUT_CLASSIFICATION,// GenericUDFToUnixTimeStamp 
Hive,WITHOUT_CLASSIFICATION,/*  not supported  */
Hive,WITHOUT_CLASSIFICATION,// "unknown"; // No information to judge. 
Hive,WITHOUT_CLASSIFICATION,//  5.2. Finally hand off to the stripe reader to produce the data. 
Hive,WITHOUT_CLASSIFICATION,//  4. We check if it is a permutation project. If it is 
Hive,WITHOUT_CLASSIFICATION,//  heartbeat started.. 
Hive,WITHOUT_CLASSIFICATION,//  there could be case where join operators input are not RS e.g.   map join with Spark. Since following estimation of statistics relies on join operators having it inputs as   reduced sink it will not work for such cases. So we should not try to estimate stats 
Hive,WITHOUT_CLASSIFICATION,//  Pattern does not contain all date fields 
Hive,WITHOUT_CLASSIFICATION,//  (partition to bucket file names) and (partition to bucket number) for 
Hive,WITHOUT_CLASSIFICATION,//  Verify if Drop table on a non-existing table is idempotent 
Hive,WITHOUT_CLASSIFICATION,//  Explaining this would really require a picture. Basically if the level is lower than   our level that means (imagine a tree) we are on the leftmost leaf node of the sub-tree   under our sibling in the tree. So we'd need to look at the buddies of that leftmost leaf   block on all the intermediate levels (aka all intermediate levels of the tree between   this guy and our sibling). Including its own buddy on its own level. And so on for every   sub-tree where our buddy is not on the same level as us (i.e. does not cover the entire 
Hive,WITHOUT_CLASSIFICATION,//  incorrect use of this class 
Hive,WITHOUT_CLASSIFICATION,//  Write schema since we need it to pull the data out. (see point #1 above) 
Hive,WITHOUT_CLASSIFICATION,/*     even for regular copy we have to use the same user permissions that distCp will use since    hive-server user might be different that the super user required to copy relevant files.    */
Hive,WITHOUT_CLASSIFICATION,//  Only release cache chunks; do not release ProcCacheChunks - they may not yet have data. 
Hive,WITHOUT_CLASSIFICATION,//  the indexes of the delimiters 
Hive,WITHOUT_CLASSIFICATION,//  After load shall see the overwritten data. 
Hive,WITHOUT_CLASSIFICATION,// DataConstraintViolationError is expected 
Hive,WITHOUT_CLASSIFICATION,// statementId = 0 
Hive,WITHOUT_CLASSIFICATION,//  process join values 
Hive,WITHOUT_CLASSIFICATION,// template <ClassName> <ValueType> <OutputType> <OutputTypeInspector> 
Hive,WITHOUT_CLASSIFICATION,//  Create ReduceSinkOp operator 
Hive,WITHOUT_CLASSIFICATION,//  populate local work if needed 
Hive,WITHOUT_CLASSIFICATION,//  create fetchwork for partitioned table 
Hive,WITHOUT_CLASSIFICATION,//  Turn on client-side authorization 
Hive,WITHOUT_CLASSIFICATION,// this is the IOW case 
Hive,WITHOUT_CLASSIFICATION,//  The synchronization here is not necessary but tests depend on it. 
Hive,WITHOUT_CLASSIFICATION,//  Since there's no close() here maintain the initial read position between writes. 
Hive,WITHOUT_CLASSIFICATION,//  fields in these aggregation classes. 
Hive,WITHOUT_CLASSIFICATION,//  No actual result directory no need to move anything. 
Hive,WITHOUT_CLASSIFICATION,//  No conversion is possible for the reduce keys 
Hive,WITHOUT_CLASSIFICATION,//  bugbug need to deal with a named type here - i.e. look it up and proxy   to it   should raise an exception if this is a typedef since won't be any   children   and thus we can quickly find this comment and limitation. 
Hive,WITHOUT_CLASSIFICATION,//  DO_GET_FOOTERS 
Hive,WITHOUT_CLASSIFICATION,//  if the same day of the month then time part should be ignored 
Hive,WITHOUT_CLASSIFICATION,//  With nulls and selected 
Hive,WITHOUT_CLASSIFICATION,//  we need to clone some operator plans and remove union operators still 
Hive,WITHOUT_CLASSIFICATION,//  != 
Hive,WITHOUT_CLASSIFICATION,// If coming from big-table side do some book-keeping and continue traversal 
Hive,WITHOUT_CLASSIFICATION,//  about filtering. 
Hive,WITHOUT_CLASSIFICATION,//  must have at most one child 
Hive,WITHOUT_CLASSIFICATION,//  Calculate result TypeInfo 
Hive,WITHOUT_CLASSIFICATION,//  Print since otherwise exception is lost. 
Hive,WITHOUT_CLASSIFICATION,/*  Update summary bitVector :     * Generate hash value of the long value and mod it by 2^bitVectorSize-1.     * In this implementation bitVectorSize is 31.      */
Hive,WITHOUT_CLASSIFICATION,// (hl_txnid <> 0 AND hl_lock_state = '" + LOCK_WAITING + "') is for multi-statement txns where 
Hive,WITHOUT_CLASSIFICATION,// use get() to make sure variable substitution works 
Hive,WITHOUT_CLASSIFICATION,//  Meanwhile the init fails. 
Hive,WITHOUT_CLASSIFICATION,//  We do not need to do a column reset since we are carefully changing the output. 
Hive,WITHOUT_CLASSIFICATION,//  verify that ptned table property set worked 
Hive,WITHOUT_CLASSIFICATION,// this is a tmp table and thus Session scoped and acid requires SQL statement to be serial in a 
Hive,WITHOUT_CLASSIFICATION,/*      * When there is no Order specified we add the Partition expressions as     * Order expressions. This is an implementation artifact. For UDAFS that     * imply order (like rank dense_rank) depend on the Order Expressions to     * work. Internally we pass the Order Expressions as Args to these functions.     * We could change the translation so that the Functions are setup with     * Partition expressions when the OrderSpec is null; but for now we are setting up     * an OrderSpec that copies the Partition expressions.      */
Hive,WITHOUT_CLASSIFICATION,//  implicit type conversion hierarchy 
Hive,WITHOUT_CLASSIFICATION,// The data type primitive category of the column being deserialized. 
Hive,WITHOUT_CLASSIFICATION,//  We need to include isInsideView inside digest to differentiate direct 
Hive,WITHOUT_CLASSIFICATION,//  we will clone here as RS will update bucket column key with its 
Hive,WITHOUT_CLASSIFICATION,//  actually create the permanent function 
Hive,WITHOUT_CLASSIFICATION,/*  Default list bucketing directory key. internal use only not for client.  */
Hive,WITHOUT_CLASSIFICATION,//  For queue size estimation purposes we assume all columns have weight one and the following   types are counted as multiple columns. This is very primitive; if we wanted to make it better 
Hive,WITHOUT_CLASSIFICATION,//  As we're calling processOp again to process the leftover "tuples" we know the "row" is   coming from the spilled matchfile. We need to recreate hashMapRowGetter against new hashtables 
Hive,WITHOUT_CLASSIFICATION,//  Set the fetch formatter to be a no-op for the ListSinkOperator since we'll   read formatted thrift objects from the output SequenceFile written by Tasks. 
Hive,WITHOUT_CLASSIFICATION,//  Introduce a select after the union 
Hive,WITHOUT_CLASSIFICATION,//  From java.sql.Timestamp used by vectorization to serializable org.apache.hadoop.hive.common.type.Timestamp 
Hive,WITHOUT_CLASSIFICATION,/*  maxComplexDepth  */
Hive,WITHOUT_CLASSIFICATION,//  local aliases need not to hand over context further 
Hive,WITHOUT_CLASSIFICATION,//  Add the filter to the queryId appender 
Hive,WITHOUT_CLASSIFICATION,//  mapjoin table descriptor contains a key descriptor which needs the field schema   (column type + column name). The column name is not really used anywhere but it   needs to be passed. Use the string defined below for that. 
Hive,WITHOUT_CLASSIFICATION,// set up props for read 
Hive,WITHOUT_CLASSIFICATION,// read friendly string: [STX]ak[EXT]av[STX]bk[ETX]bv[STX]ck[ETX]cv[STX]dk[ETX]dv 
Hive,WITHOUT_CLASSIFICATION,//  repeat 20 times 
Hive,WITHOUT_CLASSIFICATION,//  One each for min max and bloom filter 
Hive,WITHOUT_CLASSIFICATION,//  Make sure the UGI is current. 
Hive,WITHOUT_CLASSIFICATION,//  Reached the end of the tag 
Hive,WITHOUT_CLASSIFICATION,//  create view 
Hive,WITHOUT_CLASSIFICATION,/*        * if there is a remainder from numRows/numBuckets; then distribute increase the size of the first 'rem' buckets by 1.        */
Hive,WITHOUT_CLASSIFICATION,//  we need to convert the thrift type to the SQL type 
Hive,WITHOUT_CLASSIFICATION,//  used to handle skew join 
Hive,WITHOUT_CLASSIFICATION,//  push down projections 
Hive,WITHOUT_CLASSIFICATION,//  Custom parameters 
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.SourceStateUpdatedResponseProto.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,//  check if 730517 Julian Days between Jan 1 0005 and Jan 31 2005.   This method used to test Julian Days between Jan 1 2005 BCE and Jan 1 2005 CE. Since BCE 
Hive,WITHOUT_CLASSIFICATION,//  Start monitoring the Spark job returns when the Spark job has completed / failed or if 
Hive,WITHOUT_CLASSIFICATION,//  COUNT DENSE_RANK and RANK do not care about column types.  The rest do. 
Hive,WITHOUT_CLASSIFICATION,//  failure from not having permissions to create table 
Hive,WITHOUT_CLASSIFICATION,//  Optimized for sequential key lookup. 
Hive,WITHOUT_CLASSIFICATION,//  No security or the path is below the user path - full access. 
Hive,WITHOUT_CLASSIFICATION,//  index into a map 
Hive,WITHOUT_CLASSIFICATION,//  MAX_ROWS 
Hive,WITHOUT_CLASSIFICATION,//  Detect queries of the form SELECT udtf(col) AS ...   by looking for a function as the first child and then checking to see   if the function is a Generic UDTF. It's not as clean as TRANSFORM due to 
Hive,WITHOUT_CLASSIFICATION,//  Convert from mapjoin to bucket map join if enabled. 
Hive,WITHOUT_CLASSIFICATION,//  Hive values we have copied and use as is 
Hive,WITHOUT_CLASSIFICATION,//  Test with multi-level scratch dir path 
Hive,WITHOUT_CLASSIFICATION,//  clear the columnBuffers 
Hive,WITHOUT_CLASSIFICATION,//  Make a cost based decision to pick cheaper plan 
Hive,WITHOUT_CLASSIFICATION,//  The dispatcher generates the plan from the operator tree 
Hive,WITHOUT_CLASSIFICATION,// keep track for error reporting 
Hive,WITHOUT_CLASSIFICATION,// Ignored for some reason the bean was not found so don't output it 
Hive,WITHOUT_CLASSIFICATION,//  Save the current record as the new extraValue for next time so that 
Hive,WITHOUT_CLASSIFICATION,//  Now add to cache 
Hive,WITHOUT_CLASSIFICATION,// todo: https://issues.apache.org/jira/browse/HIVE-15048 
Hive,WITHOUT_CLASSIFICATION,//  For each node 
Hive,WITHOUT_CLASSIFICATION,//  Make sure originalDate is at midnight in the local time zone   since DateWritableV2 will generate dates at that time. 
Hive,WITHOUT_CLASSIFICATION,//  Concurrency 
Hive,WITHOUT_CLASSIFICATION,//  generated the log message). 
Hive,WITHOUT_CLASSIFICATION,//  Index of the next free block to split. 
Hive,WITHOUT_CLASSIFICATION,//  Do any hive related operations like moving tables and files 
Hive,WITHOUT_CLASSIFICATION,//  A specification of binary storage should not affect ser/de. 
Hive,WITHOUT_CLASSIFICATION,//  In the automation the data warehouse is the local file system based. 
Hive,WITHOUT_CLASSIFICATION,//  create a mapred task for this work 
Hive,WITHOUT_CLASSIFICATION,// case 1: 01:01:01.0000000001 
Hive,WITHOUT_CLASSIFICATION,//  Current replication state must be set on the Table object only for bootstrap dump.   Event replication State will be null in case of bootstrap dump. 
Hive,WITHOUT_CLASSIFICATION,//  on tez we're avoiding to duplicate the file info in FileInputFormat. 
Hive,WITHOUT_CLASSIFICATION,//  SessionManager is initialized 
Hive,WITHOUT_CLASSIFICATION,//  The parameter keys for the table statistics. Those keys are excluded from 'show create table' command output. 
Hive,WITHOUT_CLASSIFICATION,//  the first position of partition column 
Hive,WITHOUT_CLASSIFICATION,//  Sort the methods before omitting them. 
Hive,WITHOUT_CLASSIFICATION,//  Inherit table properties into partition properties. 
Hive,WITHOUT_CLASSIFICATION,//  Target isNull was copied at beginning of method. 
Hive,WITHOUT_CLASSIFICATION,//  lastFrom point to the same Text object which would make from.equals(lastFrom) always true 
Hive,WITHOUT_CLASSIFICATION,//  Prev/next are already checked in the calls. 
Hive,WITHOUT_CLASSIFICATION,//  But soon became very fast decimal specific. 
Hive,WITHOUT_CLASSIFICATION,//  Last partition key - anything between /key= and end 
Hive,WITHOUT_CLASSIFICATION,//  inclusive   exclusive 
Hive,WITHOUT_CLASSIFICATION,//  Make a random array of byte arrays 
Hive,WITHOUT_CLASSIFICATION,//  This makes it so that we can go back up the tree later 
Hive,WITHOUT_CLASSIFICATION,//  tables. 
Hive,WITHOUT_CLASSIFICATION,//  SortBy DESC 
Hive,WITHOUT_CLASSIFICATION,//  Test replicated drop should not drop because evid < repl.state.id 
Hive,WITHOUT_CLASSIFICATION,//  We create the join predicate info object. The object contains the join condition   split accordingly. If the join condition is not part of the equi-join predicate   the returned object will be typed as SQLKind.OTHER. 
Hive,WITHOUT_CLASSIFICATION,//  Downloaded resources dir 
Hive,WITHOUT_CLASSIFICATION,//  updatable map that holds instances of the class 
Hive,WITHOUT_CLASSIFICATION,//  First update buffer priority - we have just been using it. 
Hive,WITHOUT_CLASSIFICATION,// ************************************************************************************************   Emulate BigInteger serialization used by LazyBinary Avro Parquet and possibly others. 
Hive,WITHOUT_CLASSIFICATION,//  Reload tables from the MetaStore 
Hive,WITHOUT_CLASSIFICATION,// set arguments 
Hive,WITHOUT_CLASSIFICATION,//  don't want cache hits from llap io for testing filesystem bytes read counters 
Hive,WITHOUT_CLASSIFICATION,//  source: LlapDaemonProtocol.proto 
Hive,WITHOUT_CLASSIFICATION,//  Since TxnUtils.getTxnStore calls TxnHandler.setConf -> checkQFileTestHack -> TxnDbUtil.setConfValues   which may change the values of below two entries we need to avoid polluting the original values 
Hive,WITHOUT_CLASSIFICATION,//  Empty constructor for writable etc. 
Hive,WITHOUT_CLASSIFICATION,//  Throw away lower digits. 
Hive,WITHOUT_CLASSIFICATION,//  mask UDFs 
Hive,WITHOUT_CLASSIFICATION,//  10. If there was a cluster state change make sure we redistribute all the pools. 
Hive,WITHOUT_CLASSIFICATION,//  prepare 
Hive,WITHOUT_CLASSIFICATION,//  MY_STRINGLIST 
Hive,WITHOUT_CLASSIFICATION,//  create default users 
Hive,WITHOUT_CLASSIFICATION,//  Notify if we have successfully copied the file. 
Hive,WITHOUT_CLASSIFICATION,//  Set handling for low resource conditions. 
Hive,WITHOUT_CLASSIFICATION,//  caller should not try to allocate another arena before waiting for the previous one. 
Hive,WITHOUT_CLASSIFICATION,//  If this operator has a materialized view below   we make its cost tiny and adjust the cost of its 
Hive,WITHOUT_CLASSIFICATION,//  our stats for NDV is approx not accurate. 
Hive,WITHOUT_CLASSIFICATION,//  required   optional   required 
Hive,WITHOUT_CLASSIFICATION,//  RUN_AS 
Hive,WITHOUT_CLASSIFICATION,//  This method takes care of bit-flipping for descending order 
Hive,WITHOUT_CLASSIFICATION,/*    * skip mode should not throw exception when a invalid partition directory   * is found. It should just ignore it    */
Hive,WITHOUT_CLASSIFICATION,//  non-partitioned table 
Hive,WITHOUT_CLASSIFICATION,//  We don't add this to the resources because we don't want to read config values from it.   But we do find it because we want to remember where it is for later in case anyone calls 
Hive,WITHOUT_CLASSIFICATION,//  Ignore the value we got from OpTraits.   The logic below will fall back to the estimate from numReducers 
Hive,WITHOUT_CLASSIFICATION,//  the directory does not exist 
Hive,WITHOUT_CLASSIFICATION,//  --listHAPeers 
Hive,WITHOUT_CLASSIFICATION,//  hive jar 
Hive,WITHOUT_CLASSIFICATION,//  Cleanup session log directory. 
Hive,WITHOUT_CLASSIFICATION,//  PRE - all the fields are required and serialized in order - is   !isRealThrift 
Hive,WITHOUT_CLASSIFICATION,//  Note: the stats for ACID tables do not have any coordination with either Hive ACID logic         like txn commits time outs etc.; nor the lower level sync in metastore pertaining         to ACID updates. So the are not themselves ACID. 
Hive,WITHOUT_CLASSIFICATION,//  First partition key - anything between key= and first / 
Hive,WITHOUT_CLASSIFICATION,//  optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  Step 4 : Reanalyze 
Hive,WITHOUT_CLASSIFICATION,//  do not understand why it is needed and wonder if it could be combined with close. 
Hive,WITHOUT_CLASSIFICATION,//  found a file at depth which is less than number of partition keys 
Hive,WITHOUT_CLASSIFICATION,//  Preemption will finally be registered as a deallocateTask as a result of preemptContainer   That resets preemption info and allows additional tasks to be pre-empted if required. 
Hive,WITHOUT_CLASSIFICATION,//  ALTER TABLE table_name DROP [IF EXISTS] PARTITION partition_spec PARTITION partition_spec...; 
Hive,WITHOUT_CLASSIFICATION,//  existing n-gram just increment count 
Hive,WITHOUT_CLASSIFICATION,// the idea is that this will use LockHandle.dbConn 
Hive,WITHOUT_CLASSIFICATION,//  Find out if we need to throw away the tuple or not. 
Hive,WITHOUT_CLASSIFICATION,//  Copy current value; do not change current scale. 
Hive,WITHOUT_CLASSIFICATION,//  optional .FragmentRuntimeInfo fragment_runtime_info = 9; 
Hive,WITHOUT_CLASSIFICATION,//  we have a storage specification for a primitive column type 
Hive,WITHOUT_CLASSIFICATION,//     } 
Hive,WITHOUT_CLASSIFICATION,//  No-Op - we don't really write anything here .. 
Hive,WITHOUT_CLASSIFICATION,//  There's a race between removing the current task from the preemption queue and the actual scheduler   attempting to take an element from the preemption queue to make space for another task.   If the current element is removed to make space - that is OK since the current task is completing and   will end up making space for execution. Any kill message sent out by the scheduler to the task will   be ignored since the task knows it has completed (otherwise it would not be in this callback).     If the task is removed from the queue as a result of this callback and the scheduler happens to   be in the section where it's looking for a preemptible task - the scheuler may end up pulling the   next pre-emptible task and killing it (an extra preemption).   TODO: This potential extra preemption can be avoided by synchronizing the entire tryScheduling block.\   This would essentially synchronize all operations - it would be better to see if there's an   approach where multiple locks could be used to avoid single threaded operation.   - It checks available and preempts (which could be this task)   - Or this task completes making space and removing the need for preemption 
Hive,WITHOUT_CLASSIFICATION,//  if we find it. 
Hive,WITHOUT_CLASSIFICATION,//  copy set of deduped locks back to original list 
Hive,WITHOUT_CLASSIFICATION,//  None are null so all are selected 
Hive,WITHOUT_CLASSIFICATION,//  The number of stripes should match the key index count 
Hive,WITHOUT_CLASSIFICATION,//  Special handling for timestamp column   field name   field type 
Hive,WITHOUT_CLASSIFICATION,//  after the first child is evaluated. 
Hive,WITHOUT_CLASSIFICATION,//  This is a non-native table.   We need to set stats as inaccurate. 
Hive,WITHOUT_CLASSIFICATION,//  Thrift configs 
Hive,WITHOUT_CLASSIFICATION,//  Add 5 partitions to all tables 
Hive,WITHOUT_CLASSIFICATION,// here means no open transaction but different queries 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) Typei64  */
Hive,WITHOUT_CLASSIFICATION,//  SERDE 
Hive,WITHOUT_CLASSIFICATION,//  Create a dummy TableScanOperator for the file generated through fileSinkOp 
Hive,WITHOUT_CLASSIFICATION,// re-check locks which were in Waiting state - should now be Acquired 
Hive,WITHOUT_CLASSIFICATION,//  Create views registry 
Hive,WITHOUT_CLASSIFICATION,//  The plan needs to be broken only if one of the sub-queries involve a 
Hive,WITHOUT_CLASSIFICATION,//  assertEquals(1 << 18 map.getCapacity()); 
Hive,WITHOUT_CLASSIFICATION,// If there is no group of a file no need to call chgrp 
Hive,WITHOUT_CLASSIFICATION,//  not used for mock but 
Hive,WITHOUT_CLASSIFICATION,// Buffers to hold filter pushdown information 
Hive,WITHOUT_CLASSIFICATION,//  either colstats is null or is estimated 
Hive,WITHOUT_CLASSIFICATION,//  Check if a bigint is implicitely cast to a double as part of a comparison   Perform the check here instead of in GenericUDFBaseCompare to guarantee it is only run once per operator 
Hive,WITHOUT_CLASSIFICATION,//  db1.testtable3.p should also be in COLUMNS will fix in separate ticket 
Hive,WITHOUT_CLASSIFICATION,//                    1.23456789012345678901234567890123456789012345 
Hive,WITHOUT_CLASSIFICATION,//  exact match 
Hive,WITHOUT_CLASSIFICATION,// so now we have written some new data to bkt=0 and it shows up 
Hive,WITHOUT_CLASSIFICATION,// so generate empty Dyn Part call 
Hive,WITHOUT_CLASSIFICATION,//  short-circuit quickly - forward all rows 
Hive,WITHOUT_CLASSIFICATION,// tableHandle can be null if table doesn't exist 
Hive,WITHOUT_CLASSIFICATION,/* this captures mapping of Hive type names to HCat type names; in the long run    * we should just use Hive types directly but that is a larger refactoring effort    * For HCat->Pig mapping see PigHCatUtil.getPigType(Type)    * For Pig->HCat mapping see HCatBaseStorer#validateSchema(...) */
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setRef(int java.sql.Ref)    */
Hive,WITHOUT_CLASSIFICATION,//  nanosecond interval in 2 primitives) produces a type timestamp (TimestampColumnVector). 
Hive,WITHOUT_CLASSIFICATION,/*  every line below this is identical for evaluateLong & evaluateString  */
Hive,WITHOUT_CLASSIFICATION,//  Calite bug CALCITE-987 
Hive,WITHOUT_CLASSIFICATION,/*  Let's write more bytes to the files to test that ContentSummaryInputFormat is actually working returning the file size not from the filesystem  */
Hive,WITHOUT_CLASSIFICATION,//  Round to the specified number of decimal places using half-even round function. 
Hive,WITHOUT_CLASSIFICATION,//  add backup task to runnable 
Hive,WITHOUT_CLASSIFICATION,//  more than 1 thread should call this close() function. 
Hive,WITHOUT_CLASSIFICATION,/*    * Use this constructor when only ascending sort order is used.   * By default for ascending order NULL first.    */
Hive,WITHOUT_CLASSIFICATION,//  I don't think event notifications in case of failures are necessary but other HMS operations   make this call whether the event failed or succeeded. To make this behavior consistent   this call is made for failed events also. 
Hive,WITHOUT_CLASSIFICATION,//  Add a new column 
Hive,WITHOUT_CLASSIFICATION,//  jline will detect if <tab> is regular character 
Hive,WITHOUT_CLASSIFICATION,/*      * Restriction.14.h :: Correlated Sub Queries cannot contain Windowing clauses.      */
Hive,WITHOUT_CLASSIFICATION,//  check if static partition appear after dynamic partitions 
Hive,WITHOUT_CLASSIFICATION,//  Same as hash64's default seed. 
Hive,WITHOUT_CLASSIFICATION,//  the jsonObject for this vertex 
Hive,WITHOUT_CLASSIFICATION,//  2.1 The ndv is the minimum of the PK and the FK. 
Hive,WITHOUT_CLASSIFICATION,/*  * Specialized class for doing a vectorized map join that is an left semi join on a Single-Column Long * using a hash set.  */
Hive,WITHOUT_CLASSIFICATION,//  LOG.debug("VectorMapJoinFastLongHashTable findReadSlot key " + key + " slot " + slot + " pairIndex " + pairIndex + " found key (i = " + i + ")"); 
Hive,WITHOUT_CLASSIFICATION,//  3. Virtual columns 
Hive,WITHOUT_CLASSIFICATION,//  Fake two live session 
Hive,WITHOUT_CLASSIFICATION,//  For each range we have intersect them. If they don't overlap   the range can be discarded 
Hive,WITHOUT_CLASSIFICATION,//  and produce the correlated variables in the new output. 
Hive,WITHOUT_CLASSIFICATION,//  If a task contains an operator which instructs bucketizedhiveinputformat 
Hive,WITHOUT_CLASSIFICATION,//  4. Perform another major compaction. Nothing should change. Both deltas and  both base dirs   should have the same name. 
Hive,WITHOUT_CLASSIFICATION,// remove trailing  
Hive,WITHOUT_CLASSIFICATION,//  TODO: we should call this more often. In theory for DATE type time should never matter but 
Hive,WITHOUT_CLASSIFICATION,//       This is a sync call that will feed data to the consumer. 
Hive,WITHOUT_CLASSIFICATION,//  verify that no rows were selected 
Hive,WITHOUT_CLASSIFICATION,//  if this transaction isn't ok skip over it 
Hive,WITHOUT_CLASSIFICATION,//  Just check to make sure base_5 below is not new. 
Hive,WITHOUT_CLASSIFICATION,/*  1 files x 100 size for 111 splits  */
Hive,WITHOUT_CLASSIFICATION,//  TIME 
Hive,WITHOUT_CLASSIFICATION,//  MySQL returns 0 if the string is not a well-formed double value.   But we decided to return NULL instead which is more conservative. 
Hive,WITHOUT_CLASSIFICATION,// matches 2 rows  matches 2 rows 
Hive,WITHOUT_CLASSIFICATION,//  Timeout is chosen to make sure that even if one iteration takes more than   half of the script.timeout but less than script.timeout we will still 
Hive,WITHOUT_CLASSIFICATION,//  No update necessary. 
Hive,WITHOUT_CLASSIFICATION,//  We suspect that LIKE pushdown into JDO is invalid; see HIVE-5134. Check for like here. 
Hive,WITHOUT_CLASSIFICATION,//  empty set - cannot convert 
Hive,WITHOUT_CLASSIFICATION,//  If we're using TS's stats for mapjoin optimization check each branch and see if there's any   upstream operator (e.g. JOIN LATERAL_VIEW) that can increase output data size. 
Hive,WITHOUT_CLASSIFICATION,//  Each child should has its own outputObjInspector 
Hive,WITHOUT_CLASSIFICATION,//  Backtrack value columns of cRS to pRS 
Hive,WITHOUT_CLASSIFICATION,//  The instance 
Hive,WITHOUT_CLASSIFICATION,//  We need to get the ColumnAccessInfo and viewToTableSchema for views. 
Hive,WITHOUT_CLASSIFICATION,// remove the path with which no alias associates 
Hive,WITHOUT_CLASSIFICATION,//     sb.append((char) i);    } 
Hive,WITHOUT_CLASSIFICATION,//  recently evicted index (used for next key/value)   count of excluded rows from previous flush 
Hive,WITHOUT_CLASSIFICATION,//  Only columns present in the batch and non-complex types. 
Hive,WITHOUT_CLASSIFICATION,//  in the same line. 
Hive,WITHOUT_CLASSIFICATION,//  One byte is always available for writing. 
Hive,WITHOUT_CLASSIFICATION,//  internal name for expressions and estimate column statistics for expression. 
Hive,WITHOUT_CLASSIFICATION,//  only leader publishes instance uri as endpoint which will be used by clients to make connections to HS2 via   service discovery. 
Hive,WITHOUT_CLASSIFICATION,//  Transfer columnVector objects from base batch to outgoing batch. 
Hive,WITHOUT_CLASSIFICATION,//  Update the output position for the cor vars: only pass on the cor 
Hive,WITHOUT_CLASSIFICATION,//  make sure the vector was flattened 
Hive,WITHOUT_CLASSIFICATION,//  test second IF argument with nulls 
Hive,WITHOUT_CLASSIFICATION,//  Create metrics directory if it is not present 
Hive,WITHOUT_CLASSIFICATION,//  Stored as directories. We don't care about the skew otherwise. 
Hive,WITHOUT_CLASSIFICATION,//  Out of range for whole batch. 
Hive,WITHOUT_CLASSIFICATION,//  simple distribute-by goes here 
Hive,WITHOUT_CLASSIFICATION,//  Note: we may later have special logic to pick up old AMs if any. 
Hive,WITHOUT_CLASSIFICATION,// Get the job info from the configuration 
Hive,WITHOUT_CLASSIFICATION,//  Add the relevant database 'namespace' as a WriteEntity 
Hive,WITHOUT_CLASSIFICATION,//  Nothing so far. 
Hive,WITHOUT_CLASSIFICATION,//  context for current input file 
Hive,WITHOUT_CLASSIFICATION,//  STRUCT_ENTRY 
Hive,WITHOUT_CLASSIFICATION,//  No table information yet; looks like it could be valid. 
Hive,WITHOUT_CLASSIFICATION,//  e.getKey() (alias) can be null in case of constant expressions. see   input8.q 
Hive,WITHOUT_CLASSIFICATION,//  Check if input can be pruned 
Hive,WITHOUT_CLASSIFICATION,//  Operation not recognized set to null and let upper level handle this case 
Hive,WITHOUT_CLASSIFICATION,//  100000. 
Hive,WITHOUT_CLASSIFICATION,// then invalidate column stats 
Hive,WITHOUT_CLASSIFICATION,//  No need to get footers 
Hive,WITHOUT_CLASSIFICATION,/*  Test decimal scalar to decimal column addition. This is used to cover all the   * cases used in the source code template ScalarArithmeticColumnDecimal.txt.    */
Hive,WITHOUT_CLASSIFICATION,//  Regardless of our matching result we keep that information to make multiple use 
Hive,WITHOUT_CLASSIFICATION,//  if there are aggregate functions or grouping sets we will need   value generator 
Hive,WITHOUT_CLASSIFICATION,//  assumption is that environment has already been cleaned once globally   hence each thread does not call cleanUp() and createSources() again 
Hive,WITHOUT_CLASSIFICATION,//  Load the incremental dump and ensure it does nothing and lastReplID remains same 
Hive,WITHOUT_CLASSIFICATION,//  5. Perform another major compaction 
Hive,WITHOUT_CLASSIFICATION,/*  This list may be modified by specific cli drivers to mask strings that change on every test  */
Hive,WITHOUT_CLASSIFICATION,//  3. Generate input event. 
Hive,WITHOUT_CLASSIFICATION,//  There is some information about the windowing functions that needs to be initialized   during query compilation time and made available to during the map/reduce tasks via   plan serialization. 
Hive,WITHOUT_CLASSIFICATION,//  Copied here until a utility version of this released in ORC. 
Hive,WITHOUT_CLASSIFICATION,//  the +1 is for the main map operator itself 
Hive,WITHOUT_CLASSIFICATION,//  Continue to handle changes to a specific plan. 
Hive,WITHOUT_CLASSIFICATION,//  Boolean 
Hive,WITHOUT_CLASSIFICATION,//  Various unsupported methods. 
Hive,WITHOUT_CLASSIFICATION,//  When the reducer is encountered for the first time 
Hive,WITHOUT_CLASSIFICATION,//  done. For broadcast joins that includes the dummy parents. 
Hive,WITHOUT_CLASSIFICATION,//  Continue range.. 
Hive,WITHOUT_CLASSIFICATION,//  Storage Descriptor data 
Hive,WITHOUT_CLASSIFICATION,//  for JOIN-RS case it's not possible generally to merge if child has   less key/partition columns than parents 
Hive,WITHOUT_CLASSIFICATION,//  NoSuchObjectException gets swallowed by a TApplicationException in remote mode. 
Hive,WITHOUT_CLASSIFICATION,//  Need to update the queryPlan's output as well so that post-exec hook get executed.   This is only needed for dynamic partitioning since for SP the the WriteEntity is   constructed at compile time and the queryPlan already contains that.   For DP WriteEntity creation is deferred at this stage so we need to update 
Hive,WITHOUT_CLASSIFICATION,//  although its likely to be a valid exception we will retry   with cbo off anyway.   for tests we would like to avoid retrying to catch cbo failures 
Hive,WITHOUT_CLASSIFICATION,//  timestamp scalar/scalar 
Hive,WITHOUT_CLASSIFICATION,//  not forward compatible 
Hive,WITHOUT_CLASSIFICATION,//  Local mode outputcommitter hook is not invoked in Hadoop 1.x 
Hive,WITHOUT_CLASSIFICATION,//  setup mapJoinTables and serdes 
Hive,WITHOUT_CLASSIFICATION,//  The way this works is a session in WM pool will move back to tez AM pool on a kill and will get   reassigned back to WM pool on GetRequest based on user pool mapping. Only if we remove the session from active   sessions list of its WM pool will the queue'd GetRequest be processed 
Hive,WITHOUT_CLASSIFICATION,//  Get object cache 
Hive,WITHOUT_CLASSIFICATION,//  Make sure flow and double equality compare works 
Hive,WITHOUT_CLASSIFICATION,//  negative test 
Hive,WITHOUT_CLASSIFICATION,//  exprInfo is the key 
Hive,WITHOUT_CLASSIFICATION,//  It's ok to send a cancel to an already completed future. Is a no-op 
Hive,WITHOUT_CLASSIFICATION,//  Bail out: empty list 
Hive,WITHOUT_CLASSIFICATION,//  Most of the above will be failed offers and takes (due to speed of the thing). 
Hive,WITHOUT_CLASSIFICATION,//  there should be 1 call to create partitions with batch sizes of 10 
Hive,WITHOUT_CLASSIFICATION,//  Ignore changes in the amount of white space 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)      * @see org.apache.hadoop.mapreduce.RecordWriter#write(java.lang.Object java.lang.Object)       */
Hive,WITHOUT_CLASSIFICATION,//  NEW TAI LUE LETTER LOW FA U+199D (3 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  Loop to rewrite rest of INSERT references 
Hive,WITHOUT_CLASSIFICATION,//  The following steps seem roundabout but they are meant to aid in   recovery if a failure occurs and to keep a consistent state in the FS 
Hive,WITHOUT_CLASSIFICATION,//  if the value is repeating use row 0 
Hive,WITHOUT_CLASSIFICATION,//  match this configuration before merging else will not be merged 
Hive,WITHOUT_CLASSIFICATION,//  class ExpressionBuilder; 
Hive,WITHOUT_CLASSIFICATION,//  state == CLOSE doesn't mean all children are also in state CLOSE 
Hive,WITHOUT_CLASSIFICATION,/*  * * The vectorized MapOperator. * * There are 3 modes of reading for vectorization: * *   1) One for the Vectorized Input File Format which returns VectorizedRowBatch as the row. * *   2) One for using VectorDeserializeRow to deserialize each row into the VectorizedRowBatch. *      Currently these Input File Formats: *        TEXTFILE *        SEQUENCEFILE * *   3) And one using the regular partition deserializer to get the row object and assigning *      the row object into the VectorizedRowBatch with VectorAssignRow. *      This picks up Input File Format not supported by the other two.  */
Hive,WITHOUT_CLASSIFICATION,//  Probably not a local filesystem; no need to check. 
Hive,WITHOUT_CLASSIFICATION,//  enable trash so it can be tested   FS_TRASH_CHECKPOINT_INTERVAL_KEY (hadoop-2)   FS_TRASH_INTERVAL_KEY (hadoop-2) 
Hive,WITHOUT_CLASSIFICATION,//  Case 1. Fail the reader sending back the error we received from the reader event. 
Hive,WITHOUT_CLASSIFICATION,//  Create the Jetty server. If jetty conf file exists use that to create server 
Hive,WITHOUT_CLASSIFICATION,//  A stripped down version of fastSetFromBytes. 
Hive,WITHOUT_CLASSIFICATION,//  This hook verifies that the location of every output table is empty 
Hive,WITHOUT_CLASSIFICATION,//  1/ test LazyBinarySerDe 
Hive,WITHOUT_CLASSIFICATION,//  to the select list. 
Hive,WITHOUT_CLASSIFICATION,// just rename the directory 
Hive,WITHOUT_CLASSIFICATION,/*  * If a join has been automatically converted into a sort-merge join create a conditional * task to try map-side join with each table as the big table. It is similar to * hive.auto.convert.join but is only applicable to joins which have been automatically * converted to sort-merge joins. For hive.auto.convert.join the backup task is the * map-reduce join whereas here the backup task is the sort-merge join. * * Depending on the inputs a sort-merge join may be faster or slower than the map-side join. * The other advantage of sort-merge join is that the output is also bucketed and sorted. * Consider a very big table say 1TB with 10 buckets being joined with a very small table say * 10MB with 10 buckets the sort-merge join may perform slower since it will be restricted to * 10 mappers.  */
Hive,WITHOUT_CLASSIFICATION,/*    * for now a top level QB can have 1 where clause SQ predicate.    */
Hive,WITHOUT_CLASSIFICATION,//  use this buffer to hold column's cells value length for usages in 
Hive,WITHOUT_CLASSIFICATION,//  End HiveProjectOverIntersectRemoveRule.java 
Hive,WITHOUT_CLASSIFICATION,//  we ensure that we don't try to read any data in case of skip read. 
Hive,WITHOUT_CLASSIFICATION,//  so it doesn't matter if we wait for all inputs or any input to be ready. 
Hive,WITHOUT_CLASSIFICATION,// this is the root of the partition in which the 'file' is located 
Hive,WITHOUT_CLASSIFICATION,//  Make sure the signature works. 
Hive,WITHOUT_CLASSIFICATION,/*  * Root abstract class for a hash table result.  */
Hive,WITHOUT_CLASSIFICATION,//  Verify dropTable recycle table files 
Hive,WITHOUT_CLASSIFICATION,//  We are going to use LBSerDe to serialize values; create OI for retrieval. 
Hive,WITHOUT_CLASSIFICATION,//  Couldn't find the from that contains subquery; replace with ALLCOLREF. 
Hive,WITHOUT_CLASSIFICATION,//  ETL strategy requested through config 
Hive,WITHOUT_CLASSIFICATION,//  hmm..this looks a bit wierd...setup boots qtestutil...this part used to be in beforeclass 
Hive,WITHOUT_CLASSIFICATION,// create RexNode for LHS 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#getWarnings()    */
Hive,WITHOUT_CLASSIFICATION,// this part of reduceKeys is later used to create column names strictly for non-distinct aggregates   with parameters same as distinct keys which expects _col0 at the end. So we always append   _col0 at the end instead of _col<i> 
Hive,WITHOUT_CLASSIFICATION,//  LOG.debug("VectorMapJoinFastTableContainer load newThreshold " + newThreshold); 
Hive,WITHOUT_CLASSIFICATION,//  Allocator uses memory manager to request memory so create the manager next. 
Hive,WITHOUT_CLASSIFICATION,//  Reset ckpt and last repl ID keys to empty set for allowing bootstrap load 
Hive,WITHOUT_CLASSIFICATION,// baseReader.getRowNumber() seems to point at the start of the batch todo: validate 
Hive,WITHOUT_CLASSIFICATION,//  check reset operation: 
Hive,WITHOUT_CLASSIFICATION,//  set vector[0] to null object reference to verify correct null handling 
Hive,WITHOUT_CLASSIFICATION,//  Join types should be all the same for merging (or returns null) 
Hive,WITHOUT_CLASSIFICATION,//  08S01 (Communication error) is the default sql state.  Override the sqlstate 
Hive,WITHOUT_CLASSIFICATION,//  format the upgrade script name eg upgrade-x-y-dbType.sql 
Hive,WITHOUT_CLASSIFICATION,//  but if the value is rounded by more scaling 
Hive,WITHOUT_CLASSIFICATION,//  We format it so we are sure we are getting the right value 
Hive,WITHOUT_CLASSIFICATION,/*    * Return all the known job ids for this user based on the optional filter conditions.   * <p>   * Example usages:   * 1. curl -s 'http://localhost:50111/templeton/v1/jobs?user.name=hsubramaniyan'   * Return all the Job IDs submitted by hsubramaniyan   * 2. curl -s   * 'http://localhost:50111/templeton/v1/jobs?user.name=hsubramaniyan%26showall=true'   * Return all the Job IDs that are visible to hsubramaniyan   * 3. curl -s   * 'http://localhost:50111/templeton/v1/jobs?user.name=hsubramaniyan%26jobid=job_201312091733_0003'   * Return all the Job IDs for hsubramaniyan after job_201312091733_0003.   * 4. curl -s 'http://localhost:50111/templeton/v1/jobs?   * user.name=hsubramaniyan%26jobid=job_201312091733_0003%26numrecords=5'   * Return the first 5(atmost) Job IDs submitted by hsubramaniyan after job_201312091733_0003.   * 5.  curl -s   * 'http://localhost:50111/templeton/v1/jobs?user.name=hsubramaniyan%26numrecords=5'   * Return the first 5(atmost) Job IDs submitted by hsubramaniyan after sorting the Job ID list   * lexicographically.   * </p>   * <p>   * Supporting pagination using "jobid" and "numrecords" parameters:   * Step 1: Get the start "jobid" = job_xxx_000 "numrecords" = n   * Step 2: Issue a curl command by specifying the user-defined "numrecords" and "jobid"   * Step 3: If list obtained from Step 2 has size equal to "numrecords" retrieve the list's   * last record and get the Job Id of the last record as job_yyy_k else quit.   * Step 4: set "jobid"=job_yyy_k and go to step 2.   * </p>   * @param fields If "fields" set to "*" the request will return full details of the job.   * If "fields" is missing will only return the job ID. Currently the value can only   * be "*" other values are not allowed and will throw exception.   * @param showall If "showall" is set to "true" the request will return all jobs the user   * has permission to view not only the jobs belonging to the user.   * @param jobid If "jobid" is present the records whose Job Id is lexicographically greater   * than "jobid" are only returned. For example if "jobid" = "job_201312091733_0001"   * the jobs whose Job ID is greater than "job_201312091733_0001" are returned. The number of   * records returned depends on the value of "numrecords".   * @param numrecords If the "jobid" and "numrecords" parameters are present the top #numrecords   * records appearing after "jobid" will be returned after sorting the Job Id list   * lexicographically.   * If "jobid" parameter is missing and "numrecords" is present the top #numrecords will   * be returned after lexicographically sorting the Job Id list. If "jobid" parameter is present   * and "numrecords" is missing all the records whose Job Id is greater than "jobid" are returned.   * @return list of job items based on the filter conditions specified by the user.    */
Hive,WITHOUT_CLASSIFICATION,//  get delegation tokens from hcat server and store them into the "job"   These will be used in to publish partitions to   hcat normally in OutputCommitter.commitJob()   when the JobTracker in Hadoop MapReduce starts supporting renewal of 
Hive,WITHOUT_CLASSIFICATION,//  Use the hints later in top level QB. 
Hive,WITHOUT_CLASSIFICATION,//  Combine the column field schemas and the partition keys to create the   whole schema 
Hive,WITHOUT_CLASSIFICATION,//  If this set is not empty it means we need to generate a separate task for collecting 
Hive,WITHOUT_CLASSIFICATION,// need merge isDirect flag to input even if the newInput does not have a parent 
Hive,WITHOUT_CLASSIFICATION,//  by supplying using "o" this enforces identity/equls matching   which will most probably make the signature very unique 
Hive,WITHOUT_CLASSIFICATION,//  The id of the JobHandle used to track the actual Spark job 
Hive,WITHOUT_CLASSIFICATION,//  the lack of a special token. 
Hive,WITHOUT_CLASSIFICATION,/*  Number of digits in mantissa.  */
Hive,WITHOUT_CLASSIFICATION,//  Max time when waiting for read locks on node list 
Hive,WITHOUT_CLASSIFICATION,//  All fractional digits become integer digits. 
Hive,WITHOUT_CLASSIFICATION,//  most likely the user specified an invalid partition 
Hive,WITHOUT_CLASSIFICATION,//  e.g. a dummy vertex for a mergejoin branch 
Hive,WITHOUT_CLASSIFICATION,//  best attempt shouldn't really kill DAG for this 
Hive,WITHOUT_CLASSIFICATION,//  number of nodes on stack   current mark 
Hive,WITHOUT_CLASSIFICATION,//  Whether there is to be a tag added to the end of each key and the tag value. 
Hive,WITHOUT_CLASSIFICATION,// copy the hive conf into the job conf and restore it  in the backend context 
Hive,WITHOUT_CLASSIFICATION,//  add some data and nulls 
Hive,WITHOUT_CLASSIFICATION,//  get the Table objects for this batch of table names and get iterator 
Hive,WITHOUT_CLASSIFICATION,//  adjust arrays 
Hive,WITHOUT_CLASSIFICATION,//  nodes one of them is column and the other is numeric const 
Hive,WITHOUT_CLASSIFICATION,//  can happen with virtual columns. RS would add the column to its output columns   but it would not exist in the grandparent output columns or exprMap. 
Hive,WITHOUT_CLASSIFICATION,//  if number of elements in map cannot be determined this value will be used 
Hive,WITHOUT_CLASSIFICATION,//  child should be a join for this to happen. 
Hive,WITHOUT_CLASSIFICATION,//  The only ABA problem we care about. Ok to have another buffer in there; 
Hive,WITHOUT_CLASSIFICATION,//  Adjustable. 
Hive,WITHOUT_CLASSIFICATION,//  Assuming FileSystem.getAllStatistics() returns all schemes that are accessed on task side   as well. If not we need a way to get all the schemes that are accessed by the tez task/llap. 
Hive,WITHOUT_CLASSIFICATION,//  figure out subquery expression column's type 
Hive,WITHOUT_CLASSIFICATION,//  Individual columns are going to be pivoted to HBase cells   and for each row they need to be written out in order   of column name so sort the column names now creating a   mapping to their column position.  However the first 
Hive,WITHOUT_CLASSIFICATION,//  setup to run concurrent operations 
Hive,WITHOUT_CLASSIFICATION,//  (a scalar) and trivial to evaluate. 
Hive,WITHOUT_CLASSIFICATION,//  test that read columns are initially an empty list 
Hive,WITHOUT_CLASSIFICATION,// Found some columns in user specified schema which are neither regular not dynamic partition columns 
Hive,WITHOUT_CLASSIFICATION,/*   * The job argument is passed so that configuration overrides can be used to initialize  * the metastore configuration in the special case of an embedded metastore  * (hive.metastore.uris = "").   */
Hive,WITHOUT_CLASSIFICATION,/*        * create SelectListOI        */
Hive,WITHOUT_CLASSIFICATION,//  PRINCIPAL_GRANTS 
Hive,WITHOUT_CLASSIFICATION,//  Expected error 
Hive,WITHOUT_CLASSIFICATION,//  We cannot merge (1.2) 
Hive,WITHOUT_CLASSIFICATION,//  GenericUDF is stateful - we have to make a copy here 
Hive,WITHOUT_CLASSIFICATION,// If the record reader (from which the record is originated) is already seen and valid  no need to re-encode the record. 
Hive,WITHOUT_CLASSIFICATION,//  Parameters for exporting metadata on table drop (requires the use of the) 
Hive,WITHOUT_CLASSIFICATION,//  print parent op i.e. where data comes from 
Hive,WITHOUT_CLASSIFICATION,//  set up a db and table 
Hive,WITHOUT_CLASSIFICATION,/*      * According to the javadoc getMax() can return -1. In this case     * default to 200MB. This will probably never actually happen.      */
Hive,WITHOUT_CLASSIFICATION,//  This hash function returns the same result as String.hashCode() when   all characters are ASCII while Text.hashCode() always returns a   different result. 
Hive,WITHOUT_CLASSIFICATION,//  end of struct 
Hive,WITHOUT_CLASSIFICATION,//  Load data 
Hive,WITHOUT_CLASSIFICATION,//  no custom composite key class provided. return null 
Hive,WITHOUT_CLASSIFICATION,//  For HBase storage handler 
Hive,WITHOUT_CLASSIFICATION,//  likewise 
Hive,WITHOUT_CLASSIFICATION,//  Sign in2 with a different key. 
Hive,WITHOUT_CLASSIFICATION,/*          * Gen Join between outer Operator and SQ op          */
Hive,WITHOUT_CLASSIFICATION,//  See class comment about refcounts. 
Hive,WITHOUT_CLASSIFICATION,//  6.1 Determine type of UDAF   This is the GenericUDAF name 
Hive,WITHOUT_CLASSIFICATION,//  left is larger 
Hive,WITHOUT_CLASSIFICATION,//  http://dev.mysql.com/doc/refman/5.0/en/connector-j-reference-error-sqlstates.html 
Hive,WITHOUT_CLASSIFICATION,//  Verify that the names match the PARTITIONED ON clause. 
Hive,WITHOUT_CLASSIFICATION,//  set the link between mapjoin and parent vertex 
Hive,WITHOUT_CLASSIFICATION,// newer versions (12c and later) support OFFSET/FETCH 
Hive,WITHOUT_CLASSIFICATION,/*          * Repeating.          */
Hive,WITHOUT_CLASSIFICATION,//  Did we read all the data? 
Hive,WITHOUT_CLASSIFICATION,//  Read the altered db via CachedStore (altered user from "user2" to "user1") 
Hive,WITHOUT_CLASSIFICATION,//  SRC_TXN_TO_WRITE_ID_LIST 
Hive,WITHOUT_CLASSIFICATION,//  The join columns which are also skewed 
Hive,WITHOUT_CLASSIFICATION,// this succeeds as abortTxn is idempotent 
Hive,WITHOUT_CLASSIFICATION,//  Copy the BigTable values into the overflow batch. Since the overflow batch may   not get flushed here we must copy by value. 
Hive,WITHOUT_CLASSIFICATION,//  Use HiveInputFormat if any of the paths is not splittable 
Hive,WITHOUT_CLASSIFICATION,//  We check whether the join can be combined with any of its children 
Hive,WITHOUT_CLASSIFICATION,//  Case 1: is repeating no nulls 
Hive,WITHOUT_CLASSIFICATION,//  [optional] alias of the column (external name 
Hive,WITHOUT_CLASSIFICATION,//  Walk over all the sources (which are guaranteed to be reduce sink   operators). 
Hive,WITHOUT_CLASSIFICATION,//  When split-update is enabled we can choose not to write   any delta files when there are no inserts. In such cases only the delete_deltas   would be written & they are closed separately below. 
Hive,WITHOUT_CLASSIFICATION,//  Sort all the inputs outputs.   If a lock needs to be acquired on any partition a read lock needs to be acquired on all 
Hive,WITHOUT_CLASSIFICATION,//  If the input FileSinkOperator is a dynamic partition enabled the tsMerge input schema   needs to include the partition column and the fsOutput should have 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: in Hive AST Rows->Range(Physical) & Range -> Values (logical) 
Hive,WITHOUT_CLASSIFICATION,//  -n <username> 
Hive,WITHOUT_CLASSIFICATION,// OR 
Hive,WITHOUT_CLASSIFICATION,//  1. We check if it is a permutation project. If it is 
Hive,WITHOUT_CLASSIFICATION,//  Update maxLength if length is greater than the largest value seen so far 
Hive,WITHOUT_CLASSIFICATION,//  instantiated. 
Hive,WITHOUT_CLASSIFICATION,//  array of null column values   input ObjectInspectors 
Hive,WITHOUT_CLASSIFICATION,//  Value becomes zero for rounding beyond. 
Hive,WITHOUT_CLASSIFICATION,//  Format the storage format statements 
Hive,WITHOUT_CLASSIFICATION,//  dynamic partition usecase - partition values were null or not all were specified   need to figure out which keys are not specified. 
Hive,WITHOUT_CLASSIFICATION,//  no longer a best match if more than one. 
Hive,WITHOUT_CLASSIFICATION,//  Just bitwise-OR the bits together - size/# functions should be the same 
Hive,WITHOUT_CLASSIFICATION,//  This restricts macro creation to privileged users. 
Hive,WITHOUT_CLASSIFICATION,/*           for now for simplicity we are doing just one directory ( one database ) come back to use          of multiple databases once we have the basic flow to chain creating of tasks in place for          a database ( directory )       */
Hive,WITHOUT_CLASSIFICATION,//  to disk 
Hive,WITHOUT_CLASSIFICATION,//  we reach a runlength here use the previous length and reset   runlength 
Hive,WITHOUT_CLASSIFICATION,//  If we're moving files around for an ACID write then the rules and paths are all different. 
Hive,WITHOUT_CLASSIFICATION,//  We only consider the materialized view to be outdated if forceOutdated = true i.e.   if it is a rebuild. Otherwise it passed the test and we use it as it is. 
Hive,WITHOUT_CLASSIFICATION,//  3. Create GB 
Hive,WITHOUT_CLASSIFICATION,//  for leaf we don't do anything 
Hive,WITHOUT_CLASSIFICATION,//  verify cm.recycle(Path) api moves file to cmroot dir 
Hive,WITHOUT_CLASSIFICATION,//  Default location of HiveServer2 
Hive,WITHOUT_CLASSIFICATION,//  If there are multiple aliases in source we do not know   how to merge. 
Hive,WITHOUT_CLASSIFICATION,/*  alternate1 = useColumnSortOrderIsDesc  */
Hive,WITHOUT_CLASSIFICATION,// Flush if memory limits were reached 
Hive,WITHOUT_CLASSIFICATION,//  Now we only try the first partition if the first partition doesn't   contain enough size we change to normal mode. 
Hive,WITHOUT_CLASSIFICATION,//  Await future result with a timeout to check the abort field occasionally.   It's possible that the interrupt which comes in along with an abort is suppressed   by some other operator. 
Hive,WITHOUT_CLASSIFICATION,//  this event can never occur. If it does fail. 
Hive,WITHOUT_CLASSIFICATION,//  When either name or value is null the set method below will fail   and throw IllegalArgumentException 
Hive,WITHOUT_CLASSIFICATION,//  There will not be any MR or Tez job above this task 
Hive,WITHOUT_CLASSIFICATION,//  The following data is used to compute a partitioned table's NDV based   on partitions' NDV when useDensityFunctionForNDVEstimation = true. Global NDVs cannot be   accurately derived from partition NDVs because the domain of column value two partitions   can overlap. If there is no overlap then global NDV is just the sum   of partition NDVs (UpperBound). But if there is some overlay then   global NDV can be anywhere between sum of partition NDVs (no overlap)   and same as one of the partition NDV (domain of column value in all other   partitions is subset of the domain value in one of the partition)   (LowerBound).But under uniform distribution we can roughly estimate the global   NDV by leveraging the min/max values.   And we also guarantee that the estimation makes sense by comparing it to the   UpperBound (calculated by "sum(\"NUM_DISTINCTS\")")   and LowerBound (calculated by "max(\"NUM_DISTINCTS\")") 
Hive,WITHOUT_CLASSIFICATION,//  Dump and load only truncate (0 records) 
Hive,WITHOUT_CLASSIFICATION,//  same string 
Hive,WITHOUT_CLASSIFICATION,//  None. 
Hive,WITHOUT_CLASSIFICATION,//  we've got what we need; mark the queue 
Hive,WITHOUT_CLASSIFICATION,/*          * if the keyHash is missing in the bloom filter then the value cannot         * exist in any of the spilled partition - return NOMATCH          */
Hive,WITHOUT_CLASSIFICATION,//  If it is a windowing spec we include it in the list   Further we will examine its children AST nodes to check whether   there are aggregation functions within 
Hive,WITHOUT_CLASSIFICATION,//  Original bucket files should stay until Cleaner kicks in. 
Hive,WITHOUT_CLASSIFICATION,/*    * Right trim and truncate a slice of a byte array to a maximum number of characters and   * place the result into element i of a vector.    */
Hive,WITHOUT_CLASSIFICATION,//  CHILDREN 
Hive,WITHOUT_CLASSIFICATION,//  If the child SelectOperator does not have the ColumnExprMap   we do not need to update the ColumnExprMap in the parent SelectOperator. 
Hive,WITHOUT_CLASSIFICATION,//  so far same as java.math.BigDecimal but the scaling below is   specific to ANSI SQL Numeric. 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:SourceStateUpdatedRequestProto) 
Hive,WITHOUT_CLASSIFICATION,//  This is needed for tracking the dependencies for inputs along with their parents. 
Hive,WITHOUT_CLASSIFICATION,//  We repartition: new number of splits 
Hive,WITHOUT_CLASSIFICATION,/*  * Directly deserialize with the caller reading field-by-field the LazySimple (text) * serialization format. * * The caller is responsible for calling the read method for the right type of each field * (after calling readNextField). * * Reading some fields require a results object to receive value information.  A separate * results object is created by the caller at initialization per different field even for the same * type. * * Some type values are by reference to either bytes in the deserialization buffer or to * other type specific buffers.  So those references are only valid until the next time set is * called.  */
Hive,WITHOUT_CLASSIFICATION,//  no match 
Hive,WITHOUT_CLASSIFICATION,//  make sure MAP task environment points to HIVE_JOB_CREDSTORE_PASSWORD 
Hive,WITHOUT_CLASSIFICATION,//  First we parse the view query and create the materialization object 
Hive,WITHOUT_CLASSIFICATION,/*  * represents a collection of rows that is acted upon by a TableFunction or a WindowFunction.  */
Hive,WITHOUT_CLASSIFICATION,//  Testing multiByte string with reference starting mid array 
Hive,WITHOUT_CLASSIFICATION,//  Group column found 
Hive,WITHOUT_CLASSIFICATION,//  If one of the predicates is = then any other predicate with it is illegal.   Add to residual 
Hive,WITHOUT_CLASSIFICATION,//  Go over all the destination tables 
Hive,WITHOUT_CLASSIFICATION,// //////////  Second Incremental //////////// 
Hive,WITHOUT_CLASSIFICATION,//  SCHEMA_VERSION 
Hive,WITHOUT_CLASSIFICATION,//  2c. This is a compressed buffer. We need to uncompress it; the buffer can comprise   several disk ranges so we might need to combine them. 
Hive,WITHOUT_CLASSIFICATION,//  A simple ROWNUM > offset and ROWNUM <= (offset + limit) won't work it will return nothing 
Hive,WITHOUT_CLASSIFICATION,//  Verify that there is no notifications available yet 
Hive,WITHOUT_CLASSIFICATION,//  Check each ExprNodeDesc. 
Hive,WITHOUT_CLASSIFICATION,//  move up files 
Hive,WITHOUT_CLASSIFICATION,//  update the connection 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setURL(int java.net.URL)    */
Hive,WITHOUT_CLASSIFICATION,//  Two cases:   1. srcs has only a src directory if rename src directory to destf we also need to   Copy/move each file under the source directory to avoid to delete the destination   directory if it is the root of an HDFS encryption zone.   2. srcs must be a list of files -- ensured by LoadSemanticAnalyzer 
Hive,WITHOUT_CLASSIFICATION,// it is OK curReader is closed for we only need footer buffer info from preReader. 
Hive,WITHOUT_CLASSIFICATION,//  Wrap the inner parts of the loop in a catch throwable so that any errors in the loop   don't doom the entire thread. 
Hive,WITHOUT_CLASSIFICATION,//  Take the empty buffer out of the free list. 
Hive,WITHOUT_CLASSIFICATION,//  start heartbeat thread 
Hive,WITHOUT_CLASSIFICATION,//  Get the "transactional" tblproperties value 
Hive,WITHOUT_CLASSIFICATION,//  No duplicate names.  This should be ok 
Hive,WITHOUT_CLASSIFICATION,//  create a task for this local work; right now this local work is shared 
Hive,WITHOUT_CLASSIFICATION,//  Only distinct nodes that are NOT part of the key should be added to distExprNodes 
Hive,WITHOUT_CLASSIFICATION,//  We have just locked a buffer that wasn't previously locked. 
Hive,WITHOUT_CLASSIFICATION,//   We can use alter table partition rename to convert/normalize the legacy partition    column values. In so we should not enable the validation to the old partition spec    passed in this command. 
Hive,WITHOUT_CLASSIFICATION,//  time which needs to be thread protected. 
Hive,WITHOUT_CLASSIFICATION,//  Boolean to long is done with an IdentityExpression   Boolean to double is done with standard Long to Double cast   See org.apache.hadoop.hive.ql.exec.vector.expressions for remaining cast VectorExpression   classes 
Hive,WITHOUT_CLASSIFICATION,/*            * One element.            */
Hive,WITHOUT_CLASSIFICATION,//  For now if a bigint is going to be cast to a double throw an error or warning 
Hive,WITHOUT_CLASSIFICATION,/*  Distinct value estimator  */
Hive,WITHOUT_CLASSIFICATION,//  since we are using thrift 'part' will not have the create time and   last DDL time set since it does not get updated in the add_partition()   call - likewise part2 and part3 - set it correctly so that equals check   doesn't fail 
Hive,WITHOUT_CLASSIFICATION,//  Removes tasks from the runningList and sends out a preempt request to the system.   Subsequent tasks will be scheduled again once the de-allocate request for the preempted 
Hive,WITHOUT_CLASSIFICATION,//  3. Update the existing row in newly-converted ACID table 
Hive,WITHOUT_CLASSIFICATION,/*  * An single long value map optimized for vector map join.  */
Hive,WITHOUT_CLASSIFICATION,/*  operators for which there is chance the optimization can be applied  */
Hive,WITHOUT_CLASSIFICATION,//  We could not find a common category return null 
Hive,WITHOUT_CLASSIFICATION,//  Temporary till the external interface makes use of a single connection per   instance. 
Hive,WITHOUT_CLASSIFICATION,// Make sure that the table alias and column alias are stored  in the column info 
Hive,WITHOUT_CLASSIFICATION,//  These tests inherently cause exceptions to be written to the test output   logs. This is undesirable since you it might appear to someone looking   at the test output logs as if something is failing when it isn't. 
Hive,WITHOUT_CLASSIFICATION,//  Note: this relies on the fact that we always evict the entire column so if         we have the column data we assume we have all the streams we need. 
Hive,WITHOUT_CLASSIFICATION,//  1/ reserve spaces for the byte size of the map   which is a integer and takes four bytes 
Hive,WITHOUT_CLASSIFICATION,//  If we are overwriting we disable existing sources 
Hive,WITHOUT_CLASSIFICATION,//  skip day/time part if both dates are end of the month 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#clearWarnings()    */
Hive,WITHOUT_CLASSIFICATION,// count at the size for 'cost' estimation later 
Hive,WITHOUT_CLASSIFICATION,// we just created top level node for this jobId 
Hive,WITHOUT_CLASSIFICATION,//  Unique ID is registered based on Submit response. Theoretically we could get a ping   when the task is valid but we haven't stored the unique ID yet so taskNodeId is null.   However the next heartbeat(s) should get the value eventually and mark task as alive. 
Hive,WITHOUT_CLASSIFICATION,//  Hmm... why don't many other operations here need locks? 
Hive,WITHOUT_CLASSIFICATION,//  we can bail out 
Hive,WITHOUT_CLASSIFICATION,//  SASL/Kerberos properties 
Hive,WITHOUT_CLASSIFICATION,//  L<->R for inner/semi join L->R for left outer join R->L for right outer join 
Hive,WITHOUT_CLASSIFICATION,//  We optimize by assuming that a repeating list/map will run from   from 0 .. lengths[0] in the child vector.   Sanity check the assumption that we can start at 0. 
Hive,WITHOUT_CLASSIFICATION,/*    * callback method used by subclasses to set the RawInputOI on the Evaluator.    */
Hive,WITHOUT_CLASSIFICATION,//  optional string dag_name = 5; 
Hive,WITHOUT_CLASSIFICATION,//  Re-attempts are left upto the RPC layer. If there's a failure reported after this   mark all attempts running on this node as KILLED. The node itself cannot be killed from   here that's only possible via the scheduler.   The assumption is that if there's a failure to communicate with the node - it will   eventually timeout - and no more tasks will be allocated on it. 
Hive,WITHOUT_CLASSIFICATION,//  Now that we have found real data emit sign byte if necessary and do negative fixup. 
Hive,WITHOUT_CLASSIFICATION,/*        * Verify that new job requests have no issues.        */
Hive,WITHOUT_CLASSIFICATION,//  Since warehouse path is non-qualified the database should be located on second filesystem 
Hive,WITHOUT_CLASSIFICATION,//  the rowID column is a string 
Hive,WITHOUT_CLASSIFICATION,//  found suitable join keys   add them to key list ensuring that if there is a   non-equi join predicate it appears at the end of the   key list; also mark the null filtering property 
Hive,WITHOUT_CLASSIFICATION,//  To be used with primitive types 
Hive,WITHOUT_CLASSIFICATION,//  metastore stats is unavailable fallback to old way 
Hive,WITHOUT_CLASSIFICATION,//  age <= '50' 
Hive,WITHOUT_CLASSIFICATION,//  Elt is a special case because it can take variable number of arguments. 
Hive,WITHOUT_CLASSIFICATION,//  2 VARCHAR test 
Hive,WITHOUT_CLASSIFICATION,// reconfigure log4j after settings via hiveconf are write into System Properties 
Hive,WITHOUT_CLASSIFICATION,//  try using both permanent functions 
Hive,WITHOUT_CLASSIFICATION,//  we need to add up all the estimates from the siblings of this reduce sink 
Hive,WITHOUT_CLASSIFICATION,//  Does a breadth first traversal of the tasks 
Hive,WITHOUT_CLASSIFICATION,// Assert.assertFalse(itr.hasNext()); 
Hive,WITHOUT_CLASSIFICATION,//  EmptyBuckets = true 
Hive,WITHOUT_CLASSIFICATION,//  generate single split typically happens when reading data out of order by queries.   if order by query returns no rows no files will exists in input path 
Hive,WITHOUT_CLASSIFICATION,//  TODO Ideally this should only need to send in the TaskAttemptId. Everything else should be   inferred from this.   Passing in parameters until there's some dag information stored and tracked in the daemon. 
Hive,WITHOUT_CLASSIFICATION,//  The null in union type should be removed 
Hive,WITHOUT_CLASSIFICATION,//  This is a percentage value between 0 and 1 
Hive,WITHOUT_CLASSIFICATION,//  required   required   optional   optional   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  If no keyValueSeparator is seen all bytes belong to key and 
Hive,WITHOUT_CLASSIFICATION,//  TODO: These can eventually be used to replace generateTimestampScalarCompareTimestampColumn() 
Hive,WITHOUT_CLASSIFICATION,//  We want message to be sent when session commits thus we run in   transacted mode. 
Hive,WITHOUT_CLASSIFICATION,//  Note: this sets LoadFileType incorrectly for ACID; is that relevant for load? 
Hive,WITHOUT_CLASSIFICATION,//  has been rewritten; apply rules post-decorrelation 
Hive,WITHOUT_CLASSIFICATION,//  since removeParent/removeChild updates the childOperators and parentOperators list in place   we need to make a copy of list to iterator over them 
Hive,WITHOUT_CLASSIFICATION,//  Values should unique (given how we do the checking and "addOrMerge") 
Hive,WITHOUT_CLASSIFICATION,//  Enums are one of two Avro types that Hive doesn't have any native support for. 
Hive,WITHOUT_CLASSIFICATION,// MSSQL specific parser 
Hive,WITHOUT_CLASSIFICATION,//  LATERAL VIEW OUTER not supported in CBO 
Hive,WITHOUT_CLASSIFICATION,//  TODO: Ideally we want tez to use CallableWithMdc that retains the MDC for threads created in   thread pool. For now we will push both dagId and queryId into NDC and the custom thread   pool that we use for task execution and llap io (StatsRecordingThreadPool) will pop them 
Hive,WITHOUT_CLASSIFICATION,//  Define constants and local variables. 
Hive,WITHOUT_CLASSIFICATION,//  in case of broadcast-join read the broadcast edge inputs   (possibly asynchronously) 
Hive,WITHOUT_CLASSIFICATION,//  1.1) Extract name as we will need it afterwards: 
Hive,WITHOUT_CLASSIFICATION,//  Now check for overflow. 
Hive,WITHOUT_CLASSIFICATION,//  Existence 
Hive,WITHOUT_CLASSIFICATION,//  config parameter that suggests to hcat that metastore clients not be cached - default is false   this parameter allows highly-parallel hcat usescases to not gobble up too many connections that 
Hive,WITHOUT_CLASSIFICATION,//  Remove the entry if there's nothing left at the specific priority level 
Hive,WITHOUT_CLASSIFICATION,//  Should still be able to get the 2nd session. 
Hive,WITHOUT_CLASSIFICATION,//  Set values needed for numeric arithmetic UDFs 
Hive,WITHOUT_CLASSIFICATION,// hasNext implies there is some column in the batch 
Hive,WITHOUT_CLASSIFICATION,//  can not queue more requests as queue is full 
Hive,WITHOUT_CLASSIFICATION,/*  Convert an integer value in milliseconds since the epoch to a timestamp value   * for use in a long column vector which is represented in nanoseconds since the epoch.    */
Hive,WITHOUT_CLASSIFICATION,/*  Miscellaneous errors range 9000 - 9998  */
Hive,WITHOUT_CLASSIFICATION,//  Found ugi perform doAs(). 
Hive,WITHOUT_CLASSIFICATION,//  check if any right pair exists for left objects 
Hive,WITHOUT_CLASSIFICATION,//  1. Gen Calcite Plan 
Hive,WITHOUT_CLASSIFICATION,//  Test for valid values for both. 
Hive,WITHOUT_CLASSIFICATION,// so now 'working' should be sorted like delta_5_20 delta_5_10 delta_11_20 delta_51_60 for example  and we want to end up with the best set containing all relevant data: delta_5_20 delta_51_60 
Hive,WITHOUT_CLASSIFICATION,/*    * Use this copy method when the source batch may get reused before the target batch is finished.   * Any bytes column vector values will be copied to the target by value into the column's   * data buffer.    */
Hive,WITHOUT_CLASSIFICATION,//  Get an array of UTF-8 byte arrays from an array of strings 
Hive,WITHOUT_CLASSIFICATION,//  and then compare the two tables 
Hive,WITHOUT_CLASSIFICATION,//  Special case - Date requires its own specific BetweenDynamicValue class but derives from FilterLongColumnBetween 
Hive,WITHOUT_CLASSIFICATION,//  Others (a1) should be kept 
Hive,WITHOUT_CLASSIFICATION,//  after that inputOp is the parent of selOp. 
Hive,WITHOUT_CLASSIFICATION,/*  not a real field  */
Hive,WITHOUT_CLASSIFICATION,// Initialize metrics first as some metrics are for initialization stuff. 
Hive,WITHOUT_CLASSIFICATION,//   The maximum column length = MFieldSchema.FNAME in metastore/src/model/package.jdo 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see javax.sql.DataSource#getConnection()    */
Hive,WITHOUT_CLASSIFICATION,//  try widening conversion otherwise fail union 
Hive,WITHOUT_CLASSIFICATION,//  look through the file with no rows selected 
Hive,WITHOUT_CLASSIFICATION,//  Select none in 1st child none as 2nd child and none as 3rd. 
Hive,WITHOUT_CLASSIFICATION,//  Row-mode is the expected value. 
Hive,WITHOUT_CLASSIFICATION,//  Move all data from dest4_sequencefile to dest4 
Hive,WITHOUT_CLASSIFICATION,//  Split join condition 
Hive,WITHOUT_CLASSIFICATION,//  0. Register that we have visited this operator in this rule 
Hive,WITHOUT_CLASSIFICATION,//  The following is a complex type for special handling 
Hive,WITHOUT_CLASSIFICATION,//  a mixture of input columns and new scratch columns (for the aggregation output). 
Hive,WITHOUT_CLASSIFICATION,// verify that we are indeed doing an Acid write (import) 
Hive,WITHOUT_CLASSIFICATION,//  DB_PATTERNS 
Hive,WITHOUT_CLASSIFICATION,//  2. Go thru the blocks; add stuff to results and prepare the decompression work (see below). 
Hive,WITHOUT_CLASSIFICATION,//  The lowest digit is power = 0. 
Hive,WITHOUT_CLASSIFICATION,//  Arrange so result* has a longer digit tail and it lines up; we will shift the shift* digits   as we do our addition and them into the result. 
Hive,WITHOUT_CLASSIFICATION,// this has state so can't be cached 
Hive,WITHOUT_CLASSIFICATION,//  we do not want the start group to clear the storage 
Hive,WITHOUT_CLASSIFICATION,//  Next we locate all the iterate methods for each of these classes. 
Hive,WITHOUT_CLASSIFICATION,//  Set the config value to empty string which should result in all catalogs being cached. 
Hive,WITHOUT_CLASSIFICATION,//  create and put .hiverc sample file to default directory 
Hive,WITHOUT_CLASSIFICATION,//  This is purely for testing convenience; has no bearing on FS operations such as list. 
Hive,WITHOUT_CLASSIFICATION,//  SSL settings 
Hive,WITHOUT_CLASSIFICATION,//  Get the distinct values of the GROUP BY fields and the arguments   to the agg functions. 
Hive,WITHOUT_CLASSIFICATION,//  catch-all due to some exec time dependencies on session state   that would cause ClassNoFoundException otherwise 
Hive,WITHOUT_CLASSIFICATION,//  We are revoking another duck; don't wait. We could also give the duck 
Hive,WITHOUT_CLASSIFICATION,//  TODO: lossy conversion distance is considered in seconds 
Hive,WITHOUT_CLASSIFICATION,//  Add new operator to cache work group of existing operator (if group exists) 
Hive,WITHOUT_CLASSIFICATION,//  Store the given token in the UGI 
Hive,WITHOUT_CLASSIFICATION,//  Calculate the parameters 
Hive,WITHOUT_CLASSIFICATION,//  Get the parent TS of victimRS. 
Hive,WITHOUT_CLASSIFICATION,//  COLUMN_COUNT 
Hive,WITHOUT_CLASSIFICATION,/*  For cast on constant operator in all members of the input list and return new list   * containing results.    */
Hive,WITHOUT_CLASSIFICATION,//  4. Insert RS on reduce side with Reduce side GB as input 
Hive,WITHOUT_CLASSIFICATION,//  If only one distinct aggregate and one or more non-distinct aggregates 
Hive,WITHOUT_CLASSIFICATION,//  Select all with a is not null child none as 2nd child and is null with 3rd and then   expect the 3rd child to not be invoked. 
Hive,WITHOUT_CLASSIFICATION,//  positions of variable arguments (columns or non-constant expressions) 
Hive,WITHOUT_CLASSIFICATION,// ---------------------------------------   Just so we can get the output type... 
Hive,WITHOUT_CLASSIFICATION,/*    * Reads through an undesired field.   *   * No data values are valid after this call.   * Designed for skipping columns that are not included.    */
Hive,WITHOUT_CLASSIFICATION,/*    * These members have information for deserializing a row into the VectorizedRowBatch   * columns.   *   * We say "source" because when there is conversion we are converting th deserialized source into   * a target data type.    */
Hive,WITHOUT_CLASSIFICATION,//  Partition columns are appended at end we only care about stats column 
Hive,WITHOUT_CLASSIFICATION,//  CREATED_AT 
Hive,WITHOUT_CLASSIFICATION,//  a list of doubles 
Hive,WITHOUT_CLASSIFICATION,//  we do not want the end group to cause a checkAndGenObject 
Hive,WITHOUT_CLASSIFICATION,//  When there are PARTITION and ORDER BY clauses will have different partition expressions. 
Hive,WITHOUT_CLASSIFICATION,//  have to remember it. 
Hive,WITHOUT_CLASSIFICATION,//  If the character set for encoding is constant we can optimize that 
Hive,WITHOUT_CLASSIFICATION,//  this time even more inaccurate 
Hive,WITHOUT_CLASSIFICATION,//  replace the distinct with the count aggregation 
Hive,WITHOUT_CLASSIFICATION,//  for hive script operator 
Hive,WITHOUT_CLASSIFICATION,//  technique. 
Hive,WITHOUT_CLASSIFICATION,//  Since we won't be able to update this as we add for now estimate 10x usage.   This shouldn't be much and this cache should be remove later anyway. 
Hive,WITHOUT_CLASSIFICATION,//  for non-LLAP mode most of these are not relevant. Only noConditionalTaskSize is used by shared scan optimizer. 
Hive,WITHOUT_CLASSIFICATION,//  Since row mode takes everyone. 
Hive,WITHOUT_CLASSIFICATION,//  does it need an additional MR job 
Hive,WITHOUT_CLASSIFICATION,//  TODO: set correct vendorCode field 
Hive,WITHOUT_CLASSIFICATION,//  If the current expression node does not have a virtual/partition column or 
Hive,WITHOUT_CLASSIFICATION,// create JavaBinaryObjectInspector 
Hive,WITHOUT_CLASSIFICATION,//  the current char will be written out later. 
Hive,WITHOUT_CLASSIFICATION,//  Examine the last child. It could be an alias. 
Hive,WITHOUT_CLASSIFICATION,//  returnAfterUse will take care of this 
Hive,WITHOUT_CLASSIFICATION,//  Decimal longwords. 
Hive,WITHOUT_CLASSIFICATION,//  We do not need to do anything it is in the OR expression 
Hive,WITHOUT_CLASSIFICATION,//  it is an extraction fn need to be parsed 
Hive,WITHOUT_CLASSIFICATION,//  If the type cast UDF is for a parameterized type then it should implement   the SettableUDF interface so that we can pass in the params.   Not sure if this is the cleanest solution but there does need to be a way 
Hive,WITHOUT_CLASSIFICATION,// list  struct 
Hive,WITHOUT_CLASSIFICATION,//  valid merge -- register set size gets bigger & dense automatically 
Hive,WITHOUT_CLASSIFICATION,//  looks like a subq plan. 
Hive,WITHOUT_CLASSIFICATION,//  BucketizedHiveInputFormat should be used for either sort merge join or bucket map join 
Hive,WITHOUT_CLASSIFICATION,//  well. 
Hive,WITHOUT_CLASSIFICATION,//  Primitive. 
Hive,WITHOUT_CLASSIFICATION,//  CHAR NOT BETWEEN 
Hive,WITHOUT_CLASSIFICATION,//  generate a map join task for the big table 
Hive,WITHOUT_CLASSIFICATION,//  Output is type interval_day_time. 
Hive,WITHOUT_CLASSIFICATION,//  property speficied file found in local file system   use the specified file 
Hive,WITHOUT_CLASSIFICATION,//  Same as commitDropTable where we always delete the data (accumulo table) 
Hive,WITHOUT_CLASSIFICATION,//  Callers duplicate the buffer they have to for BufferChunk; so we don't have to. 
Hive,WITHOUT_CLASSIFICATION,//  All must be selected otherwise size would be zero. Repeating property will not change. 
Hive,WITHOUT_CLASSIFICATION,// org.apache.commons.exec.DefaultExecutor requires   that current directory exists 
Hive,WITHOUT_CLASSIFICATION,//  The isNull check and work has already been performed. 
Hive,WITHOUT_CLASSIFICATION,//  Copy the current object contents into the output. Only copy selected entries 
Hive,WITHOUT_CLASSIFICATION,//  Check for delegation token if present add it in the header 
Hive,WITHOUT_CLASSIFICATION,//  Preserving the old logic. Hmm... 
Hive,WITHOUT_CLASSIFICATION,//  We have already explored the stack deep enough but   we do not have a matching 
Hive,WITHOUT_CLASSIFICATION,//  For n-way join only spill big table rows once 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#prepareStatement(java.lang.String   * java.lang.String[])    */
Hive,WITHOUT_CLASSIFICATION,//  Update aggregate partition column stats for a table in cache 
Hive,WITHOUT_CLASSIFICATION,//  2. Add UDAF 
Hive,WITHOUT_CLASSIFICATION,//  datetime type isn't currently supported 
Hive,WITHOUT_CLASSIFICATION,//  v[4] 
Hive,WITHOUT_CLASSIFICATION,// Helper classes for ConnParam comparison logics. 
Hive,WITHOUT_CLASSIFICATION,/*        * Handle case with nulls. Don't do function if the value is null to save time       * because calling the function can be expensive.        */
Hive,WITHOUT_CLASSIFICATION,//  should be a constant or column 
Hive,WITHOUT_CLASSIFICATION,//  delete remaining directories for external tables (can affect stats for following tests) 
Hive,WITHOUT_CLASSIFICATION,//  Note: we are creating a brand new the partition so this is going to be valid for ACID. 
Hive,WITHOUT_CLASSIFICATION,//  than the configured the header size 
Hive,WITHOUT_CLASSIFICATION,//  eat it 
Hive,WITHOUT_CLASSIFICATION,//  No node exists throw exception 
Hive,WITHOUT_CLASSIFICATION,//  part1 ... part20 
Hive,WITHOUT_CLASSIFICATION,// for locks associated with a txn we always heartbeat txn and timeout based on that 
Hive,WITHOUT_CLASSIFICATION,//  Clean time out locks from the database not associated with a transactions i.e. locks   for read-only autoCommit=true statements.  This does a commit   and thus should be done before any calls to heartbeat that will leave 
Hive,WITHOUT_CLASSIFICATION,//  Only creates the expiration tracker if expiration is configured. 
Hive,WITHOUT_CLASSIFICATION,//  look for a row like "INFO  : Query ID = asherman_20170718154720_17c7d18b-36e6-4b35-a8e2-f50847db58ae" 
Hive,WITHOUT_CLASSIFICATION,//  Find operators in work 
Hive,WITHOUT_CLASSIFICATION,//  4.1) Adding ROW__ID field 
Hive,WITHOUT_CLASSIFICATION,//  Check if owid is outside the range of all owids present. 
Hive,WITHOUT_CLASSIFICATION,//  C also has one outer join filter associated with A(c.k>20) which is making 2=0:1 
Hive,WITHOUT_CLASSIFICATION,//  Add a dummy node to cache   Partnames: [tab1part1...tab1part9] 
Hive,WITHOUT_CLASSIFICATION,//  test.performanceTest(); 
Hive,WITHOUT_CLASSIFICATION,//  if it's wrapped by top-level select star query skip ambiguity check (for backward compatibility) 
Hive,WITHOUT_CLASSIFICATION,//  Initialize any entries that could be used in an output vector to have false for null value. 
Hive,WITHOUT_CLASSIFICATION,//  should be OK since the lock is ephemeral and will eventually be deleted   when the query finishes and zookeeper session is closed. 
Hive,WITHOUT_CLASSIFICATION,//  use CombineHiveInputFormat for map-only merging 
Hive,WITHOUT_CLASSIFICATION,//  There is a Project on top (due to nullability) 
Hive,WITHOUT_CLASSIFICATION,//  Running example 
Hive,WITHOUT_CLASSIFICATION,//        in any sensible way. So for now the lock is going to be epic. 
Hive,WITHOUT_CLASSIFICATION,/*      * does the row match the pattern represented by this SymbolFunction      */
Hive,WITHOUT_CLASSIFICATION,//  MatchStats for each candidate 
Hive,WITHOUT_CLASSIFICATION,/*  Temporarily holds location of exponent				 * in string.  */
Hive,WITHOUT_CLASSIFICATION,//  Bytes remaining in the current chunk of data 
Hive,WITHOUT_CLASSIFICATION,//  does not add back up task here because back up task should be the same   type of the original task. 
Hive,WITHOUT_CLASSIFICATION,//  For equal-priority rules user rules come first because they are more specific; then apps 
Hive,WITHOUT_CLASSIFICATION,//  make sure the dpp sink has output for all the corresponding part columns 
Hive,WITHOUT_CLASSIFICATION,//  Now get a non-existant entry 
Hive,WITHOUT_CLASSIFICATION,//  tests a multimap structure 
Hive,WITHOUT_CLASSIFICATION,// rollback is done for the benefit of Postgres which throws (SQLState=25P02 ErrorCode=0) if  you attempt any stmt in a txn which had an error. 
Hive,WITHOUT_CLASSIFICATION,//  the Configuration 
Hive,WITHOUT_CLASSIFICATION,//  If not ReduceSink Op skip 
Hive,WITHOUT_CLASSIFICATION,//  Optimize: whole decimal fits in one binary word. 
Hive,WITHOUT_CLASSIFICATION,//  Need to subtract 1 as nwi_next would be the next write id to be allocated but we need highest   allocated write id. 
Hive,WITHOUT_CLASSIFICATION,// no more files for current bucket 
Hive,WITHOUT_CLASSIFICATION,//  the time and number counters become available only after the 1st 
Hive,WITHOUT_CLASSIFICATION,//  Add min/max and bloom filter aggregations 
Hive,WITHOUT_CLASSIFICATION,//  Some cf:cq 
Hive,WITHOUT_CLASSIFICATION,//  limit is reached or batchSize reduces to 0 whichever comes earlier. 
Hive,WITHOUT_CLASSIFICATION,/*  Move files one by one because source is a subdirectory of destination  */
Hive,WITHOUT_CLASSIFICATION,/* as of hadoop 2.3.0 PseudoAuthenticationHandler only expects user.name as a query param      * (not as a form param in a POST request.  For backwards compatibility we this logic      * to get user.name when it's sent as a form parameter.      * This is added in Hive 0.13 and should be de-supported in 0.15 */
Hive,WITHOUT_CLASSIFICATION,//  scan 
Hive,WITHOUT_CLASSIFICATION,//  The number of partitions aggregated per cache node   If the number of partitions requested is > this value we'll fetch directly from Metastore 
Hive,WITHOUT_CLASSIFICATION,//  FKCOLUMN_NAME 
Hive,WITHOUT_CLASSIFICATION,//  #2 
Hive,WITHOUT_CLASSIFICATION,// CTAS with non-ACID target table 
Hive,WITHOUT_CLASSIFICATION,//  Cannot be a static because default basePersistDirectory is unique per-instance 
Hive,WITHOUT_CLASSIFICATION,//  Fractional part powered up too high. 
Hive,WITHOUT_CLASSIFICATION,//  If there is a PTF between cRS and pRS we cannot ignore the order direction 
Hive,WITHOUT_CLASSIFICATION,//  -1 buckets means to turn off bucketing 
Hive,WITHOUT_CLASSIFICATION,//  Same thing -- might be deleted by other nodes so just go on. 
Hive,WITHOUT_CLASSIFICATION,//  Launch upto maxthreads tasks 
Hive,WITHOUT_CLASSIFICATION,/*  allowNull  */
Hive,WITHOUT_CLASSIFICATION,//  #1 
Hive,WITHOUT_CLASSIFICATION,//  read the first row in parquet data page this will be only happened once for this instance 
Hive,WITHOUT_CLASSIFICATION,//  Return true for exprNodeColumnDesc 
Hive,WITHOUT_CLASSIFICATION,//  not a nullable union 
Hive,WITHOUT_CLASSIFICATION,//  call-1: open to read data - split 1 => mock:/mocktable6/0_0   call-2: AcidUtils.getAcidState - split 1 => ls mock:/mocktable6   call-3: open to read data - split 2 => mock:/mocktable6/0_1   call-4: AcidUtils.getAcidState - split 2 => ls mock:/mocktable6   call-5: read footer - split 2 => mock:/mocktable6/0_0 (to get offset since it's original file) 
Hive,WITHOUT_CLASSIFICATION,//  check second most significant part 
Hive,WITHOUT_CLASSIFICATION,//  We always need to call reset on the codec. 
Hive,WITHOUT_CLASSIFICATION,//  Find the list of scripts to execute for this upgrade 
Hive,WITHOUT_CLASSIFICATION,//  for now allow only create-view with 'select with grant' 
Hive,WITHOUT_CLASSIFICATION,//  add additional overhead of each map entries 
Hive,WITHOUT_CLASSIFICATION,//  And now we wander straight into the swamp when instead of adding we subtract it from UTC   midnight to supposedly get local midnight (in the above case 4:00 UTC). Of course given 
Hive,WITHOUT_CLASSIFICATION,//  #4 
Hive,WITHOUT_CLASSIFICATION,//  we are done reading a batch send it to consumer for processing 
Hive,WITHOUT_CLASSIFICATION,//  3.4 Try GenericUDF translation 
Hive,WITHOUT_CLASSIFICATION,//  correct version stored by Metastore during startup 
Hive,WITHOUT_CLASSIFICATION,//  there should be 2 calls to create partitions with each batch size of 5 
Hive,WITHOUT_CLASSIFICATION,//  Should not happen 
Hive,WITHOUT_CLASSIFICATION,//  If dynamic allocation is enabled numbers for memory and cores are meaningless. So we don't   try to get it. 
Hive,WITHOUT_CLASSIFICATION,//  When longer we assume the caller will default with nulls etc. 
Hive,WITHOUT_CLASSIFICATION,//  for small tables only; so get the big table position first 
Hive,WITHOUT_CLASSIFICATION,//  Note: the list is expected to be a few items; if it's longer we may want an IHM. 
Hive,WITHOUT_CLASSIFICATION,//  Inject a behaviour where it throws exception if an INSERT event is found   As we dynamically add a partition through INSERT INTO cmd it should just add ADD_PARTITION   event not an INSERT event 
Hive,WITHOUT_CLASSIFICATION,//  Column aliases defined by query for lateral view output are duplicated 
Hive,WITHOUT_CLASSIFICATION,//  then serialize again using hrsd and compare results 
Hive,WITHOUT_CLASSIFICATION,//  show table level privileges 
Hive,WITHOUT_CLASSIFICATION,//  Assert values retrieved 
Hive,WITHOUT_CLASSIFICATION,//  Inject a behaviour where some events missing from notification_log table. 
Hive,WITHOUT_CLASSIFICATION,//  simply need to remember that we've seen an event operator. 
Hive,WITHOUT_CLASSIFICATION,/*      * add Window Functions      */
Hive,WITHOUT_CLASSIFICATION,//  Path must be reused. 
Hive,WITHOUT_CLASSIFICATION,//  Bytes necessary to store extra bits of the second timestamp if storing a timestamp 
Hive,WITHOUT_CLASSIFICATION,//  update table level column stats 
Hive,WITHOUT_CLASSIFICATION,//  If current is JoinOperaotr we will stop to traverse the tree   when any of parent ReduceSinkOperaotr of this JoinOperator is   not considered as a correlated ReduceSinkOperator. 
Hive,WITHOUT_CLASSIFICATION,//  #3 
Hive,WITHOUT_CLASSIFICATION,/*      * Sum input is DECIMAL_64 and output is DECIMAL.     *     * Any mode (PARTIAL1 PARTIAL2 FINAL COMPLETE).      */
Hive,WITHOUT_CLASSIFICATION,//  ADD_PARTITION EVENT to partitioned table 
Hive,WITHOUT_CLASSIFICATION,//  Task Failed 
Hive,WITHOUT_CLASSIFICATION,//  Called one or more times on the client and AM. 
Hive,WITHOUT_CLASSIFICATION,//  Must be deterministic order map for comparison across Java versions 
Hive,WITHOUT_CLASSIFICATION,//  Patch the optimized query back into original CTAS AST replacing the   original query. 
Hive,WITHOUT_CLASSIFICATION,// this works because logically we need S lock on NONACIDORCTBL to read and X lock to write but 
Hive,WITHOUT_CLASSIFICATION,//  Check if the bucketing and/or sorting columns were inferred 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setRowId(int java.sql.RowId)    */
Hive,WITHOUT_CLASSIFICATION,//  No mutator created 
Hive,WITHOUT_CLASSIFICATION,//  try either yyyy-mm-dd or integer representing days since epoch 
Hive,WITHOUT_CLASSIFICATION,//  #6 
Hive,WITHOUT_CLASSIFICATION,//  Move the intermediate archived directory to the original parent directory 
Hive,WITHOUT_CLASSIFICATION,//  Process the last byte. 
Hive,WITHOUT_CLASSIFICATION,//  either initTxnMgr or from the SessionState in that order. 
Hive,WITHOUT_CLASSIFICATION,//  TODO: Look at repeating optimizations... 
Hive,WITHOUT_CLASSIFICATION,//  The partition spec is not present 
Hive,WITHOUT_CLASSIFICATION,/* non acid txn managers don't support txns but fwd lock requests to lock managers        acid txn manager requires all locks to be associated with a txn so if we        end up here w/o an open txn it's because we are processing something like "use <database>        which by definition needs no locks */
Hive,WITHOUT_CLASSIFICATION,//  #5 
Hive,WITHOUT_CLASSIFICATION,//  Column-reference node e.g. a column in the input row 
Hive,WITHOUT_CLASSIFICATION,//  new threads. 
Hive,WITHOUT_CLASSIFICATION,//    Operations involving/returning year-month intervals   
Hive,WITHOUT_CLASSIFICATION,//  estimate number of reducers 
Hive,WITHOUT_CLASSIFICATION,//  This type information specifies the data types the partition needs to read. 
Hive,WITHOUT_CLASSIFICATION,//  read totalSeconds nanos from DataInput 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setDate(int java.sql.Date)    */
Hive,WITHOUT_CLASSIFICATION,//  no filter will be executed for constant 
Hive,WITHOUT_CLASSIFICATION,//  Handle *repeated* join key if found. 
Hive,WITHOUT_CLASSIFICATION,//  Stop the Composite Service 
Hive,WITHOUT_CLASSIFICATION,//  holds the root of the operator tree we're currently processing   this could be a table scan but also a join ptf etc (i.e.: 
Hive,WITHOUT_CLASSIFICATION,//  load the HS2 connection url properties from hive-site.xml if it is present in the classpath 
Hive,WITHOUT_CLASSIFICATION,//  extract drop privileges 
Hive,WITHOUT_CLASSIFICATION,//  Check if the partitions exist in the sourceTable 
Hive,WITHOUT_CLASSIFICATION,//  Not necessary here cause noone will be looking at these after us; set them for clarity. 
Hive,WITHOUT_CLASSIFICATION,//  IF_EXISTS 
Hive,WITHOUT_CLASSIFICATION,//  We need to initialize those MuxOperators first because if we first   initialize other operators the states of all parents of those MuxOperators   are INIT (including this DemuxOperator)   but the inputInspector of those MuxOperators has not been set. 
Hive,WITHOUT_CLASSIFICATION,//  Date part 
Hive,WITHOUT_CLASSIFICATION,//  100 >= x   neg-infinity to end inclusive 
Hive,WITHOUT_CLASSIFICATION,//  STATEMENT 
Hive,WITHOUT_CLASSIFICATION,//  Prevent instantiation 
Hive,WITHOUT_CLASSIFICATION,//  Set the table where we're writing this data 
Hive,WITHOUT_CLASSIFICATION,//  #8 
Hive,WITHOUT_CLASSIFICATION,//  Stop 
Hive,WITHOUT_CLASSIFICATION,//  We now have to probe the global hash and find-or-allocate 
Hive,WITHOUT_CLASSIFICATION,//  populate reduce task 
Hive,WITHOUT_CLASSIFICATION,//  E.g. For scale 2 the minimum is "0.01" 
Hive,WITHOUT_CLASSIFICATION,//  if newCols are not specified use default ones. 
Hive,WITHOUT_CLASSIFICATION,//  find out the null-bytes 
Hive,WITHOUT_CLASSIFICATION,//  if its a partial line continue collecting the pieces 
Hive,WITHOUT_CLASSIFICATION,//  source: LlapPluginProtocol.proto 
Hive,WITHOUT_CLASSIFICATION,//  Tez can handle unpopulated buckets 
Hive,WITHOUT_CLASSIFICATION,//  #7 
Hive,WITHOUT_CLASSIFICATION,//  Assumption: At this point Parse Tree gen & resolution will always   be true (since we started out that way). 
Hive,WITHOUT_CLASSIFICATION,//  No instantiation. 
Hive,WITHOUT_CLASSIFICATION,//  populate stage 
Hive,WITHOUT_CLASSIFICATION,//  This is a dummy assigner 
Hive,WITHOUT_CLASSIFICATION,//  The trailing zeroes extend into the integer part -- we only want to eliminate the   fractional zero digits. 
Hive,WITHOUT_CLASSIFICATION,/* for CTAS TransactionalValidationListener.makeAcid() runs to late to make table Acid         so the initial write ends up running as non-acid... */
Hive,WITHOUT_CLASSIFICATION,// ---------------------------------------------------------------------------   Semi join specific members.   
Hive,WITHOUT_CLASSIFICATION,//  join conditions 
Hive,WITHOUT_CLASSIFICATION,//  r-------- 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hadoop.mapreduce.RecordReader#getCurrentValue()    */
Hive,WITHOUT_CLASSIFICATION,/*  Return true if this is one of a small set of functions for which   * it is significantly easier to use the old code path in vectorized   * mode instead of implementing a new optimized VectorExpression.   *   * Depending on performance requirements and frequency of use these   * may be implemented in the future with an optimized VectorExpression.    */
Hive,WITHOUT_CLASSIFICATION,//  log an exception - this produces enough text to force a new logfile   (as appender.sliding.policies.size.size=1KB) 
Hive,WITHOUT_CLASSIFICATION,//  returncode 
Hive,WITHOUT_CLASSIFICATION,//  Get the 10^N power to turn digits into the desired decimal with a possible   fractional part. 
Hive,WITHOUT_CLASSIFICATION,/*  Because we use Hive's 'string' type when Avro calls for enum we have to expressly check for enum-ness  */
Hive,WITHOUT_CLASSIFICATION,//  If the difference is larger than 2^128 (d4 != 0) then D is   definitely larger than power so increment. 
Hive,WITHOUT_CLASSIFICATION,//  Once we drop support for old Hadoop versions change these   to getBytes() and getLength() to fix the deprecation warnings.   Not worth a shim. 
Hive,WITHOUT_CLASSIFICATION,//  Assert that a and b are not the same within epsilon tolerance. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#setFetchDirection(int)    */
Hive,WITHOUT_CLASSIFICATION,//  Check immediately after reducer is assigned in cae the abort came in during 
Hive,WITHOUT_CLASSIFICATION,//  Use the RowResolver from the input operator to generate a input   ObjectInspector that can be used to initialize the UDTF. Then the   resulting output object inspector can be used to make the RowResolver 
Hive,WITHOUT_CLASSIFICATION,//  As Exchange operator is introduced later on we make a   sort operator create a new stage for the moment 
Hive,WITHOUT_CLASSIFICATION,//  update this information in sparkWorkMap 
Hive,WITHOUT_CLASSIFICATION,//  3. Build operator 
Hive,WITHOUT_CLASSIFICATION,//        older-node tasks proactively. For now let the heartbeats fail them. 
Hive,WITHOUT_CLASSIFICATION,//  multi-table inserts not supported 
Hive,WITHOUT_CLASSIFICATION,//  then just look at the other locks. 
Hive,WITHOUT_CLASSIFICATION,//  Nothing to do 
Hive,WITHOUT_CLASSIFICATION,//  zone1 zone2 should already have been checked for nulls. 
Hive,WITHOUT_CLASSIFICATION,//  Sanity check 
Hive,WITHOUT_CLASSIFICATION,//  use varchar's text field directly 
Hive,WITHOUT_CLASSIFICATION,//  Modify table schema. Add columns. 
Hive,WITHOUT_CLASSIFICATION,// This method does not depend on MetastoreConf.LIMIT_PARTITION_REQUEST setting: 
Hive,WITHOUT_CLASSIFICATION,//  TYPE_DESC 
Hive,WITHOUT_CLASSIFICATION,// if partition spec node is present set partition spec 
Hive,WITHOUT_CLASSIFICATION,//  UNDONE... 
Hive,WITHOUT_CLASSIFICATION,// Test for publish with missing partition key values 
Hive,WITHOUT_CLASSIFICATION,//  more accurate information about the original NDV of the column before any filtering. 
Hive,WITHOUT_CLASSIFICATION,//  if we have no replication state on record for the obj allow replacement. 
Hive,WITHOUT_CLASSIFICATION,//  read the type 
Hive,WITHOUT_CLASSIFICATION,//  column stats for a group by column 
Hive,WITHOUT_CLASSIFICATION,//  read the second flush and make sure we see all 5 rows 
Hive,WITHOUT_CLASSIFICATION,//  Not used by the direct access client -- native vector map join. 
Hive,WITHOUT_CLASSIFICATION,//  this can happen only on top most limit not while visiting Limit Operator   since that can be within subquery. 
Hive,WITHOUT_CLASSIFICATION,//  in ExecDriver as well to have proper local properties. 
Hive,WITHOUT_CLASSIFICATION,//  No need to skip seek here index won't be used anymore. 
Hive,WITHOUT_CLASSIFICATION,//  If we had the entire pool other list couldn't exist.   We exhausted the entire-pool-sized list. 
Hive,WITHOUT_CLASSIFICATION,//  plans. 
Hive,WITHOUT_CLASSIFICATION,//  In memory hashMap   Stores small table key/value pairs   Stores big table rows 
Hive,WITHOUT_CLASSIFICATION,//  ROW is null for delete events. 
Hive,WITHOUT_CLASSIFICATION,//  Missing database name in the query 
Hive,WITHOUT_CLASSIFICATION,//  For the generation of the values expression just get the inputs 
Hive,WITHOUT_CLASSIFICATION,/*    * ResultExpression is a Select List with the following variation:   * - the select keyword is optional. The parser checks if the expression doesn't start with   * select; if not it prefixes it.   * - Window Fn clauses are not permitted.   * - expressions can operate on the input columns plus the psuedo column 'path'   * which is array of   * structs. The shape of the struct is   * the same as the input.    */
Hive,WITHOUT_CLASSIFICATION,//  check if we can convert to map join no bucket scaling. 
Hive,WITHOUT_CLASSIFICATION,//  This implementation of vectorized JOIN is delegating all the work   to the row-mode implementation by hijacking the big table node evaluators   and calling the row-mode join processOp for each row in the input batch.   Since the JOIN operator is not fully vectorized anyway atm (due to the use   of row-mode small-tables) this is a reasonable trade-off. 
Hive,WITHOUT_CLASSIFICATION,//  followed by a call to finishedAddingInitialColumns. 
Hive,WITHOUT_CLASSIFICATION,//  remove local copy of HDFS location from resource map. 
Hive,WITHOUT_CLASSIFICATION,//  all together so there is only one security check 
Hive,WITHOUT_CLASSIFICATION,//  Get the application id of the Spark app 
Hive,WITHOUT_CLASSIFICATION,//    testtable1.*:     S 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setClob(java.lang.String java.sql.Clob)    */
Hive,WITHOUT_CLASSIFICATION,//  If we're in replication scope it's possible that we're running the export long after   the table was dropped so the table not existing currently or being a different kind of   table is not an error - it simply means we should no-op and let a future export   capture the appropriate state 
Hive,WITHOUT_CLASSIFICATION,//  If involving local file system 
Hive,WITHOUT_CLASSIFICATION,/*      * flip column references if join condition specified in reverse order to     * join sources.      */
Hive,WITHOUT_CLASSIFICATION,//  For simpler access we make these members protected instead of   providing get methods. 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)      * @see org.apache.hadoop.mapreduce.RecordWriter#close(org.apache.hadoop.mapreduce.TaskAttemptContext)       */
Hive,WITHOUT_CLASSIFICATION,//  Only support a single expression when it's a UDTF 
Hive,WITHOUT_CLASSIFICATION,//             // re-home location now that we know the rest of the partvals              Table table = jobInfo.getTableInfo().getTable();                List<String> partitionCols = new ArrayList<String>(); 
Hive,WITHOUT_CLASSIFICATION,//  create a TaskInputOutputContext 
Hive,WITHOUT_CLASSIFICATION,//  Even if table location is specified table creation should fail 
Hive,WITHOUT_CLASSIFICATION,/*    * Verify table for Key: Long x Hash Table: HashMultiSet    */
Hive,WITHOUT_CLASSIFICATION,//  Use SubmitWorkRequestProto.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,//  We only allow one single PK. 
Hive,WITHOUT_CLASSIFICATION,//  3. Walk through UDAF & Collect Distinct Info 
Hive,WITHOUT_CLASSIFICATION,//  And round up may cause us to exceed our precision/scale... 
Hive,WITHOUT_CLASSIFICATION,//  Start with capacity 1; make sure we expand on every put. 
Hive,WITHOUT_CLASSIFICATION,//  Assert.assertEquals("expected uri" api.getAddedResource("jar")); 
Hive,WITHOUT_CLASSIFICATION,//  set value for the union type 
Hive,WITHOUT_CLASSIFICATION,//  Create the parent znodes recursively; ignore if the parent already exists. 
Hive,WITHOUT_CLASSIFICATION,//  MYINT 
Hive,WITHOUT_CLASSIFICATION,//  uninitialized bucket 
Hive,WITHOUT_CLASSIFICATION,//  For dynamic partitioned hash join assuming table is split evenly among the reduce tasks. 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: specify Dynamic partitions in dest_tab for WriteEntity 
Hive,WITHOUT_CLASSIFICATION,//  see rowLength javadoc 
Hive,WITHOUT_CLASSIFICATION,/*    * Called at the beginning of the compile phase to have another chance to optimize the operator plan    */
Hive,WITHOUT_CLASSIFICATION,//  DATA_PATH 
Hive,WITHOUT_CLASSIFICATION,/*  * An multi-key hash map based on the BytesBytesMultiHashMap.  */
Hive,WITHOUT_CLASSIFICATION,// last partial batch 
Hive,WITHOUT_CLASSIFICATION,//    outputTypeInfos[outputIndex++] = smallTableTypeInfos[smallTableRetainKeyColumnNums[i]];   } 
Hive,WITHOUT_CLASSIFICATION,//  All columns are dynamic nothing to do. 
Hive,WITHOUT_CLASSIFICATION,//  Multiple children 
Hive,WITHOUT_CLASSIFICATION,//  Set up the locations starting from startIndex and wrapping around the sorted array. 
Hive,WITHOUT_CLASSIFICATION,/*      * Determine the big table retained mapping first so we can optimize out (with     * projection) copying inner join big table keys in the subsequent small table results section.      */
Hive,WITHOUT_CLASSIFICATION,//  Internal vars 
Hive,WITHOUT_CLASSIFICATION,//  Codahale. We just include the pool name in the counter name. 
Hive,WITHOUT_CLASSIFICATION,//  probably a cross product 
Hive,WITHOUT_CLASSIFICATION,// should be no-op since p=3 exists 
Hive,WITHOUT_CLASSIFICATION,/*    * Integer value was interpreted to timestamp inconsistently in milliseconds comparing   * to float/double in seconds. Since the issue exists for a long time and some users may   * use in such inconsistent way use the following flag to keep backward compatible.   * If the flag is set to false integer value is interpreted as timestamp in milliseconds;   * otherwise it's interpreted as timestamp in seconds.    */
Hive,WITHOUT_CLASSIFICATION,//  ... 
Hive,WITHOUT_CLASSIFICATION,/*        * a mouthful but safe: - a QB is guaranteed to have atleast 1       * destination - we don't support multi insert so picking the first dest.        */
Hive,WITHOUT_CLASSIFICATION,//  Adding oracle jdbc driver if exists 
Hive,WITHOUT_CLASSIFICATION,// c14Value = (Map<??>) rowValues[13];  assertEquals(2 c14Value.size());  Map<??> mapVal = (Map<??>) c14Value.get(Integer.valueOf(1));  assertEquals(2 mapVal.size());  assertEquals(Integer.valueOf(12) mapVal.get(Integer.valueOf(11)));  assertEquals(Integer.valueOf(14) mapVal.get(Integer.valueOf(13)));  mapVal = (Map<??>) c14Value.get(Integer.valueOf(2));  assertEquals(1 mapVal.size());  assertEquals(Integer.valueOf(22) mapVal.get(Integer.valueOf(21))); 
Hive,WITHOUT_CLASSIFICATION,//  Ensure only one final event is ever sent. 
Hive,WITHOUT_CLASSIFICATION,//  Notify any queries waiting on this cacheEntry to become valid. 
Hive,WITHOUT_CLASSIFICATION,//  looks like owner is an unsupported type 
Hive,WITHOUT_CLASSIFICATION,//  Verify if drop partition on a non-existing partition is idempotent and just a noop. 
Hive,WITHOUT_CLASSIFICATION,//  If we get to here we know that we've archived the partition files but   they may be in the original partition location or in the intermediate   original dir. 
Hive,WITHOUT_CLASSIFICATION,//  Add NOT NULL constraints 
Hive,WITHOUT_CLASSIFICATION,//  Has to use full name to make sure it does not conflict with   org.apache.commons.lang.StringUtils 
Hive,WITHOUT_CLASSIFICATION,// Use of ToolRunner "-files" option could be considered here 
Hive,WITHOUT_CLASSIFICATION,/*    * build   *     ^(TOK_INSERT   *         ^(TOK_DESTINATION...)   *      )    */
Hive,WITHOUT_CLASSIFICATION,//  Continue with next table 
Hive,WITHOUT_CLASSIFICATION,/*    * Return the maximum absolute decimal64 value for a precision.    */
Hive,WITHOUT_CLASSIFICATION,//  Generate the columns according to the column mapping provided   Note: The generated column names are same as the   family_name.qualifier_name. If the qualifier   name is null each column is familyname_col[i] where i is the index of   the column ranging   from 0 to n-1 where n is the size of the column mapping. The filter   function removes any   special characters other than alphabets and numbers from the column   family and qualifier name   as the only special character allowed in a column name is "_" which is   used as a separator   between the column family and qualifier name. 
Hive,WITHOUT_CLASSIFICATION,//  set first argument to IF -- boolean flag 
Hive,WITHOUT_CLASSIFICATION,//  CLI 
Hive,WITHOUT_CLASSIFICATION,//  5 workers to run getReflectionObjectInspector concurrently 
Hive,WITHOUT_CLASSIFICATION,//  Now compact 
Hive,WITHOUT_CLASSIFICATION,//  check if the pruner only contains partition columns 
Hive,WITHOUT_CLASSIFICATION,//  No need for overflow checks assume selectivity is always <= 1.0 
Hive,WITHOUT_CLASSIFICATION,//  if the union is the first time seen set current task to GenMRUnionCtx 
Hive,WITHOUT_CLASSIFICATION,//  Requesting less partitions than allowed should work 
Hive,WITHOUT_CLASSIFICATION,//  position the cursor to line 0 
Hive,WITHOUT_CLASSIFICATION,//     props.put(Constants.SERIALIZATION_NULL_FORMAT "\\N");      props.put(Constants.SERIALIZATION_FORMAT "1"); 
Hive,WITHOUT_CLASSIFICATION,//  No need to execute at this stage 
Hive,WITHOUT_CLASSIFICATION,//  It can happen that although there're some partitions in memory but their sizes are all 0. 
Hive,WITHOUT_CLASSIFICATION,//  The join key is a table column. Create the ExprNodeDesc based on this column. 
Hive,WITHOUT_CLASSIFICATION,//  4. Result 
Hive,WITHOUT_CLASSIFICATION,//  The dispatcher fires the processor corresponding to the closest matching 
Hive,WITHOUT_CLASSIFICATION,//  We create a new sort operator on the corresponding input 
Hive,WITHOUT_CLASSIFICATION,//  If they set ifNotExists check for existence first and bail if it exists.  This is 
Hive,WITHOUT_CLASSIFICATION,//  return table name for column name if no column has been specified. 
Hive,WITHOUT_CLASSIFICATION,//  HIVE-5336. Re-number the position after remove such that:   (1) getPosition on a column always returns a value between ..schema.size()-1 
Hive,WITHOUT_CLASSIFICATION,// we will create the folder if it does not exist. 
Hive,WITHOUT_CLASSIFICATION,/* (can't push predicate to 'delete' delta)    * if we were to push to 'delete' delta we'd filter out all rows since the 'row' is always NULL for    * delete events and we'd produce data as if the delete never happened */
Hive,WITHOUT_CLASSIFICATION,//  set the timezone of the object mapper 
Hive,WITHOUT_CLASSIFICATION,//  append the third group within pattern: "}" 
Hive,WITHOUT_CLASSIFICATION,//  We can just restart the session if we have received one. 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) CommaOrSemicolon  */
Hive,WITHOUT_CLASSIFICATION,//  handle file format check for table level 
Hive,WITHOUT_CLASSIFICATION,//  Do implicit conversion accepting the source type and putting it in the same   target type ColumnVector type. 
Hive,WITHOUT_CLASSIFICATION,//  Safety limit for potential list bugs. 
Hive,WITHOUT_CLASSIFICATION,//  Look for tables but do not find any 
Hive,WITHOUT_CLASSIFICATION,//  operator we can use the same OI. 
Hive,WITHOUT_CLASSIFICATION,/*       End of additional steps     */
Hive,WITHOUT_CLASSIFICATION,//  Overwhelmingly executes once or maybe twice (replacing stale value). 
Hive,WITHOUT_CLASSIFICATION,//  We store CHAR type stripped of pads. 
Hive,WITHOUT_CLASSIFICATION,// skip this and rest cmds in the line 
Hive,WITHOUT_CLASSIFICATION,/*    *  The algorithm looks at all the mapjoins in the operator pipeline until   *  it hits RS Op and for each mapjoin examines if it has paralllel semijoin   *  edge or dynamic partition pruning.    */
Hive,WITHOUT_CLASSIFICATION,//  run the optimizations that use stats for optimization 
Hive,WITHOUT_CLASSIFICATION,//  Consolidation for outer joins 
Hive,WITHOUT_CLASSIFICATION,//  date 
Hive,WITHOUT_CLASSIFICATION,//  Max time when waiting for write locks on node list 
Hive,WITHOUT_CLASSIFICATION,//  Random batchSize unique ordered integers of 1024 (VectorizedRowBatch.DEFAULT_SIZE) indices.   This could be smarter... 
Hive,WITHOUT_CLASSIFICATION,//  Give it a pass. Optionally have LiteralDelegate provide a getLiteralClass() to check. 
Hive,WITHOUT_CLASSIFICATION,//  This is not the datanucleus id but the id assigned by the sequence 
Hive,WITHOUT_CLASSIFICATION,//  Preserve interrupt status 
Hive,WITHOUT_CLASSIFICATION,//  Note: columnIds below makes additional changes for ACID. Don't use this var directly. 
Hive,WITHOUT_CLASSIFICATION,//  Basic case 
Hive,WITHOUT_CLASSIFICATION,//  we skip default directory only if all value is false 
Hive,WITHOUT_CLASSIFICATION,//  Check if the metastore key is set first 
Hive,WITHOUT_CLASSIFICATION,//  Inputs are not the same bail out 
Hive,WITHOUT_CLASSIFICATION,//  time 
Hive,WITHOUT_CLASSIFICATION,//  If we are only processing a PARTITION BY reset our evaluators. 
Hive,WITHOUT_CLASSIFICATION,//  The value is before the value record offset.  Make byte segment reference absolute. 
Hive,WITHOUT_CLASSIFICATION,/*    * For now exclude CHAR until we determine why there is a difference (blank padding)   * serializing with LazyBinarySerializeWrite and the regular SerDe...    */
Hive,WITHOUT_CLASSIFICATION,//  SKEWED_COL_NAMES 
Hive,WITHOUT_CLASSIFICATION,//  10. Run rule to fix windowing issue when it is done over 
Hive,WITHOUT_CLASSIFICATION,//  Bail out if it is not enabled for rewriting 
Hive,WITHOUT_CLASSIFICATION,//  merging from 'target'(inner) to 'node'(outer) 
Hive,WITHOUT_CLASSIFICATION,//  LinkedHashMap to provide the same iteration order when selecting a random host. 
Hive,WITHOUT_CLASSIFICATION,//  found the class so this would be hadoop version 2.4 or newer (See   HADOOP-10221 HADOOP-10451) 
Hive,WITHOUT_CLASSIFICATION,//  The object for storing row data 
Hive,WITHOUT_CLASSIFICATION,//  the time has come 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   required   required   required   required 
Hive,WITHOUT_CLASSIFICATION,/*  Backward-compatibility interface for the case where there is no explicit   * name for the function.    */
Hive,WITHOUT_CLASSIFICATION,//  The object is reused during evaluating make a copy here 
Hive,WITHOUT_CLASSIFICATION,// this exception indicates that a {@code record} could not be parsed and the  caller can decide whether to drop it or send it to dead letter queue.  rolling back the txn and retrying won't help since the tuple will be exactly the same  when it's replayed. 
Hive,WITHOUT_CLASSIFICATION,//  nulls on left no nulls on right 
Hive,WITHOUT_CLASSIFICATION,//  Drop first and then create 
Hive,WITHOUT_CLASSIFICATION,//  set result to x / p (the quotient) 
Hive,WITHOUT_CLASSIFICATION,/*    * Multiple file sink descriptors are linked.   * Use the task created by the first linked file descriptor    */
Hive,WITHOUT_CLASSIFICATION,//  The row consists of some string columns some Array<Array<int> > columns. 
Hive,WITHOUT_CLASSIFICATION,//  The type info of each column being assigned. 
Hive,WITHOUT_CLASSIFICATION,//  remove values in key exprs   schema for value is already fixed in MapJoinProcessor#convertJoinOpMapJoinOp 
Hive,WITHOUT_CLASSIFICATION,/*      * When we have DECIMAL_64 as the input parameter then we have to see if there is a special     * vector UDAF for it.  If not we will need to convert the input parameter.      */
Hive,WITHOUT_CLASSIFICATION,//        Filter.g stuff. That way this method and ...ByFilter would just be merged. 
Hive,WITHOUT_CLASSIFICATION,//  there is only one FK 
Hive,WITHOUT_CLASSIFICATION,//  set() will only allocate memory if the buffer of result is smaller than 
Hive,WITHOUT_CLASSIFICATION,//  skip c19 since not selected by query 
Hive,WITHOUT_CLASSIFICATION,//  verification passed - encode the reply 
Hive,WITHOUT_CLASSIFICATION,//  Nothing to find for this type. 
Hive,WITHOUT_CLASSIFICATION,//  Even if no reduction let's still test the original   predicate to see if it was already a constant   in which case we don't need any runtime decision 
Hive,WITHOUT_CLASSIFICATION,//  Zookeeper related configs 
Hive,WITHOUT_CLASSIFICATION,//  2. Get Hive Aggregate Info 
Hive,WITHOUT_CLASSIFICATION,//  For each entry in dynamic-multi-dimension collection.   Retrieve skewed column.   Retrieve skewed   map. 
Hive,WITHOUT_CLASSIFICATION,//  compose file text: 
Hive,WITHOUT_CLASSIFICATION,//  Determine the default encoding type (specified on the table or the global default   if none was provided) 
Hive,WITHOUT_CLASSIFICATION,//  Add constraints.   We need not do a deep retrieval of the Table Column Descriptor while persisting the   constraints since this transaction involving create table is not yet committed. 
Hive,WITHOUT_CLASSIFICATION,//  Status has not changed continue waiting. 
Hive,WITHOUT_CLASSIFICATION,//  Since we have done an exact match on TS-SEL-GBY-RS-GBY-(SEL)-FS 
Hive,WITHOUT_CLASSIFICATION,//  Table operations. 
Hive,WITHOUT_CLASSIFICATION,//  We don't want that. 
Hive,WITHOUT_CLASSIFICATION,//  field to look for the record identifier in   field inside recId to look for row id in   field inside recId to look for original write id in   field inside recId to look for bucket in   OI for the original row   OI for the record identifier struct   OI for the long row id inside the recordIdentifier   OI for the original write id inside the record   identifer 
Hive,WITHOUT_CLASSIFICATION,//  push down current ppd context to newly added filter 
Hive,WITHOUT_CLASSIFICATION,//  data 
Hive,WITHOUT_CLASSIFICATION,//  granularity 
Hive,WITHOUT_CLASSIFICATION,//  string length should work after readFields() 
Hive,WITHOUT_CLASSIFICATION,//  set to min possible value 
Hive,WITHOUT_CLASSIFICATION,//  If a operator wants to do some work at the end of a group 
Hive,WITHOUT_CLASSIFICATION,//  Move clock forward and request a task at p=1 
Hive,WITHOUT_CLASSIFICATION,//  Get outputFieldOIs 
Hive,WITHOUT_CLASSIFICATION,//  For column to column only we toss in date and interval_year_month. 
Hive,WITHOUT_CLASSIFICATION,//  Verify if create table is not called on table t1 but called for t2 and t3. 
Hive,WITHOUT_CLASSIFICATION,//  is not known estimate that based on the number of entries 
Hive,WITHOUT_CLASSIFICATION,//  Convert the stub from the configuration back into a normal Token 
Hive,WITHOUT_CLASSIFICATION,// add props from params set in table schema 
Hive,WITHOUT_CLASSIFICATION,//  This has to be called before initializing the instance of RawStore 
Hive,WITHOUT_CLASSIFICATION,//  We should not use this optimization if sorted dynamic partition optimizer is used 
Hive,WITHOUT_CLASSIFICATION,//  A Statement#execute after ResultSet#close should be fine too 
Hive,WITHOUT_CLASSIFICATION,//  first get the columns in named columns 
Hive,WITHOUT_CLASSIFICATION,//  2. Then update pool allocations. 
Hive,WITHOUT_CLASSIFICATION,//  Format the row format statement 
Hive,WITHOUT_CLASSIFICATION,//  There should be 2 original bucket files (000000_0 and 000001_0) plus one delta directory   and one delete_delta directory. When split-update is enabled an update event is split into   a combination of delete and insert that generates the delete_delta directory.   The delta directory should also have 2 bucket files (bucket_00000 and bucket_00001) 
Hive,WITHOUT_CLASSIFICATION,//  10000 bytes per stripe   1024 bytes per split 
Hive,WITHOUT_CLASSIFICATION,/*    * if the given filterCondn refers to only 1 table alias in the QBJoinTree   * we return that alias's position. Otherwise we return -1    */
Hive,WITHOUT_CLASSIFICATION,//  Check there are no compactions requests left. 
Hive,WITHOUT_CLASSIFICATION,//  I64_VAL 
Hive,WITHOUT_CLASSIFICATION,//  pre-calculated offset values for each alias 
Hive,WITHOUT_CLASSIFICATION,//  is used 
Hive,WITHOUT_CLASSIFICATION,// skip skipSize rows of batch 
Hive,WITHOUT_CLASSIFICATION,//  sparse map. 
Hive,WITHOUT_CLASSIFICATION,//  Erase both headers of the blocks to merge. 
Hive,WITHOUT_CLASSIFICATION,//  Given the previous range and the current range calculate the new sum   from the previous sum and the difference to save the computation. 
Hive,WITHOUT_CLASSIFICATION,//  Literal bigint. 
Hive,WITHOUT_CLASSIFICATION,//  A list of alrady loaded containers   Number of partitions each table should have   The partition to be spilled next 
Hive,WITHOUT_CLASSIFICATION,//  Configure the AuthFilter with the Kerberos params iff security 
Hive,WITHOUT_CLASSIFICATION,//  Converts amt days to milliseconds 
Hive,WITHOUT_CLASSIFICATION,//  E.E: Lock we are examining is exclusive 
Hive,WITHOUT_CLASSIFICATION,//  Remove the proxy privilege and the auth should fail (in reality the proxy setting should not be changed on the fly) 
Hive,WITHOUT_CLASSIFICATION,//  current transaction 
Hive,WITHOUT_CLASSIFICATION,//  Create schema with a serde then remap it 
Hive,WITHOUT_CLASSIFICATION,//  scalar/scalar 
Hive,WITHOUT_CLASSIFICATION,//  1. Recompose filter possibly by pulling out common elements from DNF 
Hive,WITHOUT_CLASSIFICATION,//  Parse out words in the sentence 
Hive,WITHOUT_CLASSIFICATION,//  constructing the default MapredWork 
Hive,WITHOUT_CLASSIFICATION,// teseted on Oracle Database 11g Express Edition Release 11.2.0.2.0 - 64bit Production 
Hive,WITHOUT_CLASSIFICATION,//  No escaping. 
Hive,WITHOUT_CLASSIFICATION,/*    * TODO: expose this as an operation to client.  Useful for streaming API to abort all remaining   * trasnactions in a batch on IOExceptions.   * Caller must rollback the transaction if not all transactions were aborted since this will not   * attempt to delete associated locks in this case.   *   * @param dbConn An active connection   * @param txnids list of transactions to abort   * @param max_heartbeat value used by {@link #performTimeOuts()} to ensure this doesn't Abort txn which were   *                      hearbetated after #performTimeOuts() select and this operation.   * @param isStrict true for strict mode false for best-effort mode.   *                 In strict mode if all txns are not successfully aborted then the count of   *                 updated ones will be returned and the caller will roll back.   *                 In best-effort mode we will ignore that fact and continue deleting the locks.   * @return Number of aborted transactions   * @throws SQLException    */
Hive,WITHOUT_CLASSIFICATION,//  retrieve enabled NOT NULL constraint from metastore 
Hive,WITHOUT_CLASSIFICATION,//  18 digits   20 digits 
Hive,WITHOUT_CLASSIFICATION,//  describe/explain/show commands 
Hive,WITHOUT_CLASSIFICATION,//  Repeating null value 
Hive,WITHOUT_CLASSIFICATION,// add another column 
Hive,WITHOUT_CLASSIFICATION,//  We need to update the status of the creation signature 
Hive,WITHOUT_CLASSIFICATION,//  6. Apply Partition Pruning 
Hive,WITHOUT_CLASSIFICATION,//  operations that require insert/delete privileges 
Hive,WITHOUT_CLASSIFICATION,//  Evaluate the value 
Hive,WITHOUT_CLASSIFICATION,//  get StructFields for bucketed cols 
Hive,WITHOUT_CLASSIFICATION,//  See SessionInitContext javadoc. 
Hive,WITHOUT_CLASSIFICATION,//  only user belonging to admin role can create new roles. 
Hive,WITHOUT_CLASSIFICATION,/*  For the case when the output can have null values follow     * the convention that the data values must be 1 for long and     * NaN for double. This is to prevent possible later zero-divide errors     * in complex arithmetic expressions like col2 / (col1 - 1)     * in the case when some col1 entries are null.      */
Hive,WITHOUT_CLASSIFICATION,//  insert the new task between current task and its child 
Hive,WITHOUT_CLASSIFICATION,//  Tracks running and queued (allocated) tasks. Cleared after a task completes. 
Hive,WITHOUT_CLASSIFICATION,//  Matches only ForwardOperators which are reducers and are followed by GroupByOperators 
Hive,WITHOUT_CLASSIFICATION,//  Process the row batch that has less than DEFAULT_SIZE rows 
Hive,WITHOUT_CLASSIFICATION,//  add self to the end of the queue 
Hive,WITHOUT_CLASSIFICATION,//  For each task completion event get the associated task id job id 
Hive,WITHOUT_CLASSIFICATION,/*  vContextEnvironment  */
Hive,WITHOUT_CLASSIFICATION,//  just last one. 
Hive,WITHOUT_CLASSIFICATION,//  Filtering for outer join just removes rows available for hash table matching. 
Hive,WITHOUT_CLASSIFICATION,//  -hiveconf x=y 
Hive,WITHOUT_CLASSIFICATION,//  Test basic assign to vector. 
Hive,WITHOUT_CLASSIFICATION,//  in all the other cases we can not merge 
Hive,WITHOUT_CLASSIFICATION,//  This will be true if a node was examined by the Vectorizer class. 
Hive,WITHOUT_CLASSIFICATION,//  The only allowed non-overlapping option is extra bytes at the end. 
Hive,WITHOUT_CLASSIFICATION,//  normal. Check stopTimer() works. 
Hive,WITHOUT_CLASSIFICATION,//  unsupported type 
Hive,WITHOUT_CLASSIFICATION,//  Pick random avail port 
Hive,WITHOUT_CLASSIFICATION,//  The JDOException or the Nucleus Exception may be wrapped further in a MetaException 
Hive,WITHOUT_CLASSIFICATION,//  Processor creation. 
Hive,WITHOUT_CLASSIFICATION,//  GBYRSGBYRSGBY... (top to bottom) 
Hive,WITHOUT_CLASSIFICATION,//  if not already a part of the group-by 
Hive,WITHOUT_CLASSIFICATION,//  Tests for the Partition add_partition(Partition partition) method 
Hive,WITHOUT_CLASSIFICATION,//  update the subcache 
Hive,WITHOUT_CLASSIFICATION,//  This get should fail because its variance ((10-0)/10) is way past MAX_VARIANCE (0.5) 
Hive,WITHOUT_CLASSIFICATION,//  strict admin check -   allows ONLY if hadoop.security.instrumentation.requires.admin is set to true   when hadoop.security.instrumentation.requires.admin is set to true checks if hadoop.security.authorization   is true and if the logged in user (via PAM or SPNEGO + kerberos) is in hive.users.in.admin.role list 
Hive,WITHOUT_CLASSIFICATION,// look for the " nonEscapedSemiColon " in the query text not the table name which comes  in the result 
Hive,WITHOUT_CLASSIFICATION,//  process method call. 
Hive,WITHOUT_CLASSIFICATION,//  optional string user = 1; 
Hive,WITHOUT_CLASSIFICATION,//  Drop db "testDatabaseOps1" via ObjectStore 
Hive,WITHOUT_CLASSIFICATION,//  Right side 
Hive,WITHOUT_CLASSIFICATION,//  Create the column expr map 
Hive,WITHOUT_CLASSIFICATION,//  First $ separated substring will be txnId and the rest are ValidReaderWriteIdList 
Hive,WITHOUT_CLASSIFICATION,//  Create the routes group 
Hive,WITHOUT_CLASSIFICATION,//   @Ignore("not needed but useful for testing") 
Hive,WITHOUT_CLASSIFICATION,//  PK_NAME 
Hive,WITHOUT_CLASSIFICATION,//  Scale down no rounding to clear fraction. 
Hive,WITHOUT_CLASSIFICATION,//  2^62*2^63 
Hive,WITHOUT_CLASSIFICATION,//  exclusive 
Hive,WITHOUT_CLASSIFICATION,//  Set that as the row id in the mutation 
Hive,WITHOUT_CLASSIFICATION,//  The output* arrays start at index 0 for output evaluator aggregations. 
Hive,WITHOUT_CLASSIFICATION,//  We need a pointer to the hash map since this class must be static to support having 
Hive,WITHOUT_CLASSIFICATION,//  base object inspector   start column number   number of columns 
Hive,WITHOUT_CLASSIFICATION,//  Complete first request. Second pending request should go through. 
Hive,WITHOUT_CLASSIFICATION,//  Alter database set DB property 
Hive,WITHOUT_CLASSIFICATION,//  add selectOp to match the schema 
Hive,WITHOUT_CLASSIFICATION,//  get names of all tables under this dbName 
Hive,WITHOUT_CLASSIFICATION,//  Populate semijoin select if needed 
Hive,WITHOUT_CLASSIFICATION,//  hack off the last word and try again 
Hive,WITHOUT_CLASSIFICATION,//  move to the next root node 
Hive,WITHOUT_CLASSIFICATION,//  use LinkedHashMap<String Operator<? extends OperatorDesc>>   getAliasToWork()   should not apply this for non-native table 
Hive,WITHOUT_CLASSIFICATION,//  Check to see if the directory already exists before calling   mkdirs() because if the file system is read-only mkdirs will   throw an exception even if the directory already exists. 
Hive,WITHOUT_CLASSIFICATION,//  Copy the source files to cmroot. As the client will move the source files to another   location we should make a copy of the files to cmroot instead of moving it. 
Hive,WITHOUT_CLASSIFICATION,//  add/override properties found from hive-site with user-specific properties 
Hive,WITHOUT_CLASSIFICATION,//  Should only be used if n > 0. 
Hive,WITHOUT_CLASSIFICATION,//  There's usually nothing to escape so we will be optimistic. 
Hive,WITHOUT_CLASSIFICATION,//  In order to fix HIVE-16948 
Hive,WITHOUT_CLASSIFICATION,//  Test that timestamp arithmetic is done in UTC and then converted back to local timezone 
Hive,WITHOUT_CLASSIFICATION,//  When we have split-update and there are two kinds of delta directories-   the delta_x_y/ directory one which has only insert events and   the delete_delta_x_y/ directory which has only the delete events.   The clever thing about this kind of splitting is that everything in the delta_x_y/   directory can be processed as base files. However this is left out currently   as an improvement for the future. 
Hive,WITHOUT_CLASSIFICATION,//       LOG.info("discover ptns called"); 
Hive,WITHOUT_CLASSIFICATION,//  case the HCAT_KEY_TOKEN_SIGNATURE property in the conf will not be set 
Hive,WITHOUT_CLASSIFICATION,//  so exit the loop and check next lock 
Hive,WITHOUT_CLASSIFICATION,//  Let YARN pick the queue name if it isn't provided in hive-site or via the command-line 
Hive,WITHOUT_CLASSIFICATION,//  If there's no authentication then directly substitute the user 
Hive,WITHOUT_CLASSIFICATION,//  The joins have been automatically converted to map-joins.   However if the joins were converted to sort-merge joins automatically   they should also be tried as map-joins. 
Hive,WITHOUT_CLASSIFICATION,//  Create a single insert delta with 150000 rows with 15000 rowIds per original transaction id. 
Hive,WITHOUT_CLASSIFICATION,//  because inverse is scaled 2^128 
Hive,WITHOUT_CLASSIFICATION,//  would still be empty because no stats are actually populated. 
Hive,WITHOUT_CLASSIFICATION,//  LazySimple seems to throw away everything but \n and \r. 
Hive,WITHOUT_CLASSIFICATION,//  Queries rejected from being cached because they exceeded the max cache entry size. 
Hive,WITHOUT_CLASSIFICATION,//  Just retrieve value from conf 
Hive,WITHOUT_CLASSIFICATION,//  HYBRID strategy 
Hive,WITHOUT_CLASSIFICATION,//  don't re-display warnings we have already seen 
Hive,WITHOUT_CLASSIFICATION,//  line 1:14 Table not found table_name 
Hive,WITHOUT_CLASSIFICATION,//  Save to usedCacheEntry to ensure reader is released after query. 
Hive,WITHOUT_CLASSIFICATION,//  All the data comes from disk. The reader may have split it into multiple slices.   It is also possible there's no data in the file. 
Hive,WITHOUT_CLASSIFICATION,//  ensure that the table properties were copied 
Hive,WITHOUT_CLASSIFICATION,//  We should initialize the SerDe with the TypeInfo when available. 
Hive,WITHOUT_CLASSIFICATION,//  There can be up to 5e-16 error 
Hive,WITHOUT_CLASSIFICATION,//  we are in unsecure mode. 
Hive,WITHOUT_CLASSIFICATION,//  AM sent a shouldDie=true 
Hive,WITHOUT_CLASSIFICATION,//  -Dtest.hms.client.configs=/tmp/conf/core-site.xml/tmp/conf/hive-site.xml 
Hive,WITHOUT_CLASSIFICATION,//  All children of RS are descendants 
Hive,WITHOUT_CLASSIFICATION,//  check bucket/sort cols 
Hive,WITHOUT_CLASSIFICATION,//  the first time we see a big key. If this key is not in the last   table (the last table can always be streamed) we define that we get 
Hive,WITHOUT_CLASSIFICATION,//  Assumes value is written after key. 
Hive,WITHOUT_CLASSIFICATION,//  Partition-keys added in order. 
Hive,WITHOUT_CLASSIFICATION,// result 
Hive,WITHOUT_CLASSIFICATION,//  For Map check for virtual columns. 
Hive,WITHOUT_CLASSIFICATION,//  trailing zeroes (or rounding). 
Hive,WITHOUT_CLASSIFICATION,//  ConcurrentHashMap does not allow null - use a substitute value. 
Hive,WITHOUT_CLASSIFICATION,//  Exchange multiple partitions using partial partition-spec (only one partition column) 
Hive,WITHOUT_CLASSIFICATION,//  get tag value from object (last of list) 
Hive,WITHOUT_CLASSIFICATION,//  If we reached here either :   1. patternWithWildCardChar and patternWithoutWildCardChar are both nulls.   2. patternWithWildCardChar and patternWithoutWildCardChar are both not nulls.   This is an internal error and we should not let this happen so throw an exception. 
Hive,WITHOUT_CLASSIFICATION,// create 1 row in a file 000001_0_copy2 (and empty 000000_0_copy2?) 
Hive,WITHOUT_CLASSIFICATION,//  case the statement is an INSERT 
Hive,WITHOUT_CLASSIFICATION,//  3) Keep track of colname-to-posmap && RR for new op 
Hive,WITHOUT_CLASSIFICATION,//  column node 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hadoop.mapreduce.InputSplit#getLength()    */
Hive,WITHOUT_CLASSIFICATION,/*    * This method looks in locations specified above and returns the first location where the file   * exists. If the file does not exist in any one of the locations it returns null    */
Hive,WITHOUT_CLASSIFICATION,//  lists are compatible if and only-if the elements are compatible 
Hive,WITHOUT_CLASSIFICATION,//  All inputs of this UnionOperator are in the same Reducer.   We do not need to break the operator tree. 
Hive,WITHOUT_CLASSIFICATION,//  we've seen this terminal before and have created a union work object.   just need to add this work to it. There will be no children of this one   since we've passed this operator before. 
Hive,WITHOUT_CLASSIFICATION,//  noop 
Hive,WITHOUT_CLASSIFICATION,//  See if we need to kill some sessions because the pool was resized down while   a bunch of sessions were outstanding. See also deltaRemaining javadoc. 
Hive,WITHOUT_CLASSIFICATION,//  internal variable 
Hive,WITHOUT_CLASSIFICATION,//  test first IF argument repeating 
Hive,WITHOUT_CLASSIFICATION,//  Generate the signer with secret. 
Hive,WITHOUT_CLASSIFICATION,//  check keys are copied from token store when token is loaded 
Hive,WITHOUT_CLASSIFICATION,//  Null for default partition. 
Hive,WITHOUT_CLASSIFICATION,//  in subquery case tmp may be from outside. 
Hive,WITHOUT_CLASSIFICATION,//  this position in parent is a constant   now propagate the constant from the parent to the child 
Hive,WITHOUT_CLASSIFICATION,//  Multi-byte truncation. 
Hive,WITHOUT_CLASSIFICATION,//  get a record reader for the idx-th chunk 
Hive,WITHOUT_CLASSIFICATION,// make it looks like 31-32 has been compacted but not cleaned 
Hive,WITHOUT_CLASSIFICATION,// hive conf option --hiveconf 
Hive,WITHOUT_CLASSIFICATION,//  GLOBAL - all pools inherit 
Hive,WITHOUT_CLASSIFICATION,//  This file descriptor is linked to other file descriptors.   One use case is that a union->select (star)->file sink is broken down.   For eg: consider a query like:   select * from (subq1 union all subq2)x;   where subq1 or subq2 involves a map-reduce job.   It is broken into two independent queries involving subq1 and subq2 directly and   the sub-queries write to sub-directories of a common directory. So the file sink 
Hive,WITHOUT_CLASSIFICATION,// call the appropriate hive authorizer function 
Hive,WITHOUT_CLASSIFICATION,// test content summary 
Hive,WITHOUT_CLASSIFICATION,//  Task metrics. 
Hive,WITHOUT_CLASSIFICATION,//  When sync is called it will return 100 the value signaling the end of the file this should   result in a call to sync to the beginning of the block it was searching [50 100] and it   should continue normally 
Hive,WITHOUT_CLASSIFICATION,//  Validate the update. 
Hive,WITHOUT_CLASSIFICATION,//  closing of open scope should be ok: 
Hive,WITHOUT_CLASSIFICATION,// Hive Stuff 
Hive,WITHOUT_CLASSIFICATION,//  When deal with big data the VectorizedRowBatch will be used for the different file split   to cache the data. Here is the situation: the first split only have 100 rows   and VectorizedRowBatch cache them meanwhile the size of VectorizedRowBatch will be   updated to 100. The following code is to simulate the size change but there will be no   ArrayIndexOutOfBoundsException when process the next split which has more than 100 rows. 
Hive,WITHOUT_CLASSIFICATION,//  Ordering of constant and column in expression is important in correct range generation 
Hive,WITHOUT_CLASSIFICATION,//  ALTER VIEW AS SELECT requires the view must exist 
Hive,WITHOUT_CLASSIFICATION,//  Instantiate a SerializationContext which this will use to lookup the   Serialization class and the   actual class being deserialized 
Hive,WITHOUT_CLASSIFICATION,/*  grant priv required  */
Hive,WITHOUT_CLASSIFICATION,/*    * These members have information for data type conversion.   * Not defined if there is no conversion.    */
Hive,WITHOUT_CLASSIFICATION,//  Format the serde statement 
Hive,WITHOUT_CLASSIFICATION,//  4. We create the Filter/Join with the new condition 
Hive,WITHOUT_CLASSIFICATION,//  ok 
Hive,WITHOUT_CLASSIFICATION,//  Lets split up 64-bit hashcode into two 32-bit hash codes and employ the technique mentioned   in the above paper 
Hive,WITHOUT_CLASSIFICATION,//  Replacing it directly in the pool should unblock get. 
Hive,WITHOUT_CLASSIFICATION,//  If there is a hint and no operator is removed then throw error 
Hive,WITHOUT_CLASSIFICATION,/*      * for Select Distinct Queries we don't move any aggregations.      */
Hive,WITHOUT_CLASSIFICATION,//  Trim blanks because OldHiveDecimal did... 
Hive,WITHOUT_CLASSIFICATION,//  create table will start and coomit the transaction 
Hive,WITHOUT_CLASSIFICATION,//  optional .SignableVertexSpec vertex = 1; 
Hive,WITHOUT_CLASSIFICATION,//  BALLOT BOX WITH X U+2612 (3 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  uber > llap > container 
Hive,WITHOUT_CLASSIFICATION,//  Create a new FetchWork to reference the new cache location. 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   optional   optional   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  check if the old values are still there in HIVE_CONF_RESTRICTED_LIST 
Hive,WITHOUT_CLASSIFICATION,//  HIVE_SERVICE refers to a logical service name. For now hiveserver2 hostname will be   used to give service actions a name. This is used by kill query command so it can   be authorized specifically to a service if necessary. 
Hive,WITHOUT_CLASSIFICATION,//  Throw away extra if more than 9 decimal places 
Hive,WITHOUT_CLASSIFICATION,/*   * (non-Javadoc)  *  * @see  * org.apache.hadoop.hive.ql.security.authorization.HiveAuthorizationProvider  * #authorize(org.apache.hadoop.hive.metastore.api.Database  * org.apache.hadoop.hive.ql.security.authorization.Privilege[]  * org.apache.hadoop.hive.ql.security.authorization.Privilege[])   */
Hive,WITHOUT_CLASSIFICATION,//  Simulate SHOW LOCKS with different filter options 
Hive,WITHOUT_CLASSIFICATION,//  Answer must be 0 or 1 depending on relative magnitude   of dividend and divisor. 
Hive,WITHOUT_CLASSIFICATION,//  Inserted in sort order. Hence no explict sort. 
Hive,WITHOUT_CLASSIFICATION,//  re-set the static variables in HiveConf to default values 
Hive,WITHOUT_CLASSIFICATION,/*    * LONG.    */
Hive,WITHOUT_CLASSIFICATION,// for queries with a windowing expressions the selexpr may have a third child 
Hive,WITHOUT_CLASSIFICATION,//  more bits should be considered for finding q (longest zero runs)   set MSB to 1 
Hive,WITHOUT_CLASSIFICATION,//  Use Input class to read length. 
Hive,WITHOUT_CLASSIFICATION,//  1 sec is 0.000000373 months (1/2678400). 1 month is 31 days. 
Hive,WITHOUT_CLASSIFICATION,//  Carefully check the children to make sure they are Decimal64. 
Hive,WITHOUT_CLASSIFICATION,//  For unbucketed tables we have exactly 1 RecordUpdater (until HIVE-19208) for each AbstractRecordWriter which   ends up writing to a file bucket_000000.   See also {@link #getBucket(Object)} 
Hive,WITHOUT_CLASSIFICATION,//  Special handling of grouping function 
Hive,WITHOUT_CLASSIFICATION,//  Fraction digits from lower longword. 
Hive,WITHOUT_CLASSIFICATION,//  add element to ListColumnVector one by one 
Hive,WITHOUT_CLASSIFICATION,//  Use a final variable to properly parameterize the processVectorInspector closure. 
Hive,WITHOUT_CLASSIFICATION,//  null means don't return metadata; we'd need the array anyway for now. 
Hive,WITHOUT_CLASSIFICATION,//  if the colType is not the known type long double etc then get 
Hive,WITHOUT_CLASSIFICATION,//  The storage handler does not provide predicate decomposition   support so we'll implement the entire filter in Hive.  However   we still provide the full predicate to the storage handler in   case it wants to do any of its own prefiltering. 
Hive,WITHOUT_CLASSIFICATION,//  clone thread local file system statistics 
Hive,WITHOUT_CLASSIFICATION,//  out.writeInt(numberRows); 
Hive,WITHOUT_CLASSIFICATION,//  repeated .IOSpecProto output_specs = 11; 
Hive,WITHOUT_CLASSIFICATION,//  For ORC & Parquet all the following statements are the same   ANALYZE TABLE T [PARTITION (...)] COMPUTE STATISTICS   ANALYZE TABLE T [PARTITION (...)] COMPUTE STATISTICS noscan;   There will not be any Spark job above this task 
Hive,WITHOUT_CLASSIFICATION,//  the byte comparison is potentially expensive so is better to branch on null 
Hive,WITHOUT_CLASSIFICATION,//  We index the get requests to make sure there are no ordering artifacts when we requeue. 
Hive,WITHOUT_CLASSIFICATION,//  load the options first so we can override on the command line 
Hive,WITHOUT_CLASSIFICATION,//  Make a batch to test the trim functions. 
Hive,WITHOUT_CLASSIFICATION,//  kv7.txt KEYS 
Hive,WITHOUT_CLASSIFICATION,/*    * When no mapping is defined it is assumed that the hive column names are equivalent to the column names in the   * underlying table    */
Hive,WITHOUT_CLASSIFICATION,//  VALID_WRITE_IDLIST 
Hive,WITHOUT_CLASSIFICATION,//  if this is an update we need to skip the first col since it is row id 
Hive,WITHOUT_CLASSIFICATION,//  Marked as skipped previously. Don't bother processing the rest of the payload. 
Hive,WITHOUT_CLASSIFICATION,// getPos() should always return 0 
Hive,WITHOUT_CLASSIFICATION,//  Deserialize value into vector row columns. 
Hive,WITHOUT_CLASSIFICATION,//  Get our own connection to the database so we can get table and partition information. 
Hive,WITHOUT_CLASSIFICATION,//  Store arrayByteEnd+1 in startPosition[arrayLength]   so that we can use the same formula to compute the length of 
Hive,WITHOUT_CLASSIFICATION,//  Various helper methods. 
Hive,WITHOUT_CLASSIFICATION,//  Override the default delegation token lifetime for LLAP.   Also set all the necessary ZK settings to defaults and LLAP configs if not set. 
Hive,WITHOUT_CLASSIFICATION,//  Column will be removed from filter   Column will be removed from filter 
Hive,WITHOUT_CLASSIFICATION,//  if the running class was loaded directly (through eclipse) rather than through a 
Hive,WITHOUT_CLASSIFICATION,//  init 
Hive,WITHOUT_CLASSIFICATION,//  By setting the comparison to less the search should use the block [50 100] 
Hive,WITHOUT_CLASSIFICATION,//  HIVE-13704 states that we should use run() instead of execute() due to a hadoop known issue   added by HADOOP-10459 
Hive,WITHOUT_CLASSIFICATION,//  Test the idempotent behavior of DROP FUNCTION 
Hive,WITHOUT_CLASSIFICATION,//  note that we may have two or more duplicate partition names. 
Hive,WITHOUT_CLASSIFICATION,//        Not clear of ReplCopyWork should inherit from CopyWork. 
Hive,WITHOUT_CLASSIFICATION,//  not supported 
Hive,WITHOUT_CLASSIFICATION,//  [-v|--verbose] 
Hive,WITHOUT_CLASSIFICATION,//  Find the constant origin of a certain column if it is originated from a constant 
Hive,WITHOUT_CLASSIFICATION,//  SELECT count(*) FROM t). 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: here we should use the new partition predicate pushdown API to   get a list of pruned list 
Hive,WITHOUT_CLASSIFICATION,//  Required to check the original types manually as PrimitiveType.equals does not care about it 
Hive,WITHOUT_CLASSIFICATION,//  Ignore - this is expected. 
Hive,WITHOUT_CLASSIFICATION,//  that a new one gets created for the next query on the same AM. 
Hive,WITHOUT_CLASSIFICATION,/*    * Element for Key: row and byte[] x Hash Table: HashMap    */
Hive,WITHOUT_CLASSIFICATION,//  converted table 
Hive,WITHOUT_CLASSIFICATION,//  Skip trailing blank characters. 
Hive,WITHOUT_CLASSIFICATION,//  Merge numDistinctValue Estimators 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getRowId(java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,// it's set in parseRewrittenQuery() 
Hive,WITHOUT_CLASSIFICATION,//  Assume one separator (depth) needed. 
Hive,WITHOUT_CLASSIFICATION,//  Set OpTraits for dynamically partitioned hash join:   bucketColNames: Re-use previous joinOp's bucketColNames. Parent operators should be     reduce sink which should have bucket columns based on the join keys.   numBuckets: set to number of reducers   sortCols: This is an unsorted join - no sort cols 
Hive,WITHOUT_CLASSIFICATION,//  Finalize paths. 
Hive,WITHOUT_CLASSIFICATION,//  any file claim remain in trash would be granted 
Hive,WITHOUT_CLASSIFICATION,//  Need to preserve currentUser 
Hive,WITHOUT_CLASSIFICATION,//  The create time is set 
Hive,WITHOUT_CLASSIFICATION,//  Create a database and a table in that database.  Because the AlternateFailurePreListener is   being used each attempt to create something should require two calls by the RetryingHMSHandler 
Hive,WITHOUT_CLASSIFICATION,//  UNDONE: Fall through for these... they don't appear to be supported yet. 
Hive,WITHOUT_CLASSIFICATION,//  Whether there's any error occurred during query execution. Used for query lifetime hook. 
Hive,WITHOUT_CLASSIFICATION,//  Deserialize group key into vector row columns. 
Hive,WITHOUT_CLASSIFICATION,//  None are null so none are selected 
Hive,WITHOUT_CLASSIFICATION,//  Walk through all our inputs and set them to note that this read is part of an update or a 
Hive,WITHOUT_CLASSIFICATION,//  No check needed for single byte read. 
Hive,WITHOUT_CLASSIFICATION,//  Even if there are no results to move at least check that we have permission   to check the existence of zeroRowsPath or the read using the cache will fail. 
Hive,WITHOUT_CLASSIFICATION,//  Try to narrow type of constant 
Hive,WITHOUT_CLASSIFICATION,/*    * Responsible for the flow of rows through the PTF Chain.   * An Invocation wraps a TableFunction.   * The PTFOp hands the chain each row through the processRow call.   * It also notifies the chain of when a Partition starts/finishes.   *   * There are several combinations depending   * whether the TableFunction and its successor support Streaming or Batch mode.   *   * Combination 1: Streaming + Streaming   * - Start Partition: invoke startPartition on tabFn.   * - Process Row: invoke process Row on tabFn.   *   Any output rows hand to next tabFn in chain or forward to next Operator.   * - Finish Partition: invoke finishPartition on tabFn.   *   Any output rows hand to next tabFn in chain or forward to next Operator.   *   * Combination 2: Streaming + Batch   * same as Combination 1   *   * Combination 3: Batch + Batch   * - Start Partition: create or reset the Input Partition for the tabFn   *   caveat is: if prev is also batch and it is not providing an Output Iterator   *   then we can just use its Output Partition.   * - Process Row: collect row in Input Partition   * - Finish Partition : invoke evaluate on tabFn on Input Partition   *   If function gives an Output Partition: set it on next Invocation's Input Partition   *   If function gives an Output Iterator: iterate and call processRow on next Invocation.   *   For last Invocation in chain: forward rows to next Operator.   *   * Combination 3: Batch + Stream   * Similar to Combination 3 except Finish Partition behavior slightly different   * - Finish Partition : invoke evaluate on tabFn on Input Partition   *   iterate output rows: hand to next tabFn in chain or forward to next Operator.   *    */
Hive,WITHOUT_CLASSIFICATION,//  to allow for future ctor mutabulity in design 
Hive,WITHOUT_CLASSIFICATION,//  Column 0 
Hive,WITHOUT_CLASSIFICATION,//  Inside of a MR job we can pull out the actual properties 
Hive,WITHOUT_CLASSIFICATION,//  If we're here we want more events and either batchIter is null or batchIter 
Hive,WITHOUT_CLASSIFICATION,//  ignore.. provides invalid url sometimes intentionally 
Hive,WITHOUT_CLASSIFICATION,// add new column with cascade option 
Hive,WITHOUT_CLASSIFICATION,//  Intermittent failure 
Hive,WITHOUT_CLASSIFICATION,// if impersonation is turned on this called using the HiveSessionImplWithUGI  using sessionProxy. so the currentUser will be the impersonated user here eg. oozie  we cannot create a proxy user which represents Oozie's client user here since  we cannot authenticate it using Kerberos/Digest. We trust the user which opened  session using Kerberos in this case.  if impersonation is turned off the current user is Hive which can open 
Hive,WITHOUT_CLASSIFICATION,//  Ideally we'd want 1 worker to try for every slot; e.g. if there are 4 workers we want 3   to re-read i.e. probability of falling back = 0.75 or 1/4 < random([01)). However we   make it slightly more probable (2.0x) to avoid too much re-reading. This is hand-wavy. 
Hive,WITHOUT_CLASSIFICATION,//  Queue for disabled nodes. Nodes make it out of this queue when their expiration timeout is hit. 
Hive,WITHOUT_CLASSIFICATION,//  Look for functions but do not find any 
Hive,WITHOUT_CLASSIFICATION,//  return null if failed to find 
Hive,WITHOUT_CLASSIFICATION,//  The token is already removed. 
Hive,WITHOUT_CLASSIFICATION,//  Chooses a representative alias index and order to use as the String the first is used   because it is set in the constructor 
Hive,WITHOUT_CLASSIFICATION,/*  * Specialized class for doing a vectorized map join that is an inner join on a Single-Column Long * using a hash map.  */
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#createNClob()    */
Hive,WITHOUT_CLASSIFICATION,//  field within complex type 
Hive,WITHOUT_CLASSIFICATION,//  We never lose pool session so we should still be able to get. 
Hive,WITHOUT_CLASSIFICATION,//  need to compute the input size at runtime and select the biggest as   the big table. 
Hive,WITHOUT_CLASSIFICATION,/*    * Create a new type for handling precision conversions from Decimal -> Double/Float   *    * The type is only relevant to boxLiteral and all other functions treat it identically.    */
Hive,WITHOUT_CLASSIFICATION,//  We are looking based on the original FSOP so use the original path as is. 
Hive,WITHOUT_CLASSIFICATION,// now we have delta_0004_0004_0000 with delete events 
Hive,WITHOUT_CLASSIFICATION,//  this SEL is SEL(*)   for LV 
Hive,WITHOUT_CLASSIFICATION,/*  vectorization only works with struct object inspectors  */
Hive,WITHOUT_CLASSIFICATION,//  close them all 
Hive,WITHOUT_CLASSIFICATION,//  base file 
Hive,WITHOUT_CLASSIFICATION,//  for thrift connects 
Hive,WITHOUT_CLASSIFICATION,//  Init the list object inspector for handling partial aggregations 
Hive,WITHOUT_CLASSIFICATION,//  NUM_TRUES 
Hive,WITHOUT_CLASSIFICATION,//  real struct 
Hive,WITHOUT_CLASSIFICATION,/*  Pretty print the values  */
Hive,WITHOUT_CLASSIFICATION,//  Use modified portions of doFastScaleDown code here since we do not want to allocate a   temporary FastHiveDecimal object. 
Hive,WITHOUT_CLASSIFICATION,//  Exponential back-off for NDVs.   1) Descending order sort of NDVs   2) denominator = NDV1 * (NDV2 ^ (1/2)) * (NDV3 ^ (1/4))) * .... 
Hive,WITHOUT_CLASSIFICATION,//  Retrieve partitions. 
Hive,WITHOUT_CLASSIFICATION,//  This is only used by ORC to derive the structure. Most fields are unused. 
Hive,WITHOUT_CLASSIFICATION,//  Passing 0 for currentTxn means this validTxnList is not wrt to any txn 
Hive,WITHOUT_CLASSIFICATION,// if importing into existing transactional table or will create a new transactional table  (because Export was done from transactional table) need a writeId   Explain plan doesn't open a txn and hence no need to allocate write id. 
Hive,WITHOUT_CLASSIFICATION,//  snapshot of subset of wm tez session info for printing in events summary 
Hive,WITHOUT_CLASSIFICATION,//  As of now Hive Meta Store uses the same configuration as Hadoop SASL configuration 
Hive,WITHOUT_CLASSIFICATION,//  test rounding 
Hive,WITHOUT_CLASSIFICATION,//  Stats were available try to reduce 
Hive,WITHOUT_CLASSIFICATION,//  for casting floating point types to boolean 
Hive,WITHOUT_CLASSIFICATION,//  for set role NONE clear all roles for current session. 
Hive,WITHOUT_CLASSIFICATION,//  read the data if it isn't null 
Hive,WITHOUT_CLASSIFICATION,//  optional   optional   optional   optional   optional   optional   optional   optional   optional   optional   optional   optional   optional   optional   optional   optional   optional   optional   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  D5. Test remainder. Carry indicates result<0 therefore QH 1 too 
Hive,WITHOUT_CLASSIFICATION,//  all participating instances uses the same latch path and curator randomly chooses one instance to be leader   which can be verified via leaderLatch.hasLeadership() 
Hive,WITHOUT_CLASSIFICATION,//  generate struct for each of the given prefixes 
Hive,WITHOUT_CLASSIFICATION,//  Using the second table since a table called "test_table" exists in both databases 
Hive,WITHOUT_CLASSIFICATION,//  Note: Thrift returns an SSL socket that is already bound to the specified host:port   Therefore an open called on this would be a no-op later   Hence any TTransportException related to connecting with the peer are thrown here.   Bubbling them up the call hierarchy so that a retry can happen in openTransport   if dynamic service discovery is configured. 
Hive,WITHOUT_CLASSIFICATION,//  Registry uses ephemeral sequential znodes that are never updated as of now. 
Hive,WITHOUT_CLASSIFICATION,//  HIVE-5839 
Hive,WITHOUT_CLASSIFICATION,//        move the setupPool code to ctor. For now at least hasInitialSessions will be false. 
Hive,WITHOUT_CLASSIFICATION,//  GroupBy not distinct like disabling 
Hive,WITHOUT_CLASSIFICATION,//  first authorize the call 
Hive,WITHOUT_CLASSIFICATION,//  the required outputLength. 
Hive,WITHOUT_CLASSIFICATION,//  There can be atmost one element eligible to be converted to   metadata only 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getClob(java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  Otherwise return the row. 
Hive,WITHOUT_CLASSIFICATION,//  the columns in nonPartColIndxsThatRqrStats/nonPartColNamesThatRqrStats/hiveColStats   are in same order 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getInt(java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  ^(TOK_ALTERTABLE_ADDPARTS identifier ifNotExists? alterStatementSuffixAddPartitionsElement+) 
Hive,WITHOUT_CLASSIFICATION,//  Sanity check the config. 
Hive,WITHOUT_CLASSIFICATION,//  The interval to wake up and check the queue 
Hive,WITHOUT_CLASSIFICATION,//  It's a column. 
Hive,WITHOUT_CLASSIFICATION,//  USER_PRIVILEGES 
Hive,WITHOUT_CLASSIFICATION,//  to provide the type params to the type cast. 
Hive,WITHOUT_CLASSIFICATION,//  After Load from this dump all target tables/partitions will have initial set of data but source will have latest data. 
Hive,WITHOUT_CLASSIFICATION,// pretend this partition exists 
Hive,WITHOUT_CLASSIFICATION,//  Create a writable object inspector for primitive type and return it. 
Hive,WITHOUT_CLASSIFICATION,//  CLIENT/TOOL END     Singleton instance in the job client 
Hive,WITHOUT_CLASSIFICATION,//  Column 1 
Hive,WITHOUT_CLASSIFICATION,//  A call to increaseBufferSpace() or ensureValPreallocated() will ensure that buffer[] points to   a byte[] with sufficient space for the specified size.   This will either point to smallBuffer or to a newly allocated byte array for larger values. 
Hive,WITHOUT_CLASSIFICATION,//  set up the fetch operator for the new input file. 
Hive,WITHOUT_CLASSIFICATION,//  Subtract 1. 
Hive,WITHOUT_CLASSIFICATION,//  No reason to poll untill the job is initialized 
Hive,WITHOUT_CLASSIFICATION,// cause them to be localized for the Sqoop MR job tasks 
Hive,WITHOUT_CLASSIFICATION,/*    * The type information for all fields.    */
Hive,WITHOUT_CLASSIFICATION,//  Incoming events can be ignored until the point when shuffle needs to be handled instead of just scans. 
Hive,WITHOUT_CLASSIFICATION,//  rs1's schema is key 0 max 1 min 2 
Hive,WITHOUT_CLASSIFICATION,//  If there is a single discardable operator it is a TableScanOperator   and it means that we have merged filter expressions for it. Thus we   might need to remove DPP predicates from the retainable TableScanOperator 
Hive,WITHOUT_CLASSIFICATION,//  Column 2 
Hive,WITHOUT_CLASSIFICATION,//  already committed or aborted. 
Hive,WITHOUT_CLASSIFICATION,//  select columns that actually do not exist in the file. 
Hive,WITHOUT_CLASSIFICATION,//  1. Translate the UDAF 
Hive,WITHOUT_CLASSIFICATION,//  check if right is valid 
Hive,WITHOUT_CLASSIFICATION,//  c/p from OrcInputFormat 
Hive,WITHOUT_CLASSIFICATION,//  Order by is not necessary but MS SQL require it to use FETCH 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getArray(int)    */
Hive,WITHOUT_CLASSIFICATION,//  drop role. ignore error. 
Hive,WITHOUT_CLASSIFICATION,// In DbTxnManager.acquireLocks() we have   2 ReadEntity: [default@acidtblpart@p=p1 default@acidtblpart]   1 WriteEntity: default@acidtblpart Type=TABLE WriteType=INSERT isDP=false 
Hive,WITHOUT_CLASSIFICATION,//  If it is a extract operator we need to rewrite it 
Hive,WITHOUT_CLASSIFICATION,//  Trigger query hooks before query execution. 
Hive,WITHOUT_CLASSIFICATION,//  Subscriber can get notification about drop of a database in HCAT   by listening on a topic named "HCAT" and message selector string   as "HCAT_EVENT = HCAT_DROP_DATABASE" 
Hive,WITHOUT_CLASSIFICATION,//  Table creation should succeed even if location is specified 
Hive,WITHOUT_CLASSIFICATION,/*  * This servlet is based off of the JMXProxyServlet from Tomcat 7.0.14. It has * been rewritten to be read only and to output in a JSON format so it is not * really that close to the original.  */
Hive,WITHOUT_CLASSIFICATION,//  We need to get the partition's column names from the partition serde.   (e.g. Avro provides the table schema and ignores the partition schema..). 
Hive,WITHOUT_CLASSIFICATION,//  apply join filters on the row. 
Hive,WITHOUT_CLASSIFICATION,/*    * Translate column names by walking the AST    */
Hive,WITHOUT_CLASSIFICATION,//  no dynamic partitions 
Hive,WITHOUT_CLASSIFICATION,//  Extract tables used by the query which will in turn be used to generate   the corresponding txn write ids 
Hive,WITHOUT_CLASSIFICATION,//  remove this cor var from output position mapping 
Hive,WITHOUT_CLASSIFICATION,//  Assumes the result set is set to a valid row 
Hive,WITHOUT_CLASSIFICATION,//  Check if this txn state is already replicated for this given table. If yes then it is 
Hive,WITHOUT_CLASSIFICATION,//  Shouldn't really happen. 
Hive,WITHOUT_CLASSIFICATION,//  ETL strategies will have start=3 (start of first stripe) 
Hive,WITHOUT_CLASSIFICATION,/* analyzeExport() creates TableSpec which in turn tries to build     "public List<Partition> partitions" by looking in the metastore to find Partitions matching     the partition spec in the Export command.  These of course don't exist yet since we've not     ran the insert stmt yet!!!!!!!       */
Hive,WITHOUT_CLASSIFICATION,//  Tracks completed requests pre node 
Hive,WITHOUT_CLASSIFICATION,//  Successful task ID's 
Hive,WITHOUT_CLASSIFICATION,//  Assumes the cache lock has already been taken. 
Hive,WITHOUT_CLASSIFICATION,//  Session TxnManager that is already in use. 
Hive,WITHOUT_CLASSIFICATION,//  the histogram object 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)  * @see org.apache.hadoop.mapreduce.RecordReader#close()   */
Hive,WITHOUT_CLASSIFICATION,//  Generate applicationId for the LLAP splits 
Hive,WITHOUT_CLASSIFICATION,//  We are going to build the name 
Hive,WITHOUT_CLASSIFICATION,//  Spark task we're currently processing 
Hive,WITHOUT_CLASSIFICATION,//  2. If we did not generate anything for the new predicate we bail out 
Hive,WITHOUT_CLASSIFICATION,//  Hadoop queue information 
Hive,WITHOUT_CLASSIFICATION,//  If a table import statement specified a location and the table(unpartitioned)   already exists ensure that the locations are the same.   Partitioned tables not checked here since the location provided would need 
Hive,WITHOUT_CLASSIFICATION,//  Event 2 (alter: marker stats event) 3 (insert) 4 (alter: stats update event) 
Hive,WITHOUT_CLASSIFICATION,//  Sorry too many ifs but this form looks optimal 
Hive,WITHOUT_CLASSIFICATION,//  In general when can have unlimited # of branches   we currently only handle either 1 or 2 branch. 
Hive,WITHOUT_CLASSIFICATION,//  needed 
Hive,WITHOUT_CLASSIFICATION,//  Forward the overflow batch over and over:        Reference a new one big table row's values each time        cross product      Current "batch" of small table values.     TODO: This could be further optimized to copy big table (equal) keys once         and only copy big table values each time...         And not set repeating every time...   
Hive,WITHOUT_CLASSIFICATION,//  Adding the S3 credentials from Hadoop config to be hidden 
Hive,WITHOUT_CLASSIFICATION,//  Trim trailing zeroes and re-adjust scale. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#setAutoCommit(boolean)    */
Hive,WITHOUT_CLASSIFICATION,//  estimated number of rows will be product of NDVs 
Hive,WITHOUT_CLASSIFICATION,//  lazily create instances 
Hive,WITHOUT_CLASSIFICATION,//  Record current valid txn list that will be used throughout the query   compilation and processing. We only do this if 1) a transaction   was already opened and 2) the list has not been recorded yet   e.g. by an explicit open transaction command. 
Hive,WITHOUT_CLASSIFICATION,//  1) First branch is query second branch is MV 
Hive,WITHOUT_CLASSIFICATION,//  Desc will be null if its CREATE TABLE LIKE. Desc will be   contained in CreateTableLikeDesc. Currently HCat disallows CTLT in   pre-hook. So desc can never be null. 
Hive,WITHOUT_CLASSIFICATION,//  We'll over allocate and then shrink the array for each type 
Hive,WITHOUT_CLASSIFICATION,// this includes the mandatory alias 
Hive,WITHOUT_CLASSIFICATION,//  third group 
Hive,WITHOUT_CLASSIFICATION,//  Call out to the real configure method 
Hive,WITHOUT_CLASSIFICATION,//  second overflow IS an error in ANSI SQL Numeric.   CAST(10000 AS DECIMAL(3838)) throws overflow error. 
Hive,WITHOUT_CLASSIFICATION,// some commands like "show databases" don't start implicit transactions 
Hive,WITHOUT_CLASSIFICATION,//  The heartbeat has timeout double check whether we can remove it 
Hive,WITHOUT_CLASSIFICATION,//  index for value(+ from keys - from values) 
Hive,WITHOUT_CLASSIFICATION,//  The UDTF expects arguments in an object[] 
Hive,WITHOUT_CLASSIFICATION,//  Construct skewed-value to location map except default directory.   why? query logic knows default-dir structure and don't need to get from map 
Hive,WITHOUT_CLASSIFICATION,// look at queryPlan.outputs(WriteEntity.t - that's the table)  for example drop table in an explicit txn is not allowed  in some cases this requires looking at more than just the operation  for example HiveOperation.LOAD - OK if target is MM table but not OK if non-acid table 
Hive,WITHOUT_CLASSIFICATION,//  this is the original parent of the currentRootOperator as we scan   through the graph. A root operator might have multiple parents and   we just use this one to remember where we came from in the current 
Hive,WITHOUT_CLASSIFICATION,/*      * Don't catch any execution exceptions here and let the caller catch it.      */
Hive,WITHOUT_CLASSIFICATION,//  Sets permissions and group name on partition dirs and files. 
Hive,WITHOUT_CLASSIFICATION,//  we should have stats for all columns (estimated or actual) 
Hive,WITHOUT_CLASSIFICATION,//  If new SerDe needs to store fields in metastore but the old serde doesn't save   the fields so that new SerDe could operate. Note that this may fail if some fields   from old SerDe are too long to be stored in metastore but there's nothing we can do. 
Hive,WITHOUT_CLASSIFICATION,//  log warning if row count is missing 
Hive,WITHOUT_CLASSIFICATION,//  Use getPerfLogger to get an instance of PerfLogger 
Hive,WITHOUT_CLASSIFICATION,//  partition was found but was empty. 
Hive,WITHOUT_CLASSIFICATION,//  generate basic tez config 
Hive,WITHOUT_CLASSIFICATION,//  Set the HiveDecimalWritable from bytes without converting to String first for   better performance. 
Hive,WITHOUT_CLASSIFICATION,/*  10 files x 100 size for 1 splits  */
Hive,WITHOUT_CLASSIFICATION,//  Add a new partition via ObjectStore 
Hive,WITHOUT_CLASSIFICATION,//  -e <query> 
Hive,WITHOUT_CLASSIFICATION,//  stored stats 
Hive,WITHOUT_CLASSIFICATION,/*        * Now new job requests should succeed as all cancel threads would have completed.        */
Hive,WITHOUT_CLASSIFICATION,//  Nothing currently available for hash sets. 
Hive,WITHOUT_CLASSIFICATION,//  leaving some table from the list of tables to be cached 
Hive,WITHOUT_CLASSIFICATION,// MERGE statements could have inserted a cardinality violation branch we need to avoid that 
Hive,WITHOUT_CLASSIFICATION,//  normalize prop name 
Hive,WITHOUT_CLASSIFICATION,//  this can be a max of 65 never > 127 
Hive,WITHOUT_CLASSIFICATION,//  Add default dir at the end of each list 
Hive,WITHOUT_CLASSIFICATION,//  included will not be null row options will fill the array with trues if null 
Hive,WITHOUT_CLASSIFICATION,//  setDays resets the isNull[i] to false if there is a parse exception 
Hive,WITHOUT_CLASSIFICATION,//  Fail silently 
Hive,WITHOUT_CLASSIFICATION,//  Test that existing exclusive partition with new shared_read coalesces to 
Hive,WITHOUT_CLASSIFICATION,//  could be null for default partition 
Hive,WITHOUT_CLASSIFICATION,//  3. Construct Join Rel Node and RowResolver for the new Join Node 
Hive,WITHOUT_CLASSIFICATION,// Use i 
Hive,WITHOUT_CLASSIFICATION,//  of its parent SparkWorks for the small tables 
Hive,WITHOUT_CLASSIFICATION,//  If the modelerType attribute was not found the class name is used   instead. 
Hive,WITHOUT_CLASSIFICATION,//  Make vectorized operator 
Hive,WITHOUT_CLASSIFICATION,//  "java version" system property is formatted   major_version.minor_version.patch_level.   Find second dot instead of last dot to be safe 
Hive,WITHOUT_CLASSIFICATION,// set to empty "Text" if hive.metastore.token.signature property is set to null 
Hive,WITHOUT_CLASSIFICATION,//  Group by operators select the key cols so no need to find them in the values 
Hive,WITHOUT_CLASSIFICATION,//  Only mark output NULL when input is NULL. 
Hive,WITHOUT_CLASSIFICATION,//  create the directories FileSinkOperators need 
Hive,WITHOUT_CLASSIFICATION,//  Need a way to know what thread to interrupt since this is a blocking thread. 
Hive,WITHOUT_CLASSIFICATION,//  This may be possible when srcType is string but destType is integer 
Hive,WITHOUT_CLASSIFICATION,// since T3 overlaps with Long Running (still open) GC does nothing 
Hive,WITHOUT_CLASSIFICATION,/*    * Creates the configuration object necessary to run a specific vertex from   * map work. This includes input formats input processor etc.    */
Hive,WITHOUT_CLASSIFICATION,//  the file may not exist and we just ignore this 
Hive,WITHOUT_CLASSIFICATION,//  Show we cannot create a child of a null directory 
Hive,WITHOUT_CLASSIFICATION,//  Bloom filter for the new node that we will eventually add to the cache 
Hive,WITHOUT_CLASSIFICATION,// -----------------------------------------------------------------------------------------------   Convert to string/UTF-8 ASCII bytes methods.  ----------------------------------------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  some bookkeeping 
Hive,WITHOUT_CLASSIFICATION,//  ForwardOperator so that we can add multiple filter/group by operators as children 
Hive,WITHOUT_CLASSIFICATION,//  Event dump each sub-dir is an individual event dump.   We need to guarantee that the directory listing we got is in order of evid. 
Hive,WITHOUT_CLASSIFICATION,//  Try another slot. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setNClob(int java.io.Reader long)    */
Hive,WITHOUT_CLASSIFICATION,//  the schema for intersect all is like this   R3 + count(c) as cnt + min(c) as m   we create a input project for udtf whose schema is like this   min(c) as m + R3 
Hive,WITHOUT_CLASSIFICATION,//  The simple validity check is to see if the file is of size 0 or not.   Other checks maybe added in the future. 
Hive,WITHOUT_CLASSIFICATION,//  Don't mess with the cached object. 
Hive,WITHOUT_CLASSIFICATION,//     Assert.assertFalse(metaStore.isPathExists(new Path(tableLocation + "/year=2017"))); 
Hive,WITHOUT_CLASSIFICATION,//  can clean 
Hive,WITHOUT_CLASSIFICATION,/*          * Get our Single-Column Long hash multi-set information for this specialized class.          */
Hive,WITHOUT_CLASSIFICATION,// clean up if above throws 
Hive,WITHOUT_CLASSIFICATION,//  if this rel references corVar   and now it needs to be rewritten   it must have been pulled above the Correlator   replace the input ref to account for the LHS of the   Correlator 
Hive,WITHOUT_CLASSIFICATION,//  For explain plan txn won't be opened and doesn't make sense to allocate write id 
Hive,WITHOUT_CLASSIFICATION,//  Register function 
Hive,WITHOUT_CLASSIFICATION,//  Power of ten way beyond our precision/scale... 
Hive,WITHOUT_CLASSIFICATION,//  move all the children to the front of queue 
Hive,WITHOUT_CLASSIFICATION,// Test outputformat with complex data type and with reduce 
Hive,WITHOUT_CLASSIFICATION,//  parsing error invalid url string 
Hive,WITHOUT_CLASSIFICATION,//  T is settable recursively i.e all the nested fields are also settable. 
Hive,WITHOUT_CLASSIFICATION,//  with constant folding then the result will be IfExprLongColumnLongScalar. 
Hive,WITHOUT_CLASSIFICATION,//  Use SignableVertexSpec.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,//  Test select root.col2 from root:struct<col1:struct<a:booleanb:double>col2:double> 
Hive,WITHOUT_CLASSIFICATION,//  Initialize transient fields. To be called after deserialization of other fields. 
Hive,WITHOUT_CLASSIFICATION,//  This is the threshold that the user has specified to fit in mapjoin 
Hive,WITHOUT_CLASSIFICATION,/*    * Tests if LOCATION_1 is returned when file is present in the first directory in lookup order    */
Hive,WITHOUT_CLASSIFICATION,//  BINARY_VALUE 
Hive,WITHOUT_CLASSIFICATION,//  Simplify vector by brute-force flattening noNulls if isRepeating   This can be used to reduce combinatorial explosion of code paths in VectorExpressions 
Hive,WITHOUT_CLASSIFICATION,//  skip entire the data: 
Hive,WITHOUT_CLASSIFICATION,//  set nothing for prepared sql 
Hive,WITHOUT_CLASSIFICATION,//  all files were copied successfully in last try. So can break from here. 
Hive,WITHOUT_CLASSIFICATION,//  Timestamps with a second VInt storing additional bits of the seconds field. 
Hive,WITHOUT_CLASSIFICATION,//  remember the count() positions 
Hive,WITHOUT_CLASSIFICATION,/*  initialize rowNums to have 1 row  */
Hive,WITHOUT_CLASSIFICATION,//    read back!   
Hive,WITHOUT_CLASSIFICATION,// heartbeater should be running in the background every 1/2 second 
Hive,WITHOUT_CLASSIFICATION,//  4. Create and return IN clause 
Hive,WITHOUT_CLASSIFICATION,//  For pattern 'd' find digits. 
Hive,WITHOUT_CLASSIFICATION,//  in theory the below call isn't needed in non thrift_mode but let's not   get too crazy 
Hive,WITHOUT_CLASSIFICATION,//  Class loading is thread safe. 
Hive,WITHOUT_CLASSIFICATION,//  If started from main() and noLog is on we should not output   any logs. To turn the log on please set -Dtest.silent=false 
Hive,WITHOUT_CLASSIFICATION,//  Explicitly mis-set the catalog name 
Hive,WITHOUT_CLASSIFICATION,//  Second incremental load 
Hive,WITHOUT_CLASSIFICATION,// now make sure we get the stats we expect for partition we are going to add data to later 
Hive,WITHOUT_CLASSIFICATION,//  If the client did not specify qop then just negotiate the one supported by server 
Hive,WITHOUT_CLASSIFICATION,//  Round using the "half-up" method used in Hive. 
Hive,WITHOUT_CLASSIFICATION,//  will strain out the record id for the underlying writer. 
Hive,WITHOUT_CLASSIFICATION,//  Load using same dump to a DB with view. It should fail as DB is not empty. 
Hive,WITHOUT_CLASSIFICATION,//  1. Collect GB Keys 
Hive,WITHOUT_CLASSIFICATION,//  Assume we don't need to fetch the rest of the skewed column data if we have no columns. 
Hive,WITHOUT_CLASSIFICATION,//  Add the new task as child of each of the passed in tasks 
Hive,WITHOUT_CLASSIFICATION,//    throw new HiveException("batch.selected is not in sort order and unique");   } 
Hive,WITHOUT_CLASSIFICATION,// checkoutputspecs might've set some properties we need to have context reflect that 
Hive,WITHOUT_CLASSIFICATION,//  TABLE_STATS 
Hive,WITHOUT_CLASSIFICATION,//  now look in any jars we've packaged using JarFinder. Returns null   when 
Hive,WITHOUT_CLASSIFICATION,//  The super method will reload a hash table partition of one of the small tables.   Currently for native vector map join it will only be one small table. 
Hive,WITHOUT_CLASSIFICATION,//  Swap the first element of the metastoreUris[] with a random element from the rest   of the array. Rationale being that this method will generally be called when the default   connection has died and the default connection is likely to be the first array element. 
Hive,WITHOUT_CLASSIFICATION,/*  new Exception() */
Hive,WITHOUT_CLASSIFICATION,//  Start with dummy vector operator as the parent of the parallel vector operator tree we are   creating 
Hive,WITHOUT_CLASSIFICATION,//  //////////////////   String utilities   ////////////////// 
Hive,WITHOUT_CLASSIFICATION,//  Aggregate this batch. 
Hive,WITHOUT_CLASSIFICATION,//  used for testing 
Hive,WITHOUT_CLASSIFICATION,//  There should be a reader event available or coming soon so okay to be blocking call. 
Hive,WITHOUT_CLASSIFICATION,//  Decode the value if necessary 
Hive,WITHOUT_CLASSIFICATION,//  runInternal which defers the close to the called in that method. 
Hive,WITHOUT_CLASSIFICATION,/*    * getConvertedOI without any caching.    */
Hive,WITHOUT_CLASSIFICATION,/*  Locate the op where the branch starts.  This function works only for the following pattern.   *     TS1       TS2   *      |         |   *     FIL       FIL   *      |         |   *      |     ---------   *      RS    |   |   |   *      |    RS  SEL SEL   *      |    /    |   |   *      |   /    GBY GBY   *      JOIN       |  |   *                 |  SPARKPRUNINGSINK   *                 |   *              SPARKPRUNINGSINK    */
Hive,WITHOUT_CLASSIFICATION,//  call-1: listLocatedStatus - mock:/mocktbl2   call-2: check side file for mock:/mocktbl2/0_0   call-3: open - mock:/mocktbl2/0_0   call-4: check side file for  mock:/mocktbl2/0_1 
Hive,WITHOUT_CLASSIFICATION,//  1 NULL 
Hive,WITHOUT_CLASSIFICATION,//  make sure only map-joins can be performed. 
Hive,WITHOUT_CLASSIFICATION,//  safe to assume else is ORC as semantic analyzer will check for RC/ORC 
Hive,WITHOUT_CLASSIFICATION,//  A1 removed from A.   Make sure that we can still get a session from A. 
Hive,WITHOUT_CLASSIFICATION,//  5 minutes. 
Hive,WITHOUT_CLASSIFICATION,//  For the failures the users have been notified we just need to clean up. There's no   session here (or it's unused) so no conflicts are possible. We just remove it.   For successes the user has also been notified so various requests are also possible;   however to start we'd just put the session into the sessions list and go from there. 
Hive,WITHOUT_CLASSIFICATION,//  for Xlint code will never reach here 
Hive,WITHOUT_CLASSIFICATION,/*    * Sets the job state to COMPLETED and also sets the results value. Returns true   * if COMPLETED status is set. Otherwise it returns false.    */
Hive,WITHOUT_CLASSIFICATION,/*        * Trigger kill threads and verify that we get InterruptedException and expected       * Message. This should raise 3 kill operations and ensure that retries keep the time out       * occupied for 4 sec.        */
Hive,WITHOUT_CLASSIFICATION,/*        we have reached the point where we are transferring files across fileSystems.     */
Hive,WITHOUT_CLASSIFICATION,//  Fill high long from middle long and middle long from lower long. 
Hive,WITHOUT_CLASSIFICATION,/*    * Capture the CTE definitions in a Query.    */
Hive,WITHOUT_CLASSIFICATION,/*              * Equal key series checking.              */
Hive,WITHOUT_CLASSIFICATION,/*            * Optionally read current value's big length.  {Big Value Len} {Big Value Bytes}            */
Hive,WITHOUT_CLASSIFICATION,//  long range bias for 32-bit hashcodes 
Hive,WITHOUT_CLASSIFICATION,//  https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/TransparentEncryption.html#Running_as_the_superuser 
Hive,WITHOUT_CLASSIFICATION,//  Try to find the class 
Hive,WITHOUT_CLASSIFICATION,//  write the sync bytes   flush header 
Hive,WITHOUT_CLASSIFICATION,// We store the position to the constant value for later use. 
Hive,WITHOUT_CLASSIFICATION,/* do fast path first (in 1 statement) if doesn't work rollback and do the long version */
Hive,WITHOUT_CLASSIFICATION,//  optional int32 within_dag_priority = 3; 
Hive,WITHOUT_CLASSIFICATION,//  Using a member variable in the closure will not do the right thing... 
Hive,WITHOUT_CLASSIFICATION,//  Have to scan the directory to find min date greater than currentDir. 
Hive,WITHOUT_CLASSIFICATION,//  sets up temp and task temp path 
Hive,WITHOUT_CLASSIFICATION,//  Join clause: rewriting is needed 
Hive,WITHOUT_CLASSIFICATION,//  optional int32 am_port = 7; 
Hive,WITHOUT_CLASSIFICATION,//  This is a semijoin branch. Find if this is creating a potential   cycle with childJoin. 
Hive,WITHOUT_CLASSIFICATION,//  Parameters for exporting metadata on table drop (requires the use of the)   org.apache.hadoop.hive.ql.parse.MetaDataExportListener preevent listener 
Hive,WITHOUT_CLASSIFICATION,//  No temp tables just call underlying client 
Hive,WITHOUT_CLASSIFICATION,//  by now 'prunedCols' are columns used by child operators and 'columns' 
Hive,WITHOUT_CLASSIFICATION,//  First we quickly check if the two table scan operators can actually be merged 
Hive,WITHOUT_CLASSIFICATION,//  MY_16BIT_INT 
Hive,WITHOUT_CLASSIFICATION,//  avro guarantees that the key will be of type string. So we just need to worry about   deserializing the value here 
Hive,WITHOUT_CLASSIFICATION,//  The entire seconds field is stored in the first 4 bytes. 
Hive,WITHOUT_CLASSIFICATION,//  I'm assuming that there is no transaction ID for a read lock. 
Hive,WITHOUT_CLASSIFICATION,//  AUTHORIZER 
Hive,WITHOUT_CLASSIFICATION,// default outputTypeInfo is long 
Hive,WITHOUT_CLASSIFICATION,//  Now create session specific dirs 
Hive,WITHOUT_CLASSIFICATION,/*  Comma separated list of classes in a batch  */
Hive,WITHOUT_CLASSIFICATION,//  REPL_POLICY 
Hive,WITHOUT_CLASSIFICATION,//  let writers release the memory for garbage collection 
Hive,WITHOUT_CLASSIFICATION,//  1/ reserve spaces for the byte size of the struct   which is a integer and takes four bytes 
Hive,WITHOUT_CLASSIFICATION,//  of the outputs of intermediate map reduce jobs. 
Hive,WITHOUT_CLASSIFICATION,//  Don't break if this allocation failure was a result of a LOCALITY_DELAY. Others could still be allocated. 
Hive,WITHOUT_CLASSIFICATION,//  Newer tasks first. 
Hive,WITHOUT_CLASSIFICATION,//  This is just the directory.  We need to recurse and find the actual files.  But don't   do this until we have determined there is no base.  This saves time.  Plus   it is possible that the cleaner is running and removing these original files   in which case recursing through them could cause us to get an error. 
Hive,WITHOUT_CLASSIFICATION,//  IS_REPLACE 
Hive,WITHOUT_CLASSIFICATION,//  UTF-8 byte constants used by string/UTF-8 bytes to decimal and decimal to String/UTF-8 byte   conversion. 
Hive,WITHOUT_CLASSIFICATION,/*      * For better performance on LONG/DOUBLE we don't want the conditional     * statements inside the for loop.      */
Hive,WITHOUT_CLASSIFICATION,//  Directory where path resides 
Hive,WITHOUT_CLASSIFICATION,//  There's no more data. 
Hive,WITHOUT_CLASSIFICATION,//  higerbound when useDensityFunctionForNDVEstimation is true. 
Hive,WITHOUT_CLASSIFICATION,//  hconf is null in unit testing 
Hive,WITHOUT_CLASSIFICATION,//  Either this arena is being allocated or it is already allocated or it is next. The 
Hive,WITHOUT_CLASSIFICATION,/*      * these are the functions that have a Window.     * Fns w/o a Window have already been processed.      */
Hive,WITHOUT_CLASSIFICATION,//  push down filters 
Hive,WITHOUT_CLASSIFICATION,//  keeps track of the right-hand-side table name of the left-semi-join and 
Hive,WITHOUT_CLASSIFICATION,/*  1 files x 1000 size for 10 splits  */
Hive,WITHOUT_CLASSIFICATION,//  Node1 marked as failed node2 has capacity. 
Hive,WITHOUT_CLASSIFICATION,//  Literal smallint. 
Hive,WITHOUT_CLASSIFICATION,//  KerberosName.getShorName can only be used for kerberos user but not for the user   logged in via other authentications such as LDAP 
Hive,WITHOUT_CLASSIFICATION,//  rowId <= '2014-07-01' 
Hive,WITHOUT_CLASSIFICATION,//  Calculate which writer to use from the remaining values - this needs to   be done before we delete cols. 
Hive,WITHOUT_CLASSIFICATION,//  This Project will be what the old input maps to   replacing any previous mapping from old input). 
Hive,WITHOUT_CLASSIFICATION,//  Note: this is called under the epic lock. 
Hive,WITHOUT_CLASSIFICATION,//  Reset for reading. 
Hive,WITHOUT_CLASSIFICATION,//  Check if this is the best match so far 
Hive,WITHOUT_CLASSIFICATION,/*  fall through  */
Hive,WITHOUT_CLASSIFICATION,//  always long 
Hive,WITHOUT_CLASSIFICATION,//  No such table in the given database 
Hive,WITHOUT_CLASSIFICATION,//  pre-compute normalization so we don't have to deal   with SQLExceptions later 
Hive,WITHOUT_CLASSIFICATION,//  6. Generate Join operator 
Hive,WITHOUT_CLASSIFICATION,//  Besides the HiveShims jar which is Hadoop version dependent we also   always need to include hive shims common jars. 
Hive,WITHOUT_CLASSIFICATION,//  No locality delay 
Hive,WITHOUT_CLASSIFICATION,//  no need to generate is not null predicate for partitioning or   virtual column since those columns can never be null. 
Hive,WITHOUT_CLASSIFICATION,//  5. Take care of view creation 
Hive,WITHOUT_CLASSIFICATION,/*  Compare two strings from two byte arrays each   * with their own start position and length.   * Use lexicographic unsigned byte value order.   * This is what's used for UTF-8 sort order.   * Return negative value if arg1 < arg2 0 if arg1 = arg2   * positive if arg1 > arg2.    */
Hive,WITHOUT_CLASSIFICATION,// FileSystem fs = FileSystem.get(getConf()); 
Hive,WITHOUT_CLASSIFICATION,//  Decimal columns use HiveDecimalWritable. 
Hive,WITHOUT_CLASSIFICATION,//  delim 
Hive,WITHOUT_CLASSIFICATION,//  If it is not a column we need for the keys move on 
Hive,WITHOUT_CLASSIFICATION,//  We walk through the AST.   We replace all the TOK_TABREF by adding additional masking and filter if   the table needs to be masked or filtered.   For the replacement we leverage the methods that are used for 
Hive,WITHOUT_CLASSIFICATION,//     ve = vc.getVectorExpression(exprDesc);      assertTrue(ve instanceof IfExprVarCharScalarVarCharScalar); 
Hive,WITHOUT_CLASSIFICATION,//  In HiveMetaStore the deleteData flag indicates whether DFS data should be   removed on a drop. 
Hive,WITHOUT_CLASSIFICATION,//  values we put in above. 
Hive,WITHOUT_CLASSIFICATION,//  Adding a select operator to top of semijoin to ensure projection of only correct columns 
Hive,WITHOUT_CLASSIFICATION,//  populate partition info 
Hive,WITHOUT_CLASSIFICATION,//  in the projection. 
Hive,WITHOUT_CLASSIFICATION,//  transform the table reference to an absolute reference (i.e. "db.table") 
Hive,WITHOUT_CLASSIFICATION,//  Cache extractObject 
Hive,WITHOUT_CLASSIFICATION,//  Case 9: column stats NO grouping sets 
Hive,WITHOUT_CLASSIFICATION,//  existing avro data 
Hive,WITHOUT_CLASSIFICATION,//  Key is column name and the value is the col stat object 
Hive,WITHOUT_CLASSIFICATION,//  SettableMapObjectInspector 
Hive,WITHOUT_CLASSIFICATION,//  Check that HIVE_EXEC_INPUT_LISTING_MAX_THREADS has priority overr DEPRECATED_MAPRED_DFSCLIENT_PARALLELISM_MAX 
Hive,WITHOUT_CLASSIFICATION,//  optional string token_identifier = 8; 
Hive,WITHOUT_CLASSIFICATION,/*  If this boolean is true we bypass the cache.  */
Hive,WITHOUT_CLASSIFICATION,//  Go over the schema and convert type to thrift type 
Hive,WITHOUT_CLASSIFICATION,//  user is providing config so it could be null. 
Hive,WITHOUT_CLASSIFICATION,//  exact limit can be taken care of by the fetch operator 
Hive,WITHOUT_CLASSIFICATION,// we do not care about the transformation or rewriting of AST   which following statement does   we only care about the restriction checks they perform.   We plan to get rid of these restrictions later 
Hive,WITHOUT_CLASSIFICATION,//  This DemuxOperator can appear multiple times in MuxOperator's   parentOperators 
Hive,WITHOUT_CLASSIFICATION,//  only one reducer if this configuration does not prevents 
Hive,WITHOUT_CLASSIFICATION,//  GRANT_OPTION 
Hive,WITHOUT_CLASSIFICATION,//  No room. 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   required   required   required   required   required   required 
Hive,WITHOUT_CLASSIFICATION,//  Reparse text passing null for context to avoid clobbering   the top-level token stream. 
Hive,WITHOUT_CLASSIFICATION,//  The list of bytes used for the separators in the column (a nested struct    such as Array<Array<int>> will use multiple separators).   The list of separators + escapeChar are the bytes required to be escaped. 
Hive,WITHOUT_CLASSIFICATION,/*  * The root interface for a vector map join hash set.  */
Hive,WITHOUT_CLASSIFICATION,//  Should return null when there is no column 
Hive,WITHOUT_CLASSIFICATION,//  2) Insert data into both tables 
Hive,WITHOUT_CLASSIFICATION,// The complete list of output columns. These should be added to the  Vectorized row batch for processing. The index in the row batch is  equal to the index in this array plus initialOutputCol. 
Hive,WITHOUT_CLASSIFICATION,// The query needs ROW__ID: maybe explicitly asked maybe it's part of   Update/Delete statement.  Either way we need to decorate "original" rows with row__id 
Hive,WITHOUT_CLASSIFICATION,//  Check if ARRAY_IDX argument is of category LIST 
Hive,WITHOUT_CLASSIFICATION,//  no interpolation needed because position does not have a fraction 
Hive,WITHOUT_CLASSIFICATION,//  Ignore leading zeroes. 
Hive,WITHOUT_CLASSIFICATION,//  delete column statistics if present 
Hive,WITHOUT_CLASSIFICATION,//  use left alias (~mysql postgresql)   try widening conversion otherwise fail union 
Hive,WITHOUT_CLASSIFICATION,//  This means there is a second VInt present that specifies additional bits of the timestamp.   The reversed nanoseconds value is still encoded in this VInt. 
Hive,WITHOUT_CLASSIFICATION,//  Check constraint fails only if it evaluates to false NULL/UNKNOWN should evaluate to TRUE 
Hive,WITHOUT_CLASSIFICATION,//  production is: byte 
Hive,WITHOUT_CLASSIFICATION,//  default arg-less run simply runs and does not care about failure 
Hive,WITHOUT_CLASSIFICATION,//  starting Tez session pool in start here to let parent session state initialize on CliService state to avoid   SessionState.get() return null during createTezDir 
Hive,WITHOUT_CLASSIFICATION,//  some UDFs may emit strings of variable length. like pattern matching   UDFs. it's hard to find the length of such UDFs.   return the variable length from config 
Hive,WITHOUT_CLASSIFICATION,//  check if stats need to be (re)calculated 
Hive,WITHOUT_CLASSIFICATION,//  first promote the next group to be the current group if we reached a   new group in the previous fetch 
Hive,WITHOUT_CLASSIFICATION,//  Test "alter table" with rename 
Hive,WITHOUT_CLASSIFICATION,//  Any more input? 
Hive,WITHOUT_CLASSIFICATION,//  Partitions added now should inherit table-schema properties etc. 
Hive,WITHOUT_CLASSIFICATION,/*          * Initialize Single-Column Long members for this specialized class.          */
Hive,WITHOUT_CLASSIFICATION,//  2.3 Check if GROUPING_ID needs to be projected out 
Hive,WITHOUT_CLASSIFICATION,//    Rewrite logic:     1. rewrite join condition.   2. map output positions and produce cor vars if any.   
Hive,WITHOUT_CLASSIFICATION,//  a root Task 
Hive,WITHOUT_CLASSIFICATION,//     HCatUtil.logAllTokens(LOGcontext); 
Hive,WITHOUT_CLASSIFICATION,//  ~ Methods ---------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  Bootstrap constraint dump shouldn't fail if the table is dropped/renamed while dumping it.   Just log a debug message and skip it. 
Hive,WITHOUT_CLASSIFICATION,/*  Testing for equality of doubles after a math operation is     * not always reliable so use this as a tolerance.      */
Hive,WITHOUT_CLASSIFICATION,//  Lock database operation is to acquire the lock explicitly the operation   itself doesn't need to be locked. Set the WriteEntity as WriteType:   DDL_NO_LOCK here otherwise it will conflict with Hive's transaction. 
Hive,WITHOUT_CLASSIFICATION,//  Following a suggestion from Gopal quickly read in the bytes from the stream.   CONSIDER: Have ORC read the whole input stream into a big byte array with one call to   the read(byte[] b int off int len) method and then let this method read from the big   byte array. 
Hive,WITHOUT_CLASSIFICATION,//  Keeps existing output column map etc. 
Hive,WITHOUT_CLASSIFICATION,//  same session 
Hive,WITHOUT_CLASSIFICATION,//  Non-empty java opts with -Xmx specified twice 
Hive,WITHOUT_CLASSIFICATION,//  Use table properties in case of unpartitioned tables   and the union of table properties and partition properties with partition   taking precedence in the case of partitioned tables 
Hive,WITHOUT_CLASSIFICATION,//  is not expected further down the pipeline. see jira for more details 
Hive,WITHOUT_CLASSIFICATION,//  Reset port setting 
Hive,WITHOUT_CLASSIFICATION,//  table as second read entity 
Hive,WITHOUT_CLASSIFICATION,//  Each http request must have an Authorization header 
Hive,WITHOUT_CLASSIFICATION,//  Note: for deallocateEvicted we do not release the memory to memManager; it may   happen that the evictor tries to use the allowance before the move finishes.   Retrying/more defrag should take care of that. 
Hive,WITHOUT_CLASSIFICATION,//  Note - important to retain the same key as the export 
Hive,WITHOUT_CLASSIFICATION,//  operations require select priv 
Hive,WITHOUT_CLASSIFICATION,//  The partition got dropped before we went looking for it. 
Hive,WITHOUT_CLASSIFICATION,//  Hadoop DelegationTokenManager default is 1 week. 
Hive,WITHOUT_CLASSIFICATION,/*    * When transforming a Not In SubQuery we need to check for nulls in the   * Joining expressions of the SubQuery. If there are nulls then the SubQuery always   * return false. For more details see   * https://issues.apache.org/jira/secure/attachment/12614003/SubQuerySpec.pdf   *   * Basically SQL semantics say that:   * - R1.A not in (null 1 2 ...)   *   is always false.   *   A 'not in' operator is equivalent to a '<> all'. Since a not equal check with null   *   returns false a not in predicate against aset with a 'null' value always returns false.   *   * So for not in SubQuery predicates:   * - we join in a null count predicate.   * - And the joining condition is that the 'Null Count' query has a count of 0.   *    */
Hive,WITHOUT_CLASSIFICATION,//  Created on demand. 
Hive,WITHOUT_CLASSIFICATION,//  the operator stack. 
Hive,WITHOUT_CLASSIFICATION,//  we'll set up tez to combine spits for us iff the input format   is HiveInputFormat 
Hive,WITHOUT_CLASSIFICATION,//  Ignore potentially incorrect values 
Hive,WITHOUT_CLASSIFICATION,//  prevent view from referencing itself 
Hive,WITHOUT_CLASSIFICATION,//  Generate binary sortable key for current row in vectorized row batch. 
Hive,WITHOUT_CLASSIFICATION,//  Used by replication copy files from source to destination. It is possible source file is   changed/removed during copy so double check the checksum after copy 
Hive,WITHOUT_CLASSIFICATION,//  means serializing another instance. 
Hive,WITHOUT_CLASSIFICATION,//  do not print duplicate status while still in middle of print interval. 
Hive,WITHOUT_CLASSIFICATION,//  bail out 
Hive,WITHOUT_CLASSIFICATION,//  Use UTC date to ensure reader date is same on all timezones. 
Hive,WITHOUT_CLASSIFICATION,//  We always set the null flag to false when there is a value. 
Hive,WITHOUT_CLASSIFICATION,// Read the template into a string; 
Hive,WITHOUT_CLASSIFICATION,//  Bootstrap dump with empty db 
Hive,WITHOUT_CLASSIFICATION,//  Case 2. 
Hive,WITHOUT_CLASSIFICATION,//  sleep this many seconds between each retry. 
Hive,WITHOUT_CLASSIFICATION,//  we first look for this alias from CTE and then from catalog. 
Hive,WITHOUT_CLASSIFICATION,//  If the partition columns can't all be found in the values then the data is not bucketed 
Hive,WITHOUT_CLASSIFICATION,//  DEST_TABLE_NAME 
Hive,WITHOUT_CLASSIFICATION,//  a binary operator (gt lt ge le eq ne) 
Hive,WITHOUT_CLASSIFICATION,//  portion of the join output. 
Hive,WITHOUT_CLASSIFICATION,//  only 2 valid partitions should be added 
Hive,WITHOUT_CLASSIFICATION,//  Create a client instance 
Hive,WITHOUT_CLASSIFICATION,//  All the setup is done in GenMapRedUtils 
Hive,WITHOUT_CLASSIFICATION,// old version of thrift client should have (lc.isSetOperationType() == false) but they do not  If you add a default value to a variable isSet() for that variable is true regardless of the where the  message was created (for object variables.   It works correctly for boolean vars e.g. LockComponent.isTransactional).  in test mode upgrades are not tested so client version and server version of thrift always matches so  we see UNSET here it means something didn't set the appropriate value. 
Hive,WITHOUT_CLASSIFICATION,// H1 - should allocate 
Hive,WITHOUT_CLASSIFICATION,//  runtime objects 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *    * @see   * org.apache.hadoop.hive.ql.udf.ptf.TableFunctionEvaluator#finishPartition()   *    * for fns that are not ISupportStreamingModeForWindowing give them the   * remaining rows (rows whose span went beyond the end of the partition) for   * rest of the functions invoke terminate.   *    * while numOutputRows < numInputRows for each Fn that doesn't have enough o/p   * invoke getNextObj if there is no O/p then flag this as an error.    */
Hive,WITHOUT_CLASSIFICATION,//  This helper object deserializes LazyBinary format small table values into columns of a row 
Hive,WITHOUT_CLASSIFICATION,// disable datasource  Case it is an insert overwrite we have to disable the existing Druid DataSource 
Hive,WITHOUT_CLASSIFICATION,//  Need a concurrent weakhashmap. WeakKeys() so that when underlying transport gets out of   scope it still can be GC'ed. Since value of map has a ref to key need weekValues as well. 
Hive,WITHOUT_CLASSIFICATION,//  Raw socket connection (non-sasl) 
Hive,WITHOUT_CLASSIFICATION,//  Allocate 1-1-... xN; free every other one allocate N/2 (or N/4). 
Hive,WITHOUT_CLASSIFICATION,//  the right token. 
Hive,WITHOUT_CLASSIFICATION,//  Move from the tmp dir to an intermediate directory in the same level as 
Hive,WITHOUT_CLASSIFICATION,//  multiple instances of such classes 
Hive,WITHOUT_CLASSIFICATION,//  unused 
Hive,WITHOUT_CLASSIFICATION,//  shell_cmd = "/bin/bash -c \'" + shell_cmd + "\'"; 
Hive,WITHOUT_CLASSIFICATION,//  Special module for tests in the rootDir. 
Hive,WITHOUT_CLASSIFICATION,//  Or UDF (rowId <= 'd' or rowId >= 'q') 
Hive,WITHOUT_CLASSIFICATION,//  HCat will always prune columns based on what we ask of it - so the 
Hive,WITHOUT_CLASSIFICATION,//  Okay we're going to need these originals.  Recurse through them and figure out what we   really need. 
Hive,WITHOUT_CLASSIFICATION,//  No existing lock for this partition. 
Hive,WITHOUT_CLASSIFICATION,//  FUNC 
Hive,WITHOUT_CLASSIFICATION,//  Now pick a server node randomly 
Hive,WITHOUT_CLASSIFICATION,// 3)  test bad field names 
Hive,WITHOUT_CLASSIFICATION,/*      * Check.5.h :: For In and Not In the SubQuery must implicitly or     * explicitly only contain one select item.      */
Hive,WITHOUT_CLASSIFICATION,/*        * Do a round each as physical with no row selection and logical with row selection.        */
Hive,WITHOUT_CLASSIFICATION,//  Build new join. 
Hive,WITHOUT_CLASSIFICATION,//  some join alias could be changed: alias -> newAlias 
Hive,WITHOUT_CLASSIFICATION,//  just return k1 is smaller than k2 
Hive,WITHOUT_CLASSIFICATION,//  Infer schema 
Hive,WITHOUT_CLASSIFICATION,//  set memory available for operators 
Hive,WITHOUT_CLASSIFICATION,//  Does a pool exist for this path already 
Hive,WITHOUT_CLASSIFICATION,//  unused / unknown reason 
Hive,WITHOUT_CLASSIFICATION,//  end of union 
Hive,WITHOUT_CLASSIFICATION,//  Invalid schemes 
Hive,WITHOUT_CLASSIFICATION,// suppress multi-spaces 
Hive,WITHOUT_CLASSIFICATION,//  Create the walker and  the rules dispatcher. 
Hive,WITHOUT_CLASSIFICATION,//  then reopened session will use user specified queue name else default cluster queue names. 
Hive,WITHOUT_CLASSIFICATION,//  Ok to be interrupted 
Hive,WITHOUT_CLASSIFICATION,//  default block size is set to 8 as most cache line sizes are 64 bytes and also AVX512 friendly 
Hive,WITHOUT_CLASSIFICATION,/*    * Wrapper class to write a HS2ConnectionConfig file    */
Hive,WITHOUT_CLASSIFICATION,// Complete one task on host1. 
Hive,WITHOUT_CLASSIFICATION,//  compare next part 
Hive,WITHOUT_CLASSIFICATION,// --------------------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  all keys matched. 
Hive,WITHOUT_CLASSIFICATION,//  Check query results cache.   If no masking/filtering required then we can check the cache now before   generating the operator tree and going through CBO. 
Hive,WITHOUT_CLASSIFICATION,//  Should not have tried to print any thing. 
Hive,WITHOUT_CLASSIFICATION,/*    * Returns the singleton instance of jobId->delegation-token-in-string-form cache    */
Hive,WITHOUT_CLASSIFICATION,// check for QUERY_HINT expressions on ast 
Hive,WITHOUT_CLASSIFICATION,//  Reset the location db and table name and compare the partitions 
Hive,WITHOUT_CLASSIFICATION,//  2^32 + .01 
Hive,WITHOUT_CLASSIFICATION,/*  january is 0  */
Hive,WITHOUT_CLASSIFICATION,//  when we reach here we must have some data already (because size >0).   We need to see if there are any data flushed into file system. If not   we can   directly read from the current write block. Otherwise we need to read   from the beginning of the underlying file. 
Hive,WITHOUT_CLASSIFICATION,//  Fetch existing Ingestion Spec from Druid if any 
Hive,WITHOUT_CLASSIFICATION,//  Set isNull before calls in case they change their mind. 
Hive,WITHOUT_CLASSIFICATION,//  Use LlapOutputSocketInitMessage.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,//  Setting {minmax}SessionTimeout defaults to be the same as in Zookeeper 
Hive,WITHOUT_CLASSIFICATION,//  ...for each of the tables that are part of the materialized view   where the transaction had to be committed after the materialization was created... 
Hive,WITHOUT_CLASSIFICATION,//  Create an instance of hive in order to create the tables 
Hive,WITHOUT_CLASSIFICATION,//  Initiate a minor compaction request on the table. 
Hive,WITHOUT_CLASSIFICATION,//  the function should support both short date and full timestamp format   time part of the timestamp should not be skipped 
Hive,WITHOUT_CLASSIFICATION,//  Primitive column types ignore nulls and just copy all values. 
Hive,WITHOUT_CLASSIFICATION,//  only input 2 side has nulls 
Hive,WITHOUT_CLASSIFICATION,// updating bucket column should move row from one file to another - not supported 
Hive,WITHOUT_CLASSIFICATION,//  LOG.info("Writing offset " + tailOffset + " at " + lrPtrOffset); 
Hive,WITHOUT_CLASSIFICATION,// make sure to get all deltas within a single transaction;  multi-statement txn  generate multiple delta files with the same txnId range  of course if maxWriteId has already been minor compacted all per statement deltas are obsolete 
Hive,WITHOUT_CLASSIFICATION,//  If the query contains more than one join 
Hive,WITHOUT_CLASSIFICATION,//  LOG.debug("finishOuterRepeated batch #" + batchCounter + " " + joinResult.name() + " batch.size " + batch.size + " someRowsFilteredOut " + someRowsFilteredOut); 
Hive,WITHOUT_CLASSIFICATION,/*  matches skewed values.  */
Hive,WITHOUT_CLASSIFICATION,//  Use vector parent to get VectorizationContext. 
Hive,WITHOUT_CLASSIFICATION,/*       here is a portion of the above "explain".  The "filterExpr:" in the TableScan is the pushed predicate      w/o PPD the line is simply not there otherwise the plan is the same       Map Operator Tree:         TableScan          alias: acidtbl          filterExpr: (a = 3) (type: boolean)            Filter Operator             predicate: (a = 3) (type: boolean)             Select Operator             ...        */
Hive,WITHOUT_CLASSIFICATION,//  Note - Kerberos user w/o appId doesn't have access. 
Hive,WITHOUT_CLASSIFICATION,//  Mixing down into the lower bits - this produces a worse hashcode in purely   numeric terms but leaving entropy in the higher bits is not useful for a   2^n bucketing scheme. See JSR166 ConcurrentHashMap r1.89 (released under Public Domain)   Note: ConcurrentHashMap has since reverted this to retain entropy bits higher   up to support the 2-level hashing for segment which operates at a higher bitmask 
Hive,WITHOUT_CLASSIFICATION,//  we need to check if the properties are valid especially for stats.   they might be changed via alter table .. update statistics or   alter table .. set tblproperties. If the property is not row_count   or raw_data_size it could not be changed through update statistics 
Hive,WITHOUT_CLASSIFICATION,/*             for table replication if we reach the max number of tasks then for the next run we will            try to reload the same table again this is mainly for ease of understanding the code            as then we can avoid handling == > loading partitions for the table given that            the creation of table lead to reaching max tasks vs  loading next table since current            one does not have partitions.            */
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setCharacterStream(int java.io.Reader   * long)    */
Hive,WITHOUT_CLASSIFICATION,//  prints short events information that are safe for consistent testing 
Hive,WITHOUT_CLASSIFICATION,//  LOG.debug("VectorMapJoinFastLongHashTable findReadSlot returning not found");   We know we never went that far when we were inserting.   LOG.debug("VectorMapJoinFastLongHashTable findReadSlot key " + key + " slot " + slot + " pairIndex " + pairIndex + " largestNumberOfSteps " + largestNumberOfSteps + " (i = " + i + ")"); 
Hive,WITHOUT_CLASSIFICATION,//  Create the output OI array 
Hive,WITHOUT_CLASSIFICATION,//  Expected for permanent UDFs at this point. 
Hive,WITHOUT_CLASSIFICATION,//  Use the current return type when creating a new call for   operators with return type built into the operator   definition and with no type inference rules such as   cast function with less than 2 operands. 
Hive,WITHOUT_CLASSIFICATION,//  1.2 Create TableScanDesc 
Hive,WITHOUT_CLASSIFICATION,//  if column value is provided replace column name with value 
Hive,WITHOUT_CLASSIFICATION,//  Hive UDTF only has a single input 
Hive,WITHOUT_CLASSIFICATION,//  Connection.getMetaData().getTableTypes() 
Hive,WITHOUT_CLASSIFICATION,//  Output will also be repeating and null 
Hive,WITHOUT_CLASSIFICATION,//  All are selected 
Hive,WITHOUT_CLASSIFICATION,//  SCHEMA_VERSIONS 
Hive,WITHOUT_CLASSIFICATION,//  returns Path of the partition created (if any) else Path of table 
Hive,WITHOUT_CLASSIFICATION,//  CredentialProvider/CredentialProviderFactory may not exist depending on the version of   hadoop-2 being used to build Hive. Use reflection to do the following lines   to allow the test to compile regardless of what version of hadoop-2.   Update credName entry in the credential provider.  CredentialProvider provider = CredentialProviderFactory.getProviders(conf).get(0);  provider.createCredentialEntry(credName credPassword.toCharArray());  provider.createCredentialEntry(credName3 credOnlyPassword.toCharArray());  provider.flush(); 
Hive,WITHOUT_CLASSIFICATION,//  sessionState.getQueueName() comes from cluster wide configured queue names.   sessionState.getConf().get("tez.queue.name") is explicitly set by user in a session.   TezSessionPoolManager sets tez.queue.name if user has specified one or use the one from   cluster wide queue names.   There is no way to differentiate how this was set (user vs system).   Unset this after opening the session so that reopening of session uses the correct queue   names i.e if client has not died and if the user has explicitly set a queue name 
Hive,WITHOUT_CLASSIFICATION,//  number of digits in a (1..37)   number of digits in b (1..37) 
Hive,WITHOUT_CLASSIFICATION,//  Table files don't have footer rows. 
Hive,WITHOUT_CLASSIFICATION,//  Reload tables from the MetaStore and create data files 
Hive,WITHOUT_CLASSIFICATION,//  Transport specific confs 
Hive,WITHOUT_CLASSIFICATION,//  For now only alter name owner class name type 
Hive,WITHOUT_CLASSIFICATION,/*  logicalColumnIndex  */
Hive,WITHOUT_CLASSIFICATION,//  Try to get cluster information once to avoid immediate cluster-update event in WM. 
Hive,WITHOUT_CLASSIFICATION,//  If we found an exact bin match for value v then just increment that bin's count.   Otherwise we need to insert a new bin and trim the resulting histogram back to size.   A possible optimization here might be to set some threshold under which 'v' is just   assumed to be equal to the closest bin -- if fabs(v-bins[bin].x) < THRESHOLD then   just increment 'bin'. This is not done now because we don't want to make any 
Hive,WITHOUT_CLASSIFICATION,//  Counters for debugging we cannot use existing counters (cntr and nextCntr)   in Operator since we want to individually track the number of rows from 
Hive,WITHOUT_CLASSIFICATION,//  There may be multiple selects - chose the one closest to the table 
Hive,WITHOUT_CLASSIFICATION,//  Look for single column optimization. 
Hive,WITHOUT_CLASSIFICATION,//  Test alter table 
Hive,WITHOUT_CLASSIFICATION,//  However it must end after the split end otherwise the next one would have been read. 
Hive,WITHOUT_CLASSIFICATION,//  get partition metadata if partition specified 
Hive,WITHOUT_CLASSIFICATION,/*                * Restriction 2.h Subquery isnot allowed in LHS                */
Hive,WITHOUT_CLASSIFICATION,//  if aggr is distinct the parameter is name is constructed as   KEY.lastKeyColName:<tag>._colx 
Hive,WITHOUT_CLASSIFICATION,//  OR(=($0 1) =($0 2) AND(=($0 0) =($1 8)))   transformation creates 9 nodes AND(OR(=($0 1) =($0 2) =($0 0)) OR(=($0 1) =($0 2) =($1 8)))   thus it is NOT triggered 
Hive,WITHOUT_CLASSIFICATION,//  The user has not returned and the kill has failed.   We are going to brute force kill the AM; whatever user does is now irrelevant. 
Hive,WITHOUT_CLASSIFICATION,//  create new local work and setup the dummy ops 
Hive,WITHOUT_CLASSIFICATION,//  We cannot merge (1.1) 
Hive,WITHOUT_CLASSIFICATION,// found a conflict 
Hive,WITHOUT_CLASSIFICATION,//  Turn on speculative execution for reducers 
Hive,WITHOUT_CLASSIFICATION,// We can read more than we need if the actualCount is not multiple   of the byteBuffer size and file is big enough. In that case we cannot  use flip method but we need to set buffer limit manually to trans. 
Hive,WITHOUT_CLASSIFICATION,//  Remove unused table scan operators 
Hive,WITHOUT_CLASSIFICATION,//  compare hive version and metastore version 
Hive,WITHOUT_CLASSIFICATION,//  rowId <= 'm' 
Hive,WITHOUT_CLASSIFICATION,/*    * Pass in configs and pre-create a parse context    */
Hive,WITHOUT_CLASSIFICATION,//  if we got exception during doing the unlock rethrow it here 
Hive,WITHOUT_CLASSIFICATION,//  both the classname and the protocol name are Table properties   the only hardwired assumption is that records are fixed on a   per Table basis 
Hive,WITHOUT_CLASSIFICATION,//  COL_NAME 
Hive,WITHOUT_CLASSIFICATION,//  Get the parameter values 
Hive,WITHOUT_CLASSIFICATION,// SubQueryUtils.rewriteParentQueryWhere(clonedSearchCond subQueryAST); 
Hive,WITHOUT_CLASSIFICATION,//  now this shouldn't find the path on the fs 
Hive,WITHOUT_CLASSIFICATION,//  we're replacing the current big table with a new one. Need   to count the current one as a map table then. 
Hive,WITHOUT_CLASSIFICATION,/*          * Get our Single-Column String hash map information for this specialized class.          */
Hive,WITHOUT_CLASSIFICATION,//  For the current context for generating File Sink Operator it is either INSERT INTO or INSERT OVERWRITE. 
Hive,WITHOUT_CLASSIFICATION,//  default is ClassLoaderContextSelector which is created during automatic logging   initialization in a static initialization block.   Changing ContextSelector at runtime requires creating new context factory which will   internally create new context selector based on system property. 
Hive,WITHOUT_CLASSIFICATION,//  Poll on the operation status till the operation is complete 
Hive,WITHOUT_CLASSIFICATION,// second column exists 
Hive,WITHOUT_CLASSIFICATION,//  Start an INSERT statement transaction and roll back this transaction. 
Hive,WITHOUT_CLASSIFICATION,//  Set the table as transactional for compaction to work 
Hive,WITHOUT_CLASSIFICATION,// Update min counter if new value is less than min seen so far 
Hive,WITHOUT_CLASSIFICATION,//  in the absence of uncompressed/raw data size total file size will be used for statistics   annotation. But the file may be compressed encoded and serialized which may be lesser in size   than the actual uncompressed/raw data size. This factor will be multiplied to file size to estimate 
Hive,WITHOUT_CLASSIFICATION,//  Restore the interrupted status since we do not want to catch it. 
Hive,WITHOUT_CLASSIFICATION,//  set all properties specified via command line 
Hive,WITHOUT_CLASSIFICATION,//  Operand one|Operand another | or result   unknown | T | T 
Hive,WITHOUT_CLASSIFICATION,//  Now output this timestamp's millis value to the equivalent toTz. 
Hive,WITHOUT_CLASSIFICATION,//  To avoid having a huge BloomFilter we need to scale up False Positive Probability 
Hive,WITHOUT_CLASSIFICATION,//  Setup deserializer/obj inspectors for the incoming data source 
Hive,WITHOUT_CLASSIFICATION,//  estimate row count 
Hive,WITHOUT_CLASSIFICATION,/*  we just made an existing table full acid which wasn't acid before and it passed all checks      initialize the Write ID sequence so that we can handle assigning ROW_IDs to 'original'      files already present in the table.  */
Hive,WITHOUT_CLASSIFICATION,// catching exceptions here makes sure that the thread doesn't die in case of unexpected  exceptions 
Hive,WITHOUT_CLASSIFICATION,//  check only the partition that exists all should be well 
Hive,WITHOUT_CLASSIFICATION,//  constant varchar projection 
Hive,WITHOUT_CLASSIFICATION,//  3. SelectOperator should use only simple cast/column access 
Hive,WITHOUT_CLASSIFICATION,// load same data again (additive) 
Hive,WITHOUT_CLASSIFICATION,//  The pool is empty; queue the request. 
Hive,WITHOUT_CLASSIFICATION,/*  100 files x 1000 size for 111 splits  */
Hive,WITHOUT_CLASSIFICATION,//  2. Build nonPart/Part/Virtual column info for new RowSchema 
Hive,WITHOUT_CLASSIFICATION,//  histogram used for quantile approximation   the quantiles requested 
Hive,WITHOUT_CLASSIFICATION,//  because only 10 fractional digits it's not this much accurate 
Hive,WITHOUT_CLASSIFICATION,/*    * This test collector operator is for MapJoin row-mode.    */
Hive,WITHOUT_CLASSIFICATION,//  Should this also just be ignored? Throw for now doAs unlike queue is often set by admin. 
Hive,WITHOUT_CLASSIFICATION,//  NOT_NULL_CONSTRAINT_COLS 
Hive,WITHOUT_CLASSIFICATION,// If it's a FileSink to bucketed files use the bucket count as the reducer number 
Hive,WITHOUT_CLASSIFICATION,//     Collections.sort(kvs CellComparator.COMPARATOR); 
Hive,WITHOUT_CLASSIFICATION,//  Determine input vector expression using the VectorizationContext. 
Hive,WITHOUT_CLASSIFICATION,//  Initialize the resources from command line 
Hive,WITHOUT_CLASSIFICATION,//  is source CMD 
Hive,WITHOUT_CLASSIFICATION,//  Fall through and look for other options... 
Hive,WITHOUT_CLASSIFICATION,//  The union task is empty. The files created for all the inputs are   assembled in the union context and later used to initialize the union   plan 
Hive,WITHOUT_CLASSIFICATION,//  see DefaultRuleDispatcher#dispatch() 
Hive,WITHOUT_CLASSIFICATION,//  first project all group-by keys plus the transformed agg input 
Hive,WITHOUT_CLASSIFICATION,//  If we've filled the buffer write it out 
Hive,WITHOUT_CLASSIFICATION,//  Unknown category 
Hive,WITHOUT_CLASSIFICATION,//  Before Cleaner there should be 6 items: 
Hive,WITHOUT_CLASSIFICATION,// abort proactively so that we don't wait for timeout  perhaps we should add a version of RecordWriter.closeBatch(boolean abort) which 
Hive,WITHOUT_CLASSIFICATION,//  restore data 
Hive,WITHOUT_CLASSIFICATION,//  branch 
Hive,WITHOUT_CLASSIFICATION,//  Fail if mis-configured. 
Hive,WITHOUT_CLASSIFICATION,//  if not every partition uses bitvector for ndv we just fall back to   the traditional extrapolation methods. 
Hive,WITHOUT_CLASSIFICATION,//  Flip inclusion. 
Hive,WITHOUT_CLASSIFICATION,//  Monday 1st July 1985 12:00:00 AM 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setBinaryStream(int java.io.InputStream)    */
Hive,WITHOUT_CLASSIFICATION,//  blank " " (1 byte)   Smiling Face with Open Mouth and Smiling Eyes U+1F604 (4 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  database. 
Hive,WITHOUT_CLASSIFICATION,// Asserting other partition parameters can also be changed but not the location 
Hive,WITHOUT_CLASSIFICATION,//  Message Bus related properties. 
Hive,WITHOUT_CLASSIFICATION,//  This method is used to check whether the subType is a sub type of the groupType.   For nested attribute we need to check its existence by the root path in a recursive way. 
Hive,WITHOUT_CLASSIFICATION,//  (numSlotsAvailable can go negative if the callback after the thread completes is delayed) 
Hive,WITHOUT_CLASSIFICATION,//  This is expected 
Hive,WITHOUT_CLASSIFICATION,//  Check the limit 
Hive,WITHOUT_CLASSIFICATION,//  this is for ConditionalTask 
Hive,WITHOUT_CLASSIFICATION,//  We get the information from Calcite. 
Hive,WITHOUT_CLASSIFICATION,//  With a timeout of 3000. 
Hive,WITHOUT_CLASSIFICATION,//  Per JDBC spec if the driver does not support catalogs   it will silently ignore this request. 
Hive,WITHOUT_CLASSIFICATION,//  check entries beyond 2nd one 
Hive,WITHOUT_CLASSIFICATION,//  TODO: assert iKey is HBaseSerDe#HBASE_KEY_COL 
Hive,WITHOUT_CLASSIFICATION,//  need different record handler for MergeFileWork 
Hive,WITHOUT_CLASSIFICATION,//  Set constraint name if null before sending to listener 
Hive,WITHOUT_CLASSIFICATION,//  The common case by far. 
Hive,WITHOUT_CLASSIFICATION,/*          * if the keyHash is missing in the bloom filter then the value cannot exist in any of the         * spilled partition - return NOMATCH          */
Hive,WITHOUT_CLASSIFICATION,//  right now are a few cheap redundant update calls; let's just do the simple thing. 
Hive,WITHOUT_CLASSIFICATION,//  Update messages 
Hive,WITHOUT_CLASSIFICATION,//  HiveConf hive.stats.ndv.error default produces 16 
Hive,WITHOUT_CLASSIFICATION,//  a column family becomes a MAP 
Hive,WITHOUT_CLASSIFICATION,//  Make sure Hadoop credentials objects do not reuse the maps. 
Hive,WITHOUT_CLASSIFICATION,//  Setup the necessary metadata if originating from analyze rewrite 
Hive,WITHOUT_CLASSIFICATION,//  Ensure Pig schema is correct. 
Hive,WITHOUT_CLASSIFICATION,//  either variables will never be null because a default value is returned in case of absence 
Hive,WITHOUT_CLASSIFICATION,//  Allocate writeId from test txn and then verify ValidWriteIdList.   Write Ids of committed and self test txn should be valid but writeId of open txn should be invalid. 
Hive,WITHOUT_CLASSIFICATION,// see bucket_num_reducers.q bucket_num_reducers2.q   todo: try using set VerifyNumReducersHook.num.reducers=10; 
Hive,WITHOUT_CLASSIFICATION,//  Not supported for the test case 
Hive,WITHOUT_CLASSIFICATION,/*    * If this task contains a sortmergejoin it can be converted to a map-join task if this operator   * is present in the mapper. For eg. if a sort-merge join operator is present followed by a   * regular join it cannot be converted to a auto map-join.    */
Hive,WITHOUT_CLASSIFICATION,//  link the work with the work associated with the reduce sink that triggered this rule 
Hive,WITHOUT_CLASSIFICATION,//  First handle the condition where the first fetch was never done (big table is empty). 
Hive,WITHOUT_CLASSIFICATION,//  First try to extract a long value from the strings and compare them. 
Hive,WITHOUT_CLASSIFICATION,//  UNDONE: For now all... 
Hive,WITHOUT_CLASSIFICATION,//  user did NOT specify partition 
Hive,WITHOUT_CLASSIFICATION,// For Windows OS we need to pass HIVE_HADOOP_CLASSPATH Java parameter while starting 
Hive,WITHOUT_CLASSIFICATION,//  test the same day of month 
Hive,WITHOUT_CLASSIFICATION,//  class PartitionListComposingSpecProxy; 
Hive,WITHOUT_CLASSIFICATION,//  skewed value 
Hive,WITHOUT_CLASSIFICATION,//  Build row type from field <type name> 
Hive,WITHOUT_CLASSIFICATION,//  Simple truncation. 
Hive,WITHOUT_CLASSIFICATION,//  iterate through all RS and locate the one introduce by enforce bucketing 
Hive,WITHOUT_CLASSIFICATION,//  Fail - "transactional" is set to true but the table is not bucketed 
Hive,WITHOUT_CLASSIFICATION,//  Verify that we have got correct set of delete_deltas. 
Hive,WITHOUT_CLASSIFICATION,//  v[5] is not calculated since high integer is always 0 for our decimals. 
Hive,WITHOUT_CLASSIFICATION,//  It is possible to have a file with same checksum in cmPath but the content is   partially copied or corrupted. In this case just overwrite the existing file with   new one. 
Hive,WITHOUT_CLASSIFICATION,//  skip when already at EOF: 
Hive,WITHOUT_CLASSIFICATION,/*  Test parent references from PreparedStatement  */
Hive,WITHOUT_CLASSIFICATION,//  pos of driver alias 
Hive,WITHOUT_CLASSIFICATION,//  We use a mapping object here so we can build the projection in any order and   get the ordered by 0 to n-1 output columns at the end.     Also to avoid copying a big table key into the small table result area for inner joins   we reference it with the projection so there can be duplicate output columns 
Hive,WITHOUT_CLASSIFICATION,//  requires exact types on both sides of SetOp) 
Hive,WITHOUT_CLASSIFICATION,//  Physical optimizers which follow this need to be careful not to invalidate the inferences   made by this optimizer. Only optimizers which depend on the results of this one should 
Hive,WITHOUT_CLASSIFICATION,//  We can use the whole batch for output of no matches. 
Hive,WITHOUT_CLASSIFICATION,/*    * Return length in characters of UTF8 string in byte array   * beginning at start that is len bytes long.    */
Hive,WITHOUT_CLASSIFICATION,/*  *	Source code for the "strtod" library procedure. * * Copyright 1988-1992 Regents of the University of California * Permission to use copy modify and distribute this * software and its documentation for any purpose and without * fee is hereby granted provided that the above copyright * notice appear in all copies.  The University of California * makes no representations about the suitability of this * software for any purpose.  It is provided "as is" without * express or implied warranty.  */
Hive,WITHOUT_CLASSIFICATION,//  For caching aggregate column stats for all and all minus default partition   Key is column name and the value is a list of 2 col stat objects 
Hive,WITHOUT_CLASSIFICATION,//  figure out which kind of bloom filter we want for each column   picks bloom_filter_utf8 if its available otherwise bloom_filter 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) UnflagArgs  */
Hive,WITHOUT_CLASSIFICATION,//  All selected do nothing 
Hive,WITHOUT_CLASSIFICATION,//  Hive 0.12 behavior where double * decimal -> decimal is gone. 
Hive,WITHOUT_CLASSIFICATION,//  No VectorUDFAdaptor usage. 
Hive,WITHOUT_CLASSIFICATION,//  default 
Hive,WITHOUT_CLASSIFICATION,//  add all children 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   required   optional   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  always just write mono 
Hive,WITHOUT_CLASSIFICATION,//  check if all parents are finished 
Hive,WITHOUT_CLASSIFICATION,/*  * This is the base class for the output parser. * Output parser will parse the output of a Pig/ * Hive/Hadoop or other job and extract jobid. * Note Hadoop jobid extract is rely on the API * Hadoop application submitting the job. Different * api will result in different console output. The * jobid extraction logic is not always working in * this case  */
Hive,WITHOUT_CLASSIFICATION,//  Use UserPayloadProto.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,// gbInfo already has ExprNode for gbkeys 
Hive,WITHOUT_CLASSIFICATION,//  testing druid queries row filtering is present 
Hive,WITHOUT_CLASSIFICATION,//  default no-op implementation 
Hive,WITHOUT_CLASSIFICATION,//  Just remove delete_delta if there have been no delete events. 
Hive,WITHOUT_CLASSIFICATION,//  TABLE-ONLY fetch partitions if regular export don't if metadata-only 
Hive,WITHOUT_CLASSIFICATION,/*    * A PTF Function must provide the 'external' names of the columns in the transformed Raw Input.   *    */
Hive,WITHOUT_CLASSIFICATION,//  MUTATE DATA 
Hive,WITHOUT_CLASSIFICATION,//  nullIndicator is now at a different location in the output of 
Hive,WITHOUT_CLASSIFICATION,//  Make sure we only return valDecompressor once. 
Hive,WITHOUT_CLASSIFICATION,// 0 means there is no transaction i.e. it a select statement which is not part of  explicit transaction or a IUD statement that is not writing to ACID table 
Hive,WITHOUT_CLASSIFICATION,//  use tez to combine splits 
Hive,WITHOUT_CLASSIFICATION,//  New plan is absolutely better than old plan. 
Hive,WITHOUT_CLASSIFICATION,//  IS_ENABLE_AND_ACTIVATE 
Hive,WITHOUT_CLASSIFICATION,//  No Op return to the caller since long polling timeout has expired 
Hive,WITHOUT_CLASSIFICATION,//  See the above. Release the headers after unlocking. 
Hive,WITHOUT_CLASSIFICATION,//  Note: just like the move path we only do one level of recursion. 
Hive,WITHOUT_CLASSIFICATION,//  test repeating nulls case 
Hive,WITHOUT_CLASSIFICATION,/*    * Allocate the source deserialization related arrays.    */
Hive,WITHOUT_CLASSIFICATION,//  Nothing to do. 
Hive,WITHOUT_CLASSIFICATION,//  RexLiteral's equal only consider value and type which isn't sufficient   so providing custom comparator which distinguishes b/w objects irrespective   of value/type 
Hive,WITHOUT_CLASSIFICATION,//  This should never happen if it does it's a bug with the potential to produce   incorrect results. 
Hive,WITHOUT_CLASSIFICATION,//  Get estimation parameters 
Hive,WITHOUT_CLASSIFICATION,//  The IEEE 754 floating point spec specifies that signed -0.0 and 0.0 should be treated as equal. 
Hive,WITHOUT_CLASSIFICATION,//  temporary single-batch context used for vectorization 
Hive,WITHOUT_CLASSIFICATION,//  Consider a query like: select * from V where the view V is defined as:   select * from T   The inputs will contain V and T (parent: V)   T will be marked as an indirect entity using isDirect flag.   This will help in distinguishing from the case where T is a direct dependency 
Hive,WITHOUT_CLASSIFICATION,//  violation in ETL queue 
Hive,WITHOUT_CLASSIFICATION,//  Table created in hive catalog should have been automatically set to transactional 
Hive,WITHOUT_CLASSIFICATION,//     operators 
Hive,WITHOUT_CLASSIFICATION,//  1. Kill queries. 
Hive,WITHOUT_CLASSIFICATION,//  Allocate output column and get column number; 
Hive,WITHOUT_CLASSIFICATION,//  partSpecToFileMapping is null if big table is partitioned 
Hive,WITHOUT_CLASSIFICATION,//  Clear completed instances in this case. Don't want to provide information from the previous run. 
Hive,WITHOUT_CLASSIFICATION,//  Determine the transaction manager to use from the configuration. 
Hive,WITHOUT_CLASSIFICATION,//  Drop the tables when we're done.  This makes the test work inside an IDE 
Hive,WITHOUT_CLASSIFICATION,//  History File stream 
Hive,WITHOUT_CLASSIFICATION,//  the version that was included with the original magic which is mapped 
Hive,WITHOUT_CLASSIFICATION,/*  Datatype of column  */
Hive,WITHOUT_CLASSIFICATION,//  prove invariant to the compiler: len1 = len2   all array access between (start1 start1+len1)    and (start2 start2+len2) are valid   no more OOB exceptions are possible 
Hive,WITHOUT_CLASSIFICATION,/*    * RowResolver helper methods    */
Hive,WITHOUT_CLASSIFICATION,//  Execute generated plan. 
Hive,WITHOUT_CLASSIFICATION,//  it may be a field name return the identifier and let the caller decide   whether it is or not 
Hive,WITHOUT_CLASSIFICATION,//  set of joins already processed 
Hive,WITHOUT_CLASSIFICATION,//  Establish context 
Hive,WITHOUT_CLASSIFICATION,// no such partition 
Hive,WITHOUT_CLASSIFICATION,//  Check the stripped property is the empty string 
Hive,WITHOUT_CLASSIFICATION,//  if all the ColumnStatisticsObjs contain bitvectors we do not need to   use uniform distribution assumption because we can merge bitvectors   to get a good estimation. 
Hive,WITHOUT_CLASSIFICATION,//  Create a data container 
Hive,WITHOUT_CLASSIFICATION,//  should not happen 
Hive,WITHOUT_CLASSIFICATION,//  Test that exclusive blocks exclusive and write 
Hive,WITHOUT_CLASSIFICATION,//  when we run a task after the jar has been added. 
Hive,WITHOUT_CLASSIFICATION,//  Whether the IF statement boolean expression was repeating. 
Hive,WITHOUT_CLASSIFICATION,//  split the children into vertices that make up the union and vertices that are 
Hive,WITHOUT_CLASSIFICATION,//  figure out correlation and presence of non-equi join predicate 
Hive,WITHOUT_CLASSIFICATION,//  appends might exist after the root message so strip tokens off until we 
Hive,WITHOUT_CLASSIFICATION,//  array of strings type or an array of arrays of strings. 
Hive,WITHOUT_CLASSIFICATION,//  If this constant was created while doing constant folding foldedFromCol holds the name of   original column from which it was folded. 
Hive,WITHOUT_CLASSIFICATION,// Override Hive specific operators 
Hive,WITHOUT_CLASSIFICATION,//  Not the right host. 
Hive,WITHOUT_CLASSIFICATION,//  We only need a username for UGI to use for groups; getGroups will fetch the groups   based on Hadoop configuration as documented at 
Hive,WITHOUT_CLASSIFICATION,// make sure not to loose 
Hive,WITHOUT_CLASSIFICATION,//  when bias correction is enabled 
Hive,WITHOUT_CLASSIFICATION,//  Release the unreleased stripe-level buffers. See class comment about refcounts. 
Hive,WITHOUT_CLASSIFICATION,//  1 is excluded via property 3 already has stats so we only expect two updates. 
Hive,WITHOUT_CLASSIFICATION,//  This run of Initiator doesn't add any compaction_queue entry 
Hive,WITHOUT_CLASSIFICATION,//  1) We extract the collations indices 
Hive,WITHOUT_CLASSIFICATION,//  Test that existing shared_read table with new shared_read coalesces to 
Hive,WITHOUT_CLASSIFICATION,//  run as a batch 
Hive,WITHOUT_CLASSIFICATION,//  Woe us. 
Hive,WITHOUT_CLASSIFICATION,//  Verify dropTable recycle partition files 
Hive,WITHOUT_CLASSIFICATION,//  avoid instantiation 
Hive,WITHOUT_CLASSIFICATION,//  Return just the single Range 
Hive,WITHOUT_CLASSIFICATION,//  only green qualifies and it's in entry 1 
Hive,WITHOUT_CLASSIFICATION,//  Add cast expression if needed. Child expressions of a udf may return different data types   and that would require converting their data types to evaluate the udf.   For example decimal column added to an integer column would require integer column to be   cast to decimal. 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: partColsIsNull is only used for PTF which isn't supported yet. 
Hive,WITHOUT_CLASSIFICATION,//  Possible reasons to end up here:   - Unable to read version from manifest.mf   - Version string is not in the proper X.x.xxx format 
Hive,WITHOUT_CLASSIFICATION,//  Complex type constants currently not supported by VectorUDFArgDesc.prepareConstant. 
Hive,WITHOUT_CLASSIFICATION,//  Handle normal case 
Hive,WITHOUT_CLASSIFICATION,//  Current match may be out of order w.r.t. the global name list so add specific parts. 
Hive,WITHOUT_CLASSIFICATION,//  COL_NAMESPACE 
Hive,WITHOUT_CLASSIFICATION,//  no need to override assigns - all assign ops will fail due to 0 size 
Hive,WITHOUT_CLASSIFICATION,//  -D 
Hive,WITHOUT_CLASSIFICATION,//  for each row as it is produced 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#createClob()    */
Hive,WITHOUT_CLASSIFICATION,//  Insert junk in middle of file. Assumes file is on local disk. 
Hive,WITHOUT_CLASSIFICATION,//  rename partitioned table 
Hive,WITHOUT_CLASSIFICATION,//  All values are filtered out 
Hive,WITHOUT_CLASSIFICATION,// Final check find size of already-calculated Mapjoin Operators in same work (spark-stage). 
Hive,WITHOUT_CLASSIFICATION,// Current state of each selected column - e.g. current run length etc. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure the proper transaction manager that supports ACID is being used 
Hive,WITHOUT_CLASSIFICATION,//  find the same key 
Hive,WITHOUT_CLASSIFICATION,//  Invalid app name. Checked later. 
Hive,WITHOUT_CLASSIFICATION,//  We cannot apply the reduction 
Hive,WITHOUT_CLASSIFICATION,//  Accept int writables and convert them. 
Hive,WITHOUT_CLASSIFICATION,//  row 2 - results should be null 
Hive,WITHOUT_CLASSIFICATION,//  Allow date to string casts.  NOTE: I suspect this is the reverse of what we actually   want but it matches the code in o.a.h.h.serde2.typeinfo.TypeInfoUtils.  I can't see how   users would be altering date columns into string columns.  The other I easily see since   Hive did not originally support datetime types.  Also the comment in the Hive code   says string to date even though the code does the opposite.  But for now I'm keeping 
Hive,WITHOUT_CLASSIFICATION,//  number of aborted txns found in exceptions 
Hive,WITHOUT_CLASSIFICATION,//  Launch Task 
Hive,WITHOUT_CLASSIFICATION,//  Test a single high-precision multiply of random inputs. 
Hive,WITHOUT_CLASSIFICATION,//  each branch 
Hive,WITHOUT_CLASSIFICATION,/*  We just checked the user specified schema columns among regular table column and found some which are not            'regular'.  Now check is they are dynamic partition columns              For dynamic partitioning              Given "create table multipart(a int b int) partitioned by (c int d int);"              for "insert into multipart partition(c='1'd)(da) values(23);" we expect parse tree to look like this               (TOK_INSERT_INTO                (TOK_TAB                  (TOK_TABNAME multipart)                  (TOK_PARTSPEC                    (TOK_PARTVAL c '1')                    (TOK_PARTVAL d)                  )                )                (TOK_TABCOLNAME d a)               ) */
Hive,WITHOUT_CLASSIFICATION,// We have found a valid cookie in the client request. 
Hive,WITHOUT_CLASSIFICATION,//  -h 
Hive,WITHOUT_CLASSIFICATION,//  Do any of the other fields need to be set? 
Hive,WITHOUT_CLASSIFICATION,//  Open 5 txns 
Hive,WITHOUT_CLASSIFICATION,//  If the inputOI is the same as the outputOI just return an   IdentityConverter. 
Hive,WITHOUT_CLASSIFICATION,//  "(TS%FIL%)|(TS%FIL%FIL%)" 
Hive,WITHOUT_CLASSIFICATION,//  Pretend like it has fractional digits so we can get the trailing zero count. 
Hive,WITHOUT_CLASSIFICATION,//  The output path used by the subclasses.   Used as a final destination; same as outPath for MM tables. 
Hive,WITHOUT_CLASSIFICATION,//  if TopNHashes are active proceed if not already excluded (i.e order by limit) 
Hive,WITHOUT_CLASSIFICATION,//  No need to check again if it exists. 
Hive,WITHOUT_CLASSIFICATION,//  Normally on import trying to create a table or a partition in a db that does not yet exist   is a error condition. However in the case of a REPL LOAD it is possible that we are trying   to create tasks to create a table inside a db that as-of-now does not exist but there is   a precursor Task waiting that will create it before this is encountered. Thus we instantiate   defaults and do not error out in that case. 
Hive,WITHOUT_CLASSIFICATION,//  D2 already done - iulRindex initialized before normalization of R. 
Hive,WITHOUT_CLASSIFICATION,//  Empty list 
Hive,WITHOUT_CLASSIFICATION,//  this indicates original query was either correlated EXISTS or IN 
Hive,WITHOUT_CLASSIFICATION,//  -g 
Hive,WITHOUT_CLASSIFICATION,//  In future this may examine config to return appropriate HCatReader 
Hive,WITHOUT_CLASSIFICATION,//  specific files if they exist. 
Hive,WITHOUT_CLASSIFICATION,/*   This class authenticates HS2 web UI via PAM. To authenticate use   * httpGet with header name "Authorization"   * and header value "Basic authB64Code"    where  authB64Code is Base64 string for "login:password"  */
Hive,WITHOUT_CLASSIFICATION,//  Indices 
Hive,WITHOUT_CLASSIFICATION,//  Convert the work in the SMB plan to a regular join   Note that the operator tree is not fixed only the path/alias mappings in the   plan are fixed. The operator tree will still contain the SMBJoinOperator 
Hive,WITHOUT_CLASSIFICATION,// create a file we'll import later 
Hive,WITHOUT_CLASSIFICATION,//  local mode   command like dfs 
Hive,WITHOUT_CLASSIFICATION,//  Have to rely on Hive implementation of filesystem permission checks. 
Hive,WITHOUT_CLASSIFICATION,//  1. Generate RS operator   1.1 Prune the tableNames only count the tableNames that are not empty strings   as empty string in table aliases is only allowed for virtual columns. 
Hive,WITHOUT_CLASSIFICATION,//  Not using ByRef now since it's unsafe for text readers. Might be safe for others. 
Hive,WITHOUT_CLASSIFICATION,//  For compare we will convert requisite children   For BETWEEN skip the first child (the revert boolean) 
Hive,WITHOUT_CLASSIFICATION,//  CREATE TABLE ... AS 
Hive,WITHOUT_CLASSIFICATION,//  handle repeating null 
Hive,WITHOUT_CLASSIFICATION,//  Indicate we used the last row's bytes for large buffer. 
Hive,WITHOUT_CLASSIFICATION,//  MSCK called to drop stale paritions from metastore and there are   stale partitions. 
Hive,WITHOUT_CLASSIFICATION,//  Add signature 
Hive,WITHOUT_CLASSIFICATION,//  key = (key + (key << 3)) + (key << 11); 
Hive,WITHOUT_CLASSIFICATION,//  Turn off passwords enable sasl and set a keytab 
Hive,WITHOUT_CLASSIFICATION,/*    * Outer join (hash map).    */
Hive,WITHOUT_CLASSIFICATION,//  clear the previous values recorded. 
Hive,WITHOUT_CLASSIFICATION,//  Classify partitions within the table directory into groups   based on shared SD properties. 
Hive,WITHOUT_CLASSIFICATION,//  Initialize the metrics system 
Hive,WITHOUT_CLASSIFICATION,//  to use MiniMRCluster. MAPREDUCE-2350 
Hive,WITHOUT_CLASSIFICATION,//  handle repeating case 
Hive,WITHOUT_CLASSIFICATION,//  If (numReducers > 0 && newNumReducers > 0 && newNumReducers != numReducers)   we will not consider ReduceSinkOperator with this newNumReducer as a correlated   ReduceSinkOperator 
Hive,WITHOUT_CLASSIFICATION,//  Perform a major compaction 
Hive,WITHOUT_CLASSIFICATION,/*    * Verify table for Key: byte[] x Hash Table: HashMap    */
Hive,WITHOUT_CLASSIFICATION,/*        * Now new job requests should succeed as list operation has no cancel threads.        */
Hive,WITHOUT_CLASSIFICATION,//  hive added files and jars 
Hive,WITHOUT_CLASSIFICATION,//  next node in consistent order died or does not have free slots rollover to next 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: power can be positive or negative.   NOTE: e.g. power = 2 is effectively multiply by 10^2 
Hive,WITHOUT_CLASSIFICATION,//  add the privs for roles in curRoles to new role-to-priv map 
Hive,WITHOUT_CLASSIFICATION,//  DEFAULT_PARTITION_NAME 
Hive,WITHOUT_CLASSIFICATION,//  Get our vector map join fast hash table variation from the   vector map join table container. 
Hive,WITHOUT_CLASSIFICATION,//  LOG.info("VectorMapJoinFastTableContainer load keyCountAdj " + keyCountAdj);   LOG.info("VectorMapJoinFastTableContainer load threshold " + threshold);   LOG.info("VectorMapJoinFastTableContainer load loadFactor " + loadFactor);   LOG.info("VectorMapJoinFastTableContainer load wbSize " + wbSize); 
Hive,WITHOUT_CLASSIFICATION,//  Insert 5 rows to both tables 
Hive,WITHOUT_CLASSIFICATION,//  retrieve token and store in the cache 
Hive,WITHOUT_CLASSIFICATION,//  The ANTLR grammar looks like :   1.  KW_CONSTRAINT idfr=identifier KW_FOREIGN KW_KEY fkCols=columnParenthesesList   KW_REFERENCES tabName=tableName parCols=columnParenthesesList   enableSpec=enableSpecification validateSpec=validateSpecification relySpec=relySpecification   -> ^(TOK_FOREIGN_KEY $idfr $fkCols $tabName $parCols $relySpec $enableSpec $validateSpec)   when the user specifies the constraint name (i.e. child.getChildCount() == 7)   2.  KW_FOREIGN KW_KEY fkCols=columnParenthesesList   KW_REFERENCES tabName=tableName parCols=columnParenthesesList   enableSpec=enableSpecification validateSpec=validateSpecification relySpec=relySpecification   -> ^(TOK_FOREIGN_KEY $fkCols  $tabName $parCols $relySpec $enableSpec $validateSpec)   when the user does not specify the constraint name (i.e. child.getChildCount() == 6) 
Hive,WITHOUT_CLASSIFICATION,//  Order keys 
Hive,WITHOUT_CLASSIFICATION,//  replace bucketing columns with hashcode % numBuckets 
Hive,WITHOUT_CLASSIFICATION,//  Create IN clauses 
Hive,WITHOUT_CLASSIFICATION,/*      * This test verifies that the ALTER TABLE ... SET OWNER command will change the     * owner metadata of the table in HMS.      */
Hive,WITHOUT_CLASSIFICATION,//  5. Release the copies we made directly to the cleaner. 
Hive,WITHOUT_CLASSIFICATION,/*      * Convert our source object we just read into the target object and store that in the     * VectorizedRowBatch.      */
Hive,WITHOUT_CLASSIFICATION,// prefixing with '_mask_' to ensure no conflict with named  columns in the file schema 
Hive,WITHOUT_CLASSIFICATION,//  LOG.info("returning "+t); 
Hive,WITHOUT_CLASSIFICATION,//  simple join from 2 relations: denom = max(v1 v2) 
Hive,WITHOUT_CLASSIFICATION,//  look for any valid versions.  This will also throw NoSuchObjectException if the schema   itself doesn't exist which is what we want. 
Hive,WITHOUT_CLASSIFICATION,//  Hive will re-use the Configuration object that it passes in to be   initialized.  Therefore we need to make sure we don't look for any 
Hive,WITHOUT_CLASSIFICATION,//  in this TestFilter. 
Hive,WITHOUT_CLASSIFICATION,//  Protected for testing and so we can pass in a conf for testing. 
Hive,WITHOUT_CLASSIFICATION,//  grantor 
Hive,WITHOUT_CLASSIFICATION,//  get the list of Dynamic partition paths 
Hive,WITHOUT_CLASSIFICATION,//  100 is the start 
Hive,WITHOUT_CLASSIFICATION,/*  * - starting from the given rowIdx scan in the given direction until a row's expr * evaluates to an amt that crosses the 'amt' threshold specified in the BoundaryDef.  */
Hive,WITHOUT_CLASSIFICATION,//  Try to read the dropped partition via CachedStore 
Hive,WITHOUT_CLASSIFICATION,//  string IN 
Hive,WITHOUT_CLASSIFICATION,//  1)  to partitioned table 
Hive,WITHOUT_CLASSIFICATION,//  nothing to add 
Hive,WITHOUT_CLASSIFICATION,//  Task has completed 
Hive,WITHOUT_CLASSIFICATION,//  src.position(start) can't accept negative numbers. 
Hive,WITHOUT_CLASSIFICATION,//  need three params to differentiate between this and 2 param method auto   generated since   some calls in the autogenerated code use null param for 2nd param and thus 
Hive,WITHOUT_CLASSIFICATION,//  Note: we don't add ADDED jars RELOADABLE jars etc. That is by design; there are too many ways   to add jars in Hive some of which are session/etc. specific. Env + conf + arg should be enough. 
Hive,WITHOUT_CLASSIFICATION,//  Create Key/Value TableDesc. When the operator plan is split into MR tasks   the reduce operator will initialize Extract operator with information 
Hive,WITHOUT_CLASSIFICATION,//  If we've opened a transaction we need to commit or rollback rather than explicitly 
Hive,WITHOUT_CLASSIFICATION,/*      * CHAR: strategic blanks string length beyond max      */
Hive,WITHOUT_CLASSIFICATION,//  c14:map<intmap<intint>> 
Hive,WITHOUT_CLASSIFICATION,//  fallback to regular logic 
Hive,WITHOUT_CLASSIFICATION,//  extract all the columns 
Hive,WITHOUT_CLASSIFICATION,//  We know they are not equal because the one with the larger scale has non-zero digits   below the other's scale (since the scale does not include trailing zeroes). 
Hive,WITHOUT_CLASSIFICATION,//  add supported protocols 
Hive,WITHOUT_CLASSIFICATION,//  TODO : verify if any escaping is needed for values 
Hive,WITHOUT_CLASSIFICATION,//  Use method addDelegationTokens instead of getDelegationToken to get all the tokens including KMS. 
Hive,WITHOUT_CLASSIFICATION,//  the biggest output from a parent 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: Hive by convention doesn't pushdown non deterministic expressions 
Hive,WITHOUT_CLASSIFICATION,//  local plan is not null we want to merge it into SMBMapJoinOperator's local work 
Hive,WITHOUT_CLASSIFICATION,//  there are no elements in the list 
Hive,WITHOUT_CLASSIFICATION,//  Get partial aggregation results and store in reduceValues 
Hive,WITHOUT_CLASSIFICATION,//  2048 comes from tblproperties   Compact ttp1 
Hive,WITHOUT_CLASSIFICATION,//  Create the lineage context 
Hive,WITHOUT_CLASSIFICATION,//  If source path is a subdirectory of the destination path (or the other way around):     ex: INSERT OVERWRITE DIRECTORY 'target/warehouse/dest4.out' SELECT src.value WHERE src.key >= 300;     where the staging directory is a subdirectory of the destination directory   (1) Do not delete the dest dir before doing the move operation.   (2) It is assumed that subdir and dir are in same encryption zone.   (3) Move individual files from scr dir to dest dir. 
Hive,WITHOUT_CLASSIFICATION,//  find the move task 
Hive,WITHOUT_CLASSIFICATION,//  Serialize the hcatPartitionSpec. 
Hive,WITHOUT_CLASSIFICATION,/*                * Multi-Key specific lookup key.                */
Hive,WITHOUT_CLASSIFICATION,//  Make sure buffers are eligible for discard. 
Hive,WITHOUT_CLASSIFICATION,//  Clear rounding portion in middle longword and add 1 at right scale (roundMultiplyFactor);   lower longword result is 0; 
Hive,WITHOUT_CLASSIFICATION,//  The other overload should have been used. 
Hive,WITHOUT_CLASSIFICATION,// Factory method for serDe 
Hive,WITHOUT_CLASSIFICATION,/*    * fastSerializationUtilsRead middle word is 63 bits. So we need a multiplier 2^63    *   *    2^63 =   *      9223372036854775808 (Long.MAX_VALUE) or   *      9223372036854775808 or   *      9223372036854775808 (16 digit comma'd)    */
Hive,WITHOUT_CLASSIFICATION,//  If the table alias to information map already contains the current table 
Hive,WITHOUT_CLASSIFICATION,//  If we reached here we have match for HS2 generated cookie 
Hive,WITHOUT_CLASSIFICATION,//  -deregister <versionNumber> 
Hive,WITHOUT_CLASSIFICATION,//  are running using the same umbilical. 
Hive,WITHOUT_CLASSIFICATION,//  Set up the security for plugin endpoint.   We will create the token and publish it in the AM registry.   Note: this application ID is bogus and is only needed for JobTokenSecretManager. 
Hive,WITHOUT_CLASSIFICATION,// 234 
Hive,WITHOUT_CLASSIFICATION,//  This is the start of container-annotated logging. 
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.IOSpecProto.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,//  The ANTLR grammar looks like :   1. KW_CONSTRAINT idfr=identifier KW_PRIMARY KW_KEY pkCols=columnParenthesesList    constraintOptsCreate?   -> ^(TOK_PRIMARY_KEY $pkCols $idfr constraintOptsCreate?)   when the user specifies the constraint name.   2.  KW_PRIMARY KW_KEY columnParenthesesList   constraintOptsCreate?   -> ^(TOK_PRIMARY_KEY columnParenthesesList constraintOptsCreate?)   when the user does not specify the constraint name. 
Hive,WITHOUT_CLASSIFICATION,//  Tests for Partition appendPartition(String tableName String dbName String name) method 
Hive,WITHOUT_CLASSIFICATION,//  currently all Tez work is on the cluster 
Hive,WITHOUT_CLASSIFICATION,//  Verify no preemption requests - since everything is at the same priority 
Hive,WITHOUT_CLASSIFICATION,//  -ve hashcodes had conversion to positive done in different ways in the past   abs() is now obsolete and all inserts now use & Integer.MAX_VALUE    the compat mode assumes that old data could've been loaded using the other conversion 
Hive,WITHOUT_CLASSIFICATION,//  init aggregationParameterFields 
Hive,WITHOUT_CLASSIFICATION,//  -p 
Hive,WITHOUT_CLASSIFICATION,//  While processing bucket columns atleast one bucket column   missed. This results in a different bucketing scheme.   Add empty list 
Hive,WITHOUT_CLASSIFICATION,//  Add sorting/bucketing if needed 
Hive,WITHOUT_CLASSIFICATION,//  long_size / tableRowSize + long_size 
Hive,WITHOUT_CLASSIFICATION,//  Skip class loading if the class name didn't change 
Hive,WITHOUT_CLASSIFICATION,//  It can be fully qualified name or use default database 
Hive,WITHOUT_CLASSIFICATION,//  the outputOps in this vertex. 
Hive,WITHOUT_CLASSIFICATION,//  for bucketed tables hive.optimize.sort.dynamic.partition optimization 
Hive,WITHOUT_CLASSIFICATION,//  Do not display vectorization objects. 
Hive,WITHOUT_CLASSIFICATION,//  8.090000000000000000000000000000000000000123456 
Hive,WITHOUT_CLASSIFICATION,//  Abort all the allocated txns so that the mapped write ids are referred as aborted ones. 
Hive,WITHOUT_CLASSIFICATION,//  Bogus warnings despite closeQuietly. 
Hive,WITHOUT_CLASSIFICATION,//  Fall-back for an unexpected RelNode type 
Hive,WITHOUT_CLASSIFICATION,//  this means that nothing was set for default stripe size previously so we should unset it. 
Hive,WITHOUT_CLASSIFICATION,//  Start the cache threads.   Cache also serves as buffer manager. 
Hive,WITHOUT_CLASSIFICATION,//  The data must be of type String 
Hive,WITHOUT_CLASSIFICATION,//  this means the process will exit without waiting for this thread 
Hive,WITHOUT_CLASSIFICATION,//  this shouldn't throw an exception 
Hive,WITHOUT_CLASSIFICATION,//  The serialized (non-NULL) series keys.  These 3 members represent the value. 
Hive,WITHOUT_CLASSIFICATION,//  streaming ingest writer with single transaction batch size in which case the transaction is   either committed or aborted. In either cases we don't need flush length file but we need to   flush intermediate footer to reduce memory pressure. Also with HIVE-19206 streaming writer does   automatic memory management which would require flush of open files without actually closing it. 
Hive,WITHOUT_CLASSIFICATION,// so now if HIVEFETCHTASKCONVERSION were to use a stale value it would use a 
Hive,WITHOUT_CLASSIFICATION,// r = runStatementOnDriver("explain  " + query);  logResuts(r "Explain logical1" ""); 
Hive,WITHOUT_CLASSIFICATION,//  LOG.debug(CLASS_NAME + " repeated key " + key); 
Hive,WITHOUT_CLASSIFICATION,//  For Non-MM tables directory structure is   <table-dir>/<staging-dir>/<partition-dir> 
Hive,WITHOUT_CLASSIFICATION,//  Test 256 or greater is n % 256 
Hive,WITHOUT_CLASSIFICATION,//  HS2 init without the knowledge of LLAP usage (or lack thereof) in the cluster. 
Hive,WITHOUT_CLASSIFICATION,//  handles cases where the query has a predicate "column-name=constant" 
Hive,WITHOUT_CLASSIFICATION,//  if we have a singleton AND or OR just return the child 
Hive,WITHOUT_CLASSIFICATION,//  There is bitvector but it is not adjacent to the previous ones. 
Hive,WITHOUT_CLASSIFICATION,//  Log at warn given how unfortunate this is. 
Hive,WITHOUT_CLASSIFICATION,// load 1st row 
Hive,WITHOUT_CLASSIFICATION,//  handle string types properly 
Hive,WITHOUT_CLASSIFICATION,//  http://wiki.apache.org/pig/PigErrorHandlingFunctionalSpecification#Error_codes 
Hive,WITHOUT_CLASSIFICATION,/*    * Gets list of job ids and calls getJobStatus to get status for each job id.    */
Hive,WITHOUT_CLASSIFICATION,//  -r 
Hive,WITHOUT_CLASSIFICATION,//  override MR properties from tblproperties if applicable 
Hive,WITHOUT_CLASSIFICATION,// before reparsing i.e. they are known to SemanticAnalyzer logic 
Hive,WITHOUT_CLASSIFICATION,//  Both inputs to the join are unique. There is nothing to be gained by   this rule. In fact this aggregate+join may be the result of a previous   invocation of this rule; if we continue we might loop forever. 
Hive,WITHOUT_CLASSIFICATION,//  make a copy 
Hive,WITHOUT_CLASSIFICATION,// //////////////////////////////////////////// 
Hive,WITHOUT_CLASSIFICATION,//  number of elements   sum of elements   sum[x-avg^2] (this is actually n times the variance) 
Hive,WITHOUT_CLASSIFICATION,//  returns true if the specified path matches the prefix stored 
Hive,WITHOUT_CLASSIFICATION,//  set 1st entry to null 
Hive,WITHOUT_CLASSIFICATION,/*    * Substitute for any carriage return or line feed characters in line with the escaped   * 2-character sequences \r or \n.   *   * @param line  the string for the CRLF substitution.   * @return If there were no replacements then just return line.  Otherwise a new String with   *         escaped CRLF.    */
Hive,WITHOUT_CLASSIFICATION,//  This stream can be separated by RG using index. Let's do that. 
Hive,WITHOUT_CLASSIFICATION,//  Since rowCount is used later to instantiate a BytesBytesMultiHashMap 
Hive,WITHOUT_CLASSIFICATION,/*      * Connect via kerberos with trusted proxy user      */
Hive,WITHOUT_CLASSIFICATION,//  Add test parameters from storage formats specified in ADDITIONAL_STORAGE_FORMATS table. 
Hive,WITHOUT_CLASSIFICATION,//  src is scratch directory need to trim the part key value pairs from path 
Hive,WITHOUT_CLASSIFICATION,//  configure the broker 
Hive,WITHOUT_CLASSIFICATION,//  Connection.getMetaData().getTableTypes() when type config is set to "HIVE" 
Hive,WITHOUT_CLASSIFICATION,//  Testing multiByte string substring 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setObject(java.lang.String   * java.lang.Object int int)    */
Hive,WITHOUT_CLASSIFICATION,//  Drop the materialized view but not its data 
Hive,WITHOUT_CLASSIFICATION,//  Should also not be able to add fields of different types with same name 
Hive,WITHOUT_CLASSIFICATION,//  Especially since LLAP is prone to turn it off in the MapJoinDesc in later 
Hive,WITHOUT_CLASSIFICATION,//  Async op in progress; the callback will take care of this. 
Hive,WITHOUT_CLASSIFICATION,//  get next batch of table names in this list 
Hive,WITHOUT_CLASSIFICATION,/*            * Failed to set job status as COMPLETED which mean the main thread would have           * exited and not waiting for the result. Kill the submitted job.            */
Hive,WITHOUT_CLASSIFICATION,//  TaskWrapper is used in structures as well as for ordering using Comparators 
Hive,WITHOUT_CLASSIFICATION,/*    * It represents a WindowFrame applied to a Partitioning. A Window can   * refer to a <i>source</i> Window by name. The source Window provides the   * basis for this Window definition. This Window specification   * extends/overrides the <i>source</i> Window definition. In our e.g. the   * Select Expression $sum(p_retailprice) over (w1)$ is translated into a   * WindowFunction instance that has a Window specification that refers   * to the global Window Specification 'w1'. The Function's specification   * has no content but inherits all its attributes from 'w1' during   * subsequent phases of translation.    */
Hive,WITHOUT_CLASSIFICATION,//  When we are doing vector deserialization these are the fast deserializer and   the vector row deserializer. 
Hive,WITHOUT_CLASSIFICATION,//  ObjectStore also stores db name in lowercase 
Hive,WITHOUT_CLASSIFICATION,//  loglevel & args are parsed by the python processor 
Hive,WITHOUT_CLASSIFICATION,/*      * If the user asking the token is same as the 'owner' then don't do     * any proxy authorization checks. For cases like oozie where it gets     * a delegation token for another user we need to make sure oozie is     * authorized to get a delegation token.      */
Hive,WITHOUT_CLASSIFICATION,//  Generate the list bucketing pruning predicate 
Hive,WITHOUT_CLASSIFICATION,// Set transitive to true by default 
Hive,WITHOUT_CLASSIFICATION,//  Just forward the row as is 
Hive,WITHOUT_CLASSIFICATION,//  we haven't added anything so should return an all ok 
Hive,WITHOUT_CLASSIFICATION,//  </Classification> 
Hive,WITHOUT_CLASSIFICATION,//  Now apply SARG if any; w/o sarg this will just initialize stripeRgs. 
Hive,WITHOUT_CLASSIFICATION,/*      * add columns from inpRR      */
Hive,WITHOUT_CLASSIFICATION,//  go through all map joins and find out all which have enabled bucket map 
Hive,WITHOUT_CLASSIFICATION,//  clone the original join operator and replace it with the MJ 
Hive,WITHOUT_CLASSIFICATION,//  restore  input and output streams 
Hive,WITHOUT_CLASSIFICATION,//  Not updated yet. 
Hive,WITHOUT_CLASSIFICATION,//  Connect Jersey 
Hive,WITHOUT_CLASSIFICATION,//  Note that -1000000000 is a valid value corresponding to a nanosecond timestamp   of 999999999 because if the second VInt is present we use the value   (-reversedNanoseconds - 1) as the second VInt. 
Hive,WITHOUT_CLASSIFICATION,//  Operator is a file sink or reduce sink. Something that forces a new vertex. 
Hive,WITHOUT_CLASSIFICATION,//  We want the driver to try to print the header... 
Hive,WITHOUT_CLASSIFICATION,//  LO     LEFT\RIGHT   skip  filtered   valid   skip        --(1)     --(1)    --(1)   filtered    +-(1)     +-(1)    +-(1)   valid       +-(1)     +-(4*)   ++(2)     * If right alias has any pair for left alias continue (3)   -1 for continue : has pair but not in this turn    0 for inner join (++) : join and continue LO 
Hive,WITHOUT_CLASSIFICATION,//  It's all good: create a new entry in the map (or update existing one) 
Hive,WITHOUT_CLASSIFICATION,//  In case the job context is not up yet let's wait since this is supposed to be a   "synchronous" RPC. 
Hive,WITHOUT_CLASSIFICATION,/*    * Scratch objects.    */
Hive,WITHOUT_CLASSIFICATION,//  We got using() clause in previous join. Need to generate select list as   per standard. For * we will have joining columns first non-repeated   followed by other columns. 
Hive,WITHOUT_CLASSIFICATION,//  Has this filesink already been processed 
Hive,WITHOUT_CLASSIFICATION,//  This is constant for whole series. 
Hive,WITHOUT_CLASSIFICATION,//  first to make sure we go through a complete iteration of the loop before resetting it. 
Hive,WITHOUT_CLASSIFICATION,/* when running in unit test mode pass this property to HCat      which will in turn pass it to Hive to make sure that Hive      tries to write to a directory that exists. */
Hive,WITHOUT_CLASSIFICATION,//  A new table is always created with a new column descriptor 
Hive,WITHOUT_CLASSIFICATION,//  year   month   day 
Hive,WITHOUT_CLASSIFICATION,//  != 0 
Hive,WITHOUT_CLASSIFICATION,//  set the bit to 1 if an element is not null 
Hive,WITHOUT_CLASSIFICATION,//  Check if the file format of the file matches that of the table. 
Hive,WITHOUT_CLASSIFICATION,//  we use this map to map the position of argList to the position of grouping set 
Hive,WITHOUT_CLASSIFICATION,//  we're interested in specific partitions   don't check for any others 
Hive,WITHOUT_CLASSIFICATION,//  Number of rows not matching the regex 
Hive,WITHOUT_CLASSIFICATION,//  Attempting to fix a valid - should not result in a new file. 
Hive,WITHOUT_CLASSIFICATION,//  Loop through each of the lists of exprs looking for a match. 
Hive,WITHOUT_CLASSIFICATION,//  Check if we should turn into streaming mode 
Hive,WITHOUT_CLASSIFICATION,//  Test negative integers result in "" 
Hive,WITHOUT_CLASSIFICATION,// Attempt extended Acl operations only if its enabled 8791but don't fail the operation regardless. 
Hive,WITHOUT_CLASSIFICATION,//  Read each expression and save it to the value registry 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:SourceStateUpdatedResponseProto) 
Hive,WITHOUT_CLASSIFICATION,//  skewed value has the same length. 
Hive,WITHOUT_CLASSIFICATION,//  The value read in last time 
Hive,WITHOUT_CLASSIFICATION,//  stop once we see a dynamic partition 
Hive,WITHOUT_CLASSIFICATION,// Test when the session is opened by a user. (HiveSessionImplwithUGI) 
Hive,WITHOUT_CLASSIFICATION,//  then assume it is from its own vertex 
Hive,WITHOUT_CLASSIFICATION,//  Add rounding. 
Hive,WITHOUT_CLASSIFICATION,//  schema. 
Hive,WITHOUT_CLASSIFICATION,//  currently testProccedures always returns an empty resultset for Hive 
Hive,WITHOUT_CLASSIFICATION,//  Possible concurrent modification issues if we try to remove cache entries while   traversing the cache structures. Save the entries to remove in a separate list. 
Hive,WITHOUT_CLASSIFICATION,//  otherwise fall back to return null i.e. to use local tmp dir only 
Hive,WITHOUT_CLASSIFICATION,//  Make sure nothing escapes this run method and kills the metastore at large   so wrap it in a big catch Throwable statement. 
Hive,WITHOUT_CLASSIFICATION,/*    * These members have information for extracting a row column objects from VectorizedRowBatch   * columns.    */
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#createArrayOf(java.lang.String   * java.lang.Object[])    */
Hive,WITHOUT_CLASSIFICATION,//  compute statistics for columns viewtime 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#setEscapeProcessing(boolean)    */
Hive,WITHOUT_CLASSIFICATION,//  Generate test data 
Hive,WITHOUT_CLASSIFICATION,//  Take away the only session as if it was expiring. 
Hive,WITHOUT_CLASSIFICATION,//  StandardStruct uses ArrayList to store the row. 
Hive,WITHOUT_CLASSIFICATION,//  no-arg ctor required for JSON deserialization 
Hive,WITHOUT_CLASSIFICATION,//  Create rules registry to not trigger a rule more than once 
Hive,WITHOUT_CLASSIFICATION,//  it wasn't create db/table 
Hive,WITHOUT_CLASSIFICATION,//  User provided a fully specified partition spec but it doesn't exist fail. 
Hive,WITHOUT_CLASSIFICATION,//  If a join occurs before the sort-merge join it is not useful to convert the the sort-merge   join to a mapjoin. It might be simpler to perform the join and then a sort-merge join   join. By converting the sort-merge join to a map-join the job will be executed in 2   mapjoins in the best case. The number of inputs for the join is more than 1 so it would   be difficult to figure out the big table for the mapjoin. 
Hive,WITHOUT_CLASSIFICATION,//  construct output object inspector 
Hive,WITHOUT_CLASSIFICATION,//  Left input positions are not changed. 
Hive,WITHOUT_CLASSIFICATION,//  -------------------------------- First Pass ---------------------------------- //   Identify SparkPartitionPruningSinkOperators and break OP tree if necessary 
Hive,WITHOUT_CLASSIFICATION,//  HCat will allow these operations to be performed. 
Hive,WITHOUT_CLASSIFICATION,//  1. Insert two rows to a partitioned MM table. 
Hive,WITHOUT_CLASSIFICATION,//  Identical strings 
Hive,WITHOUT_CLASSIFICATION,//  In this case we are assuming that there is a single distinct function. 
Hive,WITHOUT_CLASSIFICATION,//  5 : Create and drop partition P2 to T2 10 times => 20 events 
Hive,WITHOUT_CLASSIFICATION,//  invalid character present return null 
Hive,WITHOUT_CLASSIFICATION,//  Directory 
Hive,WITHOUT_CLASSIFICATION,//  Location will vary by system. 
Hive,WITHOUT_CLASSIFICATION,//  It is of the form topSubQuery:innerSubQuery:....:innerMostSubQuery 
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.SubmitWorkResponseProto.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,//  no integer part 
Hive,WITHOUT_CLASSIFICATION,// only have 1 file so done 
Hive,WITHOUT_CLASSIFICATION,//  if writable constant is null then return size 0 
Hive,WITHOUT_CLASSIFICATION,/*  its a map  */
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#prepareStatement(java.lang.String int)    */
Hive,WITHOUT_CLASSIFICATION,//  Same priority for all tasks. 
Hive,WITHOUT_CLASSIFICATION,//  Create table on Target. 
Hive,WITHOUT_CLASSIFICATION,//  make left a child of right 
Hive,WITHOUT_CLASSIFICATION,//  4.2) Modifying filter condition. The incremental rewriting rule generated an OR   clause where first disjunct contains the condition for the UPDATE branch.   TOK_WHERE     or        and <- DISJUNCT FOR <UPDATE>           =              .                 TOK_TABLE_OR_COL                    $hdt$_0                 a              .                 TOK_TABLE_OR_COL                    $hdt$_1                 a           =              .                 TOK_TABLE_OR_COL                    $hdt$_0                 c              .                 TOK_TABLE_OR_COL                    $hdt$_1                 c        and <- DISJUNCT FOR <INSERT>           TOK_FUNCTION              isnull              .                 TOK_TABLE_OR_COL                    $hdt$_0                 a           TOK_FUNCTION              isnull              .                 TOK_TABLE_OR_COL                    $hdt$_0 
Hive,WITHOUT_CLASSIFICATION,//  exceptions in the range 
Hive,WITHOUT_CLASSIFICATION,//  We assume the VARCHAR maximum length was enforced when the object was created. 
Hive,WITHOUT_CLASSIFICATION,//  Stub out the serializer 
Hive,WITHOUT_CLASSIFICATION,//  test repeating logic 
Hive,WITHOUT_CLASSIFICATION,//  [SUMMARY|OPERATOR|EXPRESSION|DETAIL] 
Hive,WITHOUT_CLASSIFICATION,//  Return immediately. No entries found for pruning. Verified via the timeout. 
Hive,WITHOUT_CLASSIFICATION,// AND b < 1 
Hive,WITHOUT_CLASSIFICATION,/*      * allow multiple mappings to the same ColumnInfo.     * When a ColumnInfo is mapped multiple times only the     * first inverse mapping is captured.      */
Hive,WITHOUT_CLASSIFICATION,//  Steps:   1. Extract the archive in a temporary folder   2. Move the archive dir to an intermediate dir that is in at the same      dir as originalLocation. Call the new dir intermediate-extracted.   3. Rename the original partitions dir to an intermediate dir. Call the      renamed dir intermediate-archive   4. Rename intermediate-extracted to the original partitions dir   5. Change the metadata   6. Delete the archived partitions files in intermediate-archive 
Hive,WITHOUT_CLASSIFICATION,/*    * In skip mode msck should ignore invalid partitions instead of   * throwing exception    */
Hive,WITHOUT_CLASSIFICATION,//     assertTrue(exc instanceof HCatException);      assertEquals(ErrorType.ERROR_PUBLISHING_PARTITION ((HCatException) exc).getErrorType());   With Dynamic partitioning this isn't an error that the keyValues specified didn't values 
Hive,WITHOUT_CLASSIFICATION,//  class FSPaths 
Hive,WITHOUT_CLASSIFICATION,//  Unnecessary: data.putInt(bOffset -1); data.putInt(bOffset + 4 -1); 
Hive,WITHOUT_CLASSIFICATION,// for other tasks just return its children tasks 
Hive,WITHOUT_CLASSIFICATION,//  LASTHEARTBEAT 
Hive,WITHOUT_CLASSIFICATION,//  It's ok to update metrics for two tasks in parallel but not for the same one. 
Hive,WITHOUT_CLASSIFICATION,//  TODO CAT - for now always use the default catalog.  Eventually will want to see if   the user specified a catalog 
Hive,WITHOUT_CLASSIFICATION,//  If the returned value is HiveDecimal we assume maximum precision/scale. 
Hive,WITHOUT_CLASSIFICATION,//  class ConnectionImpl 
Hive,WITHOUT_CLASSIFICATION,//  Now do an in-place reversal in result.getBytes(). First reverse every 
Hive,WITHOUT_CLASSIFICATION,//  BINARY_STATS 
Hive,WITHOUT_CLASSIFICATION,//  Set DDL time to now if not specified 
Hive,WITHOUT_CLASSIFICATION,//  All tables or partitions are bucketed and their bucket number is   stored in 'bucketNumbers' we need to check if the number of buckets in 
Hive,WITHOUT_CLASSIFICATION,//  no scheme - use default file system uri 
Hive,WITHOUT_CLASSIFICATION,//  These aren't column types they are info for how things are stored in thrift. 
Hive,WITHOUT_CLASSIFICATION,//  If any of the type isn't exact double is chosen. 
Hive,WITHOUT_CLASSIFICATION,//  HCat wants to intercept following tokens and special-handle them. 
Hive,WITHOUT_CLASSIFICATION,//  Ok use result with some or all fractional digits stripped. 
Hive,WITHOUT_CLASSIFICATION,//  for auth 
Hive,WITHOUT_CLASSIFICATION,//  Converting to/from external table 
Hive,WITHOUT_CLASSIFICATION,// TezEdgeProperty.EdgeType 
Hive,WITHOUT_CLASSIFICATION,//  Do nothing - this should generate proper index. 
Hive,WITHOUT_CLASSIFICATION,//  we need to specify the reserved memory for each work that contains Map Join 
Hive,WITHOUT_CLASSIFICATION,//  Fixup parent and child relations. 
Hive,WITHOUT_CLASSIFICATION,//  look them up to make sure they are all there 
Hive,WITHOUT_CLASSIFICATION,// statementId is from directory name (or 0 if there is none) 
Hive,WITHOUT_CLASSIFICATION,//  Using biggest small table calculate number of partitions to create for each small table 
Hive,WITHOUT_CLASSIFICATION,//  need to use a new filesystem object here to have the correct ugi 
Hive,WITHOUT_CLASSIFICATION,//  position of last sync   16 random bytes 
Hive,WITHOUT_CLASSIFICATION,//  set up the staging directory to use 
Hive,WITHOUT_CLASSIFICATION,//  GROUP_PRIVILEGES 
Hive,WITHOUT_CLASSIFICATION,//  no cache 
Hive,WITHOUT_CLASSIFICATION,// https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/TransparentEncryption.html#Running_as_the_superuser 
Hive,WITHOUT_CLASSIFICATION,//  2.4 Determine the Direction of order by 
Hive,WITHOUT_CLASSIFICATION,//  Different columns means different commands have to be run. 
Hive,WITHOUT_CLASSIFICATION,//  Verify that the partitions specified are continuous   If a subpartition value is specified without specifying a partition's value 
Hive,WITHOUT_CLASSIFICATION,//  Merge them together. 
Hive,WITHOUT_CLASSIFICATION,/*    * A conditional node is constructed if its condition is true. All the nodes   * that have been pushed since the node was opened are made children of the   * conditional node which is then pushed on to the stack. If the condition is   * false the node is not constructed and they are left on the stack.    */
Hive,WITHOUT_CLASSIFICATION,//  The following two keys should ideally be used to control RM connect timeouts. However 
Hive,WITHOUT_CLASSIFICATION,//  after constant folding of child expression the return type of UDFWhen might have changed   so recreate the expression 
Hive,WITHOUT_CLASSIFICATION,//  URIs are checked for string equivalence even spaces make them different 
Hive,WITHOUT_CLASSIFICATION,// check if orc and not sorted 
Hive,WITHOUT_CLASSIFICATION,//  Only print the first line of the stack trace as it contains the error message and other   lines may contain line numbers which are volatile   Also only take the string after the first two spaces because the prefix is a date and   and time stamp 
Hive,WITHOUT_CLASSIFICATION,//  Release the HMS connection for this service thread 
Hive,WITHOUT_CLASSIFICATION,//  add more variables as required 
Hive,WITHOUT_CLASSIFICATION,//  since count has a return type of BIG INT we need to make a literal of type big int   relbuilder's literal doesn't allow this 
Hive,WITHOUT_CLASSIFICATION,//  This is a table or dynamic partition 
Hive,WITHOUT_CLASSIFICATION,//  These functions only work on the STRING type. 
Hive,WITHOUT_CLASSIFICATION,//  Schedule CMClearer thread. Will be invoked by metastore 
Hive,WITHOUT_CLASSIFICATION,//  call-1: listLocatedStatus - mock:/mocktbl   call-2: check existence of side file for mock:/mocktbl/0_0   call-3: open - mock:/mocktbl/0_0   call-4: check existence of side file for mock:/mocktbl/0_1 
Hive,WITHOUT_CLASSIFICATION,//  There are some txns in the list which has no write id allocated and hence go ahead and do it.   Get the next write id for the given table and update it with new next write id. 
Hive,WITHOUT_CLASSIFICATION,//  if scheme is specified but not authority then use the default authority 
Hive,WITHOUT_CLASSIFICATION,//  Stores result in cache 
Hive,WITHOUT_CLASSIFICATION,//  Set output names in ReduceSink 
Hive,WITHOUT_CLASSIFICATION,//  llap cache purge requires admin privilege as it mutates state (cache) on the cluster 
Hive,WITHOUT_CLASSIFICATION,//  by default we put row into partition in memory 
Hive,WITHOUT_CLASSIFICATION,//  There should be 3 delta directories. The new one is the aborted one. 
Hive,WITHOUT_CLASSIFICATION,/*    * This method helps to re-use a session in case there has been no change in   * the configuration of a session. This will happen only in the case of non-hive-server2   * sessions for e.g. when a CLI session is started. The CLI session could re-use the   * same tez session eliminating the latencies of new AM and containers.    */
Hive,WITHOUT_CLASSIFICATION,//  The caller has already stopped the session. 
Hive,WITHOUT_CLASSIFICATION,//  We might want to setXAttr for the new location in the future 
Hive,WITHOUT_CLASSIFICATION,//  first argument is the column to be transformed 
Hive,WITHOUT_CLASSIFICATION,//  Using property defined in HiveConf.ConfVars to test System property   overriding 
Hive,WITHOUT_CLASSIFICATION,//  Indicates the initial capacity of the cache. 
Hive,WITHOUT_CLASSIFICATION,//  The separator for the hive row would be using \x02 so the separator for this struct would be   \x02 + 1 = \x03 
Hive,WITHOUT_CLASSIFICATION,//  GRANTOR 
Hive,WITHOUT_CLASSIFICATION,//  Based on the plan outputs find out the target table name and column names. 
Hive,WITHOUT_CLASSIFICATION,//  Step 1: Check if mapJoinTask has a single child. 
Hive,WITHOUT_CLASSIFICATION,//  these are closure-bound for all the walkers in context 
Hive,WITHOUT_CLASSIFICATION,//  Should only down-cast if within valid range. 
Hive,WITHOUT_CLASSIFICATION,//  compile time. 
Hive,WITHOUT_CLASSIFICATION,//  DELEGATION_TOKEN 
Hive,WITHOUT_CLASSIFICATION,//  List was recreated while we were exhausting it. 
Hive,WITHOUT_CLASSIFICATION,//  CLASS_NAME 
Hive,WITHOUT_CLASSIFICATION,// kerberos connections to HMS if required. 
Hive,WITHOUT_CLASSIFICATION,//  If we had a cache range already we expect a single matching disk slice.   Given that there's cached data we expect there to be some disk data. 
Hive,WITHOUT_CLASSIFICATION,/*        * Now tasks would have passed. Verify that new job requests should succeed with no issues.        */
Hive,WITHOUT_CLASSIFICATION,//  Close and release resources within a running query process. Since it runs under   driver state COMPILING EXECUTING or INTERRUPT it would not have race condition 
Hive,WITHOUT_CLASSIFICATION,//  get the SEL(*) branch 
Hive,WITHOUT_CLASSIFICATION,//  get the context info and set up the shared tmp URI 
Hive,WITHOUT_CLASSIFICATION,//  LOG.debug(CLASS_NAME + " currentKey " +        VectorizedBatchUtil.displayBytes(currentKeyOutput.getData() 0 currentKeyOutput.getLength())); 
Hive,WITHOUT_CLASSIFICATION,//  Leave this one for the next round. 
Hive,WITHOUT_CLASSIFICATION,//  writeId for data from non-acid table and so writeIdHwm=0 would ensure those data are readable by any txns. 
Hive,WITHOUT_CLASSIFICATION,//  Case 3: column stats hash aggregation NO grouping sets 
Hive,WITHOUT_CLASSIFICATION,//  To check whether we have enough memory to allocate for another hash partition   we need to get the size of the first hash partition to get an idea. 
Hive,WITHOUT_CLASSIFICATION,//  We just act as a pass-thru between the session and allocation manager. We don't change the   allocation target (only WM thread can do that); therefore we can do this directly and   actualState-based sync will take care of multiple potential message senders. 
Hive,WITHOUT_CLASSIFICATION,//  From this point on the update is in motion - if someone changes the state again that 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#registerOutParameter(java.lang.String int)    */
Hive,WITHOUT_CLASSIFICATION,// cleaner is a static object use static synchronized to make sure its thread-safe 
Hive,WITHOUT_CLASSIFICATION,//  zero out the bits above bitsToWrite 
Hive,WITHOUT_CLASSIFICATION,//  Setting key to same value should not trigger configChange event during shutdown 
Hive,WITHOUT_CLASSIFICATION,/*      * Bloom filter merge input and output are BYTES.     *     * Just modes (PARTIAL2 FINAL).      */
Hive,WITHOUT_CLASSIFICATION,//  Don't worry about this as it likely just means it's already been created. 
Hive,WITHOUT_CLASSIFICATION,// Remove subquery 
Hive,WITHOUT_CLASSIFICATION,//  CREATE_TABLE - INSERT - TRUNCATE - INSERT - The result is just one record. 
Hive,WITHOUT_CLASSIFICATION,//  2.1 This is the new number of rows after PK is joining with FK 
Hive,WITHOUT_CLASSIFICATION,//  switch the database 
Hive,WITHOUT_CLASSIFICATION,//  Not based on ARP and cannot assume uniform distribution bail. 
Hive,WITHOUT_CLASSIFICATION,//  restore index 
Hive,WITHOUT_CLASSIFICATION,//  The Hive type of this column 
Hive,WITHOUT_CLASSIFICATION,// for non-prefix maps 
Hive,WITHOUT_CLASSIFICATION,//  otherwise all null afterwards 
Hive,WITHOUT_CLASSIFICATION,/*    * For primitive types use LazyBinary's object.   * For complex types make a standard (Java) object from LazyBinary's object.    */
Hive,WITHOUT_CLASSIFICATION,/*  1 files x 1000 size for 9 splits  */
Hive,WITHOUT_CLASSIFICATION,//  restart sensitive instance id 
Hive,WITHOUT_CLASSIFICATION,//  Other nodes may be trying to delete this at the same time   so just log errors and skip them. 
Hive,WITHOUT_CLASSIFICATION,//  override this with a no-op if subclass doesn't need to treat NaN as null 
Hive,WITHOUT_CLASSIFICATION,//  if any expression of child is referencing parent column which is result of function 
Hive,WITHOUT_CLASSIFICATION,/*  * Abstract class for a hash map result.  For reading the values one-by-one.  */
Hive,WITHOUT_CLASSIFICATION,//  pRS-cRS 
Hive,WITHOUT_CLASSIFICATION,//  to cleanup the entries less than min_uncommitted_txnid from the TXN_TO_WRITE_ID table. 
Hive,WITHOUT_CLASSIFICATION,//  Create table associated with the import 
Hive,WITHOUT_CLASSIFICATION,//  This way the only way the recursive stack of fetchNextBatch returns is if:      a) We got a nonempty result and we can consume      b) We reached the end of the queue and there are no more events.   So when we return from the fetchNextBatch() stack if we have no more   results in batch we're done. 
Hive,WITHOUT_CLASSIFICATION,//  E.g. "hive-metastore/_HOST@EXAMPLE.COM". 
Hive,WITHOUT_CLASSIFICATION,// this will cause next txn to be marked aborted but the data is still written to disk 
Hive,WITHOUT_CLASSIFICATION,//  Got a match return the value 
Hive,WITHOUT_CLASSIFICATION,//  getDelay <=0 means the task will be evicted from the queue. 
Hive,WITHOUT_CLASSIFICATION,//  Events can start coming in the moment the InputInitializer is created. The pruner   must be setup and initialized here so that it sets up it's structures to start accepting events.   Setting it up in initialize leads to a window where events may come in before the pruner is 
Hive,WITHOUT_CLASSIFICATION,//  write sql statements to file 
Hive,WITHOUT_CLASSIFICATION,//  Even if the service hasn't started up. It's OK to make this invocation since this will   only happen after the AtomicReference address has been populated. Not adding an additional check. 
Hive,WITHOUT_CLASSIFICATION,// For now because subquery is only supported in filter 
Hive,WITHOUT_CLASSIFICATION,//  put a empty list or null 
Hive,WITHOUT_CLASSIFICATION,//  scope close: 
Hive,WITHOUT_CLASSIFICATION,//  evaluate will return a Text object 
Hive,WITHOUT_CLASSIFICATION,//  Drain the buffer 
Hive,WITHOUT_CLASSIFICATION,//  row count using the classic formula. 
Hive,WITHOUT_CLASSIFICATION,//  We can update all partitions with a single analyze query. 
Hive,WITHOUT_CLASSIFICATION,//  End RelShuttleImpl.java 
Hive,WITHOUT_CLASSIFICATION,//  Don't restrict child expressions for projection.   Always use loose FILTER mode. 
Hive,WITHOUT_CLASSIFICATION,/*    * If the parent reduce sink of the big table side has the same emit key cols as its parent we   * can create a bucket map join eliminating the reduce sink.    */
Hive,WITHOUT_CLASSIFICATION,/*    * Job request execution time out in seconds. If it is 0 then request   * will not be timed out.    */
Hive,WITHOUT_CLASSIFICATION,//  Alter the db via CachedStore (can only alter owner or parameters) 
Hive,WITHOUT_CLASSIFICATION,// Test for merging of configs 
Hive,WITHOUT_CLASSIFICATION,//  Start by getting the work part of the task and call the output plan for   the work 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#getAutoCommit()    */
Hive,WITHOUT_CLASSIFICATION,//  null values and values of zero length are not added to the cachedMap 
Hive,WITHOUT_CLASSIFICATION,//  the rest ops are FKs. 
Hive,WITHOUT_CLASSIFICATION,//  The values from HiveIntervalDayTime.getTotalSeconds(). 
Hive,WITHOUT_CLASSIFICATION,//  along the way for the columns that the group by uses as keys 
Hive,WITHOUT_CLASSIFICATION,//  Testing substring starting from index 1 
Hive,WITHOUT_CLASSIFICATION,//  The MathExpr class contains helper functions for cases when existing library 
Hive,WITHOUT_CLASSIFICATION,//  Initialize a result 
Hive,WITHOUT_CLASSIFICATION,//  Copy of partitions that will be split into batches 
Hive,WITHOUT_CLASSIFICATION,/*  Get the mode of the lock encoded in the path  */
Hive,WITHOUT_CLASSIFICATION,//  Different result after clearing. 
Hive,WITHOUT_CLASSIFICATION,//  Open a new connection with these conf & vars 
Hive,WITHOUT_CLASSIFICATION,// LockRequestBuilder dedups locks on the same entity to only keep the highest level lock requested 
Hive,WITHOUT_CLASSIFICATION,//  Compute the fixed size overhead for the keys 
Hive,WITHOUT_CLASSIFICATION,//  Precondition: make sure this is done after the rest of the SerDe initialization is done. 
Hive,WITHOUT_CLASSIFICATION,//  get arguments 
Hive,WITHOUT_CLASSIFICATION,/*        * recreate cluster so that it picks up the additional traitDef        */
Hive,WITHOUT_CLASSIFICATION,//  5/ update the byte size of the map 
Hive,WITHOUT_CLASSIFICATION,//  If any partition is updated then update repl state in partition object 
Hive,WITHOUT_CLASSIFICATION,//  Write the value 
Hive,WITHOUT_CLASSIFICATION,//  and return false. 
Hive,WITHOUT_CLASSIFICATION,//  bucketized keys (note that the order need not be the same). 
Hive,WITHOUT_CLASSIFICATION,//  -f 
Hive,WITHOUT_CLASSIFICATION,//     deserializedBigInteger.equals(deserializedBigIntegerExpected)); 
Hive,WITHOUT_CLASSIFICATION,//  Decrease then increase qp - sessions should not be killed on return. 
Hive,WITHOUT_CLASSIFICATION,//  Here the global state is confined to just this process. 
Hive,WITHOUT_CLASSIFICATION,//  -e 
Hive,WITHOUT_CLASSIFICATION,//  2nd level GB: create a GB (all keys + sum(c) as a + sum(VCol*c) as b) for 
Hive,WITHOUT_CLASSIFICATION,//  Preserve the original view definition as specified by the user. 
Hive,WITHOUT_CLASSIFICATION,//  using binary search. 
Hive,WITHOUT_CLASSIFICATION,//  End RelShuttle.java 
Hive,WITHOUT_CLASSIFICATION,//  if property specified file not found in local file system   use default setting 
Hive,WITHOUT_CLASSIFICATION,//  Reusable output for serialization 
Hive,WITHOUT_CLASSIFICATION,//  Get all user jars from work (e.g. input format stuff). 
Hive,WITHOUT_CLASSIFICATION,//  Failure handling of IMPORT command and REPL LOAD commands are different.   IMPORT will set the last repl ID before copying data files and hence need to allow   replacement if loaded from same dump twice after failing to copy in previous attempt.   But REPL LOAD will set the last repl ID only after the successful copy of data files and 
Hive,WITHOUT_CLASSIFICATION,/*  nothing  */
Hive,WITHOUT_CLASSIFICATION,//  all other tables are small and are cached in the hash table 
Hive,WITHOUT_CLASSIFICATION,//  get all the tasks nodes from root task 
Hive,WITHOUT_CLASSIFICATION,//  TXNID 
Hive,WITHOUT_CLASSIFICATION,//  Handle repeating case 
Hive,WITHOUT_CLASSIFICATION,//  production is: set<FieldType()> 
Hive,WITHOUT_CLASSIFICATION,//  Try to eat a dot now since it could be the end.  We remember if we saw a dot so we can 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getDate(java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  If the login context name is not set we are in the client and don't need auth. 
Hive,WITHOUT_CLASSIFICATION,//  When stopping the process we are redirecting from   the streams might be closed during reading.   We should not log the related exceptions in a visible level   as they might mislead the user. 
Hive,WITHOUT_CLASSIFICATION,/*  columnar splits of unknown size - estimate worst-case  */
Hive,WITHOUT_CLASSIFICATION,//  We remove it from the TS too if it was pushed 
Hive,WITHOUT_CLASSIFICATION,//  Try to infer the type of the constant only if there are two 
Hive,WITHOUT_CLASSIFICATION,//  Disable memory estimation for this test class 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:UpdateFragmentRequestProto) 
Hive,WITHOUT_CLASSIFICATION,//  Create split for the previous unfinished stripe. 
Hive,WITHOUT_CLASSIFICATION,//  Test that existing shared_read table with new exclusive coalesces to 
Hive,WITHOUT_CLASSIFICATION,//  use LinkedHashMap to make sure the iteration order is 
Hive,WITHOUT_CLASSIFICATION,// ************************************************************************************************   Decimal Division / Remainder. 
Hive,WITHOUT_CLASSIFICATION,/*    * ============================== HOW TO RUN THIS TEST: ====================================   *   * You can run this test:   *   * a) Via the command line:   *    $ mvn clean install   *    $ java -jar target/benchmarks.jar VectorGroupByOperatorCountBench -prof perf     -f 1 (Linux)   *    $ java -jar target/benchmarks.jar VectorGroupByOperatorCountBench -prof perfnorm -f 3 (Linux)   *    $ java -jar target/benchmarks.jar VectorGroupByOperatorCountBench -prof perfasm  -f 1 (Linux)   *    $ java -jar target/benchmarks.jar VectorGroupByOperatorCountBench -prof gc  -f 1 (allocation counting via gc)   *    $ java -jar target/benchmarks.jar VectorGroupByOperatorBench -p hasNulls=true -p isRepeating=false -p aggregation=bloom_filter  -p processMode=HASH -p evalMode=PARTIAL1   *    $ java -agentlib:jdwp=transport=dt_socketaddress=127.0.0.1:6006suspend=yserver=y -jar target/benchmarks.jar VectorGroupByOperatorBench    */
Hive,WITHOUT_CLASSIFICATION,//  Addition with overflow check. Overflow produces NULL output. 
Hive,WITHOUT_CLASSIFICATION,//  Create the DemuxOperaotr 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:QueryCompleteResponseProto) 
Hive,WITHOUT_CLASSIFICATION,//  how to get around that. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#getParameterMetaData()    */
Hive,WITHOUT_CLASSIFICATION,//  set to one of the roles user belongs to. 
Hive,WITHOUT_CLASSIFICATION,//  Compute the reducers run time statistics for the job 
Hive,WITHOUT_CLASSIFICATION,//  modify conf by using 'set' commands 
Hive,WITHOUT_CLASSIFICATION,/*  Base Case. It's leaf.  */
Hive,WITHOUT_CLASSIFICATION,//  map key separator 
Hive,WITHOUT_CLASSIFICATION,//  An error heuristic could have generated different ErrorAndSolution   for each task attempt but most likely they are the same. Plus   one of those is probably good enough for debugging 
Hive,WITHOUT_CLASSIFICATION,//  Update null counter if a null value is seen 
Hive,WITHOUT_CLASSIFICATION,//  Batch of rows to emit per processNextRecord() call. 
Hive,WITHOUT_CLASSIFICATION,//  This is to mimic previous behavior where NoSuchObjectException was thrown through this   method. 
Hive,WITHOUT_CLASSIFICATION,//  No version annotation? 
Hive,WITHOUT_CLASSIFICATION,//  Fill the all the vector entries with provided value 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#prepareStatement(java.lang.String int[])    */
Hive,WITHOUT_CLASSIFICATION,//  In case the job is empty there won't be JobStart/JobEnd events. The only way 
Hive,WITHOUT_CLASSIFICATION,//  regenerate the valueTableDesc 
Hive,WITHOUT_CLASSIFICATION,//  test UDF considers the difference in time components date1 and date2 
Hive,WITHOUT_CLASSIFICATION,//  Create the ObjectInspectors for the fields 
Hive,WITHOUT_CLASSIFICATION,//  Operands 
Hive,WITHOUT_CLASSIFICATION,//  Sign stays the same. 
Hive,WITHOUT_CLASSIFICATION,//  The caller of this method should guarantee this 
Hive,WITHOUT_CLASSIFICATION,//  Add sign byte since high bit is off. 
Hive,WITHOUT_CLASSIFICATION,//  results 
Hive,WITHOUT_CLASSIFICATION,// oterwise it may later release permit acquired by someone else 
Hive,WITHOUT_CLASSIFICATION,//  Either the token should be passed in here or in ctor. 
Hive,WITHOUT_CLASSIFICATION,//  If the table has property EXTERNAL set update table type   accordingly 
Hive,WITHOUT_CLASSIFICATION,// not allowed in a tx 
Hive,WITHOUT_CLASSIFICATION,//  Write another large value. This should use a different byte buffer 
Hive,WITHOUT_CLASSIFICATION,// get detailed "tableInfo" from query "desc extended tablename;" 
Hive,WITHOUT_CLASSIFICATION,//  Check ownership for all partitions 
Hive,WITHOUT_CLASSIFICATION,//  PKTABLE_NAME 
Hive,WITHOUT_CLASSIFICATION,//  This is always replaced atomically so we don't care about concurrency here. 
Hive,WITHOUT_CLASSIFICATION,//  We don't write a first empty value.   Get an offset to reduce the relative offset later if there are more than 1 value. 
Hive,WITHOUT_CLASSIFICATION,//  pull apart the kids of the OR expression 
Hive,WITHOUT_CLASSIFICATION,//  Add value to NumDistinctValue Estimator 
Hive,WITHOUT_CLASSIFICATION,//  get the path expression for the 1st row only 
Hive,WITHOUT_CLASSIFICATION,//  First scale up with 2. Check overflow 
Hive,WITHOUT_CLASSIFICATION,//  we are not running this mapred task via child jvm 
Hive,WITHOUT_CLASSIFICATION,//  Boring scenario #1 - two concurrent increases. 
Hive,WITHOUT_CLASSIFICATION,//  Cache administration 
Hive,WITHOUT_CLASSIFICATION,//  Add the test. 
Hive,WITHOUT_CLASSIFICATION,//  Add another partition to the source. 
Hive,WITHOUT_CLASSIFICATION,//  We are the last to initialize. 
Hive,WITHOUT_CLASSIFICATION,//  do a deep copy in case downstream changes it. 
Hive,WITHOUT_CLASSIFICATION,// ((ISetLongArg) expr).setArg(3); 
Hive,WITHOUT_CLASSIFICATION,//  a row with no columns 
Hive,WITHOUT_CLASSIFICATION,//  purpose 
Hive,WITHOUT_CLASSIFICATION,//  Alter table for perform schema evolution. 
Hive,WITHOUT_CLASSIFICATION,//  Copy critical columns. 
Hive,WITHOUT_CLASSIFICATION,//  Only the KILLED case requires a message to be sent out to the AM. 
Hive,WITHOUT_CLASSIFICATION,//  We don't throw a new exception for this -- just keep going with the   next one. 
Hive,WITHOUT_CLASSIFICATION,//  HiveDecimal -> Float -> Number 
Hive,WITHOUT_CLASSIFICATION,//  Helper method. 
Hive,WITHOUT_CLASSIFICATION,//  In Hadoop 1.X and Hadoop 2.X HADOOP_HOME is gone and replaced with HADOOP_PREFIX 
Hive,WITHOUT_CLASSIFICATION,//  add another partitioning key based on floor(1/rand) % targetShardsPerGranularity 
Hive,WITHOUT_CLASSIFICATION,//  try ignoring the 200 transaction and make sure it works still 
Hive,WITHOUT_CLASSIFICATION,//  Serde for FetchTask 
Hive,WITHOUT_CLASSIFICATION,//  REQUEST_TYPE 
Hive,WITHOUT_CLASSIFICATION,//  project the relevant key column 
Hive,WITHOUT_CLASSIFICATION,//  attempt to locate an existing jar for the class. 
Hive,WITHOUT_CLASSIFICATION,// when compacting each split needs to process the whole logical bucket 
Hive,WITHOUT_CLASSIFICATION,// everything is now in base/ 
Hive,WITHOUT_CLASSIFICATION,//  Return less than because of right's digits below left's scale. 
Hive,WITHOUT_CLASSIFICATION,//  build the locations in a predictable order to simplify testing 
Hive,WITHOUT_CLASSIFICATION,//  check that hook to disable transforms has not been added 
Hive,WITHOUT_CLASSIFICATION,//  Columns 0..N-1 are keys. Column N is the aggregate value input 
Hive,WITHOUT_CLASSIFICATION,//  false - not in cache yet 
Hive,WITHOUT_CLASSIFICATION,//  Replace virtual columns with nulls. See javadoc for details. 
Hive,WITHOUT_CLASSIFICATION,//  all is well 
Hive,WITHOUT_CLASSIFICATION,//  All are selected do nothing 
Hive,WITHOUT_CLASSIFICATION,//  write it out from hive to an rcfile table and to an orc table 
Hive,WITHOUT_CLASSIFICATION,//  currently we support only raw data size stat 
Hive,WITHOUT_CLASSIFICATION,/*    * This helper method copies the group keys from one vectorized row batch to another   * but does not increment the outputBatch.size (i.e. the next output position).   *    * It was designed for VectorGroupByOperator's sorted reduce group batch processing mode   * to copy the group keys at startGroup.    */
Hive,WITHOUT_CLASSIFICATION,/*  * This is a pluggable policy to choose the candidate map-join table for converting a join to a * sort merge join. The largest table is chosen based on the size of the tables.  */
Hive,WITHOUT_CLASSIFICATION,//  Instantiating the HMSHandler with hive.metastore.checkForDefaultDb will cause it to   initialize an instance of the DummyRawStoreForJdoConnection 
Hive,WITHOUT_CLASSIFICATION,//  Duplicate. 
Hive,WITHOUT_CLASSIFICATION,//  Set partition and order columns in overflowBatch.   We can set by ref since our last batch is held by us. 
Hive,WITHOUT_CLASSIFICATION,//  The partitons are also the same so check the fieldschema 
Hive,WITHOUT_CLASSIFICATION,//  Test StandardObjectInspector both with field comments and without 
Hive,WITHOUT_CLASSIFICATION,//  statuses can be null if it is DDL etc 
Hive,WITHOUT_CLASSIFICATION,//  repeated .org.apache.hadoop.hive.ql.hooks.proto.MapFieldEntry otherInfo = 50; 
Hive,WITHOUT_CLASSIFICATION,//  remove from list of live operations 
Hive,WITHOUT_CLASSIFICATION,//  Insert the current table alias entry into the map if not already present in tableAliasToInfo. 
Hive,WITHOUT_CLASSIFICATION,//  Evaluation of the decimal Constant Vector Expression after the vector is 
Hive,WITHOUT_CLASSIFICATION,//  Make sure we've built the lock manager 
Hive,WITHOUT_CLASSIFICATION,//  Continue with next database 
Hive,WITHOUT_CLASSIFICATION,//  if it was null the new (V2) authorization plugin must be specified in   config 
Hive,WITHOUT_CLASSIFICATION,//  see http://en.wikipedia.org/wiki/Approximations_of_%CF%80   Below is the simple Newton's equation 
Hive,WITHOUT_CLASSIFICATION,//  Handle aborted deltas. Currently this can only happen for MM tables. 
Hive,WITHOUT_CLASSIFICATION,//  The set object containing the IN list.   We use a HashSet of HiveDecimalWritable objects instead of HiveDecimal objects so   we can lookup DecimalColumnVector HiveDecimalWritable quickly without creating   a HiveDecimal lookup object. 
Hive,WITHOUT_CLASSIFICATION,//  the process of choosing a new blank works. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure we don't collide with the source. 
Hive,WITHOUT_CLASSIFICATION,//  Already an existing semijoin branch reuse it 
Hive,WITHOUT_CLASSIFICATION,//  if correlation optimizer will not try to optimize this query 
Hive,WITHOUT_CLASSIFICATION,//  Dynamic Partition Insert case 
Hive,WITHOUT_CLASSIFICATION,//  A Statement#close after ResultSet#close should close the statement 
Hive,WITHOUT_CLASSIFICATION,//  Time based log retrieval may not fetch the above log line so logging to stderr for debugging purpose. 
Hive,WITHOUT_CLASSIFICATION,//  Following two config keys are required by FileOutputFormat to work   correctly.   In usual case of Hadoop JobTracker will set these before launching   tasks.   Since there is no jobtracker here we set it ourself. 
Hive,WITHOUT_CLASSIFICATION,//  Normalize to positive. 
Hive,WITHOUT_CLASSIFICATION,//  TopN query 
Hive,WITHOUT_CLASSIFICATION,//  BRound with digits 
Hive,WITHOUT_CLASSIFICATION,//  Add BIGINT values 
Hive,WITHOUT_CLASSIFICATION,//  Since no NULLs we can provide values for all rows. 
Hive,WITHOUT_CLASSIFICATION,//  We need to go lookup the table and get the select statement and then parse it. 
Hive,WITHOUT_CLASSIFICATION,//  does not make sense to have any of the metastore config variables to be 
Hive,WITHOUT_CLASSIFICATION,//  this makes sure MJ has the same downstream operator plan as the original join 
Hive,WITHOUT_CLASSIFICATION,//  compare the results fetched last time 
Hive,WITHOUT_CLASSIFICATION,//  There may not be a base dir if the partition was empty before inserts or if this   partition is just now being converted to ACID. 
Hive,WITHOUT_CLASSIFICATION,//  ever be created for a taskAttempt 
Hive,WITHOUT_CLASSIFICATION,//  Listener parameters aren't expected to have many values. So far only   DbNotificationListener will add a parameter; let's set a low initial capacity for now.   If we find out many parameters are added then we can adjust or remove this initial capacity. 
Hive,WITHOUT_CLASSIFICATION,/*  * Base class for mocking job operations with concurrent requests.  */
Hive,WITHOUT_CLASSIFICATION,//  is the 3 letter sequence "foo". 
Hive,WITHOUT_CLASSIFICATION,//  deferClose indicates if the close/destroy should be deferred when the process has been   interrupted it should be set to true if the compile is called within another method like 
Hive,WITHOUT_CLASSIFICATION,//  could also check WRITE_SET but that seems overkill 
Hive,WITHOUT_CLASSIFICATION,//  sign mark 
Hive,WITHOUT_CLASSIFICATION,//  We have no data from this point on (could be unneeded) skip. 
Hive,WITHOUT_CLASSIFICATION,//  Lets first test for default permissions this is the case when user specified nothing. 
Hive,WITHOUT_CLASSIFICATION,//  onCreateTable alters the table to add the topic name.  Since this class is generating   that alter we don't want to notify on that alter.  So take a quick look and see if 
Hive,WITHOUT_CLASSIFICATION,//  indicate that we've replaced the value 
Hive,WITHOUT_CLASSIFICATION,//  ensure the table is online 
Hive,WITHOUT_CLASSIFICATION,//  write a null element (element field is omitted) 
Hive,WITHOUT_CLASSIFICATION,//  Get partition-list from source. 
Hive,WITHOUT_CLASSIFICATION,//  DEFAULT_POOL_PATH 
Hive,WITHOUT_CLASSIFICATION,//  Make sure we don't compact if we don't need to compact. 
Hive,WITHOUT_CLASSIFICATION,//  If CBO did not optimize the query we might need to replace grouping function   Special handling of grouping function 
Hive,WITHOUT_CLASSIFICATION,// redact the sensitive information from the configuration values 
Hive,WITHOUT_CLASSIFICATION,//  This is a noop return successfully 
Hive,WITHOUT_CLASSIFICATION,//  0. We check the conditions to apply this transformation      if we do not meet them we bail out 
Hive,WITHOUT_CLASSIFICATION,//  TODO: De-link from SessionState. A TezSession can be linked to different Hive Sessions via the pool. 
Hive,WITHOUT_CLASSIFICATION,//  the 2 element list 
Hive,WITHOUT_CLASSIFICATION,//  LOG.debug("VectorMapJoinFastLongHashTable expandAndRehash new logicalHashBucketCount " + logicalHashBucketCount + " resizeThreshold " + resizeThreshold + " metricExpands " + metricExpands); 
Hive,WITHOUT_CLASSIFICATION,//  converts partNames into "partName1 string partName2 string" 
Hive,WITHOUT_CLASSIFICATION,/*  useExternalBuffer  */
Hive,WITHOUT_CLASSIFICATION,//  Restart even if there's an internal error. 
Hive,WITHOUT_CLASSIFICATION,//  Initialize the function localizer. 
Hive,WITHOUT_CLASSIFICATION,//  Add another session. 
Hive,WITHOUT_CLASSIFICATION,//  check if it has sq_count_check 
Hive,WITHOUT_CLASSIFICATION,//  Thread executing the query 
Hive,WITHOUT_CLASSIFICATION,//  Convert the field to Java class String because objects of String type 
Hive,WITHOUT_CLASSIFICATION,//  if its retrying first regenerate the path list. 
Hive,WITHOUT_CLASSIFICATION,// ------------------------------------------------------------------------------------------------ 
Hive,WITHOUT_CLASSIFICATION,//  0/0 for entry 0 should be set as NULL 
Hive,WITHOUT_CLASSIFICATION,//  delete jar and its dependencies added using query1 
Hive,WITHOUT_CLASSIFICATION,//  if the vertex name is longer than column 1 width trim it down 
Hive,WITHOUT_CLASSIFICATION,/*                * Common outer join result processing.                */
Hive,WITHOUT_CLASSIFICATION,//  Coordinator is running as Overlord as well. 
Hive,WITHOUT_CLASSIFICATION,//  Finally remove the partition columns from the end of derivedSchema.   (Clearing the subList writes through to the underlying 
Hive,WITHOUT_CLASSIFICATION,//  1959 
Hive,WITHOUT_CLASSIFICATION,//  We need to update the exprNode as currently   they refer to columns in the output of the join;   they should refer to the columns output by the RS 
Hive,WITHOUT_CLASSIFICATION,//  v[7] -- since left integer #5 is always 0 some products here are not included. 
Hive,WITHOUT_CLASSIFICATION,//  also add the last VCol 
Hive,WITHOUT_CLASSIFICATION,//  info from RR) 
Hive,WITHOUT_CLASSIFICATION,//  The number of duplicates for each series key (NULL or non-NULL). 
Hive,WITHOUT_CLASSIFICATION,//  We don't check compatibility of two object inspectors but directly   pass them into ObjectInspectorUtils.compare() users of this class   should make sure ObjectInspectorUtils.compare() doesn't throw exceptions   and returns correct results. 
Hive,WITHOUT_CLASSIFICATION,//  We will try pushdown first so make the filter. This will also validate the expression 
Hive,WITHOUT_CLASSIFICATION,/*      * used to initialize Streaming Evaluator.      */
Hive,WITHOUT_CLASSIFICATION,//  create a table 
Hive,WITHOUT_CLASSIFICATION,//  for the optimization that reduce number of input file we limit number   of files allowed. If more than specific number of files have to be   selected we skip this optimization. Since having too many files as   inputs can cause unpredictable latency. It's not necessarily to be   cheaper. 
Hive,WITHOUT_CLASSIFICATION,//  Only permanent functions need to be authorized.   Built-in function access is allowed to all users.   If user can create a temp function they should be able to use it   without additional authorization. 
Hive,WITHOUT_CLASSIFICATION,// complete 2nd txn 
Hive,WITHOUT_CLASSIFICATION,//     The result of the swapping operation is either      i)  a Project or 
Hive,WITHOUT_CLASSIFICATION,//  Preempt only if there's no pending preemptions to avoid preempting twice for a task. 
Hive,WITHOUT_CLASSIFICATION,//  send these potentially large objects at longer intervals to avoid overloading the AM 
Hive,WITHOUT_CLASSIFICATION,//  The DB foo is non-existent. 
Hive,WITHOUT_CLASSIFICATION,// ---------------------------------------------------------------------------   Process Single-Column String Inner Big-Only Join on a vectorized row batch.   
Hive,WITHOUT_CLASSIFICATION,//  Decimal types can be specified with different precision and scales e.g. decimal(105)   as opposed to other data types which can be represented by constant strings.   The regex matches only the "decimal" prefix of the type. 
Hive,WITHOUT_CLASSIFICATION,//  All the catalogs should be cached 
Hive,WITHOUT_CLASSIFICATION,//  Finally get all the stuff for serdes - just the params. 
Hive,WITHOUT_CLASSIFICATION,//  Set config so that TxnUtils.buildQueryWithINClauseStrings() will   produce multiple queries 
Hive,WITHOUT_CLASSIFICATION,/*  Key is the database name. Value a map from the qualified name to the view object.  */
Hive,WITHOUT_CLASSIFICATION,//  Create a fake fs root for local fs 
Hive,WITHOUT_CLASSIFICATION,//  if left's signum wins we don't need to do anything 
Hive,WITHOUT_CLASSIFICATION,//  Check to see if this is a table level request on a partitioned table.  If so 
Hive,WITHOUT_CLASSIFICATION,//  for one element the variance is always 0 
Hive,WITHOUT_CLASSIFICATION,//  A mapping from a hadoop job ID to the stack traces collected from the map reduce task logs 
Hive,WITHOUT_CLASSIFICATION,//  create colinfo and then row resolver 
Hive,WITHOUT_CLASSIFICATION,//  Generic Function node e.g. CASE an operator or a UDF node 
Hive,WITHOUT_CLASSIFICATION,//  single split 
Hive,WITHOUT_CLASSIFICATION,//  in-memory HDFS 
Hive,WITHOUT_CLASSIFICATION,//  Turn escape on. 
Hive,WITHOUT_CLASSIFICATION,//  NODE_TYPE 
Hive,WITHOUT_CLASSIFICATION,//  We assume cache chunks would always match the way we read so check and skip it. 
Hive,WITHOUT_CLASSIFICATION,// this can never be null or empty; 
Hive,WITHOUT_CLASSIFICATION,/*        * in case of TopN for windowing we need to distinguish between rows with       * null partition keys and rows with value 0 for partition keys.        */
Hive,WITHOUT_CLASSIFICATION,/*  Count of all values seen so far  */
Hive,WITHOUT_CLASSIFICATION,//  aggregation classes 
Hive,WITHOUT_CLASSIFICATION,//  go over all the input paths and calculate a known total size known 
Hive,WITHOUT_CLASSIFICATION,//  Get the Key 
Hive,WITHOUT_CLASSIFICATION,/*    * Extract column from the given ExprNodeDesc    */
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.QueryCompleteRequestProto.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,//  Testing negative substring index 
Hive,WITHOUT_CLASSIFICATION,//  Then partition number if any. 
Hive,WITHOUT_CLASSIFICATION,//  There are non-numeric arguments that don't match from one UDF to   another. We give up at this point. 
Hive,WITHOUT_CLASSIFICATION,//  Tracks pending preemptions per host using the hostname || Always to be accessed inside a lock 
Hive,WITHOUT_CLASSIFICATION,//  set ColumnAccessInfo for view column authorization 
Hive,WITHOUT_CLASSIFICATION,//  Map of Integer to String 
Hive,WITHOUT_CLASSIFICATION,//  Remove entry for operator 
Hive,WITHOUT_CLASSIFICATION,//  merge task could be after dynamic partition insert 
Hive,WITHOUT_CLASSIFICATION,//  Use type promotion 
Hive,WITHOUT_CLASSIFICATION,//  IS_DYNAMIC_PARTITION_WRITE 
Hive,WITHOUT_CLASSIFICATION,//  equal to sum of small tables size. 
Hive,WITHOUT_CLASSIFICATION,//  If there are aggregations in order by we need to remember them in qb. 
Hive,WITHOUT_CLASSIFICATION,//  need to run this; to get consistent filterop conditions(for operator tree matching) 
Hive,WITHOUT_CLASSIFICATION,// replace view 
Hive,WITHOUT_CLASSIFICATION,//  For numeric we'll do minimum necessary cast - if we cast to the type   of expression bad things will happen. 
Hive,WITHOUT_CLASSIFICATION,//  Do nothing but count. 
Hive,WITHOUT_CLASSIFICATION,//  Get the transaction 
Hive,WITHOUT_CLASSIFICATION,//  boolean that says whether to slow start or not 
Hive,WITHOUT_CLASSIFICATION,//  We need to consolidate 2 or more buffers into one to decompress. 
Hive,WITHOUT_CLASSIFICATION,//  initialize stats publisher if necessary 
Hive,WITHOUT_CLASSIFICATION,//  Create a client to manage our transaction 
Hive,WITHOUT_CLASSIFICATION,/*      * index of Rank function.      */
Hive,WITHOUT_CLASSIFICATION,//  preempt on any host. 
Hive,WITHOUT_CLASSIFICATION,//  Determin which task has been preempted. Normally task2 would be preempted based on it starting   later. However - both may have the same start time so either could be picked. 
Hive,WITHOUT_CLASSIFICATION,/*  * Directly serialize with the caller writing field-by-field a serialization format. * * The caller is responsible for calling the write method for the right type of each field * (or calling writeNull if the field is a NULL). *  */
Hive,WITHOUT_CLASSIFICATION,//  first table in union query with view as parent 
Hive,WITHOUT_CLASSIFICATION,//  Test the validation of incorrect NULL values in the tables 
Hive,WITHOUT_CLASSIFICATION,/* trace error if not exists */
Hive,WITHOUT_CLASSIFICATION,//  To track cleaner metrics 
Hive,WITHOUT_CLASSIFICATION,//  We have exhausted our current batch read the next batch. 
Hive,WITHOUT_CLASSIFICATION,// jump out the loop if we need input from the big table 
Hive,WITHOUT_CLASSIFICATION,//  set fake input and output streams 
Hive,WITHOUT_CLASSIFICATION,//  synchronous event processing loop. Won't return until all events have 
Hive,WITHOUT_CLASSIFICATION,//  Throw exception 
Hive,WITHOUT_CLASSIFICATION,// swallow the exception since it won't affect the final result 
Hive,WITHOUT_CLASSIFICATION,//  If the session has a delegation token obtained from the metastore then cancel it 
Hive,WITHOUT_CLASSIFICATION,//  append as-is 
Hive,WITHOUT_CLASSIFICATION,//  Try authenticating with the http/_HOST principal 
Hive,WITHOUT_CLASSIFICATION,//  column/column 
Hive,WITHOUT_CLASSIFICATION,//  get the db names out 
Hive,WITHOUT_CLASSIFICATION,//  since it is not used further up the tree 
Hive,WITHOUT_CLASSIFICATION,//  Last row of last batch determines isGroupResultNull and long lastValue. 
Hive,WITHOUT_CLASSIFICATION,//  Empty parameters are sent no COLUMN_MAPPING 
Hive,WITHOUT_CLASSIFICATION,//  External client currently cannot use guaranteed. 
Hive,WITHOUT_CLASSIFICATION,/*    * Executes the callable task with help of execute() call and gets the result   * of the task. It also sets job status as COMPLETED if state is not already   * set to FAILED and returns result to future.    */
Hive,WITHOUT_CLASSIFICATION,//  have to do initialization here because the super's constructor   calls next and thus we need to initialize before our constructor 
Hive,WITHOUT_CLASSIFICATION,//  Install the Configuration in the runtime. 
Hive,WITHOUT_CLASSIFICATION,//  2. Extract columns and values 
Hive,WITHOUT_CLASSIFICATION,//  Index of entries by table usage. 
Hive,WITHOUT_CLASSIFICATION,//  If the field that is passed in is NOT a primitive and either the   field is not declared (no schema was given at initialization) or   the field is declared as a primitive in initialization serialize   the data to JSON string.  Otherwise serialize the data in the   delimited way. 
Hive,WITHOUT_CLASSIFICATION,//  The parameters are checked manually so do not check them 
Hive,WITHOUT_CLASSIFICATION,//  batch size of 13 and decaying factor of 2 
Hive,WITHOUT_CLASSIFICATION,// weren't able to check 
Hive,WITHOUT_CLASSIFICATION,//  There should be 2 delta directories 
Hive,WITHOUT_CLASSIFICATION,//  if the aggregation type is sum we do a scale-up 
Hive,WITHOUT_CLASSIFICATION,//  Should generate [2014-01-01 2014-07-01) 
Hive,WITHOUT_CLASSIFICATION,//  This is called from HCat so always allow embedded metastore (as was the default). 
Hive,WITHOUT_CLASSIFICATION,//  Core logic to load hash table using HashTableLoader 
Hive,WITHOUT_CLASSIFICATION,//  disabled for acid path 
Hive,WITHOUT_CLASSIFICATION,//  If the IMetaStoreClient#close was called HMSHandler#shutdown would have already   cleaned up thread local RawStore. Otherwise do it now. 
Hive,WITHOUT_CLASSIFICATION,//  Add a shutdown hook for cleanup if there are elements remaining in the cache which were not cleaned up.   This is the best effort approach. Ignore any error while doing so. Notice that most of the clients   would get cleaned up via either the removalListener or the close() call only the active clients   that are in the cache or expired but being used in other threads wont get cleaned. The following code will only   clean the active cache ones. The ones expired from cache but being hold by other threads are in the mercy   of finalize() being called. 
Hive,WITHOUT_CLASSIFICATION,//  check the easy cases first 
Hive,WITHOUT_CLASSIFICATION,//  Make sure nothing really moved 
Hive,WITHOUT_CLASSIFICATION,//  3. Simulate emitting records in processNextRecord() with large memory usage limit. 
Hive,WITHOUT_CLASSIFICATION,// previously when path is empty or null and no default path is specified   __HIVE_DEFAULT_PARTITION__ was the return value for escapePathName 
Hive,WITHOUT_CLASSIFICATION,// in practice we don't really care about the data in any of these tables (except as far as  it creates partitions the SQL being test is not actually executed and results of the  wrt ACID metadata is supplied manually via addDynamicPartitions().  But having data makes  it easier to follow the intent 
Hive,WITHOUT_CLASSIFICATION,//  Export case 
Hive,WITHOUT_CLASSIFICATION,//  use multiple lines for statements not terminated by the delimiter 
Hive,WITHOUT_CLASSIFICATION,//  /////////////////////////////////////   ResultSet output formatting classes   ///////////////////////////////////// 
Hive,WITHOUT_CLASSIFICATION,//  PRIMITIVE_ENTRY 
Hive,WITHOUT_CLASSIFICATION,//  For serialization. 
Hive,WITHOUT_CLASSIFICATION,//  It's a table alias. 
Hive,WITHOUT_CLASSIFICATION,//  Our reading is positioned to the value. 
Hive,WITHOUT_CLASSIFICATION,//  1. If the table has a Sample specified bail from Calcite path. 
Hive,WITHOUT_CLASSIFICATION,//  try alternate config param 
Hive,WITHOUT_CLASSIFICATION,//  serializeScale < fastScale. 
Hive,WITHOUT_CLASSIFICATION,// record partitions that were written to 
Hive,WITHOUT_CLASSIFICATION,//  Optimize the scenario when there are no grouping keys - only 1 reducer is 
Hive,WITHOUT_CLASSIFICATION,//  No other columns provided non-NULL values.  We can return repeated output. 
Hive,WITHOUT_CLASSIFICATION,//  PartitionView does not have SD and we do not need to update its column stats 
Hive,WITHOUT_CLASSIFICATION,//  this will be used by the outputcommitter to pass on to the metastore client   which in turn will pass on to the TokenSelector so that it can select 
Hive,WITHOUT_CLASSIFICATION,//  Map 1 .......... container  SUCCEEDED      7          7        0        0       0       0 
Hive,WITHOUT_CLASSIFICATION,//  Don't fail; this is best-effort. 
Hive,WITHOUT_CLASSIFICATION,//  Skip the MM directory that we have found. 
Hive,WITHOUT_CLASSIFICATION,/*      * arguments      */
Hive,WITHOUT_CLASSIFICATION,//  If simple map join the whole relation goes in memory 
Hive,WITHOUT_CLASSIFICATION,//  The assign method will be overridden for CHAR and VARCHAR. 
Hive,WITHOUT_CLASSIFICATION,//  We have found a map. Systematically deserialize the values of the map and return back the   map 
Hive,WITHOUT_CLASSIFICATION,/*    * Thread pool to execute job requests.    */
Hive,WITHOUT_CLASSIFICATION,//  Do the join. It does fetching of next row groups itself. 
Hive,WITHOUT_CLASSIFICATION,//  Authorization is done. Just call super. 
Hive,WITHOUT_CLASSIFICATION,//  push the feed to its subscribers 
Hive,WITHOUT_CLASSIFICATION,/*        Start of cleanup     */
Hive,WITHOUT_CLASSIFICATION,//  At this point we've set up all the tables and ptns we're going to test drops across   Replicate it first and then we'll drop it on the source. 
Hive,WITHOUT_CLASSIFICATION,//  ROW__ID is always in the first field 
Hive,WITHOUT_CLASSIFICATION,//  Note: we assume reuse is only possible for the same user and config. 
Hive,WITHOUT_CLASSIFICATION,//  Use ranges and duplicate multipliers to reduce the size of the display. 
Hive,WITHOUT_CLASSIFICATION,//  col2:double>); 
Hive,WITHOUT_CLASSIFICATION,/*      * (non-Javadoc)     * @see org.apache.hadoop.hive.ql.udf.ptf.TableFunctionResolver#getOutputNames()     * Set to null only because carryForwardNames is true.      */
Hive,WITHOUT_CLASSIFICATION,//  get aliasToPath and pass it to the heuristic 
Hive,WITHOUT_CLASSIFICATION,//  Try to insert up to n times. Rehash if that fails. 
Hive,WITHOUT_CLASSIFICATION,//  initialize FetchTask right here 
Hive,WITHOUT_CLASSIFICATION,/*    * IMPLEMENTATION NOTE:   *    We implement HiveDecimal with the mutable FastHiveDecimal class.  That class uses   *    protected on all its methods so they will not be visible in the HiveDecimal class.   *   *    So even if one casts to FastHiveDecimal you shouldn't be able to violate the immutability   *    of a HiveDecimal class.    */
Hive,WITHOUT_CLASSIFICATION,//  Do not create an identity project if it does not rename any fields 
Hive,WITHOUT_CLASSIFICATION,//  change file modification time and look for cache misses 
Hive,WITHOUT_CLASSIFICATION,//  Keep an open txn which refers to the aborted txn. 
Hive,WITHOUT_CLASSIFICATION,//  update the attrs 
Hive,WITHOUT_CLASSIFICATION,//  table is deleted 
Hive,WITHOUT_CLASSIFICATION,//  The hash code for each non-NULL key. 
Hive,WITHOUT_CLASSIFICATION,//  POOL_TRIGGERS 
Hive,WITHOUT_CLASSIFICATION,//  A MuxOperator should only have a single child 
Hive,WITHOUT_CLASSIFICATION,//  Determine the name of our map or reduce task for debug tracing. 
Hive,WITHOUT_CLASSIFICATION,//  do a group by to aggregate minmax and bloom filter. 
Hive,WITHOUT_CLASSIFICATION,//  Password file contents are trimmed of trailing whitespaces and newlines 
Hive,WITHOUT_CLASSIFICATION,//  don't do zero-divide if one comes up at random 
Hive,WITHOUT_CLASSIFICATION,//  only one result column   verify the column name   verify the column name 
Hive,WITHOUT_CLASSIFICATION,//  extract stages 
Hive,WITHOUT_CLASSIFICATION,//  Do not allow temp table rename if the new name already exists as a temp table 
Hive,WITHOUT_CLASSIFICATION,//  These 4 types are not supported yet.   We should define a complex type date in thrift that contains a single int   member and DynamicSerDe   should convert it to date type at runtime. 
Hive,WITHOUT_CLASSIFICATION,//  number of digits to retain from the end 
Hive,WITHOUT_CLASSIFICATION,//  tableScan is only available during compile 
Hive,WITHOUT_CLASSIFICATION,//  Check if two arguments were passed 
Hive,WITHOUT_CLASSIFICATION,//  and again one last time. 
Hive,WITHOUT_CLASSIFICATION,//  Note: we may make size/etc. configurable later. 
Hive,WITHOUT_CLASSIFICATION,//  Note: we don't pass the config to reopen. If the session was already open it would         have kept running with its current config - preserve that behavior. 
Hive,WITHOUT_CLASSIFICATION,// Calcite creates null literal with Null type here but 
Hive,WITHOUT_CLASSIFICATION,//  If it is a RIGHT / FULL OUTER JOIN we need to iterate through the row container   that contains all the right records that did not produce results. Then for each   of those records we replace the left side with NULL values and produce the   records.   Observe that we only enter this block when we have finished iterating through   all the left and right records (aliasNum == numAliases - 2) and thus we have   tried to evaluate the post-filter condition on every possible combination. 
Hive,WITHOUT_CLASSIFICATION,/*  first_name is null or       first_name <> 'sue' or       id >= 12 or       id <= 4;  */
Hive,WITHOUT_CLASSIFICATION,// push down projections to columnar store works for RCFile and ORCFile 
Hive,WITHOUT_CLASSIFICATION,// Uses level parallel implementation of a bfs. Recursive DFS implementations  have a issue where the number of threads can run out if the number of  nested sub-directories is more than the pool size.  Using a two queue implementation is simpler than one queue since then we will  have to add the complex mechanisms to let the free worker threads know when new levels are  discovered using notify()/wait() mechanisms which can potentially lead to bugs if  not done right 
Hive,WITHOUT_CLASSIFICATION,//  Stop requested and handled inside. 
Hive,WITHOUT_CLASSIFICATION,//  load the properties from config file 
Hive,WITHOUT_CLASSIFICATION,//  The fields that HS2 uses to give AM information about plugin endpoint.   Some of these will be removed when AM registry is implemented as AM will generate and publish them. 
Hive,WITHOUT_CLASSIFICATION,//  First try non-random values 
Hive,WITHOUT_CLASSIFICATION,// note: inserts go into 'new part'... so this won't fail 
Hive,WITHOUT_CLASSIFICATION,// throw exception to simulate an issue with cleaner thread 
Hive,WITHOUT_CLASSIFICATION,//  If the file is missing or getting modified then refer CM path 
Hive,WITHOUT_CLASSIFICATION,//  Get the other one by examining Join Op 
Hive,WITHOUT_CLASSIFICATION,//  make sure the columns does not already exist 
Hive,WITHOUT_CLASSIFICATION,//  FINAL REDUCTION:   Case 7: NO column stats — numRows / 2   Case 8: column stats grouping sets — Min(numRows ndvProduct * sizeOfGroupingSet)   Case 9: column stats NO grouping sets - Min(numRows ndvProduct) 
Hive,WITHOUT_CLASSIFICATION,//  Enable TransactionalValidationListener + create.as.acid 
Hive,WITHOUT_CLASSIFICATION,// if HADOOP_PROXY_USER is set create DelegationToken using real user 
Hive,WITHOUT_CLASSIFICATION,//  Check specificFilterSet for QTest specific ones. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#setSavepoint()    */
Hive,WITHOUT_CLASSIFICATION,//  When all inputs are accounted for the output is forwarded appropriately. 
Hive,WITHOUT_CLASSIFICATION,//  directory creation is otherwise within the writers 
Hive,WITHOUT_CLASSIFICATION,// ************************************************************************************************   Binary to Decimal Conversion. 
Hive,WITHOUT_CLASSIFICATION,//  originally copied from org.apache.hadoop.mapred.lib.InputSampler but seemed to have a bug 
Hive,WITHOUT_CLASSIFICATION,//  List of compactions to clean. 
Hive,WITHOUT_CLASSIFICATION,// Get the output location in the order partition keys are defined for the table. 
Hive,WITHOUT_CLASSIFICATION,// Start Metrics 
Hive,WITHOUT_CLASSIFICATION,//  Storage information. 
Hive,WITHOUT_CLASSIFICATION,//  and 0 if condition needs to be computed. 
Hive,WITHOUT_CLASSIFICATION,//  do nothing handled below - types will mismatch 
Hive,WITHOUT_CLASSIFICATION,//  bucketed or sorted table/partition they cannot be merged. 
Hive,WITHOUT_CLASSIFICATION,//  blocks if no more llap queries can be submitted. 
Hive,WITHOUT_CLASSIFICATION,//  Cached successfully add to policy. 
Hive,WITHOUT_CLASSIFICATION,//  Note: we assume here the session before we resolve killQuery result here is still         "in use". That is because all the user ops above like return reopen etc.         don't actually return/reopen/... when kill query is in progress. 
Hive,WITHOUT_CLASSIFICATION,//  apply overlay query specific settings if any 
Hive,WITHOUT_CLASSIFICATION,//  get the collection separator and map key separator 
Hive,WITHOUT_CLASSIFICATION,//  Evaluate the aggregation input argument expression. 
Hive,WITHOUT_CLASSIFICATION,//  as the initialCapacity which cannot be 0 we provide a reasonable   positive number here 
Hive,WITHOUT_CLASSIFICATION,//  Col2 
Hive,WITHOUT_CLASSIFICATION,//  Add the jar file 
Hive,WITHOUT_CLASSIFICATION,// @Ignore("see bucket_num_reducers_acid.q") 
Hive,WITHOUT_CLASSIFICATION,//  Test different format types 
Hive,WITHOUT_CLASSIFICATION,/*    * Generate the GroupByOperator for the Query Block (parseInfo.getXXX(dest)).   * The new GroupByOperator will be a child of the reduceSinkOperatorInfo.   *   * @param mode   *          The mode of the aggregation (PARTIAL1 or COMPLETE)   * @param genericUDAFEvaluators   *          If not null this function will store the mapping from Aggregation   *          StringTree to the genericUDAFEvaluator in this parameter so it   *          can be used in the next-stage GroupBy aggregations.   * @return the new GroupByOperator    */
Hive,WITHOUT_CLASSIFICATION,//  BOOL_VAL 
Hive,WITHOUT_CLASSIFICATION,//  All partitions with blurb="isLocatedOutsideTablePath" should have 2 columns 
Hive,WITHOUT_CLASSIFICATION,//  Expected if the operation takes time. Continue the loop and wait for op completion. 
Hive,WITHOUT_CLASSIFICATION,//  null args: 
Hive,WITHOUT_CLASSIFICATION,//  Note: the sinks and DDL cannot coexist at this time; but if they could we would 
Hive,WITHOUT_CLASSIFICATION,//  MAP requires 2 levels: key separator and key-pair separator. 
Hive,WITHOUT_CLASSIFICATION,//  close off the buffer with a normal tag 
Hive,WITHOUT_CLASSIFICATION,//  now check the table folder and see if we find anything   that isn't in the metastore 
Hive,WITHOUT_CLASSIFICATION,//  Logger jobs 
Hive,WITHOUT_CLASSIFICATION,//  Get ready for a another round of small table values. 
Hive,WITHOUT_CLASSIFICATION,/*      * Get the list of table scan operators for this join. A interface supportSkewJoinOptimization     * has been provided. Currently it is only enabled for simple filters and selects.      */
Hive,WITHOUT_CLASSIFICATION,//  Col1 
Hive,WITHOUT_CLASSIFICATION,//  need at least 1 ZK server for testing 
Hive,WITHOUT_CLASSIFICATION,// if here we are now doing an Acid read so must have OrcSplit.  CombineHiveInputFormat is 
Hive,WITHOUT_CLASSIFICATION,//  This helper object serializes LazyBinary format reducer values from columns of a row 
Hive,WITHOUT_CLASSIFICATION,//  no check for the line? How to check?   if the line is invalid for any reason the job will fail. 
Hive,WITHOUT_CLASSIFICATION,//  closeHBaseConnections 
Hive,WITHOUT_CLASSIFICATION,//  Create cost metadata provider 
Hive,WITHOUT_CLASSIFICATION,//  Parse until pair separator (currentLevel). 
Hive,WITHOUT_CLASSIFICATION,//  need a state store eventually for current state & measure backoffs 
Hive,WITHOUT_CLASSIFICATION,// construct the -setfacl command 
Hive,WITHOUT_CLASSIFICATION,/*  10 files x 1000 size for 99 splits  */
Hive,WITHOUT_CLASSIFICATION,//  COLS 
Hive,WITHOUT_CLASSIFICATION,//  found the plan is already connected which means this is derived from the cache. 
Hive,WITHOUT_CLASSIFICATION,/*    * Element for Key: byte[] x Hash Table: HashMultiSet    */
Hive,WITHOUT_CLASSIFICATION,/*  Hcat requires ALTER_DATA privileges for ALTER TABLE LOCATION statements      * for the old table/partition location and the new location.       */
Hive,WITHOUT_CLASSIFICATION,//  Add 1 for tag 
Hive,WITHOUT_CLASSIFICATION,//  we're continuing an existing command 
Hive,WITHOUT_CLASSIFICATION,//  wrapping for exception handling 
Hive,WITHOUT_CLASSIFICATION,//  leadership state changes and sending out notifications to listener happens inside synchronous method in curator.   Do only lightweight actions in main-event handler thread. Time consuming operations are handled via separate   executor service registered via registerLeaderLatchListener(). 
Hive,WITHOUT_CLASSIFICATION,//  This call fills in the column names types and partition column count in 
Hive,WITHOUT_CLASSIFICATION,//  no leading 0 for month and day should work 
Hive,WITHOUT_CLASSIFICATION,//  grant option 
Hive,WITHOUT_CLASSIFICATION,// handle the isNull array first in tight loops 
Hive,WITHOUT_CLASSIFICATION,//  extract stats keys from StatsTask 
Hive,WITHOUT_CLASSIFICATION,//  Should not be used. 
Hive,WITHOUT_CLASSIFICATION,//  both branches are null. 
Hive,WITHOUT_CLASSIFICATION,//  Col3 
Hive,WITHOUT_CLASSIFICATION,//  generation. 
Hive,WITHOUT_CLASSIFICATION,//  Use VertexOrBinary.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,//  1 WriteEntity: default@acidtblpart Type=TABLE WriteType=INSERT isDP=false 
Hive,WITHOUT_CLASSIFICATION,//  This collector is just a row counter. 
Hive,WITHOUT_CLASSIFICATION,//  targetPath path is /x/y/z/1/2/3 here /x/y/z is present in the file system   create the structure till /x/y/z/1/2 to work rename for multilevel directory   and if rename fails delete the path /x/y/z/1   If targetPath have multilevel directories like /x/y/z/1/2/3  /x/y/z/1/2/4   the renaming of the directories are not atomic the execution will happen one   by one 
Hive,WITHOUT_CLASSIFICATION,//  Assume the full ACID table. 
Hive,WITHOUT_CLASSIFICATION,//  can't happen 
Hive,WITHOUT_CLASSIFICATION,//  split exclusively serves alias which needs to be sampled   add it to the split list of the alias. 
Hive,WITHOUT_CLASSIFICATION,//  2nd task requested host2 got host4 since host3 is dead and host2 is full 
Hive,WITHOUT_CLASSIFICATION,//  create a syntax tree for a function call 'myisnull(col0 "UNKNOWN")' 
Hive,WITHOUT_CLASSIFICATION,//  Map each aborted write id with each allocated txn. 
Hive,WITHOUT_CLASSIFICATION,//  There should still be four directories in the location. 
Hive,WITHOUT_CLASSIFICATION,//  Bucket MapJoin in LLAP make sure the caches are populated.   Get the subcache. 
Hive,WITHOUT_CLASSIFICATION,//  If enablejobreconnect param was not passed by a user use a cluster   wide default 
Hive,WITHOUT_CLASSIFICATION,//  optional   optional   optional   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  This also provides completion information and a possible notification when task actually starts running (first heartbeat) 
Hive,WITHOUT_CLASSIFICATION,//  Rows to be emitted with a separate thread per processNextRecord() call. 
Hive,WITHOUT_CLASSIFICATION,//  1.2 Add GrpSet Col 
Hive,WITHOUT_CLASSIFICATION,//  SerDe property for how the Hive column maps to Accumulo 
Hive,WITHOUT_CLASSIFICATION,//  Only allow constant field name for now 
Hive,WITHOUT_CLASSIFICATION,//  This function checks whether all bucketing columns are also in join keys and are in same order 
Hive,WITHOUT_CLASSIFICATION,//  Test getTables() 
Hive,WITHOUT_CLASSIFICATION,//  Test that 2 separate partitions don't coalesce. 
Hive,WITHOUT_CLASSIFICATION,//  header 
Hive,WITHOUT_CLASSIFICATION,//  Copy bytes into scratch buffer. 
Hive,WITHOUT_CLASSIFICATION,//  block to make sure move happened successfully 
Hive,WITHOUT_CLASSIFICATION,//  Make sure the cleanup doesn't leave the pool without a session. 
Hive,WITHOUT_CLASSIFICATION,// release S on T6  attempt to X on T6 again - succeed 
Hive,WITHOUT_CLASSIFICATION,//  key columns 
Hive,WITHOUT_CLASSIFICATION,//  LOG.info("extractThriftToken("+tokenStrForm+""+tokenSignature+")"); 
Hive,WITHOUT_CLASSIFICATION,//  placeholder; minimum pf value is enforced in NGramEstimator 
Hive,WITHOUT_CLASSIFICATION,//  there should be only one ColumnStatistics 
Hive,WITHOUT_CLASSIFICATION,//  Sanity check; restrictedConfig is always set in setup. 
Hive,WITHOUT_CLASSIFICATION,//  NEW TAI LUE LETTER THA U+1992 (3 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  Round towards negative infinity. 
Hive,WITHOUT_CLASSIFICATION,//  PARTITION_VALUES 
Hive,WITHOUT_CLASSIFICATION,//  Verify that COLUMN_STATS_ACCURATE is removed from params 
Hive,WITHOUT_CLASSIFICATION,/*  resultSignum  */
Hive,WITHOUT_CLASSIFICATION,//  Get the field objectInspector and the field object. 
Hive,WITHOUT_CLASSIFICATION,//  It is a constant we can ignore it 
Hive,WITHOUT_CLASSIFICATION,//  Note: other parent readers init everything in ctor but union does it in startStripe. 
Hive,WITHOUT_CLASSIFICATION,//  No move pending and no intervening discard the allocator can release. 
Hive,WITHOUT_CLASSIFICATION,//  Hadoop is missing a public API to check for snapshotable directories. Check with the directory name   until a more appropriate API is provided by HDFS-12257. 
Hive,WITHOUT_CLASSIFICATION,//  If it is the first child we set the mode variable value   Otherwise if the mode we are working on is different we   bail out 
Hive,WITHOUT_CLASSIFICATION,//  this is to keep track of null literal which already has been visited 
Hive,WITHOUT_CLASSIFICATION,//  Reset the selection vector. 
Hive,WITHOUT_CLASSIFICATION,//  Strip the leading ";" if provided   (this is the assumption with which we're going to start configuring sessionConfExt) 
Hive,WITHOUT_CLASSIFICATION,//  IMPORTANT NOTE: For Multi-OR the VectorizationContext class will catch cases with 3 or                   more parameters... 
Hive,WITHOUT_CLASSIFICATION,// create the serialized string for type 
Hive,WITHOUT_CLASSIFICATION,//  Decimals are stored as BigInteger so convert and compare 
Hive,WITHOUT_CLASSIFICATION,//  only write to the record file if we are writing a line ...   otherwise we might get garbage from backspaces and such. 
Hive,WITHOUT_CLASSIFICATION,//  Map filter to the new filter over join 
Hive,WITHOUT_CLASSIFICATION,/* since COMPACTOR_MAX_NUM_DELTA=2    we expect files 12 to be minor compacted by 1 job to produce delta_21_23    * 35 to be minor compacted by 2nd job (file 4 is obsolete) to make delta_25_33 (4th is skipped)    *    * and then the 'requested'    * minor compaction to combine delta_21_23 delta_25_33 and delta_35_35 to make delta_21_35    * or major compaction to create base_35 */
Hive,WITHOUT_CLASSIFICATION,// this uses VectorizedOrcAcidRowBatchReader 
Hive,WITHOUT_CLASSIFICATION,//  If we are going to use cache change the path to depend on file ID for extra consistency. 
Hive,WITHOUT_CLASSIFICATION,//  accumulate the counts 
Hive,WITHOUT_CLASSIFICATION,//  If available copy state to registry for optimization rules 
Hive,WITHOUT_CLASSIFICATION,//  Task is just created 
Hive,WITHOUT_CLASSIFICATION,//  write header 
Hive,WITHOUT_CLASSIFICATION,//  At least one task would have been added to update the repl state 
Hive,WITHOUT_CLASSIFICATION,/* Assert.assertEquals(1        TxnDbUtil.countLockComponents(((DbLockManager.DbHiveLock) locks.get(0)).lockId));     */
Hive,WITHOUT_CLASSIFICATION,//  standard object 
Hive,WITHOUT_CLASSIFICATION,//  if false prune it 
Hive,WITHOUT_CLASSIFICATION,/*  neither side is repeating  */
Hive,WITHOUT_CLASSIFICATION,//  no truncate the table is missing either due to drop/rename which follows the truncate.   or the existing table is newer than our update. 
Hive,WITHOUT_CLASSIFICATION,//  see javadoc of AccumuloCompositeRowId 
Hive,WITHOUT_CLASSIFICATION,//  2^32-1 + .01 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hadoop.mapreduce.RecordReader#initialize(   * org.apache.hadoop.mapreduce.InputSplit   * org.apache.hadoop.mapreduce.TaskAttemptContext)    */
Hive,WITHOUT_CLASSIFICATION,//  Next check if this table has partitions and if so   get the list of partition names as well as allocate 
Hive,WITHOUT_CLASSIFICATION,//  leading spaces are significant 
Hive,WITHOUT_CLASSIFICATION,//  These are null when evaluate() is called for the first time 
Hive,WITHOUT_CLASSIFICATION,// since the loop left it == txnToWriteIds.size() 
Hive,WITHOUT_CLASSIFICATION,//  Acquire different locks at different levels 
Hive,WITHOUT_CLASSIFICATION,//  firstFetchHappened == true. In reality it almost always calls joinOneGroup. Fix it? 
Hive,WITHOUT_CLASSIFICATION,//  No more matches expected. 
Hive,WITHOUT_CLASSIFICATION,//  follow it. 
Hive,WITHOUT_CLASSIFICATION,//  we also need to delete partdate=2008-01-01 to make it consistent. 
Hive,WITHOUT_CLASSIFICATION,//  We now have a vector of aggregation buffer sets to use for each row   We can start computing the aggregates.   If the number of distinct keys in the batch is 1 we can   use the optimized code path of aggregateInput 
Hive,WITHOUT_CLASSIFICATION,/*            * if we could not get status for some reason log it and send empty status back with           * just the ID so that caller knows to even look in the log file            */
Hive,WITHOUT_CLASSIFICATION,//  Sample data 
Hive,WITHOUT_CLASSIFICATION,//  Assuming that a valid UGI with kerberos cred is created by HS2 or LLAP 
Hive,WITHOUT_CLASSIFICATION,/*      * translate args      */
Hive,WITHOUT_CLASSIFICATION,//  It is possible the table is deleted during fetching tables of the database   in that case continue with the next table 
Hive,WITHOUT_CLASSIFICATION,//  This happens when the code inside the JMX bean threw an exception so   log it and don't output the bean. 
Hive,WITHOUT_CLASSIFICATION,//  It's hard to distinguish a union with null from a null union. 
Hive,WITHOUT_CLASSIFICATION,//  Use nullIndicator to decide whether to project null.   Do nothing if the literal is null. 
Hive,WITHOUT_CLASSIFICATION,//  Rip apart the object inspector making sure we got what we expect. 
Hive,WITHOUT_CLASSIFICATION,//  4. Gather GB Memory threshold 
Hive,WITHOUT_CLASSIFICATION,//  the udtf op 
Hive,WITHOUT_CLASSIFICATION,//  no HS2 instances are running 
Hive,WITHOUT_CLASSIFICATION,//  make this client wait if job tracker is not behaving well. 
Hive,WITHOUT_CLASSIFICATION,//  If we're here then socket1.getLocalPort was the port to exclude   Since both sockets were open together at a point in time we're   guaranteed that socket2.getLocalPort() is not the same. 
Hive,WITHOUT_CLASSIFICATION,//  so we don't lose this. A bit of a weird dance here. 
Hive,WITHOUT_CLASSIFICATION,//  at the end 
Hive,WITHOUT_CLASSIFICATION,/*    * Phase1: hold onto any CTE definitions in aliasToCTE.   * CTE definitions are global to the Query.    */
Hive,WITHOUT_CLASSIFICATION,//  Create cmroot with permission 700 if not exist 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#getResultSet()    */
Hive,WITHOUT_CLASSIFICATION,//  Test a query where timeout does not kick in. Set it to 5s; 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * This provides a LazyFloat like class which can be initialized from data stored in a   * binary format.   *   * @see org.apache.hadoop.hive.serde2.lazy.LazyObject#init   *        (org.apache.hadoop.hive.serde2.lazy.ByteArrayRef int int)    */
Hive,WITHOUT_CLASSIFICATION,//  Wildcard bind 
Hive,WITHOUT_CLASSIFICATION,//  Fetch the TableScan Operator. 
Hive,WITHOUT_CLASSIFICATION,//  call-1: listLocatedStatus - mock:/mocktbl 
Hive,WITHOUT_CLASSIFICATION,//  bail on mux-operator because mux operator masks the emit keys of the   constituent reduce sinks 
Hive,WITHOUT_CLASSIFICATION,//  key expiration - create an already expired key 
Hive,WITHOUT_CLASSIFICATION,// @VisibleForTesting 
Hive,WITHOUT_CLASSIFICATION,//  The following union operation returns a union which traverses over the   first set once and then  then over each element of second set in order   that is not contained in first. This means it doesn't replace anything   in first set and would preserve the WriteType in WriteEntity in first   set in case of outputs list. 
Hive,WITHOUT_CLASSIFICATION,//  we've not seen this terminal before. we need to check   rootUnionWorkMap which contains the information of mapping the root   operator of a union work to a union work 
Hive,WITHOUT_CLASSIFICATION,//  Someone is allocating an arena. 
Hive,WITHOUT_CLASSIFICATION,//  Re-enable timeouts 
Hive,WITHOUT_CLASSIFICATION,// This the set of entities that the statement represented by extLockId wants to update 
Hive,WITHOUT_CLASSIFICATION,//  Session should not be lost; however the fraction should be discarded. 
Hive,WITHOUT_CLASSIFICATION,//  VectorizedBatchUtil.debugDisplayOneRow(batch batchIndex CLASS_NAME + " NOMATCH" + " currentKey " + currentKey); 
Hive,WITHOUT_CLASSIFICATION,/*    * check if a Select Expr is a constant.   * - current logic used is to look for HiveParser.TOK_TABLE_OR_COL   * - if there is none then the expression is a constant.    */
Hive,WITHOUT_CLASSIFICATION,//  not fetching from a table directly but from a temp location 
Hive,WITHOUT_CLASSIFICATION,/*    * Constructors of various flavors follow.    */
Hive,WITHOUT_CLASSIFICATION,//  old schemas within it. 
Hive,WITHOUT_CLASSIFICATION,//  serialize json based on field annotations only 
Hive,WITHOUT_CLASSIFICATION,//  check implementation class: 
Hive,WITHOUT_CLASSIFICATION,//  List of softreferences 
Hive,WITHOUT_CLASSIFICATION,//  If negotiation is complete remove this handler from the pipeline and register it with   the Kryo instance to handle encryption if needed. 
Hive,WITHOUT_CLASSIFICATION,//  this is really just -1 
Hive,WITHOUT_CLASSIFICATION,//  Case 5: column stats NO hash aggregation NO grouping sets 
Hive,WITHOUT_CLASSIFICATION,/*    * Lookup an long in the hash set.   *   * @param key   *         The long key.   * @param hashSetResult   *         The object to receive small table value(s) information on a MATCH.   *         Or for SPILL it has information on where to spill the big table row.   *   * @return   *         Whether the lookup was a match no match or spilled (the partition with the key   *         is currently spilled).    */
Hive,WITHOUT_CLASSIFICATION,//  hex input is also supported 
Hive,WITHOUT_CLASSIFICATION,//  base. 
Hive,WITHOUT_CLASSIFICATION,/*    * DECIMAL_64.    */
Hive,WITHOUT_CLASSIFICATION,//  MIDDLE pattern 
Hive,WITHOUT_CLASSIFICATION,//  join operator 
Hive,WITHOUT_CLASSIFICATION,//  initialize map local work 
Hive,WITHOUT_CLASSIFICATION,//  Add all non-virtual columns from the TableScan operator. 
Hive,WITHOUT_CLASSIFICATION,// ---------------------------------------------------------------------------   Process Multi-Key Inner Big-Only Join on a vectorized row batch.   
Hive,WITHOUT_CLASSIFICATION,//  lazily create PathChildrenCache 
Hive,WITHOUT_CLASSIFICATION,//  group by requires "ArrayList" don't ask. 
Hive,WITHOUT_CLASSIFICATION,//  priority = 30 / (4000 - 100) = 0.0076 
Hive,WITHOUT_CLASSIFICATION,//  Type-specific handling 
Hive,WITHOUT_CLASSIFICATION,//  Its not clear if this rewrite is always performant on MR since extra map phase   introduced for 2nd MR job may offset gains of this multi-stage aggregation.   We need a cost model for MR to enable this on MR. 
Hive,WITHOUT_CLASSIFICATION,//  get table metadata 
Hive,WITHOUT_CLASSIFICATION,//    { "key": { "reducesinkkey0":int "reducesinkkey1":int } "value": { "_col6":int } } 
Hive,WITHOUT_CLASSIFICATION,//  sparse-sparse merge 
Hive,WITHOUT_CLASSIFICATION,// table ownership for create/drop/alter index 
Hive,WITHOUT_CLASSIFICATION,//  get the tables for the desired patten - populate the output stream 
Hive,WITHOUT_CLASSIFICATION,//  Keep separate from the creating events in case the send blocks. 
Hive,WITHOUT_CLASSIFICATION,/*      * The following tests will verify the deprecation variable is still usable.      */
Hive,WITHOUT_CLASSIFICATION,//  Assume the worst. 
Hive,WITHOUT_CLASSIFICATION,//  Tell the operator the status of the next key-grouped VectorizedRowBatch that will be delivered   to the process method.  E.g. by reduce-shuffle.  These semantics are needed by PTF so it can 
Hive,WITHOUT_CLASSIFICATION,//  Add the actual source input 
Hive,WITHOUT_CLASSIFICATION,//  Move the pointer to the next byte since we have written 
Hive,WITHOUT_CLASSIFICATION,//  We will generate results for all matching and non-matching rows. 
Hive,WITHOUT_CLASSIFICATION,//  get the group by keys to ColumnInfo 
Hive,WITHOUT_CLASSIFICATION,// failed because object doesn't exist 
Hive,WITHOUT_CLASSIFICATION,/*  Thread simulating a user session in HiveServer2.  */
Hive,WITHOUT_CLASSIFICATION,/*      * Keeps track of regular timed heartbeats. Is primarily used as a timing mechanism to send /     * log counters.      */
Hive,WITHOUT_CLASSIFICATION,/*  verify the connection fails after canceling the token  */
Hive,WITHOUT_CLASSIFICATION,//  Decode UTF-8 
Hive,WITHOUT_CLASSIFICATION,//  Same object. 
Hive,WITHOUT_CLASSIFICATION,//  be aware that result could be the same object as z. 
Hive,WITHOUT_CLASSIFICATION,// next() should always return false 
Hive,WITHOUT_CLASSIFICATION,//  optional string executionMode = 4; 
Hive,WITHOUT_CLASSIFICATION,//  NULL plan means WM is disabled via a command; it could still be reenabled. 
Hive,WITHOUT_CLASSIFICATION,//  set that parent initialization is done and call initialize on children 
Hive,WITHOUT_CLASSIFICATION,//  Note: this thing should know nothing about ACID or schema. It reads physical columns by index;         schema evolution/ACID schema considerations should be on higher level. 
Hive,WITHOUT_CLASSIFICATION,//  3. Get Aggregation FN from Calcite given name ret type and input arg 
Hive,WITHOUT_CLASSIFICATION,//  we are currently walking the big table side of the merge join. we need to create or hook up 
Hive,WITHOUT_CLASSIFICATION,//  partition values are specified on non-partitioned table 
Hive,WITHOUT_CLASSIFICATION,//  sort and pick partition keys 
Hive,WITHOUT_CLASSIFICATION,//  remove requested quantiles from the head of the list 
Hive,WITHOUT_CLASSIFICATION,//  Lock a few blocks without telling the policy. 
Hive,WITHOUT_CLASSIFICATION,//  We need to add a cast to DATETIME Family 
Hive,WITHOUT_CLASSIFICATION,//  Use Case 8. 
Hive,WITHOUT_CLASSIFICATION,//  if row count is 0 and where there are no nulls it means index is disabled and we don't have stats 
Hive,WITHOUT_CLASSIFICATION,//  Some cases were converted before calling getVectorExpressionForUdf.   So emulate those cases first. 
Hive,WITHOUT_CLASSIFICATION,//  Return aggregate collations 
Hive,WITHOUT_CLASSIFICATION,//  If this is the last byte leave the high bit off 
Hive,WITHOUT_CLASSIFICATION,//  Add partitions located in the table-directory (i.e. default). 
Hive,WITHOUT_CLASSIFICATION,//  fileHeader resultType arg2Type arg3Type 
Hive,WITHOUT_CLASSIFICATION,// testing MATCHED AND with CASE statement  using target.a breaks this 
Hive,WITHOUT_CLASSIFICATION,//  If old table is in the cache but the new table *cannot* be cached 
Hive,WITHOUT_CLASSIFICATION,//  A null cq implies an empty column qualifier 
Hive,WITHOUT_CLASSIFICATION,//  2^56 * 2^56 
Hive,WITHOUT_CLASSIFICATION,//  Only log on the first wait and check after wait on the last iteration. 
Hive,WITHOUT_CLASSIFICATION,//  return "0sec if no difference 
Hive,WITHOUT_CLASSIFICATION,/*        * use a run-length encoding. We only record run length if a same       * 'prevValueLen' occurs more than one time. And we negative the run       * length to distinguish a runLength and a normal value length. For       * example if the values' lengths are 1112 we record 1 ~22. And for       * value lengths 123 we record 123.        */
Hive,WITHOUT_CLASSIFICATION,//  The key of the next lowest reader. 
Hive,WITHOUT_CLASSIFICATION,/*     * Expected result 0th entry i the RecordIdentifier + data.  1st entry file before compact */
Hive,WITHOUT_CLASSIFICATION,//  to tasks started after the addFile() call completes. 
Hive,WITHOUT_CLASSIFICATION,//  the key is found in MapColumnVector set the value 
Hive,WITHOUT_CLASSIFICATION,//  This means there are tables of something in the database 
Hive,WITHOUT_CLASSIFICATION,//  Save the evaluator so that it can be used by the next-stage 
Hive,WITHOUT_CLASSIFICATION,//  to this plan:     Project-A' (all gby keys + rewritten nullable ProjExpr)     Aggregate (groupby(all left input refs)                   agg0(rewritten expression)                   agg1()...)       Project-B' (rewriten original projected exprs)         Join(replace corvar w/ input ref from LeftInputRel)           LeftInputRel           RightInputRel   
Hive,WITHOUT_CLASSIFICATION,//  Update the aggregations. 
Hive,WITHOUT_CLASSIFICATION,//  This is arbitrary. Note that metadata may come from a big scan and nuke all the data   from some small frequently accessed tables because it gets such a large priority boost   to start with. Think of the multiplier as the number of accesses after which the data   becomes more important than some random read-once metadata in a pure-LFU scheme. 
Hive,WITHOUT_CLASSIFICATION,//  1st Cancel 
Hive,WITHOUT_CLASSIFICATION,//  Negative numbers indicate a column to be (deserialize) read from the small table's   LazyBinary value row. 
Hive,WITHOUT_CLASSIFICATION,//  String or string equivalent is considered numeric when used in arithmetic operator. 
Hive,WITHOUT_CLASSIFICATION,/*    * STRING.   *   * Can be used to write CHAR and VARCHAR when the caller takes responsibility for   * truncation/padding issues.    */
Hive,WITHOUT_CLASSIFICATION,/*    * fastSerializationUtilsRead lower word is 62 bits (the lower bit is used as the sign and is   * removed).  So we need a multiplier 2^62   *   *    2^62 =   *      4611686018427387904 or   *      4611686018427387904 or   *      4611686018427387904 (16 digit comma'd)    */
Hive,WITHOUT_CLASSIFICATION,//  The ObjectInspector for the row ID 
Hive,WITHOUT_CLASSIFICATION,//  if numReducers < 0 and newNumReducers > 0 
Hive,WITHOUT_CLASSIFICATION,//  continue.. null out the field? 
Hive,WITHOUT_CLASSIFICATION,//  those tables directory. 
Hive,WITHOUT_CLASSIFICATION,//  If the serializer is ThriftJDBCBinarySerDe then it requires that NoOpFetchFormatter be used. But when it isn't   then either the ThriftFormatter or the DefaultFetchFormatter should be used. 
Hive,WITHOUT_CLASSIFICATION,// ************************************************************************************************   Decimal Rounding. 
Hive,WITHOUT_CLASSIFICATION,//  Update the joinKeys appropriately. 
Hive,WITHOUT_CLASSIFICATION,//  3. Perform a major compaction 
Hive,WITHOUT_CLASSIFICATION,//  Add a column.   Change SerDe File I/O formats. 
Hive,WITHOUT_CLASSIFICATION,//  Store the changes 
Hive,WITHOUT_CLASSIFICATION,//  set method. This requires calcite change 
Hive,WITHOUT_CLASSIFICATION,//  the combinations below definitely result in overflow 
Hive,WITHOUT_CLASSIFICATION,// remove currTask from parentTasks 
Hive,WITHOUT_CLASSIFICATION,//  -ve dates are also valid dates - the dates are within 1959 to 2027 
Hive,WITHOUT_CLASSIFICATION,//  We will store all the new /changed properties in the job in the   udf context so the the HCatInputFormat.setInput method need not 
Hive,WITHOUT_CLASSIFICATION,//  For now olderClass has 1 version and newerClass 2 versions... 
Hive,WITHOUT_CLASSIFICATION,//  Allow endFunctionListeners to add any counters they have collected 
Hive,WITHOUT_CLASSIFICATION,//  From https://docs.microsoft.com/en-us/sql/t-sql/language-elements/reserved-keywords-transact-sql#odbc-reserved-keywords 
Hive,WITHOUT_CLASSIFICATION,//  partition level column stats merging 
Hive,WITHOUT_CLASSIFICATION,//  create new operator: HashTable DummyOperator which share the table desc 
Hive,WITHOUT_CLASSIFICATION,// create a few read locks all on the same resource 
Hive,WITHOUT_CLASSIFICATION,//  Check whether current operators are equal 
Hive,WITHOUT_CLASSIFICATION,//  so let's create a new list and copy it if we don't have a linked list 
Hive,WITHOUT_CLASSIFICATION,/*      * validate and setup SymbolInfo      */
Hive,WITHOUT_CLASSIFICATION,//  Possible because a queryComplete message from the AM can come in first - KILL / SUCCESSFUL   before the fragmentComplete is reported 
Hive,WITHOUT_CLASSIFICATION,//  No heartbeat 
Hive,WITHOUT_CLASSIFICATION,//  Given the keyIndex these arrays return:     The ColumnVector.Type     The type specific index into longIndices doubleIndices etc... 
Hive,WITHOUT_CLASSIFICATION,// must be just a column name 
Hive,WITHOUT_CLASSIFICATION,//  varchar 
Hive,WITHOUT_CLASSIFICATION,//  child can be EXPR AS ALIAS or EXPR. 
Hive,WITHOUT_CLASSIFICATION,//  deletes for the bucket being taken into consideration for this split processing. 
Hive,WITHOUT_CLASSIFICATION,//  prevent instantiation 
Hive,WITHOUT_CLASSIFICATION,//  For dynamic partitioned writes without all keyvalues specified   we create a temp dir for the associated write job 
Hive,WITHOUT_CLASSIFICATION,//  Since "ifexists" was not set to true trying to create the same table   again   will result in an exception. 
Hive,WITHOUT_CLASSIFICATION,//  Set of values to look for. Include the original blank value Long.MIN_VALUE to make sure 
Hive,WITHOUT_CLASSIFICATION,//  Relative positions of the blocks don't change over time; priorities we expire can only   decrease; we only have one block that could have broken heap rule and we always move it   down; therefore we can update priorities of other blocks as we go for part of the heap -   we correct any discrepancy w/the parent after expiring priority and any block we expire   the priority for already has lower priority than that of its children. 
Hive,WITHOUT_CLASSIFICATION,//  If table of current event has partition flag different from existing table it means some   of the previous events in same batch have drop and create table events with same same but   different partition flag. In this case should go with current event's table type and so   create the dummy table object for adding repl tasks. 
Hive,WITHOUT_CLASSIFICATION,//  verify udf reflect is allowed (no exception will be thrown) 
Hive,WITHOUT_CLASSIFICATION,//  bigTableCandidates can never be null 
Hive,WITHOUT_CLASSIFICATION,//  Find tables which name contains _to_find_ or _hidden_ in the default database 
Hive,WITHOUT_CLASSIFICATION,//  Subscriber can get notification about addition of a table in HCAT   by listening on a topic named "HCAT" and message selector string   as "HCAT_EVENT = HCAT_ADD_TABLE" 
Hive,WITHOUT_CLASSIFICATION,//  Independent of hashtable and can be modified no need to copy. 
Hive,WITHOUT_CLASSIFICATION,//  This is integer because in Derby DN converts boolean to char breaking sysdb. 
Hive,WITHOUT_CLASSIFICATION,//  Open the log file and read the lines parse out stack traces 
Hive,WITHOUT_CLASSIFICATION,//  File checksum is not implemented for local filesystem (RawLocalFileSystem) 
Hive,WITHOUT_CLASSIFICATION,//  0. Handle initialization results. 
Hive,WITHOUT_CLASSIFICATION,//  Create another table for incremental repl verification 
Hive,WITHOUT_CLASSIFICATION,//  Cancel the query 
Hive,WITHOUT_CLASSIFICATION,/*            * We have a "regular" single rows from the Input File Format reader that we will need           * to deserialize.            */
Hive,WITHOUT_CLASSIFICATION,//  Determine which rows are left. 
Hive,WITHOUT_CLASSIFICATION,//  NEW_SCHEMA 
Hive,WITHOUT_CLASSIFICATION,//  8. Incase this QB corresponds to subquery then modify its RR to point   to subquery alias 
Hive,WITHOUT_CLASSIFICATION,//  remove valid columns 
Hive,WITHOUT_CLASSIFICATION,//  find file instead of dir. dont change inputpath 
Hive,WITHOUT_CLASSIFICATION,//  done processing the task 
Hive,WITHOUT_CLASSIFICATION,//  the subqueries are map-only jobs 
Hive,WITHOUT_CLASSIFICATION,//  If there is a correlation condition anywhere in the filter don't   push this filter past project since in some cases it can prevent a   Correlate from being de-correlated. 
Hive,WITHOUT_CLASSIFICATION,//  accessing order of join cols to bucket cols should be same 
Hive,WITHOUT_CLASSIFICATION,//  task to the new task. 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: this partitionSpec has to be ordered map 
Hive,WITHOUT_CLASSIFICATION,//  If credential provider has entry for our credential then it should be used 
Hive,WITHOUT_CLASSIFICATION,//  First value is written without: next relative offset next value length is next value last   flag is next value length small flag etc. 
Hive,WITHOUT_CLASSIFICATION,//  Need to drop the primary DB as metastore is shared by both primary/replica. So constraints 
Hive,WITHOUT_CLASSIFICATION,//  Make it a power of 2 by backing down (i.e. the -2). 
Hive,WITHOUT_CLASSIFICATION,//  v[1] where (product % MULTIPLER_INTWORD_DECIMAL) is the carry from v[0]. 
Hive,WITHOUT_CLASSIFICATION,//  did not find the column 
Hive,WITHOUT_CLASSIFICATION,//  Store the bucket path to bucket number mapping in the table scan operator.   Although one mapper per file is used (BucketizedInputHiveInput) it is possible that   any mapper can pick up any file (depending on the size of the files). The bucket number 
Hive,WITHOUT_CLASSIFICATION,//  no rename the table is missing either due to drop/rename which follows the current rename.   or the existing table is newer than our update. 
Hive,WITHOUT_CLASSIFICATION,//  Avro considers bytes primitive Hive doesn't. Make them list of tinyint. 
Hive,WITHOUT_CLASSIFICATION,//  Set HiveConf statics to default values 
Hive,WITHOUT_CLASSIFICATION,//  updateCurrentKey needs to be called to initialize the master key   (there should be a null check added in the future in rollMasterKey)   updateCurrentKey(); 
Hive,WITHOUT_CLASSIFICATION,//  TODO Setup SSL Shuffle 
Hive,WITHOUT_CLASSIFICATION,//  vectors 
Hive,WITHOUT_CLASSIFICATION,//  if collection usage threshold is not support worst case set memory threshold on memory usage (before GC) 
Hive,WITHOUT_CLASSIFICATION,/*    * Helper to determine what java options to use for the containers   * Falls back to Map-reduces map java opts if no tez specific options   * are set    */
Hive,WITHOUT_CLASSIFICATION,//  In one work only one map join operator can be bucketed 
Hive,WITHOUT_CLASSIFICATION,//  check singleAggRel is single_value agg 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * This provides a LazyBinary like class which can be initialized from data stored in a   * binary format.   *   * @see org.apache.hadoop.hive.serde2.lazy.LazyObject#init   *        (org.apache.hadoop.hive.serde2.lazy.ByteArrayRef int int)    */
Hive,WITHOUT_CLASSIFICATION,//  table for which show locks is being executed 
Hive,WITHOUT_CLASSIFICATION,//  set a pass a property to operation and check if its set the query config 
Hive,WITHOUT_CLASSIFICATION,//  timestamp BETWEEN 
Hive,WITHOUT_CLASSIFICATION,//  bypass only if outerRR is not null. Otherwise we need to look for expressions in outerRR for   subqueries e.g. select min(b.value) from table b group by b.key 
Hive,WITHOUT_CLASSIFICATION,//  Ascending   Null first (default for ascending order) 
Hive,WITHOUT_CLASSIFICATION,//  interface into the registry service 
Hive,WITHOUT_CLASSIFICATION,//  This is a 1-stage map-reduce processing of the groupby. Tha map-side   aggregates was just used to   reduce output data. In case of distincts partial results are not used   and so iterate is again   invoked on the reducer. In case of non-distincts partial results are   used and merge is invoked   on the reducer. 
Hive,WITHOUT_CLASSIFICATION,// see also https://issues.apache.org/jira/browse/HIVE-9938 
Hive,WITHOUT_CLASSIFICATION,//  Try empty rows query 
Hive,WITHOUT_CLASSIFICATION,// returns IP addr 
Hive,WITHOUT_CLASSIFICATION,//  Wait for another iteration to make sure event gets processed for D2 to receive allocation. 
Hive,WITHOUT_CLASSIFICATION,//  Check that we are cleaning up the empty aborted transactions 
Hive,WITHOUT_CLASSIFICATION,// the row__ids are the same after compaction 
Hive,WITHOUT_CLASSIFICATION,//  These constants are also imported by org.apache.hadoop.hive.ql.io.AcidUtils. 
Hive,WITHOUT_CLASSIFICATION,//  For run length byte encoding record the number of bits within current byte to consume to 
Hive,WITHOUT_CLASSIFICATION,//  remove reducer 
Hive,WITHOUT_CLASSIFICATION,//  This still could be DPP. 
Hive,WITHOUT_CLASSIFICATION,//  Whole repeated key batch was filtered out. 
Hive,WITHOUT_CLASSIFICATION,//  This spawns a separate thread to walk through the cache and removes expired nodes.   Only one cleaner thread should be running at any point. 
Hive,WITHOUT_CLASSIFICATION,//  Step3: move to the file destination 
Hive,WITHOUT_CLASSIFICATION,//  to handle the rest of the aggregation that the bottom aggregate hasn't handled 
Hive,WITHOUT_CLASSIFICATION,//  returns rows from possibly multiple bucket files of small table in ascending order   by utilizing primary queue (borrowed from hadoop) 
Hive,WITHOUT_CLASSIFICATION,//  Need to preserve loggedInUser 
Hive,WITHOUT_CLASSIFICATION,//  We may have already connected `work` with `childWork` in case for example lateral view:      TS       |      ...       |      LVF       | \      SEL SEL       |    |      LVJ-UDTF       |      SEL       |      RS   Here RS can be reached from TS via two different paths. If there is any child work after RS   we don't want to connect them with the work associated with TS more than once. 
Hive,WITHOUT_CLASSIFICATION,//               degree of parallelism 
Hive,WITHOUT_CLASSIFICATION,//  Make it a power of 2. 
Hive,WITHOUT_CLASSIFICATION,//  Partition value can't end in this suffix 
Hive,WITHOUT_CLASSIFICATION,//  The planner gives us a subset virtual columns available for this table scan.      AND   We only support some virtual columns in vectorization.     So create the intersection.  Note these are available vectorizable virtual columns.   Later we remember which virtual columns were *actually used* in the query so   just those will be included in the Map VectorizedRowBatchCtx that has the   information for creating the Map VectorizedRowBatch.   
Hive,WITHOUT_CLASSIFICATION,//  This instance will not be added back since it's services are not up yet. 
Hive,WITHOUT_CLASSIFICATION,//  match! 
Hive,WITHOUT_CLASSIFICATION,//  Compare cell value with constant value in filter   1 if they match and cell value isn't other return true   2 if they don't match but cell is other and value in filter is not skewed value     return unknown. why not true? true is not enough. since not true is false     but not unknown is unknown.     For example skewed column C skewed value 1 2. clause: where not ( c =3)     cell is other evaluate (not(c=3)).     other to (c=3) if ture. not(c=3) will be false. but it is wrong skip default dir     but if unknown. not(c=3) will be unknown. we will choose default dir.   3 all others return false 
Hive,WITHOUT_CLASSIFICATION,//  default to false 
Hive,WITHOUT_CLASSIFICATION,//  Setting hive.server2.enable.doAs to True ensures that HS2 performs the query operation as   the connected user instead of the user running HS2. 
Hive,WITHOUT_CLASSIFICATION,//  If we found something before we ran out of components use it. 
Hive,WITHOUT_CLASSIFICATION,//  Verify the actual locations being correct.   os13 should be on a different location. Splits are supposed to be consistent across JVMs   the test is setup to verify a different host (make sure not to hash to the same host as os11os12).   If the test were to fail because the host is the same - the assumption about consistent across JVM 
Hive,WITHOUT_CLASSIFICATION,/*    * Kills templeton job with multiple retries if job exists. Returns true if kill job   * attempt is success. Otherwise returns false.    */
Hive,WITHOUT_CLASSIFICATION,// if needRequireLock is false the release here will do nothing because there is no lock 
Hive,WITHOUT_CLASSIFICATION,//  Since equiv f should get back first container 
Hive,WITHOUT_CLASSIFICATION,//  queryPlan here. 
Hive,WITHOUT_CLASSIFICATION,//  For spark in non-local mode any added dependencies are stored at   SparkFiles::getRootDirectory which is the executor's working directory.   In local mode we need to manually point the process's working directory to it 
Hive,WITHOUT_CLASSIFICATION,//  Return empty result since only constant Desc exists 
Hive,WITHOUT_CLASSIFICATION,//  before closing the operator check if statistics gathering is requested   and is provided by record writer. this is different from the statistics   gathering done in processOp(). In processOp() for each row added   serde statistics about the row is gathered and accumulated in hashmap.   this adds more overhead to the actual processing of row. But if the   record writer already gathers the statistics it can simply return the   accumulated statistics which will be aggregated in case of spray writers 
Hive,WITHOUT_CLASSIFICATION,//  Calculate unique skewed elements for each skewed column. 
Hive,WITHOUT_CLASSIFICATION,//  One serialized key for 1 or more rows for the duplicate keys.   LOG.info("reduceSkipTag " + reduceSkipTag + " tag " + tag + " reduceTagByte " + (int) reduceTagByte + " keyLength " + serializedKeySeries.getSerializedLength());   LOG.info("process offset " + serializedKeySeries.getSerializedStart() + " length " + serializedKeySeries.getSerializedLength()); 
Hive,WITHOUT_CLASSIFICATION,//  Trailing space should ignored for char comparisons.   So write stripped values for this SerDe. 
Hive,WITHOUT_CLASSIFICATION,//  setting these props to match LazySimpleSerde 
Hive,WITHOUT_CLASSIFICATION,//  Check column types 
Hive,WITHOUT_CLASSIFICATION,//  check if task is started 
Hive,WITHOUT_CLASSIFICATION,//  Internal representation is an integer representing day offset from our epoch value 1970-01-01 
Hive,WITHOUT_CLASSIFICATION,//  Not public since we must have the serialize write object. 
Hive,WITHOUT_CLASSIFICATION,//  classloader invokes this static block when its first loaded (lazy initialization). 
Hive,WITHOUT_CLASSIFICATION,//  constant or null expr just return 
Hive,WITHOUT_CLASSIFICATION,//  1. We apply the transformation 
Hive,WITHOUT_CLASSIFICATION,//  we create a dummy vertex for a mergejoin branch for a self join if this 
Hive,WITHOUT_CLASSIFICATION,//  FUTURE: Add INTERVAL_YEAR_MONTH etc as desired. 
Hive,WITHOUT_CLASSIFICATION,//  Advance the primary reader to the next record 
Hive,WITHOUT_CLASSIFICATION,//  4. Walk through UDAF & Collect UDAF Info 
Hive,WITHOUT_CLASSIFICATION,//  UNIQUE_CONSTRAINT_COLS 
Hive,WITHOUT_CLASSIFICATION,//  An array was passed as parameter 2 make sure it's an array of primitives 
Hive,WITHOUT_CLASSIFICATION,//  Number of arguments to this UDF   External Name 
Hive,WITHOUT_CLASSIFICATION,//  Valid paths 
Hive,WITHOUT_CLASSIFICATION,// surrogate pair case 
Hive,WITHOUT_CLASSIFICATION,//  Fetch rows from splits 
Hive,WITHOUT_CLASSIFICATION,//  We do not need to do anything we bail out 
Hive,WITHOUT_CLASSIFICATION,//  The numbers of input columns and output columns should match for regular query 
Hive,WITHOUT_CLASSIFICATION,/*        * Raise custom exception like IOException and verify expected Message.        */
Hive,WITHOUT_CLASSIFICATION,//  old test is moved to msck_repair_2.q 
Hive,WITHOUT_CLASSIFICATION,//  walk operator tree to create expression tree for filter buckets 
Hive,WITHOUT_CLASSIFICATION,//  The columns in the group by expressions should not intersect with the columns in the   distinct expressions 
Hive,WITHOUT_CLASSIFICATION,// we have WHEN NOT MATCHED AND <boolean expr> THEN INSERT 
Hive,WITHOUT_CLASSIFICATION,// so the plan knows we are 'reading' this db - locks security... 
Hive,WITHOUT_CLASSIFICATION,// note that this KeyInterval may be adjusted later due to copy_N files 
Hive,WITHOUT_CLASSIFICATION,// Check if the existing partition values can be type casted to the new column type 
Hive,WITHOUT_CLASSIFICATION,//  table matcher. 
Hive,WITHOUT_CLASSIFICATION,//  NEXT_TXN_ID.ntxn_next could be min_uncommitted_txnid. 
Hive,WITHOUT_CLASSIFICATION,//  Right now we assume only FM and HLL are available. 
Hive,WITHOUT_CLASSIFICATION,/*        * since there is a collision index will be used for the next value        * so have the map point back to original index.        */
Hive,WITHOUT_CLASSIFICATION,//  Add the Auth filter 
Hive,WITHOUT_CLASSIFICATION,//  Fill the buffer with key value pairs. 
Hive,WITHOUT_CLASSIFICATION,//  Is this field a null? 
Hive,WITHOUT_CLASSIFICATION,//  Edge case? 
Hive,WITHOUT_CLASSIFICATION,//  In this case A-B-D join will be executed first and ABD-C join will be executed in next 
Hive,WITHOUT_CLASSIFICATION,//  generate absolute path relative to current directory or hdfs home   directory 
Hive,WITHOUT_CLASSIFICATION,//  Reads the index file for each requested mapId and figures out the overall   length of the response - which is populated into the response header. 
Hive,WITHOUT_CLASSIFICATION,//  The actual deserialization may involve nested records which require recursion. 
Hive,WITHOUT_CLASSIFICATION,//  different queries in the session may be using the same lock manager. 
Hive,WITHOUT_CLASSIFICATION,//  Lock operations themselves don't require the lock. 
Hive,WITHOUT_CLASSIFICATION,//  partition columns   partition values 
Hive,WITHOUT_CLASSIFICATION,//  Update the leaf in place 
Hive,WITHOUT_CLASSIFICATION,//  create conditional work list and task list 
Hive,WITHOUT_CLASSIFICATION,//  if custom root specified update the parent path 
Hive,WITHOUT_CLASSIFICATION,//  Nope so look to see if our home dir has been explicitly set 
Hive,WITHOUT_CLASSIFICATION,/*  Object Inspectors corresponding to the struct returned by TerminatePartial and the long     * field within the struct - "count"      */
Hive,WITHOUT_CLASSIFICATION,/*                * In a single-threaded init case with this the ordering of sessions in the queue will be               * (with 2 sessions 3 queues) s1q1 s1q2 s1q3 s2q1 s2q2 s2q3 there by ensuring uniform               * distribution of the sessions across queues at least to begin with. Then as sessions get               * freed up the list may change this ordering.               * In a multi threaded init case it's a free for all.                */
Hive,WITHOUT_CLASSIFICATION,//  because this file will be fetched by fetch operator 
Hive,WITHOUT_CLASSIFICATION,//  2. Reduce filter with stats information 
Hive,WITHOUT_CLASSIFICATION,//  Summary for column statistics 
Hive,WITHOUT_CLASSIFICATION,/*            * Clear out any rows we may have processed in row-mode for the current partition..            */
Hive,WITHOUT_CLASSIFICATION,//  added project if need to produce new keys than the original input   fields 
Hive,WITHOUT_CLASSIFICATION,//  look for getFieldName() or isFieldName() 
Hive,WITHOUT_CLASSIFICATION,//  Only used for dynamic partitioned hash joins (mapjoin operator in the reducer) 
Hive,WITHOUT_CLASSIFICATION,//  Choose first up to a full batch with no selection. 
Hive,WITHOUT_CLASSIFICATION,//  Implementation of row container 
Hive,WITHOUT_CLASSIFICATION,//  As writeIdHwm is known query all writeIds under the writeId HWM.   If any writeId under HWM is allocated by txn > txnId HWM or belongs to open/aborted txns   then will be added to invalid list. The results should be sorted in ascending order based   on write id. The sorting is needed as exceptions list in ValidWriteIdList would be looked-up 
Hive,WITHOUT_CLASSIFICATION,//  value will be NULL. 
Hive,WITHOUT_CLASSIFICATION,//  test when first argument has nulls 
Hive,WITHOUT_CLASSIFICATION,//  13. To record move events we need to cluster fraction updates that happens at step 11. 
Hive,WITHOUT_CLASSIFICATION,//  Using the hook on startup ensures that the hook always has priority   over settings in *.xml.  The thread local conf needs to be used because at this point   it has already been initialized using conf. 
Hive,WITHOUT_CLASSIFICATION,//  Iterate over the rest of the children 
Hive,WITHOUT_CLASSIFICATION,//  If cbucketcols or pbucketcols have constant node expressions avoid the merge. 
Hive,WITHOUT_CLASSIFICATION,// insert clause 
Hive,WITHOUT_CLASSIFICATION,//  Ket is partition values and the value is a wrapper around the partition object 
Hive,WITHOUT_CLASSIFICATION,//  No need to collect statistics of index columns 
Hive,WITHOUT_CLASSIFICATION,//  5. Put uncompressed data to cache. 
Hive,WITHOUT_CLASSIFICATION,//  handle the single block case 
Hive,WITHOUT_CLASSIFICATION,//  parent reduce sinks 
Hive,WITHOUT_CLASSIFICATION,//  Clear all in-memory partitions first 
Hive,WITHOUT_CLASSIFICATION,//  NOT_NULL_CONSTRAINTS 
Hive,WITHOUT_CLASSIFICATION,// HCat doesn't support transactional tables 
Hive,WITHOUT_CLASSIFICATION,//  Round to power of 2 here as is required by WriteBuffers 
Hive,WITHOUT_CLASSIFICATION,// delta/ with files in raw format are a result of Load Data (as opposed to compaction  or streaming ingest so must have interval length == 1. 
Hive,WITHOUT_CLASSIFICATION,//  Linear interpolation to get the exact percentile 
Hive,WITHOUT_CLASSIFICATION,//  Drop databases created by other test cases 
Hive,WITHOUT_CLASSIFICATION,//  LOG.info("First tail offset " + writeBuffers.getWritePoint()); 
Hive,WITHOUT_CLASSIFICATION,//  Use Case 9. 
Hive,WITHOUT_CLASSIFICATION,//  Pre-install the database so all the tables are there. 
Hive,WITHOUT_CLASSIFICATION,//  Check that dropping database from wrong catalog fails 
Hive,WITHOUT_CLASSIFICATION,//  first create expression from defaultValueAST 
Hive,WITHOUT_CLASSIFICATION,//  WriteId of recently committed txn which was open when get ValidTxnList snapshot should be invalid as well. 
Hive,WITHOUT_CLASSIFICATION,//  all columns 
Hive,WITHOUT_CLASSIFICATION,//  Since bigTableValueExpressions may do a calculation and produce a scratch column we   need to map to the right batch column. 
Hive,WITHOUT_CLASSIFICATION,//  accepting Object means accepting everything   but there is a conversion cost. 
Hive,WITHOUT_CLASSIFICATION,//  different level the drop command specified. 
Hive,WITHOUT_CLASSIFICATION,//  LinkedHashMap have a repeatable iteration order. 
Hive,WITHOUT_CLASSIFICATION,//  Cleanup the mapwork path 
Hive,WITHOUT_CLASSIFICATION,//  2 jobs 2 stages per job 2 tasks per stage. 
Hive,WITHOUT_CLASSIFICATION,//  reset the resolver 
Hive,WITHOUT_CLASSIFICATION,//  This is the overwhelmingly common case. 
Hive,WITHOUT_CLASSIFICATION,// first child should be rowid 
Hive,WITHOUT_CLASSIFICATION,//  Link backtrack SelectOp to FileSinkOp 
Hive,WITHOUT_CLASSIFICATION,//  initialize reduce operator tree 
Hive,WITHOUT_CLASSIFICATION,//  for example original it is max 0 dist 1 min 2 
Hive,WITHOUT_CLASSIFICATION,//  constant = constant expressions. We shouldn't be getting this 
Hive,WITHOUT_CLASSIFICATION,//  arbitrary column names used internally for serializing to spill table 
Hive,WITHOUT_CLASSIFICATION,//  5. GroupingSets Cube Rollup 
Hive,WITHOUT_CLASSIFICATION,//  If the whole column vector has no nulls this is true otherwise false. 
Hive,WITHOUT_CLASSIFICATION,//  Use Case 10. 
Hive,WITHOUT_CLASSIFICATION,//  Generate the intermediate aggregate B the one on the bottom that converts   a distinct call to group by call.   Bottom aggregate is the same as the original aggregate except that 
Hive,WITHOUT_CLASSIFICATION,//  operations. So READ COMMITTED is sufficient. 
Hive,WITHOUT_CLASSIFICATION,//  else fallback to HLLOriginal algorithm 
Hive,WITHOUT_CLASSIFICATION,//  FILES_ADDED 
Hive,WITHOUT_CLASSIFICATION,//  Create the filter for the queryId appender 
Hive,WITHOUT_CLASSIFICATION,//  with HIVE-7832 the dictionaries will be disabled after writing the first   stripe as there are too many distinct values. Hence only 3 stripes as   compared to 25 stripes in version 0.11 (above test case) 
Hive,WITHOUT_CLASSIFICATION,//  Do the per-batch setup for an outer join. 
Hive,WITHOUT_CLASSIFICATION,//  Get the table from metastore 
Hive,WITHOUT_CLASSIFICATION,//  we already check if rowCnt is null and rowCnt==0 means table is   empty. 
Hive,WITHOUT_CLASSIFICATION,//  Reset the conf variable values that we changed for this test. 
Hive,WITHOUT_CLASSIFICATION,//  We should copy only those table parameters that are specified in the config. 
Hive,WITHOUT_CLASSIFICATION,//  skip no semijoin branch 
Hive,WITHOUT_CLASSIFICATION,//  Copy to new slot table. 
Hive,WITHOUT_CLASSIFICATION,//  counts are cached to avoid repeated complex computation. If register value 
Hive,WITHOUT_CLASSIFICATION,//  Stores the Tablescan operators processed to avoid redoing them. 
Hive,WITHOUT_CLASSIFICATION,//  number of registers - 2^p 
Hive,WITHOUT_CLASSIFICATION,/*  * Test submission of concurrent job requests with the controlled number of concurrent * Requests. Verify that we get busy exception and appropriate message.  */
Hive,WITHOUT_CLASSIFICATION,//  If the child has a different schema we create a Project operator between them both   as we cannot prune the columns in the GroupBy operator 
Hive,WITHOUT_CLASSIFICATION,//  go through each element of the map
Hive,WITHOUT_CLASSIFICATION,//  One serialized key for 1 or more rows for the duplicate keys. 
Hive,WITHOUT_CLASSIFICATION,//  For backwards compatibility since some threads used to be hard coded but only run if   frequency was > 0 
Hive,WITHOUT_CLASSIFICATION,//  Sum all non-null double column values; maintain isGroupResultNull. 
Hive,WITHOUT_CLASSIFICATION,//  Uses non-transactional table cannot be considered 
Hive,WITHOUT_CLASSIFICATION,// Inet4Address/Inet6Address 
Hive,WITHOUT_CLASSIFICATION,//  Verify the ValidWriteIdList with one open txn on this table. Write ID of open txn should be invalid. 
Hive,WITHOUT_CLASSIFICATION,//  no hash aggregations for group by 
Hive,WITHOUT_CLASSIFICATION,//  it's set to to set our own conf value. 
Hive,WITHOUT_CLASSIFICATION,//  equal to 3 
Hive,WITHOUT_CLASSIFICATION,//  checking against the partition in question instead. 
Hive,WITHOUT_CLASSIFICATION,/*   registrations and un-registrations will happen as and when tasks are submitted or are removed.  reference counting is likely required.  A connection needs to be established to each app master.  Ignore exceptions when communicating with the AM.  At a later point report back saying the AM is dead so that tasks can be removed from the running queue.  Race: When a task completes - it sends out it's message via the regular TaskReporter. The AM after this may run another DAG  or may die. This may need to be consolidated with the LlapTaskReporter. Try ensuring there's no race between the two.  Single thread which sends heartbeats to AppMasters as events drain off a queue.    */
Hive,WITHOUT_CLASSIFICATION,//  End AggregateExpandDistinctAggregatesRule.java 
Hive,WITHOUT_CLASSIFICATION,//  grouping(c1 c2 c3)   is equivalent to 
Hive,WITHOUT_CLASSIFICATION,//  todo HIVE-3841   sampling on task running 
Hive,WITHOUT_CLASSIFICATION,//  STAGE_COUNTERS 
Hive,WITHOUT_CLASSIFICATION,//  Perform any bucket expressions.  Results will go into scratch columns. 
Hive,WITHOUT_CLASSIFICATION,//  all returned type will be Text 
Hive,WITHOUT_CLASSIFICATION,//  Index of the last seen delimiter in the given line 
Hive,WITHOUT_CLASSIFICATION,//  1. We go over the expressions in the project operator      and we separate the windowing nodes that are result 
Hive,WITHOUT_CLASSIFICATION,//  get nanos between [epoch at toZone] and [local time at toZone] 
Hive,WITHOUT_CLASSIFICATION,//  update the pending state for now as we release this lock to take both. 
Hive,WITHOUT_CLASSIFICATION,//  This means the DB name is null 
Hive,WITHOUT_CLASSIFICATION,//  class HiveEndPoint 
Hive,WITHOUT_CLASSIFICATION,//  the setChildren method initializes the object inspector needed by the operators   based on path and partition information. 
Hive,WITHOUT_CLASSIFICATION,//  Knuth "The Art of Computer Programming" 3rd edition vol.II Alg.D   pg 272   D1. Normalize so high digit of D >= BASE/2 - that guarantee 
Hive,WITHOUT_CLASSIFICATION,//  Probably an expression cant handle that 
Hive,WITHOUT_CLASSIFICATION,//  Same; with the termination after the failed update we should maintain the correct count. 
Hive,WITHOUT_CLASSIFICATION,//  Start the session in a fire-and-forget manner. When the asynchronously initialized parts of   the session are needed the corresponding getters and other methods will wait as needed. 
Hive,WITHOUT_CLASSIFICATION,//  Use the big table row as output. 
Hive,WITHOUT_CLASSIFICATION,//  Also try creating a UGI object for the SPNego principal 
Hive,WITHOUT_CLASSIFICATION,//  hcatalog specific configurations that can be put in hive-site.xml 
Hive,WITHOUT_CLASSIFICATION,/*    * a) Order predciates based on ndv in reverse order. b) ndvCrossProduct =   * ndv(pe0) * ndv(pe1) ^(1/2) * ndv(pe2) ^(1/4) * ndv(pe3) ^(1/8) ...    */
Hive,WITHOUT_CLASSIFICATION,//  remove the current task from its original parent task's dependent task 
Hive,WITHOUT_CLASSIFICATION,//  Walk over the input schema and copy in the output 
Hive,WITHOUT_CLASSIFICATION,//  filter enabled injection enabled exception not expected 
Hive,WITHOUT_CLASSIFICATION,//  The table is not bucketed add a dummy filter :: rand() 
Hive,WITHOUT_CLASSIFICATION,//  order does not matter below so go wide 
Hive,WITHOUT_CLASSIFICATION,//  Set the bucketing version 
Hive,WITHOUT_CLASSIFICATION,//  Use LinkedHashMap to provide deterministic order 
Hive,WITHOUT_CLASSIFICATION,//  This intentionally does not include interval types. 
Hive,WITHOUT_CLASSIFICATION,//  Test an invalid case without version 
Hive,WITHOUT_CLASSIFICATION,//  Re-escape any backtick (`) characters in the identifier. 
Hive,WITHOUT_CLASSIFICATION,//  Merge the names from the imposed schema into the types   from the derived schema. 
Hive,WITHOUT_CLASSIFICATION,//  Start after group keys. 
Hive,WITHOUT_CLASSIFICATION,//  Defining a bunch of configs here instead of in HiveConf. These are experimental and mainly   for use when retry handling is fixed in Yarn/Hadoop 
Hive,WITHOUT_CLASSIFICATION,//  We couldn't do SQL filter pushdown. Get names via normal means. 
Hive,WITHOUT_CLASSIFICATION,//  copy whole value for strings 
Hive,WITHOUT_CLASSIFICATION,//  STATE 
Hive,WITHOUT_CLASSIFICATION,//  Drop all partitions from "tbl1" "tbl2" "tbl3" and add 2 new partitions to "tbl4" and "tbl5" 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getDate(int)    */
Hive,WITHOUT_CLASSIFICATION,//  Test boolean-valued (non-filter) IN expression for strings 
Hive,WITHOUT_CLASSIFICATION,//  TimestampColumnArithmeticDateColumn.txt   TimestampScalarArithmeticDateColumn.txt   TimestampColumnArithmeticDateScalar.txt 
Hive,WITHOUT_CLASSIFICATION,//  Default to driver's txn manager if no txn manager specified 
Hive,WITHOUT_CLASSIFICATION,//  its a ddl query. 
Hive,WITHOUT_CLASSIFICATION,//  ~ Static fields/initializers --------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,// longer term we should always have a txn id and then we won't need to track locks here at all 
Hive,WITHOUT_CLASSIFICATION,//  new entry in the hash table 
Hive,WITHOUT_CLASSIFICATION,//  The Routing appender which manages underlying appenders 
Hive,WITHOUT_CLASSIFICATION,//  Give preference to TBLPROPERTIES over SERDEPROPERTIES   (really we should only use TBLPROPERTIES so this is just   for backwards compatibility with the original specs). 
Hive,WITHOUT_CLASSIFICATION,/*    * Flush a partially full deserializerBatch.   * @return Return true if the operator tree is not done yet.    */
Hive,WITHOUT_CLASSIFICATION,//  Since the log length of the sql operation may vary during HIVE dev calculate a proper maxRows. 
Hive,WITHOUT_CLASSIFICATION,// use inspector to get a byte[] out of LazyBinary 
Hive,WITHOUT_CLASSIFICATION,//  Add the request interceptor to the client builder 
Hive,WITHOUT_CLASSIFICATION,//  Explode 
Hive,WITHOUT_CLASSIFICATION,//  Add alias table name and partitions to hadoop conf so that their   children will inherit these 
Hive,WITHOUT_CLASSIFICATION,//  overflow batch. 
Hive,WITHOUT_CLASSIFICATION,/*  * Specialized class for doing a vectorized map join that is an left semi join on Multi-Key * using hash set.  */
Hive,WITHOUT_CLASSIFICATION,/*      * from the prunedCols list filter out columns that refer to WindowFns or WindowExprs     * the returned list is set as the prunedList needed by the PTFOp.      */
Hive,WITHOUT_CLASSIFICATION,//  If the expired nodes did not result in cache being cleanUntil% in size 
Hive,WITHOUT_CLASSIFICATION,//  We go through these hijinxes because java considers System.getEnv   to be read-only and offers no way to set an env var from within   a process only for processes that we sub-spawn. 
Hive,WITHOUT_CLASSIFICATION,//  Monday 26th August 1985 12:00:00 AM 
Hive,WITHOUT_CLASSIFICATION,//  If any aggregate functions do not support splitting bail out 
Hive,WITHOUT_CLASSIFICATION,//  3. We build the new predicate and return it 
Hive,WITHOUT_CLASSIFICATION,//  Float family timestamp are handled via descriptor based lookup int family needs 
Hive,WITHOUT_CLASSIFICATION,// directory is empty or doesn't have any that could have been produced by load data 
Hive,WITHOUT_CLASSIFICATION,//  QL execution stuff 
Hive,WITHOUT_CLASSIFICATION,// 1 partitions updated (and no other entries) 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#execute(java.lang.String int)    */
Hive,WITHOUT_CLASSIFICATION,//  TODO: relying everywhere on the magical constants and columns being together means ACID         columns are going to be super hard to change in a backward compat manner. I can         foresee someone cursing while refactoring all the magic for prefix schema changes.   Exclude the row column. 
Hive,WITHOUT_CLASSIFICATION,//  We expect that colId will be the same for all (or many) SDs. 
Hive,WITHOUT_CLASSIFICATION,//  Concurrent increase and revocation increase fails - no revocation is needed. 
Hive,WITHOUT_CLASSIFICATION,/*    * Represents a UDAF invocation in the context of a Window Frame. As   * explained above sometimes UDAFs will be handled as Window Functions   * even w/o an explicit Window specification. This is to support Queries   * that have no Group By clause. A Window Function invocation captures:   * - the ASTNode that represents this invocation   * - its name   * - whether it is star/distinct invocation.   * - its alias   * - and an optional Window specification    */
Hive,WITHOUT_CLASSIFICATION,//  Make sure we capture the same metrics as Hadoop2 metrics system via annotations. 
Hive,WITHOUT_CLASSIFICATION,//  Relies on the fact that cache does not actually store these. 
Hive,WITHOUT_CLASSIFICATION,// points at the last txn which we don't want to heartbeat 
Hive,WITHOUT_CLASSIFICATION,//  Only trigger major compaction for ttp2 (delta.pct.threshold=0.5) because of the newly inserted row (actual pct: 0.66) 
Hive,WITHOUT_CLASSIFICATION,//  Tamil Om U+0BD0 (3 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  Create temporary scratch dir 
Hive,WITHOUT_CLASSIFICATION,//  All of this is completely bogus and mostly captures the following function:   f(output) = I-eyeballed-the(output) == they-look-ok.   It's pretty much a golden file... 
Hive,WITHOUT_CLASSIFICATION,//  Next column has a similar name as previous but different casing.   This is allowed in Druid but it should fail in Hive. 
Hive,WITHOUT_CLASSIFICATION,//  Need to be final to pass it to an inner class 
Hive,WITHOUT_CLASSIFICATION,//  BlockingDeque methods 
Hive,WITHOUT_CLASSIFICATION,//  flush if necessary 
Hive,WITHOUT_CLASSIFICATION,//  No support. 
Hive,WITHOUT_CLASSIFICATION,//  Read database table via CachedStore 
Hive,WITHOUT_CLASSIFICATION,//  Update the aggs 
Hive,WITHOUT_CLASSIFICATION,//  flag to indicate if there is no data in parquet data page 
Hive,WITHOUT_CLASSIFICATION,//  Create a standard copy of the object. 
Hive,WITHOUT_CLASSIFICATION,/*    *  Pre-allocated members for storing information on single- and multi-valued-small-table matches.   *   *  ~ValueCounts   *                Number of (empty) small table values.   *  ~AllMatchIndices   *                (Logical) indices into allMatchs to the first row of a match of a   *                possible series of duplicate keys.   *  ~DuplicateCounts   *                The duplicate count for each matched key.   *    */
Hive,WITHOUT_CLASSIFICATION,//  FUNCTION_NAME 
Hive,WITHOUT_CLASSIFICATION,// next command should produce an error 
Hive,WITHOUT_CLASSIFICATION,//     to merge it with its right child 
Hive,WITHOUT_CLASSIFICATION,//  0 - Primary Key   1 - PK-FK relationship   2 - Unique Constraint   3 - Not Null Constraint 
Hive,WITHOUT_CLASSIFICATION,/*        * Multiple values.        */
Hive,WITHOUT_CLASSIFICATION,/*    * A PTF Input represents the input to a PTF Function. An Input can be a Hive SubQuery or Table   * or another PTF Function. An Input instance captures the ASTNode that this instance was created from.    */
Hive,WITHOUT_CLASSIFICATION,//  This method can be replaced with Files.copy(source target REPLACE_EXISTING)   once Hive uses JAVA 7. 
Hive,WITHOUT_CLASSIFICATION,//  Store text of the ORIGINAL QUERY 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.ICLIService#getFunctions(org.apache.hive.service.cli.SessionHandle)    */
Hive,WITHOUT_CLASSIFICATION,//  Otherwise return null 
Hive,WITHOUT_CLASSIFICATION,//  This is not called when building HashTable; we don't expect it to be called ever. 
Hive,WITHOUT_CLASSIFICATION,//  ** Methods that need a data object ** 
Hive,WITHOUT_CLASSIFICATION,//  At the end of this function the stream should be pointing to the last token that   corresponds to the value being skipped. This way the next call to nextToken   will advance it to the next field name. 
Hive,WITHOUT_CLASSIFICATION,//  3 8 
Hive,WITHOUT_CLASSIFICATION,//  For LOAD you only add it if it does exist as you might be loading an outdated MV 
Hive,WITHOUT_CLASSIFICATION,// check behavior while change the order of columns 
Hive,WITHOUT_CLASSIFICATION,//  ALTER MV ... REBUILD 
Hive,WITHOUT_CLASSIFICATION,//  if it is a corVar change it to be input ref. 
Hive,WITHOUT_CLASSIFICATION,//  throw a HiveException for non-rcfile. 
Hive,WITHOUT_CLASSIFICATION,//  The SIMD optimized form of "a != b" is "((a - b) ^ (b - a)) >>> 63" 
Hive,WITHOUT_CLASSIFICATION,//  run sql operations 
Hive,WITHOUT_CLASSIFICATION,//  Revalidated the new version after upgrade 
Hive,WITHOUT_CLASSIFICATION,//  sparse-dense merge 
Hive,WITHOUT_CLASSIFICATION,//  It's possible that the Job doesn't have the token in its credentials. In this case unwrapAuthenticatinoToken 
Hive,WITHOUT_CLASSIFICATION,//  Either we've found multiple big table branches or the current branch cannot   be a big table branch. Disable mapjoin for these cases. 
Hive,WITHOUT_CLASSIFICATION,//  cols 
Hive,WITHOUT_CLASSIFICATION,//  We also need to update the expr so that the index query can be generated. 
Hive,WITHOUT_CLASSIFICATION,// unique to the load func and input file name (table in our case). 
Hive,WITHOUT_CLASSIFICATION,//  The tasks from now on are more important than the candidate. 
Hive,WITHOUT_CLASSIFICATION,//  Defining partition names in unsorted order 
Hive,WITHOUT_CLASSIFICATION,//  Format a single cluster sort statement 
Hive,WITHOUT_CLASSIFICATION,//  try to combine next level works recursively. 
Hive,WITHOUT_CLASSIFICATION,//  Set the start and stop rows only if asked to 
Hive,WITHOUT_CLASSIFICATION,//  We could just remove here and handle the missing tail during read but that can be 
Hive,WITHOUT_CLASSIFICATION,//  MAPPING 
Hive,WITHOUT_CLASSIFICATION,//  LOG.info("Creating list record: copying " + lengthsLength + " lrPtrOffset " + lrPtrOffset); 
Hive,WITHOUT_CLASSIFICATION,/*    * Recursively extract fields from ExprNodeDesc. Deeply nested structs can have multiple levels of   * fields in them    */
Hive,WITHOUT_CLASSIFICATION,//  TRUNCATE_PARTITION EVENT on partitioned table 
Hive,WITHOUT_CLASSIFICATION,//  not setting ranges scans the entire table 
Hive,WITHOUT_CLASSIFICATION,//  Capture stdout and stderr 
Hive,WITHOUT_CLASSIFICATION,//  add to destination pool 
Hive,WITHOUT_CLASSIFICATION,//  Get a list of indexes for which the columns in the schema are the same 
Hive,WITHOUT_CLASSIFICATION,//  Multiple parents - find the right one based on the table alias in the parentExpr 
Hive,WITHOUT_CLASSIFICATION,//  Check that an exception from getMetaData() is reported correctly 
Hive,WITHOUT_CLASSIFICATION,//  class PartitionIterator; 
Hive,WITHOUT_CLASSIFICATION,// r = runStatementOnDriver("explain formatted " + s); 
Hive,WITHOUT_CLASSIFICATION,//  If there is only 1 table ALIAS return it 
Hive,WITHOUT_CLASSIFICATION,// if this column is coming from right input only then we update num nulls 
Hive,WITHOUT_CLASSIFICATION,//  not qualify this optimization 
Hive,WITHOUT_CLASSIFICATION,//  check for required fields 
Hive,WITHOUT_CLASSIFICATION,//  Wrap the transport exception in an RTE since UGI.doAs() then goes   and unwraps this for us out of the doAs block. We then unwrap one   more time in our catch clause to get back the TTE. (ugh) 
Hive,WITHOUT_CLASSIFICATION,//  Thread-unsafe position used at write time. 
Hive,WITHOUT_CLASSIFICATION,//  higher compute cost. 
Hive,WITHOUT_CLASSIFICATION,//  No nulls case 
Hive,WITHOUT_CLASSIFICATION,//  This query will give a runtime error 
Hive,WITHOUT_CLASSIFICATION,//  Drop a primary key 
Hive,WITHOUT_CLASSIFICATION,//  GET_PROGRESS_UPDATE 
Hive,WITHOUT_CLASSIFICATION,//  get aggregation evaluators 
Hive,WITHOUT_CLASSIFICATION,//  Remove a column 
Hive,WITHOUT_CLASSIFICATION,//  set the local work so all the operator can get this context 
Hive,WITHOUT_CLASSIFICATION,//  SECRET 
Hive,WITHOUT_CLASSIFICATION,//  create dispatcher and graph walker 
Hive,WITHOUT_CLASSIFICATION,/*  mergeSum  */
Hive,WITHOUT_CLASSIFICATION,//  Note fs.delete will fail on Windows. The reason is in OutputCommitter   Hadoop is still writing to _logs/history. On Linux OS don't care file is still   open and remove the directory anyway but on Windows OS refuse to remove a   directory containing open files. So on Windows we will leave output directory   behind when job fail. User needs to remove the output directory manually 
Hive,WITHOUT_CLASSIFICATION,//  I-(1/2)            D-(1/2)    I-(1/3)     U-(1/3)     D-(2/2)     I-(1/1) - new part 
Hive,WITHOUT_CLASSIFICATION,//  Generate ReduceSinkOperator 
Hive,WITHOUT_CLASSIFICATION,//  Finally check if it is serializable 
Hive,WITHOUT_CLASSIFICATION,//  hadoop-1 gets 3 and hadoop-2 gets 0. *sigh* 
Hive,WITHOUT_CLASSIFICATION,//  SCHEMA 
Hive,WITHOUT_CLASSIFICATION,//  maximum table size 
Hive,WITHOUT_CLASSIFICATION,//  Run initiator to execute CompactionTxnHandler.cleanEmptyAbortedTxns() 
Hive,WITHOUT_CLASSIFICATION,//  Helper methods 
Hive,WITHOUT_CLASSIFICATION,//  If the function is being added under a database 'namespace' then add an entity representing   the database (only applicable to permanent/metastore functions).   We also add a second entity representing the function name.   The authorization api implementation can decide which entities it wants to use to   authorize the create/drop function call. 
Hive,WITHOUT_CLASSIFICATION,//  If rightInputRel is a filter and contains correlated   reference make sure the correlated keys in the filter   condition forms a unique key of the RHS. 
Hive,WITHOUT_CLASSIFICATION,//  Round up. 
Hive,WITHOUT_CLASSIFICATION,// now recompute state since we've done minor compactions and have different 'best' set of deltas 
Hive,WITHOUT_CLASSIFICATION,//  struct<map<k:vk:v>_map<k:vk:v>>> 
Hive,WITHOUT_CLASSIFICATION,//  Given these 2 lines we don't need to double check later. 
Hive,WITHOUT_CLASSIFICATION,/*      * load partition that doesn't exist in T     * There is some parallelism going on if you load more than 1 partition which I don't     * understand. In testImportPartitionedCreate2() that's reasonable since each partition is     * loaded in parallel.  Why it happens here is beyond me.     * The file name changes from run to run between 000000_0 and 000001_0 and 000002_0     * The data is correct but this causes ROW__ID.bucketId/file names to change      */
Hive,WITHOUT_CLASSIFICATION,//  Copy the group key to output batch now.  We'll copy in the aggregates at the end of the group. 
Hive,WITHOUT_CLASSIFICATION,//  START 
Hive,WITHOUT_CLASSIFICATION,//  This does the testing using a remote metastore as that finds more issues in thrift 
Hive,WITHOUT_CLASSIFICATION,//  This string constant is used to indicate to AlterHandler that 
Hive,WITHOUT_CLASSIFICATION,//  1.1 Build col details used by scan 
Hive,WITHOUT_CLASSIFICATION,//  view column authorization again even if it is triggered again. 
Hive,WITHOUT_CLASSIFICATION,//  Literal tinyint. 
Hive,WITHOUT_CLASSIFICATION,//  Timer is shared across entire factory and must be released separately 
Hive,WITHOUT_CLASSIFICATION,//  char columns should have correct display size/precision 
Hive,WITHOUT_CLASSIFICATION,//  do rest of tests on db we just picked up above. 
Hive,WITHOUT_CLASSIFICATION,// ensure there is partition dir 
Hive,WITHOUT_CLASSIFICATION,//  in case of replication idempotent is taken care by getTargetTxnId 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#getClientInfo()    */
Hive,WITHOUT_CLASSIFICATION,//  Test that existing exclusive partition with new shared_write coalesces to 
Hive,WITHOUT_CLASSIFICATION,//  outer join cannot be performed on a table which is being cached 
Hive,WITHOUT_CLASSIFICATION,//  If this Project has correlated reference create value generator 
Hive,WITHOUT_CLASSIFICATION,//  Return the type string of the first argument (argument 0). 
Hive,WITHOUT_CLASSIFICATION,//  this is SEL(*) cols + UDTF cols 
Hive,WITHOUT_CLASSIFICATION,//  Path being passed to us is a table dump location. We go ahead and load it in as needed.   If tblName is null then we default to the table name specified in _metadata which is good.   or are both specified in which case that's what we are intended to create the new table as. 
Hive,WITHOUT_CLASSIFICATION,//  Test LazyHCatRecord init and read 
Hive,WITHOUT_CLASSIFICATION,/*    * Map    */
Hive,WITHOUT_CLASSIFICATION,//  we need to read bucket number which is the last column in value (after partition columns) 
Hive,WITHOUT_CLASSIFICATION,// Codahale artifacts are lazily-created. 
Hive,WITHOUT_CLASSIFICATION,//  Must be consistent with uncompressed stream seek in ORC. See call site comments. 
Hive,WITHOUT_CLASSIFICATION,//  In the case of altering a table for its partitions we don't need to lock the table   itself just the partitions.  But the table will have a ReadEntity.  So mark that   ReadEntity as no lock. 
Hive,WITHOUT_CLASSIFICATION,//  get exception in resolving partition   it could be DESCRIBE table key   return null   continue processing for DESCRIBE table key 
Hive,WITHOUT_CLASSIFICATION,//  We expect the DAGs to not be super large so store full dependency set for each vertex to 
Hive,WITHOUT_CLASSIFICATION,//  make 5 stripes with 2 rows each 
Hive,WITHOUT_CLASSIFICATION,//  3. Add UDAF args deduped to reduce values 
Hive,WITHOUT_CLASSIFICATION,//  not comparing hashCtx - irrelevant 
Hive,WITHOUT_CLASSIFICATION,//  0 implies Netty default of 2 * number of available processors 
Hive,WITHOUT_CLASSIFICATION,//  No boolean value match for extended 1 char field. 
Hive,WITHOUT_CLASSIFICATION,//  Test when two jars are added with shared dependencies and one jar is deleted the shared dependencies should not be deleted 
Hive,WITHOUT_CLASSIFICATION,//  Caller must remember small value length. 
Hive,WITHOUT_CLASSIFICATION,//  Must have one of those at this point. 
Hive,WITHOUT_CLASSIFICATION,//  Write a large value. This should use a different byte buffer 
Hive,WITHOUT_CLASSIFICATION,//  no rows will be filtered 
Hive,WITHOUT_CLASSIFICATION,//  add parents for the newly created operator 
Hive,WITHOUT_CLASSIFICATION,/*      * Called when the value in the partition has changed. Update the currentRank      */
Hive,WITHOUT_CLASSIFICATION,//  If we get a UnionOperator right now we only handle it when   we can find correlated ReduceSinkOperators from all inputs. 
Hive,WITHOUT_CLASSIFICATION,//  For eg: select count(1) from T where t.ds = .... 
Hive,WITHOUT_CLASSIFICATION,//  2 original files 2 delta directories 1 delete_delta directory and 2 base directories 
Hive,WITHOUT_CLASSIFICATION,//  Get the partition object if it already exists 
Hive,WITHOUT_CLASSIFICATION,//  we errored 
Hive,WITHOUT_CLASSIFICATION,//  This weirdness of setting it in our conf and then reading back does two things.   One it handles the conversion of the TimeUnit.  Two it keeps the value around for   later in case we need it again. 
Hive,WITHOUT_CLASSIFICATION,//  Test that read can acquire after write 
Hive,WITHOUT_CLASSIFICATION,//  initialize pathToAliases 
Hive,WITHOUT_CLASSIFICATION,//  3. For uncompressed case we need some special processing before read. 
Hive,WITHOUT_CLASSIFICATION,//  id is appended since there could be multiple scalar subqueries and FILTER 
Hive,WITHOUT_CLASSIFICATION,//  the positions in rsColInfoLst are as follows   --grpkey----distkey----values--   but distUDAF may be before/after some non-distUDAF   i.e. their positions can be mixed.   so for all UDAF we first check to see if it is groupby key if not is it distinct key 
Hive,WITHOUT_CLASSIFICATION,//  main memory HashMap 
Hive,WITHOUT_CLASSIFICATION,/*      * Basic algorithm:     *     * 1. Determine if rounding part is non-zero for rounding.     * 2. Scale away fractional digits if present.     * 3. If rounding clear integer rounding portion and add 1.     *      */
Hive,WITHOUT_CLASSIFICATION,//  VERSION 
Hive,WITHOUT_CLASSIFICATION,//  scale/signum 
Hive,WITHOUT_CLASSIFICATION,//  init aggregationClasses 
Hive,WITHOUT_CLASSIFICATION,/*  Whether to skipPruning - depends on the payload from an event which may signal skip - if the event payload is too large  */
Hive,WITHOUT_CLASSIFICATION,//  This won't have a decimal part because the HAS_DECIMAL_MASK bit is not set. 
Hive,WITHOUT_CLASSIFICATION,//  COMBINING ACUTE ACENT U+0301 (2 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  may not be true with correlation operators (mux-demux) 
Hive,WITHOUT_CLASSIFICATION,//  get the function documentation 
Hive,WITHOUT_CLASSIFICATION,//  foo <= 'm' 
Hive,WITHOUT_CLASSIFICATION,//  a bucket centered at 'v' already exists so this must be checked in the next step. 
Hive,WITHOUT_CLASSIFICATION,//  Verify that there is now only 1 new directory: base_xxxxxxx and the rest have have been cleaned. 
Hive,WITHOUT_CLASSIFICATION,//  to use this via command line arg "decimal(7_2)"   to use this via command line arg "decimal(38_18)" 
Hive,WITHOUT_CLASSIFICATION,//  if row count exists or stats aren't to be estimated return 
Hive,WITHOUT_CLASSIFICATION,//  remember for additional processing later 
Hive,WITHOUT_CLASSIFICATION,//  Timestamp values are PST (timezone for tests is set to PST by default) 
Hive,WITHOUT_CLASSIFICATION,//  Delete the data in the database 
Hive,WITHOUT_CLASSIFICATION,//  9. Handle select distinct as GBY if there exist windowing functions 
Hive,WITHOUT_CLASSIFICATION,//  no means no 
Hive,WITHOUT_CLASSIFICATION,//  Now we delete the rest of tables 
Hive,WITHOUT_CLASSIFICATION,//  If table is missing then partitions are also would've been dropped. Just no-op. 
Hive,WITHOUT_CLASSIFICATION,/*    * Captures how the Input to a PTF Function should be partitioned and   * ordered. Refers to a /Partition/ and /Order/ instance.    */
Hive,WITHOUT_CLASSIFICATION,//  need to check paths and partition desc for MapWorks 
Hive,WITHOUT_CLASSIFICATION,// If we return false it is just a noop 
Hive,WITHOUT_CLASSIFICATION,/*  All must be selected otherwise size would be zero.         * Repeating property will not change.          */
Hive,WITHOUT_CLASSIFICATION,//  We have some disk buffers... see if we have entire part etc. 
Hive,WITHOUT_CLASSIFICATION,//  will be invoked anyway in TezTask. Doing it early to initialize triggers for non-pool tez session. 
Hive,WITHOUT_CLASSIFICATION,//  expecting this exception 
Hive,WITHOUT_CLASSIFICATION,//  get the number of columns in the user's rows 
Hive,WITHOUT_CLASSIFICATION,//  Verify that a task kill went out for all nodes running on the specified host. 
Hive,WITHOUT_CLASSIFICATION,/*      * 7. Order Use in Order By from the block above. RelNode has no pointer to     * parent hence we need to go top down; but OB at each block really belong     * to its src/from. Hence the need to pass in sort for each block from     * its parent.     * 8. Limit      */
Hive,WITHOUT_CLASSIFICATION,//  RawLocalFileSystem seems not able to get the right permissions for a local file it   always returns hdfs default permission (00666). So we can not overwrite a directory   by deleting and recreating the directory and restoring its permissions. We should   delete all its files and subdirectories instead. 
Hive,WITHOUT_CLASSIFICATION,//  This is an SMB join. 
Hive,WITHOUT_CLASSIFICATION,//  List<Coord>   Coord holds two doubles 
Hive,WITHOUT_CLASSIFICATION,//  optional string user = 7; 
Hive,WITHOUT_CLASSIFICATION,//  NumberFormatException value out of range   other unknown cases 
Hive,WITHOUT_CLASSIFICATION,//  Dummy create table command to mark proper last repl ID after dump 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * In order to update a Decimal128 fast (w/o allocation) we need to expose access to the   * internal storage bytes and scale.   * @return    */
Hive,WITHOUT_CLASSIFICATION,//  Add the UDTFOperator to the operator DAG 
Hive,WITHOUT_CLASSIFICATION,/*        * Validate input formats of all the partitions can be vectorized.        */
Hive,WITHOUT_CLASSIFICATION,//  this may happen if we were able to establish connection once but its no longer valid 
Hive,WITHOUT_CLASSIFICATION,//  If ckpt property not set or empty means bootstrap is not run on this object. 
Hive,WITHOUT_CLASSIFICATION,//  It also set up the connection between each parent work and child work. 
Hive,WITHOUT_CLASSIFICATION,//  alter table add column: change the metadata 
Hive,WITHOUT_CLASSIFICATION,//  Add another partition without stats. 
Hive,WITHOUT_CLASSIFICATION,//  figure out if a table is Acid or not. 
Hive,WITHOUT_CLASSIFICATION,//  close ResultSet ignore exception if any 
Hive,WITHOUT_CLASSIFICATION,//  set alias to work and put into smallTableAliasList 
Hive,WITHOUT_CLASSIFICATION,// Validate that some progress is being made 
Hive,WITHOUT_CLASSIFICATION,//  this means there is no existing partition 
Hive,WITHOUT_CLASSIFICATION,//  if skip authorization skip checking;   if it is inside a view skip checking;   if authorization flag is not enabled skip checking. 
Hive,WITHOUT_CLASSIFICATION,//  Round with digits 
Hive,WITHOUT_CLASSIFICATION,//  now set the output for the history 
Hive,WITHOUT_CLASSIFICATION,//  wait until rj.isComplete 
Hive,WITHOUT_CLASSIFICATION,//  of newAggRel 
Hive,WITHOUT_CLASSIFICATION,//  Open the session if it is closed. 
Hive,WITHOUT_CLASSIFICATION,//  These errors happen if the JNI lib is not available for your platform. 
Hive,WITHOUT_CLASSIFICATION,//  Now add hivemetastore-site.xml.  Again we add this before our own config files so that the 
Hive,WITHOUT_CLASSIFICATION,//  We need to carry the insideView information from calcite into the ast. 
Hive,WITHOUT_CLASSIFICATION,//  Prefix for separate row keys 
Hive,WITHOUT_CLASSIFICATION,//  The children after not might need a cast. Get common types for the two comparisons.   Casting for 'between' is handled here as a special case because the first child is for NOT and doesn't need 
Hive,WITHOUT_CLASSIFICATION,//  Check for part of log message as well as part of progress information 
Hive,WITHOUT_CLASSIFICATION,// The following code is for mapjoin 
Hive,WITHOUT_CLASSIFICATION,//  null error message here means the user has access. 
Hive,WITHOUT_CLASSIFICATION,/*    * INTERVAL_YEAR_MONTH.    */
Hive,WITHOUT_CLASSIFICATION,//  disable resource monitoring although it should be off by default 
Hive,WITHOUT_CLASSIFICATION,// add the number of partitions given by the current batchsize 
Hive,WITHOUT_CLASSIFICATION,//  rightInputRel has this shape:           Filter (references corvar)           FilterInputRel 
Hive,WITHOUT_CLASSIFICATION,//  Configure web application contexts for the web server 
Hive,WITHOUT_CLASSIFICATION,//  counters for task execution side 
Hive,WITHOUT_CLASSIFICATION,//  lower case null is used within json objects 
Hive,WITHOUT_CLASSIFICATION,//  nulls are considered not matching for equality comparison   add the position of the most recently inserted key 
Hive,WITHOUT_CLASSIFICATION,/*      * All ROW__IDs are unique on read after conversion to acid     * ROW__IDs are exactly the same before and after compaction     * Also check the file name (only) after compaction for completeness      */
Hive,WITHOUT_CLASSIFICATION,//  Base type name to PrimitiveTypeEntry map. 
Hive,WITHOUT_CLASSIFICATION,//  this means the key didn't exist so the insertion point is negative minus 1. 
Hive,WITHOUT_CLASSIFICATION,//  if the aggregation buffer is not estimable then get all the   declared fields and compute the sizes from field types 
Hive,WITHOUT_CLASSIFICATION,//  3. Allocate the buffers prepare cache keys.   At this point we have read all the CBs we need to read. cacheBuffers contains some cache   data and some unallocated membufs for decompression. toDecompress contains all the work we   need to do and each item points to one of the membufs in cacheBuffers as target. The iter 
Hive,WITHOUT_CLASSIFICATION,//  Header row + 2 transactions = 3 rows 
Hive,WITHOUT_CLASSIFICATION,//  This key will be put in the conf file when planning an acid operation 
Hive,WITHOUT_CLASSIFICATION,//  for fast check of possible existence of RS (will be checked again in SimpleFetchOptimizer) 
Hive,WITHOUT_CLASSIFICATION,//  SettableStructObjectInspector 
Hive,WITHOUT_CLASSIFICATION,//  Must support offsets to be able to split. 
Hive,WITHOUT_CLASSIFICATION,//  Only applicable to n-way Hybrid Grace Hash Join 
Hive,WITHOUT_CLASSIFICATION,//  Despite having a fixed schema from Hive we have sparse columns in Accumulo 
Hive,WITHOUT_CLASSIFICATION,//  Lookup type infos for our input types and expected return type 
Hive,WITHOUT_CLASSIFICATION,//  Make one have a non-standard location 
Hive,WITHOUT_CLASSIFICATION,//  In case of any other exception retry. If this also fails report original error and exit. 
Hive,WITHOUT_CLASSIFICATION,//  Set the FS perms to read-only access and create ACL entries allowing write access. 
Hive,WITHOUT_CLASSIFICATION,//  We are skipping the CDS table here as it seems to be totally useless. 
Hive,WITHOUT_CLASSIFICATION,//  long NOT BETWEEN 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getTime(int)    */
Hive,WITHOUT_CLASSIFICATION,//  check that the columns referenced in rightJoinKeys form an 
Hive,WITHOUT_CLASSIFICATION,/*      *  we analyze each side and let the     *    left and right exprs in the Conjunct object.     *     * @return Conjunct  contains details on the left and right side of the conjunct expression.      */
Hive,WITHOUT_CLASSIFICATION,// Log with double base 
Hive,WITHOUT_CLASSIFICATION,//  currently this is sole field affecting mergee task 
Hive,WITHOUT_CLASSIFICATION,/*  Unit test for GitHub Howl issue #3  */
Hive,WITHOUT_CLASSIFICATION,//  Get all valid partition paths and existing partitions for them (if any) 
Hive,WITHOUT_CLASSIFICATION,//  To the consumer of joinOutputProjRel nullIndicator is located 
Hive,WITHOUT_CLASSIFICATION,//  So far we've read the one's complement   add 1 to turn it into two's complement 
Hive,WITHOUT_CLASSIFICATION,//  If the output has some extra fields set them to NULL in convert(). 
Hive,WITHOUT_CLASSIFICATION,//  If input contains header skip header. 
Hive,WITHOUT_CLASSIFICATION,//  selectObjs hold the row from the select op until receiving a row from 
Hive,WITHOUT_CLASSIFICATION,//  create task to aliases mapping and alias to input file mapping for resolver 
Hive,WITHOUT_CLASSIFICATION,//  If not equal convert all to double and compare 
Hive,WITHOUT_CLASSIFICATION,//  Get the column names of the aggregations for reduce sink 
Hive,WITHOUT_CLASSIFICATION,//  for auto reduce parallelism - minimum reducers requested 
Hive,WITHOUT_CLASSIFICATION,// this will create delta_20_24 and delete_delta_20_24. See MockRawReader 
Hive,WITHOUT_CLASSIFICATION,//  Provide a facility to set current timestamp during tests 
Hive,WITHOUT_CLASSIFICATION,//  Try to get as consistent view as we can; make copy of the headers. 
Hive,WITHOUT_CLASSIFICATION,//  recreate the partition if it existed before 
Hive,WITHOUT_CLASSIFICATION,//     "char" 
Hive,WITHOUT_CLASSIFICATION,//  The same applies to files added with "addFile". They're only guaranteed to be available 
Hive,WITHOUT_CLASSIFICATION,//  even though the stats were estimated we need to warn user that   stats are not available 
Hive,WITHOUT_CLASSIFICATION,//  No encoding => must have no data. 
Hive,WITHOUT_CLASSIFICATION,//  With Data 
Hive,WITHOUT_CLASSIFICATION,//  Add in fields used in the condition. 
Hive,WITHOUT_CLASSIFICATION,//  describe the table - populate the output stream 
Hive,WITHOUT_CLASSIFICATION,//  Recalculate the HDFS stats if auto gather stats is set 
Hive,WITHOUT_CLASSIFICATION,//  the join key. 
Hive,WITHOUT_CLASSIFICATION,//  skip rowid 
Hive,WITHOUT_CLASSIFICATION,//  all of the integer types   float   double   string char varchar 
Hive,WITHOUT_CLASSIFICATION,//  in order to make the dependencies accessible. 
Hive,WITHOUT_CLASSIFICATION,//  gen would have prevented it) 
Hive,WITHOUT_CLASSIFICATION,//  nothing to do here. 
Hive,WITHOUT_CLASSIFICATION,//  Conversion of Avro primitive types to Hive primitive types   Avro             Hive   Null   boolean          boolean    check   int              int        check   long             bigint     check   float            double     check   double           double     check   bytes            binary     check   fixed            binary     check   string           string     check                    tinyint                    smallint 
Hive,WITHOUT_CLASSIFICATION,//  constant means no filter ignore it when it is null 
Hive,WITHOUT_CLASSIFICATION,//  we might have to connect parent work with this work later. 
Hive,WITHOUT_CLASSIFICATION,//  true   true   true   false   false   false   false   true 
Hive,WITHOUT_CLASSIFICATION,//  Create a file with all the job properties to be read by spark-submit. Change the   file's permissions so that only the owner can read it. This avoid having the 
Hive,WITHOUT_CLASSIFICATION,/*    * Get the list of tracking jobs.  These can be used to determine which jobs have   * expired.    */
Hive,WITHOUT_CLASSIFICATION,//  implement RelOptRule   We override the rule in order to do union all branch elimination 
Hive,WITHOUT_CLASSIFICATION,//  Create parameter converters 
Hive,WITHOUT_CLASSIFICATION,//  we check if there is only one immediate child task and it is stats task 
Hive,WITHOUT_CLASSIFICATION,//  UK_NAME 
Hive,WITHOUT_CLASSIFICATION,//  use the multi-char delimiter to parse the lazy struct 
Hive,WITHOUT_CLASSIFICATION,//  Here we recursively check:   1. whether there are exact one LIMIT in the query   2. whether there is no aggregation group-by distinct sort by      distributed by or table sampling in any of the sub-query.   The query only qualifies if both conditions are satisfied.     Example qualified queries:      CREATE TABLE ... AS SELECT col1 col2 FROM tbl LIMIT ..      INSERT OVERWRITE TABLE ... SELECT col1 hash(col2) split(col1)                                 FROM ... LIMIT...      SELECT * FROM (SELECT col1 as col2 (SELECT * FROM ...) t1 LIMIT ...) t2);   
Hive,WITHOUT_CLASSIFICATION,//  check semantic conditions 
Hive,WITHOUT_CLASSIFICATION,//  tasks including all of dependencies. 
Hive,WITHOUT_CLASSIFICATION,//  ptf node form is: ^(TOK_PTBLFUNCTION $name $alias?   partitionTableFunctionSource partitioningSpec? expression*)   ptf node guaranteed to have an alias here 
Hive,WITHOUT_CLASSIFICATION,//  get bigKeysDirToTaskMap 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setTimestamp(int java.sql.Timestamp)    */
Hive,WITHOUT_CLASSIFICATION,//  it has already been initialized using hiveConf. 
Hive,WITHOUT_CLASSIFICATION,/*    * Gets status of job form job id. If maximum concurrent job status requests are configured   * then status request will be executed on a thread from thread pool. If job status request   * time out is configured then request execution thread will be interrupted if thread   * times out and does no action.    */
Hive,WITHOUT_CLASSIFICATION,// from Load Data into acid converted table 
Hive,WITHOUT_CLASSIFICATION,//  We thought we had the entire part to cache but we don't; convert start to   non-cached. Since we are at the first gap the previous stuff must be contiguous. 
Hive,WITHOUT_CLASSIFICATION,//  MY_ENUM_STRING_MAP 
Hive,WITHOUT_CLASSIFICATION,// clean tables in default db 
Hive,WITHOUT_CLASSIFICATION,//  always send secure cookies for SSL mode 
Hive,WITHOUT_CLASSIFICATION,//  By default ArgumentCompletor is in "strict" mode meaning   a token is only auto-completed if all prior tokens   match. We don't want that since there are valid tokens 
Hive,WITHOUT_CLASSIFICATION,//  clear CurrentFunctionsInUse set to capture new set of functions 
Hive,WITHOUT_CLASSIFICATION,//  Make CHAR and VARCHAR type info parsable. 
Hive,WITHOUT_CLASSIFICATION,//  Set up context for readNextComplexField. 
Hive,WITHOUT_CLASSIFICATION,//  Return false only occurred error when execution the sql and the sql should follow the rules 
Hive,WITHOUT_CLASSIFICATION,//  For now. 
Hive,WITHOUT_CLASSIFICATION,//  create a split for the given partition 
Hive,WITHOUT_CLASSIFICATION,//  for each dynamically created DP directory construct a full partition spec   and load the partition based on that 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#isClosed()    */
Hive,WITHOUT_CLASSIFICATION,//  return value not checked due to concurrent access 
Hive,WITHOUT_CLASSIFICATION,//  output debug info 
Hive,WITHOUT_CLASSIFICATION,//  These tasks should have come from the same job. 
Hive,WITHOUT_CLASSIFICATION,//  Create a view with name already exist. Just to verify if failure flow clears the added create_table event. 
Hive,WITHOUT_CLASSIFICATION,/*    * List status jobs request. If maximum concurrent job list requests are configured then   * list request will be executed on a thread from thread pool. If job list request time out   * is configured then request execution thread will be interrupted if thread times out and   * does no action.    */
Hive,WITHOUT_CLASSIFICATION,//  For all parents (other than the big table) insert a dummy store operator 
Hive,WITHOUT_CLASSIFICATION,//  Clean up the databases 
Hive,WITHOUT_CLASSIFICATION,//  Server args 
Hive,WITHOUT_CLASSIFICATION,//  OBJECT_TYPE 
Hive,WITHOUT_CLASSIFICATION,//  EVENTS 
Hive,WITHOUT_CLASSIFICATION,//  create the project after GB. For those repeated values e.g. select 
Hive,WITHOUT_CLASSIFICATION,//  tracing down the operator tree from the table scan operator 
Hive,WITHOUT_CLASSIFICATION,// note the enum names match field names in the struct 
Hive,WITHOUT_CLASSIFICATION,//  the remaining parameters in definedRestrictedSet are starting parameter name 
Hive,WITHOUT_CLASSIFICATION,//  getManifestAttribute ("Specification-Title")   getManifestAttribute ("Implementation-Version")   getManifestAttribute ("Implementation-ReleaseDate")   getManifestAttribute ("Implementation-Vendor")   getManifestAttribute ("Implementation-License") 
Hive,WITHOUT_CLASSIFICATION,//  How many levels of ancestors to keep in the stack during dispatching 
Hive,WITHOUT_CLASSIFICATION,//  first underflow is NOT an error in ANSI SQL Numeric.   CAST(0.000000000....0001 AS DECIMAL(381)) is "0.0" without an error. 
Hive,WITHOUT_CLASSIFICATION,//  Need to run a Spark job to make sure the jar is added to the class loader. Monitoring   SparkContext#addJar() doesn't mean much we can only be sure jars have been distributed 
Hive,WITHOUT_CLASSIFICATION,//  test when third argument has nulls and repeats 
Hive,WITHOUT_CLASSIFICATION,//  If this import is being done for replication then this will be a managed table and replacements   are allowed irrespective of what the table currently looks like. So no more checks are necessary. 
Hive,WITHOUT_CLASSIFICATION,/*    * A flag to indicate whether to cancel the task when exception TimeoutException or   * InterruptedException or CancellationException raised. The default is cancel thread.    */
Hive,WITHOUT_CLASSIFICATION,//  as the index. 
Hive,WITHOUT_CLASSIFICATION,//  2. Insert MapSide RS 
Hive,WITHOUT_CLASSIFICATION,//  The test table has 500 rows so total query time should be ~ 2500ms 
Hive,WITHOUT_CLASSIFICATION,//  Retrieve the MBean server 
Hive,WITHOUT_CLASSIFICATION,//  query will try to add 64 more partitions to already existing 57 partitions but will get cancelled for violation 
Hive,WITHOUT_CLASSIFICATION,//  running all the ZK servers 
Hive,WITHOUT_CLASSIFICATION,//  Note: we could call HiveFileFormatUtils.getPartitionDescFromPathRecursively for MM tables.         The recursive call is usually needed for non-MM tables because the path management         is not strict and the code does whatever. That should not happen for MM tables.         Keep it like this for now; may need replacement if we find a valid use case. 
Hive,WITHOUT_CLASSIFICATION,// if here it means currently committing txn performed update/delete and we should check WW conflict 
Hive,WITHOUT_CLASSIFICATION,//  Read-lock. Not updating any stats at the moment. 
Hive,WITHOUT_CLASSIFICATION,// seconds 
Hive,WITHOUT_CLASSIFICATION,//  read the whole file 
Hive,WITHOUT_CLASSIFICATION,//  Publish configs for this instance as the data on the node 
Hive,WITHOUT_CLASSIFICATION,/*       * Check.5.h :: For In and Not In the SubQuery must implicitly or      * explicitly only contain one select item.       */
Hive,WITHOUT_CLASSIFICATION,//  2/31 to 2/29 
Hive,WITHOUT_CLASSIFICATION,//  This should not happen unless we are evicting a lot at once or buffers are large (so 
Hive,WITHOUT_CLASSIFICATION,//  When we introduce a discrepancy to the state we give the task to an updater unless it   was already given to one.  If the updater is already doing stuff it would handle the   changed state when it's done with whatever it's doing. The updater is not going to   give up until the discrepancies are eliminated. 
Hive,WITHOUT_CLASSIFICATION,//  Find functions which name contains _to_find_ in the dummy database 
Hive,WITHOUT_CLASSIFICATION,//  Events can start coming in the moment the InputInitializer is created. The pruner   must be setup and initialized here so that it sets up it's structures to start accepting events.   Setting it up in initialize leads to a window where events may come in before the pruner is   initialized which may cause it to drop events. 
Hive,WITHOUT_CLASSIFICATION,/*  If statistics for the column already exist use it.  */
Hive,WITHOUT_CLASSIFICATION,//  Note that we need to call getResults for simple fetch optimization.   However we need to skip all the results. 
Hive,WITHOUT_CLASSIFICATION,//  compute distance and store it in sorted map 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:UpdateFragmentResponseProto) 
Hive,WITHOUT_CLASSIFICATION,//  The sort order (ascending/descending) for each field. Set to true when descending (invert). 
Hive,WITHOUT_CLASSIFICATION,//  Make sure we don't collide with the source files.   MM tables don't support concat so we don't expect the merge of merged files. 
Hive,WITHOUT_CLASSIFICATION,//  create VertexGroup 
Hive,WITHOUT_CLASSIFICATION,// case substring from index to the end 
Hive,WITHOUT_CLASSIFICATION,//  sleep for expiry time and then fetch again   sleep twice the TTL interval - things should have been cleaned by then. 
Hive,WITHOUT_CLASSIFICATION,//  Walk through the AST. 
Hive,WITHOUT_CLASSIFICATION,//  The process has not logged in using keytab   this should be a test mode can't use keytab to authenticate   with zookeeper. 
Hive,WITHOUT_CLASSIFICATION,// ========================== 20000 range starts here ========================// 
Hive,WITHOUT_CLASSIFICATION,//  Check job config for overrides otherwise use the default server value. 
Hive,WITHOUT_CLASSIFICATION,//  FastBitSet rather than using 31 integers. 
Hive,WITHOUT_CLASSIFICATION,//  the user tries to actually use this session and fails proceeding to return/destroy it. 
Hive,WITHOUT_CLASSIFICATION,// insert into newTableName select * from ts <where partition spec> 
Hive,WITHOUT_CLASSIFICATION,/*  these are things that goes through singleton initialization on most queries  */
Hive,WITHOUT_CLASSIFICATION,//  One last check. 
Hive,WITHOUT_CLASSIFICATION,//  IS_TBL_LEVEL 
Hive,WITHOUT_CLASSIFICATION,//  Verify that getNextNotification(last) returns zero events if there are no more notifications available 
Hive,WITHOUT_CLASSIFICATION,//  nulls 
Hive,WITHOUT_CLASSIFICATION,//  then OR the current node with the previous one 
Hive,WITHOUT_CLASSIFICATION,//  -5 years + 121 months = -5 years + 10 years + 1 month = 5 years 1 month 
Hive,WITHOUT_CLASSIFICATION,//  Create map of source file system to destination path to list of files to copy 
Hive,WITHOUT_CLASSIFICATION,//  remove '' at begining 
Hive,WITHOUT_CLASSIFICATION,//  Qualified column access for which table was not found 
Hive,WITHOUT_CLASSIFICATION,//  write out the plan to a local file 
Hive,WITHOUT_CLASSIFICATION,//  Change the resource plan so that the session gets killed. 
Hive,WITHOUT_CLASSIFICATION,//  Get the updated path list 
Hive,WITHOUT_CLASSIFICATION,//  set really low batch size to ensure batching 
Hive,WITHOUT_CLASSIFICATION,//  unpartitioned table 
Hive,WITHOUT_CLASSIFICATION,//  Verify that partition_1 was added correctly and properties were inherited from the HCatTable. 
Hive,WITHOUT_CLASSIFICATION,//  if some application depends on the original value being set. 
Hive,WITHOUT_CLASSIFICATION,/*    * Note that when serializing a row the logical mapping using selected in use has already   * been performed.  batchIndex is the actual index of the row.    */
Hive,WITHOUT_CLASSIFICATION,//  Get task detail link from the jobtask page 
Hive,WITHOUT_CLASSIFICATION,//  Project the column corresponding to the distinct aggregate. Project   as-is all the non-distinct aggregates 
Hive,WITHOUT_CLASSIFICATION,//  Since the start is 0 and the length is 100 the first call to sync should be with the value   50 so return that for getPos() 
Hive,WITHOUT_CLASSIFICATION,/*    * Relative start position of the windowing. Can be negative.    */
Hive,WITHOUT_CLASSIFICATION,//  initialize HCatInputFormat 
Hive,WITHOUT_CLASSIFICATION,//  Infix operator 
Hive,WITHOUT_CLASSIFICATION,//  Rounding numbers that increase int digits 
Hive,WITHOUT_CLASSIFICATION,/*   * Impl note: Hive provides authorization with it's own model and calls the defined  * HiveAuthorizationProvider from Driver.doAuthorization(). However HCat has to  * do additional calls to the auth provider to implement expected behavior for  * StorageDelegationAuthorizationProvider. This means that the defined auth provider  * is called by both Hive and HCat. The following are missing from Hive's implementation  * and when they are fixed in Hive we can remove the HCat-specific auth checks.  * 1. CREATE DATABASE/TABLE ADD PARTITION statements does not call  * HiveAuthorizationProvider.authorize() with the candidate objects which means that  * we cannot do checks against defined LOCATION.  * 2. HiveOperation does not define sufficient Privileges for most of the operations  * especially database operations.  * 3. For some of the operations Hive SemanticAnalyzer does not add the changed  * object as a WriteEntity or ReadEntity.  *  * @see https://issues.apache.org/jira/browse/HCATALOG-244  * @see https://issues.apache.org/jira/browse/HCATALOG-245   */
Hive,WITHOUT_CLASSIFICATION,//  No need to kill anything. 
Hive,WITHOUT_CLASSIFICATION,//  If currTask is rootTasks remove it and add its children to the rootTasks which currTask is its only parent   task 
Hive,WITHOUT_CLASSIFICATION,//  W/ size 0 query will fail but at least we'd get to see the query in debug output. 
Hive,WITHOUT_CLASSIFICATION,//  Do not merge if we do not know how to connect two operator trees. 
Hive,WITHOUT_CLASSIFICATION,//  If all arguments are of known length then we can keep track of the max   length of the return type. However if the return length exceeds the 
Hive,WITHOUT_CLASSIFICATION,//  create operator info list to return 
Hive,WITHOUT_CLASSIFICATION,//  The source column names for ORC serde that will be used in the schema. 
Hive,WITHOUT_CLASSIFICATION,//  If value is null the type should also be VOID. 
Hive,WITHOUT_CLASSIFICATION,//  setup the compression codec 
Hive,WITHOUT_CLASSIFICATION,//  Do NOTHING if output is NULL. 
Hive,WITHOUT_CLASSIFICATION,//  construct outer struct 
Hive,WITHOUT_CLASSIFICATION,//  Create two tables one as user "foo" and other as user "bar" 
Hive,WITHOUT_CLASSIFICATION,/* now both batches have committed (but not closed) so we for each primary file we expect a side    file to exist and indicate the true length of primary file */
Hive,WITHOUT_CLASSIFICATION,//  sql std authorization is managing privileges at the table/view levels   only   ignore partitions 
Hive,WITHOUT_CLASSIFICATION,//  Remove any semijoin branch associated with hashjoin's parent's operator 
Hive,WITHOUT_CLASSIFICATION,//  assumptions about the range of numeric data being analyzed. 
Hive,WITHOUT_CLASSIFICATION,//  preceeding work must be set to the newly generated map 
Hive,WITHOUT_CLASSIFICATION,//     Assert.assertEquals("Comparing Parameters(totalSize)" "0"          createdTable.getParameters().get("totalSize"));      Assert.assertEquals("Comparing Parameters(numFiles)" "0" 
Hive,WITHOUT_CLASSIFICATION,// skip first child since it is struct 
Hive,WITHOUT_CLASSIFICATION,// second "split" is delta_200_200 
Hive,WITHOUT_CLASSIFICATION,//  reloadable jars 
Hive,WITHOUT_CLASSIFICATION,//  Cleanup the synthetic predicate in the tablescan operator by   replacing it with "true" 
Hive,WITHOUT_CLASSIFICATION,/*    * The storage arrays for this column vector corresponds to the storage of a HiveIntervalDayTime:    */
Hive,WITHOUT_CLASSIFICATION,/*      * DOUBLE: Min and max.      */
Hive,WITHOUT_CLASSIFICATION,//  allocate a temporary output dir on the location of the table 
Hive,WITHOUT_CLASSIFICATION,//  batches will be sized 1241 
Hive,WITHOUT_CLASSIFICATION,//  In checking if a mapjoin can be converted to bucket mapjoin 
Hive,WITHOUT_CLASSIFICATION,//  be used because that is the correct move task for the "merge and move" use case. 
Hive,WITHOUT_CLASSIFICATION,//  The input file has changed - every operator can invoke specific action 
Hive,WITHOUT_CLASSIFICATION,//  Round to the specified number of decimal places using the standard Hive round function. 
Hive,WITHOUT_CLASSIFICATION,//  Base64 encoded and stringified token for server 
Hive,WITHOUT_CLASSIFICATION,/*            * {Rel Offset Word} [Big Value Len] [Next Value Small Len] {Value Bytes}           *           * 2nd and beyond records have a relative offset word at the beginning.            */
Hive,WITHOUT_CLASSIFICATION,//  access the fields 
Hive,WITHOUT_CLASSIFICATION,//  HBase input formats are not thread safe today. See HIVE-8808. 
Hive,WITHOUT_CLASSIFICATION,//  It is guaranteed there is only 1 list within listBucketCols. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setUnicodeStream(int java.io.InputStream   * int)    */
Hive,WITHOUT_CLASSIFICATION,//  Largest size allowed in smallBuffer 
Hive,WITHOUT_CLASSIFICATION,//  Disable auth so the call should succeed 
Hive,WITHOUT_CLASSIFICATION,//  Do nothing as this was fixed by MAPREDUCE-1447. 
Hive,WITHOUT_CLASSIFICATION,//  1. Insert five rows to Non-ACID table. 
Hive,WITHOUT_CLASSIFICATION,/*   * (non-Javadoc)  *  * @see  * org.apache.hadoop.hive.ql.security.authorization.HiveAuthorizationProvider  * #authorize(org.apache.hadoop.hive.ql.metadata.Partition  * org.apache.hadoop.hive.ql.security.authorization.Privilege[]  * org.apache.hadoop.hive.ql.security.authorization.Privilege[])   */
Hive,WITHOUT_CLASSIFICATION,//  FULL_TABLE_NAMES 
Hive,WITHOUT_CLASSIFICATION,//  Cap at fact-row-count because numerical artifacts can cause it 
Hive,WITHOUT_CLASSIFICATION,//  Send the bucket IDs associated with the tasks must happen after parallelism is set. 
Hive,WITHOUT_CLASSIFICATION,//  there are no elements in the union 
Hive,WITHOUT_CLASSIFICATION,/*        * once the source node is reached; stop traversal for this QB        */
Hive,WITHOUT_CLASSIFICATION,//  There should be one base dir in the location 
Hive,WITHOUT_CLASSIFICATION,//  print the stack from all threads for debugging purposes 
Hive,WITHOUT_CLASSIFICATION,/*    * Type of job request.    */
Hive,WITHOUT_CLASSIFICATION,//  Network cost of map side join 
Hive,WITHOUT_CLASSIFICATION,//  Spill the big table rows into appropriate partition:   When the JoinResult is SPILL it means the corresponding small table row may have been   spilled to disk (at least the partition that holds this row is on disk). So we need to 
Hive,WITHOUT_CLASSIFICATION,//  Build map to not convert multiple times further remove already included predicates 
Hive,WITHOUT_CLASSIFICATION,//  Set the location in the StorageDescriptor 
Hive,WITHOUT_CLASSIFICATION,//  as HiveServer2 output is consumed by JDBC/ODBC clients. 
Hive,WITHOUT_CLASSIFICATION,//  we need to know if it is COUNT since this is specialized for IN/NOT IN   corr subqueries. 
Hive,WITHOUT_CLASSIFICATION,//  Remove the value of every key found matching 
Hive,WITHOUT_CLASSIFICATION,//  convert each key-value-map to appropriate expression. 
Hive,WITHOUT_CLASSIFICATION,// this should not schedule a new compaction due to prior failures but will create Attempted entry 
Hive,WITHOUT_CLASSIFICATION,//  Add tbl_id and empty bitvector 
Hive,WITHOUT_CLASSIFICATION,//  Means user specified a table not a partition 
Hive,WITHOUT_CLASSIFICATION,//  convert to RequiredPrivileges 
Hive,WITHOUT_CLASSIFICATION,//  Reserve 4 bytes for the hash (don't just reserve there may be junk there) 
Hive,WITHOUT_CLASSIFICATION,//  otherwise GBevaluator and expr nodes may get shared among multiple GB ops 
Hive,WITHOUT_CLASSIFICATION,//  miniHS2_2 will continue to be leader 
Hive,WITHOUT_CLASSIFICATION,//  LAST_ANALYZED 
Hive,WITHOUT_CLASSIFICATION,// ************************************************************************************************   Emulate SerializationUtils Deserialization used by ORC. 
Hive,WITHOUT_CLASSIFICATION,//  Translate the double into sign exponent and significand according 
Hive,WITHOUT_CLASSIFICATION,// return true if both are null or false if one is null and the other isn't 
Hive,WITHOUT_CLASSIFICATION,//  Replicate the remaining INSERT OVERWRITE operations on the table. 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.CLIServiceTest#tearDown()    */
Hive,WITHOUT_CLASSIFICATION,//  add the select operator 
Hive,WITHOUT_CLASSIFICATION,//  For each BaseWork with MJ operator we build a SparkWork for its small table BaseWorks 
Hive,WITHOUT_CLASSIFICATION,/*         each Partition may have different I/O Format so have to check them all before deciding to        make a full CRUD table.        Run in batches to prevent OOM        */
Hive,WITHOUT_CLASSIFICATION,// ************************************************************************************************   Decimal Math. 
Hive,WITHOUT_CLASSIFICATION,//  else do common code 
Hive,WITHOUT_CLASSIFICATION,//  skip the driver and directly loadable tables 
Hive,WITHOUT_CLASSIFICATION,/*    * Wait time in milliseconds before another cancel request is made.    */
Hive,WITHOUT_CLASSIFICATION,// 1234 
Hive,WITHOUT_CLASSIFICATION,//  Find the parsed deltas- some of them containing only the insert delta events 
Hive,WITHOUT_CLASSIFICATION,//  If the "strict" mode is on we have to provide partition pruner for each table. 
Hive,WITHOUT_CLASSIFICATION,//  Test gt/lt/lte/gte/like for strings. 
Hive,WITHOUT_CLASSIFICATION,//  7. Perform Logical optimization 
Hive,WITHOUT_CLASSIFICATION,//  data array and masks array are then traversed together and checked for corresponding set bits. 
Hive,WITHOUT_CLASSIFICATION,//  5. Update the maps   NOTE: Output RR for SortRel is considered same as its input; we may   end up not using VC that is present in sort rel. Also note that   rowtype of sortrel is the type of it child; if child happens to be   synthetic project that we introduced then that projectrel would 
Hive,WITHOUT_CLASSIFICATION,//  eliminate stripes that doesn't satisfy the predicate condition 
Hive,WITHOUT_CLASSIFICATION,//  destination on disk 
Hive,WITHOUT_CLASSIFICATION,//  MM tables need custom handling for union suffix; DP tables use parent too. 
Hive,WITHOUT_CLASSIFICATION,//  The same umbilical is used by multiple tasks. Problematic in the case where multiple tasks 
Hive,WITHOUT_CLASSIFICATION,//  4) Return new operator 
Hive,WITHOUT_CLASSIFICATION,//  If a third parameter has been specified it should be an integer that specifies the number 
Hive,WITHOUT_CLASSIFICATION,/*    * parse a String as a Select List. This allows table functions to be passed expression Strings   * that are translated in   * the context they define at invocation time. Currently used by NPath to allow users to specify   * what output they want.   * NPath allows expressions n 'tpath' a column that represents the matched set of rows. This   * column doesn't exist in   * the input schema and hence the Result Expression cannot be analyzed by the regular Hive   * translation process.    */
Hive,WITHOUT_CLASSIFICATION,// FileOutputFormat.getWorkOutputPath takes TaskInputOutputContext instead of  TaskAttemptContext so can't use that here 
Hive,WITHOUT_CLASSIFICATION,//  Reset everything for the next arena; assume everything has been cleaned. 
Hive,WITHOUT_CLASSIFICATION,/*                * Multi-Key specific save key.                */
Hive,WITHOUT_CLASSIFICATION,//  create a deeply nested table which has more partition keys than the pool size 
Hive,WITHOUT_CLASSIFICATION,//  3) Create ROW_ID column in select clause from left input for the RIGHT OUTER JOIN.   This is needed for the UPDATE clause. Hence we find the following node:   TOK_QUERY     TOK_FROM        TOK_RIGHTOUTERJOIN           TOK_SUBQUERY              TOK_QUERY                 ...                 TOK_INSERT                    ...                    TOK_SELECT   And then we create the following child node:   TOK_SELEXPR      .         TOK_TABLE_OR_COL            cmv_mat_view 
Hive,WITHOUT_CLASSIFICATION,//  create an empty file (which is not a valid rcfile) 
Hive,WITHOUT_CLASSIFICATION,//  Smile mapper is used to read query results that are serilized as binary instead of json 
Hive,WITHOUT_CLASSIFICATION,//  we can still fold since here null is equivalent to false. 
Hive,WITHOUT_CLASSIFICATION,//  1 second 
Hive,WITHOUT_CLASSIFICATION,//  nesting level limits 
Hive,WITHOUT_CLASSIFICATION,//  interceptor for adding username pwd 
Hive,WITHOUT_CLASSIFICATION,//  Test VARCHAR literal to string column comparison 
Hive,WITHOUT_CLASSIFICATION,//  if all left data in small tables are less than and equal to the left data   in big table let's them catch up 
Hive,WITHOUT_CLASSIFICATION,//  has nulls not repeating 
Hive,WITHOUT_CLASSIFICATION,//  Use Case 6. 
Hive,WITHOUT_CLASSIFICATION,// ~ Static fields/initializers --------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  Vectorization only supports PRIMITIVE data types. Assert the same 
Hive,WITHOUT_CLASSIFICATION,/*        * Multi-Key check for repeating.        */
Hive,WITHOUT_CLASSIFICATION,//  Read permission/no permissions or the expected user. 
Hive,WITHOUT_CLASSIFICATION,/*      * 2. build Map-side Op Graph. Graph template is either:     * Input -> PTF_map -> ReduceSink     * or     * Input -> ReduceSink     *     * Here the ExprNodeDescriptors in the QueryDef are based on the Input Operator's RR.      */
Hive,WITHOUT_CLASSIFICATION,//  Hive assumes that user names the files as per the corresponding   bucket. For e.g file names should follow the format 000000_0 000000_1 etc.   Here the 1st file will belong to bucket 0 and 2nd to bucket 1 and so on. 
Hive,WITHOUT_CLASSIFICATION,//  flatten AND 
Hive,WITHOUT_CLASSIFICATION,//  Re-use an existing available column of the same required type. 
Hive,WITHOUT_CLASSIFICATION,//  Test capability for tests. 
Hive,WITHOUT_CLASSIFICATION,//  This code with branches and all is not executed if there are no string keys 
Hive,WITHOUT_CLASSIFICATION,//  modifiable 
Hive,WITHOUT_CLASSIFICATION,//  test with nulls in input 
Hive,WITHOUT_CLASSIFICATION,//  there were no grp and perms to begin with. 
Hive,WITHOUT_CLASSIFICATION,//  We start: 
Hive,WITHOUT_CLASSIFICATION,//  actualBatchSize is half of batchSize when 1 exception is expected 
Hive,WITHOUT_CLASSIFICATION,//  set columnAccessInfo for ViewColumnAuthorization 
Hive,WITHOUT_CLASSIFICATION,//  PART_ARCHIVE_LEVEL 
Hive,WITHOUT_CLASSIFICATION,//  optional .VertexOrBinary work_spec = 1; 
Hive,WITHOUT_CLASSIFICATION,//  Create a new open session request object 
Hive,WITHOUT_CLASSIFICATION,//  Zero(es). 
Hive,WITHOUT_CLASSIFICATION,//  Use try .. finally to cleanup temp file if something goes wrong 
Hive,WITHOUT_CLASSIFICATION,//  All alters done now we replicate them over. 
Hive,WITHOUT_CLASSIFICATION,//  Delete the original node... 
Hive,WITHOUT_CLASSIFICATION,// per acid write to test nonAcid2acid conversion mixed with load data 
Hive,WITHOUT_CLASSIFICATION,//  Sort columns are not allowed for full ACID table. So change it to insert-only table 
Hive,WITHOUT_CLASSIFICATION,//  Current value. 
Hive,WITHOUT_CLASSIFICATION,//  Vector SerDe can be disabled both on client and server side. 
Hive,WITHOUT_CLASSIFICATION,//  More than TS operator 
Hive,WITHOUT_CLASSIFICATION,//  if length of (prefix/ds=__HIVE_DEFAULT_PARTITION__/000000_0) is greater than max key prefix 
Hive,WITHOUT_CLASSIFICATION,// create 1 row in a file 000000_0_copy_2 
Hive,WITHOUT_CLASSIFICATION,//  First delete any MVs to avoid race conditions 
Hive,WITHOUT_CLASSIFICATION,//  Determine the temp table path 
Hive,WITHOUT_CLASSIFICATION,//  update for "{\"writeid\":1\"bucketid\":536936448\"rowid\":0}\t1\t1\t1\t" 
Hive,WITHOUT_CLASSIFICATION,//  Use the cache rather than full query execution.   At this point the caller should return from semantic analysis. 
Hive,WITHOUT_CLASSIFICATION,//  of the specified operator class 
Hive,WITHOUT_CLASSIFICATION,//  Reuse the partition specs from dest partition since they should be the same 
Hive,WITHOUT_CLASSIFICATION,//  optional string application_id_string = 1; 
Hive,WITHOUT_CLASSIFICATION,//  Check to see if we have seen this request before.  If so ignore it.  If not   add it to our queue. 
Hive,WITHOUT_CLASSIFICATION,// so that we can test "old" files 
Hive,WITHOUT_CLASSIFICATION,//  LOG.debug("generateHashMultiSetResultSingleValue enter..."); 
Hive,WITHOUT_CLASSIFICATION,//  In future this may examine context to return appropriate HCatWriter 
Hive,WITHOUT_CLASSIFICATION,//     Driver driver = new Driver(conf);      SessionState.start(new CliSessionState(conf)); 
Hive,WITHOUT_CLASSIFICATION,//  In case of test if we might not want to remove the log directory 
Hive,WITHOUT_CLASSIFICATION,// "no inputs"; // Cannot use with input formats. 
Hive,WITHOUT_CLASSIFICATION,// make 2 more inserts so that we have 000000_0_copy_1 000000_0_copy_2 files in export 
Hive,WITHOUT_CLASSIFICATION,//  We fill starting with highest digit in highest longword (HIGHWORD_DECIMAL_DIGITS) and   move down.  At end will will shift everything down if necessary. 
Hive,WITHOUT_CLASSIFICATION,//  Use Case 12. 
Hive,WITHOUT_CLASSIFICATION,//  Multi-column.  Also covers table in non-default database 
Hive,WITHOUT_CLASSIFICATION,//  (\uD867\uDE3D is Okhotsk atka mackerel in Kanji). 
Hive,WITHOUT_CLASSIFICATION,/*            * Multi-Key outer null detection.            */
Hive,WITHOUT_CLASSIFICATION,/*    * Input array is used to fill the entire size of the vector row batch    */
Hive,WITHOUT_CLASSIFICATION,//  Drop any constraints on the table 
Hive,WITHOUT_CLASSIFICATION,//  Format a sorted by statement 
Hive,WITHOUT_CLASSIFICATION,//  descriptor. 
Hive,WITHOUT_CLASSIFICATION,//  Restore the context. 
Hive,WITHOUT_CLASSIFICATION,//  fetch operator 
Hive,WITHOUT_CLASSIFICATION,//  scriptOperator to echo the output of the select 
Hive,WITHOUT_CLASSIFICATION,// ------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  Have that the NULL does not interfere with the current equal key series if there   is one. We do not set saveJoinResult.        Let a current MATCH equal key series keep going or      Let a current SPILL equal key series keep going or      Let a current NOMATCH keep not matching. 
Hive,WITHOUT_CLASSIFICATION,//  if a table was created in a user specified location using the DDL like   create table tbl ... location .... it should be treated like an external table   in the table rename its data location should not be changed. We can check   if the table directory was created directly under its database directory to tell   if it is such a table 
Hive,WITHOUT_CLASSIFICATION,/*  Sets the field and tag in the union. Returns the union.  */
Hive,WITHOUT_CLASSIFICATION,//  is sorted. 
Hive,WITHOUT_CLASSIFICATION,/*    * Maximum number of times a cancel request is sent to job request execution   * thread. Future.cancel may not be able to interrupt the thread if it is   * blocked on network calls.    */
Hive,WITHOUT_CLASSIFICATION,//  The ACID state is probably absent. Warning is logged in the get method. 
Hive,WITHOUT_CLASSIFICATION,//  if we pushed the predicate into the table scan we need to remove the 
Hive,WITHOUT_CLASSIFICATION,//  use that task 
Hive,WITHOUT_CLASSIFICATION,//  Druid timestamp column 
Hive,WITHOUT_CLASSIFICATION,//  if log4j configuration file not set or could not found use default setting 
Hive,WITHOUT_CLASSIFICATION,//  HTTP today but might not be 
Hive,WITHOUT_CLASSIFICATION,//  Use defaults... Partitions are put in the table directory. 
Hive,WITHOUT_CLASSIFICATION,/*        * Restriction.8.m :: We allow only 1 SubQuery expression per Query.        */
Hive,WITHOUT_CLASSIFICATION,//  only needed when grouping sets are present 
Hive,WITHOUT_CLASSIFICATION,//  Test that existing shared_read db with new shared_write coalesces to 
Hive,WITHOUT_CLASSIFICATION,//  glorified cast from Iterable<TBase> to Iterable<Partition> 
Hive,WITHOUT_CLASSIFICATION,//  All tables good on destination drop on source. 
Hive,WITHOUT_CLASSIFICATION,//  So min(txn_id) would be a non-zero txnid. 
Hive,WITHOUT_CLASSIFICATION,//  get all join columns from join keys 
Hive,WITHOUT_CLASSIFICATION,//  Make sure we only return keyDecompressor once. 
Hive,WITHOUT_CLASSIFICATION,//  Filters don't change the column names - so no need to do anything for them 
Hive,WITHOUT_CLASSIFICATION,/*    * Can this mapjoin be converted to a bucketed mapjoin ?   * The following checks are performed:   * a. The join columns contains all the bucket columns.   * b. The join keys are not transformed in the sub-query.   * c. All partitions contain the expected number of files (number of buckets).   * d. The number of buckets in the big table can be divided by no of buckets in small tables.    */
Hive,WITHOUT_CLASSIFICATION,//  No location expected with AccumuloStorageHandler 
Hive,WITHOUT_CLASSIFICATION,//  fall through 
Hive,WITHOUT_CLASSIFICATION,//  Check Vectorized ORC reader against ORC row reader 
Hive,WITHOUT_CLASSIFICATION,//  Value becomes null for rounding beyond. 
Hive,WITHOUT_CLASSIFICATION,//  Open a txn to be tested for ValidWriteIdList. Get the ValidTxnList during open itself.   Verify the ValidWriteIdList with no open/aborted write txns on this table. 
Hive,WITHOUT_CLASSIFICATION,//  Now we are handling exact types. Base implementation handles type promotion. 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   optional   optional   required   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  We don't support masking/filtering against ACID query at the moment 
Hive,WITHOUT_CLASSIFICATION,//  update file sink descriptor 
Hive,WITHOUT_CLASSIFICATION,//  move on to process to the next parsedDelta. 
Hive,WITHOUT_CLASSIFICATION,//                    1234567890123456789012345678901234567.8                              1         2         3 
Hive,WITHOUT_CLASSIFICATION,//  default threshold for using main memory based HashMap 
Hive,WITHOUT_CLASSIFICATION,//  Prefix for primary row keys 
Hive,WITHOUT_CLASSIFICATION,//  For MapWork getAllRootOperators is not suitable since it checks   getPathToAliases and will return null if this is empty. Here we are 
Hive,WITHOUT_CLASSIFICATION,//  And finally cache policy uses cache to notify it of eviction. The cycle is complete! 
Hive,WITHOUT_CLASSIFICATION,//  Create new Project-Sort-Project sequence 
Hive,WITHOUT_CLASSIFICATION,//  This request at a lower priority should not affect anything. 
Hive,WITHOUT_CLASSIFICATION,/*  * Interface for a vector map join hash table (which could be a hash map hash multi-set or * hash set) for a single long.  */
Hive,WITHOUT_CLASSIFICATION,//  add aux jars 
Hive,WITHOUT_CLASSIFICATION,// delete something but make sure txn is rolled back 
Hive,WITHOUT_CLASSIFICATION,//  Set the config value to 2 catalogs other than hive 
Hive,WITHOUT_CLASSIFICATION,/*          * Single-Column String specific repeated lookup.          */
Hive,WITHOUT_CLASSIFICATION,//  Create the struct if needed 
Hive,WITHOUT_CLASSIFICATION,//  context.addFilter(Utils.getXSRFFilterHolder(null null) "/"    FilterMapping.REQUEST);   Filtering does not work here currently doing filter in ThriftHttpServlet 
Hive,WITHOUT_CLASSIFICATION,//  Initialization fails and so does the retry no resource plan change. 
Hive,WITHOUT_CLASSIFICATION,//  Not needed anymore. 
Hive,WITHOUT_CLASSIFICATION,//  zero length key is not allowed by block compress writer so we use a byte   writable 
Hive,WITHOUT_CLASSIFICATION,//  The size to flush the string buffer at 
Hive,WITHOUT_CLASSIFICATION,//   TODO: Fix LoadPartitionDoneEvent. Currently LPDE can only carry a single partition-spec. And that defeats the purpose. 
Hive,WITHOUT_CLASSIFICATION,//  outside the inner loop results in NPE/OutOfBounds errors 
Hive,WITHOUT_CLASSIFICATION,// release locks from "select a from T7" - to unblock hte drop partition  retest the the "drop partiton" X lock 
Hive,WITHOUT_CLASSIFICATION,//  We skipped over leading 0x00s and 0xFFs 
Hive,WITHOUT_CLASSIFICATION,//  If the expr is column op const will try to cast the const to string   according to the data type of the column 
Hive,WITHOUT_CLASSIFICATION,//  No need to check finishable here; if it was set it would already be in the queue. 
Hive,WITHOUT_CLASSIFICATION,//  Perform some checks on whether the node will become available or not. 
Hive,WITHOUT_CLASSIFICATION,//  Since we're only creating a view (not executing it) we don't need to   optimize or translate the plan (and in fact those procedures can 
Hive,WITHOUT_CLASSIFICATION,//  This will throw an expected exception since client-server modes are incompatible 
Hive,WITHOUT_CLASSIFICATION,//  we didn't find case or when udf 
Hive,WITHOUT_CLASSIFICATION,//  delimited way. 
Hive,WITHOUT_CLASSIFICATION,//  Set this if we encounter a condition we were not expecting. 
Hive,WITHOUT_CLASSIFICATION,//  BINARY_COLUMNS 
Hive,WITHOUT_CLASSIFICATION,//  mr 
Hive,WITHOUT_CLASSIFICATION,//  Note that this will be invoked in 2 cases:      1) DirectSQL was disabled to start with;      2) DirectSQL threw and was disabled in handleDirectSqlError. 
Hive,WITHOUT_CLASSIFICATION,//  Note: no location check here; the buffer is always locked for move. 
Hive,WITHOUT_CLASSIFICATION,//  As of HIVE-8745 these decimal values should be trimmed of trailing zeros. 
Hive,WITHOUT_CLASSIFICATION,//  Null last (default for descending order) 
Hive,WITHOUT_CLASSIFICATION,//  Calcite always needs the else clause to be defined explicitly 
Hive,WITHOUT_CLASSIFICATION,//  Change all the linked file sink descriptors 
Hive,WITHOUT_CLASSIFICATION,//  Also we prefer a missed heartbeat over a stuck query in case of discrepancy in ET. 
Hive,WITHOUT_CLASSIFICATION,//  Create a directory with no permissions 
Hive,WITHOUT_CLASSIFICATION,//  TableDesc#getDeserializer will ultimately instantiate the AccumuloSerDe with a null   Configuration   We have to accept this and just fail late if data is attempted to be pulled from the   Configuration 
Hive,WITHOUT_CLASSIFICATION,//  new *hive-site.xml file 
Hive,WITHOUT_CLASSIFICATION,//  Empty java opts 
Hive,WITHOUT_CLASSIFICATION,// Remove any virtual cols 
Hive,WITHOUT_CLASSIFICATION,//  2^62 
Hive,WITHOUT_CLASSIFICATION,//  Scaling down may have opened up trailing zeroes... 
Hive,WITHOUT_CLASSIFICATION,//  Vectorized implementation of ROUND(Col N) function 
Hive,WITHOUT_CLASSIFICATION,//  first field always starts from 0 even when missing 
Hive,WITHOUT_CLASSIFICATION,//  ASCENDING 
Hive,WITHOUT_CLASSIFICATION,//  New operators 
Hive,WITHOUT_CLASSIFICATION,//  we have the dag now proceed to get the splits: 
Hive,WITHOUT_CLASSIFICATION,//  need to capture the timing 
Hive,WITHOUT_CLASSIFICATION,//  begin to walk through the task tree. 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.operation.Operation#close()    */
Hive,WITHOUT_CLASSIFICATION,//  Verify mergeOnlyTask is NOT optimized (a merge task writes directly to finalDirName then a MoveTask is executed) 
Hive,WITHOUT_CLASSIFICATION,//  Remove operator and combine 
Hive,WITHOUT_CLASSIFICATION,//  Each headers[i] is a "virtual" byte at i * minAllocation. 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: here we should use the new partition predicate pushdown API to get a list of   pruned list 
Hive,WITHOUT_CLASSIFICATION,//  CMS   Parallel GC   G1GC   other vendors like IBM Azul etc. use different names 
Hive,WITHOUT_CLASSIFICATION,//  Hive QueryId is not always unique. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure the user has not requested an insane amount of txns. 
Hive,WITHOUT_CLASSIFICATION,//  Execute one instruction; terminate on executing a script if there is an error   in silent mode prevent the query and prompt being echoed back to terminal 
Hive,WITHOUT_CLASSIFICATION,/* create delta_1_1_0/bucket0 with 1 row and close the file */
Hive,WITHOUT_CLASSIFICATION,//  1. Gen Optimized AST 
Hive,WITHOUT_CLASSIFICATION,//  web port cannot be obtained 
Hive,WITHOUT_CLASSIFICATION,//  refs. These comparisons are AND'ed together. 
Hive,WITHOUT_CLASSIFICATION,/*    * Uses generic JDBC escape functions to add a limit clause to a query string    */
Hive,WITHOUT_CLASSIFICATION,//  Don't need to recordShuffleInfo since the out of sync unregister will not remove the   credentials 
Hive,WITHOUT_CLASSIFICATION,//  DemuxOperator forwards a row to exactly one child in its children list   based on the tag and newTagToChildIndex in processOp() method.   So we need not to do anything in here. 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) Struct  */
Hive,WITHOUT_CLASSIFICATION,//  compact ttp2 by running the Worker explicitly in order to get the reference to the compactor MR job 
Hive,WITHOUT_CLASSIFICATION,//  Can there be no ACLs? There's some access (to get ACLs) so assume it means free for all. 
Hive,WITHOUT_CLASSIFICATION,//  block to make sure kill happened successfully 
Hive,WITHOUT_CLASSIFICATION,// map join dump file name 
Hive,WITHOUT_CLASSIFICATION,//  same instance of Driver which can run multiple queries. 
Hive,WITHOUT_CLASSIFICATION,//  Increase qp check that the pool grows. 
Hive,WITHOUT_CLASSIFICATION,//  We may need to do linear interpolation to get the exact percentile 
Hive,WITHOUT_CLASSIFICATION,/*  10 files x 1000 size for 9 splits  */
Hive,WITHOUT_CLASSIFICATION,//  Do this only on your own peril and never in the production code 
Hive,WITHOUT_CLASSIFICATION,//  DateColumnArithmeticTimestampColumn.txt   DateScalarArithmeticTimestampColumn.txt   DateColumnArithmeticTimestampScalar.txt 
Hive,WITHOUT_CLASSIFICATION,//  Marker to track if the previous character was an escape character 
Hive,WITHOUT_CLASSIFICATION,//  The default setting is "throw"; assume doValidate && !doSkip means throw. 
Hive,WITHOUT_CLASSIFICATION,//  Not doing any check 
Hive,WITHOUT_CLASSIFICATION,//  Execute extended optimization   For each RS check whether other RS in same work could be merge into this one.   If they are merged RS operators in the resulting work will be considered 
Hive,WITHOUT_CLASSIFICATION,//  Signature for wrapped storer see comments in LoadFuncBasedInputDriver.initialize 
Hive,WITHOUT_CLASSIFICATION,//  Constant node 
Hive,WITHOUT_CLASSIFICATION,/*    * - a subclass must provide this method.   * - this method is invoked during translation and also when the Operator is initialized during runtime.   * - a subclass must use this call to setup the shape of its output.   * - subsequent to this call a call to getOutputOI call on the {@link TableFunctionEvaluator} must return the OI   * of the output of this function.    */
Hive,WITHOUT_CLASSIFICATION,//  Remove if the path is not present 
Hive,WITHOUT_CLASSIFICATION,//  In case of multi-table insert the path to alias mapping is needed for   all the sources. Since there is no   reducer treat it as a plan with null reducer 
Hive,WITHOUT_CLASSIFICATION,//  It can be optimized later so that an operator operator (init/close) is performed   only after that operation has been performed on all the parents. This will require   initializing the whole tree in all the mappers (which might be required for mappers   spanning multiple files anyway in future) 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * This provides a LazyInteger like class which can be initialized from data stored in a   * binary format.   *   * @see org.apache.hadoop.hive.serde2.lazy.LazyObject#init   *        (org.apache.hadoop.hive.serde2.lazy.ByteArrayRef int int)    */
Hive,WITHOUT_CLASSIFICATION,//  Calculate complete dynamic-multi-dimension collection. 
Hive,WITHOUT_CLASSIFICATION,/*      * 3. convert filterNode      */
Hive,WITHOUT_CLASSIFICATION,/*         We already handled all delete deltas above and there should not be any other deltas for        any table type.  (this was acid 1.0 code path).          */
Hive,WITHOUT_CLASSIFICATION,//  This VectorExpression (IN) is a special case so don't return a descriptor. 
Hive,WITHOUT_CLASSIFICATION,//  Find the biggest reduce sink 
Hive,WITHOUT_CLASSIFICATION,//  inputTs is the year/month/day/hour/minute/second in the local timezone.   For this UDF we want it in the timezone represented by fromTz 
Hive,WITHOUT_CLASSIFICATION,//  For each component in this lock request   add an entry to the txn_components table 
Hive,WITHOUT_CLASSIFICATION,//  Setup exprNode 
Hive,WITHOUT_CLASSIFICATION,//  getCanonicalHostName would either return FQDN or an IP. 
Hive,WITHOUT_CLASSIFICATION,//  HTTP Server 
Hive,WITHOUT_CLASSIFICATION,//  Top level query 
Hive,WITHOUT_CLASSIFICATION,//  used to group dependent tasks for multi table inserts 
Hive,WITHOUT_CLASSIFICATION,// "select * from tab1" txn 
Hive,WITHOUT_CLASSIFICATION,// //////////  Bootstrap   //////////// 
Hive,WITHOUT_CLASSIFICATION,//  unfortunately making prunedPartitions immutable is not possible   here with SemiJoins not all tables are costed in CBO so their 
Hive,WITHOUT_CLASSIFICATION,//  Use milliseconds parser if pattern matches our special-case millis pattern string 
Hive,WITHOUT_CLASSIFICATION,/*      * ============================ [PERF] ===================================     * This function is called for every row. Setting up the selected/projected     * columns at the first call and don't do that for the following calls.     * Ideally this should be done in the constructor where we don't need to     * branch in the function for each row.     * =========================================================================      */
Hive,WITHOUT_CLASSIFICATION,//  Don't send the parsedDbName as this method will parse itself. 
Hive,WITHOUT_CLASSIFICATION,/*    * Close.    */
Hive,WITHOUT_CLASSIFICATION,//  If a operator wants to do some work at the beginning of a group 
Hive,WITHOUT_CLASSIFICATION,//  MODIFIER LETTER SMALL X U+02E3 (2 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  3) If too many sessions are outstanding (e.g. due to expiration restarts - should      not happen with in-use sessions because WM already kills the extras) we will kill 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#executeUpdate(java.lang.String int[])    */
Hive,WITHOUT_CLASSIFICATION,//  Try to fold otherwise return the expression itself 
Hive,WITHOUT_CLASSIFICATION,//  The mapping from the index of a child operator to its corresponding 
Hive,WITHOUT_CLASSIFICATION,//  For instance this is the case when we are creating the table. 
Hive,WITHOUT_CLASSIFICATION,//  Create currJobContext the latest so it gets all the config changes 
Hive,WITHOUT_CLASSIFICATION,//  Only stored to update based on the original in fixTmpPath.   Only stored to update based on the original in fixTmpPath. 
Hive,WITHOUT_CLASSIFICATION,//  execute() of Prepared statement 
Hive,WITHOUT_CLASSIFICATION,//  a column family 
Hive,WITHOUT_CLASSIFICATION,//  If it multiple level of folder are there fs.rename is failing so first   create the targetpath.getParent() if it not exist 
Hive,WITHOUT_CLASSIFICATION,//  Test class to read a series of values to the designated input stream 
Hive,WITHOUT_CLASSIFICATION,//  This implementation of vectorized JOIN is delegating all the work   to the row-mode implementation by hijacking the big table node evaluators   and calling the row-mode join processOp for each row in the input batch.   Since the JOIN operator is not fully vectorized anyway at the moment   (due to the use of row-mode small-tables) this is a reasonable trade-off. 
Hive,WITHOUT_CLASSIFICATION,//  generates grouping set   position of grouping set generally the last of keys   declared grouping set values   bitsets acquired from grouping set values 
Hive,WITHOUT_CLASSIFICATION,/*        * We have a field and are positioned to it.  Read it.        */
Hive,WITHOUT_CLASSIFICATION,//  Now we create the filter with the transactions information.   In particular each table in the materialization will only have contents such that:   ROW_ID.writeid <= high_watermark and ROW_ID.writeid not in (open/invalid_ids)   Hence we add that condition on top of the source table.   The rewriting will then have the possibility to create partial rewritings that read   the materialization and the source tables and hence produce an incremental 
Hive,WITHOUT_CLASSIFICATION,//  Since we cannot merge operators into a single MR job from here   we should remove ReduceSinkOperators added into walked in exploitJFC 
Hive,WITHOUT_CLASSIFICATION,//  Where the log files wll be written 
Hive,WITHOUT_CLASSIFICATION,//  Original bucket files and delta directory should have been cleaned up. 
Hive,WITHOUT_CLASSIFICATION,//  Finally add the fixed acid key index. 
Hive,WITHOUT_CLASSIFICATION,//  This method finds any columns on the right side of a set statement (thus rcols) and puts them 
Hive,WITHOUT_CLASSIFICATION,//  Is there a select following   Clone the select also. It is useful for a follow-on optimization where the union 
Hive,WITHOUT_CLASSIFICATION,// getDataSize tries to estimate stats if it doesn't exist using file size   we would like to avoid file system calls  if it too expensive 
Hive,WITHOUT_CLASSIFICATION,//  Cache settings will need to be setup in llap-daemon-site.xml - since the daemons don't read hive-site.xml 
Hive,WITHOUT_CLASSIFICATION,//  Floor on an integer argument is a noop but it is less code to handle it this way. 
Hive,WITHOUT_CLASSIFICATION,//  perform HA upgrade 
Hive,WITHOUT_CLASSIFICATION,// if a lock is associated with a txn we can only "unlock" if if it's in WAITING state   which really means that the caller wants to give up waiting for the lock 
Hive,WITHOUT_CLASSIFICATION,//  Sum all non-null decimal column values for avg; maintain isGroupResultNull; after last row of   last group batch compute the group avg when sum is non-null. 
Hive,WITHOUT_CLASSIFICATION,//  if we get some non-literals we need to punt 
Hive,WITHOUT_CLASSIFICATION,//  try again with some different data values and divisor 
Hive,WITHOUT_CLASSIFICATION,//  SLOW: Do remainder with BigInteger. 
Hive,WITHOUT_CLASSIFICATION,//  We will load into MM directory and hide previous directories if needed. 
Hive,WITHOUT_CLASSIFICATION,//  currently only handles one input input 
Hive,WITHOUT_CLASSIFICATION,//  call-5: open - mock:/mocktbl/0_1 
Hive,WITHOUT_CLASSIFICATION,// -----------------------------------------------------------------------------------------------   Value conversion methods.  ----------------------------------------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  these are mostly copied from the root pom.xml 
Hive,WITHOUT_CLASSIFICATION,//  We will be returning a Text object 
Hive,WITHOUT_CLASSIFICATION,//  reset 
Hive,WITHOUT_CLASSIFICATION,//  For grouping sets add a dummy grouping key 
Hive,WITHOUT_CLASSIFICATION,//  verify that some dummy param can be set 
Hive,WITHOUT_CLASSIFICATION,// ---------------------------------------------------------------------------   Process Single-Column Long Outer Join on a vectorized row batch.   
Hive,WITHOUT_CLASSIFICATION,//  If we do we cannot merge as we would end up with a cycle in the DAG. 
Hive,WITHOUT_CLASSIFICATION,//  Exception from the RPC layer - communication failure consider as KILLED / service down. 
Hive,WITHOUT_CLASSIFICATION,//  End of string. 
Hive,WITHOUT_CLASSIFICATION,//  maxPosition is the 1.0 percentile 
Hive,WITHOUT_CLASSIFICATION,//  create tables as user1 
Hive,WITHOUT_CLASSIFICATION,//        need to make sure we don't get two write IDs for the same table. 
Hive,WITHOUT_CLASSIFICATION,//  Another small write. smallBuffer should be re-used for this write 
Hive,WITHOUT_CLASSIFICATION,/*  Dynamic partition pruning is enabled only for map join   * hive.spark.dynamic.partition.pruning is false and   * hive.spark.dynamic.partition.pruning.map.join.only is true    */
Hive,WITHOUT_CLASSIFICATION,//  if the offset is bigger than our current number of fields grow it 
Hive,WITHOUT_CLASSIFICATION,//  Step 2.1: Connect the operator trees of two MapRedTasks. 
Hive,WITHOUT_CLASSIFICATION,//  if we already found a variable this isn't a sarg 
Hive,WITHOUT_CLASSIFICATION,//  This will replace the old value if there is one   Overwrite the existing file 
Hive,WITHOUT_CLASSIFICATION,/*  vertex is waiting for input/slots or complete  */
Hive,WITHOUT_CLASSIFICATION,//  TODO: pause fetching 
Hive,WITHOUT_CLASSIFICATION,//  Verify the scenario when maxProbeSize is a very small value it doesn't fail 
Hive,WITHOUT_CLASSIFICATION,//  rename un-managed files to conform to Hive's naming standard   Example:   /warehouse/table/part-m-00000_1417075294718 will get renamed to /warehouse/table/.hive-staging/000000_0   If staging directory already contains the file taskId_copy_N naming will be used. 
Hive,WITHOUT_CLASSIFICATION,//  Register with the AMReporter when the callable is setup. Unregister once it starts running. 
Hive,WITHOUT_CLASSIFICATION,//  If it exists we want this to be an error condition. Repl Load is not intended to replace a   db. 
Hive,WITHOUT_CLASSIFICATION,//  0/0 for entry 0 should work but generate NaN 
Hive,WITHOUT_CLASSIFICATION,//  k1 not equals k3 
Hive,WITHOUT_CLASSIFICATION,//  This method is used to traverse the DAG created in tasks list and add the dependent task to 
Hive,WITHOUT_CLASSIFICATION,//  Given a candidate map-join can this join be converted.   The candidate map-join was derived from the pluggable sort merge join big 
Hive,WITHOUT_CLASSIFICATION,//  Set the updated fetch size from the server into the configuration map for the client 
Hive,WITHOUT_CLASSIFICATION,//  First see if we have sessions that we were planning to restart/kill; get rid of those. 
Hive,WITHOUT_CLASSIFICATION,//  if we're generating the splits in the AM we just need to set 
Hive,WITHOUT_CLASSIFICATION,//  When the next value is small it was not recorded with the old (i.e. next) value and we 
Hive,WITHOUT_CLASSIFICATION,//        synchronized. Best-effort to display the queue in order. 
Hive,WITHOUT_CLASSIFICATION,// ************************************************************************************************   Emulate SerializationUtils Serialization used by ORC. 
Hive,WITHOUT_CLASSIFICATION,//  cannot hold all map tables in memory. Cannot convert. 
Hive,WITHOUT_CLASSIFICATION,//  RS then ReduceSinkDeDuplication optimization should merge them 
Hive,WITHOUT_CLASSIFICATION,// Else recurse to the children. 
Hive,WITHOUT_CLASSIFICATION,//  Return the wrapper of the root node 
Hive,WITHOUT_CLASSIFICATION,//  Deserialize data to column values and populate the row record 
Hive,WITHOUT_CLASSIFICATION,//  org.apache.thrift.protocol.TJSONProtocol.class.getName()); 
Hive,WITHOUT_CLASSIFICATION,//  mark if agg produces count(*) which needs to reference the 
Hive,WITHOUT_CLASSIFICATION,/*  256 files x 1000 size for 111 splits  */
Hive,WITHOUT_CLASSIFICATION,//  Old containers which are likely shutting down or new containers which   launched between YARN Service status/diagnostics. Skip for this iteration. 
Hive,WITHOUT_CLASSIFICATION,//  Create the tez tmp dir and a directory for Hive resources. 
Hive,WITHOUT_CLASSIFICATION,//  TBL_TYPES 
Hive,WITHOUT_CLASSIFICATION,//  string NOT BETWEEN 
Hive,WITHOUT_CLASSIFICATION,//  Given that we are trying to reuse this session MUST be in some pool.sessions.   Kills that could have removed it must have cleared sessionToReuse. 
Hive,WITHOUT_CLASSIFICATION,//  rcfile write 
Hive,WITHOUT_CLASSIFICATION,//  Thread pool for taking entities off the wait queue. 
Hive,WITHOUT_CLASSIFICATION,//  Test string + double 
Hive,WITHOUT_CLASSIFICATION,//  Expected error: should throw java.security.cert.CertificateException 
Hive,WITHOUT_CLASSIFICATION,//  ip address size check - check for something better than non zero 
Hive,WITHOUT_CLASSIFICATION,//  return true when the child type and the conversion target type is the 
Hive,WITHOUT_CLASSIFICATION,//  1) Get valid txn list. 
Hive,WITHOUT_CLASSIFICATION,//  split do not include ; itself 
Hive,WITHOUT_CLASSIFICATION,//  Ignore exceptions from stop 
Hive,WITHOUT_CLASSIFICATION,//  one-time setup to make query able to run with Tez 
Hive,WITHOUT_CLASSIFICATION,//  Set high worker count so we get a longer queue. 
Hive,WITHOUT_CLASSIFICATION,//  Should we get all partitions for a partitioned table? 
Hive,WITHOUT_CLASSIFICATION,// if HiveConf has changed new object should be returned 
Hive,WITHOUT_CLASSIFICATION,//  By default we need the results from dropPartitions(); 
Hive,WITHOUT_CLASSIFICATION,//  A setVal with the same function signature as rightTrim leftTrim truncate etc below. 
Hive,WITHOUT_CLASSIFICATION,//  this vertex has multiple reduce operators 
Hive,WITHOUT_CLASSIFICATION,//  verify invalid column error 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#setReadOnly(boolean)    */
Hive,WITHOUT_CLASSIFICATION,//  Create client 
Hive,WITHOUT_CLASSIFICATION,/*      * use an array instead of only one object in case in future hive does not do     * the byte copy.      */
Hive,WITHOUT_CLASSIFICATION,//  Special case for unions. These items translate to VertexGroups 
Hive,WITHOUT_CLASSIFICATION,//  TODO HIVE-14042. Cleanup may be required if exiting early. 
Hive,WITHOUT_CLASSIFICATION,//  Note: this is a recursive struct 
Hive,WITHOUT_CLASSIFICATION,//  This should only be true for copy tasks created from functions otherwise there should never 
Hive,WITHOUT_CLASSIFICATION,//  when we have partial partitions specification we must assume partitions   lie in standard place - if they were in custom locations putting   them into one archive would involve mass amount of copying   in full partition specification case we allow custom locations 
Hive,WITHOUT_CLASSIFICATION,//  Someone is not done.   Both user and the kill have returned. 
Hive,WITHOUT_CLASSIFICATION,//  Map from PrimitiveTypeInfo to AbstractPrimitiveWritableObjectInspector. 
Hive,WITHOUT_CLASSIFICATION,//  Schedule a task - it should get the only duck; the 2nd one at the same pri doesn't get one.   When the first one finishes the duck goes to the 2nd and then becomes unused. 
Hive,WITHOUT_CLASSIFICATION,// -----------------------------------------------------------------------------------------------   Mutate operations.  ----------------------------------------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  2. Get Table Metadata 
Hive,WITHOUT_CLASSIFICATION,//  Adding them to restricted list. 
Hive,WITHOUT_CLASSIFICATION,//  Set this to read because we can't overwrite any existing partitions 
Hive,WITHOUT_CLASSIFICATION,//  Case 3.1 - Max in list members: 1000 Max query string length: 1KB and exact 1000 members in a single IN clause 
Hive,WITHOUT_CLASSIFICATION,//  Make the union operator 
Hive,WITHOUT_CLASSIFICATION,//  no stats/indexes 
Hive,WITHOUT_CLASSIFICATION,//  Field length is difference between positions hence one extra. 
Hive,WITHOUT_CLASSIFICATION,//  source table scan 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: we use JavaPrimitiveObjectInspector instead of   StandardPrimitiveObjectInspector 
Hive,WITHOUT_CLASSIFICATION,//  for consistency with tables. 
Hive,WITHOUT_CLASSIFICATION,//  These values come from setValueResult when it finds a key.  These values allow this 
Hive,WITHOUT_CLASSIFICATION,//  called at runtime to initialize the custom edge. 
Hive,WITHOUT_CLASSIFICATION,//  want to isolate any potential issue it may introduce. 
Hive,WITHOUT_CLASSIFICATION,//  Look for an unlikely database name and see if either MetaException or TException is thrown 
Hive,WITHOUT_CLASSIFICATION,//  we've reached our limit throw the last one. 
Hive,WITHOUT_CLASSIFICATION,//  since this test runs on local file system which does not have an API to tell if files or   open or not we are testing for negative case even though the bucket files are still open 
Hive,WITHOUT_CLASSIFICATION,//  The same id as reported by TaskRunnerCallable.getRequestId 
Hive,WITHOUT_CLASSIFICATION,//  months) produces a type date via a calendar calculation. 
Hive,WITHOUT_CLASSIFICATION,// create delta_0002_0002_0000 (can't push predicate) 
Hive,WITHOUT_CLASSIFICATION,/*  we don't want to cancel the delegation token if we think the callback is going to     to be retried for example because the job is not complete yet  */
Hive,WITHOUT_CLASSIFICATION,/*    * Config name used to find the number of concurrent requests.    */
Hive,WITHOUT_CLASSIFICATION,// do we need to add a connection status listener?  What will that do? 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Wrapper#isWrapperFor(java.lang.Class)    */
Hive,WITHOUT_CLASSIFICATION,//  this should be the case only if this is a create partition.   The privilege needed on the table should be ALTER_DATA and not CREATE 
Hive,WITHOUT_CLASSIFICATION,//  Use TCompactProtocol to read serialized TColumns 
Hive,WITHOUT_CLASSIFICATION,//  trivial case nothing to read. 
Hive,WITHOUT_CLASSIFICATION,//  Different table name 
Hive,WITHOUT_CLASSIFICATION,//  NULL 1 
Hive,WITHOUT_CLASSIFICATION,//  We gather the operators that will be used for next iteration of extended optimization 
Hive,WITHOUT_CLASSIFICATION,//  Series of equal keys. 
Hive,WITHOUT_CLASSIFICATION,//  register to session first for backward compatibility 
Hive,WITHOUT_CLASSIFICATION,//  EUROPE_FRANCE 
Hive,WITHOUT_CLASSIFICATION,//  most recent instance of the pmf 
Hive,WITHOUT_CLASSIFICATION,//  Figure out the partition spec from the input.   This is only done once for the first row (when stat == null)   since all rows in the same mapper should be from the same partition. 
Hive,WITHOUT_CLASSIFICATION,//  Regardless of the above we should have the key we've signed with. 
Hive,WITHOUT_CLASSIFICATION,//  fall-through to throw exception its not expected for execution to reach here. 
Hive,WITHOUT_CLASSIFICATION,//  all partition column type should be string   partition column is virtual column 
Hive,WITHOUT_CLASSIFICATION,//  All non-primitive OIs are writable so we need only check this case. 
Hive,WITHOUT_CLASSIFICATION,//  used only for explain. 
Hive,WITHOUT_CLASSIFICATION,// can't have relative path if there is scheme/authority 
Hive,WITHOUT_CLASSIFICATION,//  NULL 0 
Hive,WITHOUT_CLASSIFICATION,//  By definition here we copy up to the limit of the buffer. 
Hive,WITHOUT_CLASSIFICATION,//  temporary type-safe casting 
Hive,WITHOUT_CLASSIFICATION,/*    * Truncate a slice of a byte array to a maximum number of characters and   * place the result into element i of a vector.    */
Hive,WITHOUT_CLASSIFICATION,//  for split sampling. shrinkedLength is checked against IOContext.getCurrentBlockStart   which is from RecordReader.getPos(). So some inputformats which does not support getPos() 
Hive,WITHOUT_CLASSIFICATION,//  Previously this was handled by filterTableNames.  But it can't be anymore because we can no   longer depend on a 1-1 mapping between table name and entry in the list. 
Hive,WITHOUT_CLASSIFICATION,//  No nanos. 
Hive,WITHOUT_CLASSIFICATION,//  check if the new configs are added to HIVE_CONF_RESTRICTED_LIST 
Hive,WITHOUT_CLASSIFICATION,//  try dropping table as user1 - should succeed 
Hive,WITHOUT_CLASSIFICATION,//  the big table has reached a new key group. try to let the small tables 
Hive,WITHOUT_CLASSIFICATION,//  enable dynamic partitioning 
Hive,WITHOUT_CLASSIFICATION,//  integer and boolean types require no conversion so use a no-op 
Hive,WITHOUT_CLASSIFICATION,//  2. Use self alias 
Hive,WITHOUT_CLASSIFICATION,//  If a double quote is seen and the index is not inside a single quoted string and the previous character   was not an escape then update the hasUnterminatedDoubleQuote flag 
Hive,WITHOUT_CLASSIFICATION,//  localizing files for AM submitting DAG) 
Hive,WITHOUT_CLASSIFICATION,//  Set later with setOutput* methods. 
Hive,WITHOUT_CLASSIFICATION,//  If this is used in the future - make sure to disable grouping in the payload if it isn't already disabled 
Hive,WITHOUT_CLASSIFICATION,//  Get the string value and convert to a Interval value. 
Hive,WITHOUT_CLASSIFICATION,//  Try single stripe 
Hive,WITHOUT_CLASSIFICATION,//  ===== EVENT METHODS 
Hive,WITHOUT_CLASSIFICATION,//  Add the transformation that computes the lineage information. 
Hive,WITHOUT_CLASSIFICATION,//  Assumption:   1. This will be run last after PP Col Pruning in the PreJoinOrder   optimizations.   2. If ProjectRel is not synthetic then PPD would have already pushed   relevant pieces down and hence no point in running PPD again.   3. For synthetic Projects we don't care about non deterministic UDFs 
Hive,WITHOUT_CLASSIFICATION,//  Subscriber can get notification about addition of a database in HCAT   by listening on a topic named "HCAT" and message selector string   as "HCAT_EVENT = HCAT_ADD_DATABASE" 
Hive,WITHOUT_CLASSIFICATION,/*    * Returns {@code true} if such base file can be used to materialize the snapshot represented by   * this {@code ValidWriteIdList}.   * @param writeId highest write ID in a given base_xxxx file   * @return true if the base file can be used    */
Hive,WITHOUT_CLASSIFICATION,//  return 
Hive,WITHOUT_CLASSIFICATION,/*    * Update the VectorPTFDesc with data that is used during validation and that doesn't rely on   * VectorizationContext to lookup column names etc.    */
Hive,WITHOUT_CLASSIFICATION,// verify that a new sessionstate has default db 
Hive,WITHOUT_CLASSIFICATION,//  1) Add new vector child to the vector parent's children list. 
Hive,WITHOUT_CLASSIFICATION,//  rare case 
Hive,WITHOUT_CLASSIFICATION,//  Subclasses can override this step (for example for temporary tables) 
Hive,WITHOUT_CLASSIFICATION,//  sort is trivial 
Hive,WITHOUT_CLASSIFICATION,//  drop table is idempotent 
Hive,WITHOUT_CLASSIFICATION,// make sure to compare them as Entity i.e. that it's the same table or partition etc 
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.EntityDescriptorProto.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,//  boolean that tells if the HiveMetaStore (remote) server is being used.   Can be used to determine if the calls to metastore api (HMSHandler) are being made with   embedded metastore or a remote one 
Hive,WITHOUT_CLASSIFICATION,//  Verify that objectStore fetches the latest notification event ID 
Hive,WITHOUT_CLASSIFICATION,//  if list bucketing then bail out 
Hive,WITHOUT_CLASSIFICATION,//  Create a ColumnStatistics Obj 
Hive,WITHOUT_CLASSIFICATION,//  test that there is no lead second adjustment 
Hive,WITHOUT_CLASSIFICATION,//  store column name in map-work 
Hive,WITHOUT_CLASSIFICATION,//  get partition metadata 
Hive,WITHOUT_CLASSIFICATION,//  Should come back a null. 
Hive,WITHOUT_CLASSIFICATION,//  Format the properties statement 
Hive,WITHOUT_CLASSIFICATION,//  Test one random high-precision subtract. 
Hive,WITHOUT_CLASSIFICATION,//        calling close on an unopened session is probably harmless. 
Hive,WITHOUT_CLASSIFICATION,//  get the needed columns by id and name 
Hive,WITHOUT_CLASSIFICATION,//  Finally check the filter for non-built-in UDFs. If these are present we cannot 
Hive,WITHOUT_CLASSIFICATION,//  The output of the lateral view join will be the columns from the select   parent followed by the column from the UDTF parent 
Hive,WITHOUT_CLASSIFICATION,// compaction doesn't filter deltas but *may* have a reader for 'base' 
Hive,WITHOUT_CLASSIFICATION,// Testing substring index starting with 1 and zero length 
Hive,WITHOUT_CLASSIFICATION,// 0. SetOp rewrite 
Hive,WITHOUT_CLASSIFICATION,//  Everything in the batch has already been filtered out. 
Hive,WITHOUT_CLASSIFICATION,//  Inherent most properties from table level schema and overwrite some properties   in the following code.   This is mainly for saving CPU and memory to reuse the column names types and 
Hive,WITHOUT_CLASSIFICATION,//  source of replication not set 
Hive,WITHOUT_CLASSIFICATION,//  do bounds check for OOB exception 
Hive,WITHOUT_CLASSIFICATION,//  Count non-null column rows. 
Hive,WITHOUT_CLASSIFICATION,//  Logged at INFO in multiple other places. 
Hive,WITHOUT_CLASSIFICATION,//  Require ADMIN privilege 
Hive,WITHOUT_CLASSIFICATION,//  pos of outer join alias=<pos of other alias:num of filters on outer join alias>xn   for example   a left outer join b on a.k=b.k AND a.k>5 full outer join c on a.k=c.k AND a.k>10 AND c.k>20     That means on a(pos=0) there are overlapped filters associated with b(pos=1) and c(pos=2).   (a)b has one filter on a (a.k>5) and (a)c also has one filter on a (a.k>10)   making filter map for a as 0=1:1:2:1. 
Hive,WITHOUT_CLASSIFICATION,//  change file length and look for cache misses 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.CLIServiceClient#getTableTypes(org.apache.hive.service.cli.SessionHandle)    */
Hive,WITHOUT_CLASSIFICATION,//  Check that there is one datasource with the published segment 
Hive,WITHOUT_CLASSIFICATION,//  Special case (rare) - the segment is on buffer boundary. 
Hive,WITHOUT_CLASSIFICATION,//  Test translation of both IN filters and boolean-valued IN expressions (non-filters). 
Hive,WITHOUT_CLASSIFICATION,//  Ok this isn't one we track.  Just return whatever matches the string 
Hive,WITHOUT_CLASSIFICATION,//  represents the total memory that this Join operator will use if it is a MapJoin operator 
Hive,WITHOUT_CLASSIFICATION,//  One last test: if we are enabling the rewrite we need to check that query 
Hive,WITHOUT_CLASSIFICATION,// try an invalid alter table with partition key name 
Hive,WITHOUT_CLASSIFICATION,//  UDTF is not handled yet so the parent SelectOp of UDTF should just assume   all columns. 
Hive,WITHOUT_CLASSIFICATION,//  check delegation token in job conf if any 
Hive,WITHOUT_CLASSIFICATION,//  Test in upper case 
Hive,WITHOUT_CLASSIFICATION,//  Rollup and Cubes are syntactic sugar on top of grouping sets 
Hive,WITHOUT_CLASSIFICATION,//  8. We create the group_by operator 
Hive,WITHOUT_CLASSIFICATION,//  CBO related 
Hive,WITHOUT_CLASSIFICATION,//  we need plugins to handle llap and uber mode 
Hive,WITHOUT_CLASSIFICATION,//  Number the test rows with collection order. 
Hive,WITHOUT_CLASSIFICATION,//  To avoid long overflow we will divide the max row count by denominator   and use that factor to multiply with other row counts 
Hive,WITHOUT_CLASSIFICATION,//  For the CHAR and VARCHAR data types the maximum character length of   the columns.  Otherwise 0. 
Hive,WITHOUT_CLASSIFICATION,//  If none of the columns need to be cast there's no need for an additional select operator 
Hive,WITHOUT_CLASSIFICATION,//  limit * 64 : compensation of arrays for key/value/hashcodes 
Hive,WITHOUT_CLASSIFICATION,//  Junk after exponent. 
Hive,WITHOUT_CLASSIFICATION,//  super hack city notice the mod plus only happens after firstfield   hit so == 0 is right. 
Hive,WITHOUT_CLASSIFICATION,//  We will estimate map as an object (only if it's a field). 
Hive,WITHOUT_CLASSIFICATION,//  if after merge the sparse switching threshold is exceeded then change   to dense encoding 
Hive,WITHOUT_CLASSIFICATION,//  ObjectInspector for input data. 
Hive,WITHOUT_CLASSIFICATION,//  Same for char 
Hive,WITHOUT_CLASSIFICATION,//  Determine minimum of all non-null double column values; maintain isGroupResultNull. 
Hive,WITHOUT_CLASSIFICATION,/*  'smith' = last_name   */
Hive,WITHOUT_CLASSIFICATION,//  the reducer. 
Hive,WITHOUT_CLASSIFICATION,//  UNDONE: Trim trailing zeroes... 
Hive,WITHOUT_CLASSIFICATION,//  ERROR_MESSAGE 
Hive,WITHOUT_CLASSIFICATION,//  tableNames = client.listTableNamesByFilter(dbName filter (short) 2);   assertEquals(2 tableNames.size()); 
Hive,WITHOUT_CLASSIFICATION,//  all small aliases are staged.. no need full bucket context 
Hive,WITHOUT_CLASSIFICATION,//  Set so we can verify they are reset by operation 
Hive,WITHOUT_CLASSIFICATION,//  Should be no need for child vector expressions which would imply casting/conversion. 
Hive,WITHOUT_CLASSIFICATION,/*  * ELT(index string ....) returns the string column/expression value at the specified * index expression. * * The first argument expression indicates the index of the string to be retrieved from * remaining arguments.  We return NULL when the index number is less than 1 or * index number is greater than the number of the string arguments.  */
Hive,WITHOUT_CLASSIFICATION,//  there should be expectedCallCount calls to drop partitions with each batch size of 
Hive,WITHOUT_CLASSIFICATION,// First child should be operand 
Hive,WITHOUT_CLASSIFICATION,//  Insert the additional http headers 
Hive,WITHOUT_CLASSIFICATION,//  no jar is found. 
Hive,WITHOUT_CLASSIFICATION,//  ROW 
Hive,WITHOUT_CLASSIFICATION,//  log4j2 
Hive,WITHOUT_CLASSIFICATION,// case 3: verify the difference. 
Hive,WITHOUT_CLASSIFICATION,//  as we process the grouping sets. 
Hive,WITHOUT_CLASSIFICATION,//  we do not need to apply the optimization 
Hive,WITHOUT_CLASSIFICATION,//  optional   required   required 
Hive,WITHOUT_CLASSIFICATION,//  A noop if we are in process of sending or if we have the correct value. 
Hive,WITHOUT_CLASSIFICATION,//  last param no complete 
Hive,WITHOUT_CLASSIFICATION,//  sparse registers are delta and variable length encoded 
Hive,WITHOUT_CLASSIFICATION,//  when we are running current query 
Hive,WITHOUT_CLASSIFICATION,//  ----------------------------------------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,// it seems that LoadTableDesc has Operation.INSERT only for CTAS... 
Hive,WITHOUT_CLASSIFICATION,//  unexpected! 
Hive,WITHOUT_CLASSIFICATION,//  This position is a constant. 
Hive,WITHOUT_CLASSIFICATION,//  we use the default field delimiter('\1') to replace the multiple-char field delimiter   but we cannot use it to parse the row since column data can contain '\1' as well 
Hive,WITHOUT_CLASSIFICATION,//  One call per root Input 
Hive,WITHOUT_CLASSIFICATION,//  check the inspectors 
Hive,WITHOUT_CLASSIFICATION,//  Use Case 11. 
Hive,WITHOUT_CLASSIFICATION,//  Only columns can be selected for both sorted and bucketed positions 
Hive,WITHOUT_CLASSIFICATION,//  entry point (aliasNum = 0) 
Hive,WITHOUT_CLASSIFICATION,//  we need the expr that generated the key of the reduce sink 
Hive,WITHOUT_CLASSIFICATION,//  Add to cache (same group as tsOp) 
Hive,WITHOUT_CLASSIFICATION,//  Use Case 7. 
Hive,WITHOUT_CLASSIFICATION,//  NodeId can be null if the task gets unregistered due to failure / being killed by the daemon itself 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#getTransactionIsolation()    */
Hive,WITHOUT_CLASSIFICATION,//  col2 
Hive,WITHOUT_CLASSIFICATION,//  if both old and new params are not null merge them 
Hive,WITHOUT_CLASSIFICATION,//  Reserve space for the int length. 
Hive,WITHOUT_CLASSIFICATION,//  executeQuery should always throw a SQLException 
Hive,WITHOUT_CLASSIFICATION,//  Intentionally overwrites anything the user may have put here 
Hive,WITHOUT_CLASSIFICATION,//  false for continue : has pair but not in this turn 
Hive,WITHOUT_CLASSIFICATION,//  replace original STDDEV_POP(x) with     SQRT(       (SUM(x * x) - SUM(x) * SUM(x) / COUNT(x))       / COUNT(x)) 
Hive,WITHOUT_CLASSIFICATION,// not to be confused with useVectorizedInputFileFormat at Vectorizer level  which represents the value of configuration hive.vectorized.use.vectorized.input.format 
Hive,WITHOUT_CLASSIFICATION,//  Try the different getters 
Hive,WITHOUT_CLASSIFICATION,//  convert as such. 
Hive,WITHOUT_CLASSIFICATION,//  physical optimizer stages... 
Hive,WITHOUT_CLASSIFICATION,// now that exceptions (aka abortedTxnList) is sorted 
Hive,WITHOUT_CLASSIFICATION,//  BLOCKED_BY_INT_ID 
Hive,WITHOUT_CLASSIFICATION,//  First try to reuse from the same pool - should "just work". 
Hive,WITHOUT_CLASSIFICATION,//  for those stmtHandle passed from HiveDatabaseMetaData instead of Statement 
Hive,WITHOUT_CLASSIFICATION,//  Bail out if there is nothing to push 
Hive,WITHOUT_CLASSIFICATION,//  test dropping tables and trash behavior 
Hive,WITHOUT_CLASSIFICATION,//  insert some data in new schema 
Hive,WITHOUT_CLASSIFICATION,//  ** Methods that does not need a data object ** 
Hive,WITHOUT_CLASSIFICATION,//  row id 
Hive,WITHOUT_CLASSIFICATION,//  col1 
Hive,WITHOUT_CLASSIFICATION,//  Perform any key expressions.  Results will go into scratch columns. 
Hive,WITHOUT_CLASSIFICATION,/*      * 2. initialize WFns.      */
Hive,WITHOUT_CLASSIFICATION,//  Uses a no-op proxy 
Hive,WITHOUT_CLASSIFICATION,//  orc creates 1000 batch size to make memory check align with 5000 instead of 5120 
Hive,WITHOUT_CLASSIFICATION,/*    * Initialize using an StructObjectInspector.   * No projection -- the column range 0 .. fields.size()-1    */
Hive,WITHOUT_CLASSIFICATION,//  private void writeObject(ObjectOutputStream out) throws IOException {   out.writeObject(types_by_column_name);   out.writeObject(ordered_types);   } 
Hive,WITHOUT_CLASSIFICATION,//  create a file with 5 blocks spread around the cluster 
Hive,WITHOUT_CLASSIFICATION,//  It is possible that the row got absorbed in the operator tree. 
Hive,WITHOUT_CLASSIFICATION,// supports AcidInputFormat which do not use the KEY pass ROW__ID info 
Hive,WITHOUT_CLASSIFICATION,//  check that right row(s) are selected 
Hive,WITHOUT_CLASSIFICATION,//        cluster state changes it will notify us and we'd update the queries again. 
Hive,WITHOUT_CLASSIFICATION,//  Request two messages 
Hive,WITHOUT_CLASSIFICATION,// If coming from small-table side do some book-keeping and skip traversal. 
Hive,WITHOUT_CLASSIFICATION,//  If serialization.format property has the default value it will not to be included in   SERDE properties 
Hive,WITHOUT_CLASSIFICATION,// first try full match 
Hive,WITHOUT_CLASSIFICATION,//  Join key origin has been traced to a table column. Check if the table is external. 
Hive,WITHOUT_CLASSIFICATION,//  Write the remaining part of the array 
Hive,WITHOUT_CLASSIFICATION,//  for outer joins contains the potential nulls for the concerned aliases 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#executeUpdate(java.lang.String int)    */
Hive,WITHOUT_CLASSIFICATION,//  Ok to not lock the list for this and use a volatile lastAccessTime instead 
Hive,WITHOUT_CLASSIFICATION,//  created in case the mapjoin failed. 
Hive,WITHOUT_CLASSIFICATION,//  table should not be null. 
Hive,WITHOUT_CLASSIFICATION,//  Constant from Accumulo's AuthenticationTokenIdentifier 
Hive,WITHOUT_CLASSIFICATION,//  one to produce these will be the same as using any other. 
Hive,WITHOUT_CLASSIFICATION,//  drop the table first in case some previous test created it 
Hive,WITHOUT_CLASSIFICATION,//  PASS 
Hive,WITHOUT_CLASSIFICATION,//  The base composite-service is already stopped don't do anything again. 
Hive,WITHOUT_CLASSIFICATION,//  Run ExecDriver in another JVM 
Hive,WITHOUT_CLASSIFICATION,// now start concurrent "select * from tab1" txn 
Hive,WITHOUT_CLASSIFICATION,//  Check there is no log file without the suffix 
Hive,WITHOUT_CLASSIFICATION,//  2. Update Col Stats Map with col stats for columns from right side of 
Hive,WITHOUT_CLASSIFICATION,//  rc will only be overwritten if close errors out 
Hive,WITHOUT_CLASSIFICATION,//  If cred provider has entry and conf does not cred provider is used. 
Hive,WITHOUT_CLASSIFICATION,//  SR.E: Lock we are examining is exclusive 
Hive,WITHOUT_CLASSIFICATION,//  this entry of output is not present in the output schema   so we first check the table schema to see if it is a part col 
Hive,WITHOUT_CLASSIFICATION,//  Fetch the column expression. There should be atleast one. 
Hive,WITHOUT_CLASSIFICATION,// this should block behind the X lock on  T6 
Hive,WITHOUT_CLASSIFICATION,//  Default to all of user's authorizations when no configuration is provided 
Hive,WITHOUT_CLASSIFICATION,// Publish the new partition(s) 
Hive,WITHOUT_CLASSIFICATION,//  IncrementalRows constructor should buffer the first "incrementalBufferRows" rows 
Hive,WITHOUT_CLASSIFICATION,//  TODO constraintCache 
Hive,WITHOUT_CLASSIFICATION,//  Job Hash Map 
Hive,WITHOUT_CLASSIFICATION,//  The object was added later for the same class; see addToProcessing. 
Hive,WITHOUT_CLASSIFICATION,//  Now do the add with Java BigDecimal 
Hive,WITHOUT_CLASSIFICATION,//  parts of the partition 
Hive,WITHOUT_CLASSIFICATION,//  LazySimple seems to work better with an row object array instead of a Java object... 
Hive,WITHOUT_CLASSIFICATION,//  Timeseries query results as records 
Hive,WITHOUT_CLASSIFICATION,//  Create remote dirs once. 
Hive,WITHOUT_CLASSIFICATION,// To change body of overridden methods use File | Settings | File Templates. 
Hive,WITHOUT_CLASSIFICATION,//  spot check null propagation 
Hive,WITHOUT_CLASSIFICATION,//  if we have a base to work from 
Hive,WITHOUT_CLASSIFICATION,//  add to list of saved historic operations 
Hive,WITHOUT_CLASSIFICATION,//  Basic sanity check. Other cases are not skipped because it is similar to the case for Long. 
Hive,WITHOUT_CLASSIFICATION,//  number of spilled partitions   only one (last one) partition is left in memory   how often (# of rows apart) to check if memory is full   configuration for n-way join   write buffer size for BytesBytesMultiHashMap 
Hive,WITHOUT_CLASSIFICATION,//  Reader will check for the event queue upon the end of the input stream - no need to interrupt. 
Hive,WITHOUT_CLASSIFICATION,/*      * Populate vectorMapJoininfo.      */
Hive,WITHOUT_CLASSIFICATION,//  Constructor to with the individual addInitialColumn method 
Hive,WITHOUT_CLASSIFICATION,//  Ignore Index tables those will be dropped with parent tables 
Hive,WITHOUT_CLASSIFICATION,//  A helper object that efficiently copies the big table key columns (input or key expressions) 
Hive,WITHOUT_CLASSIFICATION,//  remember the event operators we've seen 
Hive,WITHOUT_CLASSIFICATION,//  First we find the SELECT closest to the top. 
Hive,WITHOUT_CLASSIFICATION,//  If we join on different keys on different tables we can no longer apply   multi-join conversion as this is no longer a valid star join.   Bail out if this is the case. 
Hive,WITHOUT_CLASSIFICATION,//  For spark job with empty source data it's not submitted actually so we would never   receive JobStart/JobEnd event in JobStateListener use JavaFutureAction to get current   job state. 
Hive,WITHOUT_CLASSIFICATION,//  HIVE-4889 
Hive,WITHOUT_CLASSIFICATION,//  Read the altered "tbl" via CachedStore 
Hive,WITHOUT_CLASSIFICATION,//  now add the keywords from the current connection 
Hive,WITHOUT_CLASSIFICATION,//  If owner information is unchanged then DB properties would've changed 
Hive,WITHOUT_CLASSIFICATION,//  Currently SMB is broken so we cannot check if it's  compatible with IO elevator.   So we don't use the below code that would get the correct MapWork. See HIVE-16985. 
Hive,WITHOUT_CLASSIFICATION,// we are compacting and it's acid schema so create a reader for the 1st bucket file that is not empty 
Hive,WITHOUT_CLASSIFICATION,//  If it is not a materialized view we do not rewrite it 
Hive,WITHOUT_CLASSIFICATION,//  Tailing zeroes difference ok... 
Hive,WITHOUT_CLASSIFICATION,//  Check columns. 
Hive,WITHOUT_CLASSIFICATION,//  Closing the operator can sometimes yield more rows (HIVE-11892) 
Hive,WITHOUT_CLASSIFICATION,/*          * Extract information from reference word from slot table.          */
Hive,WITHOUT_CLASSIFICATION,//  optional int64 delete_delay = 2 [default = 0]; 
Hive,WITHOUT_CLASSIFICATION,//  Note that the pool is per EDC - within EDC CVBs are expected to have the same schema. 
Hive,WITHOUT_CLASSIFICATION,//  Extract type for the arguments 
Hive,WITHOUT_CLASSIFICATION,//  This is expected to fail. 
Hive,WITHOUT_CLASSIFICATION,//  restrict with any filters found from WHERE predicates. 
Hive,WITHOUT_CLASSIFICATION,//  After this optimization the tree should be like:    TS -> (FIL "skewed rows") * -> RS -                                       \                                         ->   JOIN                                       /           \    TS -> (FIL "skewed rows") * -> RS -             \                                                     \                                                       ->  UNION -> ..                                                     /    TS -> (FIL "no skewed rows") * -> RS -          /                                          \        /                                           -> JOIN                                          /    TS -> (FIL "no skewed rows") * -> RS -   
Hive,WITHOUT_CLASSIFICATION,//  for windows paths 
Hive,WITHOUT_CLASSIFICATION,// user running the test belongs to 
Hive,WITHOUT_CLASSIFICATION,//  Set the collection fields; some code might not check presence before accessing them. 
Hive,WITHOUT_CLASSIFICATION,//  replace each of the position alias in GROUPBY with the actual column name 
Hive,WITHOUT_CLASSIFICATION,//  If old table is in the cache and the new table can also be cached 
Hive,WITHOUT_CLASSIFICATION,//  Multiple threads could try to initialize at the same time. 
Hive,WITHOUT_CLASSIFICATION,//  if number of elements in list cannot be determined this value will be used 
Hive,WITHOUT_CLASSIFICATION,/*          * Default any additional data columns to NULL once for the file (if they are present).          */
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) ConstMap  */
Hive,WITHOUT_CLASSIFICATION,/*      * Do common analysis of the IF statement boolean expression.     *     * The following protected members can be examined afterwards:     *     *   boolean isIfStatementResultRepeated     *   boolean isIfStatementResultThen     *     *   int thenSelectedCount     *   int[] thenSelected     *   int elseSelectedCount     *   int[] elseSelected      */
Hive,WITHOUT_CLASSIFICATION,//  create db 
Hive,WITHOUT_CLASSIFICATION,//                    12345678901234567890123456789012345678                              1         2         3 
Hive,WITHOUT_CLASSIFICATION,//  add the following strings:   1. column name   2. table name   3. tablename.columnname 
Hive,WITHOUT_CLASSIFICATION,//  pRS-cRS-cGBY 
Hive,WITHOUT_CLASSIFICATION,//  First we remove the input operators of the expression that 
Hive,WITHOUT_CLASSIFICATION,//  Row column information. 
Hive,WITHOUT_CLASSIFICATION,//  For now we always convert to double if we can't find a common type 
Hive,WITHOUT_CLASSIFICATION,//  Create default route 
Hive,WITHOUT_CLASSIFICATION,/*  Validate skewed information.  */
Hive,WITHOUT_CLASSIFICATION,//  Insert the value corresponding to the current expression in currExprNodeInfo.exprNodeValues. 
Hive,WITHOUT_CLASSIFICATION,//  We should technically update memory usage if updating the old object but we don't do it   for now; there is no mechanism to properly notify the cache policy/etc. wrt parallel evicts. 
Hive,WITHOUT_CLASSIFICATION,//  If the data is not escaped reference the data directly. 
Hive,WITHOUT_CLASSIFICATION,//  at some point these should be inserted as a "db" 
Hive,WITHOUT_CLASSIFICATION,//  replace the original selectOp in the parents with selectUnionOp 
Hive,WITHOUT_CLASSIFICATION,//  Create a new conf object to bypass metastore authorization as we need to   retrieve all materialized views from all databases 
Hive,WITHOUT_CLASSIFICATION,//  asc   nulls first 
Hive,WITHOUT_CLASSIFICATION,//  authorize this call on the schema objects 
Hive,WITHOUT_CLASSIFICATION,//  Data structures 
Hive,WITHOUT_CLASSIFICATION,//  First time registration or new register comes in before the previous unregister. 
Hive,WITHOUT_CLASSIFICATION,//  We rely on the caller to supply a reasonable total; we could log a warning   if this doesn't match the allocation of the last session beyond some threshold. 
Hive,WITHOUT_CLASSIFICATION,//  Shouldn't hit 14 digits until year 2286 
Hive,WITHOUT_CLASSIFICATION,//  The column has been read from disk. 
Hive,WITHOUT_CLASSIFICATION,//  reset value in case any date fields are missing from the date pattern 
Hive,WITHOUT_CLASSIFICATION,//  Handle dual nature. 
Hive,WITHOUT_CLASSIFICATION,//  test nulls propagation 
Hive,WITHOUT_CLASSIFICATION,//  Clone the table 
Hive,WITHOUT_CLASSIFICATION,// Check metrics during semantic analysis. 
Hive,WITHOUT_CLASSIFICATION,//  print out last part of buffer 
Hive,WITHOUT_CLASSIFICATION,//  find the extra table 
Hive,WITHOUT_CLASSIFICATION,//  Offset relative to the beginning of the stream of where this RG ends. 
Hive,WITHOUT_CLASSIFICATION,//  required   optional   optional   optional   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  Based on update() above. 
Hive,WITHOUT_CLASSIFICATION,//  This is the overwrite case we do not care about the accuracy. 
Hive,WITHOUT_CLASSIFICATION,//  The only allowed flag is new-alloc and that only if we are not discarding. 
Hive,WITHOUT_CLASSIFICATION,//  for left-semi join generate an additional selection & group-by   operator before ReduceSink 
Hive,WITHOUT_CLASSIFICATION,//  Attempt to match Oracle semantics for timestamp arithmetic   where timestamp arithmetic is done in UTC then converted back to local timezone 
Hive,WITHOUT_CLASSIFICATION,//  If the table's location is currently unset it is left unset allowing the metastore to   fill in the table's location.   Note that the previous logic for some reason would make a special case if the DB was the   default database and actually attempt to generate a  location.   This seems incorrect and uncessary since the metastore is just as able to fill in the   default table location in the case of the default DB as it is for non-default DBs. 
Hive,WITHOUT_CLASSIFICATION,//  end ListIterator 
Hive,WITHOUT_CLASSIFICATION,//  since metastore connections don't require the url this is allowable. 
Hive,WITHOUT_CLASSIFICATION,//  UGI information is not available at connection setup time it will be set later   via set_ugi() rpc. 
Hive,WITHOUT_CLASSIFICATION,/*        * Sleep until all threads with clean up tasks are completed. 2 seconds completing task       * and 1 sec grace period.        */
Hive,WITHOUT_CLASSIFICATION,//  makes the message more informative - helps to find bugs in client code 
Hive,WITHOUT_CLASSIFICATION,//  get ObjInspectors for entire record and bucketed cols 
Hive,WITHOUT_CLASSIFICATION,//  Anything else is a FAIL. 
Hive,WITHOUT_CLASSIFICATION,//  Note: CopyWork supports copying multiple files but ReplCopyWork doesn't. 
Hive,WITHOUT_CLASSIFICATION,// 1 split since mutateTransaction txn just does deletes 
Hive,WITHOUT_CLASSIFICATION,/*  For the case when the output can have null values follow     * the convention that the data values must be 1 for long and     * NaN for double. This is to prevent possible later zero-divide errors     * in complex arithmetic expressions like col2 % (col1 - 1)     * in the case when some col1 entries are null.      */
Hive,WITHOUT_CLASSIFICATION,//  Set needed columns for this dummy TableScanOperator 
Hive,WITHOUT_CLASSIFICATION,//  UNDONE: Provide isRepeated selected isNull 
Hive,WITHOUT_CLASSIFICATION,//  Catch the exception caused by missing jpam.so which otherwise would   crashes the thread and causes the client hanging rather than notifying   the client nicely 
Hive,WITHOUT_CLASSIFICATION,//  now localTask is the parent task of the current task 
Hive,WITHOUT_CLASSIFICATION,//  Confirm grouping. 
Hive,WITHOUT_CLASSIFICATION,//  One scheduler pass from the nodes that are added at startup 
Hive,WITHOUT_CLASSIFICATION,//  normalize the columns sizes 
Hive,WITHOUT_CLASSIFICATION,//  Validate the third parameter which should be an integer to represent 'k' 
Hive,WITHOUT_CLASSIFICATION,/*  move the last 16 bytes to the prefix area  */
Hive,WITHOUT_CLASSIFICATION,//  waitOnPrecursor determines whether or not non-existence of   a dependent object is an error. For regular imports it is.   for now the only thing this affects is whether or not the   db exists. 
Hive,WITHOUT_CLASSIFICATION,//  "AVG_DECIMAL" 
Hive,WITHOUT_CLASSIFICATION,//  This is the min number of reducer(s) for the bottom layer ReduceSinkOperators to avoid query 
Hive,WITHOUT_CLASSIFICATION,//  Run load on primary itself 
Hive,WITHOUT_CLASSIFICATION,//  Verify we hit an error while connecting 
Hive,WITHOUT_CLASSIFICATION,//  flag for bucket map join. One usage is to set BucketizedHiveInputFormat 
Hive,WITHOUT_CLASSIFICATION,//  We are here when the left and right are non-zero and have the same sign. 
Hive,WITHOUT_CLASSIFICATION,//  bit packing 
Hive,WITHOUT_CLASSIFICATION,// replace ${hiveconf:hive.metastore.warehouse.dir} with actual dir if existed.  we only want the absolute path so remove the header such as hdfs://localhost:57145 
Hive,WITHOUT_CLASSIFICATION,//  Forgive error 
Hive,WITHOUT_CLASSIFICATION,//  A mapping once established is not dependent upon the file channel that was used to   create it. delete file and hold onto the map 
Hive,WITHOUT_CLASSIFICATION,//  for each dir get all files under the dir do getSplits to each   individual file   and then create a BucketizedHiveInputSplit on it 
Hive,WITHOUT_CLASSIFICATION,// ValidWriteIdList with HWM=MAX_LONG i.e. include the data for aborted txn 
Hive,WITHOUT_CLASSIFICATION,//  3. Insert ReduceSide GB 
Hive,WITHOUT_CLASSIFICATION,//  if this is a selStarNoCompute then this select operator   is treated like a default operator so just call the super classes   process method. 
Hive,WITHOUT_CLASSIFICATION,//  a array of bitvectors where each entry denotes whether the element is to   be used or not (whether it is null or not). The size of the bitvector is   same as the number of inputs(aliases) under consideration currently. 
Hive,WITHOUT_CLASSIFICATION,//  Hadoop IPC wraps InterruptedException. GRRR. 
Hive,WITHOUT_CLASSIFICATION,//  Intended predicate to be removed 
Hive,WITHOUT_CLASSIFICATION,//  Adds tables only for create view (PPD filter can be appended by outer query) 
Hive,WITHOUT_CLASSIFICATION,//  only vectorized orc input is cached. so there's a reason to 
Hive,WITHOUT_CLASSIFICATION,// we use the same mechanism to copy "files"/"otherFiles" and "libdir" but we only want to put  contents of "libdir" in Sqoop/lib thus we pass the list of names here 
Hive,WITHOUT_CLASSIFICATION,//  this must be lead/lag UDAF 
Hive,WITHOUT_CLASSIFICATION,//  Allocated 
Hive,WITHOUT_CLASSIFICATION,//  Trim trailing zeroes -- but only below the decimal point. 
Hive,WITHOUT_CLASSIFICATION,//  Unlikely to be thrown. 
Hive,WITHOUT_CLASSIFICATION,//  We need to make sure that the list element type is settable. 
Hive,WITHOUT_CLASSIFICATION,//  Create database without location clause 
Hive,WITHOUT_CLASSIFICATION,//  c21-c23 
Hive,WITHOUT_CLASSIFICATION,//  The query has enforced that a sort-merge join should be performed.   For more details look at 'removedReduceSinkBucketSort' in FileSinkDesc.java 
Hive,WITHOUT_CLASSIFICATION,//  That is always true now; but it wasn't some day the below would throw in getColumnData. 
Hive,WITHOUT_CLASSIFICATION,//  Allow debugging by disabling column reuse (input cols are never reused by design only 
Hive,WITHOUT_CLASSIFICATION,//  A field because we cannot multi-inherit. 
Hive,WITHOUT_CLASSIFICATION,//  Kill previously launched child MR jobs started by this launcher to prevent having 
Hive,WITHOUT_CLASSIFICATION,//  test delete column stats; if no col name is passed all column stats associated with the 
Hive,WITHOUT_CLASSIFICATION,//  These need to be based on the target. 
Hive,WITHOUT_CLASSIFICATION,//  First kill any running MR jobs 
Hive,WITHOUT_CLASSIFICATION,//  private BinarySortableDeserializeRead keyBinarySortableDeserializeRead; 
Hive,WITHOUT_CLASSIFICATION,//  if the return type of the GenericUDF is boolean and all partitions agree on   a result we update the state of the node to be TRUE of FALSE 
Hive,WITHOUT_CLASSIFICATION,//  Synchronize on the cache entry so that no one else can invalidate this entry 
Hive,WITHOUT_CLASSIFICATION,//  Fraction digit parsing move to next lower longword. 
Hive,WITHOUT_CLASSIFICATION,//  If one of the children (left or right) is:   (i) a union or   (ii) an identity projection followed by a union   merge with it 
Hive,WITHOUT_CLASSIFICATION,//  now that the primary reader has advanced we need to see if we 
Hive,WITHOUT_CLASSIFICATION,//  This cache range is a prefix of the requested one; the above also applies.   The cache may still contain the rest of the requested range so don't set gotAllData. 
Hive,WITHOUT_CLASSIFICATION,//  Setup stdout and stderr 
Hive,WITHOUT_CLASSIFICATION,//  Note: scratchdir is reused implicitly because the sessionId is the same. 
Hive,WITHOUT_CLASSIFICATION,//  the value has a schema and not a FieldSchema 
Hive,WITHOUT_CLASSIFICATION,//  validate sort columns and bucket columns 
Hive,WITHOUT_CLASSIFICATION,//  LLAP cache can be disabled via config or isPlanCache 
Hive,WITHOUT_CLASSIFICATION,//  If does not contain a limit operation we bail out 
Hive,WITHOUT_CLASSIFICATION,//  outside of [0..20] range 
Hive,WITHOUT_CLASSIFICATION,//  Correlate does not have an ON clause.   For a LEFT correlate predicate must be evaluated first.   For INNER we can defer. 
Hive,WITHOUT_CLASSIFICATION,//  partCount not equally divided into batches.  last batch size will be less than batch size 
Hive,WITHOUT_CLASSIFICATION,//  Suppress leading zeroes. 
Hive,WITHOUT_CLASSIFICATION,//  Extra element to make sure we have the same formula to compute the   length of each element of the array. 
Hive,WITHOUT_CLASSIFICATION,//  The other list doesn't exist create it at the first index of our op. 
Hive,WITHOUT_CLASSIFICATION,//  We have statistics for the table. Size appropriately. 
Hive,WITHOUT_CLASSIFICATION,//  Add original direcotries to obsolete list if any 
Hive,WITHOUT_CLASSIFICATION,//  The context for creating the VectorizedRowBatch for this Map node that   the Vectorizer class determined. 
Hive,WITHOUT_CLASSIFICATION,//  if DP is enabled get the final output writers and prepare the real output row 
Hive,WITHOUT_CLASSIFICATION,// register JVM metrics 
Hive,WITHOUT_CLASSIFICATION,//  Lock was outdated and it was removed (then maybe another transaction picked it up)   or changed its state 
Hive,WITHOUT_CLASSIFICATION,//  Skip combine for all paths 
Hive,WITHOUT_CLASSIFICATION,/*  Test decimal column to decimal scalar division. This is used to cover all the   * cases used in the source code template ColumnDivideScalarDecimal.txt.   * The template is used for division and modulo.    */
Hive,WITHOUT_CLASSIFICATION,//  Normal case no variable-length arguments 
Hive,WITHOUT_CLASSIFICATION,//  Account for potential partial chunks. 
Hive,WITHOUT_CLASSIFICATION,//  groupingId = PrimitiveObjectInspectorUtils.getInt(arguments[0].get() groupingIdOI); 
Hive,WITHOUT_CLASSIFICATION,//  Register the pending events to be sent for this spec. 
Hive,WITHOUT_CLASSIFICATION,//  Get the id for the next entry in the queue 
Hive,WITHOUT_CLASSIFICATION,//  This method takes Object[] so it accepts whatever types that are   passed in. 
Hive,WITHOUT_CLASSIFICATION,/*  Just copy the payload.  {@link recordIdColumnVector} has already been populated  */
Hive,WITHOUT_CLASSIFICATION,//  matching Oracle behavior. 
Hive,WITHOUT_CLASSIFICATION,//  For ORC case send the boundaries of the stripes so we don't have to send the footer. 
Hive,WITHOUT_CLASSIFICATION,//  convert skewData to contain ExprNodeDesc in the keys 
Hive,WITHOUT_CLASSIFICATION,//  The cost of the result 
Hive,WITHOUT_CLASSIFICATION,//  When people forget to quote a string op1/op2 is null.   For example select * from some_table where ds > 2012-12-1 and ds < 2012-12-2 . 
Hive,WITHOUT_CLASSIFICATION,//  fetch the table marked by the message and compare 
Hive,WITHOUT_CLASSIFICATION,//  For now this only is used to determine the bucketing/sorting of outputs in the future   this can be removed to optimize the query plan based on the bucketing/sorting properties 
Hive,WITHOUT_CLASSIFICATION,//  Re-align the positionMap by -1 for the columns appearing after hcatFieldSchema. 
Hive,WITHOUT_CLASSIFICATION,//  A very simple counter to keep track of number of rows processed by an   operator. It dumps   every 1 million times and quickly before that 
Hive,WITHOUT_CLASSIFICATION,//  for non partitioned table this will represent the last tableName replicated else its the name of the 
Hive,WITHOUT_CLASSIFICATION,//  logging inside 
Hive,WITHOUT_CLASSIFICATION,//  Cache key 
Hive,WITHOUT_CLASSIFICATION,//  first try known drivers... 
Hive,WITHOUT_CLASSIFICATION,//  Cache size should be 0 now 
Hive,WITHOUT_CLASSIFICATION,//  test Feb of leap year 2/29 
Hive,WITHOUT_CLASSIFICATION,/*  Submits the request and returns  */
Hive,WITHOUT_CLASSIFICATION,//  crtTblDesc 
Hive,WITHOUT_CLASSIFICATION,//  Mapping from constraint name to list of default constraints 
Hive,WITHOUT_CLASSIFICATION,//  Some keys need to be left to null corresponding to that grouping set. 
Hive,WITHOUT_CLASSIFICATION,//  Write cost 
Hive,WITHOUT_CLASSIFICATION,// die! 
Hive,WITHOUT_CLASSIFICATION,//  remove this branch 
Hive,WITHOUT_CLASSIFICATION,//  A synonym in some places in the code... 
Hive,WITHOUT_CLASSIFICATION,//  No padding needed. 
Hive,WITHOUT_CLASSIFICATION,//  so the operation is atomic. 
Hive,WITHOUT_CLASSIFICATION,//  We need to check if the total size of local tables is under the limit.   At here we are using a strong condition which is the total size of   local tables used by all input paths. Actually we can relax this condition   to check the total size of local tables for every input path.   Example:                 UNION_ALL                /         \               /           \              /             \             /               \         MapJoin1          MapJoin2        /   |   \         /   |   \       /    |    \       /    |    \     Big1   S1   S2    Big2   S3   S4   In this case we have two MapJoins MapJoin1 and MapJoin2. Big1 and Big2 are two   big tables and S1 S2 S3 and S4 are four small tables. Hash tables of S1 and S2   will only be used by Map tasks processing Big1. Hash tables of S3 and S4 will only   be used by Map tasks processing Big2. If Big1!=Big2 we should only check if the size   of S1 + S2 is under the limit and if the size of S3 + S4 is under the limit.   But right now we are checking the size of S1 + S2 + S3 + S4 is under the limit.   If Big1=Big2 we will only scan a path once. So MapJoin1 and MapJoin2 will be executed   in the same Map task. In this case we need to make sure the size of S1 + S2 + S3 + S4 
Hive,WITHOUT_CLASSIFICATION,//  initialize the keys and values 
Hive,WITHOUT_CLASSIFICATION,//  Enabled to accept quoting of all character backslash qooting mechanism 
Hive,WITHOUT_CLASSIFICATION,//  If user has fully specified partition validate that partition exists 
Hive,WITHOUT_CLASSIFICATION,//  Is the user trying to insert into a external tables 
Hive,WITHOUT_CLASSIFICATION,//  However the fastBigIntegerBytes can take on trailing zeroes -- so make it larger. 
Hive,WITHOUT_CLASSIFICATION,//  create table 
Hive,WITHOUT_CLASSIFICATION,//  Stub out the ZKI mock 
Hive,WITHOUT_CLASSIFICATION,//  Check based on the Hive integer type we need to test with isByte isShort isInt isLong   so we do not use corrupted (truncated) values for the Hive integer type. 
Hive,WITHOUT_CLASSIFICATION,//  re-open the hms connection 
Hive,WITHOUT_CLASSIFICATION,//  Whether this OI is for the column-level schema (as opposed to nested column fields). 
Hive,WITHOUT_CLASSIFICATION,//  remember the event operators we've abandoned. 
Hive,WITHOUT_CLASSIFICATION,//  base tables set up let's replicate them over 
Hive,WITHOUT_CLASSIFICATION,//  Convert from bucket map join to sort merge bucket map join if enabled. 
Hive,WITHOUT_CLASSIFICATION,//  doesn't require additional MR Jobs 
Hive,WITHOUT_CLASSIFICATION,//  If input produces correlated variables move them to the front   right after any existing GROUP BY fields. 
Hive,WITHOUT_CLASSIFICATION,/*      * 1. initialize args      */
Hive,WITHOUT_CLASSIFICATION,//  Must use raw local because the checksummer doesn't honor flushes. 
Hive,WITHOUT_CLASSIFICATION,/*  a and b shouldn't be even; If a and b are even then none of the values       * will set bit 0 thus introducing errors in the estimate. Both a and b can be even       * 25% of the times and as a result 25% of the bit vectors could be inaccurate. To avoid this       * always pick odd values for a and b.        */
Hive,WITHOUT_CLASSIFICATION,//  validate the (materialized) view statement 
Hive,WITHOUT_CLASSIFICATION,// Update JobConf using MRInput info like filename comes via this 
Hive,WITHOUT_CLASSIFICATION,//  best effort attempt to write all output from the script before marking the operator 
Hive,WITHOUT_CLASSIFICATION,//  Assumes row schema => stringintstring 
Hive,WITHOUT_CLASSIFICATION,//  Get max split size for HiveRelMdParallelism 
Hive,WITHOUT_CLASSIFICATION,//  map work should start with our ts op 
Hive,WITHOUT_CLASSIFICATION,//  because of scaling down this could happen 
Hive,WITHOUT_CLASSIFICATION,/*            * First of Multiple elements.            */
Hive,WITHOUT_CLASSIFICATION,//  check the hints to see if the user has specified a map-side join. This   will be removed later on once the cost-based 
Hive,WITHOUT_CLASSIFICATION,// show tables <dbname> is in invalid show tables syntax. Hive does not return  any tables in this case 
Hive,WITHOUT_CLASSIFICATION,//  We assume stream list is sorted by column and that non-data   streams do not interleave data streams for the same column. 
Hive,WITHOUT_CLASSIFICATION,// HIVE-17138: this creates 1 delta_0000013_0000013_0000/bucket_00001 
Hive,WITHOUT_CLASSIFICATION,//  Currently only used during re-optimization related parts. 
Hive,WITHOUT_CLASSIFICATION,// add mapreduce job tag placeholder 
Hive,WITHOUT_CLASSIFICATION,/*    * If there is no credential provider configured for hadoop jobConf should not contain   * credstore password and provider path even if HIVE_JOB_CRESTORE_PASSWORD env is set    */
Hive,WITHOUT_CLASSIFICATION,//  a bit before we restart the loop. 
Hive,WITHOUT_CLASSIFICATION,//  (bytes[fieldByteEnd] == separator) 
Hive,WITHOUT_CLASSIFICATION,//  LazySimpleSerDe doesn't support projection. 
Hive,WITHOUT_CLASSIFICATION,/*    * for a given Work Descriptor it extracts information about the ReduceSinkOps   * in the Work. For Tez you can restrict it to ReduceSinks for a particular output   * vertex.    */
Hive,WITHOUT_CLASSIFICATION,//  get the input and prepare the output 
Hive,WITHOUT_CLASSIFICATION,//  We are skipping the SKEWED_STRING_LIST table here as it seems to be totally useless. 
Hive,WITHOUT_CLASSIFICATION,//  EXPERIMENT 
Hive,WITHOUT_CLASSIFICATION,//  1. Do few checks to determine eligibility of optimization   2. look at ExprNodeFuncGenericDesc in select list to see if its min max count etc.      If it is   3. Connect to metastore and get the stats   4. Compose rows and add it in FetchWork 
Hive,WITHOUT_CLASSIFICATION,//  Don't try to log anything when appender is stopped 
Hive,WITHOUT_CLASSIFICATION,//  and then see what happens based on the provided schema 
Hive,WITHOUT_CLASSIFICATION,//  Test between 
Hive,WITHOUT_CLASSIFICATION,//  Validate the third parameter which should also be an integer 
Hive,WITHOUT_CLASSIFICATION,//  of the Hive config values. 
Hive,WITHOUT_CLASSIFICATION,// use smallint as outputTypeInfo 
Hive,WITHOUT_CLASSIFICATION,//  InputFormat 
Hive,WITHOUT_CLASSIFICATION,//  the vertex that should be inlined. <Operator list of Vertex that is 
Hive,WITHOUT_CLASSIFICATION,//  Start HiveServer2 with given config   Fail if server doesn't start 
Hive,WITHOUT_CLASSIFICATION,//  We should not update the following 3 values if SerDeInfo contains these.   This is to keep backward compatible with getSchema() where these 3 keys   are updated after SerDeInfo properties got copied. 
Hive,WITHOUT_CLASSIFICATION,//  Retrieve skewed columns. 
Hive,WITHOUT_CLASSIFICATION,//  Tests concurrent modification and that results are the same per input across threads   but different between inputs. 
Hive,WITHOUT_CLASSIFICATION,//  Rule requires that aggregate key to be the same as the join key.   By the way neither a super-set nor a sub-set would work. 
Hive,WITHOUT_CLASSIFICATION,//  Either we were interrupted by one of:   1. handleEvent() in which case there is a reader (error) event waiting for us in the queue   2. Some other unrelated cause which interrupted us in which case there may not be a reader event coming.   Either way we should not try to block trying to read the reader events queue. 
Hive,WITHOUT_CLASSIFICATION,/*    * split pairs by delimiter.    */
Hive,WITHOUT_CLASSIFICATION,//  arbitrary tokens the renewer should be the principal of the JobTracker 
Hive,WITHOUT_CLASSIFICATION,//  Add test parameters from official storage formats registered with Hive via   StorageFormatDescriptor. 
Hive,WITHOUT_CLASSIFICATION,//  static partition and list bucketing 
Hive,WITHOUT_CLASSIFICATION,//  ignore the char after escape_char 
Hive,WITHOUT_CLASSIFICATION,//  data and we can just ignore them. 
Hive,WITHOUT_CLASSIFICATION,//  We have already updated the metrics for the failure; change the state. 
Hive,WITHOUT_CLASSIFICATION,/*  This needs to return a "live" connection to be used by operation that follows it.          Thus it only closes Connection on failure/retry.  */
Hive,WITHOUT_CLASSIFICATION,//  otherwise compare it with power and half. 
Hive,WITHOUT_CLASSIFICATION,// return System.getProperty("test.build.data" "build/test/data") + "/dfs/"; 
Hive,WITHOUT_CLASSIFICATION,//  acidOp flag has to be checked to use JAVA hash which works like   identity function for integers necessary to read RecordIdentifier   incase of ACID updates/deletes. 
Hive,WITHOUT_CLASSIFICATION,//  we try to fold the expression to remove e.g. cast on constant 
Hive,WITHOUT_CLASSIFICATION,//  The other list will be exhausted when it commits. Create new one pending that commit. 
Hive,WITHOUT_CLASSIFICATION,//  A_STRING 
Hive,WITHOUT_CLASSIFICATION,//  This multiply produces more than 38 digits --> overflow.  --------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  Eventually we want this to be a richer description of having   a DB TABLE ROLE etc scope. For now we have a trivial impl   of having only DB and TABLE scopes as determined by whether   or not the tableName is null. 
Hive,WITHOUT_CLASSIFICATION,//  Wrap thrift connection with SASL for secure connection. 
Hive,WITHOUT_CLASSIFICATION,//  Don't pass the parsed db name as get_partitions_by_filter will parse it itself 
Hive,WITHOUT_CLASSIFICATION,//  this is not transactional 
Hive,WITHOUT_CLASSIFICATION,//  Flip the sign bit (and unused bits of the high-order byte) of the seven-byte long back. 
Hive,WITHOUT_CLASSIFICATION,//  Is this a truncate column command 
Hive,WITHOUT_CLASSIFICATION,//  These are the vectorized batch expressions for filtering key expressions and value 
Hive,WITHOUT_CLASSIFICATION,//  Number of tokens to drop between sleep intervals; 
Hive,WITHOUT_CLASSIFICATION,//  verify if table has been the target of replication and if so check HiveConf if we're allowed   to override. If not fail. 
Hive,WITHOUT_CLASSIFICATION,//  We are going to add splits for these directories with recursive = false so we ignore   any subdirectories (deltas or original directories) and only read the original files.   The fact that there's a loop calling addSplitsForGroup already implies it's ok to   the real input format multiple times... however some split concurrency/etc configs   that are applied separately in each call will effectively be ignored for such splits. 
Hive,WITHOUT_CLASSIFICATION,//  Removed from heap without evicting. 
Hive,WITHOUT_CLASSIFICATION,//  ignored. 
Hive,WITHOUT_CLASSIFICATION,//  No limit nothing to propagate we just bail out 
Hive,WITHOUT_CLASSIFICATION,//  For now we don't support joins on or using DECIMAL_64. 
Hive,WITHOUT_CLASSIFICATION,//  not a conversion function 
Hive,WITHOUT_CLASSIFICATION,// "123456789" "987654321" "1234" "4321" 
Hive,WITHOUT_CLASSIFICATION,//  Set proxy user privilege and initialize the global state of ProxyUsers 
Hive,WITHOUT_CLASSIFICATION,//  partial time. time part will be skipped 
Hive,WITHOUT_CLASSIFICATION,//  We need to extrapolate this partition based on the other partitions 
Hive,WITHOUT_CLASSIFICATION,//  dummy handle for ThriftCLIService 
Hive,WITHOUT_CLASSIFICATION,//  there are some required privileges missing create error message   sort the privileges so that error message is deterministic (for tests) 
Hive,WITHOUT_CLASSIFICATION,//  walk the list and acquire the locks - if any lock cant be acquired release all locks sleep 
Hive,WITHOUT_CLASSIFICATION,//  remove small table ailias from aliasToWork;Avoid concurrent modification 
Hive,WITHOUT_CLASSIFICATION,//  initialize output vector buffer to receive data 
Hive,WITHOUT_CLASSIFICATION,//  not sure we need this exec context; but all the operators in the work   will pass this context throught 
Hive,WITHOUT_CLASSIFICATION,//  replace stderr and run command 
Hive,WITHOUT_CLASSIFICATION,//  In case of dynamic queries it is possible to have incomplete dummy partitions 
Hive,WITHOUT_CLASSIFICATION,//  In the cases that have multi-stage insert e.g. a "hive.skewjoin.key"-based skew join   it can happen that we want multiple commits into the same directory from different   tasks (not just task instances). In non-MM case Utilities.renameOrMoveFiles ensures   unique names. We could do the same here but this will still cause the old file to be   deleted because it has not been committed in /this/ FSOP. We are going to fail to be   safe. Potentially we could implement some partial commit between stages if this 
Hive,WITHOUT_CLASSIFICATION,//  if all row indexes are null then indexes are disabled 
Hive,WITHOUT_CLASSIFICATION,//  This should now throw some useful exception. 
Hive,WITHOUT_CLASSIFICATION,//  execute query ignore exception if any 
Hive,WITHOUT_CLASSIFICATION,//  Print the column names 
Hive,WITHOUT_CLASSIFICATION,//  Not expected to be encountered for Hive - fail 
Hive,WITHOUT_CLASSIFICATION,//  Clears the dest dir when src is sub-dir of dest. 
Hive,WITHOUT_CLASSIFICATION,/*    * fastSetFromBigIntegerBytes word size we choose is 56 bits to stay below the 64 bit sign bit:   * So we need a multiplier 2^56   *   *    2^56 =   *      72057594037927936 or   *      72057594037927936 or   *      72057594037927936  (16 digit comma'd)    */
Hive,WITHOUT_CLASSIFICATION,//  int 
Hive,WITHOUT_CLASSIFICATION,/*      * partitioning Spec      */
Hive,WITHOUT_CLASSIFICATION,//  Virtual relation generated by the reduce sync 
Hive,WITHOUT_CLASSIFICATION,// set value to MIN_VALUE so that -MIN_VALUE overflows and gets set to MIN_VALUE again 
Hive,WITHOUT_CLASSIFICATION,//  test getAllTables 
Hive,WITHOUT_CLASSIFICATION,//  hive server's session input stream is not used   open a per-session file in auto-flush mode for writing temp results and tmp error output 
Hive,WITHOUT_CLASSIFICATION,//  2/ write the size of the map which is a VInt 
Hive,WITHOUT_CLASSIFICATION,//  stageList 
Hive,WITHOUT_CLASSIFICATION,//  The first bounds check requires at least one more byte beyond for 2nd int (hence >=). 
Hive,WITHOUT_CLASSIFICATION,//  There should be 2 original bucket files (000000_0 and 000001_0) a base directory   plus two new delta directories and one delete_delta directory that would be created due to 
Hive,WITHOUT_CLASSIFICATION,// normalize prop name 
Hive,WITHOUT_CLASSIFICATION,//  The total size of local tables in localWork[i] is unknown. 
Hive,WITHOUT_CLASSIFICATION,//  Need to get a new one see the comment wrt threadlocals. 
Hive,WITHOUT_CLASSIFICATION,// //////////  First Incremental //////////// 
Hive,WITHOUT_CLASSIFICATION,/*      * Check the 1st-level children and do simple semantic checks: 1) CTLT and     * CTAS should not coexists. 2) CTLT or CTAS should not coexists with column     * list (target table schema). 3) CTAS does not support partitioning (for     * now).      */
Hive,WITHOUT_CLASSIFICATION,//  DATE_STATS 
Hive,WITHOUT_CLASSIFICATION,//  execute the test query 
Hive,WITHOUT_CLASSIFICATION,// --0e 
Hive,WITHOUT_CLASSIFICATION,//  combine two lists 
Hive,WITHOUT_CLASSIFICATION,//  for each alias add object inspector for filter tag as the last element 
Hive,WITHOUT_CLASSIFICATION,//  it may contain duplicates remove duplicates 
Hive,WITHOUT_CLASSIFICATION,//  We use a separate metastore client for heartbeat calls to ensure heartbeat RPC calls are   isolated from the other transaction related RPC calls. 
Hive,WITHOUT_CLASSIFICATION,//  This could be brittle. 
Hive,WITHOUT_CLASSIFICATION,//  We assume ranges in "ranges" are non-overlapping; thus we will save next in advance. 
Hive,WITHOUT_CLASSIFICATION,/*      * The virtual columns available under vectorization.  They may not actually     * be used in this query.  Unused columns will be null just like unused data and partition     * columns are.      */
Hive,WITHOUT_CLASSIFICATION,//  Traverse through all the source files and see if any file is not copied or partially copied.   If yes then add to the retry list. If source file missing then retry with CM path. if CM path 
Hive,WITHOUT_CLASSIFICATION,// ************************************************************************************************   Initialize (fastSetFrom*). 
Hive,WITHOUT_CLASSIFICATION,//  production is: typedef DefinitionType() this.name 
Hive,WITHOUT_CLASSIFICATION,// check that all calls were recorded. 
Hive,WITHOUT_CLASSIFICATION,//    Operations involving/returning day-time intervals   
Hive,WITHOUT_CLASSIFICATION,/*      * 6. Project      */
Hive,WITHOUT_CLASSIFICATION,//  Insert overwrite on unpartitioned table 
Hive,WITHOUT_CLASSIFICATION,//  M_STRING_STRING 
Hive,WITHOUT_CLASSIFICATION,//  Tests for int add_partitions_pspec(PartitionSpecProxy partitionSpec) method 
Hive,WITHOUT_CLASSIFICATION,//  For stripe-level streams we don't need the extra refcount on the block. 
Hive,WITHOUT_CLASSIFICATION,//  object inspector for serializing input tuples 
Hive,WITHOUT_CLASSIFICATION,//  We handle ReduceSinkOperator here as we can safely ignore table alias   and the current comparator implementation does not.   We can ignore table alias since when we compare ReduceSinkOperator all   its ancestors need to match (down to table scan) thus we make sure that   both plans are the same. 
Hive,WITHOUT_CLASSIFICATION,/*   Distcp currently does not copy a single file in a distributed manner hence we dont care about  the size of file if there is only file we dont want to launch distcp.    */
Hive,WITHOUT_CLASSIFICATION,//  ------ Additional static classes defined after this point ------ 
Hive,WITHOUT_CLASSIFICATION,//  Initialize second mocked filesystem (implement only necessary stuff) 
Hive,WITHOUT_CLASSIFICATION,//  Error was expected 
Hive,WITHOUT_CLASSIFICATION,//  Arithmetic specializations are done in a convoluted manner; mark them as built-in. 
Hive,WITHOUT_CLASSIFICATION,//  clear up any existing databases 
Hive,WITHOUT_CLASSIFICATION,//  we set viewProjectToTableSchema so that we can leverage ColumnPruner. 
Hive,WITHOUT_CLASSIFICATION,//  Do full constant propagation   Only perform expression short-cutting - remove unnecessary AND/OR operators 
Hive,WITHOUT_CLASSIFICATION,//  write value element 
Hive,WITHOUT_CLASSIFICATION,/*    * Used to keep position/length for complex type fields.   * NOTE: The top level uses startPositions instead.    */
Hive,WITHOUT_CLASSIFICATION,// JobID job = new JobID(); 
Hive,WITHOUT_CLASSIFICATION,//  Linear search since this won't take much time from the total execution anyway   lower has the range of [0 .. total-1] 
Hive,WITHOUT_CLASSIFICATION,//  Make sure the path is normalized (we expect validation to pass since we just created it). 
Hive,WITHOUT_CLASSIFICATION,//  propagate input format if necessary 
Hive,WITHOUT_CLASSIFICATION,//  Bean methods 
Hive,WITHOUT_CLASSIFICATION,//  This is for backward compatibility. If the user did not specify the   output column list we assume that there are 2 columns: key and value.   However if the script outputs: col1 col2 col3 seperated by TAB the   requirement is: key is col and value is (col2 TAB col3) 
Hive,WITHOUT_CLASSIFICATION,//  If we don't create a new separate filter. In most cases there will only be one. 
Hive,WITHOUT_CLASSIFICATION,//  Same primitive category but different qualifiers. 
Hive,WITHOUT_CLASSIFICATION,//  toss all other exceptions related to reflection failure 
Hive,WITHOUT_CLASSIFICATION,//  The original may have settable info that needs to be added to the new copy. 
Hive,WITHOUT_CLASSIFICATION,// @NOTE this code is very similar to the code at org/apache/hadoop/hive/ql/parse/CalcitePlanner.java:2362 
Hive,WITHOUT_CLASSIFICATION,//  Before Cleaner there should be 5 items: 
Hive,WITHOUT_CLASSIFICATION,//  has failed because the query was killed from under it. 
Hive,WITHOUT_CLASSIFICATION,/*  * Planner rule that creates a {@code SemiJoinRule} from a * {@link org.apache.calcite.rel.core.Join} on top of a * {@link org.apache.calcite.rel.logical.LogicalAggregate}. * * TODO Remove this rule and use Calcite's SemiJoinRule. Not possible currently * since Calcite doesnt use RelBuilder for this rule and we want to generate HiveSemiJoin rel here.  */
Hive,WITHOUT_CLASSIFICATION,/*  Table giving binary powers of 10.  Entry  */
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setClob(java.lang.String java.io.Reader)    */
Hive,WITHOUT_CLASSIFICATION,//  process the third child nodeif exists to get partition spec(s) 
Hive,WITHOUT_CLASSIFICATION,//  optional string src_name = 2; 
Hive,WITHOUT_CLASSIFICATION,//  copy the test files into hadoop if required. 
Hive,WITHOUT_CLASSIFICATION,/*  * Test submission of concurrent job requests.  */
Hive,WITHOUT_CLASSIFICATION,//  Supports keeping a TimestampWritable object without having to import that definition... 
Hive,WITHOUT_CLASSIFICATION,//  Process the normal splits 
Hive,WITHOUT_CLASSIFICATION,//  check that the columns referenced in these comparisons form 
Hive,WITHOUT_CLASSIFICATION,//  Position where we'd write   Position where we'd read (unsafely at write time). 
Hive,WITHOUT_CLASSIFICATION,//  We only need to apply negation to all 3 words when there are 3 words etc. 
Hive,WITHOUT_CLASSIFICATION,//  thrown when the table to be altered does not exist 
Hive,WITHOUT_CLASSIFICATION,//  Set up mock warehouse 
Hive,WITHOUT_CLASSIFICATION,//  For PARTIAL1 and PARTIAL2 
Hive,WITHOUT_CLASSIFICATION,// value is correct 
Hive,WITHOUT_CLASSIFICATION,//  IMPORT [[EXTERNAL] TABLE new_or_original_tablename [PARTITION (part_column="value"[ ...])]]   FROM 'source_path'      [LOCATION 'import_target_path'] 
Hive,WITHOUT_CLASSIFICATION,//  In Hive server mode we are not able to retry in the FetchTask   case when calling fetch queries since execute() has returned. 
Hive,WITHOUT_CLASSIFICATION,//  inner join 
Hive,WITHOUT_CLASSIFICATION,//    throw new HiveException("remove is not in sort order and unique");   } 
Hive,WITHOUT_CLASSIFICATION,//  Does not need to be unique just non-zero distinct value to test against. 
Hive,WITHOUT_CLASSIFICATION,//  Whether we are using an acid compliant transaction manager has already been caught in   UpdateDeleteSemanticAnalyzer so if we are updating or deleting and getting nonAcid   here it means the table itself doesn't support it. 
Hive,WITHOUT_CLASSIFICATION,//  Just making sure Date.valueOf() works ok 
Hive,WITHOUT_CLASSIFICATION,//  These are used in getImplicitConvertUDFMethod 
Hive,WITHOUT_CLASSIFICATION,//  how many columns 
Hive,WITHOUT_CLASSIFICATION,//  adding 16KB constant memory for keyBinarySortableDeserializeRead as the rabit hole is deep to implement   MemoryEstimate interface also it is constant overhead 
Hive,WITHOUT_CLASSIFICATION,// set up the fetch operator for the new input file. 
Hive,WITHOUT_CLASSIFICATION,//  3. INSERT OVERWRITE 
Hive,WITHOUT_CLASSIFICATION,//  Project with the output of our operator. 
Hive,WITHOUT_CLASSIFICATION,//  (Re)allocate larger to be a multiple of 1024 (DEFAULT_SIZE). 
Hive,WITHOUT_CLASSIFICATION,//  there should be 3 calls to create partitions with batch sizes of 23 15 8 
Hive,WITHOUT_CLASSIFICATION,//  Init output object inspectors.     The return type for a partial aggregation is still a list of strings.     The return type for FINAL and COMPLETE is a full aggregation result which is 
Hive,WITHOUT_CLASSIFICATION,//  Create temp table with current connection 
Hive,WITHOUT_CLASSIFICATION,//  2) Drain unused sessions; the close() is sync so delegate to the caller. 
Hive,WITHOUT_CLASSIFICATION,//  Variables for LLAP hash table loading memory monitor 
Hive,WITHOUT_CLASSIFICATION,//  iterate and update masks array 
Hive,WITHOUT_CLASSIFICATION,//  If we are in the system registry and this feature is enabled try to get it from metastore. 
Hive,WITHOUT_CLASSIFICATION,//  We try to push the full Filter predicate iff:   - the Filter is on top of a TableScan or   - the Filter is on top of a PTF (between PTF and Filter there might be Select operators)   Otherwise we push only the synthetic join predicates   Note : pushing Filter on top of PTF is necessary so the LimitPushdownOptimizer for Rank   functions gets enabled 
Hive,WITHOUT_CLASSIFICATION,//  corresponding branch since only that branch will factor is the reduction 
Hive,WITHOUT_CLASSIFICATION,//        after all the perf changes that we might was well hardcode them separately. 
Hive,WITHOUT_CLASSIFICATION,//  This is fast path for query optimizations if we can find this info   quickly using directSql do it. No point in failing back to slow path   here. 
Hive,WITHOUT_CLASSIFICATION,//  with a non null value before trying to alter the partition column type. 
Hive,WITHOUT_CLASSIFICATION,//  root is the start of the operator pipeline we're currently 
Hive,WITHOUT_CLASSIFICATION,//  Extract on date: special handling since function in Hive does   include <time_unit>. Observe that <time_unit> information   is implicit in the function name thus translation will   proceed correctly if we just ignore the <time_unit> 
Hive,WITHOUT_CLASSIFICATION,//  2b. This is a known incomplete CB caused by ORC CB end boundaries being estimates. 
Hive,WITHOUT_CLASSIFICATION,//  see comment next to the field 
Hive,WITHOUT_CLASSIFICATION,//  The input file has changed - load the correct hash bucket 
Hive,WITHOUT_CLASSIFICATION,//  user specified the memory for local mode hadoop run 
Hive,WITHOUT_CLASSIFICATION,//  restore the local job tracker back to original 
Hive,WITHOUT_CLASSIFICATION,//  Don't log the stack this is normal. 
Hive,WITHOUT_CLASSIFICATION,//  HADOOP_CLIENT_OPTS is appended to HADOOP_OPTS in HADOOP.sh so we should remove the old   HADOOP_CLIENT_OPTS which might have the main debug options from current HADOOP_OPTS. A new   HADOOP_CLIENT_OPTS is created with child JVM debug options and it will be appended to   HADOOP_OPTS agina when HADOOP.sh is executed for the child process. 
Hive,WITHOUT_CLASSIFICATION,/*        * Now new job requests should succeed as status operation has no cancel threads.        */
Hive,WITHOUT_CLASSIFICATION,//  Take all the driver run hooks and post-execute them. 
Hive,WITHOUT_CLASSIFICATION,//  ELSE cast (newInput AS newInputTypeNullable) END 
Hive,WITHOUT_CLASSIFICATION,//  now hook up the children 
Hive,WITHOUT_CLASSIFICATION,//  We do not repartition: take number of splits from children 
Hive,WITHOUT_CLASSIFICATION,//  construct the inner struct 
Hive,WITHOUT_CLASSIFICATION,// c7Value = (Map<??>) rowValues[6];  assertEquals(1 c7Value.size());  assertEquals("v" c7Value.get("k")); 
Hive,WITHOUT_CLASSIFICATION,//  Avoid a copy when newTmpJars is null or empty 
Hive,WITHOUT_CLASSIFICATION,//  Either the user or the kill is not done yet. 
Hive,WITHOUT_CLASSIFICATION,//  Find first virtual column and clip them off. 
Hive,WITHOUT_CLASSIFICATION,// if this is co-rrelated we need to make RexCorrelVariable(with id and type)   id and type should be retrieved from outerRR 
Hive,WITHOUT_CLASSIFICATION,//  Final return type that goes back to Hive: a list of structs with n-grams and their   estimated frequencies. 
Hive,WITHOUT_CLASSIFICATION,//  update path in IOContext 
Hive,WITHOUT_CLASSIFICATION,// splits. 
Hive,WITHOUT_CLASSIFICATION,//  Collect newer entry is if a super-set of existing entry 
Hive,WITHOUT_CLASSIFICATION,/*  id >= 12             */
Hive,WITHOUT_CLASSIFICATION,//  Must fill high word from both middle and lower longs. 
Hive,WITHOUT_CLASSIFICATION,//  next we translate the TezWork to a Tez DAG 
Hive,WITHOUT_CLASSIFICATION,//  Assume only 1 parent for FS operator 
Hive,WITHOUT_CLASSIFICATION,//  Add SMALLINT values 
Hive,WITHOUT_CLASSIFICATION,//  there's no extensive need for this to have its own type - it mirrors   the intent of copy enough. This might change later though. 
Hive,WITHOUT_CLASSIFICATION,//  The get-session call should also fail. 
Hive,WITHOUT_CLASSIFICATION,//  verify standard case 
Hive,WITHOUT_CLASSIFICATION,//  10 is the length of "compactor." We only keep the rest. 
Hive,WITHOUT_CLASSIFICATION,//  required   optional   optional   required 
Hive,WITHOUT_CLASSIFICATION,//  do a one time initialization 
Hive,WITHOUT_CLASSIFICATION,//  Top level. 
Hive,WITHOUT_CLASSIFICATION,//  Assert that the source and target partitions are equivalent. 
Hive,WITHOUT_CLASSIFICATION,//  For backward compatibility let the above parameter be used 
Hive,WITHOUT_CLASSIFICATION,//  Verify that getOperationStatus returned only after the long polling timeout 
Hive,WITHOUT_CLASSIFICATION,//  Trying to connect with a non-existent user should still fail with   login failure. 
Hive,WITHOUT_CLASSIFICATION,//  This also gets us around the Enum issue since we just take the value 
Hive,WITHOUT_CLASSIFICATION,//  Table will be queried directly by LLAP   Acquire locks if necessary - they will be released during session cleanup.   The read will have READ_COMMITTED level semantics. 
Hive,WITHOUT_CLASSIFICATION,//  Return itself should be a no-op - the pool went from 6 to 4 with 1 session in the pool. 
Hive,WITHOUT_CLASSIFICATION,//  Prepare the field ObjectInspectors 
Hive,WITHOUT_CLASSIFICATION,//  Only process equivalences found in the join conditions. Processing   Equivalences from the left or right side infer predicates that are   already present in the Tree below the join. 
Hive,WITHOUT_CLASSIFICATION,//  Set unique constraint name if null before sending to listener 
Hive,WITHOUT_CLASSIFICATION,//  Process grouping set for the reduce sink operator 
Hive,WITHOUT_CLASSIFICATION,//  operations other than table rename 
Hive,WITHOUT_CLASSIFICATION,//  Ignore nulls 
Hive,WITHOUT_CLASSIFICATION,//  We would expect 4 entries in TXN_TO_WRITE_ID as each insert would have allocated a writeid   including aborted one. 
Hive,WITHOUT_CLASSIFICATION,//  System environment variables 
Hive,WITHOUT_CLASSIFICATION,//  Return the value 
Hive,WITHOUT_CLASSIFICATION,//  we should look take the parent of fsOp's task as the current task. 
Hive,WITHOUT_CLASSIFICATION,/*    * Using CommonTreeAdaptor because the Adaptor in ParseDriver doesn't carry   * the token indexes when duplicating a Tree.    */
Hive,WITHOUT_CLASSIFICATION,//  Round towards positive infinity. 
Hive,WITHOUT_CLASSIFICATION,//  Check if we have visited this operator 
Hive,WITHOUT_CLASSIFICATION,/*  * Test submission of concurrent job requests with the controlled number of concurrent * Requests and job request execution time outs. Verify that we get appropriate exceptions * and exception message.  */
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#getMaxRows()    */
Hive,WITHOUT_CLASSIFICATION,//  Variables for metrics 
Hive,WITHOUT_CLASSIFICATION,//  all resources including HDFS are session based. 
Hive,WITHOUT_CLASSIFICATION,// use setPartitionColumnStatistics instead 
Hive,WITHOUT_CLASSIFICATION,//  When hive.metastore.transactional.event.listeners is set 
Hive,WITHOUT_CLASSIFICATION,//  Compaction can only be done on the whole table if the table is non-partitioned. 
Hive,WITHOUT_CLASSIFICATION,// commit T1 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getInt(int)    */
Hive,WITHOUT_CLASSIFICATION,//  NEW_TBL 
Hive,WITHOUT_CLASSIFICATION,//  Since our probing method is totally bogus give up after some time. 
Hive,WITHOUT_CLASSIFICATION,//  Combo 1: Both set to none 
Hive,WITHOUT_CLASSIFICATION,//  The only time this condition should be false is in the case of dynamic partitioning   where the data is bucketed on a dynamic partitioning column and the FileSinkOperator is   being processed.  In this case the dynamic partition column will not appear in   colInfos and due to the limitations of dynamic partitioning they will appear at the   end of the input schema.  Since the order of the columns hasn't changed and no new   columns have been added/removed it is safe to assume that these will have indexes   greater than or equal to colInfos.size(). 
Hive,WITHOUT_CLASSIFICATION,//  The join columns should contain all the sort columns   The sort columns of all the tables should be in the same order 
Hive,WITHOUT_CLASSIFICATION,//  Add Spark job id to the Hive History 
Hive,WITHOUT_CLASSIFICATION,//  Set the username/passwd for the Accumulo connection 
Hive,WITHOUT_CLASSIFICATION,//  Map values may be serialized in binary format when they are primitive and binary 
Hive,WITHOUT_CLASSIFICATION,//  Oracle cannot have over 1000 expressions in a in-list 
Hive,WITHOUT_CLASSIFICATION,//  If the child SelectOperator has the ColumnExprMap   we need to update the ColumnExprMap in the parent SelectOperator. 
Hive,WITHOUT_CLASSIFICATION,//  Partition names are URL encoded. We decode the names unless Hive   is configured to use the encoded names. 
Hive,WITHOUT_CLASSIFICATION,//  All are filtered out 
Hive,WITHOUT_CLASSIFICATION,/*  (id < 10 and id < 11 and id < 12) or (id < 13 and id < 14 and id < 15) or       (id < 16 and id < 17) or id < 18  */
Hive,WITHOUT_CLASSIFICATION,//  these should have viable defaults 
Hive,WITHOUT_CLASSIFICATION,// at this point "show compactions" should have (COMPACTOR_HISTORY_RETENTION_FAILED) failed + 1 initiated (explicitly by user) 
Hive,WITHOUT_CLASSIFICATION,//  1 Convert UDAF Params to ExprNodeDesc 
Hive,WITHOUT_CLASSIFICATION,//  Make a create table statement 
Hive,WITHOUT_CLASSIFICATION,/*    * Compiles the given pattern with a proper algorithm.    */
Hive,WITHOUT_CLASSIFICATION,//  Execute the given sql statement 
Hive,WITHOUT_CLASSIFICATION,//  Add more failed compactions so that the total is exactly COMPACTOR_INITIATOR_FAILED_THRESHOLD 
Hive,WITHOUT_CLASSIFICATION,//  Now remove all BaseWorks in all the childSparkWorks that we created 
Hive,WITHOUT_CLASSIFICATION,//  Serialize each field 
Hive,WITHOUT_CLASSIFICATION,//  cookie passes the validation return null to the caller. 
Hive,WITHOUT_CLASSIFICATION,//  First allocation of write id (hwm+1) should add the table to the next_write_id meta table. 
Hive,WITHOUT_CLASSIFICATION,//  If all correlation variables are now satisfied skip creating a value 
Hive,WITHOUT_CLASSIFICATION,//  set second argument to IF 
Hive,WITHOUT_CLASSIFICATION,//  5% tolerance for long range bias and 1% for short range bias 
Hive,WITHOUT_CLASSIFICATION,//  Stripped down version of org.apache.calcite.rel.rules.AggregateExpandDistinctAggregatesRule   This is adapted for Hive but should eventually be deleted from Hive and make use of above. 
Hive,WITHOUT_CLASSIFICATION,//  get the input & output file formats 
Hive,WITHOUT_CLASSIFICATION,// Work Boundary stop exploring. 
Hive,WITHOUT_CLASSIFICATION,//  Force a re-read of the configuration file.  This is done because 
Hive,WITHOUT_CLASSIFICATION,//  The reason we use compare-command rather than simply getting the serialized output and comparing   for partition-based commands is that the partition specification order can be different in different   serializations but still be effectively the same. (a="42"b="abc") should be the same as (b="abc"a="42") 
Hive,WITHOUT_CLASSIFICATION,//  view entity 
Hive,WITHOUT_CLASSIFICATION,//  Long/double arithmetic 
Hive,WITHOUT_CLASSIFICATION,//  Use Case 4. 
Hive,WITHOUT_CLASSIFICATION,//  Close the stripe reader we are done reading. 
Hive,WITHOUT_CLASSIFICATION,// commit T2 
Hive,WITHOUT_CLASSIFICATION,//  make a clone of existing hive conf   make a clone of existing hive conf 
Hive,WITHOUT_CLASSIFICATION,//  choose a random sign 
Hive,WITHOUT_CLASSIFICATION,//  TODO: HIVE-14042. Potential blocking call. MRInput handles this correctly even if an interrupt is swallowed. 
Hive,WITHOUT_CLASSIFICATION,//  Do not support grouping set right now 
Hive,WITHOUT_CLASSIFICATION,//  CHECK_CONSTRAINT_COLS 
Hive,WITHOUT_CLASSIFICATION,/*    * The storage arrays for this column vector corresponds to the storage of a Timestamp:    */
Hive,WITHOUT_CLASSIFICATION,//  Different parts of the code rely on this being set... 
Hive,WITHOUT_CLASSIFICATION,//  Failed to init remove it from cache 
Hive,WITHOUT_CLASSIFICATION,//  MySQL parser 
Hive,WITHOUT_CLASSIFICATION,//  Return MD provider 
Hive,WITHOUT_CLASSIFICATION,//  String type affinity 
Hive,WITHOUT_CLASSIFICATION,/*    * If the init method in HMSHandler throws exception all the times it should be retried until   * HiveConf.ConfVars.HMSHANDLERATTEMPTS is reached before giving up    */
Hive,WITHOUT_CLASSIFICATION,//  dynamic partition 
Hive,WITHOUT_CLASSIFICATION,//  remember the output name of the reduce sink 
Hive,WITHOUT_CLASSIFICATION,//  State has not changed / already registered for notifications. 
Hive,WITHOUT_CLASSIFICATION,//  the types of the expressions for the lateral view generated rows 
Hive,WITHOUT_CLASSIFICATION,//  The AccumuloOutputFormat methods 
Hive,WITHOUT_CLASSIFICATION,//  For Hybrid Grace Hash Join we need to see if there is any spilled data to be processed next 
Hive,WITHOUT_CLASSIFICATION,// should not happen - this should not get called before this.start() is called 
Hive,WITHOUT_CLASSIFICATION,//  A rewriting was produced we will check whether it was part of an incremental rebuild   to try to replace INSERT OVERWRITE by INSERT 
Hive,WITHOUT_CLASSIFICATION,//  Acquire lock 
Hive,WITHOUT_CLASSIFICATION,//  Add HBase related configuration to Spark because in security mode Spark needs it   to generate hbase delegation token for Spark. This is a temp solution to deal with   Spark problem. 
Hive,WITHOUT_CLASSIFICATION,//  non-bean .. 
Hive,WITHOUT_CLASSIFICATION,//  The fourth could be combined again. 
Hive,WITHOUT_CLASSIFICATION,//  field name   field type 
Hive,WITHOUT_CLASSIFICATION,//  try merge join tree from inner most source   (it was merged from outer most to inner which could be invalid)     in a join tree ((A-B)-C)-D where C is not mergeable with A-B   D can be merged with A-B into single join If and only if C and D has same join type 
Hive,WITHOUT_CLASSIFICATION,//  Note: GROUPING SETS are not allowed with map side aggregation set to false so we don't have to worry about it 
Hive,WITHOUT_CLASSIFICATION,//  descriptors for subq1 and subq2 are linked. 
Hive,WITHOUT_CLASSIFICATION,// close one connection verify still two left 
Hive,WITHOUT_CLASSIFICATION,/* writable */
Hive,WITHOUT_CLASSIFICATION,//  Incremental Repl A -> B with alters on db/table/partition 
Hive,WITHOUT_CLASSIFICATION,//  Something else is wrong. 
Hive,WITHOUT_CLASSIFICATION,//  run some queries 
Hive,WITHOUT_CLASSIFICATION,//  Perform any partition expressions.  Results will go into scratch columns. 
Hive,WITHOUT_CLASSIFICATION,//  [-H|--help] 
Hive,WITHOUT_CLASSIFICATION,//  From https://msdn.microsoft.com/en-us/library/ms190476.aspx   e1 % e2   Precision: min(p1-s1 p2 -s2) + max( s1s2 )   Scale: max(s1 s2) 
Hive,WITHOUT_CLASSIFICATION,//  Thread local configuration is needed as many threads could make changes 
Hive,WITHOUT_CLASSIFICATION,//  4. Bailout if select involves Transform 
Hive,WITHOUT_CLASSIFICATION,/*        * Verify that new job requests should succeed with no issues.        */
Hive,WITHOUT_CLASSIFICATION,//  Test that existing shared_read partition with new shared_write coalesces to 
Hive,WITHOUT_CLASSIFICATION,//  4. Perform a major compaction. 
Hive,WITHOUT_CLASSIFICATION,// LlapIoImpl.LOG.info(prefix(ix) + " adding " + header(log[ix + 2]) + " to "      + getSecondInt(log[ix]) + " before " + log[ix + 3]); 
Hive,WITHOUT_CLASSIFICATION,//  Add the function name as a WriteEntity 
Hive,WITHOUT_CLASSIFICATION,//  Check if the given SparkTask has a child SparkTask that contains the target MapWork   If it does not then remove the target from DPP op 
Hive,WITHOUT_CLASSIFICATION,//  if this is a valid executable command then add it to the buffer 
Hive,WITHOUT_CLASSIFICATION,//  This helper object deserializes known deserialization / input file format combination into   columns of a row in a vectorized row batch. 
Hive,WITHOUT_CLASSIFICATION,//  construct a new DecimalFormat only if a new dValue 
Hive,WITHOUT_CLASSIFICATION,/*      * Rows with a rank <= rankLimit are output.     * Only the first row with rank = rankLimit is output.      */
Hive,WITHOUT_CLASSIFICATION,/*    * If the cInfo is for an ASTNode this function returns the ASTNode that it is for.    */
Hive,WITHOUT_CLASSIFICATION,//  DPP indeed Set parallel edges true 
Hive,WITHOUT_CLASSIFICATION,//  This is no-op there is no column to assign to and val is expected to be null 
Hive,WITHOUT_CLASSIFICATION,/*      *  For the moment pretend all matched are selected so we can evaluate the value     *  expressions.     *     *  Since we may use the overflow batch when generating results we will assign the     *  selected and real batch size later...      */
Hive,WITHOUT_CLASSIFICATION,// if no update or delete in Merge there is no need to to do cardinality check 
Hive,WITHOUT_CLASSIFICATION,//  Create a dummy key for searching the owid/bucket in the compressed owid ranges. 
Hive,WITHOUT_CLASSIFICATION,//  Immediate retry 
Hive,WITHOUT_CLASSIFICATION,//  create matcher for custom path 
Hive,WITHOUT_CLASSIFICATION,//  Add aggregate A (see the reference example above) the top aggregate 
Hive,WITHOUT_CLASSIFICATION,//  re-read length 
Hive,WITHOUT_CLASSIFICATION,//  create a new batch with one char column (for input) and one long column (for output) 
Hive,WITHOUT_CLASSIFICATION,//  causing each thread to get a different client even if the conf is same. 
Hive,WITHOUT_CLASSIFICATION,//  additional rows corresponding to grouping sets need to be created here. 
Hive,WITHOUT_CLASSIFICATION,//  TODO test changes to mark cleaned to clean txns and txn_components 
Hive,WITHOUT_CLASSIFICATION,//  2/ write the size of the list as a VInt 
Hive,WITHOUT_CLASSIFICATION,//  If we can put multiple group bys in a single reducer determine suitable groups of   expressions otherwise treat all the expressions as a single group 
Hive,WITHOUT_CLASSIFICATION,//  This assumes no ranges passed to cache to fetch have data beforehand. 
Hive,WITHOUT_CLASSIFICATION,//  save join type 
Hive,WITHOUT_CLASSIFICATION,//  The sorting order of the child RS is more specific than   that of the parent RS. Assign the sorting order of the child RS   to the parent RS. 
Hive,WITHOUT_CLASSIFICATION,//  1234 
Hive,WITHOUT_CLASSIFICATION,// when last txn finished (abortTransaction/commitTransaction) the currentTxnIndex is pointing at that txn  so we need to start from next one if any.  Also if batch was created but 
Hive,WITHOUT_CLASSIFICATION,//  do not overwrite. 
Hive,WITHOUT_CLASSIFICATION,//  with the values generated and propagated from the right input 
Hive,WITHOUT_CLASSIFICATION,//  Skip the colinfos which are not for this particular alias 
Hive,WITHOUT_CLASSIFICATION,//  or for a map-reduce job 
Hive,WITHOUT_CLASSIFICATION,// create HiveSessionImpl object 
Hive,WITHOUT_CLASSIFICATION,//  pipeline which can cause a cycle after hashjoin optimization. 
Hive,WITHOUT_CLASSIFICATION,//  REVOKE_GRANT_OPTION 
Hive,WITHOUT_CLASSIFICATION,//  return true if current min segment(FetchOperator) has next row 
Hive,WITHOUT_CLASSIFICATION,//  translate work to vertex 
Hive,WITHOUT_CLASSIFICATION,//  Get the positions for partition bucket and sort columns 
Hive,WITHOUT_CLASSIFICATION,//  Initialize the config 
Hive,WITHOUT_CLASSIFICATION,//  traversing an operator tree 
Hive,WITHOUT_CLASSIFICATION,//  The RPC server will take care of timeouts here. 
Hive,WITHOUT_CLASSIFICATION,//  Handle child tasks here. We could add them directly whereever we need 
Hive,WITHOUT_CLASSIFICATION,//  positive Unix time 
Hive,WITHOUT_CLASSIFICATION,//  BUCKET_COLS 
Hive,WITHOUT_CLASSIFICATION,//  available and grammar check is there in the language itself. 
Hive,WITHOUT_CLASSIFICATION,//  IntWritable so we can just sum in the reduce 
Hive,WITHOUT_CLASSIFICATION,//  full paths are replaced with base filenames 
Hive,WITHOUT_CLASSIFICATION,//  Test if the user session specific conf overlaying global init conf. 
Hive,WITHOUT_CLASSIFICATION,/*       Due to the limitation that we can only have one instance of Persistence Manager Factory in a JVM      we are not able to create multiple embedded derby instances for two different MetaStore instances.     */
Hive,WITHOUT_CLASSIFICATION,//  Couldn't find reference to expression 
Hive,WITHOUT_CLASSIFICATION,/*  Consider a query like:     *     * select * from     *   (subq1 --> has a filter)     *   join     *   (subq2 --> has a filter)     * on some key     *     * Let us assume that subq1 is the small table (either specified by the user or inferred     * automatically). The following operator tree will be created:     *     * TableScan (subq1) --> Select --> Filter --> DummyStore     *                                                         \     *                                                          \     SMBJoin     *                                                          /     *                                                         /     * TableScan (subq2) --> Select --> Filter      */
Hive,WITHOUT_CLASSIFICATION,// Non partitioned table 
Hive,WITHOUT_CLASSIFICATION,//  by using signatures and encryption. 
Hive,WITHOUT_CLASSIFICATION,//  try a valid alter table 
Hive,WITHOUT_CLASSIFICATION,//  Use table properties in case of unpartitioned tables   and the union of table properties and partition properties with partition 
Hive,WITHOUT_CLASSIFICATION,//  Find first non-sign (0xff) byte of input. 
Hive,WITHOUT_CLASSIFICATION,//  INSERT INTO 2 partitions and get the last repl ID 
Hive,WITHOUT_CLASSIFICATION,// retain this digit 
Hive,WITHOUT_CLASSIFICATION,//  For use from within HCatClient.getPartitions(). 
Hive,WITHOUT_CLASSIFICATION,//  In particular we use size of data in RS x number of uses. 
Hive,WITHOUT_CLASSIFICATION,//  Singleton using DCL. 
Hive,WITHOUT_CLASSIFICATION,//  used by GroupBy 
Hive,WITHOUT_CLASSIFICATION,//  Insert this map into the stats 
Hive,WITHOUT_CLASSIFICATION,//  Go over the subqueries and getMetaData for these 
Hive,WITHOUT_CLASSIFICATION,// as with grant also implies without grant privilege add without privilege as well 
Hive,WITHOUT_CLASSIFICATION,//  Get the existing table 
Hive,WITHOUT_CLASSIFICATION,//  In case of views the underlying views or tables are not direct dependencies   and are not used for authorization checks.   This ReadEntity represents one of the underlying tables/views so skip it.   See description of the isDirect in ReadEntity 
Hive,WITHOUT_CLASSIFICATION,//  Fill up as much of the overflow batch as possible with small table values. 
Hive,WITHOUT_CLASSIFICATION,//  regular CREATE TABLE   CREATE TABLE LIKE ... (CTLT)   CREATE TABLE AS SELECT ... (CTAS) 
Hive,WITHOUT_CLASSIFICATION,//  Set SSL 
Hive,WITHOUT_CLASSIFICATION,//  Now trim the overstuffed histogram down to the correct number of bins 
Hive,WITHOUT_CLASSIFICATION,//  Indicates that we are in test mode. 
Hive,WITHOUT_CLASSIFICATION,//  7 : Drop table T2 => 1 event 
Hive,WITHOUT_CLASSIFICATION,//  TableScan of a non-Hive table - don't support for materializations. 
Hive,WITHOUT_CLASSIFICATION,/*  Returning true does not guarantee that the task will run considering other queries    may be running in the system. Also depends upon the capacity usage configuration      */
Hive,WITHOUT_CLASSIFICATION,//  tests not setting maxRows 
Hive,WITHOUT_CLASSIFICATION,//  if we don't have column stats we just assume hash aggregation is disabled 
Hive,WITHOUT_CLASSIFICATION,//  SparkWork 
Hive,WITHOUT_CLASSIFICATION,//  Increase target list pos.   Target list is being drained.   Set delta and refcount. 
Hive,WITHOUT_CLASSIFICATION,//  Look for a hint to not run a test on some Hadoop versions 
Hive,WITHOUT_CLASSIFICATION,/*    * Helper function to create JobConf for specific ReduceWork.    */
Hive,WITHOUT_CLASSIFICATION,//  Methods that create group keys and aggregate calls 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   required   optional   optional   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  Run Cleaner.   This run doesn't do anything for the above aborted transaction since   the current compaction request entry in the compaction queue is updated   to have highest_write_id when the worker is run before the aborted   transaction. Specifically the id is 2 for the entry but the aborted   transaction has 3 as writeId. This run does transition the entry 
Hive,WITHOUT_CLASSIFICATION,//  contains aliases from sub-query   we are just converting to a common merge join operator. The shuffle   join in map-reduce case. 
Hive,WITHOUT_CLASSIFICATION,//  The overwhelming majority of cases will go here. Read 3 bytes. Tada! 
Hive,WITHOUT_CLASSIFICATION,//  [==================>>-----] 
Hive,WITHOUT_CLASSIFICATION,//  The entire current slice is part of the split. Note that if split end EQUALS   lastEnd the split would also read the next row so we do need to look at the   next slice if any (although we'd probably find we cannot use it).   Note also that we DO NOT treat end-of-file differently here cause we do not know   of any such thing. The caller must handle lastEnd vs end of split vs end of file   match correctly in terms of how LRR handles them. See above for start-of-file. 
Hive,WITHOUT_CLASSIFICATION,//  the return values are capped to return ==0 ==1 and >= 2 
Hive,WITHOUT_CLASSIFICATION,//  A launchable task is one that hasn't been queued hasn't been   initialized and is runnable. 
Hive,WITHOUT_CLASSIFICATION,//  Has the user enabled merging of files for map-only jobs or for all jobs 
Hive,WITHOUT_CLASSIFICATION,//  partitioned table => stats not updated 
Hive,WITHOUT_CLASSIFICATION,//  Look for InputFileFormat / Serde combinations we can deserialize more efficiently   using VectorDeserializeRow and a deserialize class with the DeserializeRead interface.     Do the "vectorized" row-by-row deserialization into a VectorizedRowBatch in the 
Hive,WITHOUT_CLASSIFICATION,/*            * If this is the last file for this bucket maxKey == null means the split is the tail           * of the file so we want to leave it blank to make sure any insert events in delta           * files are included; Conversely if it's not the last file set the maxKey so that           * events from deltas that don't modify anything in the current split are excluded */
Hive,WITHOUT_CLASSIFICATION,//  Case 5 - Max in list members: 1000; Max query string length: 10KB 
Hive,WITHOUT_CLASSIFICATION,//  if all bits are set expected should be 0 
Hive,WITHOUT_CLASSIFICATION,//  ((R1.x=R2.x) and R1.z=10)) and rand(1) < 0.1 
Hive,WITHOUT_CLASSIFICATION,//  Create/Delete/Write/Admin to creator 
Hive,WITHOUT_CLASSIFICATION,//  minus 1 here otherwise driver is also counted as an executor 
Hive,WITHOUT_CLASSIFICATION,//  Let uval be the value of the unsigned long with the same bits as x   Two's complement => x = uval - 2*MAX - 2   => uval = x + 2*MAX + 2   Now use the fact: (a+b)/c = a/c + b/c + (a%c+b%c)/c 
Hive,WITHOUT_CLASSIFICATION,//  VectorizedBatchUtil.debugDisplayOneRow(batch batchIndex CLASS_NAME + " NOMATCH duplicate"); 
Hive,WITHOUT_CLASSIFICATION,//  schema info. 
Hive,WITHOUT_CLASSIFICATION,//  Prepare the list of databases 
Hive,WITHOUT_CLASSIFICATION,// batching is not enabled. Try to drop all the partitions in one call 
Hive,WITHOUT_CLASSIFICATION,//  move any incompatible files to final path 
Hive,WITHOUT_CLASSIFICATION,//  Check if external table property being removed 
Hive,WITHOUT_CLASSIFICATION,//  remove values in key exprs for value table schema   value expression for hashsink will be modified in   LocalMapJoinProcessor 
Hive,WITHOUT_CLASSIFICATION,// do this check recursively on all the parent roles of curRole 
Hive,WITHOUT_CLASSIFICATION,//  deserializer is null in case of VectorMapOperator 
Hive,WITHOUT_CLASSIFICATION,//  TODO When will the queue ever be null.   Pass queue and default in as constructor parameters and make them final. 
Hive,WITHOUT_CLASSIFICATION,//  set memory usage for the MJ operator 
Hive,WITHOUT_CLASSIFICATION,/*    * the names of the Columns of the input to MatchPath. Used to setup the tpath Struct column.    */
Hive,WITHOUT_CLASSIFICATION,//  create a proxy for the local filesystem   the scheme/authority serving as the proxy is derived   from the supplied URI 
Hive,WITHOUT_CLASSIFICATION,//  Get the sort positions and sort order for the table 
Hive,WITHOUT_CLASSIFICATION,//  Adjust the aggregator argument positions.   Note aggregator does not change input ordering so the input   output position mapping can be used to derive the new positions 
Hive,WITHOUT_CLASSIFICATION,//  skewed Keys which intersect with join keys 
Hive,WITHOUT_CLASSIFICATION,//  Leaf 
Hive,WITHOUT_CLASSIFICATION,//  Sort does not change input ordering 
Hive,WITHOUT_CLASSIFICATION,//  false for the following cases:   * name is "list" which matches the spec   * name is "bag" which indicates existing hive or pig data 
Hive,WITHOUT_CLASSIFICATION,//  the fromIndex(inclusive) and toIndex(exclusive) for each unique owid. 
Hive,WITHOUT_CLASSIFICATION,//  create a syntax tree for a simple function call "longudf(col0)" 
Hive,WITHOUT_CLASSIFICATION,//  tenScale <= SqlMathUtil.MAX_POWER_TEN_INT31   so we can make this as a long comparison 
Hive,WITHOUT_CLASSIFICATION,//  look for matches in time based counters 
Hive,WITHOUT_CLASSIFICATION,//  If both are numeric make sure the new type is larger than the old. 
Hive,WITHOUT_CLASSIFICATION,//  If the database is newer than the create event then noop it. 
Hive,WITHOUT_CLASSIFICATION,//  No-op. 
Hive,WITHOUT_CLASSIFICATION,//  Use the maximum parallelism from all parent reduce sinks 
Hive,WITHOUT_CLASSIFICATION,//  The GroupByOperator is not initialized which means there is no   data   (since we initialize the operators when we see the first record).   Just do nothing here. 
Hive,WITHOUT_CLASSIFICATION,//  We use the sign of the reversed-nanoseconds field to indicate that there is a second VInt   present. 
Hive,WITHOUT_CLASSIFICATION,//  we also collect table stats while collecting column stats. 
Hive,WITHOUT_CLASSIFICATION,//  LOG.debug("VectorMapJoinFastBytesHashMap findWriteSlot slot " + slot + " tripleIndex " + tripleIndex + " existing"); 
Hive,WITHOUT_CLASSIFICATION,/*  * Simple one long key map join benchmarks. * * Build with "mvn clean install -DskipTests -Pdistitests" at main hive directory. * * From itests/hive-jmh directory run: *     java -jar target/benchmarks.jar org.apache.hive.benchmark.vectorization.mapjoin.MapJoinMultiKeyBench * *  {INNER INNER_BIG_ONLY LEFT_SEMI OUTER} *    X *  {ROW_MODE_HASH_MAP ROW_MODE_OPTIMIZED VECTOR_PASS_THROUGH NATIVE_VECTOR_OPTIMIZED NATIVE_VECTOR_FAST} *  */
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setBytes(java.lang.String byte[])    */
Hive,WITHOUT_CLASSIFICATION,/*  Object Inspectors corresponding to the struct returned by TerminatePartial and the     * fields within the struct - "maxLength" "sumLength" "count" "countNulls"      */
Hive,WITHOUT_CLASSIFICATION,//  only one of belows is not-null   total length of sample prunes splits exceeded   percent to total input prunes splits exceeded   row count per split do not prune splits 
Hive,WITHOUT_CLASSIFICATION,// as of (8/27/2014) Hive 0.14 ACID/Orc requires HiveInputFormat 
Hive,WITHOUT_CLASSIFICATION,//  Retrieve all partitions generated from partition pruner and partition column pruner 
Hive,WITHOUT_CLASSIFICATION,//  The type of the Hive column   Cannot store the actual TypeInfo because that would require 
Hive,WITHOUT_CLASSIFICATION,//  Check if this UDF has been provided with type params for the output char type 
Hive,WITHOUT_CLASSIFICATION,//  ALTER TABLE ... ADD COLUMNS 
Hive,WITHOUT_CLASSIFICATION,//  right is larger 
Hive,WITHOUT_CLASSIFICATION,//  [bacabc] 
Hive,WITHOUT_CLASSIFICATION,//  Test 4 variations of callbacks. 2 increases/2 revokes - do not update the same task again;   Then increase + decrease and decrease + increase the 2nd call coming after the message is sent;   the message callback should undo the change. 
Hive,WITHOUT_CLASSIFICATION,//  Append this container to the loaded list 
Hive,WITHOUT_CLASSIFICATION,/*  * Captures the Window processing specified in a Query. A Query may * contain: * - UDAF invocations on a Window. * - Lead/Lag function invocations that can only be evaluated in a *   Partition. * - For Queries that don't have a Group By all UDAF invocations are *   treated as Window Function invocations. * - For Queries that don't have a Group By the Having condition is *   handled as a post processing on the rows output by Windowing *   processing. * Windowing is a container of all the Select Expressions that are * to be handled by Windowing. These are held in 2 lists: the functions * list holds WindowFunction invocations; the expressions list holds * Select Expressions having Lead/Lag function calls. It may also * contain an ASTNode representing the post filter to apply on the * output of Window Functions. * Windowing also contains all the Windows defined in the Query. One of * the Windows is designated as the 'default' Window. If the Query has a * Distribute By/Cluster By clause; then the information in these * clauses is captured as a Partitioning and used as the default Window * for the Query. Otherwise the first Window specified is treated as the * default. * Finally Windowing maintains a Map from an 'alias' to the ASTNode that * represents the Select Expression that was translated to a Window * Function invocation or a Window Expression. This is used when * building RowResolvers.  */
Hive,WITHOUT_CLASSIFICATION,//  2^30 (we cannot use Integer.MAX_VALUE which is 2^31-1). 
Hive,WITHOUT_CLASSIFICATION,//  Because Pairs give Java the vapors. 
Hive,WITHOUT_CLASSIFICATION,//  returns null always 
Hive,WITHOUT_CLASSIFICATION,//  if level is <0 the return all files/directories under the specified path 
Hive,WITHOUT_CLASSIFICATION,//  If it's not in this property it won't be in any others 
Hive,WITHOUT_CLASSIFICATION,//  Equivalent to acidSinks but for DDL operations that change data. 
Hive,WITHOUT_CLASSIFICATION,//  Rewritten grouping function 
Hive,WITHOUT_CLASSIFICATION,// remove currTask from childTasks 
Hive,WITHOUT_CLASSIFICATION,//  65535 and Integer.MAX_VALUE; the check for VARCHAR precision is done in Hive. 
Hive,WITHOUT_CLASSIFICATION,//  Maximum reasonable defragmentation headroom. Mostly kicks in on very small caches. 
Hive,WITHOUT_CLASSIFICATION,//  storing nanosecond interval in 2 longs) produces a timestamp. 
Hive,WITHOUT_CLASSIFICATION,// the the bucket we care about here 
Hive,WITHOUT_CLASSIFICATION,//  start inclusive to infinity inclusive 
Hive,WITHOUT_CLASSIFICATION,//  Table comment 
Hive,WITHOUT_CLASSIFICATION,//  Make sure we cross some buffer boundaries... 
Hive,WITHOUT_CLASSIFICATION,//  -Xmx speficied in GB 
Hive,WITHOUT_CLASSIFICATION,//  have to override it with the new conf since this is where   prewarm gets the conf object 
Hive,WITHOUT_CLASSIFICATION,//  Scale down again. 
Hive,WITHOUT_CLASSIFICATION,//  we need a new object to obey our immutable behavior. 
Hive,WITHOUT_CLASSIFICATION,//  while initializing so this need to be done here instead of constructor 
Hive,WITHOUT_CLASSIFICATION,//  Release but keep the lock (if present). 
Hive,WITHOUT_CLASSIFICATION,//  Case 7: NO column stats 
Hive,WITHOUT_CLASSIFICATION,//  first call to createPartitions should throw exception 
Hive,WITHOUT_CLASSIFICATION,//  harUri is used to access the partition's files which are in the archive   The format of the RI is something like: 
Hive,WITHOUT_CLASSIFICATION,//  we are creating filter here so should not be returning NULL.   Not sure why Calcite return NULL 
Hive,WITHOUT_CLASSIFICATION,//  Check en edge case to throw Exception if we can not build a single query for 'NOT IN' clause cases as mentioned at the method comments. 
Hive,WITHOUT_CLASSIFICATION,//  We're sure this part is smaller than memory limit 
Hive,WITHOUT_CLASSIFICATION,//  Replace is essentially renaming a plan to the name of an existing plan with backup. 
Hive,WITHOUT_CLASSIFICATION,//  SUCCESSFUL 
Hive,WITHOUT_CLASSIFICATION,//  TODO: create this centrally in HS2 case 
Hive,WITHOUT_CLASSIFICATION,/*    * DECIMAL.   *   * NOTE: The scale parameter is for text serialization (e.g. HiveDecimal.toFormatString) that   * creates trailing zeroes output decimals.    */
Hive,WITHOUT_CLASSIFICATION,// now make an ExportTask from temp table 
Hive,WITHOUT_CLASSIFICATION,//  7 pending   3 pending   5 pending 
Hive,WITHOUT_CLASSIFICATION,//  3. For missing Wdw Frames or for Frames with only a Start Boundary completely 
Hive,WITHOUT_CLASSIFICATION,//  not be able to acquire the lock within that time period 
Hive,WITHOUT_CLASSIFICATION,//  DICTIONARY encoding 
Hive,WITHOUT_CLASSIFICATION,//  The output columns for the destination table should match with the join keys   This is to handle queries of the form:   insert overwrite table T3   select T1.key T1.key2 UDF(T1.value T2.value)   from T1 join T2 on T1.key = T2.key and T1.key2 = T2.key2   where T1 T2 and T3 are bucketized/sorted on key and key2   Assuming T1 is the table on which the mapper is run the following is true:   . The number of buckets for T1 and T3 should be same   . The bucketing/sorting columns for T1 T2 and T3 should be same   . The sort order of T1 should match with the sort order for T3.   . If T1 is partitioned only a single partition of T1 can be selected.   . The select list should contain with (T1.key T1.key2) or (T2.key T2.key2) 
Hive,WITHOUT_CLASSIFICATION,//  ConsoleReader will do the substitution if and only if there   is exactly one valid completion so we ignore other cases. 
Hive,WITHOUT_CLASSIFICATION,//  Table DDL 
Hive,WITHOUT_CLASSIFICATION,//  The current expression node is a column see if the column alias is already a part of   the return set s. If not and we already have an entry in set s this is an invalid expression 
Hive,WITHOUT_CLASSIFICATION,//  Use Case 5. 
Hive,WITHOUT_CLASSIFICATION,//  Validate the first parameter which is the expression to compute over. This should be an 
Hive,WITHOUT_CLASSIFICATION,//  default is false 
Hive,WITHOUT_CLASSIFICATION,//  Open txns are already sorted in ascending order. This list may or may not include HWM   but it is guaranteed that list won't have txn > HWM. But if we overwrite the HWM with currentTxn 
Hive,WITHOUT_CLASSIFICATION,//  get the #nulls 
Hive,WITHOUT_CLASSIFICATION,//  Utility to get patterns from a url every array element is match for one 
Hive,WITHOUT_CLASSIFICATION,//  the stack is the Table scan operator. 
Hive,WITHOUT_CLASSIFICATION,//  should have rolled over to next transaction batch 
Hive,WITHOUT_CLASSIFICATION,//  First we quickly check if the two RS operators can actually be merged.   We already know that these two RS operators have the same parent but   we need to check whether both RS are actually equal. Further we check   whether their child is also equal. If any of these conditions are not 
Hive,WITHOUT_CLASSIFICATION,//  Format 
Hive,WITHOUT_CLASSIFICATION,//  set results to be returned 
Hive,WITHOUT_CLASSIFICATION,//  Next put row into corresponding hash partition 
Hive,WITHOUT_CLASSIFICATION,//  List of locks to protect the above list 
Hive,WITHOUT_CLASSIFICATION,//  Partitions 
Hive,WITHOUT_CLASSIFICATION,//  they will be different values. 
Hive,WITHOUT_CLASSIFICATION,/*    * Flush any catalog objects held by the metastore implementation.  Note that this does not   * flush statistics objects.  This should be called at the beginning of each query.    */
Hive,WITHOUT_CLASSIFICATION,//  Concurrent increase and revocation then another increase - after the message is sent. 
Hive,WITHOUT_CLASSIFICATION,//  Add all the names for previous batches. 
Hive,WITHOUT_CLASSIFICATION,/*    * represents Column information exposed by a QueryBlock.    */
Hive,WITHOUT_CLASSIFICATION,//  If the struct is null and level > 1 DynamicSerDe will call   writeNull(); 
Hive,WITHOUT_CLASSIFICATION,//  cached to use serialize data 
Hive,WITHOUT_CLASSIFICATION,//  If the Group by operator has null key 
Hive,WITHOUT_CLASSIFICATION,//  All remaining functions simply delegate to objectStore 
Hive,WITHOUT_CLASSIFICATION,//  Column not found in target table. Its a new column. Its schema is map<stringstring> 
Hive,WITHOUT_CLASSIFICATION,//  A printStream that stores messages logged to it in a list. 
Hive,WITHOUT_CLASSIFICATION,//  set default spark configurations. 
Hive,WITHOUT_CLASSIFICATION,//  Test that fetching a non-existent db-name yields ObjectNotFound. 
Hive,WITHOUT_CLASSIFICATION,//  to break into multiple batches remove duplicates first. 
Hive,WITHOUT_CLASSIFICATION,//  This second attempt to create it should throw 
Hive,WITHOUT_CLASSIFICATION,// recursively remove this task from its children's parent task 
Hive,WITHOUT_CLASSIFICATION,//  If replace flag is not set by caller then by default set it to true to maintain backward compatibility 
Hive,WITHOUT_CLASSIFICATION,//  Fill up host1 with p2 tasks.   Leave host2 empty   Try running both p1 tasks on host1.   R: Single preemption triggered followed by allocation followed by another preemption.   
Hive,WITHOUT_CLASSIFICATION,//  reduce sink row resolver used to generate map join op 
Hive,WITHOUT_CLASSIFICATION,//  There's some access (to get ACLs) so assume it means free for all. 
Hive,WITHOUT_CLASSIFICATION,//  Cleanup 
Hive,WITHOUT_CLASSIFICATION,//  This is expected to be a no-op so we will return null when we use local metastore. 
Hive,WITHOUT_CLASSIFICATION,//  5. Introduce Project Rel above original left/right inputs if cast is 
Hive,WITHOUT_CLASSIFICATION,//  With Data - Unsupported for the test case 
Hive,WITHOUT_CLASSIFICATION,//  test that overflow produces null 
Hive,WITHOUT_CLASSIFICATION,// ---------------------------------------------------------------------------   Outer join specific members.   
Hive,WITHOUT_CLASSIFICATION,//  Tracks vertices for which notifications have been registered 
Hive,WITHOUT_CLASSIFICATION,//  Descendants tasks who subscribe feeds from this task 
Hive,WITHOUT_CLASSIFICATION,//  Don't fail the query - just return null (caller should skip cache lookup). 
Hive,WITHOUT_CLASSIFICATION,//  CONSIDER: Validation of type information 
Hive,WITHOUT_CLASSIFICATION,// For unit testing no harm in hard-coding allocator ceiling to LONG.MAX_VALUE 
Hive,WITHOUT_CLASSIFICATION,//  create Parquet file with specific data 
Hive,WITHOUT_CLASSIFICATION,//  Get writable object 
Hive,WITHOUT_CLASSIFICATION,//                           MRConfig.SHUFFLE_SSL_ENABLED_DEFAULT)) {          LOG.info("Encrypted shuffle is enabled.");          sslFactory = new SSLFactory(SSLFactory.Mode.SERVER conf);          sslFactory.init();        } 
Hive,WITHOUT_CLASSIFICATION,//  Cache patternkey.matcher(path).matches() 
Hive,WITHOUT_CLASSIFICATION,//  We are now positioned at the end of this field's bytes. 
Hive,WITHOUT_CLASSIFICATION,// clean up 
Hive,WITHOUT_CLASSIFICATION,//  The exception has been logged by the lower layer. 
Hive,WITHOUT_CLASSIFICATION,//  Try to construct an object 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setBlob(java.lang.String   * java.io.InputStream)    */
Hive,WITHOUT_CLASSIFICATION,/*      * what is the index of the row beyond the set of rows that match this pattern.      */
Hive,WITHOUT_CLASSIFICATION,//  array level   array level 
Hive,WITHOUT_CLASSIFICATION,//  MiniHS2 cluster is up .. let it run until someone kills the test 
Hive,WITHOUT_CLASSIFICATION,//  TYPE 
Hive,WITHOUT_CLASSIFICATION,//  to check if all field inspectors are initialized 
Hive,WITHOUT_CLASSIFICATION,//  A larger scale is ok -- we will knock off lower digits and round. 
Hive,WITHOUT_CLASSIFICATION,//  Context handler 
Hive,WITHOUT_CLASSIFICATION,//  ignore the first child since it is the variable 
Hive,WITHOUT_CLASSIFICATION,//  op is a DemuxOperator and it directly connects to childOP.   We will add this MuxOperator between DemuxOperator   and childOP. 
Hive,WITHOUT_CLASSIFICATION,//  Add a partition key & ensure its reflected in the schema. 
Hive,WITHOUT_CLASSIFICATION,//  framework expects MapWork instances that have no physical parents (i.e.: union parent is   fine broadcast parent isn't) 
Hive,WITHOUT_CLASSIFICATION,//  getXXX returns 0 for numeric types false for boolean and null for other 
Hive,WITHOUT_CLASSIFICATION,//  1.2. With that in mind determine disk ranges to read/get from cache (not by stream). 
Hive,WITHOUT_CLASSIFICATION,//  guard against poor configuration of noconditional task size. We let hash table grow till 2/3'rd memory   available for container/executor 
Hive,WITHOUT_CLASSIFICATION,//  This processing only needs to happen for the small tables 
Hive,WITHOUT_CLASSIFICATION,//  Verify that the created table is identical to sourceTable. 
Hive,WITHOUT_CLASSIFICATION,//  required string dest_input_name = 3; 
Hive,WITHOUT_CLASSIFICATION,//  row[0] is the column name 
Hive,WITHOUT_CLASSIFICATION,//  Round fractional must be 0.  Not allowed to throw away digits. 
Hive,WITHOUT_CLASSIFICATION,//  direct heap allocations need to be safer 
Hive,WITHOUT_CLASSIFICATION,/*    * intialize the tables    */
Hive,WITHOUT_CLASSIFICATION,//  if null all tables/views are returned 
Hive,WITHOUT_CLASSIFICATION,//  It passed the test load 
Hive,WITHOUT_CLASSIFICATION,//  UnsupportedOperationExceptions happen in the normal course of business   so no need to log them as errors all the time. 
Hive,WITHOUT_CLASSIFICATION,// ~ Instance fields -------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  It is not a cast 
Hive,WITHOUT_CLASSIFICATION,//  We are done. 
Hive,WITHOUT_CLASSIFICATION,//  -a <authType> 
Hive,WITHOUT_CLASSIFICATION,//  Aggregate above to sum up the sub-totals 
Hive,WITHOUT_CLASSIFICATION,//  if oldPath is a subdir of destf but it could not be cleaned 
Hive,WITHOUT_CLASSIFICATION,//  We can always do equality predicate. Just need to make sure we get appropriate   BA representation of constant of filter condition.   We can do other comparisons only if storage format in hbase is either binary   or we are dealing with string types since there lexicographic ordering will suffice. 
Hive,WITHOUT_CLASSIFICATION,//  From the value arrays and our isRepeated selected isNull arrays generate the batch! 
Hive,WITHOUT_CLASSIFICATION,//  Mixed sign cases 
Hive,WITHOUT_CLASSIFICATION,//  must be honored 
Hive,WITHOUT_CLASSIFICATION,//  Make sure the parent directory exists.  It is not an error   to recreate an existing directory 
Hive,WITHOUT_CLASSIFICATION,//  scope opened/closed once (multiple opens do not count) 
Hive,WITHOUT_CLASSIFICATION,//  For now we don't take any pool action. In future we might restore the session based   on this and get rid of the logic outside of the pool that replaces/reopens/etc. 
Hive,WITHOUT_CLASSIFICATION,//  Call the executor which will execute the appropriate command based on the parsed options 
Hive,WITHOUT_CLASSIFICATION,//  Order expressions which will only get set and used for RANGE windowing type 
Hive,WITHOUT_CLASSIFICATION,//  Phase 2 - verify we get the expected objects created by all threads. 
Hive,WITHOUT_CLASSIFICATION,//  2) We check whether output works when we merge the operators will collide.       Work1   Work2    (merge TS in W1 & W2)        Work1         \   /                  ->                  | |       X         Work3                                     Work3     If we do we cannot merge. The reason is that Tez currently does   not support parallel edges i.e. multiple edges from same work x 
Hive,WITHOUT_CLASSIFICATION,//  Stores big table rows as bytes for native vector map join. 
Hive,WITHOUT_CLASSIFICATION,//  forward compatible 
Hive,WITHOUT_CLASSIFICATION,//  try outer row resolver 
Hive,WITHOUT_CLASSIFICATION,//  check value argument 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#registerOutParameter(int int   * java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  Test setting fetch size above max 
Hive,WITHOUT_CLASSIFICATION,//  Test that read blocks exclusive 
Hive,WITHOUT_CLASSIFICATION,// do not authorize dummy readEntity or writeEntity 
Hive,WITHOUT_CLASSIFICATION,//  We are the left-most child. 
Hive,WITHOUT_CLASSIFICATION,//  divide by 10**-tenScale. check for rounding. 
Hive,WITHOUT_CLASSIFICATION,//  Definitely not an int. 
Hive,WITHOUT_CLASSIFICATION,//     runStatementOnDriver("select b from " + Table.ACIDTBL + " where a in (select b from " + Table.NONACIDORCTBL + ")"); 
Hive,WITHOUT_CLASSIFICATION,//  Using utility method above so that JDODataStoreException doesn't   have to be used here. This helps avoid adding jdo dependency for   hcatalog client uses 
Hive,WITHOUT_CLASSIFICATION,//  Try regular properties; 
Hive,WITHOUT_CLASSIFICATION,//  This is OK because the pending events will be sent via the succeeded/failed messages.   TaskDone is set before taskSucceeded/taskTerminated are sent out - which is what causes the   thread to exit 
Hive,WITHOUT_CLASSIFICATION,//  Read notification from metastore 
Hive,WITHOUT_CLASSIFICATION,//  required string vertex_name = 2; 
Hive,WITHOUT_CLASSIFICATION,//  roundPower < fastScale 
Hive,WITHOUT_CLASSIFICATION,//  Noone can take this buffer out and thus change the level after we lock and if   they take it out before we lock then we will fail to lock (same as   prepareOneHeaderForMove). 
Hive,WITHOUT_CLASSIFICATION,//  We defer allocation until we really need it since in the common case there is   no CRLF substitution. 
Hive,WITHOUT_CLASSIFICATION,//  CONCERN: isRepeating 
Hive,WITHOUT_CLASSIFICATION,//  get_partitions will parse out the catalog and db names itself 
Hive,WITHOUT_CLASSIFICATION,/*        * >> Super set of       * If the grouping columns are abc and the sorting columns are ab       * grouping columns >> sorting columns       * (or grouping columns are a superset of sorting columns)       *       * Similarly << means subset of       *       * No intersection between Sort Columns and BucketCols:       *       * 1. Sort Cols = Group By Cols ---> Partial Match       * 2. Group By Cols >> Sort By Cols --> No Match       * 3. Group By Cols << Sort By Cols --> Partial Match       *       * BucketCols <= SortCols (bucket columns is either same or a prefix of sort columns)       *       * 1. Sort Cols = Group By Cols ---> Complete Match       * 2. Group By Cols >> Sort By Cols --> No Match       * 3. Group By Cols << Sort By Cols --> Complete Match if Group By Cols >= BucketCols       * --> Partial Match otherwise       *       * BucketCols >> SortCols (bucket columns is a superset of sorting columns)       *       * 1. group by cols <= sort cols --> partial match       * 2. group by cols >> sort cols --> no match       *       * One exception to this rule is:       * If GroupByCols == SortCols and all bucketing columns are part of sorting columns       * (in any order) it is a complete match        */
Hive,WITHOUT_CLASSIFICATION,//  See planIndexReading - only read non-row-index streams if involved in SARGs. 
Hive,WITHOUT_CLASSIFICATION,//  The partition was dropped before we got around to cleaning it. 
Hive,WITHOUT_CLASSIFICATION,//  Clean up 
Hive,WITHOUT_CLASSIFICATION,/* for multi-statement txns you may have multiple events for the same      * row in the same (current) transaction.  We want to collapse these to just the last one      * regardless whether we are minor compacting.  Consider INSERT/UPDATE/UPDATE of the      * same row in the same txn.  There is no benefit passing along anything except the last      * event.  If we did want to pass it along we'd have to include statementId in the row      * returned so that compaction could write it out or make minor minor compaction understand      * how to write out delta files in delta_xxx_yyy_stid format.  There doesn't seem to be any      * value in this.      *      * todo: this could be simplified since in Acid2 even if you update the same row 2 times in 1      * txn it will have different ROW__IDs i.e. there is no such thing as multiple versions of      * the same physical row.  Leave it for now since this Acid reader should go away altogether      * and org.apache.hadoop.hive.ql.io.orc.VectorizedOrcAcidRowBatchReader will be used. */
Hive,WITHOUT_CLASSIFICATION,//  Show we cannot create a child of the directory with no permissions 
Hive,WITHOUT_CLASSIFICATION,// -----------------------------------------------------------------------------------------------   Serialization methods.  ----------------------------------------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,/*  1. is defined with skewed columns and skewed values in metadata  */
Hive,WITHOUT_CLASSIFICATION,//  For HIVE-18817 the only thing missing is the last stripe index information.   Get the information from the last stripe and append it to the existing index.   The actual stripe data can be written as-is similar to OrcFileMergeOperator. 
Hive,WITHOUT_CLASSIFICATION,/*    * tests if the beeline behaves like default mode if there is no user-specific connection   * configuration file    */
Hive,WITHOUT_CLASSIFICATION,//  Note: we don't take the scheduling lock here although the call to queue is still 
Hive,WITHOUT_CLASSIFICATION,//  a schema retriever has been provided as well. Attempt to read the write schema from the   retriever 
Hive,WITHOUT_CLASSIFICATION,//  Equal groups return what we can handle 
Hive,WITHOUT_CLASSIFICATION,//  Keep buckets from the streaming relation 
Hive,WITHOUT_CLASSIFICATION,//  Wait for startup to complete 
Hive,WITHOUT_CLASSIFICATION,//  Alter db "testDatabaseOps" via ObjectStore 
Hive,WITHOUT_CLASSIFICATION,//  Get a list of aliases for the same column 
Hive,WITHOUT_CLASSIFICATION,//  We won't try to be too strict in checking this because we're comparing   table create intents with observed tables created.   If it does have a location though we will compare as with external tables 
Hive,WITHOUT_CLASSIFICATION,//  modify it below as part of imposing view column names. 
Hive,WITHOUT_CLASSIFICATION,//   only tablename no pattern and db 
Hive,WITHOUT_CLASSIFICATION,//  we will put a fork in the plan at the source of the reduce sink 
Hive,WITHOUT_CLASSIFICATION,// -----------------------------------------------------------------------------------------------   Standard overrides methods.  ----------------------------------------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  eventSourceTableDesc eventSourceColumnName evenSourcePartKeyExpr move in lock-step.   One entry is added to each at the same time 
Hive,WITHOUT_CLASSIFICATION,//  This likely indicates that an instance has recently restarted 
Hive,WITHOUT_CLASSIFICATION,//  256KB 
Hive,WITHOUT_CLASSIFICATION,//  Float.compare() treats -0.0 and 0.0 as different 
Hive,WITHOUT_CLASSIFICATION,//  The types array tells us the number of columns in the data 
Hive,WITHOUT_CLASSIFICATION,//  Get partition column stats for this table 
Hive,WITHOUT_CLASSIFICATION,//  if one of them is null replace the old params with the new one 
Hive,WITHOUT_CLASSIFICATION,//  Map keys are required to be primitive and may be serialized in binary format 
Hive,WITHOUT_CLASSIFICATION,//  skip this column 
Hive,WITHOUT_CLASSIFICATION,//  Create a separate thread to send the events. 
Hive,WITHOUT_CLASSIFICATION,//  This is the GenericUDAF name 
Hive,WITHOUT_CLASSIFICATION,//  when column name is specified in describe table DDL colPath will   will be table_name.column_name 
Hive,WITHOUT_CLASSIFICATION,//  Test that MAX_ADDITIONAL_SECONDS_BITS is really the maximum value of the 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.CLIServiceTest#setUp()    */
Hive,WITHOUT_CLASSIFICATION,// Order matters assuming later that __time_granularity comes first then __druidPartitionKey 
Hive,WITHOUT_CLASSIFICATION,//  read the contents and make sure they match 
Hive,WITHOUT_CLASSIFICATION,//  Fraction digit continue into highest longword. 
Hive,WITHOUT_CLASSIFICATION,//  If table is dropped when dump in progress just skip partitions dump 
Hive,WITHOUT_CLASSIFICATION,//  Find the appropriate storage descriptor 
Hive,WITHOUT_CLASSIFICATION,//  we will bail out; we do not want to end up with limits all over the tree 
Hive,WITHOUT_CLASSIFICATION,//  this should probably never happen see 
Hive,WITHOUT_CLASSIFICATION,//  runCtx and ctx share the configuration but not isExplainPlan() 
Hive,WITHOUT_CLASSIFICATION,//  outPath will be   non-union case: <table-dir>/<staging-dir>/<partition-dir>/<taskid>   union case: <table-dir>/<staging-dir>/<partition-dir>/<union-dir>/<taskid> 
Hive,WITHOUT_CLASSIFICATION,//  round up to the next MB 
Hive,WITHOUT_CLASSIFICATION,//  this should work as comments are stripped by HiveCli 
Hive,WITHOUT_CLASSIFICATION,//  location: set to null here can be overwritten by the IMPORT stmt 
Hive,WITHOUT_CLASSIFICATION,//  let's see if we can go one step further and just uber this puppy 
Hive,WITHOUT_CLASSIFICATION,//  Create and delete a temp file 
Hive,WITHOUT_CLASSIFICATION,//  Case 1: If there's no delay for the heartbeat txn should be able to commit 
Hive,WITHOUT_CLASSIFICATION,//  finalization 
Hive,WITHOUT_CLASSIFICATION,// principal is specified authorize on it 
Hive,WITHOUT_CLASSIFICATION,//  Original bucket files and delta directory should stay until Cleaner kicks in. 
Hive,WITHOUT_CLASSIFICATION,//  2. use util function to aggr stats 
Hive,WITHOUT_CLASSIFICATION,//  now correct +1 error and rounding up. 
Hive,WITHOUT_CLASSIFICATION,//  store the new joinContext 
Hive,WITHOUT_CLASSIFICATION,/*  Construct list bucketing location mappings from sub-directory name.  */
Hive,WITHOUT_CLASSIFICATION,//  setup uncaught exception handler for the current thread 
Hive,WITHOUT_CLASSIFICATION,//  changing the tags. 
Hive,WITHOUT_CLASSIFICATION,//  For partitioned tables get the size of all the partitions after pruning 
Hive,WITHOUT_CLASSIFICATION,//  the reason that we set the txn manager for the cxt here is because each   query has its own ctx object. The txn mgr is shared across the 
Hive,WITHOUT_CLASSIFICATION,//  This is the one we are expecting. 
Hive,WITHOUT_CLASSIFICATION,//  If not visited yet 
Hive,WITHOUT_CLASSIFICATION,//  HIVE_JOB_CREDSTORE_PASSWORD 
Hive,WITHOUT_CLASSIFICATION,// mock operation and opHandle for operationManager 
Hive,WITHOUT_CLASSIFICATION,//  Confirm that the function is now gone 
Hive,WITHOUT_CLASSIFICATION,//  Most tests are done with ANSI SQL mode enabled set it back to true 
Hive,WITHOUT_CLASSIFICATION,//  Since HiveMetaStoreClient is not threadsafe hive clients are not  shared across threads.   Thread local variable containing each thread's unique ID is used as one of the keys for the cache 
Hive,WITHOUT_CLASSIFICATION,//  Update min if min is lesser than the smallest value seen so far 
Hive,WITHOUT_CLASSIFICATION,//  This is rather convoluted... to simplify for perf we could call getRawKeyValue   instead of writable and serialize based on Java type as opposed to OI. 
Hive,WITHOUT_CLASSIFICATION,//  Used by DatumReader.  Applications should not call.  
Hive,WITHOUT_CLASSIFICATION,//  No materialized view or not heuristic approach normal costing 
Hive,WITHOUT_CLASSIFICATION,/*     * update the Work name which referred by Operators in following Works.     */
Hive,WITHOUT_CLASSIFICATION,//  No skew on the table to take care of 
Hive,WITHOUT_CLASSIFICATION,//  Try with ascii chars 
Hive,WITHOUT_CLASSIFICATION,//  recall setup so that we get an object store with the metrics initalized 
Hive,WITHOUT_CLASSIFICATION,//  Note: we must handle downgradedTask after this. We do it at the end outside the lock. 
Hive,WITHOUT_CLASSIFICATION,//  Note that this is not a typical list accumulator - there's no call to finalize   the last list. Instead we add list to SD first as well as locally to add elements. 
Hive,WITHOUT_CLASSIFICATION,//  Deserialize the on-disk hash table 
Hive,WITHOUT_CLASSIFICATION,//  4 buildup the ob expr AST 
Hive,WITHOUT_CLASSIFICATION,//  where MAPREDUCE-1501 is not present 
Hive,WITHOUT_CLASSIFICATION,//  Localize the non-conf resources that are missing from the current list. 
Hive,WITHOUT_CLASSIFICATION,//  Is the result Decimal64 precision? 
Hive,WITHOUT_CLASSIFICATION,//  INSERT_DATA 
Hive,WITHOUT_CLASSIFICATION,//  Not sure how to get around that. 
Hive,WITHOUT_CLASSIFICATION,//  ignore the first static partition 
Hive,WITHOUT_CLASSIFICATION,//  Keep a copy of HiveConf so if Session conf changes we may need to get a new HMS client. 
Hive,WITHOUT_CLASSIFICATION,/*  Get number of partitions  */
Hive,WITHOUT_CLASSIFICATION,//  Descending 
Hive,WITHOUT_CLASSIFICATION,//  clean request 
Hive,WITHOUT_CLASSIFICATION,//  trim line 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#registerOutParameter(int int int)    */
Hive,WITHOUT_CLASSIFICATION,//  Generates a sequence list of indexes 
Hive,WITHOUT_CLASSIFICATION,//  Check a random one. These can change w/Hive versions. 
Hive,WITHOUT_CLASSIFICATION,//  If string is entirely whitespace no need to apply trailingSpaces. 
Hive,WITHOUT_CLASSIFICATION,//     assertHelper(AssertHelperOp.SAME pm0 pm1 TableScanOperator.class); 
Hive,WITHOUT_CLASSIFICATION,//  The above members are initialized by the constructor and must not be   transient.  --------------------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  Generate SQLOperator for merging the aggregations 
Hive,WITHOUT_CLASSIFICATION,/*    * update the SQL string with parameters set by setXXX methods of {@link PreparedStatement}   *   * @param sql   * @param parameters   * @return updated SQL string   * @throws SQLException     */
Hive,WITHOUT_CLASSIFICATION,//  Fill the column vector with the provided value 
Hive,WITHOUT_CLASSIFICATION,//  Store as a list to have a consistent order between getTests and the test argument generation. 
Hive,WITHOUT_CLASSIFICATION,//  2*a 
Hive,WITHOUT_CLASSIFICATION,//  Process --help 
Hive,WITHOUT_CLASSIFICATION,//  -i <init file> 
Hive,WITHOUT_CLASSIFICATION,//  Fill up host1 with tasks. Leave host2 empty. 
Hive,WITHOUT_CLASSIFICATION,// actually temp table does not support partitions cascade is not applicable here 
Hive,WITHOUT_CLASSIFICATION,//  drop tables before dropping db 
Hive,WITHOUT_CLASSIFICATION,//  FETCH_TYPE 
Hive,WITHOUT_CLASSIFICATION,//  where the first event refers to source path and  second event refers to CM path 
Hive,WITHOUT_CLASSIFICATION,//  Generate Spark plan 
Hive,WITHOUT_CLASSIFICATION,//  Don't allow a query that returns everything it will blow stuff up. 
Hive,WITHOUT_CLASSIFICATION,// Check if the configure job properties is called from input   or output for setting asymmetric properties 
Hive,WITHOUT_CLASSIFICATION,//  There should be one exception message per file 
Hive,WITHOUT_CLASSIFICATION,//  after the stats phase we might have some cyclic dependencies that we need 
Hive,WITHOUT_CLASSIFICATION,//  Insert search in the beginning would have failed if these parents didn't exist. 
Hive,WITHOUT_CLASSIFICATION,//  columnExprMap has the reverse of what we need - a mapping of the internal column names   to the ExprNodeDesc from the previous operation.   Find the key/value where the ExprNodeDesc value matches the column we are searching for. 
Hive,WITHOUT_CLASSIFICATION,// if conflict updates p=1/q=3 else update p=1/q=2  deletes from p=1/q=2 p=2/q=2  insert p=1/q=2 p=1/q=3 and new part 1/1 
Hive,WITHOUT_CLASSIFICATION,//  Only valid if allKeyInputColumnsRepeating is true. 
Hive,WITHOUT_CLASSIFICATION,//  for base type do nothing. Other types like structs may initialize   internal data   structures. 
Hive,WITHOUT_CLASSIFICATION,//  No value found. 
Hive,WITHOUT_CLASSIFICATION,//  Every thread created by this thread pool will use the same handler 
Hive,WITHOUT_CLASSIFICATION,//  time part 
Hive,WITHOUT_CLASSIFICATION,//  Test 
Hive,WITHOUT_CLASSIFICATION,//  Check if we are in LLAP if so it needs to be determined if we should use BMJ or DPHJ 
Hive,WITHOUT_CLASSIFICATION,//  NAMES 
Hive,WITHOUT_CLASSIFICATION,//  inlined> 
Hive,WITHOUT_CLASSIFICATION,//  Skip all the INSERT events 
Hive,WITHOUT_CLASSIFICATION,//  SERDE_NAME 
Hive,WITHOUT_CLASSIFICATION,//  Kryo docs say 0-8 are taken. Strange things happen if you don't set an ID when registering   classes. 
Hive,WITHOUT_CLASSIFICATION,//  create N-1 map join tasks 
Hive,WITHOUT_CLASSIFICATION,//  Username and password are added to the http request header. 
Hive,WITHOUT_CLASSIFICATION,/*  This writer will be created when writing the first row in order to get  information about how to inspect the record data.   */
Hive,WITHOUT_CLASSIFICATION,/*  Constructors  */
Hive,WITHOUT_CLASSIFICATION,//  lastly it should be in deDupedNonDistIrefs 
Hive,WITHOUT_CLASSIFICATION,//  The dispatcher finds SMB and if there is semijoin optimization before it removes it. 
Hive,WITHOUT_CLASSIFICATION,//  generates initial key 
Hive,WITHOUT_CLASSIFICATION,//  Write to a URI no locking done for this 
Hive,WITHOUT_CLASSIFICATION,//  production is: i32 
Hive,WITHOUT_CLASSIFICATION,//  Populate the cache. 
Hive,WITHOUT_CLASSIFICATION,//  update the keys to use operator name 
Hive,WITHOUT_CLASSIFICATION,//  We could start a move if it's being evicted but let's not do it for now. 
Hive,WITHOUT_CLASSIFICATION,//  Test that two shared read locks can share a partition 
Hive,WITHOUT_CLASSIFICATION,/*    * If hive job credstore location is not set but hadoop credential provider is set   * jobConf should contain hadoop credstore location and password should be from HADOOP_CREDSTORE_PASSWORD    */
Hive,WITHOUT_CLASSIFICATION,//  Go over all the tasks and dump out the plans 
Hive,WITHOUT_CLASSIFICATION,//  Round a double to 8 decimal places. 
Hive,WITHOUT_CLASSIFICATION,//  Store the row. See comments above for why we need a new copy of the row. 
Hive,WITHOUT_CLASSIFICATION,//  eg group name TaskCounter_Map_7_OUTPUT_Reducer_8 counter name OUTPUT_RECORDS 
Hive,WITHOUT_CLASSIFICATION,//  Go over the list and find if a reducer is not needed 
Hive,WITHOUT_CLASSIFICATION,//  An array of hash map results so we can do lookups on the whole batch before output result 
Hive,WITHOUT_CLASSIFICATION,//  Finally add the files to the existing AM (if any). The old code seems to do this twice   first for all the new resources regardless of type; and then for all the session resources   that are not of type file (see branch-1 calls to addAppMasterLocalFiles: from updateSession   and with resourceMap from submit). 
Hive,WITHOUT_CLASSIFICATION,//  5. Add Proj on top of TS 
Hive,WITHOUT_CLASSIFICATION,//  figure out if it is table level or partition level 
Hive,WITHOUT_CLASSIFICATION,// Read the record with existing record reader ID and same **evolved** schema 
Hive,WITHOUT_CLASSIFICATION,//  user did not specfied alias names infer names from outputOI 
Hive,WITHOUT_CLASSIFICATION,//  If it's a standard map reduce task check what if anything it inferred about 
Hive,WITHOUT_CLASSIFICATION,//  returns true as long as there is more data in mockResultData array 
Hive,WITHOUT_CLASSIFICATION,//  ////// Generate ReduceSink Operator 
Hive,WITHOUT_CLASSIFICATION,//  This data structure is needed to create the new project 
Hive,WITHOUT_CLASSIFICATION,//  Arithmetic with a type date (LongColumnVector storing epoch days) and type interval_year_month (LongColumnVector storing 
Hive,WITHOUT_CLASSIFICATION,//  Report progress for each stderr line but no more frequently than once   per minute. 
Hive,WITHOUT_CLASSIFICATION,// setBoolean  setBoolean  setShort  setInt  setFloat  setDouble  setString  setLong  setByte  setByte  setString  setTimestamp 
Hive,WITHOUT_CLASSIFICATION,//  5 rows should be returned 
Hive,WITHOUT_CLASSIFICATION,//  5. Run other optimizations that do not need stats 
Hive,WITHOUT_CLASSIFICATION,//  Confirm default managed table paths 
Hive,WITHOUT_CLASSIFICATION,//  Re-enable the node if a task completed due to preemption. Capacity has become available   and we may have been able to communicate with the node. 
Hive,WITHOUT_CLASSIFICATION,//  assign 0 to simplify hashcode 
Hive,WITHOUT_CLASSIFICATION,//  1. If we need to sort tuples based on the value of some   of their columns 
Hive,WITHOUT_CLASSIFICATION,//  Unescape the partition name 
Hive,WITHOUT_CLASSIFICATION,//  2. Local scratch dir 
Hive,WITHOUT_CLASSIFICATION,//  2nd cancel 
Hive,WITHOUT_CLASSIFICATION,//  BYTE_VAL 
Hive,WITHOUT_CLASSIFICATION,//  All output columns used for bucketing/sorting of the destination table should   belong to the same input table     insert overwrite table T3     select T1.key T2.key2 UDF(T1.value T2.value)     from T1 join T2 on T1.key = T2.key and T1.key2 = T2.key2   is not optimized whereas the insert is optimized if the select list is either changed to   (T1.key T1.key2 UDF(T1.value T2.value)) or (T2.key T2.key2 UDF(T1.value T2.value)) 
Hive,WITHOUT_CLASSIFICATION,//  They both require DbTxnManager and both need to recordValidTxns when acquiring locks in Driver 
Hive,WITHOUT_CLASSIFICATION,//  Mapping from expression node to is an expression containing only   partition or virtual column or constants 
Hive,WITHOUT_CLASSIFICATION,//  2nd bit set - element 2 was already in cache.   Should have been replaced 
Hive,WITHOUT_CLASSIFICATION,//  add some multi-byte characters to test length routine later. 
Hive,WITHOUT_CLASSIFICATION,//  spark has its own config for merging 
Hive,WITHOUT_CLASSIFICATION,//  generate pruned column list for all relevant operators 
Hive,WITHOUT_CLASSIFICATION,//  For replicating an HCatPartition definition. 
Hive,WITHOUT_CLASSIFICATION,//  operator native... 
Hive,WITHOUT_CLASSIFICATION,//  ////// 3. Generate ReduceSinkOperator2 
Hive,WITHOUT_CLASSIFICATION,//  from 2/31 to 2/28 
Hive,WITHOUT_CLASSIFICATION,//  Set the conf variable values for this test. 
Hive,WITHOUT_CLASSIFICATION,//  blank " " (1 byte)   Cyrillic Capital DJE U+402 (2 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  HS2 operation handle guid string 
Hive,WITHOUT_CLASSIFICATION,//  infrastructure is in place 
Hive,WITHOUT_CLASSIFICATION,//  nodeMap registration is not required since there's no taskId association. 
Hive,WITHOUT_CLASSIFICATION,//  it has an open txn in it 
Hive,WITHOUT_CLASSIFICATION,//  set the operation handle information in Driver so that thrift API users   can use the operation handle they receive to lookup query information in 
Hive,WITHOUT_CLASSIFICATION,//  First branch is query second branch is MV 
Hive,WITHOUT_CLASSIFICATION,/*    * If any operator which does not allow map-side conversion is present in the mapper dont   * convert it into a conditional task.    */
Hive,WITHOUT_CLASSIFICATION,//  This configuration is used only for client side configuration. 
Hive,WITHOUT_CLASSIFICATION,//  the basic premise here is that we will rsync the directory to first working drone   then execute a local rsync on the node to the other drones. This keeps   us from executing tons of rsyncs on the master node conserving CPU 
Hive,WITHOUT_CLASSIFICATION,//  Date comparisons 
Hive,WITHOUT_CLASSIFICATION,//  Create directory 
Hive,WITHOUT_CLASSIFICATION,//  remove the last '' 
Hive,WITHOUT_CLASSIFICATION,//  2*b 
Hive,WITHOUT_CLASSIFICATION,//  its list of join keys 
Hive,WITHOUT_CLASSIFICATION,//  Check what happens when we ignore these errors 
Hive,WITHOUT_CLASSIFICATION,//  connection secret show up in the child process's command line. 
Hive,WITHOUT_CLASSIFICATION,//  else ptn already exists but we do nothing with it. 
Hive,WITHOUT_CLASSIFICATION,//  CONSDIER: We need a type name parser for TypeDescription. 
Hive,WITHOUT_CLASSIFICATION,//  An LRU cache using a linked hash map 
Hive,WITHOUT_CLASSIFICATION,//  message kept around in for debugging 
Hive,WITHOUT_CLASSIFICATION,//  OBJ_TO_REFRESH 
Hive,WITHOUT_CLASSIFICATION,//  lengths stream could be empty stream or already reached end of stream before present stream. 
Hive,WITHOUT_CLASSIFICATION,//  If the catalog name isn't set we need to go through and set it. 
Hive,WITHOUT_CLASSIFICATION,//  We may have already created the tables and thus don't need to redo it. 
Hive,WITHOUT_CLASSIFICATION,/*    * Result of JobCallable task after successful task completion. This is   * expected to be set by the thread which executes JobCallable task.    */
Hive,WITHOUT_CLASSIFICATION,//  If a failure happens here the intermediate archive files won't be 
Hive,WITHOUT_CLASSIFICATION,//  Make sure the map does not expand; should be able to find space. 
Hive,WITHOUT_CLASSIFICATION,//  All of the insert update and delete tests assume two tables T and U each with columns a   and b.  U it partitioned by an additional column ds.  These are created by parseAndAnalyze   and removed by cleanupTables(). 
Hive,WITHOUT_CLASSIFICATION,//  We remove the tasks above without state checks so just reset all metrics to 0. 
Hive,WITHOUT_CLASSIFICATION,//  if the outputType is a float cast the arguments to float to replicate the overflow behavior   in non-vectorized UDF GenericUDFPosMod 
Hive,WITHOUT_CLASSIFICATION,//  For cardinality values use numRows as default try to use ColStats if available 
Hive,WITHOUT_CLASSIFICATION,//  Single-Column Long hash table import. 
Hive,WITHOUT_CLASSIFICATION,//  extract the real user from the given token string 
Hive,WITHOUT_CLASSIFICATION,//  Allows for unescaped ASCII control characters in JSON values 
Hive,WITHOUT_CLASSIFICATION,//  Do the same without specifying writer time zone. This tests deserialization of older records 
Hive,WITHOUT_CLASSIFICATION,//  Skip over any leading 0s or 0xFFs 
Hive,WITHOUT_CLASSIFICATION,//  skip the last (partitioning) column since it is always non-null 
Hive,WITHOUT_CLASSIFICATION,//  Make sure to put the instance back again in case it was removed as part of a 
Hive,WITHOUT_CLASSIFICATION,//  rank the tables. 
Hive,WITHOUT_CLASSIFICATION,//   cars <= 9 
Hive,WITHOUT_CLASSIFICATION,// used for union (all?)  CO_PARTITION_EDGE  PARTITION_EDGE 
Hive,WITHOUT_CLASSIFICATION,//  original transaction 
Hive,WITHOUT_CLASSIFICATION,//  HIVE-14444 pending rename: before 
Hive,WITHOUT_CLASSIFICATION,//  setup stats in the operator plan 
Hive,WITHOUT_CLASSIFICATION,//  capture arguments to authorizer impl call and verify ip addresses passed 
Hive,WITHOUT_CLASSIFICATION,//  Update the NEXT_WRITE_ID for the given table after incrementing by number of write ids allocated 
Hive,WITHOUT_CLASSIFICATION,//        non-vectorized validates that explicitly during UDF init. 
Hive,WITHOUT_CLASSIFICATION,//  unset   distribution of keys is fixed   can change reducer count (ORDER BY can concat adjacent buckets)   can redistribute into buckets uniformly (GROUP BY can)   do not wait for downstream tasks 
Hive,WITHOUT_CLASSIFICATION,//  Set our current entry to null (since it's done) and try again. 
Hive,WITHOUT_CLASSIFICATION,//  RESOURCE_PLAN_NAME 
Hive,WITHOUT_CLASSIFICATION,//  Add hacks for well-known collections and maps to avoid estimating them. 
Hive,WITHOUT_CLASSIFICATION,//  Read dpp outputs 
Hive,WITHOUT_CLASSIFICATION,//  MIN_OPEN_WRITE_ID 
Hive,WITHOUT_CLASSIFICATION,//  in case of "DESCRIBE FORMATTED tablename column_name" statement colPath   will contain tablename.column_name. If column_name is not specified   colPath will be equal to tableName. This is how we can differentiate   if we are describing a table or column 
Hive,WITHOUT_CLASSIFICATION,//  detect if there are attributes in join key 
Hive,WITHOUT_CLASSIFICATION,// this happens if you change BUCKET_COUNT      } 
Hive,WITHOUT_CLASSIFICATION,//  for now totalResource = taskResource for llap 
Hive,WITHOUT_CLASSIFICATION,//  Will come here if an Exception was thrown in map() or reduce().   Hadoop always call close() even if an Exception was thrown in map() or   reduce(). 
Hive,WITHOUT_CLASSIFICATION,/* (MILLIS_PER_DAY - 1) */
Hive,WITHOUT_CLASSIFICATION,//  Auto-generate column aliases 
Hive,WITHOUT_CLASSIFICATION,//  COMPRESSED 
Hive,WITHOUT_CLASSIFICATION,//  Recurse. 
Hive,WITHOUT_CLASSIFICATION,/* Compaction preserves location of rows wrt buckets/tranches (for now) */
Hive,WITHOUT_CLASSIFICATION,/*     * If the ndv of the PK - FK side don't match and the PK side is a filter    * on the Key column then scale the NDV on the FK side.    *    * As described by Peter Boncz: http://databasearchitects.blogspot.com/    * in such cases we can be off by a large margin in the Join cardinality    * estimate. The e.g. he provides is on the join of StoreSales and DateDim    * on the TPCDS dataset. Since the DateDim is populated for 20 years into    * the future while the StoreSales only has 5 years worth of data there    * are 40 times fewer distinct dates in StoreSales.    *    * In general it is hard to infer the range for the foreign key on an    * arbitrary expression. For e.g. the NDV for DayofWeek is the same    * irrespective of NDV on the number of unique days whereas the    * NDV of Quarters has the same ratio as the NDV on the keys.    *    * But for expressions that apply only on columns that have the same NDV    * as the key (implying that they are alternate keys) we can apply the    * ratio. So in the case of StoreSales - DateDim joins for predicate on the    * d_date column we can apply the scaling factor.     */
Hive,WITHOUT_CLASSIFICATION,//  Change the plan to this structure.   Note that the aggregateRel is removed.     Project-A' (replace corvar to input ref from the Join)     Join (replace corvar to input ref from LeftInputRel)       LeftInputRel       RightInputRel(oreviously FilterInputRel) 
Hive,WITHOUT_CLASSIFICATION,//  Serves as lock for itself. 
Hive,WITHOUT_CLASSIFICATION,//  Remote Spark Context property. 
Hive,WITHOUT_CLASSIFICATION,//  This reduce sink has been processed already so the work for the parentRS exists 
Hive,WITHOUT_CLASSIFICATION,//  order matters in all of these so block 
Hive,WITHOUT_CLASSIFICATION,//  handles nulls in items[] 
Hive,WITHOUT_CLASSIFICATION,/*    * Return Hadoop-native RestCsrfPreventionFilter if it is available.   * Otherwise construct our own copy of its logic.    */
Hive,WITHOUT_CLASSIFICATION,//  Set to 0 to start with. This will be decremented for all columns for which events   are generated by this source - which is eventually used to determine number of expected 
Hive,WITHOUT_CLASSIFICATION,/*    * Determines whether the current node was actually closed and pushed. This   * should only be called in the final user action of a node scope.    */
Hive,WITHOUT_CLASSIFICATION,//  infer foreign key candidates positions 
Hive,WITHOUT_CLASSIFICATION,/*    * Generate the second GroupByOperator for the Group By Plan   * (parseInfo.getXXX(dest)). The new GroupByOperator will do the second   * aggregation based on the partial aggregation results.   *   * @param mode   *          the mode of aggregation (FINAL)   * @param genericUDAFEvaluators   *          The mapping from Aggregation StringTree to the   *          genericUDAFEvaluator.   * @return the new GroupByOperator   * @throws SemanticException    */
Hive,WITHOUT_CLASSIFICATION,//  Java Primitive Class? 
Hive,WITHOUT_CLASSIFICATION,//  @Signature // XXX 
Hive,WITHOUT_CLASSIFICATION,//  couldn't convince you otherwise? well then let's llap. 
Hive,WITHOUT_CLASSIFICATION,/* best effort */
Hive,WITHOUT_CLASSIFICATION,//  Local scratch dir 
Hive,WITHOUT_CLASSIFICATION,//  Only for incremental load need to validate if event is newer than the database. 
Hive,WITHOUT_CLASSIFICATION,//  If partKey is a constant we can check whether the partitions   have been already filtered 
Hive,WITHOUT_CLASSIFICATION,//  try to query stats for a column for which stats doesn't exist 
Hive,WITHOUT_CLASSIFICATION,//  the +1 to the size is because of the main work. 
Hive,WITHOUT_CLASSIFICATION,//  Copy conf file 
Hive,WITHOUT_CLASSIFICATION,//  MY_DOUBLE 
Hive,WITHOUT_CLASSIFICATION,//  Get the bucketing version 
Hive,WITHOUT_CLASSIFICATION,//  Never locked for eviction; Java object. 
Hive,WITHOUT_CLASSIFICATION,//  Expected exception as FileNotFoundException will occur if the partitions have custom   location 
Hive,WITHOUT_CLASSIFICATION,//  verify that the two are equal 
Hive,WITHOUT_CLASSIFICATION,//  1. Initialize aux data structures 
Hive,WITHOUT_CLASSIFICATION,//  3. Determine type of UDAF 
Hive,WITHOUT_CLASSIFICATION,//  make it easy to write .q unit tests instead of unique id generation.   however this does mean that in writing tests we have to be aware that   repl dump will clash with prior dumps and thus have to clean up properly. 
Hive,WITHOUT_CLASSIFICATION,//  grouping sets at this point 
Hive,WITHOUT_CLASSIFICATION,//  If the replacement is changed make sure we redo toString again. 
Hive,WITHOUT_CLASSIFICATION,//  We store the total memory that this MapJoin is going to use   which is calculated as totalSize/buckets with totalSize 
Hive,WITHOUT_CLASSIFICATION,//  failure hooks are run after HiveStatement is closed. wait sometime for failure hook to execute 
Hive,WITHOUT_CLASSIFICATION,/*    * Tries to optimize FROM clause of multi-insert. No attempt to optimize insert clauses of the query.   * Returns true if rewriting is successful false otherwise.    */
Hive,WITHOUT_CLASSIFICATION,// have we reached a new key group? 
Hive,WITHOUT_CLASSIFICATION,//  write a delta 
Hive,WITHOUT_CLASSIFICATION,//  Retry with same dump with which it was already loaded should resume the bootstrap load. 
Hive,WITHOUT_CLASSIFICATION,//  Descending   Null last (default for descending order) 
Hive,WITHOUT_CLASSIFICATION,// root must exist already 
Hive,WITHOUT_CLASSIFICATION,//  Total: 5/6 running. 
Hive,WITHOUT_CLASSIFICATION,// this enables vectorization of ROW__ID 
Hive,WITHOUT_CLASSIFICATION,//  invariant: reducerHash != null 
Hive,WITHOUT_CLASSIFICATION,//  check incompatible versions 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#execute()    */
Hive,WITHOUT_CLASSIFICATION,//  depending on the server setup. 
Hive,WITHOUT_CLASSIFICATION,//  need to update the mapCorVarToCorRel Update the output position   for the cor vars: only pass on the cor vars that are not used in 
Hive,WITHOUT_CLASSIFICATION,//  CHAR BETWEEN 
Hive,WITHOUT_CLASSIFICATION,//  Setup the actual ports in the configuration. 
Hive,WITHOUT_CLASSIFICATION,//  Now disregard null in second pass. 
Hive,WITHOUT_CLASSIFICATION,//  Link the list record to the first element. 
Hive,WITHOUT_CLASSIFICATION,//  Dummy final assignments. 
Hive,WITHOUT_CLASSIFICATION,//  Schema that exists in the Avro data file. 
Hive,WITHOUT_CLASSIFICATION,//  remove the current active zk server 
Hive,WITHOUT_CLASSIFICATION,//  Create test database and base tables once for all the test 
Hive,WITHOUT_CLASSIFICATION,//  Non-empty java opts with -Xmx specified in KB 
Hive,WITHOUT_CLASSIFICATION,//  fetch the partition referred to by the message and compare 
Hive,WITHOUT_CLASSIFICATION,//  perform dynamic partition pruning 
Hive,WITHOUT_CLASSIFICATION,//  and restore the state before walking each child 
Hive,WITHOUT_CLASSIFICATION,//  TODO: create immutable copies of all maps 
Hive,WITHOUT_CLASSIFICATION,//  Careful with the range here now we do not want to read the whole base file like deltas. 
Hive,WITHOUT_CLASSIFICATION,//  records whether delta dir is of type 'delete_delta_x_y...' 
Hive,WITHOUT_CLASSIFICATION,//  Processing files 
Hive,WITHOUT_CLASSIFICATION,/*  Note: In the following section Metadata-only import handling logic is     interleaved with regular repl-import logic. The rule of thumb being     followed here is that MD-only imports are essentially ALTERs. They do     not load data and should not be "creating" any metadata - they should     be replacing instead. The only place it makes sense for a MD-only import     to create is in the case of a table that's been dropped and recreated     or in the case of an unpartitioned table. In all other cases it should     behave like a noop or a pure MD alter.   */
Hive,WITHOUT_CLASSIFICATION,//  For Tez we don't use appId to distinguish the tokens. 
Hive,WITHOUT_CLASSIFICATION,//  there's a small number of buffers and they all live in the heap). 
Hive,WITHOUT_CLASSIFICATION,//  If we did not kill this session we expect everything to be present. 
Hive,WITHOUT_CLASSIFICATION,//  Make a copy so that we do not modify hookContext conf. 
Hive,WITHOUT_CLASSIFICATION,//  generate the map join operator; already checked the map join 
Hive,WITHOUT_CLASSIFICATION,//  Stores negative values to count columns. Eventually set to #tasks X #columns after the source vertex completes. 
Hive,WITHOUT_CLASSIFICATION,//  End RelDecorrelator.java 
Hive,WITHOUT_CLASSIFICATION,//  get the tables/views for the desired pattern - populate the output stream 
Hive,WITHOUT_CLASSIFICATION,//  at task startup 
Hive,WITHOUT_CLASSIFICATION,//  right border is the max 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise this is not a sampling predicate. We need to process it. 
Hive,WITHOUT_CLASSIFICATION,//  should detect double 
Hive,WITHOUT_CLASSIFICATION,//  Fail if we try to access an offset out of bounds 
Hive,WITHOUT_CLASSIFICATION,//  On LLAP dynamic value registry might already be cached. 
Hive,WITHOUT_CLASSIFICATION,//  via the environment context. 
Hive,WITHOUT_CLASSIFICATION,//  There's an RPC waiting for a reply. Exception was most probably caught while processing   the RPC so send an error. 
Hive,WITHOUT_CLASSIFICATION,//  No ranges use the ranges from the child 
Hive,WITHOUT_CLASSIFICATION,// put something in WRITE_SET 
Hive,WITHOUT_CLASSIFICATION,// ***************************************************************************   Data-related configuration properties.  *************************************************************************** 
Hive,WITHOUT_CLASSIFICATION,//  Remove expression node desc and all children of it from mapping 
Hive,WITHOUT_CLASSIFICATION,//  42000 is the generic SQLState for syntax error. 
Hive,WITHOUT_CLASSIFICATION,//  Determine if all digits below a power is zero. 
Hive,WITHOUT_CLASSIFICATION,// Now populate a structure to use to apply delete events 
Hive,WITHOUT_CLASSIFICATION,/*  Testing for equality of doubles after a math operation is   * not always reliable so use this as a tolerance.    */
Hive,WITHOUT_CLASSIFICATION,//  All must be selected otherwise size would be zero   Repeating property will not change. 
Hive,WITHOUT_CLASSIFICATION,//  A very simple counter to keep track of number of rows processed by the   reducer. It dumps   every 1 million times and quickly before that 
Hive,WITHOUT_CLASSIFICATION,//  how many records the writer buffers before it writes to disk 
Hive,WITHOUT_CLASSIFICATION,/*        * Clear all the reading variables.        */
Hive,WITHOUT_CLASSIFICATION,//  Were going to update the average variable row size by sampling the current batch 
Hive,WITHOUT_CLASSIFICATION,//  Mark a task as failed due to a comm failure. 
Hive,WITHOUT_CLASSIFICATION,//  If the lock manager is still null then it means we aren't using a 
Hive,WITHOUT_CLASSIFICATION,//  this is a count(*) transform it to count(nullIndicator)   the null indicator is located at the end 
Hive,WITHOUT_CLASSIFICATION,//  For this one don't specify a location to make sure it gets put in the catalog directory 
Hive,WITHOUT_CLASSIFICATION,// comletor add space after last delimeter 
Hive,WITHOUT_CLASSIFICATION,//  End of synchronized (ti)  
Hive,WITHOUT_CLASSIFICATION,//  Recursively do the first phase of semantic analysis for the subquery 
Hive,WITHOUT_CLASSIFICATION,//  flushed. 
Hive,WITHOUT_CLASSIFICATION,//  If custom dynamic location provided need to rename to final output path 
Hive,WITHOUT_CLASSIFICATION,//  Check that the table or partition isn't sorted as we don't yet support that. 
Hive,WITHOUT_CLASSIFICATION,//  Get partition-path. For grid='XYZ' place the partition outside the table-path. 
Hive,WITHOUT_CLASSIFICATION,//  output OI strips off the partition columns and retains other columns 
Hive,WITHOUT_CLASSIFICATION,//  Rewrite all INSERT references (all the node values for this key) 
Hive,WITHOUT_CLASSIFICATION,//  Note: if compaction creates a delta it won't replace an existing base dir so the txn ID         of the base dir won't be a part of delta's range. If otoh compaction creates a base         we don't care about this value because bases don't have min txn ID in the name.         However logically this should also take base into account if it's included. 
Hive,WITHOUT_CLASSIFICATION,//  4. The cookie is secured where as the client connect does not use SSL 
Hive,WITHOUT_CLASSIFICATION,//  go ahead with the estimation 
Hive,WITHOUT_CLASSIFICATION,// below value for a is bucket id for b - txn id (logically) 
Hive,WITHOUT_CLASSIFICATION,//  Replace any occurrence of dummyVectorOperator with our TableScanOperator. 
Hive,WITHOUT_CLASSIFICATION,//  See heapifyDown comment. 
Hive,WITHOUT_CLASSIFICATION,//  We don't exit the loop early because we want to extract the error code   corresponding to the bottommost error coded exception. 
Hive,WITHOUT_CLASSIFICATION,//  ParseContext 
Hive,WITHOUT_CLASSIFICATION,//  Catch-all rule when none of the others apply. 
Hive,WITHOUT_CLASSIFICATION,//  Register tasks on 2 nodes with a dependency on vertex1 completing. 
Hive,WITHOUT_CLASSIFICATION,//  Setup the map work for this thread. Pruning modified the work instance to potentially remove   partitions. The same work instance must be used when generating splits. 
Hive,WITHOUT_CLASSIFICATION,//  Perform repl 
Hive,WITHOUT_CLASSIFICATION,//  Here are some positive cases which can be executed as below : 
Hive,WITHOUT_CLASSIFICATION,// if here it means a concrurrent acquireLock() inserted the 'key' 
Hive,WITHOUT_CLASSIFICATION,//  Input name to position map 
Hive,WITHOUT_CLASSIFICATION,// true here indicates that sq_count_check is for IN/NOT IN subqueries 
Hive,WITHOUT_CLASSIFICATION,//  The third one has the base file so it shouldn't be combined but could be a base. 
Hive,WITHOUT_CLASSIFICATION,/*    * Read a field that is under a complex type.  It may be a primitive type or deeper complex type.    */
Hive,WITHOUT_CLASSIFICATION,//  Add ReplStateLogTask only if no pending table load tasks left for next cycle 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setTime(int java.sql.Time)    */
Hive,WITHOUT_CLASSIFICATION,//  We are making a new output vectorized row batch. 
Hive,WITHOUT_CLASSIFICATION,//  but have no nulls initially 
Hive,WITHOUT_CLASSIFICATION,//  For caching TableWrapper objects. Key is aggregate of database name and table name 
Hive,WITHOUT_CLASSIFICATION,//  The MV is outdated see whether we should consider it for rewriting or not 
Hive,WITHOUT_CLASSIFICATION,/* + cCtx.nextOperatorId() */
Hive,WITHOUT_CLASSIFICATION,//  check if srcf contains nested sub-directories 
Hive,WITHOUT_CLASSIFICATION,//  Put a compaction request in the queue. 
Hive,WITHOUT_CLASSIFICATION,//  This should not be null because we were allowed to bind with this username   safe check in case we were able to bind anonymously. 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise we wouldn't be here. 
Hive,WITHOUT_CLASSIFICATION,//  If any aggregate call has a filter bail out 
Hive,WITHOUT_CLASSIFICATION,//  schema is diff return false 
Hive,WITHOUT_CLASSIFICATION,//  Control characeters! According to JSON RFC u0020 
Hive,WITHOUT_CLASSIFICATION,/*  100 files x 100 size for 10 splits  */
Hive,WITHOUT_CLASSIFICATION,//  No access. 
Hive,WITHOUT_CLASSIFICATION,//  This will guarantee file name uniqueness. 
Hive,WITHOUT_CLASSIFICATION,//  must be sync with TOperationState in order 
Hive,WITHOUT_CLASSIFICATION,/*    * NOTE: The VectorPTFDesc has already been allocated and populated.    */
Hive,WITHOUT_CLASSIFICATION,//  propagate new conf to meta store 
Hive,WITHOUT_CLASSIFICATION,//  Release buffers as we are done with all the streams... also see toRelease comment. 
Hive,WITHOUT_CLASSIFICATION,//  for local file and hdfs key and value are same. 
Hive,WITHOUT_CLASSIFICATION,//  This may be invoked before a container is ever assigned to a task. allocateTask... app decides 
Hive,WITHOUT_CLASSIFICATION,//  Try with regular DECIMAL output type. 
Hive,WITHOUT_CLASSIFICATION,//  Disabled in HIVE-19509   Disabled in HIVE-19509   Disabled in HIVE-19509   Disabled in HIVE-19509   Disabled in HIVE-19509   Disabled in HIVE-19509   Disabled in HIVE-19509 
Hive,WITHOUT_CLASSIFICATION,//  MY_ENUM_STRUCTLIST_MAP 
Hive,WITHOUT_CLASSIFICATION,// private static Properties props; 
Hive,WITHOUT_CLASSIFICATION,//  partitioned tables don't have tableDesc set on the FetchTask. Instead   they have a list of PartitionDesc objects each with a table desc.   Let's   try to fetch the desc for the first partition and use it's   deserializer. 
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.UpdateFragmentRequestProto.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,//  Partial aggregation is performed on the mapper no distinct processing at the reducer 
Hive,WITHOUT_CLASSIFICATION,//  taking precedence in the case of partitioned tables 
Hive,WITHOUT_CLASSIFICATION,//  With nulls 
Hive,WITHOUT_CLASSIFICATION,//  Get the escape information 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: This writes into a scratch buffer within HiveDecimalWritable.   
Hive,WITHOUT_CLASSIFICATION,/*  * The root interface for a vector map join hash map.  */
Hive,WITHOUT_CLASSIFICATION,//  Non-empty java opts with -Xmx specified in GB 
Hive,WITHOUT_CLASSIFICATION,//  of the correlate. 
Hive,WITHOUT_CLASSIFICATION,// a dummy group) 
Hive,WITHOUT_CLASSIFICATION,//  add the finalOp after the union 
Hive,WITHOUT_CLASSIFICATION,//        it's hard to tell w/some code paths like UDFs/OIs etc. that are used in many places. 
Hive,WITHOUT_CLASSIFICATION,//  ideally hadoop should let us know whether map execution failed or not 
Hive,WITHOUT_CLASSIFICATION,//  For LazyStruct 
Hive,WITHOUT_CLASSIFICATION,//  delim does not exist in str 
Hive,WITHOUT_CLASSIFICATION,//  100 > x   neg-infinity to end exclusive 
Hive,WITHOUT_CLASSIFICATION,//  Must be escaped by BinarySortable. 
Hive,WITHOUT_CLASSIFICATION,//  Note: This is a readLock to prevent a race with queryComplete. Operations   and mutations within this lock need to be on concurrent structures. 
Hive,WITHOUT_CLASSIFICATION,//  For the CHAR and VARCHAR data types the maximum character length of   the column.  Otherwise 0. 
Hive,WITHOUT_CLASSIFICATION,//  This semaphore provides two functions:   1. Forces a cap on the number of outstanding async writes to channel   2. Ensures that channel isn't closed if there are any outstanding async writes 
Hive,WITHOUT_CLASSIFICATION,//  This is a sub-dir under the hdfsSessionPath. Will be removed along with that dir. 
Hive,WITHOUT_CLASSIFICATION,//  STATS_OBJ 
Hive,WITHOUT_CLASSIFICATION,// compare hosts 
Hive,WITHOUT_CLASSIFICATION,//  to get stats for the metastore does not break. See HIVE-12083 for motivation. 
Hive,WITHOUT_CLASSIFICATION,//  Set the necessary Accumulo information 
Hive,WITHOUT_CLASSIFICATION,//  Test reverse order. 
Hive,WITHOUT_CLASSIFICATION,//  INSERT_ONLY tables don't have to conform to ACID requirement like ORC or bucketing 
Hive,WITHOUT_CLASSIFICATION,// Hive is more restrictive so Hive->Pig works 
Hive,WITHOUT_CLASSIFICATION,//  for the argument. 
Hive,WITHOUT_CLASSIFICATION,//  Finally create session paths for this session   Local & non-local tmp location is configurable. however it is the same across 
Hive,WITHOUT_CLASSIFICATION,//  Walk through the Task Graph and invoke SparkDynamicPartitionPruningDispatcher 
Hive,WITHOUT_CLASSIFICATION,//  We don't want to acquire read locks during update or delete as we'll be acquiring write   locks instead. Also there's no need to lock temp tables since they're session wide 
Hive,WITHOUT_CLASSIFICATION,// Get the input format 
Hive,WITHOUT_CLASSIFICATION,//  Perform reconnect with the proper user context 
Hive,WITHOUT_CLASSIFICATION,//  generator. 
Hive,WITHOUT_CLASSIFICATION,/*    * Test multi-threaded implementation of checker to find out missing partitions    */
Hive,WITHOUT_CLASSIFICATION,//  This can happen for View or Index 
Hive,WITHOUT_CLASSIFICATION,//  No shuffle is needed. For union only.   HashPartition shuffle keys are not sorted in any way.   RangePartition shuffle keys are total sorted.   HashPartition shuffle keys are sorted by partition. 
Hive,WITHOUT_CLASSIFICATION,/*        * Since we have a result for all rows we don't need to do conditional NULL maintenance or       * turn off noNulls..        */
Hive,WITHOUT_CLASSIFICATION,//  Reader count already incremented during cache lookup. 
Hive,WITHOUT_CLASSIFICATION,//  if this is not set default value is set during config initialization   Default value can't be set in this constructor as it would refer names in other ConfVars 
Hive,WITHOUT_CLASSIFICATION,//  Add the new ReadEntity that were added to readEntityMap in PlanUtils.addInput 
Hive,WITHOUT_CLASSIFICATION,//  Functionality to remove semi-join optimization 
Hive,WITHOUT_CLASSIFICATION,//  This method only returns the result when activating a resource plan.   We could also add a boolean flag to be specified by the caller to see   when the result might be needed. 
Hive,WITHOUT_CLASSIFICATION,//  generates the plan from the operator tree 
Hive,WITHOUT_CLASSIFICATION,//  [abcabc] 
Hive,WITHOUT_CLASSIFICATION,//  used for GenericUDAFBridgeEvaluator 
Hive,WITHOUT_CLASSIFICATION,//  Extract only 'split: hdfs://...' 
Hive,WITHOUT_CLASSIFICATION,//  LOG.error("Got " + RecordReaderUtils.stringifyDiskRanges(footerRange)); 
Hive,WITHOUT_CLASSIFICATION,//  Check if DB/table/partition in C doesn't have repl.source.for props. Also ensure ckpt property 
Hive,WITHOUT_CLASSIFICATION,//  Make sure the jar containing the custom CompositeRowId is included   in the mapreduce job's classpath (libjars) 
Hive,WITHOUT_CLASSIFICATION,/*          * Throw TimeoutException to caller.          */
Hive,WITHOUT_CLASSIFICATION,//           of the queue (esp. in conjunction with (1)) and rerun them. 
Hive,WITHOUT_CLASSIFICATION,//  verify when first argument (boolean flags) is repeating 
Hive,WITHOUT_CLASSIFICATION,// 4 tables 
Hive,WITHOUT_CLASSIFICATION,// pass a flag to hide prefixes 
Hive,WITHOUT_CLASSIFICATION,//  Evaluate the key expressions once. 
Hive,WITHOUT_CLASSIFICATION,//  no-arg constructor to make kyro happy. 
Hive,WITHOUT_CLASSIFICATION,/*    * BOOLEAN.    */
Hive,WITHOUT_CLASSIFICATION,//  P 
Hive,WITHOUT_CLASSIFICATION,//  put it back and one additional table 
Hive,WITHOUT_CLASSIFICATION,//  estimate the number of hash table entries based on the size of each   entry. Since the size of a entry 
Hive,WITHOUT_CLASSIFICATION,//  Use SubmitWorkResponseProto.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,//  runDropPartitions is the main function that gets called with different options   partCount: total number of partitions that will be deleted   batchSize: maximum number of partitions that can be deleted in a batch      based on the above the test will check that the batch sizes are as expected   exceptionStatus can take 3 values     noException: no exception is expected.     oneException: first call throws exception.  Since dropPartitionInBatches will retry this                    will succeed after the first failure     allException: failure case where everything fails.  Will test that the test fails after                    retrying based on maxRetries when specified or based on a decaying factor 
Hive,WITHOUT_CLASSIFICATION,//  Use Case 2. 
Hive,WITHOUT_CLASSIFICATION,//  This will trigger new calls to metastore to collect metadata 
Hive,WITHOUT_CLASSIFICATION,//  not required 
Hive,WITHOUT_CLASSIFICATION,//  Try to find the default db postfix; don't check two last components - at least there   should be a table and file (we could also try to throw away partition/bucket/acid stuff). 
Hive,WITHOUT_CLASSIFICATION,//  We've encountered a new key must save current one   We can't forward yet the aggregators have not been evaluated 
Hive,WITHOUT_CLASSIFICATION,// for NULL we just write out the type 
Hive,WITHOUT_CLASSIFICATION,//  Make sure we get exceptions strategies might have thrown. 
Hive,WITHOUT_CLASSIFICATION,/*    * Used as a dummy root operator to attach vectorized operators that will be built in parallel   * to the current non-vectorized operator tree.    */
Hive,WITHOUT_CLASSIFICATION,//  we should use '\0' for COLUMN_NAME_DELIMITER if column name contains COMMA   but we should also take care of the backward compatibility 
Hive,WITHOUT_CLASSIFICATION,//  For now old class. 
Hive,WITHOUT_CLASSIFICATION,//  allowing this to be increased via config breaks the merge impl   p=10 = ~1kb per vector or smaller 
Hive,WITHOUT_CLASSIFICATION,//  1.2. Fix up the query for materialization rebuild 
Hive,WITHOUT_CLASSIFICATION,// https://docs.oracle.com/cd/E17952_01/refman-5.6-en/select.html 
Hive,WITHOUT_CLASSIFICATION,//  Bail out if RS or TS is encountered. 
Hive,WITHOUT_CLASSIFICATION,// 1. Distinct aggregate rewrite 
Hive,WITHOUT_CLASSIFICATION,//  add constant size for unions tags 
Hive,WITHOUT_CLASSIFICATION,//  Also MIN_HISTORY_LEVEL won't have any entries as no reference for open txns. 
Hive,WITHOUT_CLASSIFICATION,//  We won't write the set   expressions in the rewritten query.  We'll patch that up later.   The set list from update should be the second child (index 1) 
Hive,WITHOUT_CLASSIFICATION,//  Runtime constants + deterministic functions can be folded. 
Hive,WITHOUT_CLASSIFICATION,//  During repl load NoSuchObjectException in foreign key shall   ignore as the foreign table may not be part of the replication 
Hive,WITHOUT_CLASSIFICATION,//  End: tests that check values from Pig that are out of range for target column 
Hive,WITHOUT_CLASSIFICATION,//  Process --listHAPeers 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   required   required 
Hive,WITHOUT_CLASSIFICATION,// Log with int input and double base 
Hive,WITHOUT_CLASSIFICATION,//  resFile   pCtx   RootTasks   FetchTask   analyzer   explainConfig   cboInfo 
Hive,WITHOUT_CLASSIFICATION,//  vectorized row batch reader 
Hive,WITHOUT_CLASSIFICATION,//  Subclasses must override this with a function that implements the desired logic. 
Hive,WITHOUT_CLASSIFICATION,/*      * Write information about the old value (which becomes our next) at the beginning     * of our new value.      */
Hive,WITHOUT_CLASSIFICATION,//  Multi-file load is for dynamic partitions when some partitions do not   need to merge and they can simply be moved to the target directory. 
Hive,WITHOUT_CLASSIFICATION,//  Don't validate column count - no encodings for vectors. 
Hive,WITHOUT_CLASSIFICATION,//  In case of Spark the credential provider location is provided in the jobConf when the job is submitted 
Hive,WITHOUT_CLASSIFICATION,//  This is checked by DDLSemanticAnalyzer 
Hive,WITHOUT_CLASSIFICATION,//  1. For Wdw Specs that refer to Window Defns inherit missing components 
Hive,WITHOUT_CLASSIFICATION,//  2.Row resolvers for input output 
Hive,WITHOUT_CLASSIFICATION,/*    * Lookup an byte array key in the hash multi-set.   *   * @param keyBytes   *         A byte array containing the key within a range.   * @param keyStart   *         The offset the beginning of the key.   * @param keyLength   *         The length of the key.   * @param hashMultiSetResult   *         The object to receive small table value(s) information on a MATCH.   *         Or for SPILL it has information on where to spill the big table row.   *   * @return   *         Whether the lookup was a match no match or spilled (the partition with the key   *         is currently spilled).    */
Hive,WITHOUT_CLASSIFICATION,//  The previous rules can pull up projections through join operators 
Hive,WITHOUT_CLASSIFICATION,//  create 9 dummy partitions 
Hive,WITHOUT_CLASSIFICATION,//  with extra structs 
Hive,WITHOUT_CLASSIFICATION,//  If Call is a redundant cast then bail out. Ex: cast(true)BOOLEAN 
Hive,WITHOUT_CLASSIFICATION,//  We need to "remember" the input object inspector so that we need to know the input type 
Hive,WITHOUT_CLASSIFICATION,//  negative range is bigger than positive range so there is no risk   of overflow here. 
Hive,WITHOUT_CLASSIFICATION,//  We need to remove those branches that   1 ended with a ReduceSinkOperator and   2 the ReduceSinkOperator's name is not the same as childReducerName.   Also if the cloned work is not the first we remove ALL leaf operators except 
Hive,WITHOUT_CLASSIFICATION,//  Add original files to obsolete list if any 
Hive,WITHOUT_CLASSIFICATION,//  delim is 2 chars 
Hive,WITHOUT_CLASSIFICATION,//  parallelism shouldn't be set for cartesian product vertex 
Hive,WITHOUT_CLASSIFICATION,//    Comparison   
Hive,WITHOUT_CLASSIFICATION,//  we already have the merge work corresponding to this merge join operator 
Hive,WITHOUT_CLASSIFICATION,//  The ELSE expression is either IdentityExpression (a column) or a ConstantVectorExpression 
Hive,WITHOUT_CLASSIFICATION,//  bigint 
Hive,WITHOUT_CLASSIFICATION,// would be nice if there was a way to determine if quotes are needed 
Hive,WITHOUT_CLASSIFICATION,// debatable if this is correct but that's how it's implemented 
Hive,WITHOUT_CLASSIFICATION,//  we have a prefix with a wildcard 
Hive,WITHOUT_CLASSIFICATION,//  replace right Key input ref 
Hive,WITHOUT_CLASSIFICATION,/*    * Vectorization.    */
Hive,WITHOUT_CLASSIFICATION,//  1 scheduling run will happen which may or may not pick up this task in the test.. 
Hive,WITHOUT_CLASSIFICATION,//  Using system classloader as the parent. Using thread context 
Hive,WITHOUT_CLASSIFICATION,/* |------+----------------+---------------+----------+-------+-----------------------------------|| Use  | Boundary2.type | Boundary2.amt | Sort Key | Order | Behavior                          || Case |                |               |          |       |                                   ||------+----------------+---------------+----------+-------+-----------------------------------||   1. | CURRENT ROW    |               | ANY      | ANY   | scan forward until row R2         ||      |                |               |          |       | such that R2.sk != R.sk           ||      |                |               |          |       | end = R2.idx                      ||   2. | FOLLOWING      | UNB           | ANY      | ANY   | end = partition.size()            ||------+----------------+---------------+----------+-------+-----------------------------------|    */
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setAsciiStream(int java.io.InputStream   * long)    */
Hive,WITHOUT_CLASSIFICATION,//  Test the idempotent behavior of Open and Commit Txn 
Hive,WITHOUT_CLASSIFICATION,//  If stats aggregator is not present clear the current aggregator stats.   For eg. if a merge is being performed stats already collected by aggregator (numrows etc.)   are still valid. However if a load file is being performed the old stats collected by   aggregator are not valid. It might be a good idea to clear them instead of leaving wrong   and old stats.   Since HIVE-12661 we maintain the old stats (although may be wrong) for CBO   purpose. We use a flag COLUMN_STATS_ACCURATE to   show the accuracy of the stats. 
Hive,WITHOUT_CLASSIFICATION,// Local file system is using pfile:/// {@link ProxyLocalFileSystem} 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setClob(int java.io.Reader)    */
Hive,WITHOUT_CLASSIFICATION,//  All the pending get requests should just be requeued elsewhere.   Note that we never queue session reuse so sessionToReuse would be null. 
Hive,WITHOUT_CLASSIFICATION,//  PARTITIONNAME 
Hive,WITHOUT_CLASSIFICATION,//  get the string representing action type if its non default action type 
Hive,WITHOUT_CLASSIFICATION,//  but kept unchanged throughout the operator tree for one row 
Hive,WITHOUT_CLASSIFICATION,//  CNAMEs/subjectAltName verification 
Hive,WITHOUT_CLASSIFICATION,//  initialize stats publishing table for noscan which has only stats task   the rest of MR task following stats task initializes it in ExecDriver.java 
Hive,WITHOUT_CLASSIFICATION,//  anchor the pattern to the start:end of the whole string. 
Hive,WITHOUT_CLASSIFICATION,//        list need to be refactored out to be done only once. 
Hive,WITHOUT_CLASSIFICATION,//  shortcut 0 length means no fields 
Hive,WITHOUT_CLASSIFICATION,// get big table 
Hive,WITHOUT_CLASSIFICATION,//  All checks passed return null. 
Hive,WITHOUT_CLASSIFICATION,//  If is a DPP check if actually it refers to same target column etc. 
Hive,WITHOUT_CLASSIFICATION,//  replace the output expression with the input expression so that 
Hive,WITHOUT_CLASSIFICATION,//  bitset array 
Hive,WITHOUT_CLASSIFICATION,//  Replace the synthetic predicate with true and bail out 
Hive,WITHOUT_CLASSIFICATION,//  For serialization only. 
Hive,WITHOUT_CLASSIFICATION,//  make the conditional task as the child of the current leaf task 
Hive,WITHOUT_CLASSIFICATION,//  unfortunately no quick path. let's do scale up/down 
Hive,WITHOUT_CLASSIFICATION,//  PK/FQ relationship: NDV of selColSourceStat is a superset of what is in tsColStat 
Hive,WITHOUT_CLASSIFICATION,//  If it is not an outer join or the post-condition filters   are empty or the row passed them 
Hive,WITHOUT_CLASSIFICATION,//  actually temp table does not support partitions cascade is not   applicable here 
Hive,WITHOUT_CLASSIFICATION,//  PRECONDITION: p should always be a directory 
Hive,WITHOUT_CLASSIFICATION,//  flag to indicate if these counters are subject to change across different test runs 
Hive,WITHOUT_CLASSIFICATION,//  If numRecords = -1 fetch all records.   Hence skip all the below checks when numRecords = -1. 
Hive,WITHOUT_CLASSIFICATION,//  Catch-all due to some exec time dependencies on session state   that would cause ClassNoFoundException otherwise 
Hive,WITHOUT_CLASSIFICATION,//  Write the items to the output stream. 
Hive,WITHOUT_CLASSIFICATION,//  Test using the same cache where first n rows are inserted then cache is cleared.   Next reuse the same cache and insert another m rows and verify the cache stores correctly.   This simulates reusing the same cache over and over again. 
Hive,WITHOUT_CLASSIFICATION,//  The output of a partial aggregation is a list of doubles representing the   histogram being constructed. The first element in the list is the user-specified   number of bins in the histogram and the histogram itself is represented as (xy)   pairs following the first element so the list length should *always* be odd. 
Hive,WITHOUT_CLASSIFICATION,//  Revert to default keystore path 
Hive,WITHOUT_CLASSIFICATION,//  Create partitions for the partitioned table 
Hive,WITHOUT_CLASSIFICATION,//  min we allow tez to pick 
Hive,WITHOUT_CLASSIFICATION,//  We have no data at all for this part of the stream (could be unneeded) skip. 
Hive,WITHOUT_CLASSIFICATION,//  If global contains includes individual modules can only contain additional includes. 
Hive,WITHOUT_CLASSIFICATION,//  We need to provide the minimum number of columns to be read so   LazySimpleDeserializeRead's separator parser does not waste time. 
Hive,WITHOUT_CLASSIFICATION,//  since we are closing the previous fsp's record writers we need to see if we can get 
Hive,WITHOUT_CLASSIFICATION,//  Task is currently running 
Hive,WITHOUT_CLASSIFICATION,//  a list of AND expressions that we need to distribute 
Hive,WITHOUT_CLASSIFICATION,//  Verify null output data entry is not 0 but rather the value specified by design 
Hive,WITHOUT_CLASSIFICATION,//  this class 
Hive,WITHOUT_CLASSIFICATION,//  string length should work after enforceMaxLength() 
Hive,WITHOUT_CLASSIFICATION,//  safety check for L53 to get parentOp although it is very unlikely that   stack size is less than 2 i.e. there is only one MergeJoinOperator in the stack. 
Hive,WITHOUT_CLASSIFICATION,//  The incoming vectorization context.  It describes the input big table vectorized row batch. 
Hive,WITHOUT_CLASSIFICATION,/* target/tmp/org.apache.hadoop.hive.ql.TestTxnCommands-1519423568221/├── export│   ├── _metadata│   └── p=1│       └── delta_0000001_0000001_0000│           └── bucket_00000 */
Hive,WITHOUT_CLASSIFICATION,// one more major compaction 
Hive,WITHOUT_CLASSIFICATION,//  limit to that for now. 
Hive,WITHOUT_CLASSIFICATION,//  Column names - we lose the enumness of this schema 
Hive,WITHOUT_CLASSIFICATION,//  LazyBinaryUtils.writeVLongToByteArray   offset   length 
Hive,WITHOUT_CLASSIFICATION,//  3) Get txn tables that are being written 
Hive,WITHOUT_CLASSIFICATION,/*    * Lookup an byte array key in the hash set.   *   * @param keyBytes   *         A byte array containing the key within a range.   * @param keyStart   *         The offset the beginning of the key.   * @param keyLength   *         The length of the key.   * @param hashSetResult   *         The object to receive small table value(s) information on a MATCH.   *         Or for SPILL it has information on where to spill the big table row.   *   * @return   *         Whether the lookup was a match no match or spilled (the partition with the key   *         is currently spilled).    */
Hive,WITHOUT_CLASSIFICATION,//  point for a linear scan has been identified at which point this value is unset. 
Hive,WITHOUT_CLASSIFICATION,//  Extrapolation is not needed for columns noExtraColumnNames 
Hive,WITHOUT_CLASSIFICATION,//  Config settings. 
Hive,WITHOUT_CLASSIFICATION,//  3/ update the byte size of the struct 
Hive,WITHOUT_CLASSIFICATION,//  Try to merge rest of operators 
Hive,WITHOUT_CLASSIFICATION,//  this test requires disruptor jar in classpath 
Hive,WITHOUT_CLASSIFICATION,//  map join operator by default has no bucket cols and num of reduce sinks 
Hive,WITHOUT_CLASSIFICATION,//  type interval_day_time (IntervalDayTimeColumnVector storing nanosecond interval in 2 primitives). 
Hive,WITHOUT_CLASSIFICATION,//  Matches only ForwardOperators which are preceded by some other operator in the tree   in particular it can't be a reducer (and hence cannot be one of the ForwardOperators 
Hive,WITHOUT_CLASSIFICATION,//  Only set the default catalog on the client. 
Hive,WITHOUT_CLASSIFICATION,//  required   required   optional   optional 
Hive,WITHOUT_CLASSIFICATION,/*    * This is the same as the setChildren method below but for empty tables.    */
Hive,WITHOUT_CLASSIFICATION,//  Test that attempting to unlock locks associated with a transaction   generates an error 
Hive,WITHOUT_CLASSIFICATION,//  Move the clock forward and trigger a run. 
Hive,WITHOUT_CLASSIFICATION,//  If there are more than one skewed values 
Hive,WITHOUT_CLASSIFICATION,//  Run the cleaner thread until cache is cleanUntil% occupied 
Hive,WITHOUT_CLASSIFICATION,//  COPY_FROM 
Hive,WITHOUT_CLASSIFICATION,//  DONE 
Hive,WITHOUT_CLASSIFICATION,//  q is contained within p' - p   set MSB to 0 
Hive,WITHOUT_CLASSIFICATION,//  Update the stats which do not require a complete scan. 
Hive,WITHOUT_CLASSIFICATION,//  The "bottom" of the call stack is at the front of the array. The elements are as follows:     [0] getStackTrace()     [1] shouldSkip()     [2] caller test method 
Hive,WITHOUT_CLASSIFICATION,//  Input value serde needs to be an array to support different SerDe   for different tags 
Hive,WITHOUT_CLASSIFICATION,//  calculate filter propagation directions for each alias 
Hive,WITHOUT_CLASSIFICATION,//  Event 5 6 7 
Hive,WITHOUT_CLASSIFICATION,//  TEZ AM will only localize FILE (no script operators in the AM) 
Hive,WITHOUT_CLASSIFICATION,//  no-op - HMSHander not needed by this impl 
Hive,WITHOUT_CLASSIFICATION,//  call-1: listLocatedStatus - mock:/mocktbl2 
Hive,WITHOUT_CLASSIFICATION,//  This is test for llap command AuthZ added in HIVE-19033 which require ZK access for it to pass 
Hive,WITHOUT_CLASSIFICATION,//  set timestamp before moving to cmroot so we can   avoid race condition CM remove the file before setting 
Hive,WITHOUT_CLASSIFICATION,//  Key design point for REPL DUMP is to not have any txns older than current txn in which dump runs.   This is needed to ensure that Repl dump doesn't copy any data files written by any open txns   mainly for streaming ingest case where one delta file shall have data from committed/aborted/open txns.   It may also have data inconsistency if the on-going txns doesn't have corresponding open/write   events captured which means catch-up incremental phase won't be able to replicate those txns.   So the logic is to wait for configured amount of time to see if all open txns < current txn is   getting aborted/committed. If not then we forcefully abort those txns just like AcidHouseKeeperService. 
Hive,WITHOUT_CLASSIFICATION,//  Evict all results grouped with this index; it cannot be any key further in the batch.   If we evict a key from this batch the keys grouped with it cannot be earlier that that key. 
Hive,WITHOUT_CLASSIFICATION,//  total 3 entries (2 valid + 1 fake) 
Hive,WITHOUT_CLASSIFICATION,//  no custom vertex or edge   custom vertex and custom edge but single MR Input   custom vertex custom edge and multi MR Input   custom vertex no custom edge multi MR Input 
Hive,WITHOUT_CLASSIFICATION,/*      * Optimize the loops by pulling special end cases and global decisions like isEscaped out!      */
Hive,WITHOUT_CLASSIFICATION,//  the correct result that the blank value is not there. 
Hive,WITHOUT_CLASSIFICATION,//  This will be hit if there's a large number of mapIds in a single request   (Determined by the cache size further up) in which case we go to disk again. 
Hive,WITHOUT_CLASSIFICATION,//  Expressions macro table used when we deserialize the query from calcite plan 
Hive,WITHOUT_CLASSIFICATION,/*  * Specialized class for doing a vectorized map join that is an inner join on Multi-Key * and only big table columns appear in the join result so a hash multi-set is used.  */
Hive,WITHOUT_CLASSIFICATION,//  Not supposed to be a compactable table. 
Hive,WITHOUT_CLASSIFICATION,//  if RS is inserted by enforce bucketing or sorting we need to remove it   since ReduceSinkDeDuplication will not merge them to single RS.   RS inserted by enforce bucketing/sorting will have bucketing column in   reduce sink key whereas RS inserted by this optimization will have   partition columns followed by bucket number followed by sort columns in   the reduce sink key. Since both key columns are not prefix subset   ReduceSinkDeDuplication will not merge them together resulting in 2 MR jobs. 
Hive,WITHOUT_CLASSIFICATION,//  TEMPORARILY: 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#createBlob()    */
Hive,WITHOUT_CLASSIFICATION,//  We have 0 bytes of data for this part for now. 
Hive,WITHOUT_CLASSIFICATION,/*  Create new source files with same filenames  */
Hive,WITHOUT_CLASSIFICATION,//  confirm the batch sizes were 23 15 8 in the three calls to create partitions 
Hive,WITHOUT_CLASSIFICATION,//  call-1: listLocatedStatus - mock:/mocktbl1 
Hive,WITHOUT_CLASSIFICATION,//  TypeInfo 
Hive,WITHOUT_CLASSIFICATION,//  COMMENTS 
Hive,WITHOUT_CLASSIFICATION,//  2) test with txn.Abort() 
Hive,WITHOUT_CLASSIFICATION,//  If an expression does not have a where clause there can be no common filter 
Hive,WITHOUT_CLASSIFICATION,//  Writer for producing row from input batch 
Hive,WITHOUT_CLASSIFICATION,/*    * This map maintains the PTFInvocationSpec for each PTF chain invocation in this QB.    */
Hive,WITHOUT_CLASSIFICATION,//  Simulate an unknown type 
Hive,WITHOUT_CLASSIFICATION,// check that files produced by compaction still have the version marker 
Hive,WITHOUT_CLASSIFICATION,//  We are trying to adding map joins to handle skew keys and map join right   now does not work with outer joins 
Hive,WITHOUT_CLASSIFICATION,//  "-blah -foo bar" form 
Hive,WITHOUT_CLASSIFICATION,//  After closing the path is set to null... 
Hive,WITHOUT_CLASSIFICATION,//  "A comma separated list of work names used as prefix. 
Hive,WITHOUT_CLASSIFICATION,//  Create table and insert two file of the same content 
Hive,WITHOUT_CLASSIFICATION,//  We only support changing the SerDe mapping and the state. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getRowId(int)    */
Hive,WITHOUT_CLASSIFICATION,//  Looks for the most encrypted table location   It may return null if there are not tables encrypted or are not part of HDFS 
Hive,WITHOUT_CLASSIFICATION,//  LRU extreme frequency of accesses should be ignored only order matters. 
Hive,WITHOUT_CLASSIFICATION,/*    * If this the first PPTF in the chain and there is no partition specified   * then assume the user wants to include the entire input in 1 partition.    */
Hive,WITHOUT_CLASSIFICATION,//  Filters are using an index which should match 3 rows 
Hive,WITHOUT_CLASSIFICATION,//  test case sensitivity 
Hive,WITHOUT_CLASSIFICATION,//  done processing so far 
Hive,WITHOUT_CLASSIFICATION,//  We are just a relay; send pause to encoded data producer. 
Hive,WITHOUT_CLASSIFICATION,//  No equivalent Java type for the backing structure need to recurse and build a list 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) FieldRequiredness  */
Hive,WITHOUT_CLASSIFICATION,// close with null reporter 
Hive,WITHOUT_CLASSIFICATION,//  these 2 flags are intended only for the big-key map work 
Hive,WITHOUT_CLASSIFICATION,//  We can only push down stuff which appears as part of   a pure conjunction:  reject OR CASE etc. 
Hive,WITHOUT_CLASSIFICATION,// invoking init method of baseHandler this way since it adds the retry logic  in case of transient failures in init method 
Hive,WITHOUT_CLASSIFICATION,//  We only support COUNT/SUM/MIN/MAX for the "single" count distinct optimization 
Hive,WITHOUT_CLASSIFICATION,//  for bucket join testing 
Hive,WITHOUT_CLASSIFICATION,//  Not completely accurate since OOB heartbeats could go out. 
Hive,WITHOUT_CLASSIFICATION,//  This get should succeed because its variance ((10-9)/9) is within past MAX_VARIANCE (0.5) 
Hive,WITHOUT_CLASSIFICATION,//  convert to DPHJ 
Hive,WITHOUT_CLASSIFICATION,//  maintain a list of non-NULL column IDs 
Hive,WITHOUT_CLASSIFICATION,//  reporter is a member variable of the Operator class. 
Hive,WITHOUT_CLASSIFICATION,//  ~ 1 week 
Hive,WITHOUT_CLASSIFICATION,//  Do we want to end the binary search 
Hive,WITHOUT_CLASSIFICATION,//  for each bucket file in big table get the corresponding bucket file   name in the small table.   more than 1 partition in the big table do the mapping for each partition 
Hive,WITHOUT_CLASSIFICATION,//  find all leaf tasks and make the DDLTask as a dependent task on all of them 
Hive,WITHOUT_CLASSIFICATION,//  If we've found it and it's already been marked acquired 
Hive,WITHOUT_CLASSIFICATION,//  then definitely this will end up zero. 
Hive,WITHOUT_CLASSIFICATION,//  Create the map if needed 
Hive,WITHOUT_CLASSIFICATION,//  Note: interestingly this would exclude LLAP app jars that the session adds for LLAP case.         Of course it doesn't matter because vertices run ON LLAP and have those jars and         moreover we anyway don't localize jars for the vertices on LLAP; but in theory         this is still crappy code that assumes there's one and only app jar. 
Hive,WITHOUT_CLASSIFICATION,//  An update error for some session that was actually already killed by us. 
Hive,WITHOUT_CLASSIFICATION,//  Check if all fields start with "key." or "value."   If so then unflatten by adding an additional level of nested key and value structs   Example: { "key.reducesinkkey0":int "key.reducesinkkey1": int "value._col6":int }   Becomes 
Hive,WITHOUT_CLASSIFICATION,//  return null since this will be handled as a special case in VectorizationContext 
Hive,WITHOUT_CLASSIFICATION,//  check the contents of the first row 
Hive,WITHOUT_CLASSIFICATION,//  No filter if any TS has no filter expression 
Hive,WITHOUT_CLASSIFICATION,//  it was a empty stream 
Hive,WITHOUT_CLASSIFICATION,//  consider approximate map side parallelism to be table data size 
Hive,WITHOUT_CLASSIFICATION,//  Giving up. 
Hive,WITHOUT_CLASSIFICATION,//  -main entry_point_name 
Hive,WITHOUT_CLASSIFICATION,//  Strings are interned and can thus be compared like this. 
Hive,WITHOUT_CLASSIFICATION,//  and so should the delete_delta directory. 
Hive,WITHOUT_CLASSIFICATION,// return the current block's length 
Hive,WITHOUT_CLASSIFICATION,//  Should have some AST   when(explainWork.getAstStringTree()).thenReturn(AST); 
Hive,WITHOUT_CLASSIFICATION,//  binary join 
Hive,WITHOUT_CLASSIFICATION,/*      * name      */
Hive,WITHOUT_CLASSIFICATION,//  Try the first again it would not be combined and we'd retain the old base (less files). 
Hive,WITHOUT_CLASSIFICATION,//  the sargs are closely tied to hive.optimize.index.filter 
Hive,WITHOUT_CLASSIFICATION,// delete the table from the database 
Hive,WITHOUT_CLASSIFICATION,//  so the new partition should be similar to the original partition 
Hive,WITHOUT_CLASSIFICATION,//  Note - above looks funny because it seems like we're instantiating a static var and   then a non-static var as the rule but the reason this is required is because Rules   are not allowed to be static but we wind up needing it initialized from a static   context. So bcompat is initialzed in a static context but this rule is initialized   before the tests run and will pick up an initialized value of bcompat. 
Hive,WITHOUT_CLASSIFICATION,//  Big table value expressions apply to ALL matching and non-matching rows. 
Hive,WITHOUT_CLASSIFICATION,//  this set is a copy of the arguments objects - avoid serializing 
Hive,WITHOUT_CLASSIFICATION,//  check table only should not exist in ms 
Hive,WITHOUT_CLASSIFICATION,//  If the result is not null the buffer was evicted during the move. 
Hive,WITHOUT_CLASSIFICATION,//  3. Insert ReduceSide GB2 
Hive,WITHOUT_CLASSIFICATION,//  Case 6 - No parenthesis 
Hive,WITHOUT_CLASSIFICATION,// so that we create empty bucket files when needed (but see HIVE-17138) 
Hive,WITHOUT_CLASSIFICATION,//  Execute all implementation variations. 
Hive,WITHOUT_CLASSIFICATION,/*    * @param partInfoList   *  @return The size of the list of partitions.   * @throws HCatExceptionConnectionFailureException   * @see org.apache.hive.hcatalog.api.HCatClient#addPartitions(java.util.List)    */
Hive,WITHOUT_CLASSIFICATION,//  null projection 
Hive,WITHOUT_CLASSIFICATION,//  4. Join Selectivity = 1/NDV 
Hive,WITHOUT_CLASSIFICATION,//  if the operator is a groupby and we are referencing the grouping 
Hive,WITHOUT_CLASSIFICATION,// fast pass worked i.e. all txns we were asked to heartbeat were Open as expected 
Hive,WITHOUT_CLASSIFICATION,//  Multiply the integer quotient back out so we can subtract it from the original to get 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hadoop.io.Writable#write(java.io.DataOutput)    */
Hive,WITHOUT_CLASSIFICATION,//  Group by contains the columns needed - no need to aggregate from children 
Hive,WITHOUT_CLASSIFICATION,//  2/ serialize the struct 
Hive,WITHOUT_CLASSIFICATION,// columnName to column position map 
Hive,WITHOUT_CLASSIFICATION,//  3. Insert ReduceSide GB1 
Hive,WITHOUT_CLASSIFICATION,/*        * Single-Column String specific declarations.        */
Hive,WITHOUT_CLASSIFICATION,//  add primitive types 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:org.apache.hadoop.hive.ql.hooks.proto.HiveHookEventProto) 
Hive,WITHOUT_CLASSIFICATION,//  append filter tag 
Hive,WITHOUT_CLASSIFICATION,//  generate SQL stmts to execute 
Hive,WITHOUT_CLASSIFICATION,//  Get "<some number>" 
Hive,WITHOUT_CLASSIFICATION,//  Connect any edges required for min/max pushdown 
Hive,WITHOUT_CLASSIFICATION,//  UNIFORM || AUTOPARALLEL (maxed out) 
Hive,WITHOUT_CLASSIFICATION,//  Only remove information of a column if it is not a key 
Hive,WITHOUT_CLASSIFICATION,//  test that overflow produces NULL 
Hive,WITHOUT_CLASSIFICATION,//  PARTITIONNAMES 
Hive,WITHOUT_CLASSIFICATION,//  Constructs a standard group by plan if:   There is no other subquery with the same group by/distinct keys or   (There are no aggregations in a representative query for the group and   There is no group by in that representative query) or   The data is skewed or   The conf variable used to control combining group bys into a single reducer is false 
Hive,WITHOUT_CLASSIFICATION,// this table needs to be converted to MM 
Hive,WITHOUT_CLASSIFICATION,//  collect name of output columns which is result of function 
Hive,WITHOUT_CLASSIFICATION,//  set up backup task 
Hive,WITHOUT_CLASSIFICATION,//  CLIENT/TOOL END     The tasks have completed control is back at the tool 
Hive,WITHOUT_CLASSIFICATION,//  logging configuration 
Hive,WITHOUT_CLASSIFICATION,//  Lower this for big key testing. 
Hive,WITHOUT_CLASSIFICATION,/*          * killThreads option has already done force shutdown. No need to do again.          */
Hive,WITHOUT_CLASSIFICATION,//  no nulls possible 
Hive,WITHOUT_CLASSIFICATION,//  Now we trigger some needed optimization rules again 
Hive,WITHOUT_CLASSIFICATION,//  In test mode we want the operation logs regardless of the settings 
Hive,WITHOUT_CLASSIFICATION,//  For har files 
Hive,WITHOUT_CLASSIFICATION,//  Create a Conf for n-way HybridHashTableContainers 
Hive,WITHOUT_CLASSIFICATION,//  test right input repeating 
Hive,WITHOUT_CLASSIFICATION,//  sync to start 
Hive,WITHOUT_CLASSIFICATION,//  Test failure if user not set 
Hive,WITHOUT_CLASSIFICATION,//  GRANTOR_NAME 
Hive,WITHOUT_CLASSIFICATION,//  c15:struct<r:ints:struct<a:intb:string>> 
Hive,WITHOUT_CLASSIFICATION,//  Add to map all the referenced positions (relative to each input rel). 
Hive,WITHOUT_CLASSIFICATION,//  scale the raw data size to split level based on ratio of split wrt to file length 
Hive,WITHOUT_CLASSIFICATION,//  sqlState errorCode should be set to appropriate values 
Hive,WITHOUT_CLASSIFICATION,//  Just to translate 
Hive,WITHOUT_CLASSIFICATION,//  only right input repeating 
Hive,WITHOUT_CLASSIFICATION,//  get the partitions for the table and populate the output 
Hive,WITHOUT_CLASSIFICATION,//  Create a new SparkTask for the specified SparkWork recursively compute 
Hive,WITHOUT_CLASSIFICATION,//  See the path in FSOP that calls fs.exists on finalPath. 
Hive,WITHOUT_CLASSIFICATION,//  Handle minimum integer case that doesn't have abs(). 
Hive,WITHOUT_CLASSIFICATION,//  We remembered the offset of just after the key length in the list record.   Read the absolute offset to the 2nd value. 
Hive,WITHOUT_CLASSIFICATION,//  The session cannot have been killed just now; this happens after all the kills in   the current iteration so we would have cleared sessionToReuse when killing this. 
Hive,WITHOUT_CLASSIFICATION,//  Strings including single escaped characters. 
Hive,WITHOUT_CLASSIFICATION,//  2.5. Remember the bad estimates for future reference. 
Hive,WITHOUT_CLASSIFICATION,//  the metric value must be zeroed: 
Hive,WITHOUT_CLASSIFICATION,//  CTAS 
Hive,WITHOUT_CLASSIFICATION,//  forward conditional on the survival of the corresponding key currently in indexes. 
Hive,WITHOUT_CLASSIFICATION,//  runs 
Hive,WITHOUT_CLASSIFICATION,//  100 == x   single row 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.operation.Operation#getResultSetSchema()    */
Hive,WITHOUT_CLASSIFICATION,//  Probably don't have a JobConf here but we can still try... 
Hive,WITHOUT_CLASSIFICATION,//  check that destination does not exist otherwise we will be   overwriting data 
Hive,WITHOUT_CLASSIFICATION,//  If this is run as a pre or post execution hook it writes a message to SessionState.err   (causing it to be cached if a CachingPrintStream is being used).  If it is run as a failure   hook it will write what has been cached by the CachingPrintStream to SessionState.out for   verification. 
Hive,WITHOUT_CLASSIFICATION,//  Push or next 
Hive,WITHOUT_CLASSIFICATION,//  Update creation metadata 
Hive,WITHOUT_CLASSIFICATION,//  Overflow. 
Hive,WITHOUT_CLASSIFICATION,//  Note: do not rename to ..service.acl; Hadoop generates .hosts setting name from this   resulting in a collision with existing hive.llap.daemon.service.hosts and bizarre errors.   These are read by Hadoop IPC so you should check the usage and naming conventions (e.g.   ".blocked" is a string hardcoded by Hadoop and defaults are enforced elsewhere in Hive) 
Hive,WITHOUT_CLASSIFICATION,//  non-temp tables should use underlying client. 
Hive,WITHOUT_CLASSIFICATION,/*      * expressions in SubQ that are joined to the Outer Query.      */
Hive,WITHOUT_CLASSIFICATION,//  Link the update repl state task with dependency collection task 
Hive,WITHOUT_CLASSIFICATION,//  sourceTask for TS is not changed (currently) but that of FS might be changed   by various optimizers (auto.convert.join for example) 
Hive,WITHOUT_CLASSIFICATION,//  Delete some data -> this will generate only delete deltas and no insert deltas: delete_delta_5_5 
Hive,WITHOUT_CLASSIFICATION,//  Now lost a finishable state. 
Hive,WITHOUT_CLASSIFICATION,//  figure out how many tasks we want for each bucket 
Hive,WITHOUT_CLASSIFICATION,//  repeated string group_vertices = 2; 
Hive,WITHOUT_CLASSIFICATION,//  CHAR tests 
Hive,WITHOUT_CLASSIFICATION,//  When deleteRecordId > currRecordIdInBatch we have to move on to look at the   next record in the batch.   But before that can we short-circuit and skip the entire batch itself   by checking if the deleteRecordId > lastRecordInBatch? 
Hive,WITHOUT_CLASSIFICATION,//  For file sink operator change the directory name 
Hive,WITHOUT_CLASSIFICATION,//  No task for given input return empty list with -1 as index 
Hive,WITHOUT_CLASSIFICATION,// "Update tab2" 
Hive,WITHOUT_CLASSIFICATION,//  RENAME_PARTITION EVENT to partitioned table 
Hive,WITHOUT_CLASSIFICATION,//  Should not reach here 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#prepareStatement(java.lang.String int int)    */
Hive,WITHOUT_CLASSIFICATION,//  Check if these belong to the same task and work with withinDagPriority 
Hive,WITHOUT_CLASSIFICATION,//  Make sure we don't reference any old buffer. 
Hive,WITHOUT_CLASSIFICATION,//  Copy the data over so that the internal state of Text will be set to 
Hive,WITHOUT_CLASSIFICATION,//  to prevent infinite loop 
Hive,WITHOUT_CLASSIFICATION,//  No truncate (ASCII) -- maximum length large. 
Hive,WITHOUT_CLASSIFICATION,//  AVG_COL_LEN 
Hive,WITHOUT_CLASSIFICATION,//  create list with variables that match some of the regexes 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   optional   required 
Hive,WITHOUT_CLASSIFICATION,/*          * Non-repeating input column. Use any non-NULL values for unassigned rows.          */
Hive,WITHOUT_CLASSIFICATION,//  Note: this is not the calling user but rather the user under which this session will 
Hive,WITHOUT_CLASSIFICATION,//  Note that output storage handlers never sees partition columns in data   or schema. 
Hive,WITHOUT_CLASSIFICATION,//  After analyzeInternal() Hiveop get set as Query   since we are passing in AST for select query so reset it. 
Hive,WITHOUT_CLASSIFICATION,//  Retrieving CD can be expensive and unnecessary so do it only when required. 
Hive,WITHOUT_CLASSIFICATION,//  Containers likely to come up soon. 
Hive,WITHOUT_CLASSIFICATION,//  for each directory add it once 
Hive,WITHOUT_CLASSIFICATION,//  Find the JDBC driver 
Hive,WITHOUT_CLASSIFICATION,//  For bucket columns   If all the columns match to the parent put them in the bucket cols   else add empty list.   For sort columns   Keep the subset of all the columns as long as order is maintained. 
Hive,WITHOUT_CLASSIFICATION,/*  * An multi-key value hash map optimized for vector map join. * * The key is stored as the provided bytes (uninterpreted).  */
Hive,WITHOUT_CLASSIFICATION,// determine if partition level privileges should be checked for input tables 
Hive,WITHOUT_CLASSIFICATION,//  NULL is considered numeric type for arithmetic operators. 
Hive,WITHOUT_CLASSIFICATION,//  Best-effort check. We cannot do a good check against caller thread since   refCount could still be > 0 if someone else locked. This is used for asserts and logs. 
Hive,WITHOUT_CLASSIFICATION,//  find the jar in local maven repo for testing 
Hive,WITHOUT_CLASSIFICATION,//  Shall never happen 
Hive,WITHOUT_CLASSIFICATION,//  in this case current task is in the root tasks   so add this new task into root tasks and remove the current task from root tasks 
Hive,WITHOUT_CLASSIFICATION,//  If any event is there and db name is known then dump the start and end logs 
Hive,WITHOUT_CLASSIFICATION,//  Create a list of operator nodes to start the walking. 
Hive,WITHOUT_CLASSIFICATION,//  3. Now handle actual returns. Sessions may be returned to the pool or may trigger expires. 
Hive,WITHOUT_CLASSIFICATION,//  Each column in the row 
Hive,WITHOUT_CLASSIFICATION,//  connect the work correctly. 
Hive,WITHOUT_CLASSIFICATION,//  this is being read because it is a dependency of a view). 
Hive,WITHOUT_CLASSIFICATION,//  Either we have user functions or metastore is old version - filter names locally. 
Hive,WITHOUT_CLASSIFICATION,//  First call to resultSet.next() should return true 
Hive,WITHOUT_CLASSIFICATION,//  handle null with selected in use 
Hive,WITHOUT_CLASSIFICATION,//  Insert the number of elements plus 2 to trigger 2 evictions. 
Hive,WITHOUT_CLASSIFICATION,//  if lesser than both NEXT_TXN_ID.ntxn_next and min(MIN_HISTORY_LEVEL .mhl_min_open_txnid). 
Hive,WITHOUT_CLASSIFICATION,//  Builds and starts the mini dfs and mapreduce clusters 
Hive,WITHOUT_CLASSIFICATION,//  If we cannot backtrack any of the columns bail out 
Hive,WITHOUT_CLASSIFICATION,//  in fact we're adding this table as a map table 
Hive,WITHOUT_CLASSIFICATION,//  -D : process these first so that we can instantiate SessionState appropriately. 
Hive,WITHOUT_CLASSIFICATION,//  Map of String to String LazyMap allows empty-string style key e.g. {"" : null}   or {"" ""} but not null style key e.g. {null:""} 
Hive,WITHOUT_CLASSIFICATION,//  The FK table name might be null if we are retrieving the constraint from the PK side 
Hive,WITHOUT_CLASSIFICATION,//  Try to store the first key.   if TopNHashes aren't active always forward 
Hive,WITHOUT_CLASSIFICATION,//  remove them from current spark work 
Hive,WITHOUT_CLASSIFICATION,//  even with tez on some jobs are run as MR. disable the flag in   the conf so that the backend runs fully as MR. 
Hive,WITHOUT_CLASSIFICATION,/*    * References to keys of the hashtable. The index is hash of the key; collisions are   * resolved using open addressing with quadratic probing. Reference format   * [40: offset into writeBuffers][8: state byte][1: has list flag]   * [15: part of hash used to optimize probing]   * Offset is tail offset of the first record for the key (the one containing the key).   * It is not necessary to store 15 bits in particular to optimize probing; in fact when   * we always store the hash it is not necessary. But we have nothing else to do with them.   * TODO: actually we could also use few bits to store largestNumberOfSteps for each   *      so we'd stop earlier on read collision. Need to profile on real queries.    */
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:VertexOrBinary) 
Hive,WITHOUT_CLASSIFICATION,//  SCALE 
Hive,WITHOUT_CLASSIFICATION,//  Writes data out as a series of chunks in the form <chunk size><chunk bytes><chunk size><chunk bytes>   Closing the output stream will 0send a final 0-length chunk which will indicate end of input. 
Hive,WITHOUT_CLASSIFICATION,//  Add temp table info to current session 
Hive,WITHOUT_CLASSIFICATION,//  check if the existing entry contains the new 
Hive,WITHOUT_CLASSIFICATION,//  Query specific info 
Hive,WITHOUT_CLASSIFICATION,//  Add Ctrl-B delimiter between the fields. This is necessary because for structs in case no   delimiter is provided hive automatically adds Ctrl-B as a default delimiter between fields 
Hive,WITHOUT_CLASSIFICATION,//  Orc store rows inside a root struct (hive writes it this way).   When we populate column vectors we skip over the root struct. 
Hive,WITHOUT_CLASSIFICATION,//  LlapIoImpl.LOG.debug("Adding batch " + batch); 
Hive,WITHOUT_CLASSIFICATION,//  store the vertex name in the operator pipeline 
Hive,WITHOUT_CLASSIFICATION,// this column doesn't come from any table 
Hive,WITHOUT_CLASSIFICATION,//  NOTE:  these references are with respect to the output 
Hive,WITHOUT_CLASSIFICATION,//  TODO Reduce the duplicated code 
Hive,WITHOUT_CLASSIFICATION,//  Get the last repl ID corresponding to all insert events except RENAME. 
Hive,WITHOUT_CLASSIFICATION,//  Should we try to tolerate corruption? Default is No. 
Hive,WITHOUT_CLASSIFICATION,//  alias1 alias2 alias3 all can be selected but overriden by biggest one (alias3) 
Hive,WITHOUT_CLASSIFICATION,//  Write the current set of valid write ids for the operated acid tables into the conf file so 
Hive,WITHOUT_CLASSIFICATION,//  Partition by the bucketing column 
Hive,WITHOUT_CLASSIFICATION,//  2^62*2^63 - 1 
Hive,WITHOUT_CLASSIFICATION,//  Create the consumer of encoded data; it will coordinate decoding to CVBs. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setBinaryStream(int java.io.InputStream   * long)    */
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#executeUpdate()    */
Hive,WITHOUT_CLASSIFICATION,/*     Comparisons using Strings for event Ids is wrong. This should be numbers since lexical string comparison    and numeric comparision differ. This requires a broader change where we return the dump Id as long and not string    fixing this here for now as it was observed in one of the builds where "1001".compareTo("998") results    in failure of the assertion below.      */
Hive,WITHOUT_CLASSIFICATION,//  AINT 
Hive,WITHOUT_CLASSIFICATION,/*    * Method to de-serialize AllocWriteIdMessage instance.    */
Hive,WITHOUT_CLASSIFICATION,//  If the current buffer contains multiple parts split it. 
Hive,WITHOUT_CLASSIFICATION,//  Avoid storing headers with data since we expect binary size allocations. 
Hive,WITHOUT_CLASSIFICATION,/*      * Make null safe Check if the job submission has gone through and if job is valid.      */
Hive,WITHOUT_CLASSIFICATION,//  DriverContext could be released in the query and close processes at same 
Hive,WITHOUT_CLASSIFICATION,//  result object 
Hive,WITHOUT_CLASSIFICATION,//  done processing the operator 
Hive,WITHOUT_CLASSIFICATION,//  This is in place to be compatible with the MR ShuffleHandler. Requests from ShuffleInputs   arrive with a job_ prefix. 
Hive,WITHOUT_CLASSIFICATION,//  This TableScanOperator could be part of semijoin optimization. 
Hive,WITHOUT_CLASSIFICATION,//  HDFS counters should be relatively consistent across test runs when compared to   local file system counters 
Hive,WITHOUT_CLASSIFICATION,/*    * After processing all the non-streaming group's batches with evaluateGroupBatch and   * isGroupResultNull is false the aggregation result value (based on getResultColumnVectorType).    */
Hive,WITHOUT_CLASSIFICATION,//  call the operator specific close routine 
Hive,WITHOUT_CLASSIFICATION,//  Set up the data structures before any notifications come in. 
Hive,WITHOUT_CLASSIFICATION,//  class HCatPartitionSpec; 
Hive,WITHOUT_CLASSIFICATION,//  Finds column by name in HCatSchema if not found returns null. 
Hive,WITHOUT_CLASSIFICATION,/*      * if there are any LeadLag functions in this Expression Tree: - setup a     * duplicate Evaluator for the 1st arg of the LLFuncDesc - initialize it     * using the InputInfo provided for this Expr tree - set the duplicate     * evaluator on the LLUDF instance.      */
Hive,WITHOUT_CLASSIFICATION,//  First process the current key. 
Hive,WITHOUT_CLASSIFICATION,//  generating the final row count relying on the basic comparator evaluation methods 
Hive,WITHOUT_CLASSIFICATION,//  Put 1 record into COMPACTION_QUEUE and do nothing 
Hive,WITHOUT_CLASSIFICATION,/*  100 files x 100 size for 1 splits  */
Hive,WITHOUT_CLASSIFICATION,//  otherwise we need to make sure that there is no subquery at any level 
Hive,WITHOUT_CLASSIFICATION,//  Cleanup structures 
Hive,WITHOUT_CLASSIFICATION,//  if this operator is the last operator we summarize the non-inlined 
Hive,WITHOUT_CLASSIFICATION,//  sample path: /llap-sasl/hiveuser/hostname/workers/worker-0000000   worker-0000000 is the sequence number which will be retained until session timeout. If a   worker does not respond due to communication interruptions it will retain the same sequence   number when it returns back. If session timeout expires the node will be deleted and new   addition of the same node (restart) will get next sequence number 
Hive,WITHOUT_CLASSIFICATION,//  define schema 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.ICLIService#closeSession(org.apache.hive.service.cli.SessionHandle)    */
Hive,WITHOUT_CLASSIFICATION,//  use SubStructObjectInspector to serialize the non-partitioning columns in the input row 
Hive,WITHOUT_CLASSIFICATION,//  The logger 
Hive,WITHOUT_CLASSIFICATION,/*    * Create information for vector map operator.   * The member oneRootOperator has been set.    */
Hive,WITHOUT_CLASSIFICATION,//  tables with various types 
Hive,WITHOUT_CLASSIFICATION,//  For partitioned tables get the size of all the partitions 
Hive,WITHOUT_CLASSIFICATION,//  col1 ... col5 
Hive,WITHOUT_CLASSIFICATION,//  Start the heartbeat after a delay which is shorter than  the HIVE_TXN_TIMEOUT 
Hive,WITHOUT_CLASSIFICATION,//  error code "08006" indicates proper shutdown 
Hive,WITHOUT_CLASSIFICATION,//  In all of the getters we try the metastore value name first.  If it is not set we try the   Hive value name. 
Hive,WITHOUT_CLASSIFICATION,//  if the cluster is running in MR2 mode return null 
Hive,WITHOUT_CLASSIFICATION,//  The number of Hive operations that are waiting to enter the compile block 
Hive,WITHOUT_CLASSIFICATION,//  Benefit (rows filtered from ts): (1 - selectivity) * # ts rows 
Hive,WITHOUT_CLASSIFICATION,/*    * Element for Key: byte[] x Hash Table: HashSet    */
Hive,WITHOUT_CLASSIFICATION,//  } 
Hive,WITHOUT_CLASSIFICATION,//  Input fullTableName is expected to be of format <db_name>.<table_name> 
Hive,WITHOUT_CLASSIFICATION,//  no grantor type for public role hence the null check 
Hive,WITHOUT_CLASSIFICATION,//  get the largest table alias from order 
Hive,WITHOUT_CLASSIFICATION,//  check only when it's in terminal state 
Hive,WITHOUT_CLASSIFICATION,//  table node 
Hive,WITHOUT_CLASSIFICATION,//  We support some virtual columns in vectorization for this table scan. 
Hive,WITHOUT_CLASSIFICATION,//  fetch the data from parquet data page for next call 
Hive,WITHOUT_CLASSIFICATION,//  Hive code has AssertionErrors in some cases - we want to record what happens 
Hive,WITHOUT_CLASSIFICATION,//  Find the record identifier column (if there) and return a possibly new ObjectInspector that 
Hive,WITHOUT_CLASSIFICATION,//  Now rememember what is supported for this query and any support that was 
Hive,WITHOUT_CLASSIFICATION,//  If in test mode then the LogDivertAppenderForTest created an extra log file containing only 
Hive,WITHOUT_CLASSIFICATION,//  Take filter pushdown into account while calculating splits; this   allows us to prune off regions immediately.  Note that although   the Javadoc for the superclass getSplits says that it returns one   split per region the implementation actually takes the scan   definition into account and excludes regions which don't satisfy 
Hive,WITHOUT_CLASSIFICATION,//  in the waitQueue. Avoid Object comparison. 
Hive,WITHOUT_CLASSIFICATION,//  optional string eventType = 1; 
Hive,WITHOUT_CLASSIFICATION,//  If datasource is in the table properties it is an INSERT/INSERT OVERWRITE as the datasource   name was already persisted. Otherwise it is a CT/CTAS and we need to get the name from the   job properties that are set by configureOutputJobProperties in the DruidStorageHandler 
Hive,WITHOUT_CLASSIFICATION,//  clean up the mapred work 
Hive,WITHOUT_CLASSIFICATION,// No token so remove the placeholder arg 
Hive,WITHOUT_CLASSIFICATION,//  mapTask and currTask should be merged by and join/union operator   (e.g. GenMRUnion1) which has multiple topOps.   assert mapTask == currTask : "mapTask.id = " + mapTask.getId()   + "; currTask.id = " + currTask.getId(); 
Hive,WITHOUT_CLASSIFICATION,//  Add inputs to ops to remove 
Hive,WITHOUT_CLASSIFICATION,// major compaction + check data + files 
Hive,WITHOUT_CLASSIFICATION,//  Implied. 
Hive,WITHOUT_CLASSIFICATION,//  transformation of the join operation 
Hive,WITHOUT_CLASSIFICATION,//  Make sure the hidden keys didn't get published 
Hive,WITHOUT_CLASSIFICATION,//    testtable1.key    S 
Hive,WITHOUT_CLASSIFICATION,//  Event 10 11 12 
Hive,WITHOUT_CLASSIFICATION,/*  Maps application identifiers (jobIds) to the associated user for the app  */
Hive,WITHOUT_CLASSIFICATION,//  For now expecting a single row (min/max aggregated bloom filter) or no rows 
Hive,WITHOUT_CLASSIFICATION,//  verify that the new configs are in effect 
Hive,WITHOUT_CLASSIFICATION,//  This could be overridden thru the jobconf. 
Hive,WITHOUT_CLASSIFICATION,// http://dev.mysql.com/doc/refman/5.7/en/select.html 
Hive,WITHOUT_CLASSIFICATION,//  check input object's length if it doesn't match   then output a new primitive with the correct params. 
Hive,WITHOUT_CLASSIFICATION,//  (FETCH_NEXT) execute the same sql again 
Hive,WITHOUT_CLASSIFICATION,//  Check if the table file has header to skip. 
Hive,WITHOUT_CLASSIFICATION,//  Add constants if there is no SELECT on top 
Hive,WITHOUT_CLASSIFICATION,//  trigger failover on miniHS2_1 
Hive,WITHOUT_CLASSIFICATION,/*    * Setup our outer join specific members.    */
Hive,WITHOUT_CLASSIFICATION,//  see http://download.oracle.com/javase/6/docs/api/constant-values.html#java.lang.Float.MAX_EXPONENT 
Hive,WITHOUT_CLASSIFICATION,//  digit  measuring stick:                  12345678901234567890123456789012345678 
Hive,WITHOUT_CLASSIFICATION,//  return the child directly if the conversion is redundant. 
Hive,WITHOUT_CLASSIFICATION,//  set output column 
Hive,WITHOUT_CLASSIFICATION,//  optional bytes initial_event_bytes = 10; 
Hive,WITHOUT_CLASSIFICATION,//  For CBO 
Hive,WITHOUT_CLASSIFICATION,/*  alternate2 = useBinarySortableCharsNeedingEscape  */
Hive,WITHOUT_CLASSIFICATION,//  which could lead to a lot of extra unnecessary scratch columns. 
Hive,WITHOUT_CLASSIFICATION,//  we're starting a new command 
Hive,WITHOUT_CLASSIFICATION,//  convert the absolute big decimal to string 
Hive,WITHOUT_CLASSIFICATION,//  Form result from lower and high words. 
Hive,WITHOUT_CLASSIFICATION,//  window based aggregations are handled differently 
Hive,WITHOUT_CLASSIFICATION,//  No dynamic partition pruning 
Hive,WITHOUT_CLASSIFICATION,//  Add string value to NumDistinctValue Estimator 
Hive,WITHOUT_CLASSIFICATION,//  execution mode 
Hive,WITHOUT_CLASSIFICATION,//  Check for Map which occupies 2 levels (key separator and key/value pair separator). 
Hive,WITHOUT_CLASSIFICATION,/*  first_name is null   */
Hive,WITHOUT_CLASSIFICATION,/*  resetValueColumnsOnly  */
Hive,WITHOUT_CLASSIFICATION,//  In most of the cases this is a column reference 
Hive,WITHOUT_CLASSIFICATION,// load hive-site.xml from classpath 
Hive,WITHOUT_CLASSIFICATION,//  we should be careful when authorizing table based on just the   table name. If columns have separate authorization domain it 
Hive,WITHOUT_CLASSIFICATION,//  NUM_DVS 
Hive,WITHOUT_CLASSIFICATION,//  Note: we assume this never happens for SerDe reader - the batch would never have vectors. 
Hive,WITHOUT_CLASSIFICATION,//  Fill values down for equal value series. 
Hive,WITHOUT_CLASSIFICATION,// Methods for metrics integration.  Each thread-local PerfLogger will open/close scope during each perf-log method. 
Hive,WITHOUT_CLASSIFICATION,//  oops this should have been caught before trying to componentize 
Hive,WITHOUT_CLASSIFICATION,//  cannot convert to complex types 
Hive,WITHOUT_CLASSIFICATION,// test invalid table name 
Hive,WITHOUT_CLASSIFICATION,// ~ Constructors ----------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  programmatically set root logger level to INFO. By default if log4j2-test.properties is not   available root logger will use ERROR log level 
Hive,WITHOUT_CLASSIFICATION,//  Temporarily re-using the TEZ AM View ACLs property for individual dag access control.   Hive may want to setup it's own parameters if it wants to control per dag access.   Setting the tez-property per dag should work for now. 
Hive,WITHOUT_CLASSIFICATION,//  type 
Hive,WITHOUT_CLASSIFICATION,/*  Exponent that derives from the fractional				 * part.  Under normal circumstatnces it is				 * the negative of the number of digits in F.				 * However if I is very long the last digits				 * of I get dropped (otherwise a long I with a				 * large negative exponent could cause an				 * unnecessary overflow on I alone).  In this				 * case fracExp is incremented one for each				 * dropped digit.  */
Hive,WITHOUT_CLASSIFICATION,//  need to do some conversions here 
Hive,WITHOUT_CLASSIFICATION,//  host3 dead before scheduling 
Hive,WITHOUT_CLASSIFICATION,// this also ensures that txn is still there in expected state 
Hive,WITHOUT_CLASSIFICATION,//  Do nothing   No migration just validate that the tables   Automatically determine if the table should be managed or external   Migrate tables to external tables   Migrate tables as managed transactional tables 
Hive,WITHOUT_CLASSIFICATION,//  all partitions are filtered by partition pruning 
Hive,WITHOUT_CLASSIFICATION,//  There should be 1 new directory: base_xxxxxxx. 
Hive,WITHOUT_CLASSIFICATION,//  if all the entries of map are representing null then return true 
Hive,WITHOUT_CLASSIFICATION,//  we're done processing events 
Hive,WITHOUT_CLASSIFICATION,//  In SemanticAnalyzer we inject SEL op before aggregation. The columns   in this SEL are derived from the table schema and do not reflect the   actual columns being selected in the current query.   In this case we skip the merge and just use the path from the child ops. 
Hive,WITHOUT_CLASSIFICATION,//  Load the defaults. 
Hive,WITHOUT_CLASSIFICATION,//  unknown field we return. We'll continue from the next field onwards. 
Hive,WITHOUT_CLASSIFICATION,//  The first version of RCFile used the sequence file header. 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:QueryCompleteRequestProto) 
Hive,WITHOUT_CLASSIFICATION,//  Moving files depends on the parentTask (we still want the dependencyTask to depend   on the parentTask) 
Hive,WITHOUT_CLASSIFICATION,// check that aborted operation didn't become committed 
Hive,WITHOUT_CLASSIFICATION,//  SR.SR.wait Lock we are examining is waiting.  In this case we keep   looking as it's possible that something in front is blocking it or 
Hive,WITHOUT_CLASSIFICATION,//  Each iteration of this loop tries to split blocks from one level of the free list into   target size blocks; if we cannot satisfy the allocation from the free list containing the 
Hive,WITHOUT_CLASSIFICATION,//  this is to prevent dropping archived partition which is archived in a 
Hive,WITHOUT_CLASSIFICATION,/*  We don't test all the combinations because (at least currently)     * the logic is inherited to be the same as testColLower which checks all the cases).      */
Hive,WITHOUT_CLASSIFICATION,//  ISNULL 
Hive,WITHOUT_CLASSIFICATION,//  Note: Do not change without changing the corresponding reference in llap-daemon-log4j2.properties 
Hive,WITHOUT_CLASSIFICATION,//  This stream will be restarted with the same random seed over and over. 
Hive,WITHOUT_CLASSIFICATION,// to create some partitions 
Hive,WITHOUT_CLASSIFICATION,//  Use Case 3. 
Hive,WITHOUT_CLASSIFICATION,//  Integer digits; stop on zeroes above. 
Hive,WITHOUT_CLASSIFICATION,//  last one for union column. 
Hive,WITHOUT_CLASSIFICATION,//  junk the destination for the 1st pass 
Hive,WITHOUT_CLASSIFICATION,//  With bucketing using two different versions. Version 1 for exiting   tables and version 2 for new tables. All the inputs to the SMB must be   from same version. This only applies to tables read directly and not 
Hive,WITHOUT_CLASSIFICATION,//  The merge file being currently processed. 
Hive,WITHOUT_CLASSIFICATION,//  Get the clusterby aliases - these are aliased to the entries in the   select list 
Hive,WITHOUT_CLASSIFICATION,//  We have a row for current group so we indicate not the last batch. 
Hive,WITHOUT_CLASSIFICATION,//  Copy data values over 
Hive,WITHOUT_CLASSIFICATION,//  Query might have been canceled. Stop the background processing. 
Hive,WITHOUT_CLASSIFICATION,//  create an invalid table which has wrong column type 
Hive,WITHOUT_CLASSIFICATION,//  initialize all forward operator 
Hive,WITHOUT_CLASSIFICATION,//  2.5 Add to field collations 
Hive,WITHOUT_CLASSIFICATION,//  finally add a project to project out the 1st columns 
Hive,WITHOUT_CLASSIFICATION,//  SERVER_PROTOCOL_VERSION 
Hive,WITHOUT_CLASSIFICATION,//  source: complexpb.proto 
Hive,WITHOUT_CLASSIFICATION,//  timebased 
Hive,WITHOUT_CLASSIFICATION,//  alias confict should not happen here. 
Hive,WITHOUT_CLASSIFICATION,//  Wait a while for tasks to respond to being cancelled 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setClob(int java.io.Reader long)    */
Hive,WITHOUT_CLASSIFICATION,//  If aggregate B had a COUNT aggregate call the corresponding aggregate at   aggregate A must be SUM. For other aggregates it remains the same. 
Hive,WITHOUT_CLASSIFICATION,//  Initialize with data row type conversion parameters. 
Hive,WITHOUT_CLASSIFICATION,//  pass the null value along to the escaping process to determine what the dir should be 
Hive,WITHOUT_CLASSIFICATION,//  Create Embedded MetaStore 
Hive,WITHOUT_CLASSIFICATION,//  Recursively clone the children 
Hive,WITHOUT_CLASSIFICATION,//  case the statement is a CREATE TABLE AS 
Hive,WITHOUT_CLASSIFICATION,//  Not expected access by the same class. 
Hive,WITHOUT_CLASSIFICATION,//  Determine if we need to read this slice for the split. 
Hive,WITHOUT_CLASSIFICATION,//  Convert dynamic arrays and maps to simple arrays. 
Hive,WITHOUT_CLASSIFICATION,//  Cached copy is valid 
Hive,WITHOUT_CLASSIFICATION,//  DOT is not affected 
Hive,WITHOUT_CLASSIFICATION,//  offset within compression buffer where the row group begins 
Hive,WITHOUT_CLASSIFICATION,//  In this case both should be DHJ operators as pRSChildMJ can only guarantee 
Hive,WITHOUT_CLASSIFICATION,//  Hash-join 
Hive,WITHOUT_CLASSIFICATION,//  a failed event should not create a new notification 
Hive,WITHOUT_CLASSIFICATION,//  DATABASE 
Hive,WITHOUT_CLASSIFICATION,//  If there is branch remove prune sink operator branch in the baseWork   If there is no branch remove the whole baseWork 
Hive,WITHOUT_CLASSIFICATION,//  configured not to ignore this 
Hive,WITHOUT_CLASSIFICATION,//  Traverse the TXN_TO_WRITE_ID to see if any of the input txns already have allocated a   write id for the same db.table. If yes then need to reuse it else have to allocate new one   The write id would have been already allocated in case of multi-statement txns where 
Hive,WITHOUT_CLASSIFICATION,//  if grouping sets are involved do early return 
Hive,WITHOUT_CLASSIFICATION,//  uses string type for binary before HIVE_CLI_SERVICE_PROTOCOL_V6 
Hive,WITHOUT_CLASSIFICATION,//  so let's just go the safe expensive way. 
Hive,WITHOUT_CLASSIFICATION,//  CONSIDER: Should be do this for all vector expressions that can 
Hive,WITHOUT_CLASSIFICATION,//  Emit the rest of word1 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setTime(java.lang.String java.sql.Time)    */
Hive,WITHOUT_CLASSIFICATION,// test some extreme cases. 
Hive,WITHOUT_CLASSIFICATION,// we need to do this to get the task path and set it for mapred implementation  since it can't be done automatically because of mapreduce->mapred abstraction 
Hive,WITHOUT_CLASSIFICATION,/*  Divide by a power of 10 equal to 10**scale to logically shift the digits     * places right by "scale" positions to eliminate them.      */
Hive,WITHOUT_CLASSIFICATION,//  I have to create the tables here (rather than in setup()) because I need the Hive   connection which is conveniently created by the semantic analyzer. 
Hive,WITHOUT_CLASSIFICATION,//  reply copy only happens for jars on hdfs not otherwise. 
Hive,WITHOUT_CLASSIFICATION,//  Need to close() because in some FileSystem   implementations flush() is no-op.   Close the file handle if it is a hdfs file.   But if it is stderr/stdout skip it since   WebHCat is not supposed to close it 
Hive,WITHOUT_CLASSIFICATION,//  This is the first batch we process after switching from hash mode 
Hive,WITHOUT_CLASSIFICATION,//  Default to lexicographicalasc 
Hive,WITHOUT_CLASSIFICATION,//  check that the partition folders exist on disk 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#nativeSQL(java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  In http mode we use NOSASL as the default auth type 
Hive,WITHOUT_CLASSIFICATION,//  no implicit casts possible 
Hive,WITHOUT_CLASSIFICATION,//  Name of the class to report for 
Hive,WITHOUT_CLASSIFICATION,//  verify whether the sql operation log is generated and fetch correctly. 
Hive,WITHOUT_CLASSIFICATION,//  Note: The following test will fail if you are running this test as root. Setting   permission to '0' on the database folder will not preclude root from being able   to create the necessary files. 
Hive,WITHOUT_CLASSIFICATION,//  row 1 
Hive,WITHOUT_CLASSIFICATION,//  This is default case with setugi off for both client and server 
Hive,WITHOUT_CLASSIFICATION,//  comment passed as table params 
Hive,WITHOUT_CLASSIFICATION,//  XXX: From o.a.zk.t.ClientBase 
Hive,WITHOUT_CLASSIFICATION,//  Avoid the NPE. 
Hive,WITHOUT_CLASSIFICATION,//  Overwhelmingly executes once. 
Hive,WITHOUT_CLASSIFICATION,//  Utility UDFs 
Hive,WITHOUT_CLASSIFICATION,//  in-place progress update related variables 
Hive,WITHOUT_CLASSIFICATION,//  with no nulls 
Hive,WITHOUT_CLASSIFICATION,/*    * provide an Iterator on the rows in a Partition.   * Iterator exposes the index of the next location.   * Client can invoke lead/lag relative to the next location.    */
Hive,WITHOUT_CLASSIFICATION,//  No ranges just return the empty list 
Hive,WITHOUT_CLASSIFICATION,//  when converting from char to string/varchar strip any trailing spaces 
Hive,WITHOUT_CLASSIFICATION,//  Re-align the columns appearing on or after startPostion(say column 1) such that   column 2 becomes column (2+offset) column 3 becomes column (3+offset) and so on. 
Hive,WITHOUT_CLASSIFICATION,//  2.2 Classify leaf predicate as Equi vs Non Equi 
Hive,WITHOUT_CLASSIFICATION,//  all outside elements should be ignored from stat estimation 
Hive,WITHOUT_CLASSIFICATION,//  One live session 
Hive,WITHOUT_CLASSIFICATION,//  move to the next child in FROM tree 
Hive,WITHOUT_CLASSIFICATION,//  Wait for all futures to complete. Check for an abort while waiting for each future. If any of the futures is cancelled / aborted - cancel all subsequent futures. 
Hive,WITHOUT_CLASSIFICATION,//  new number of register bits for higher accuracy 
Hive,WITHOUT_CLASSIFICATION,//  Emit the rest of word2 
Hive,WITHOUT_CLASSIFICATION,//  LBStruct needs ByteArrayRef 
Hive,WITHOUT_CLASSIFICATION,//  Brute force may discard up to twice as many buffers. 
Hive,WITHOUT_CLASSIFICATION,//  Is the field the configured string representing NULL? 
Hive,WITHOUT_CLASSIFICATION,//  There should be 2 delta dirs in the location 
Hive,WITHOUT_CLASSIFICATION,//  hive streaming ingest settings 
Hive,WITHOUT_CLASSIFICATION,//  for a select or create-as-select query populate the partition to column   (par2Cols) or   table to columns mapping (tab2Cols) 
Hive,WITHOUT_CLASSIFICATION,//  currently druid supports only MapBasedRow as Jackson SerDe so it should safe to cast without check 
Hive,WITHOUT_CLASSIFICATION,//  LINT 
Hive,WITHOUT_CLASSIFICATION,//  row 3 
Hive,WITHOUT_CLASSIFICATION,//  Minimum number of OR clauses needed to transform into IN clauses 
Hive,WITHOUT_CLASSIFICATION,/*  Evaluate result for position i (using bytes[] to avoid storage allocation costs)   * and set position i of the output vector to the result.    */
Hive,WITHOUT_CLASSIFICATION,//  check that /mpart4 does not exist but /mpart5 still does. 
Hive,WITHOUT_CLASSIFICATION,//  Use bucketized hive input format - that makes sure that one mapper reads the entire file 
Hive,WITHOUT_CLASSIFICATION,//  doesn't have a notion of tiny and saves the full value as an int so no overflow   expected:<null> but was:<300> 
Hive,WITHOUT_CLASSIFICATION,//  it must be on the same file system as the current destination 
Hive,WITHOUT_CLASSIFICATION,//  Atlas would be interested in lineage information for insertloadcreate etc. 
Hive,WITHOUT_CLASSIFICATION,//  row 2 
Hive,WITHOUT_CLASSIFICATION,//  Supervised kafka tasks should respect KafkaSupervisorIOConfig.completionTimeout instead of   handoffConditionTimeout 
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.TerminateFragmentResponseProto.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,//  ** Methods that need a data object **   In this function key has to be of the same structure as the Map expects.   Most cases key will be primitive type so it's OK.   In rare cases that key is not primitive the user is responsible for   defining 
Hive,WITHOUT_CLASSIFICATION,//  clear out the set. we don't need it anymore. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setBinaryStream(java.lang.String   * java.io.InputStream int)    */
Hive,WITHOUT_CLASSIFICATION,/*  All the code paths below propagate nulls even if arg2 has no nulls.     * This is to reduce the number of code paths and shorten the     * code at the expense of maybe doing unnecessary work if neither input     * has nulls. This could be improved in the future by expanding the number     * of code paths.      */
Hive,WITHOUT_CLASSIFICATION,//  Check if the join columns contains all bucket columns.   If a table is bucketized on column B but the join key is A and B   it is easy to see joining on different buckets yield empty results. 
Hive,WITHOUT_CLASSIFICATION,//  since the exceptions and the range in question overlap count the 
Hive,WITHOUT_CLASSIFICATION,//  Strip leading zeroes -- although there shouldn't be any for a decimal. 
Hive,WITHOUT_CLASSIFICATION,//  Still valid nothing more to do 
Hive,WITHOUT_CLASSIFICATION,//  A simple case. 
Hive,WITHOUT_CLASSIFICATION,/*  there are NULLs in the structColumnVector  */
Hive,WITHOUT_CLASSIFICATION,//  Initialize transaction table properties with default string value. 
Hive,WITHOUT_CLASSIFICATION,//  based on SecurityUtil.getAuthenticationMethod() 
Hive,WITHOUT_CLASSIFICATION,//  Calling close() explicitly to clean up the staging dirs 
Hive,WITHOUT_CLASSIFICATION,/*    * Verify table for Key: byte[] x Hash Table: HashMultiSet    */
Hive,WITHOUT_CLASSIFICATION,//  ts str 
Hive,WITHOUT_CLASSIFICATION,//  add dummy data for not removed by CombineHiveInputFormat etc. 
Hive,WITHOUT_CLASSIFICATION,/* the mutex pools should ideally be somewhat larger since some operations require 1           connection from each pool and we want to avoid taking a connection from primary pool           and then blocking because mutex pool is empty.  There is only 1 thread in any HMS trying           to mutex on each MUTEX_KEY except MUTEX_KEY.CheckLock.  The CheckLock operation gets a           connection from connPool first then connPoolMutex.  All others go in the opposite           order (not very elegant...).  So number of connection requests for connPoolMutex cannot           exceed (size of connPool + MUTEX_KEY.values().length - 1). */
Hive,WITHOUT_CLASSIFICATION,//  The colList is the output columns used by child operators they are   different   from input columns of the current operator. we need to find out which   input columns are used. 
Hive,WITHOUT_CLASSIFICATION,//  Which big table and small table columns are ByteColumnVector and need have their data buffer   to be manually reset for some join result processing? 
Hive,WITHOUT_CLASSIFICATION,//  Prepend column names with '_o_' if it starts with '_c' 
Hive,WITHOUT_CLASSIFICATION,//  this mapper operator is used to initialize all the operators 
Hive,WITHOUT_CLASSIFICATION,//  Minimum values 
Hive,WITHOUT_CLASSIFICATION,//  HIVE-19332: external tables should not be considered to have up-to-date stats. 
Hive,WITHOUT_CLASSIFICATION,//  it possible that some other HMS instance could have created the guid   at the same time due which this instance could not create a guid above   in such case return the guid already generated 
Hive,WITHOUT_CLASSIFICATION,//  host. 
Hive,WITHOUT_CLASSIFICATION,//  set up kafka producer 
Hive,WITHOUT_CLASSIFICATION,//  neither side is repeating 
Hive,WITHOUT_CLASSIFICATION,//  Extract rows and call process per row 
Hive,WITHOUT_CLASSIFICATION,//  The first small table; 
Hive,WITHOUT_CLASSIFICATION,//  this exception has been handled 
Hive,WITHOUT_CLASSIFICATION,//  show that their positions are recorded 
Hive,WITHOUT_CLASSIFICATION,//  if exception is thrown in scheduled tasks no further tasks will be scheduled hence this ugly catch 
Hive,WITHOUT_CLASSIFICATION,//  Thread killing the query 
Hive,WITHOUT_CLASSIFICATION,/*      * any additions to the SubQueries Select Clause.      */
Hive,WITHOUT_CLASSIFICATION,//  offsetLimit is smaller than rowCount of the input operator   thus we return the offsetLimit 
Hive,WITHOUT_CLASSIFICATION,//  Add the part to lastBatch to track the parition being dropped 
Hive,WITHOUT_CLASSIFICATION,//  if there are no more nodes. Signal timeout monitor to start timer 
Hive,WITHOUT_CLASSIFICATION,//  checksum failure 
Hive,WITHOUT_CLASSIFICATION,//  Test that 2 separate databases don't coalesce. 
Hive,WITHOUT_CLASSIFICATION,//  All parsing is done we're now good to start the export process 
Hive,WITHOUT_CLASSIFICATION,//  check access columns from readEntity 
Hive,WITHOUT_CLASSIFICATION,//  Second child node could be partitionspec or column 
Hive,WITHOUT_CLASSIFICATION,//  Figure out and encode what files we need to read.  We do this here (rather than in   getSplits below) because as part of this we discover our minimum and maximum transactions   and discovering that in getSplits is too late as we then have no way to pass it to our   mapper. 
Hive,WITHOUT_CLASSIFICATION,// Write operation always start a txn 
Hive,WITHOUT_CLASSIFICATION,// we just ran Major compaction so we should have a base_x in tblName2 that has the new files 
Hive,WITHOUT_CLASSIFICATION,//  copy full bucket context 
Hive,WITHOUT_CLASSIFICATION,//  a 
Hive,WITHOUT_CLASSIFICATION,// need to disable these so that automatic merge doesn't merge the files 
Hive,WITHOUT_CLASSIFICATION,//  Existing table is not a view 
Hive,WITHOUT_CLASSIFICATION,//  This is a semijoin branch. The stack should look like 
Hive,WITHOUT_CLASSIFICATION,// try to delete other directories if possible 
Hive,WITHOUT_CLASSIFICATION,//  process the list 
Hive,WITHOUT_CLASSIFICATION,//  Divide up rows array into different sized batches.   Modify the rows array for isRepeating / NULL patterns.   Provide iterator that will fill up a VRB with the divided up rows. 
Hive,WITHOUT_CLASSIFICATION,//  add dependency between the two work items 
Hive,WITHOUT_CLASSIFICATION,//  Test that existing shared_write partition with new shared_read coalesces to 
Hive,WITHOUT_CLASSIFICATION,//  close shouldn't matter 
Hive,WITHOUT_CLASSIFICATION,//  StringsCompleter matches against a pre-defined wordlist 
Hive,WITHOUT_CLASSIFICATION,//  if any of filter is sorted filter it's sorted filter 
Hive,WITHOUT_CLASSIFICATION,//  Do the intersection so only support in both is kept. 
Hive,WITHOUT_CLASSIFICATION,//  2. Make sure there is no dynamic addition of virtual cols 
Hive,WITHOUT_CLASSIFICATION,//  Can be converted to a Tez event if this is sufficient to decide on pre-emption 
Hive,WITHOUT_CLASSIFICATION,//  with vectorization 
Hive,WITHOUT_CLASSIFICATION,//  ACCUMULO-2962 Iterators weren't getting serialized into the InputSplit but we can   compensate because we still have that info. 
Hive,WITHOUT_CLASSIFICATION,//  ORC is in ql so we cannot do anything here. For now all the logic is in the proxy. 
Hive,WITHOUT_CLASSIFICATION,//  For string/char/varchar buffering when there are escapes. 
Hive,WITHOUT_CLASSIFICATION,//  column names also can be inferred from result of UDTF 
Hive,WITHOUT_CLASSIFICATION,//  Note: TOK_WINDOWVALUES means RANGE type TOK_WINDOWRANGE means ROWS type 
Hive,WITHOUT_CLASSIFICATION,//  build the final custom path string by replacing each column name with 
Hive,WITHOUT_CLASSIFICATION,//  We will move all the files in the table/partition directories into the first MM   directory then commit the first write ID. 
Hive,WITHOUT_CLASSIFICATION,//  short-circuit quickly - eat all rows 
Hive,WITHOUT_CLASSIFICATION,//  2. We gather the common factors and return them 
Hive,WITHOUT_CLASSIFICATION,//  Create a list of topop nodes 
Hive,WITHOUT_CLASSIFICATION,//  If caller is looking for temp table handle here. Otherwise pass on to underlying client. 
Hive,WITHOUT_CLASSIFICATION,//  reference is already accounted for in the directSize. 
Hive,WITHOUT_CLASSIFICATION,/*  This is to fulfill the contract of the interface which states that an exception shall             be thrown when a SaslServer cannot be created due to an error but null should be             returned when a Server can't be created due to the parameters supplied. And the only             thing PlainSaslServer can fail on is a non-supported authentication mechanism.             That's why we return null instead of throwing the Exception  */
Hive,WITHOUT_CLASSIFICATION,//  production is: i16 
Hive,WITHOUT_CLASSIFICATION,//  normal 
Hive,WITHOUT_CLASSIFICATION,//  For external tables we do not need to do anything else 
Hive,WITHOUT_CLASSIFICATION,// simulate concurrent session 
Hive,WITHOUT_CLASSIFICATION,//  Wait for the delete to complete 
Hive,WITHOUT_CLASSIFICATION,//  Gather columns used by aggregate operator 
Hive,WITHOUT_CLASSIFICATION,//  After INSERT INTO operation get the last Repl ID 
Hive,WITHOUT_CLASSIFICATION,//  The sender will take care of this.   The value didn't change. 
Hive,WITHOUT_CLASSIFICATION,//  Obtain the byte buffer from the input string so we can traverse it code point by code point 
Hive,WITHOUT_CLASSIFICATION,//  Reset the parameters so we can compare 
Hive,WITHOUT_CLASSIFICATION,//  anti-symmetric 
Hive,WITHOUT_CLASSIFICATION,//  overwrite buffer size and stripe size for delta writer based on BASE_DELTA_RATIO 
Hive,WITHOUT_CLASSIFICATION,//  For Arrow SerDe 
Hive,WITHOUT_CLASSIFICATION,//  make sure miniHS2_1 is not leader 
Hive,WITHOUT_CLASSIFICATION,//  write estimated count 
Hive,WITHOUT_CLASSIFICATION,//  We have propagated the value to the task. 
Hive,WITHOUT_CLASSIFICATION,//  call-2: open to read data - split 2 => mock:/mocktable4/0_1 
Hive,WITHOUT_CLASSIFICATION,//  make sure NullScanFileSystem can be loaded - HIVE-18442 
Hive,WITHOUT_CLASSIFICATION,//  get the forward op 
Hive,WITHOUT_CLASSIFICATION,//  This is the last range for this compression block. Yay! 
Hive,WITHOUT_CLASSIFICATION,//  if not dynamic partitioning then bail out 
Hive,WITHOUT_CLASSIFICATION,//  folder. 
Hive,WITHOUT_CLASSIFICATION,/*  If null then the major version number should match  */
Hive,WITHOUT_CLASSIFICATION,//  Must be deterministic order set for consistent q-test output across Java versions 
Hive,WITHOUT_CLASSIFICATION,//  Conversion requires source be placed in writable so we can call upon   VectorAssignRow to convert and assign the row column. 
Hive,WITHOUT_CLASSIFICATION,//  Walk the tree. As long as the operators between the union and the filesink   do not involve a reducer and they can be pushed above the union it makes   sense to push them above the union and remove the union. An interface   has been added to the operator 'supportUnionRemoveOptimization' to denote whether 
Hive,WITHOUT_CLASSIFICATION,//     assertTrue(dependentTasksForOne.iterator().next() instanceof DependencyCollectionTask);      assertTrue(dependentTasksForTwo.iterator().next() instanceof DependencyCollectionTask);      assertTrue(dependentTasksForThree.iterator().next() instanceof DependencyCollectionTask); 
Hive,WITHOUT_CLASSIFICATION,//  This version of Hadoop does not support getPassword() just retrieve password from conf. 
Hive,WITHOUT_CLASSIFICATION,//  CREATE MATERIALIZED VIEW ... 
Hive,WITHOUT_CLASSIFICATION,// write data to the target 
Hive,WITHOUT_CLASSIFICATION,//  Some tests control the execution of the background update thread 
Hive,WITHOUT_CLASSIFICATION,//  Copy within row. 
Hive,WITHOUT_CLASSIFICATION,//  Do this WITHOUT checking for parents 
Hive,WITHOUT_CLASSIFICATION,//  tail 
Hive,WITHOUT_CLASSIFICATION,//  boolean 
Hive,WITHOUT_CLASSIFICATION,//  Just alter the table 
Hive,WITHOUT_CLASSIFICATION,/*          * If the input to the GBy has a tab alias for the column then add an         * entry based on that tab_alias. For e.g. this query: select b.x         * count(*) from t1 b group by x needs (tab_alias=b col_alias=x) in the         * GBy RR. tab_alias=b comes from looking at the RowResolver that is the         * ancestor before any GBy/ReduceSinks added for the GBY operation.          */
Hive,WITHOUT_CLASSIFICATION,//  d 
Hive,WITHOUT_CLASSIFICATION,/*    * Write a NULL field.    */
Hive,WITHOUT_CLASSIFICATION,//  add empty string to the list of aliases. Some operators (ex. GroupBy) add 
Hive,WITHOUT_CLASSIFICATION,//  Mark Partitions with new schema with different blurb. 
Hive,WITHOUT_CLASSIFICATION,//  FileCache might be empty; see if we can remove it. "tryWriteLock" 
Hive,WITHOUT_CLASSIFICATION,//  Backing store for this cache 
Hive,WITHOUT_CLASSIFICATION,//  We assume that there are no locked blocks in the list; or if they are they can be dropped.   Therefore we always evict one contiguous sequence from the tail. We can find it in one pass   splice it out and then finalize the eviction outside of the list lock. 
Hive,WITHOUT_CLASSIFICATION,//  if this is zero we need to check if o might become zero after   scaling down.   this is not easy because there might be rounding. 
Hive,WITHOUT_CLASSIFICATION,//  be committed anymore 
Hive,WITHOUT_CLASSIFICATION,//    Rewrite logic:     1. If a Filter references a correlated field in its filter   condition rewrite the Filter to be     Filter       Join(cross product)         OriginalFilterInput         ValueGenerator(produces distinct sets of correlated variables)   and rewrite the correlated fieldAccess in the filter condition to   reference the Join output.     2. If Filter does not reference correlated variables simply   rewrite the filter condition using new input.   
Hive,WITHOUT_CLASSIFICATION,//  nothing 
Hive,WITHOUT_CLASSIFICATION,//  don't need to update tmp paths when there is no depth difference in paths 
Hive,WITHOUT_CLASSIFICATION,// // end add_partitions tests 
Hive,WITHOUT_CLASSIFICATION,/*  * Assumes that a getMapValueElement on object2 will work with a key from * object1. The equality is implemented fully the greater-than/less-than * values do not implement a transitive relation.   */
Hive,WITHOUT_CLASSIFICATION,//  2. Convert NONACIDORCTBL to ACID table with split_update enabled. (txn_props=default) 
Hive,WITHOUT_CLASSIFICATION,//  Populated if column is struct array or map types.   If struct type contains schema of the struct.   If array type contains schema of one of the elements. 
Hive,WITHOUT_CLASSIFICATION,/*    * Example dump dirs we need to be able to handle :   *   * for: hive.repl.rootdir = staging/   * Then repl dumps will be created in staging/<dumpdir>   *   * single-db-dump: staging/blah12345 will contain a db dir for the db specified   *  blah12345/   *   default/   *    _metadata   *    tbl1/   *      _metadata   *      dt=20160907/   *        _files   *    tbl2/   *    tbl3/   *    unptn_tbl/   *      _metadata   *      _files   *   * multi-db-dump: staging/bar12347 will contain dirs for each db covered   * staging/   *  bar12347/   *   default/   *     ...   *   sales/   *     ...   *   * single table-dump: staging/baz123 will contain a table object dump inside   * staging/   *  baz123/   *    _metadata   *    dt=20150931/   *      _files   *   * incremental dump : staging/blue123 will contain dirs for each event inside.   * staging/   *  blue123/   *    34/   *    35/   *    36/    */
Hive,WITHOUT_CLASSIFICATION,//  if files exists in input path then it has to be 1 as this code path gets triggered only   of order by queries which is expected to write only one file (written by one reducer) 
Hive,WITHOUT_CLASSIFICATION,//  NULL 1   0 NULL 
Hive,WITHOUT_CLASSIFICATION,//  batches will be sized 113 
Hive,WITHOUT_CLASSIFICATION,//  First "give up" on this task and put it back in the original list. 
Hive,WITHOUT_CLASSIFICATION,//  AccumuloOutputFormat complains if you re-set an already set value. We just don't care. 
Hive,WITHOUT_CLASSIFICATION,//  We only support query-time merge for MM tables so don't handle this. 
Hive,WITHOUT_CLASSIFICATION,//  do DDL time munging if thrift mode 
Hive,WITHOUT_CLASSIFICATION,//  Parse out the number of histogram bins only once if we haven't already done   so before. We need at least 2 bins; otherwise there is no point in creating   a histogram. 
Hive,WITHOUT_CLASSIFICATION,//  data stream could be empty stream or already reached end of stream before present stream.   This can happen if all values in stream are nulls or last row group values are all null. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure we fail the channel if something goes wrong.   We internally handle all the "expected" exceptions so log a lot of information here. 
Hive,WITHOUT_CLASSIFICATION,//  [A: 1 B: 0 B.x: 1 B.y: 0 C: 0] 
Hive,WITHOUT_CLASSIFICATION,//  if can't find hadoop home we can at least try /usr/bin/hadoop 
Hive,WITHOUT_CLASSIFICATION,//  delete any contents in the warehouse dir 
Hive,WITHOUT_CLASSIFICATION,//  Nothing to be done here. 
Hive,WITHOUT_CLASSIFICATION,//  optional string group_name = 1; 
Hive,WITHOUT_CLASSIFICATION,//  big input cumulative row count 
Hive,WITHOUT_CLASSIFICATION,//  No tasks qualify as preemptable 
Hive,WITHOUT_CLASSIFICATION,//  Not removing this here. Will be removed when taken off the queue and discovered to have 0   pending tasks. 
Hive,WITHOUT_CLASSIFICATION,//  for OR condition independently compute and update stats. 
Hive,WITHOUT_CLASSIFICATION,//  Read table stats via CachedStore 
Hive,WITHOUT_CLASSIFICATION,//  Comment out these checks when we are happy.. 
Hive,WITHOUT_CLASSIFICATION,//  Check if MetaException has one of InvalidObjectException or NoSuchObjectExcetion or any exception thrown from ObjectStore  which means that the   authorization checks passed. 
Hive,WITHOUT_CLASSIFICATION,//  disable filter pushdown for mapreduce when there are more than one table aliases 
Hive,WITHOUT_CLASSIFICATION,//  columns. 
Hive,WITHOUT_CLASSIFICATION,//  Clone the fileSinkDesc of the final fileSink and create similar fileSinks at 
Hive,WITHOUT_CLASSIFICATION,//  set 'n' if we haven't done so before 
Hive,WITHOUT_CLASSIFICATION,//  permissions set. 
Hive,WITHOUT_CLASSIFICATION,// these are insert events so (original txn == current) txn for all rows 
Hive,WITHOUT_CLASSIFICATION,//  add all data for an element in ListColumnVector get out the loop if there is no data or the data is for new element 
Hive,WITHOUT_CLASSIFICATION,/*        * c. Rebuilt the QueryDef.       * Why?       * - so that the ExprNodeDescriptors in the QueryDef are based on the       *   Select Operator's RowResolver        */
Hive,WITHOUT_CLASSIFICATION,//  It is expected NEXT_WRITE_ID doesn't have entry for this table and hence directly insert it. 
Hive,WITHOUT_CLASSIFICATION,//  User1 privileges:   testdb1:            S     testtable1.*:     SU     testtable2.*:     S     testtable3.*:     S     testtable4.*:   testdb2:            S 
Hive,WITHOUT_CLASSIFICATION,// by checkLock() - makes diagnostics easier. 
Hive,WITHOUT_CLASSIFICATION,//  Don't release if the buffer contains any data beyond the acceptable boundary. 
Hive,WITHOUT_CLASSIFICATION,//  not using the path child cache here as there could be more than 1 path per host (worker and slot znodes) 
Hive,WITHOUT_CLASSIFICATION,//  Include shim and admin specified libjars 
Hive,WITHOUT_CLASSIFICATION,//  If we cannot merge we bail out 
Hive,WITHOUT_CLASSIFICATION,//  Ignore if a file with same content already exist in cmroot 
Hive,WITHOUT_CLASSIFICATION,//  Try to serialize 
Hive,WITHOUT_CLASSIFICATION,//  normalized display width is based on maximum of display size   and label size 
Hive,WITHOUT_CLASSIFICATION,//  First lookup the file sink operator from the load work. 
Hive,WITHOUT_CLASSIFICATION,//  test code path 
Hive,WITHOUT_CLASSIFICATION,//  Always create partition and virtual columns. 
Hive,WITHOUT_CLASSIFICATION,//  The validatePTFOperator method will update vectorPTFDesc. 
Hive,WITHOUT_CLASSIFICATION,//  ordinal position of this column in the schema 
Hive,WITHOUT_CLASSIFICATION,//  ENTITY_NAME 
Hive,WITHOUT_CLASSIFICATION,//  sanity check. all tasks must submit events for us to succeed. 
Hive,WITHOUT_CLASSIFICATION,//  null signifies nodes that are irrelevant to the generation 
Hive,WITHOUT_CLASSIFICATION,//  This config contains all the configuration that master node wants to provide 
Hive,WITHOUT_CLASSIFICATION,//                                   having key in (select .. where a = min(b.value) 
Hive,WITHOUT_CLASSIFICATION,//  Oid for kerberos principal name 
Hive,WITHOUT_CLASSIFICATION,//  Next we verify that the destination table is not offline or a non-native table 
Hive,WITHOUT_CLASSIFICATION,//  baseCommitter.cleanupJob failed try to clean up the   metastore 
Hive,WITHOUT_CLASSIFICATION,//  if here there is attempt to set transactional to something other than 'true'   and NOT the same value it was before 
Hive,WITHOUT_CLASSIFICATION,/*    * A Unit Test convenience method for putting key and value into the hash table using the   * actual types.    */
Hive,WITHOUT_CLASSIFICATION,//  VectorizedBatchUtil.debugDisplayOneRow(batch batchIndex CLASS_NAME + " MATCH duplicate"); 
Hive,WITHOUT_CLASSIFICATION,//  last function name is replicated null if function replication was in progress when we created this state. 
Hive,WITHOUT_CLASSIFICATION,//  used for LIST_PROVIDED cases 
Hive,WITHOUT_CLASSIFICATION,//  SW.SR.acquired Lock we are examining is acquired;  We need to keep   looking because there may or may not be another shared write in front 
Hive,WITHOUT_CLASSIFICATION,//  binary keys values and hashCodes of rows lined up by index 
Hive,WITHOUT_CLASSIFICATION,//  Prepare a new query string. 
Hive,WITHOUT_CLASSIFICATION,//  and convert it to a string. Yay! 
Hive,WITHOUT_CLASSIFICATION,/*    * Call this to reinitialize the node stack. It is called automatically by the   * parser's ReInit() method.    */
Hive,WITHOUT_CLASSIFICATION,//  Both are not empty. Merge two lists. 
Hive,WITHOUT_CLASSIFICATION,//  left and right repeat and right is null 
Hive,WITHOUT_CLASSIFICATION,//  Transaction manager used for the query. This will be set at compile time based on 
Hive,WITHOUT_CLASSIFICATION,//  get the path names for the 1st row only 
Hive,WITHOUT_CLASSIFICATION,// here each group looks something like "Map 2: 2/4" "Reducer 3: 1(+2)/4"  just parse the numbers and ignore one from "Map 2" and from "(+2)" if it's there 
Hive,WITHOUT_CLASSIFICATION,//  If there is only one element in tuple contained in bag we throw away the tuple. 
Hive,WITHOUT_CLASSIFICATION,//  Put the script content in a temp file 
Hive,WITHOUT_CLASSIFICATION,//  New state is not running (user not active) any more 
Hive,WITHOUT_CLASSIFICATION,//  bucketed/sorted columns for the destination table 
Hive,WITHOUT_CLASSIFICATION,//  default is that it's not in a repl scope   default is full export/import not metadata-only 
Hive,WITHOUT_CLASSIFICATION,//  Nothing to do if it is a lock mode 
Hive,WITHOUT_CLASSIFICATION,//  Set to non-zk lock manager to avoid trying to connect to zookeeper 
Hive,WITHOUT_CLASSIFICATION,//  Data structures to store original values 
Hive,WITHOUT_CLASSIFICATION,//  not all partitions are scanned in all mappers so this could be null. 
Hive,WITHOUT_CLASSIFICATION,//  two int 
Hive,WITHOUT_CLASSIFICATION,//  This wraps an instance of an ExprNodeDesc and makes equals work like isSame see comment on 
Hive,WITHOUT_CLASSIFICATION,//  2. _success file is required for Oozie to indicate availability of data source 
Hive,WITHOUT_CLASSIFICATION,//  Create the databases and reload them from the MetaStore 
Hive,WITHOUT_CLASSIFICATION,//  start all mr/multi-mr inputs 
Hive,WITHOUT_CLASSIFICATION,//  1 file 1 dir for each for now. Plus export "data" dir.   This could be changed to a flat file list later. 
Hive,WITHOUT_CLASSIFICATION,//  UPDATE 
Hive,WITHOUT_CLASSIFICATION,//  same 
Hive,WITHOUT_CLASSIFICATION,//  Old API assumed all partitions belong to the same table; keep the same assumption 
Hive,WITHOUT_CLASSIFICATION,//  The writing thread has given us an object to wait on. 
Hive,WITHOUT_CLASSIFICATION,//  a(stringintint) can be matched with methods like   a(stringintint) a(stringintInteger) a(stringIntegerint) and a(stringIntegerInteger) 
Hive,WITHOUT_CLASSIFICATION,//  open 5 connections 
Hive,WITHOUT_CLASSIFICATION,//  Tez session settings 
Hive,WITHOUT_CLASSIFICATION,//  Now vary isRepeating   nulls possible only on left 
Hive,WITHOUT_CLASSIFICATION,//  in case of external table drop the table contents as well 
Hive,WITHOUT_CLASSIFICATION,//  only one result column 
Hive,WITHOUT_CLASSIFICATION,//  The heartbeat is consistent with what we have. 
Hive,WITHOUT_CLASSIFICATION,//  Get the order by aliases - these are aliased to the entries in the   select list 
Hive,WITHOUT_CLASSIFICATION,//  PRIMARY_KEY_COLS 
Hive,WITHOUT_CLASSIFICATION,//                    12345678901234567890123456789012345678                               1         2         3 
Hive,WITHOUT_CLASSIFICATION,//  ------ Inner classes defined after this point ------ 
Hive,WITHOUT_CLASSIFICATION,// do the authorization check 
Hive,WITHOUT_CLASSIFICATION,//  Determine if we are dealing with a numeric or date arithmetic operation 
Hive,WITHOUT_CLASSIFICATION,//  Maintain count of outstanding requests for tokenIdentifier. 
Hive,WITHOUT_CLASSIFICATION,//  Remove entries from txn_components as there may be aborted txn components 
Hive,WITHOUT_CLASSIFICATION,/*        * For better performance on LONG/DOUBLE we don't want the conditional       * statements inside the for loop.        */
Hive,WITHOUT_CLASSIFICATION,//  Acquire lock for the given materialized view. Only one rebuild per materialized   view can be triggered at a given time as otherwise we might produce incorrect   results if incremental maintenance is triggered. 
Hive,WITHOUT_CLASSIFICATION,//  Prevent view cycles 
Hive,WITHOUT_CLASSIFICATION,// to aid in testing through .q files authenticator is passed as argument to   the interface. this helps in being able to switch the user within a session.   so we need to check if the user has changed 
Hive,WITHOUT_CLASSIFICATION,//  Second request for host. Single invocation since the last has not completed. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#getResultSetHoldability()    */
Hive,WITHOUT_CLASSIFICATION,//  Next one is a new key we bail out from the inner loop 
Hive,WITHOUT_CLASSIFICATION,//  D3-D7. Loop on iulRindex - obtaining digits one-by-one as "in paper" 
Hive,WITHOUT_CLASSIFICATION,/*    * @return A new hash set result implementation specific object.   *   * The object can be used to access access spill information when the partition with the key   * is currently spilled.    */
Hive,WITHOUT_CLASSIFICATION,/*      * Descending.      */
Hive,WITHOUT_CLASSIFICATION,//  Ignore the outdated updates; for the same version ignore non-null updates because   we assume that removal is the last thing that happens for any given version. 
Hive,WITHOUT_CLASSIFICATION,/*    * getConvertedOI with caching to store settable properties of the object   * inspector. Caching might help when the object inspector   * contains complex nested data types. Caching is not explicitly required for   * the returned object inspector across multiple invocations since the   * ObjectInspectorFactory already takes care of it.    */
Hive,WITHOUT_CLASSIFICATION,/*  1 files x 1000 size for 99 splits  */
Hive,WITHOUT_CLASSIFICATION,//  Check if the comparison is supported for this type 
Hive,WITHOUT_CLASSIFICATION,//  Convert the constants available as strings to the corresponding objects 
Hive,WITHOUT_CLASSIFICATION,//  Try preempting a lower priority task in any case. 
Hive,WITHOUT_CLASSIFICATION,//  support Decimal64. 
Hive,WITHOUT_CLASSIFICATION,//  Abstract class to hold info required for the implementation 
Hive,WITHOUT_CLASSIFICATION,//  Add listener to handle any cleanup for when the connection is closed 
Hive,WITHOUT_CLASSIFICATION,/*    * FLOAT.    */
Hive,WITHOUT_CLASSIFICATION,//  1 for "_" after tname; 3 for ".qv" at the end. Version is in between. 
Hive,WITHOUT_CLASSIFICATION,//  creates scratch directories needed by the Context object 
Hive,WITHOUT_CLASSIFICATION,/*    * The following conditions are for native Vector ReduceSink.    */
Hive,WITHOUT_CLASSIFICATION,/*    * Handles expr like struct(keyvalue).key   * Follows same rules as TypeCheckProcFactory::getXpathOrFuncExprNodeDesc()   * which is equivalent version of parsing such an expression from AST    */
Hive,WITHOUT_CLASSIFICATION,//  MetadataTypedColumnsetSerDe does not need type conversions because it 
Hive,WITHOUT_CLASSIFICATION,//  Setup the hadoop vars to specify the user. 
Hive,WITHOUT_CLASSIFICATION,//  that already exist (existingParts) will not generate notifications. 
Hive,WITHOUT_CLASSIFICATION,//  v[8] -- since integer #5 is always 0 some products here are not included. 
Hive,WITHOUT_CLASSIFICATION,//  no support for statistics yet 
Hive,WITHOUT_CLASSIFICATION,//  write the empty base 
Hive,WITHOUT_CLASSIFICATION,//  QUERYLOAD op can contain an insert & overwrite 
Hive,WITHOUT_CLASSIFICATION,//  3. Calculate IN selectivity 
Hive,WITHOUT_CLASSIFICATION,//  If we weren't interrupted just propagate the error 
Hive,WITHOUT_CLASSIFICATION,//  HIVE_OBJECT 
Hive,WITHOUT_CLASSIFICATION,//  SSL conf 
Hive,WITHOUT_CLASSIFICATION,//  optional .EntityDescriptorProto merged_input_descriptor = 3; 
Hive,WITHOUT_CLASSIFICATION,/*      * For both graceful or forceful shutdown wait for tasks to terminate such that     * appropriate exceptions are raised and stored in JobRunnable.exception.      */
Hive,WITHOUT_CLASSIFICATION,//  Generate the map work for this alias_id   pass both confirmed and unknown partitions through the map-reduce 
Hive,WITHOUT_CLASSIFICATION,//  Do safety checks 
Hive,WITHOUT_CLASSIFICATION,//  If url was not specified with -u but -r was present use that. 
Hive,WITHOUT_CLASSIFICATION,//  Timeseries query results 
Hive,WITHOUT_CLASSIFICATION,//  Sets delimiter to tab (ascii 9) 
Hive,WITHOUT_CLASSIFICATION,//  Throw an error if the user asked for bucketed mapjoin to be enforced and 
Hive,WITHOUT_CLASSIFICATION,//  Reset the time we only want to count it in the loop. 
Hive,WITHOUT_CLASSIFICATION,//  Set permissions appropriately for each of the partitions we just created 
Hive,WITHOUT_CLASSIFICATION,//  this is only there for the use case where we are doing table only replication and not database level 
Hive,WITHOUT_CLASSIFICATION,//  Setting REPL DUMP and REPL LOAD as all requiring ADMIN privileges.   We might wind up loosening this in the future but right now we do not want   to do individual object based checks on every object possible and thus asking   for a broad privilege such as this is the best route forward. REPL STATUS   should use privileges similar to DESCRIBE DB/TABLE and so it asks for no 
Hive,WITHOUT_CLASSIFICATION,/*  This class is used to verify that HiveMetaStore calls the non-transactional listeners with the    * current event ID set by the DbNotificationListener class  */
Hive,WITHOUT_CLASSIFICATION,//  The group by operator has already been processed 
Hive,WITHOUT_CLASSIFICATION,//  spilled tables are loaded always (no sharing) so clear it 
Hive,WITHOUT_CLASSIFICATION,/*    * Truncate a byte array to a maximum number of characters and   * return a byte array with only truncated bytes.    */
Hive,WITHOUT_CLASSIFICATION,// set lineage info 
Hive,WITHOUT_CLASSIFICATION,//  remove the tag for in-memory side of mapjoin 
Hive,WITHOUT_CLASSIFICATION,//  The data does not belong to a recognized chunk or is split wrong. 
Hive,WITHOUT_CLASSIFICATION,//  referencing another table instead of self for the primary key. 
Hive,WITHOUT_CLASSIFICATION,//  derby fails creating multiple stats aggregator concurrently 
Hive,WITHOUT_CLASSIFICATION,//  MY_BINARY 
Hive,WITHOUT_CLASSIFICATION,//  HEADER_NAMES 
Hive,WITHOUT_CLASSIFICATION,//  to go a few % over. 
Hive,WITHOUT_CLASSIFICATION,//  Get information from YARN Service 
Hive,WITHOUT_CLASSIFICATION,// MetaException 
Hive,WITHOUT_CLASSIFICATION,// in MSSQL this means Communication Link Failure 
Hive,WITHOUT_CLASSIFICATION,//  Initially all columns are projected and in the same order 
Hive,WITHOUT_CLASSIFICATION,//  MAX_WEIGHT 
Hive,WITHOUT_CLASSIFICATION,//  lock. 
Hive,WITHOUT_CLASSIFICATION,//  We are good. 
Hive,WITHOUT_CLASSIFICATION,//  While updating local structures   Note: this is actually called under the epic writeLock in schedulePendingTasks 
Hive,WITHOUT_CLASSIFICATION,//  each parent 
Hive,WITHOUT_CLASSIFICATION,//  This works assuming the executor is running within YARN. 
Hive,WITHOUT_CLASSIFICATION,//  done 
Hive,WITHOUT_CLASSIFICATION,//  clear vertices list 
Hive,WITHOUT_CLASSIFICATION,//  Print out the un/compressed sizes of each column 
Hive,WITHOUT_CLASSIFICATION,//  here only deals with non-partition columns. We deal with partition columns next 
Hive,WITHOUT_CLASSIFICATION,//  test the last day of month 
Hive,WITHOUT_CLASSIFICATION,//  Subtract 1 for two's compliment adjustment. 
Hive,WITHOUT_CLASSIFICATION,//  Gives a list of any new paths that may have been created to maintain the persistent ephemeral node 
Hive,WITHOUT_CLASSIFICATION,//  MY_32BIT_INT 
Hive,WITHOUT_CLASSIFICATION,// write the delimiter to the stream which means we don't need output.format.string anymore 
Hive,WITHOUT_CLASSIFICATION,//  UNION_MSTRING_STRING 
Hive,WITHOUT_CLASSIFICATION,//  Red Hat: /sys/kernel/mm/redhat_transparent_hugepage/enabled            /sys/kernel/mm/redhat_transparent_hugepage/defrag   CentOS/Ubuntu/Debian OEL SLES: /sys/kernel/mm/transparent_hugepage/enabled                                    /sys/kernel/mm/transparent_hugepage/defrag 
Hive,WITHOUT_CLASSIFICATION,//  If we couldn't create the tracker node don't create the main node. 
Hive,WITHOUT_CLASSIFICATION,//  new session 
Hive,WITHOUT_CLASSIFICATION,//   1 for left outer join (+-) : join and skip further LO 
Hive,WITHOUT_CLASSIFICATION,//  NOT on boolean columns is possible. in which case return false count. 
Hive,WITHOUT_CLASSIFICATION,//  executed twice: once with the typed ps setters once with the generic setObject 
Hive,WITHOUT_CLASSIFICATION,//  the last 2 columns are VCol and c 
Hive,WITHOUT_CLASSIFICATION,//  verify outputs 
Hive,WITHOUT_CLASSIFICATION,//  The avg() result type has the same number of integer digits and 4 more decimal digits. 
Hive,WITHOUT_CLASSIFICATION,//  LOG4J2-1292 utilize gc-free Layout.encode() method: taken care of in superclass 
Hive,WITHOUT_CLASSIFICATION,//  Test valid case 
Hive,WITHOUT_CLASSIFICATION,//  The roundPower same as scale means all zeroes below round point. 
Hive,WITHOUT_CLASSIFICATION,//  Get an empty container when the small table is empty. 
Hive,WITHOUT_CLASSIFICATION,//  TODO: Extend TaskRunner2 or see if an API with callbacks will work 
Hive,WITHOUT_CLASSIFICATION,//  Set the value of the writable from the decimal digits that were written with no dot. 
Hive,WITHOUT_CLASSIFICATION,//  Asian character U+24B62 (4 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  a mixture of input big table columns and new scratch columns. 
Hive,WITHOUT_CLASSIFICATION,//  Add some margin to the wait to avoid rechecking close to the boundary. 
Hive,WITHOUT_CLASSIFICATION,//  The data is not in cache. 
Hive,WITHOUT_CLASSIFICATION,//  We drive the doProcessBatch logic with the same batch but different   grouping set id and null variation.   PERFORMANCE NOTE: We do not try to reuse columns and generate the KeyWrappers anew... 
Hive,WITHOUT_CLASSIFICATION,//  invoke DELETE /leader endpoint for failover 
Hive,WITHOUT_CLASSIFICATION,//  Check the schema of a table with one field & no partition keys. 
Hive,WITHOUT_CLASSIFICATION,/*    * Walk to Hive AST and translate the hive column names to their equivalent mappings. This is basically a cheat.   *    */
Hive,WITHOUT_CLASSIFICATION,//  5. Resolve Parse Tree 
Hive,WITHOUT_CLASSIFICATION,//  Whether the method takes an array like Object[]   or String[] etc in the last argument. 
Hive,WITHOUT_CLASSIFICATION,//  delete source   overwrite destination 
Hive,WITHOUT_CLASSIFICATION,//  otherwise it is count(null) should directly return 0. 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: only used from index related classes 
Hive,WITHOUT_CLASSIFICATION,// store the partitions temporarily until processed 
Hive,WITHOUT_CLASSIFICATION,//  days/hours/minutes/seconds all represented as seconds 
Hive,WITHOUT_CLASSIFICATION,/*      * BOOLEAN .. LONG: Min and max.      */
Hive,WITHOUT_CLASSIFICATION,//  The number of tez tasks executed by the HiveServer2 since the last restart 
Hive,WITHOUT_CLASSIFICATION,//  NUM_TXNS 
Hive,WITHOUT_CLASSIFICATION,//  LVmerge.. in the above order 
Hive,WITHOUT_CLASSIFICATION,//  Force Spark configs to be cloned by default 
Hive,WITHOUT_CLASSIFICATION,//  canHandleQbForCbo returns null if the query can be handled. 
Hive,WITHOUT_CLASSIFICATION,//  Temporary work arrays. 
Hive,WITHOUT_CLASSIFICATION,//  get a list with the current classpath components 
Hive,WITHOUT_CLASSIFICATION,//  specifies db 
Hive,WITHOUT_CLASSIFICATION,//  replace the commar. 
Hive,WITHOUT_CLASSIFICATION,/*  keyCount  */
Hive,WITHOUT_CLASSIFICATION,//  Pad output 
Hive,WITHOUT_CLASSIFICATION,//  LocalDateTime is immutable. 
Hive,WITHOUT_CLASSIFICATION,/*            * This case can happen with LLAP.  If it is able to deserialize and cache data from the           * input format it will deliver that cached data to us as VRBs.            */
Hive,WITHOUT_CLASSIFICATION,//  Quote always for fields that mimic SQL keywords like DESC 
Hive,WITHOUT_CLASSIFICATION,//  Need to register minimum open txnid for current transactions into MIN_HISTORY table. 
Hive,WITHOUT_CLASSIFICATION,//  Get the vector description from the operator. 
Hive,WITHOUT_CLASSIFICATION,//  Divide and round up. 
Hive,WITHOUT_CLASSIFICATION,//  best answer would be 1. 
Hive,WITHOUT_CLASSIFICATION,//  Path to file is specified (can be relative) so treat target as a file name (hadoop fs -put behavior) 
Hive,WITHOUT_CLASSIFICATION,//  delete partition level column stats if it exists 
Hive,WITHOUT_CLASSIFICATION,//  required   required   optional   required   optional   optional 
Hive,WITHOUT_CLASSIFICATION,/*  New method that distributes the Scan query by creating splits containing   * information about different Druid nodes that have the data for the given   * query.  */
Hive,WITHOUT_CLASSIFICATION,/*  nUnknown hive type infoot a map  */
Hive,WITHOUT_CLASSIFICATION,//  shallow copy aliasToOpInfo we won't want to clone the operator tree here 
Hive,WITHOUT_CLASSIFICATION,//  it is DESCRIBE table partition 
Hive,WITHOUT_CLASSIFICATION,//  3 7 9 
Hive,WITHOUT_CLASSIFICATION,//  The writer is local to the process. 
Hive,WITHOUT_CLASSIFICATION,//  Generate the list bucketing pruning predicate as 2 separate IN clauses   containing the partitioning and non-partitioning columns. 
Hive,WITHOUT_CLASSIFICATION,//  clean up the temp files 
Hive,WITHOUT_CLASSIFICATION,//  Could be null if there's a race between the threads processing requests with a   dag finish processed earlier. 
Hive,WITHOUT_CLASSIFICATION,//  Counters for debugging we cannot use existing counters (cntr and nextCntr) 
Hive,WITHOUT_CLASSIFICATION,// if metastore has no record of this lock it most likely timed out; either way  there is no point tracking it here any longer 
Hive,WITHOUT_CLASSIFICATION,//  10^16 - 1 
Hive,WITHOUT_CLASSIFICATION,//  This would refresh any conf resources and also local resources. 
Hive,WITHOUT_CLASSIFICATION,//  The JobTracker has exceeded its threshold and is doing a GC. 
Hive,WITHOUT_CLASSIFICATION,//  We are modifying divisor here so make a local copy. 
Hive,WITHOUT_CLASSIFICATION,//  DC_NAME 
Hive,WITHOUT_CLASSIFICATION,//  Check for a list. If found recursively init its members 
Hive,WITHOUT_CLASSIFICATION,//  No op this thread was interrupted   In this case the call might return sooner than long polling timeout 
Hive,WITHOUT_CLASSIFICATION,//  Update description 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setObject(int java.lang.Object int int)    */
Hive,WITHOUT_CLASSIFICATION,//  In future this may examine ReadEntity and/or config to return   appropriate HCatReader 
Hive,WITHOUT_CLASSIFICATION,//  10^-15 
Hive,WITHOUT_CLASSIFICATION,//  Within the proxy object we wrap the method call in a UserGroupInformation#doAs 
Hive,WITHOUT_CLASSIFICATION,//  no token found 
Hive,WITHOUT_CLASSIFICATION,//  Offset truncation. 
Hive,WITHOUT_CLASSIFICATION,//  At the beginning of the list record will be the value length. 
Hive,WITHOUT_CLASSIFICATION,//  OPEN_TXNS 
Hive,WITHOUT_CLASSIFICATION,//  all keys + VCol + c + VCol*c 
Hive,WITHOUT_CLASSIFICATION,//  check for this pattern   The pattern matching could be simplified if rules can be applied   during decorrelation     CorrelateRel(left correlation condition = true)     LeftInputRel     Project-A (a RexNode)       Aggregate (groupby (0) agg0() agg1()...) 
Hive,WITHOUT_CLASSIFICATION,//  see paper for alpha initialization. 
Hive,WITHOUT_CLASSIFICATION,//  if size of sparse map excess the threshold convert the sparse map to   dense register and switch to DENSE encoding 
Hive,WITHOUT_CLASSIFICATION,//  if query is not in compiled state or executing state which is carried over from   a combined compile/execute in runInternal throws the error 
Hive,WITHOUT_CLASSIFICATION,//  Heartbeat on the lockid first to assure that our lock is still valid.   Then look up the lock info (hopefully in the cache).  If these locks 
Hive,WITHOUT_CLASSIFICATION,//  number of distribution keys of cRS is chosen only when numDistKeys of pRS   is 0 or less. In all other cases distribution of the keys is based on   the pRS which is more generic than cRS.   Examples:   case 1: if pRS sort key is (a b) and cRS sort key is (a b c) and number of   distribution keys are 2 and 3 resp. then after merge the sort keys will   be (a b c) while the number of distribution keys will be 2.   case 2: if pRS sort key is empty and number of distribution keys is 0   and if cRS sort key is (a b) and number of distribution keys is 2 then   after merge new sort key will be (a b) and number of distribution keys   will be 2. 
Hive,WITHOUT_CLASSIFICATION,//  test string->string version 
Hive,WITHOUT_CLASSIFICATION,//  get pushdown predicates for this operator's predicate 
Hive,WITHOUT_CLASSIFICATION,//  Check if there exists bloom filter size entry 
Hive,WITHOUT_CLASSIFICATION,//  Initialization isn't finished until all parents of all operators   are initialized. For broadcast joins that means initializing the 
Hive,WITHOUT_CLASSIFICATION,//                   ROW__ID 
Hive,WITHOUT_CLASSIFICATION,//  validate principals 
Hive,WITHOUT_CLASSIFICATION,//  First shot without waiting. 
Hive,WITHOUT_CLASSIFICATION,//  We have more input but did we start with something valid? 
Hive,WITHOUT_CLASSIFICATION,//  Precision/scale exceed maximum precision. Result must be adjusted to HiveDecimal.MAX_PRECISION. 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:org.apache.hadoop.hive.ql.hooks.proto.MapFieldEntry) 
Hive,WITHOUT_CLASSIFICATION,//  Check if the group by operator has already been processed 
Hive,WITHOUT_CLASSIFICATION,//  Merge the result of last evaluate to previous evaluate. 
Hive,WITHOUT_CLASSIFICATION,// throws exception if not initialized 
Hive,WITHOUT_CLASSIFICATION,//  Evaluate the aggregation functions over the group batch. 
Hive,WITHOUT_CLASSIFICATION,//    this entry in the pathenv is a directory.   see if the required file is in this directory   
Hive,WITHOUT_CLASSIFICATION,//  1. Insert a row to Non-ACID table 
Hive,WITHOUT_CLASSIFICATION,//  Can not judge so assuming replication is not enabled. 
Hive,WITHOUT_CLASSIFICATION,//  List? 
Hive,WITHOUT_CLASSIFICATION,//  This is simply to verify that the hooks were in fact run 
Hive,WITHOUT_CLASSIFICATION,//  row resolver for the operator 
Hive,WITHOUT_CLASSIFICATION,//  Yarn ATS 
Hive,WITHOUT_CLASSIFICATION,//  this is just for SMB join use-case. The numBuckets would be equal to that of the big table   and the small table could have lesser number of buckets. In this case we want to send the   data from the right buckets to the big table side. For e.g. Big table has 8 buckets and small   table has 4 buckets bucket 0 of small table needs to be sent to bucket 4 of the big table as 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.CLIServiceClient#getCatalogs(org.apache.hive.service.cli.SessionHandle)    */
Hive,WITHOUT_CLASSIFICATION,//  Two objects. 
Hive,WITHOUT_CLASSIFICATION,//  Decimal64 
Hive,WITHOUT_CLASSIFICATION,//  It is a writable class 
Hive,WITHOUT_CLASSIFICATION,// test get_table_objects_by_name functionality 
Hive,WITHOUT_CLASSIFICATION,//  123 
Hive,WITHOUT_CLASSIFICATION,//  invariant: bucket-col IN literals of type bucketField 
Hive,WITHOUT_CLASSIFICATION,// this breaks all the tests in .q files 
Hive,WITHOUT_CLASSIFICATION,//  The one big table row's values repeat. 
Hive,WITHOUT_CLASSIFICATION,// key_dne = "50" 
Hive,WITHOUT_CLASSIFICATION,//  Map of Avro's primitive types to Hives (for those that are supported by both) 
Hive,WITHOUT_CLASSIFICATION,//  This close() function does not need to be synchronized   since it is called by its parents' main thread so no 
Hive,WITHOUT_CLASSIFICATION,//  Assumption - batchIndex is increasing; startVectorizedBatch was called 
Hive,WITHOUT_CLASSIFICATION,//  2. INSERT OVERWRITE 
Hive,WITHOUT_CLASSIFICATION,//  Use Complex.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,//  TBL_NAMES 
Hive,WITHOUT_CLASSIFICATION,//  EOF: 
Hive,WITHOUT_CLASSIFICATION,//  Select query results 
Hive,WITHOUT_CLASSIFICATION,//  Zero dividend 
Hive,WITHOUT_CLASSIFICATION,//  10^-16 
Hive,WITHOUT_CLASSIFICATION,//  Adding mysql jdbc driver if exists 
Hive,WITHOUT_CLASSIFICATION,//  we should also remove it when pulling it from Accumulo 
Hive,WITHOUT_CLASSIFICATION,//  get input path and remove this alias from pathToAlias 
Hive,WITHOUT_CLASSIFICATION,// column indexes of corresponding data in storage layer 
Hive,WITHOUT_CLASSIFICATION,//  HIVE-9644 Attempt to fold expression like :   where (case ss_sold_date when '1998-01-01' then 1=1 else null=1 end);   where ss_sold_date= '1998-01-01' ; 
Hive,WITHOUT_CLASSIFICATION,//  indicates if read buffer has data   number of rows in the temporary read buffer   cursor during reading   total number of objects in 0output 
Hive,WITHOUT_CLASSIFICATION,//  verify 
Hive,WITHOUT_CLASSIFICATION,//  Add jars containing the specified classes 
Hive,WITHOUT_CLASSIFICATION,/*    * This method takes in an input operator and a subset of its output   * column names and generates the input column names for the operator   * corresponding to those outputs. If the mapping from the input column   * name to the output column name is not simple the method returns   * false else it returns true. The list of output column names is   * modified by this method to be the list of corresponding input column   * names.    */
Hive,WITHOUT_CLASSIFICATION,//  After Load from this dump all target tables/partitions will have initial set of data. 
Hive,WITHOUT_CLASSIFICATION,/*  This method returns the flip big-endian representation of value  */
Hive,WITHOUT_CLASSIFICATION,//  v[7] -- since integer #5 is always 0 some products here are not included. 
Hive,WITHOUT_CLASSIFICATION,//  only precision is specified 
Hive,WITHOUT_CLASSIFICATION,//  Make a deep copy of the aliases so that they are not changed in the context 
Hive,WITHOUT_CLASSIFICATION,//    Rewrite logic:     1. Permute the group by keys to the front.   2. If the input of an aggregate produces correlated variables      add them to the group list.   3. Change aggCalls to reference the new project.   
Hive,WITHOUT_CLASSIFICATION,//  Some of the strings can be passed in as unicode. For example the   delimiter can be passed in as \002 - So we first check if the   string is a unicode number else go back to the old behavior 
Hive,WITHOUT_CLASSIFICATION,//  has the user explicitly asked not to sample this table 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getBytes(int)    */
Hive,WITHOUT_CLASSIFICATION,//  No children means we're at the bottom. If there are more operators to scan 
Hive,WITHOUT_CLASSIFICATION,//  B is maxed out on capacity so this move should fail the session 
Hive,WITHOUT_CLASSIFICATION,//  This will also move the iterator ahead by one code point 
Hive,WITHOUT_CLASSIFICATION,//  End of the month behavior 
Hive,WITHOUT_CLASSIFICATION,//  Look for a file to which we can move the existing file. With external services   it's possible for the service to be marked complete after each fragment. 
Hive,WITHOUT_CLASSIFICATION,//  continue; 
Hive,WITHOUT_CLASSIFICATION,/*  doClipping  */
Hive,WITHOUT_CLASSIFICATION,//  Converts Timestamp to TimestampTZ. 
Hive,WITHOUT_CLASSIFICATION,//  re-set TABLE_PROPS with reloaded tblproperties 
Hive,WITHOUT_CLASSIFICATION,//  pRS-pJOIN-cRS 
Hive,WITHOUT_CLASSIFICATION,//  production is: i64 
Hive,WITHOUT_CLASSIFICATION,//  10^-18 
Hive,WITHOUT_CLASSIFICATION,//  tables have been replicated over and verified to be identical. Now we do a couple of   alters on the source 
Hive,WITHOUT_CLASSIFICATION,//  We skip DB check for import here because we already handle it above   as a CTAS check. 
Hive,WITHOUT_CLASSIFICATION,//  Store the ugi in transport and then continue as usual. 
Hive,WITHOUT_CLASSIFICATION,//  For unpartitioned table partitionVals are not specified 
Hive,WITHOUT_CLASSIFICATION,//  delete. 
Hive,WITHOUT_CLASSIFICATION,//  Extract the launcher job submit/start time and use that to scope down   the search interval when we look for child jobs 
Hive,WITHOUT_CLASSIFICATION,//  finishTime 
Hive,WITHOUT_CLASSIFICATION,//  Then finishable must always precede non-finishable. 
Hive,WITHOUT_CLASSIFICATION,//  Still in the local JVM use the username+password or Kerberos credentials 
Hive,WITHOUT_CLASSIFICATION,//  Init 
Hive,WITHOUT_CLASSIFICATION,//  override with user defined properties 
Hive,WITHOUT_CLASSIFICATION,//  Apply isnull and instr (not supported by pushdown) via name filtering. 
Hive,WITHOUT_CLASSIFICATION,//  no locks present 
Hive,WITHOUT_CLASSIFICATION,//  lets take a look at the operators. we're checking for user   code in those. we will not run that in llap. 
Hive,WITHOUT_CLASSIFICATION,//  The registration znode. 
Hive,WITHOUT_CLASSIFICATION,//  First try to quickly lock some of the correct-sized free lists and allocate from them. 
Hive,WITHOUT_CLASSIFICATION,//  Adjust file column index for ORC struct. 
Hive,WITHOUT_CLASSIFICATION,//  Remove this server instance from ZooKeeper if dynamic service discovery is set 
Hive,WITHOUT_CLASSIFICATION,//  We do not want to keep state in two separate places so remove from hive table properties. 
Hive,WITHOUT_CLASSIFICATION,// done 
Hive,WITHOUT_CLASSIFICATION,//  for temporary tables we set the location to something in the session's scratch dir   it has the same life cycle as the tmp table 
Hive,WITHOUT_CLASSIFICATION,// toEpochMilli() returns UTC time regardless of TZ 
Hive,WITHOUT_CLASSIFICATION,//  resulting output object inspector can be used to make the RowResolver 
Hive,WITHOUT_CLASSIFICATION,//  The new ObjectInspector is the same as the old one directly return   true 
Hive,WITHOUT_CLASSIFICATION,// Power with double power 
Hive,WITHOUT_CLASSIFICATION,//  replace it back 
Hive,WITHOUT_CLASSIFICATION,//  OrcRecordUpdater.ROW. This is somewhat fragile...   Note: this guarantees that physical column IDs are in order. 
Hive,WITHOUT_CLASSIFICATION,//  We don't want to include the root struct in ACID case; it would cause the whole   struct to get read without projection. 
Hive,WITHOUT_CLASSIFICATION,//  Refer to org.apache.tez.mapreduce.hadoop.MRHelpers.processDirectConversion. 
Hive,WITHOUT_CLASSIFICATION,//  negative means the key didn't exist in the original    stream (i.e.: we changed the tree) 
Hive,WITHOUT_CLASSIFICATION,//  Determine minimum of all non-null decimal column values; maintain isGroupResultNull. 
Hive,WITHOUT_CLASSIFICATION,//  Can't be escaped it is the separator 
Hive,WITHOUT_CLASSIFICATION,//  Skip the auth in embedded mode or if the auth is disabled 
Hive,WITHOUT_CLASSIFICATION,//  Same file different offset 
Hive,WITHOUT_CLASSIFICATION,//  restore repeating and no nulls indicators 
Hive,WITHOUT_CLASSIFICATION,//  For inner joins we may apply the filter(s) now. 
Hive,WITHOUT_CLASSIFICATION,// HCatFieldSchema.getName()->position 
Hive,WITHOUT_CLASSIFICATION,//  2) If we need to create some extra sessions we'd do it just like startup does. 
Hive,WITHOUT_CLASSIFICATION,//  improved later. 
Hive,WITHOUT_CLASSIFICATION,//  TODO: If this test method is the first to run then the parameters does not contain totalSize   and numFiles if this runs after other tests (setUp/dropDatabase is successful) then the 
Hive,WITHOUT_CLASSIFICATION,// we've added Insert clauses in order or WHEN items in whenClauses 
Hive,WITHOUT_CLASSIFICATION,//  Most operations cannot run asynchronously. 
Hive,WITHOUT_CLASSIFICATION,//  should emit an exception 
Hive,WITHOUT_CLASSIFICATION,//  Callback on a separate thread so that when a task completes the thread in the main queue 
Hive,WITHOUT_CLASSIFICATION,//  filter the list of locations to those that have at least 80% of the 
Hive,WITHOUT_CLASSIFICATION,//  2 X 2 events for V1. 3 X 1 events for V2 
Hive,WITHOUT_CLASSIFICATION,//  ignore empty strings 
Hive,WITHOUT_CLASSIFICATION,//  when partition column type is not string the values from __HIVE_DEFAULT_PARTITION__ will be NULL 
Hive,WITHOUT_CLASSIFICATION,//  Apply the plan again - enable WM. 
Hive,WITHOUT_CLASSIFICATION,//  2) To unpartitioned table 
Hive,WITHOUT_CLASSIFICATION,//  test February of non-leap year 2/28 
Hive,WITHOUT_CLASSIFICATION,//  class PartitionSpecProxy; 
Hive,WITHOUT_CLASSIFICATION,//  Get failed attempts from jobfailures.jsp 
Hive,WITHOUT_CLASSIFICATION,//  SIMD loop 
Hive,WITHOUT_CLASSIFICATION,//  Get list of temp table names 
Hive,WITHOUT_CLASSIFICATION,//  In case thread count is set to 0 use single thread. 
Hive,WITHOUT_CLASSIFICATION,//  2. We then iterate through all the operators that have candidate FKs again.   We assume the PK is first joining with the FK that we just selected.   And we apply the PK-FK relationship when we compute the newrows and ndv.   After that we join the result with all the other FKs.   We do not assume the PK-FK relationship anymore and just compute the 
Hive,WITHOUT_CLASSIFICATION,//  in case of io error reset the file system object 
Hive,WITHOUT_CLASSIFICATION,//  Replicate all the events happened after bootstrap 
Hive,WITHOUT_CLASSIFICATION,//  ExecutorRunTime etc.) 
Hive,WITHOUT_CLASSIFICATION,//  runAsync queryTimeout makes sense only for a SQLOperation   Pass the original statement to SQLOperation as sql parser can remove comments by itself 
Hive,WITHOUT_CLASSIFICATION,//  if the big table has more buckets than the current small table   use "MOD" to get small table bucket names. For example if the big   table has 4 buckets and the small table has 2 buckets then the   mapping should be 0->0 1->1 2->0 3->1. 
Hive,WITHOUT_CLASSIFICATION,//  the reader pointer has moved to the end of next block or the end of   current record. 
Hive,WITHOUT_CLASSIFICATION,//  Need some extra checks   Get the running owner 
Hive,WITHOUT_CLASSIFICATION,//  years/months represented in months 
Hive,WITHOUT_CLASSIFICATION,//  Buddy block is allocated or it is on higher level of allocation than we are or we   have reached the top level. Add whatever we have got to the current free list. 
Hive,WITHOUT_CLASSIFICATION,//  Not public since we must have the field count or column sort order information. 
Hive,WITHOUT_CLASSIFICATION,//  create a simple table and test create drop get 
Hive,WITHOUT_CLASSIFICATION,//  Repeated NULLs -- skip this input column. 
Hive,WITHOUT_CLASSIFICATION,//  Changes the owner to a group and verify the change 
Hive,WITHOUT_CLASSIFICATION,//  The default is different on the client and server so it's null here. 
Hive,WITHOUT_CLASSIFICATION,//  compare set fields 
Hive,WITHOUT_CLASSIFICATION,//  In the cases of create partition by the time this event fires the partition   object has not yet come into existence and thus will not yet have a   location or an SD but these are needed to create a ql.metadata.Partition   so we use the table's SD. The only place this is used is by the   authorization hooks so we will not affect code flow in the metastore itself. 
Hive,WITHOUT_CLASSIFICATION,//  And finally return them in a flat array 
Hive,WITHOUT_CLASSIFICATION,//  The following 'deltas' includes all kinds of delta files including insert & delete deltas. 
Hive,WITHOUT_CLASSIFICATION,//  Drop table will clean the table entry from the compaction queue and hence cleaner have no effect 
Hive,WITHOUT_CLASSIFICATION,//  Many restrictions. 
Hive,WITHOUT_CLASSIFICATION,//  Check if user have erroneously specified non-existent partitioning columns 
Hive,WITHOUT_CLASSIFICATION,//  Manually modify the underlying metastore db to reflect statistics corresponding to 
Hive,WITHOUT_CLASSIFICATION,//  The RangeInputSplit *should* have all of the necesary information contained in it   which alleviates us from re-parsing our configuration from the AccumuloStorageHandler   and re-setting it into the Configuration (like we did in getSplits(...)). Thus it should   be unnecessary to re-invoke configure(...) 
Hive,WITHOUT_CLASSIFICATION,//  for asc nulls first; for desc nulls last 
Hive,WITHOUT_CLASSIFICATION,//  if all is good 
Hive,WITHOUT_CLASSIFICATION,//  Fully specified partition spec 
Hive,WITHOUT_CLASSIFICATION,//  Ensure Data structures are updated in the main TaskScheduler 
Hive,WITHOUT_CLASSIFICATION,//  Retry with CM path 
Hive,WITHOUT_CLASSIFICATION,//  Filter) are in the output and in the same position. 
Hive,WITHOUT_CLASSIFICATION,// txnid:idTxnUpdate2 
Hive,WITHOUT_CLASSIFICATION,// Execution mode: vectorized 
Hive,WITHOUT_CLASSIFICATION,//  such as "abc%" 
Hive,WITHOUT_CLASSIFICATION,//  special case: if both constants are not equal then return 0 
Hive,WITHOUT_CLASSIFICATION,//  honor custom location for external table apart from what metadata specifies 
Hive,WITHOUT_CLASSIFICATION,//  We don't use the cache's copy of the buffer. 
Hive,WITHOUT_CLASSIFICATION,//  Is the decimal value currently valid? 
Hive,WITHOUT_CLASSIFICATION,//  update paths[i] e.g. from "QUERY:id" to "id" 
Hive,WITHOUT_CLASSIFICATION,// Read should get 10 + 20 rows if immutable 50 (10+20+20) if mutable 
Hive,WITHOUT_CLASSIFICATION,//  Search like binary search to minimize comparisons. 
Hive,WITHOUT_CLASSIFICATION,//  This is doing a lot of copying here this could be improved by enforcing length   at the same time as escaping rather than as separate steps. 
Hive,WITHOUT_CLASSIFICATION,//  When data is prematurely ended the fieldPosition will be 1 more than the end. 
Hive,WITHOUT_CLASSIFICATION,//  See if the alias has a lateral view. If so chain the lateral view   operator on 
Hive,WITHOUT_CLASSIFICATION,/*    * Element for Key: Long x Hash Table: HashSet    */
Hive,WITHOUT_CLASSIFICATION,//  we need openssl 
Hive,WITHOUT_CLASSIFICATION,//  only input 1 side has nulls 
Hive,WITHOUT_CLASSIFICATION,//  Sort columns to make output deterministic 
Hive,WITHOUT_CLASSIFICATION,//  if cRS is being used for distinct - the two reduce sinks are incompatible 
Hive,WITHOUT_CLASSIFICATION,//  Replicate the changes to the replicated-table. 
Hive,WITHOUT_CLASSIFICATION,//  Add the distinct aggregate column(s) to the group-by columns 
Hive,WITHOUT_CLASSIFICATION,//  Design Note: In the future if this function can be implemented   directly to translate input to output without creating new   objects performance can probably be improved significantly.   It's implemented in the simplest way now just calling the   existing built-in function. 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) FlagArgs  */
Hive,WITHOUT_CLASSIFICATION,// txnid:idTxnUpdate1 
Hive,WITHOUT_CLASSIFICATION,//  we do not need to connect its parent to its counterpart as they have the same parents. 
Hive,WITHOUT_CLASSIFICATION,//  Archived partitions have har:/to_har_file as their location.   The original directory was saved in params 
Hive,WITHOUT_CLASSIFICATION,/*  Patterns that are included in execution logging level.     * In execution mode show only select logger messages.      */
Hive,WITHOUT_CLASSIFICATION,//  Return a constant vector expression 
Hive,WITHOUT_CLASSIFICATION,//  We do not include the dummy grouping set column in the output.  So we pass outputKeyLength   instead of keyExpressions.length 
Hive,WITHOUT_CLASSIFICATION,//  The tokens we should ignore when we are trying to do table masking. 
Hive,WITHOUT_CLASSIFICATION,//  This batch is full: break out of for loop to execute 
Hive,WITHOUT_CLASSIFICATION,//  Given a byte array consisting of a serialized BloomKFilter gives the offset (from 0)   for the start of the serialized long values that make up the bitset. 
Hive,WITHOUT_CLASSIFICATION,//  not be read. Thus 0 records. 
Hive,WITHOUT_CLASSIFICATION,// txnid:idTxnUpdate4 
Hive,WITHOUT_CLASSIFICATION,//  the jsonObject for this operator 
Hive,WITHOUT_CLASSIFICATION,// Basic case 
Hive,WITHOUT_CLASSIFICATION,//  Intentionally using deprecated method 
Hive,WITHOUT_CLASSIFICATION,//  Disable LLAP IO wrapper; doesn't propagate extra ACID columns correctly. 
Hive,WITHOUT_CLASSIFICATION,//  default executors is 4 max slots is 3. so 3 * 20% of noconditional task size will be oversubscribed 
Hive,WITHOUT_CLASSIFICATION,//  Delete the incorrectly copied file and retry with CM path 
Hive,WITHOUT_CLASSIFICATION,//  Map of Integer to Integer 
Hive,WITHOUT_CLASSIFICATION,//  If HIVE_CONF_DIR is not defined or file is not found in HIVE_CONF_DIR then check HIVE_HOME/conf 
Hive,WITHOUT_CLASSIFICATION,//  create partCount dummy partitions 
Hive,WITHOUT_CLASSIFICATION,//  Nothing to be done 
Hive,WITHOUT_CLASSIFICATION,//  Go over all the aggregation classes and and get the size of the fields of   fixed length. Keep track of the variable length 
Hive,WITHOUT_CLASSIFICATION,// check how much memory left memory 
Hive,WITHOUT_CLASSIFICATION,//  Unregister for the dirWatcher for the specific dagIdentifier in either case. 
Hive,WITHOUT_CLASSIFICATION,// txnid:idTxnUpdate3 
Hive,WITHOUT_CLASSIFICATION,/*    * Tests with queries which cannot be executed with directSQL because of type mismatch. The type   * of the num column is string but the parameters used in the where clause are numbers. After   * falling back to ORM the number of partitions cannot be fetched by the   * ObjectStore.getNumPartitionsViaOrmFilter method. They are fetched by the   * ObjectStore.getPartitionNamesPrunedByExprNoTxn method.    */
Hive,WITHOUT_CLASSIFICATION,//  while ! done 
Hive,WITHOUT_CLASSIFICATION,//  Current vector map operator read type and context. 
Hive,WITHOUT_CLASSIFICATION,//  1.4. Set needed cols in TSDesc 
Hive,WITHOUT_CLASSIFICATION,//  serialize some data in the schema before it is altered. 
Hive,WITHOUT_CLASSIFICATION,//  Logger with default base 
Hive,WITHOUT_CLASSIFICATION,//  another single call to get all the partition objects 
Hive,WITHOUT_CLASSIFICATION,//  no rows qualify 
Hive,WITHOUT_CLASSIFICATION,//  only user belonging to admin role can list role 
Hive,WITHOUT_CLASSIFICATION,//  This should not happen. 
Hive,WITHOUT_CLASSIFICATION,//  A DemuxOperator should have at least one child 
Hive,WITHOUT_CLASSIFICATION,//  Currently we do not support merging windowing functions with other   windowing functions i.e. embedding windowing functions within each   other 
Hive,WITHOUT_CLASSIFICATION,//  Set of values to look for. 
Hive,WITHOUT_CLASSIFICATION,//  3) We check whether we will end up with same operators inputing on same work.           Work1        (merge TS in W2 & W3)        Work1         /   \                  ->                  | |       X     Work2   Work3                                 Work2     If we do we cannot merge. The reason is the same as above currently   Tez does not support parallel edges.     In the check we exclude the inputs to the root operator that we are trying 
Hive,WITHOUT_CLASSIFICATION,//  both were the same and can be replaced by the new db we're loading into. 
Hive,WITHOUT_CLASSIFICATION,//  This join has been converted to a SMB join by the hive optimizer. The user did not   give a mapjoin hint in the query. The hive optimizer figured out that the join can be 
Hive,WITHOUT_CLASSIFICATION,//  Test that existing shared_write table with new exclusive coalesces to 
Hive,WITHOUT_CLASSIFICATION,//  BINARY conversions supported by GenericUDFDecimal GenericUDFTimestamp. 
Hive,WITHOUT_CLASSIFICATION,//  TODO: we could/should trace seek destinations; pps needs a "peek" method 
Hive,WITHOUT_CLASSIFICATION,//  source prep 
Hive,WITHOUT_CLASSIFICATION,//  get the scale factor to turn big decimal into a decimal < 1   This relies on the BigDecimal precision value which as of HIVE-10270 
Hive,WITHOUT_CLASSIFICATION,//  Cancel the timer 
Hive,WITHOUT_CLASSIFICATION,//  cache the results for table authorization 
Hive,WITHOUT_CLASSIFICATION,// only set output dir if partition is fully materialized 
Hive,WITHOUT_CLASSIFICATION,//  column buffers otherwise at the end when closeOp() is called things get printed multiple times. 
Hive,WITHOUT_CLASSIFICATION,//  Fall through to delta 
Hive,WITHOUT_CLASSIFICATION,//  not -1   not -1 
Hive,WITHOUT_CLASSIFICATION,//  keep column expression map explain plan uses this to display 
Hive,WITHOUT_CLASSIFICATION,// this is set in ZooKeeperStorage.create() 
Hive,WITHOUT_CLASSIFICATION,//  Proceed with a binary search 
Hive,WITHOUT_CLASSIFICATION,//  For once we actually want reference equality in Java. 
Hive,WITHOUT_CLASSIFICATION,//  Should we convert the datetime to the format Hive understands by default   - either yyyy-mm-dd HH:MM:SS or seconds since epoch?   Date d = dateparser.parse(c.rdatetime);   c.rdatetimeepoch = d.getTime() / 1000; 
Hive,WITHOUT_CLASSIFICATION,//  8 
Hive,WITHOUT_CLASSIFICATION,//  First row is all nulls 
Hive,WITHOUT_CLASSIFICATION,//  We don't need this for now so do not support it. 
Hive,WITHOUT_CLASSIFICATION,//  following mapping is to enable UDFName to UDF while generating expression for default value (in operator tree) 
Hive,WITHOUT_CLASSIFICATION,//  We have a repeated value.  The sum increases by value * batch.size. 
Hive,WITHOUT_CLASSIFICATION,/*  id <= 4              */
Hive,WITHOUT_CLASSIFICATION,//  Always set the EXPLAIN conditions. 
Hive,WITHOUT_CLASSIFICATION,//  Verify that the table does not already exist   dumpTable is only used to check the conflict for non-temporary tables 
Hive,WITHOUT_CLASSIFICATION,//  objectinspector 
Hive,WITHOUT_CLASSIFICATION,// data from delta_200_200 
Hive,WITHOUT_CLASSIFICATION,//  Setup cache if enabled. 
Hive,WITHOUT_CLASSIFICATION,/*    * If the init method of HMSHandler throws exception for the first time   * while creating RetryingHMSHandler it should be retried    */
Hive,WITHOUT_CLASSIFICATION,//  2^128 - 1 
Hive,WITHOUT_CLASSIFICATION,//  as a setting. 
Hive,WITHOUT_CLASSIFICATION,/*    * Use this constructor when there is an output column.    */
Hive,WITHOUT_CLASSIFICATION,//  generate a groupby operator (HASH mode) for a map-side partial 
Hive,WITHOUT_CLASSIFICATION,//  return true if this task is an ancestor of itself of parameter desc 
Hive,WITHOUT_CLASSIFICATION,//  Skip all the events belong to other DBs/tables. 
Hive,WITHOUT_CLASSIFICATION,//  LOG.debug("VectorMapJoinFastLongHashMap lookup " + key + " hashCode " + hashCode); 
Hive,WITHOUT_CLASSIFICATION,//  no need of merging if the move is to a local file system 
Hive,WITHOUT_CLASSIFICATION,//  i.e. the sequence must be pRS-SEL*-cRS 
Hive,WITHOUT_CLASSIFICATION,//  These operators need to be linked to enable runtime statistics to be gathered/used correctly 
Hive,WITHOUT_CLASSIFICATION,//  Remove bloomfilter if no stats generated 
Hive,WITHOUT_CLASSIFICATION,//  for now disable operating on decimal64 column vectors for semijoin reduction as   we have to make sure same decimal type should be used during bloom filter creation   and bloom filter probing 
Hive,WITHOUT_CLASSIFICATION,// since Repeating only happens when offset length is 1. 
Hive,WITHOUT_CLASSIFICATION,//  optional authzid 
Hive,WITHOUT_CLASSIFICATION,//    testLazyBinaryFast(         source rows         serde rowStructObjectInspector         serde_fewer writeRowStructObjectInspector         primitiveTypeInfos         /* useIncludeColumns */ true /* doWriteFewerColumns */ true r);   } 
Hive,WITHOUT_CLASSIFICATION,//  Exact same state as above. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#executeBatch()    */
Hive,WITHOUT_CLASSIFICATION,//  optional string hiveQueryId = 2; 
Hive,WITHOUT_CLASSIFICATION,//  GroupBy1 for the grouping set (corresponding to the rollup). 
Hive,WITHOUT_CLASSIFICATION,/*      * Optimize by running value expressions only over the matched rows.      */
Hive,WITHOUT_CLASSIFICATION,//  not ok to have a location locked by someone else. 
Hive,WITHOUT_CLASSIFICATION,//  Look at the current session's setting 
Hive,WITHOUT_CLASSIFICATION,/*    * - tree form is   *   ^(TOK_PTBLFUNCTION name alias? partitionTableFunctionSource partitioningSpec? arguments*)   * - a partitionTableFunctionSource can be a tableReference a SubQuery or another   *   PTF invocation.    */
Hive,WITHOUT_CLASSIFICATION,//  boolean that says whether tez auto reduce parallelism should be used 
Hive,WITHOUT_CLASSIFICATION,//  this plug-in to avoid getting a serialized event at run-time. 
Hive,WITHOUT_CLASSIFICATION,//  Leaving this as the 'hive' catalog (rather than choosing the default from the   configuration) because all the default UDFs are in that catalog and I think that's   would people really want here. 
Hive,WITHOUT_CLASSIFICATION,/*    * BYTE.    */
Hive,WITHOUT_CLASSIFICATION,// if needs refresh param is passed it should return new object 
Hive,WITHOUT_CLASSIFICATION,//  Create an SSL socket and connect 
Hive,WITHOUT_CLASSIFICATION,//  If HiveTableScan is not found e.g. not sequence of Project and   Filter operators execute the original getUniqueKeys method 
Hive,WITHOUT_CLASSIFICATION,//  inpPartSpec is a mapping from partition column name to its value. 
Hive,WITHOUT_CLASSIFICATION,//  Writer should match the orc configuration from the original file 
Hive,WITHOUT_CLASSIFICATION,//  We will remember completed DAG for an hour to avoid execution out-of-order fragments. 
Hive,WITHOUT_CLASSIFICATION,//  get column type 
Hive,WITHOUT_CLASSIFICATION,//  backtrack key exprs of child to parent and compare it with parent's 
Hive,WITHOUT_CLASSIFICATION,// Highest priority at this point should have come out. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setURL(java.lang.String java.net.URL)    */
Hive,WITHOUT_CLASSIFICATION,//  is   always   positive 
Hive,WITHOUT_CLASSIFICATION,//  Remove branch 
Hive,WITHOUT_CLASSIFICATION,//  We are going to create the map for each view in the given database 
Hive,WITHOUT_CLASSIFICATION,//  r--r----- 
Hive,WITHOUT_CLASSIFICATION,//  Returns true if the aggregation result will be streamed. 
Hive,WITHOUT_CLASSIFICATION,//  old bucketing logic 
Hive,WITHOUT_CLASSIFICATION,//  Hive "insert overwrite local directory" uses task id as dir name   Setting the id in jobconf helps to have the similar dir name as MR 
Hive,WITHOUT_CLASSIFICATION,//  Make sure no one calls this 
Hive,WITHOUT_CLASSIFICATION,//  else osx gives ugly temp path which screws up approvals 
Hive,WITHOUT_CLASSIFICATION,//  do a group by on the list to dedup 
Hive,WITHOUT_CLASSIFICATION,//  blank " " (1 byte)   blank " " (1 byte)   blank " " (1 byte)   Asian character U+4824 (3 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  this will stop run() from pushing records along with potentially   blocking initialization. 
Hive,WITHOUT_CLASSIFICATION,//  How much we can read from current read buffer out of what we need. 
Hive,WITHOUT_CLASSIFICATION,//  input path --> {operator --> context} 
Hive,WITHOUT_CLASSIFICATION,//  Wait for scheduling to run a few times. 
Hive,WITHOUT_CLASSIFICATION,//  We enforce a certain order when we do the reutilization.   In particular we use size of table x number of reads to 
Hive,WITHOUT_CLASSIFICATION,/*            * Single-Column Long get key.            */
Hive,WITHOUT_CLASSIFICATION,//  Message must be transacted before we return. 
Hive,WITHOUT_CLASSIFICATION,//  Push filter on top of children for retainable 
Hive,WITHOUT_CLASSIFICATION,//  Mark any scratch small table scratch columns that would normally receive a copy of the   key as null too. 
Hive,WITHOUT_CLASSIFICATION,//  The input should be in TextInputFormat. 
Hive,WITHOUT_CLASSIFICATION,//  Set to non-zk lock manager to prevent HS2 from trying to connect 
Hive,WITHOUT_CLASSIFICATION,//  Retry logic 
Hive,WITHOUT_CLASSIFICATION,//  Test append_partition_by_name 
Hive,WITHOUT_CLASSIFICATION,//  Verify moveOnlyTask is optimized 
Hive,WITHOUT_CLASSIFICATION,//  keep the dynamic partition context in conditional task resolver context 
Hive,WITHOUT_CLASSIFICATION,/*   public boolean dropPartition(String dbName String tableName String partName boolean deleteData boolean ifPurge)      throws NoSuchObjectException MetaException TException {    return dropPartition(dbName tableName partName deleteData                         ifPurge? getEnvironmentContextWithIfPurgeSet() : null);  }   */
Hive,WITHOUT_CLASSIFICATION,//  Lowest field. 
Hive,WITHOUT_CLASSIFICATION,// /////////////////////////////////////////////  ////////////////// other failure testcases  //////////////////////////////////////////// 
Hive,WITHOUT_CLASSIFICATION,//  Cannot validate the list it may be unset 
Hive,WITHOUT_CLASSIFICATION,//  New state is changed to running from something else (user is active) 
Hive,WITHOUT_CLASSIFICATION,//  Deal with the last entry 
Hive,WITHOUT_CLASSIFICATION,//  The number of reduce tasks per job. Hadoop sets this value to 1 by default   By setting this property to -1 Hive will automatically determine the correct 
Hive,WITHOUT_CLASSIFICATION,/*         we set it to completed if there is nothing the server has to report        for example DDL statements       */
Hive,WITHOUT_CLASSIFICATION,//  Step 2.4: Remove this MapJoin task 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.ICLIService#getPrimaryKeys(org.apache.hive.service.cli.SessionHandle)    */
Hive,WITHOUT_CLASSIFICATION,//  If the to string has more code points make sure to traverse it too 
Hive,WITHOUT_CLASSIFICATION,//  The log 
Hive,WITHOUT_CLASSIFICATION,//  App Base Dir / ${dagDir}   appBase/output/   appBase/output/attemptDir 
Hive,WITHOUT_CLASSIFICATION,//  The method is not exposed and we don't use it. 
Hive,WITHOUT_CLASSIFICATION,//  Name required for routing. Error out if it is not set. 
Hive,WITHOUT_CLASSIFICATION,//  This call is accessed from client (jdbc) side 
Hive,WITHOUT_CLASSIFICATION,//  Use HiveHookEventProto.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,//  Process grouping set for the reduce sink operator   For eg: consider: select key value count(1) from T group by key value with rollup.   Assuming map-side aggregation and no skew the plan would look like:     TableScan --> Select --> GroupBy1 --> ReduceSink --> GroupBy2 --> Select --> FileSink     This function is called for ReduceSink to add the additional grouping keys introduced by 
Hive,WITHOUT_CLASSIFICATION,/*  10 files x 100 size for 11 splits  */
Hive,WITHOUT_CLASSIFICATION,//                    99999999.99999999999999999999999999999949999 
Hive,WITHOUT_CLASSIFICATION,//  Coalesce is a special case because it can take variable number of arguments.   Nvl is a specialization of the Coalesce. 
Hive,WITHOUT_CLASSIFICATION,//  Use Case 1. 
Hive,WITHOUT_CLASSIFICATION,/*         try to render in place update progress bar only if the operations logs is update at least once        as this will hopefully allow printing the metadata information like query id application id        etc. have to remove these notifiers when the operation logs get merged into GetOperationStatus       */
Hive,WITHOUT_CLASSIFICATION,//  Convert the first param into a DateWritableV2 value 
Hive,WITHOUT_CLASSIFICATION,// tries to get X lock on T1 and gets Waiting state 
Hive,WITHOUT_CLASSIFICATION,// BaseSemanticAnalyzer sem = SemanticAnalyzerFactory.get(new QueryState(queryState.getConf()) input); 
Hive,WITHOUT_CLASSIFICATION,//  source table input format 
Hive,WITHOUT_CLASSIFICATION,//  Change the location and see the results 
Hive,WITHOUT_CLASSIFICATION,//  If the current child struct expression is a constant struct. 
Hive,WITHOUT_CLASSIFICATION,//  0 
Hive,WITHOUT_CLASSIFICATION,//  Try to create a table with all of the parameters set 
Hive,WITHOUT_CLASSIFICATION,//  If there's no base file do a major compaction 
Hive,WITHOUT_CLASSIFICATION,//  Now replace the old evaluators with our own 
Hive,WITHOUT_CLASSIFICATION,//  Recurse over the subqueries to fill the subquery part of the plan 
Hive,WITHOUT_CLASSIFICATION,// We don't want to push cross join 
Hive,WITHOUT_CLASSIFICATION,//  do nothing for null struct 
Hive,WITHOUT_CLASSIFICATION,//  mapOutputInfoMap is used to share the lookups with the caller 
Hive,WITHOUT_CLASSIFICATION,//  query 1 
Hive,WITHOUT_CLASSIFICATION,//  Attempt to create the table taking EXTERNAL into consideration 
Hive,WITHOUT_CLASSIFICATION,//  Found all possible rows which will not be filtered 
Hive,WITHOUT_CLASSIFICATION,//  first 3 stripes will satisfy the predicate and merged to single split last stripe will be a 
Hive,WITHOUT_CLASSIFICATION,//  finally throw an exception 
Hive,WITHOUT_CLASSIFICATION,//  Test partition listing with a partial spec - hr is specified but ds is not 
Hive,WITHOUT_CLASSIFICATION,//  of this operator. This is used for connecting them later. 
Hive,WITHOUT_CLASSIFICATION,//  This is the first call open the session 
Hive,WITHOUT_CLASSIFICATION,//  Set these two to invalid values so any attempt to use them 
Hive,WITHOUT_CLASSIFICATION,//  set fastScale to 0. 
Hive,WITHOUT_CLASSIFICATION,//  startIx is inclusive endIx is exclusive. 
Hive,WITHOUT_CLASSIFICATION,//        Not sure if these large cols could be in resultSchema. Ignore this for now 0_o 
Hive,WITHOUT_CLASSIFICATION,//  Now run a lower priority task. 
Hive,WITHOUT_CLASSIFICATION,//  Remote dirs 
Hive,WITHOUT_CLASSIFICATION,//  Keep backward compat in explain for single-file copy tasks. 
Hive,WITHOUT_CLASSIFICATION,// p=0 exists and is not empty  p=2 exists and is empty  p=3 doesn't exist 
Hive,WITHOUT_CLASSIFICATION,//  1 integer digit; 2 fraction digits.   Trailing zeroes are suppressed.  --------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  text -> byte[] -> value 
Hive,WITHOUT_CLASSIFICATION,//  query 2 
Hive,WITHOUT_CLASSIFICATION,//  RESOURCE_URIS 
Hive,WITHOUT_CLASSIFICATION,//  Sleep for longer than server's idletimeout and execute a query 
Hive,WITHOUT_CLASSIFICATION,//  can be stored in String Text or some other classes. 
Hive,WITHOUT_CLASSIFICATION,//  Can we add to current batch? 
Hive,WITHOUT_CLASSIFICATION,/*  do nothing  */
Hive,WITHOUT_CLASSIFICATION,//  Test that existing exclusive db with new shared_write coalesces to 
Hive,WITHOUT_CLASSIFICATION,//  long-running application. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#getWarnings()    */
Hive,WITHOUT_CLASSIFICATION,//  Request task1 
Hive,WITHOUT_CLASSIFICATION,//  The globalHook stuff. There's no proper way to insert this so we add it everywhere. 
Hive,WITHOUT_CLASSIFICATION,// create 2 rows in a file 000001_0 (and an empty 000000_0) 
Hive,WITHOUT_CLASSIFICATION,//  right now we assume that the group by is an ArrayList object. It may 
Hive,WITHOUT_CLASSIFICATION,//  since tasks themselves can be graphs we want to limit the number of created 
Hive,WITHOUT_CLASSIFICATION,//  The serialize routine uses this to build serializedKeyLengths. 
Hive,WITHOUT_CLASSIFICATION,//  Empties the projection columns. 
Hive,WITHOUT_CLASSIFICATION,//  0 or -1 implies fetch everything 
Hive,WITHOUT_CLASSIFICATION,//  partitions to be dropped in this batch 
Hive,WITHOUT_CLASSIFICATION,//  This is called only during move session handling removing session already checks this.   So this is not expected as remove failing will not even invoke this method 
Hive,WITHOUT_CLASSIFICATION,//  The collectable stats for the aggregator needs to be cleared.   For eg. if a file is being loaded the old number of rows are not valid 
Hive,WITHOUT_CLASSIFICATION,//  it's parent hierarchy. selfAndUpstreamComplete indicates how many of these have completed. 
Hive,WITHOUT_CLASSIFICATION,//  same above 
Hive,WITHOUT_CLASSIFICATION,//  REQ 
Hive,WITHOUT_CLASSIFICATION,//  Drop them from the proper catalog 
Hive,WITHOUT_CLASSIFICATION,//  more reliable then attempting to parse the error message from the SQLException. 
Hive,WITHOUT_CLASSIFICATION,//  0. Check if we can handle the SubQuery; 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:LlapOutputSocketInitMessage) 
Hive,WITHOUT_CLASSIFICATION,/*                * Single-Column String specific save key and lookup.                */
Hive,WITHOUT_CLASSIFICATION,//  Read cost 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:PurgeCacheRequestProto) 
Hive,WITHOUT_CLASSIFICATION,//  Cannot open the lock file for writing must be held by a live process 
Hive,WITHOUT_CLASSIFICATION,//  repl noop export on non-existant table has repl.noop does not error   import repl noop dump no error 
Hive,WITHOUT_CLASSIFICATION,//  call-1: open to read - split 1 => mock:/mocktable3/0_0 
Hive,WITHOUT_CLASSIFICATION,//  We rely on NDC information in the logs to map counters to attempt.   If that is not available appId should either be passed in or extracted from NDC. 
Hive,WITHOUT_CLASSIFICATION,//  Aggregation buffer methods. 
Hive,WITHOUT_CLASSIFICATION,//  For SMB the key column(s) in RS should be same as bucket column(s) and sort column(s)` 
Hive,WITHOUT_CLASSIFICATION,//  make sure delta_0000001_0000001_0000 appears before delta_0000002_0000002_0000 
Hive,WITHOUT_CLASSIFICATION,//  3 
Hive,WITHOUT_CLASSIFICATION,//  JAVA64_META + JAVA64_REF   JAVA64_ARRAY_META + JAVA64_REF 
Hive,WITHOUT_CLASSIFICATION,//  Replicate drop partition event and verify 
Hive,WITHOUT_CLASSIFICATION,//  test batchsize is not divisible by decaying factor 
Hive,WITHOUT_CLASSIFICATION,//  All new versions of Acid tables created after the introduction of Acid version/type system   can have TRANSACTIONAL_PROPERTIES property defined. This parameter can be used to change   the operational behavior of ACID. However if this parameter is not defined the new Acid   tables will still behave as the old ones. This is done so to preserve the behavior   in case of rolling downgrade. 
Hive,WITHOUT_CLASSIFICATION,//  These are the possible types referenced by 'type' below. 
Hive,WITHOUT_CLASSIFICATION,// since we take the RHS of set exactly as it was in Input we don't need to deal with quoting/escaping column/table names 
Hive,WITHOUT_CLASSIFICATION,//  create a union above all the branches   the schema of union looks like this 
Hive,WITHOUT_CLASSIFICATION,//  let hashtable Op be the child of this parent 
Hive,WITHOUT_CLASSIFICATION,//  Fill high long and middle from some of lower long. 
Hive,WITHOUT_CLASSIFICATION,//  Visible for testing 
Hive,WITHOUT_CLASSIFICATION,//  Project nulls for the extra fields. (Maybe a sub-class table has 
Hive,WITHOUT_CLASSIFICATION,//  Invariants. 
Hive,WITHOUT_CLASSIFICATION,//  cancel the deleg. tokens that were acquired for this job now that   we are done - we should cancel if the tokens were acquired by   HCatOutputFormat and not if they were supplied by Oozie.   In the latter case the HCAT_KEY_TOKEN_SIGNATURE property in   the conf will not be set 
Hive,WITHOUT_CLASSIFICATION,// multiple transactions only happen for streaming ingest which only allows inserts 
Hive,WITHOUT_CLASSIFICATION,//  No overlap between the two ranges 
Hive,WITHOUT_CLASSIFICATION,//  found a source which is not to be stored in memory 
Hive,WITHOUT_CLASSIFICATION,//  evaluate children 
Hive,WITHOUT_CLASSIFICATION,//  TopN query results as records (types defined by metastore) 
Hive,WITHOUT_CLASSIFICATION,//  Sequence is the following:   1) INSERT with no segments -> Original segment still present in the datasource   2) INSERT OVERWRITE with no segments -> Datasource is empty   3) INSERT OVERWRITE with no segments -> Datasource is empty   4) INSERT with no segments -> Datasource is empty   5) INSERT with one segment -> Datasource has one segment   6) INSERT OVERWRITE with one segment -> Datasource has one segment   7) INSERT with one segment -> Datasource has two segments   8) INSERT OVERWRITE with no segments -> Datasource is empty 
Hive,WITHOUT_CLASSIFICATION,//  Same depth using natural order 
Hive,WITHOUT_CLASSIFICATION,/*    * Context for using VectorDeserializeRow to deserialize each row from the Input File Format   * into the VectorizedRowBatch.    */
Hive,WITHOUT_CLASSIFICATION,//  a map that keeps track of work that need to be linked while 
Hive,WITHOUT_CLASSIFICATION,//  Use only 1 reducer if order by is present 
Hive,WITHOUT_CLASSIFICATION,//  1 0   1 1 
Hive,WITHOUT_CLASSIFICATION,//  I can't do this with @Before because I want to be able to control when the thread starts 
Hive,WITHOUT_CLASSIFICATION,/*  == long in Avro  */
Hive,WITHOUT_CLASSIFICATION,//  Try to expire the session if it's not in use; if in use bail. 
Hive,WITHOUT_CLASSIFICATION,//  INTERMEDIATE REDUCTION:   Case 1: NO column stats NO hash aggregation NO grouping sets — numRows   Case 2: NO column stats NO hash aggregation grouping sets — numRows * sizeOfGroupingSet   Case 3: column stats hash aggregation NO grouping sets — Min(numRows / 2 ndvProduct * parallelism)   Case 4: column stats hash aggregation grouping sets — Min((numRows * sizeOfGroupingSet) / 2 ndvProduct * parallelism * sizeOfGroupingSet)   Case 5: column stats NO hash aggregation NO grouping sets — numRows   Case 6: column stats NO hash aggregation grouping sets — numRows * sizeOfGroupingSet 
Hive,WITHOUT_CLASSIFICATION,//  LOG.debug("generateHashMultiSetResultSingleValue with big table..."); 
Hive,WITHOUT_CLASSIFICATION,// mapside 
Hive,WITHOUT_CLASSIFICATION,//  initialize map operator 
Hive,WITHOUT_CLASSIFICATION,//  put them in and also roll them up while we're at it 
Hive,WITHOUT_CLASSIFICATION,//  All the tasks should have deallocated their stuff. Make sure we can allocate everything. 
Hive,WITHOUT_CLASSIFICATION,//  Regular vertices 
Hive,WITHOUT_CLASSIFICATION,//  Depending on whether we are using beeline or sqlline the line endings have to be handled   differently. 
Hive,WITHOUT_CLASSIFICATION,//  Reset key and value columns; and batch.size 
Hive,WITHOUT_CLASSIFICATION,//  Extrapolation is needed for extraColumnNames. 
Hive,WITHOUT_CLASSIFICATION,// assume # can only be used at the beginning of line. 
Hive,WITHOUT_CLASSIFICATION,//  CORS check 
Hive,WITHOUT_CLASSIFICATION,//  set r.genericUDAFEvaluator 
Hive,WITHOUT_CLASSIFICATION,//  computes the sig of every object 
Hive,WITHOUT_CLASSIFICATION,//  we have just added a new node. Signal timeout monitor to reset timer 
Hive,WITHOUT_CLASSIFICATION,//  Configure header size 
Hive,WITHOUT_CLASSIFICATION,//  Field not included in query. 
Hive,WITHOUT_CLASSIFICATION,//  set up operator plan 
Hive,WITHOUT_CLASSIFICATION,//  left outer join produced a list with no values 
Hive,WITHOUT_CLASSIFICATION,//  The default encoding for this table when not otherwise specified 
Hive,WITHOUT_CLASSIFICATION,//  Recreate the database 
Hive,WITHOUT_CLASSIFICATION,//  ill-formed query like select * from t1 having c1 > 0; 
Hive,WITHOUT_CLASSIFICATION,/*  id <> 12 and       first_name in ('john' 'sue') and       id in (3450)  */
Hive,WITHOUT_CLASSIFICATION,//  Query does not contain CUBE ROLLUP or GROUPING SETS and thus   grouping should return 0 
Hive,WITHOUT_CLASSIFICATION,//  Kick out previous overflow batch results. 
Hive,WITHOUT_CLASSIFICATION,// output noNulls is set to false we need to reset the isNull array 
Hive,WITHOUT_CLASSIFICATION,//  Storage vars 
Hive,WITHOUT_CLASSIFICATION,//  Process per vertex counters that are available only via vertex Progress 
Hive,WITHOUT_CLASSIFICATION,//  This ArrayList holds the max/min N   This is the N 
Hive,WITHOUT_CLASSIFICATION,/*  canRetainByteRef  */
Hive,WITHOUT_CLASSIFICATION,//  Start with the following locks:   [path1 shared]   [path1 exclusive]   [path2 shared]   [path2 shared] 
Hive,WITHOUT_CLASSIFICATION,//  Select query results as records (types defined by metastore) 
Hive,WITHOUT_CLASSIFICATION,//  add the new aggregate column and recompute data size 
Hive,WITHOUT_CLASSIFICATION,//  alter the table 
Hive,WITHOUT_CLASSIFICATION,//  column level statistics are required only for the columns that are needed 
Hive,WITHOUT_CLASSIFICATION,//  Read the warehouse dir which can be changed so multiple MetaStore tests could be run on 
Hive,WITHOUT_CLASSIFICATION,//  At this point we are going to make a copy if needed to avoid array boundaries. 
Hive,WITHOUT_CLASSIFICATION,/*    * how is this different from the OutputShape set on the TableDef.   * This is the OI of the object coming out of the PTF.   * It is put in an output Partition whose Serde is usually LazyBinarySerde.   * So the next PTF (or Operator) in the chain gets a LazyBinaryStruct.    */
Hive,WITHOUT_CLASSIFICATION,//  Only primitive fields supports for now. 
Hive,WITHOUT_CLASSIFICATION,//  Case 2 - Max in list members: 10; Max query string length: 1KB 
Hive,WITHOUT_CLASSIFICATION,//  Linux:yes Windows:no 
Hive,WITHOUT_CLASSIFICATION,//  of the user assumptions. 
Hive,WITHOUT_CLASSIFICATION,//  Avoid a copy when oldTmpJars is null or empty 
Hive,WITHOUT_CLASSIFICATION,//  semijoin case 
Hive,WITHOUT_CLASSIFICATION,//  current random sampling implementation in InputSampler always returns   value of index 3 5 8 which can be same with previous partition key.   That induces "Split points are out of order" exception in TotalOrderPartitioner causing HIVE-7699 
Hive,WITHOUT_CLASSIFICATION,//  vertex 
Hive,WITHOUT_CLASSIFICATION,//  Now clone the tree above selOp 
Hive,WITHOUT_CLASSIFICATION,//  To be populated for SMB joins only for all the small tables 
Hive,WITHOUT_CLASSIFICATION,//  non-transitive 
Hive,WITHOUT_CLASSIFICATION,//  Reset the bytebuffer 
Hive,WITHOUT_CLASSIFICATION,//  Set the specific parameters if needed 
Hive,WITHOUT_CLASSIFICATION,//  run the map join task set task tag 
Hive,WITHOUT_CLASSIFICATION,//  Instantiate the chosen transaction manager 
Hive,WITHOUT_CLASSIFICATION,//  Run count times and get average 
Hive,WITHOUT_CLASSIFICATION,//  2. If we cannot we swap the inputs so we can try 
Hive,WITHOUT_CLASSIFICATION,//  IDE support for running tez jobs 
Hive,WITHOUT_CLASSIFICATION,//  Need to set the client's KeyProvider to the NN's for JKS   else the updates do not get flushed properly 
Hive,WITHOUT_CLASSIFICATION,//  name of child class 
Hive,WITHOUT_CLASSIFICATION,//  view column access info is carried by this.getColumnAccessInfo(). 
Hive,WITHOUT_CLASSIFICATION,//  (i.e. too large to have an effect). 
Hive,WITHOUT_CLASSIFICATION,//  The table containing the partitions is not yet loaded in cache 
Hive,WITHOUT_CLASSIFICATION,//  Use reflection to set LockManager since creating the object using the   relection in DummyTxnManager won't take Mocked object 
Hive,WITHOUT_CLASSIFICATION,//  A mapping from an operator to the columns by which it's output is bucketed 
Hive,WITHOUT_CLASSIFICATION,//  generating join output results. 
Hive,WITHOUT_CLASSIFICATION,// the token file location as initial hiveconf arg 
Hive,WITHOUT_CLASSIFICATION,//  1.1 First Add original GB Keys 
Hive,WITHOUT_CLASSIFICATION,//  First try without qualifiers - would resolve builtin/temp functions.   Otherwise try qualifying with current db name. 
Hive,WITHOUT_CLASSIFICATION,//  ReduceSink also needs MapJoin as child 
Hive,WITHOUT_CLASSIFICATION,//  SD 
Hive,WITHOUT_CLASSIFICATION,//  D4. Multiply and subtract: (some digits of) R -= D * QH 
Hive,WITHOUT_CLASSIFICATION,//  This resets vectors in both batches. 
Hive,WITHOUT_CLASSIFICATION,//  The storage root 
Hive,WITHOUT_CLASSIFICATION,/*    * - If the SubQuery has no where clause there is nothing to rewrite.   * - Decompose SubQuery where clause into list of Top level conjuncts.   * - For each conjunct   *   - Break down the conjunct into (LeftExpr LeftExprType RightExpr   *     RightExprType)   *   - If the top level operator is an Equality Operator we will break   *     it down into left and right; in all other case there is only a   *     lhs.   *   - The ExprType is based on whether the Expr. refers to the Parent   *     Query table sources refers to the SubQuery sources or both.   *   - We assume an unqualified Column refers to a SubQuery table source.   *     This is because we require Parent Column references to be qualified   *     within the SubQuery.   *   - If the lhs or rhs expr refers to both Parent and SubQuery sources   *     we flag this as Unsupported.   *   - If the conjunct as a whole only refers to the Parent Query sources   *     we flag this as an Error.   *   - A conjunct is Correlated if the lhs refers to SubQuery sources and rhs   *     refers to Parent Query sources or the reverse.   *   - Say the lhs refers to SubQuery and rhs refers to Parent Query sources; the   *     other case is handled analogously.   *     - remove this conjunct from the SubQuery where clause.   *     - for the SubQuery expression(lhs) construct a new alias   *     - in the correlated predicate replace the SubQuery   *       expression(lhs) with the alias AST.   *     - add this altered predicate to the Join predicate tracked by the   *       QBSubQuery object.   *     - add the alias AST to a list of subQueryJoinAliasExprs. This   *       list is used in the case of Outer Joins to add null check   *       predicates to the Outer Query's where clause.   *     - Add the SubQuery expression with the alias as a SelectItem to   *       the SubQuery's SelectList.   *     - In case this SubQuery contains aggregation expressions add this SubQuery   *       expression to its GroupBy; add it to the front of the GroupBy.   *   - If predicate is not correlated let it remain in the SubQuery   *     where clause.   * Additional things for Having clause:   * - A correlation predicate may refer to an aggregation expression.   * - This introduces 2 twists to the rewrite:   *   a. When analyzing equality predicates we need to analyze each side   *      to see if it is an aggregation expression from the Outer Query.   *      So for e.g. this is a valid correlation predicate:   *         R2.x = min(R1.y)   *      Where R1 is an outer table reference and R2 is a SubQuery table reference.   *   b. When hoisting the correlation predicate to a join predicate we need to   *      rewrite it to be in the form the Join code allows: so the predict needs   *      to contain a qualified column references.   *      We handle this by generating a new name for the aggregation expression   *      like R1._gby_sq_col_1 and adding this mapping to the Outer Query's   *      Row Resolver. Then we construct a joining predicate using this new   *      name; so in our e.g. the condition would be: R2.x = R1._gby_sq_col_1    */
Hive,WITHOUT_CLASSIFICATION,//  The list of table names could contain duplicates. RawStore.getTableObjectsByName()   only guarantees returning no duplicate table objects in one batch. If we need 
Hive,WITHOUT_CLASSIFICATION,// check that compacted base dir has a version file with expected value 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#prepareCall(java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  performed as a smb join based on all the tables/partitions being joined. 
Hive,WITHOUT_CLASSIFICATION,//  this is the last key we need to process 
Hive,WITHOUT_CLASSIFICATION,//  Initialize set of unprocessed small tables 
Hive,WITHOUT_CLASSIFICATION,//  This code has been only added for testing 
Hive,WITHOUT_CLASSIFICATION,// ---------------------------------------------------------------------------   Single-Column Long specific members.   
Hive,WITHOUT_CLASSIFICATION,// create input ByteArrayRef 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.CLIServiceClient#closeOperation(org.apache.hive.service.cli.OperationHandle)    */
Hive,WITHOUT_CLASSIFICATION,//  + 
Hive,WITHOUT_CLASSIFICATION,//  we need to convert these to the generated column names we can see in the Join operator 
Hive,WITHOUT_CLASSIFICATION,/*  Spot check correctness of decimal scalar subtract decimal column. The case for   * addition checks all the cases for the template so don't do that redundantly here.    */
Hive,WITHOUT_CLASSIFICATION,/*    * Deliver a vector batch to the operator tree.   *   * The Vectorized Input File Format reader has already set the partition column   * values reset and filled in the batch etc.   *   * We pass the VectorizedRowBatch through here.   *   * @return Return true if the operator tree is not done yet.    */
Hive,WITHOUT_CLASSIFICATION,/*  One of the digits was the point.  */
Hive,WITHOUT_CLASSIFICATION,//  dummy private constructor since this class is a collection of static utility methods. 
Hive,WITHOUT_CLASSIFICATION,//  remember which parent belongs to which tag 
Hive,WITHOUT_CLASSIFICATION,//  introduce derived table above one child if this is self-join   since user provided aliases are lost at this point. 
Hive,WITHOUT_CLASSIFICATION,//  Get column names and types 
Hive,WITHOUT_CLASSIFICATION,// -----------------------------------------------------------------------------------------------   Math methods.  ----------------------------------------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  cast (40 + 50 as string) 
Hive,WITHOUT_CLASSIFICATION,//  Whether the files output by this FileSink can be merged e.g. if they are to be put into a 
Hive,WITHOUT_CLASSIFICATION,//  reset the data 
Hive,WITHOUT_CLASSIFICATION,//  We create converters beforehand so that the converters can reuse the   same object for returning conversion results. 
Hive,WITHOUT_CLASSIFICATION,//  First branch should have the query (with write ID filter conditions) 
Hive,WITHOUT_CLASSIFICATION,//  Test a set of random divisions at high precision. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#getMetaData()    */
Hive,WITHOUT_CLASSIFICATION,//  use default values from fs.default.name 
Hive,WITHOUT_CLASSIFICATION,//  also check a config that has default in hiveconf 
Hive,WITHOUT_CLASSIFICATION,//  initialize input 
Hive,WITHOUT_CLASSIFICATION,//  Pass lineageState when a driver instantiates another Driver to run   or compile another query 
Hive,WITHOUT_CLASSIFICATION,//  select with grant for exporting contents 
Hive,WITHOUT_CLASSIFICATION,//  Neither select nor compaction (which is a select) wil work after this. 
Hive,WITHOUT_CLASSIFICATION,//  statistics object that is combination of statistics from all 
Hive,WITHOUT_CLASSIFICATION,//  The wrapper for byte array 
Hive,WITHOUT_CLASSIFICATION,//  Overlay the ConfVars. Note that this ignores ConfVars with null values 
Hive,WITHOUT_CLASSIFICATION,//  code below does not deal with the Connection Server.object. 
Hive,WITHOUT_CLASSIFICATION,//  if there is a transaction then this lock will be released on commit/abort/rollback instead. 
Hive,WITHOUT_CLASSIFICATION,//  ignore this exception actually this exception won't be thrown from getPartitionColumnStatistics 
Hive,WITHOUT_CLASSIFICATION,//  so that beeline won't kill the JVM 
Hive,WITHOUT_CLASSIFICATION,//  finally remove the role 
Hive,WITHOUT_CLASSIFICATION,//   write the given version to metastore 
Hive,WITHOUT_CLASSIFICATION,//  Test in http mode with ssl properties specified in url 
Hive,WITHOUT_CLASSIFICATION,//  Test getColumns() 
Hive,WITHOUT_CLASSIFICATION,//  this is the key less than the lowest key we need to process 
Hive,WITHOUT_CLASSIFICATION,/*    * MAP.    */
Hive,WITHOUT_CLASSIFICATION,//  predicate expression: userid <= 100 and subtype <= 1000.0 
Hive,WITHOUT_CLASSIFICATION,//  literals. 
Hive,WITHOUT_CLASSIFICATION,//  'transactional_properties'='default' 
Hive,WITHOUT_CLASSIFICATION,//  If it's multi-expr filter (e.g. a='5' b='2012-01-02') AND with previous exprs. 
Hive,WITHOUT_CLASSIFICATION,//  If this is the first expression 
Hive,WITHOUT_CLASSIFICATION,// Generate vectorized expression 
Hive,WITHOUT_CLASSIFICATION,//  Force the cache clear so we know its empty 
Hive,WITHOUT_CLASSIFICATION,//  If udf is requiring additional jars we can't determine the result in 
Hive,WITHOUT_CLASSIFICATION,/*       Since there can be multiple rounds of this run all of which will be tied to the same      query id -- generated in compile phase  adding a additional UUID to the end to print each run      in separate files.        */
Hive,WITHOUT_CLASSIFICATION,//  Extract input refs. They will serve as input for the function invocation 
Hive,WITHOUT_CLASSIFICATION,/*        * Here we can be in one of 4 states.       *       * 1. If map join work is null implies that we have not yet traversed the big table side. We       * just need to see if we can find a reduce sink operator in the big table side. This would       * imply a reduce side operation.       *       * 2. If we don't find a reducesink in 1 it has to be the case that it is a map side operation.       *       * 3. If we have already created a work item for the big table side we need to see if we can       * find a table scan operator in the big table side. This would imply a map side operation.       *       * 4. If we don't find a table scan operator it has to be a reduce side operation.        */
Hive,WITHOUT_CLASSIFICATION,//  max. This table is either the big table or we cannot convert. 
Hive,WITHOUT_CLASSIFICATION,//  Create the LazyStruct from the LazyStruct...Inspector 
Hive,WITHOUT_CLASSIFICATION,//  The layout for ACID files is table|partname/base|delta|delete_delta/bucket   We will always only be writing delta files ( except IOW which writes base_X/ ).   In the buckets created by FileSinkOperator   it will look like original_bucket/delta|delete_delta/bucket   (e.g. .../-ext-10004/000000_0/delta_0000014_0000014_0000/bucket_00000).  So we need to   move that into the above structure. For the first mover there will be no delta directory   so we can move the whole directory.   For everyone else we will need to just move the buckets under the existing delta   directory. 
Hive,WITHOUT_CLASSIFICATION,/*    * For T1 join T2 on T1.x = T2.y if we identify 'y' s a key of T2 then we can   * infer the join cardinality as: rowCount(T1) * selectivity(T2) i.e this is   * like a SemiJoin where the T1(Fact side/FK side) is filtered by a factor   * based on the Selectivity of the PK/Dim table side.   *   * 1. If both T1.x and T2.y are keys then use the larger one as the PK side.   * 2. In case of outer Joins: a) The FK side should be the Null Preserving   * side. It doesn't make sense to apply this heuristic in case of Dim loj Fact   * or Fact roj Dim b) The selectivity factor applied on the Fact Table should   * be 1.    */
Hive,WITHOUT_CLASSIFICATION,//  Find the next chunk size 
Hive,WITHOUT_CLASSIFICATION,/*  * The data written and read withing the same M/R job thus should never be written by one  * version of Hive and read by another. * @see org.apache.hive.hcatalog.data.ReaderWriter  */
Hive,WITHOUT_CLASSIFICATION,//  unable to parse the use command 
Hive,WITHOUT_CLASSIFICATION,//  ------r-- 
Hive,WITHOUT_CLASSIFICATION,//  If the table is partitioned we have to put the partition() clause in 
Hive,WITHOUT_CLASSIFICATION,// for Update/Delete we always write exactly (at most actually) the partitions we read 
Hive,WITHOUT_CLASSIFICATION,//  The AM can be used for multiple queries. This is an indication that a single query is complete.   We don't have a good mechanism to know when an app ends. Removing this right now ensures 
Hive,WITHOUT_CLASSIFICATION,//  Error already occurred but we still want to get the   error code of the child process if possible. 
Hive,WITHOUT_CLASSIFICATION,//  0-based index of which row we are on. 
Hive,WITHOUT_CLASSIFICATION,//  In this particular SparkSessionManager implementation we don't recycle   returned sessions. References to session are still valid. 
Hive,WITHOUT_CLASSIFICATION,//  Make fully qualified path for further use. 
Hive,WITHOUT_CLASSIFICATION,//  3. Deduce Resultset Schema 
Hive,WITHOUT_CLASSIFICATION,//  We have valid pruning expressions only retrieve qualifying partitions 
Hive,WITHOUT_CLASSIFICATION,//  Take the pattern and split it on the | to get all the composing   patterns 
Hive,WITHOUT_CLASSIFICATION,//  just an individual column 
Hive,WITHOUT_CLASSIFICATION,// there is a change here - prev version had 'transadtional' one beofre' acid' 
Hive,WITHOUT_CLASSIFICATION,//  get the last operator for processing big tables 
Hive,WITHOUT_CLASSIFICATION,//  Do the authorization 
Hive,WITHOUT_CLASSIFICATION,//  If based on the new key count keyCount is smaller than a threshold   then just load the entire restored hashmap into memory. 
Hive,WITHOUT_CLASSIFICATION,//  This call checks under lock if we can actually preempt the task.   It is possible to have a race where the update (that's also under lock) makes the   task finishable or guaranteed between the remove and kill but it's the same timing 
Hive,WITHOUT_CLASSIFICATION,//  When true indicates that this object is being read as part of an update or delete.  This is   important because in that case we shouldn't acquire a lock for it or authorize the read. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure there's a default database associated with each catalog 
Hive,WITHOUT_CLASSIFICATION,//  1 Add order by token 
Hive,WITHOUT_CLASSIFICATION,//  Now prepare partnames with 10 partitions: [tab1part11...tab1part20] but with no overlap 
Hive,WITHOUT_CLASSIFICATION,//  Combined all good.   Don't combine with that but may combine with others.   Don't combine with with that and make that a base for 0new combines. 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) HeaderList  */
Hive,WITHOUT_CLASSIFICATION,//  The partition that has to be exchanged 
Hive,WITHOUT_CLASSIFICATION,//  it represents the column name corresponding to distinct aggr if any 
Hive,WITHOUT_CLASSIFICATION,//  Multi parents cant handle that.   Right now we do not remove projection on top of   LateralViewForward operators. 
Hive,WITHOUT_CLASSIFICATION,//  LOG.debug("generateHashMultiSetResultMultiValue allMatchesIndex " + allMatchesIndex + " duplicateCount " + duplicateCount + " count " + count); 
Hive,WITHOUT_CLASSIFICATION,//  Trimming is again necessary because rounding may introduce new trailing 0's. 
Hive,WITHOUT_CLASSIFICATION,//  test for timestamp type 
Hive,WITHOUT_CLASSIFICATION,//  Populate byte[] from Timestamp 
Hive,WITHOUT_CLASSIFICATION,//  Get the last repl ID corresponding to all insert/alter/create events except DROP. 
Hive,WITHOUT_CLASSIFICATION,// "may be used (ACID table)"; 
Hive,WITHOUT_CLASSIFICATION,// lastAccessTime > 90 
Hive,WITHOUT_CLASSIFICATION,//  Test for both colNames and partNames being empty: 
Hive,WITHOUT_CLASSIFICATION,//  if client proxies connection use forwarded ip-addresses instead of just the gateway 
Hive,WITHOUT_CLASSIFICATION,//  For now we just use this to hold the object inspector.  There are no writeValue   setValue etc methods yet... 
Hive,WITHOUT_CLASSIFICATION,//  log which resources we're adding (apart from the hive exec) 
Hive,WITHOUT_CLASSIFICATION,//  Javadoc for Statement interface states that if the value is zero   then "fetch size" hint is ignored.   In this case it means reverting it to the default value. 
Hive,WITHOUT_CLASSIFICATION,//  3. Run exhaustive PPD add not null filters transitive inference 
Hive,WITHOUT_CLASSIFICATION,//    Properties   
Hive,WITHOUT_CLASSIFICATION,//  Since the user didn't supply a customized type-checking context   use default settings. 
Hive,WITHOUT_CLASSIFICATION,//  mingle existing tblproperties with those specified on the ALTER TABLE command 
Hive,WITHOUT_CLASSIFICATION,//  left and right repeat 
Hive,WITHOUT_CLASSIFICATION,//  Validation on the bitset size/3 hash functions. 
Hive,WITHOUT_CLASSIFICATION,//  One less integer digit... 
Hive,WITHOUT_CLASSIFICATION,//  if HIVE_STATS_COLLECT_SCANCOLS is enabled check. 
Hive,WITHOUT_CLASSIFICATION,//  Should only down-cast and elimination precision if within valid range. 
Hive,WITHOUT_CLASSIFICATION,//  Ignore the char after escape_char 
Hive,WITHOUT_CLASSIFICATION,//  positive test 
Hive,WITHOUT_CLASSIFICATION,/*  Get the big table row bytes container for native vector map join  */
Hive,WITHOUT_CLASSIFICATION,//  need to maintain the unique ID so that target map works can   read the output 
Hive,WITHOUT_CLASSIFICATION,//  the function should support both short date and full timestamp format 
Hive,WITHOUT_CLASSIFICATION,//  TableDesc needed for dynamic partitioned hash join 
Hive,WITHOUT_CLASSIFICATION,//  Send out the preempted request outside of the lock. 
Hive,WITHOUT_CLASSIFICATION,//  Only small table values appear in join output result. 
Hive,WITHOUT_CLASSIFICATION,//  Modulo operator with overflow/zero-divide check. 
Hive,WITHOUT_CLASSIFICATION,// now both txns concurrently updated TAB2 but different partitions. 
Hive,WITHOUT_CLASSIFICATION,//  Scale up with 5. This is done via #multiplyDestructive(int). 
Hive,WITHOUT_CLASSIFICATION,/*  Use list bucketing prunner's path.  */
Hive,WITHOUT_CLASSIFICATION,// 5)  test extra field names 
Hive,WITHOUT_CLASSIFICATION,//  because at that point we need access to the objects. 
Hive,WITHOUT_CLASSIFICATION,//                              1         2         3 
Hive,WITHOUT_CLASSIFICATION,//  skip the row. 
Hive,WITHOUT_CLASSIFICATION,//  TODO: for now we get the secure username out of UGI... after signing we can take it 
Hive,WITHOUT_CLASSIFICATION,//  Write the necessary config info to hadoop-site.xml 
Hive,WITHOUT_CLASSIFICATION,//  For UDTF's skip the function name to get the expressions 
Hive,WITHOUT_CLASSIFICATION,//  E.SW: Lock we are examining is shared write 
Hive,WITHOUT_CLASSIFICATION,/*  this may happen in one of the following case:      TS[0] FIL[26] SEL[2] DUMMY_STORE[30] MERGEJOIN[29]]                                              /                                    TS[3] FIL[27] SEL[5] ---------------       */
Hive,WITHOUT_CLASSIFICATION,//  DEST_DB 
Hive,WITHOUT_CLASSIFICATION,//  Make it possible for tests to check that the right type of PartitionExpressionProxy was 
Hive,WITHOUT_CLASSIFICATION,//  If a join operator contains a big subtree there is a chance that its 
Hive,WITHOUT_CLASSIFICATION,/*    * A PTF Function must provide the 'external' names of the columns in its Output.   *    */
Hive,WITHOUT_CLASSIFICATION,//  Add this parent to the children 
Hive,WITHOUT_CLASSIFICATION,//  record reader 
Hive,WITHOUT_CLASSIFICATION,//  Nope so look to see if Hive's home dir has been explicitly set 
Hive,WITHOUT_CLASSIFICATION,/*  Release all transient locks by simply closing the client  */
Hive,WITHOUT_CLASSIFICATION,//  At this point we know that the extracted files are in the intermediate   extracted dir or in the the original directory. 
Hive,WITHOUT_CLASSIFICATION,// you are an admin! You have all privileges no missing privileges 
Hive,WITHOUT_CLASSIFICATION,//  initialize unionExpr for reduce-side   reduce KEY has union field as the last field if there are distinct 
Hive,WITHOUT_CLASSIFICATION,//  now really scan... 
Hive,WITHOUT_CLASSIFICATION,//  The calculation is strongly dependent on the assumption that all splits   came from the same file 
Hive,WITHOUT_CLASSIFICATION,//  If the delimiter is seen and the line isn't inside a quoted string then treat   line[lastDelimiterIndex] to line[index] as a single command 
Hive,WITHOUT_CLASSIFICATION,/*  All the code paths below propagate nulls even arg3 has no     * nulls. This is to reduce the number of code paths and shorten the     * code at the expense of maybe doing unnecessary work if neither input     * has nulls. This could be improved in the future by expanding the number     * of code paths.      */
Hive,WITHOUT_CLASSIFICATION,//  support the old syntax "hivemetastore [port]" but complain 
Hive,WITHOUT_CLASSIFICATION,//  Wrap the static AccumuloInputFormat methods with methods that we can   verify were correctly called via Mockito 
Hive,WITHOUT_CLASSIFICATION,//  shared plan utils for spark 
Hive,WITHOUT_CLASSIFICATION,//  we need '=' 
Hive,WITHOUT_CLASSIFICATION,//  use this function to make the union "flat" for both execution and explain 
Hive,WITHOUT_CLASSIFICATION,//  add_partitions(5) : ok 
Hive,WITHOUT_CLASSIFICATION,//  GUID 
Hive,WITHOUT_CLASSIFICATION,//  no match for workerIdentity 
Hive,WITHOUT_CLASSIFICATION,//  TableFunctionResolver tResolver = FunctionRegistry.getTableFunctionResolver(def.getName()); 
Hive,WITHOUT_CLASSIFICATION,//  checks if default hs2 connection configuration file is present   and uses it to connect if found   no-op if the file is not present 
Hive,WITHOUT_CLASSIFICATION,//  The implementation may or may not set output it isRepeting. 
Hive,WITHOUT_CLASSIFICATION,//  Can ignore - the check failed. 
Hive,WITHOUT_CLASSIFICATION,//  availableSlots * waves => desired slots to fill   sizePerBucket/totalSize => weight for particular bucket. weights add   up to 1. 
Hive,WITHOUT_CLASSIFICATION,//  Implementation of row iterator 
Hive,WITHOUT_CLASSIFICATION,//  subqueryToRelNode might be null if subquery expression anywhere other than    as expected in filter (where/having). We should throw an appropriate error   message 
Hive,WITHOUT_CLASSIFICATION,// can happen in a race condition where another process adds a zLock under this parent  just before it is about to be deleted. It should not be a problem since this parent  can eventually be deleted by the process which hold its last child zLock 
Hive,WITHOUT_CLASSIFICATION,//  Given a byte array consisting of a serialized BloomFilter gives the offset (from 0)   for the start of the serialized long values that make up the bitset. 
Hive,WITHOUT_CLASSIFICATION,// be called many times. 
Hive,WITHOUT_CLASSIFICATION,//  SQL_STATE 
Hive,WITHOUT_CLASSIFICATION,/*    * Setup the context for reading from the next partition file.    */
Hive,WITHOUT_CLASSIFICATION,//  Even if the state has changed don't log it twice. 
Hive,WITHOUT_CLASSIFICATION,/* now process the delta files.  For normal read these should only be delete deltas.  For    * Compaction these may be any delta_x_y/.  The files inside any delta_x_y/ may be in Acid    * format (i.e. with Acid metadata columns) or 'original'. */
Hive,WITHOUT_CLASSIFICATION,//  testcase.testWithColumnNumber(count 50 checkCorrect codec);   testcase.testWithColumnNumber(count 80 checkCorrect codec); 
Hive,WITHOUT_CLASSIFICATION,// Else recurse up the parents. 
Hive,WITHOUT_CLASSIFICATION,//  Skip compaction if there's no delta files AND there's no original files 
Hive,WITHOUT_CLASSIFICATION,//  real object 
Hive,WITHOUT_CLASSIFICATION,// not relevant for LOAD 
Hive,WITHOUT_CLASSIFICATION,// for RU this may be null so we should default it to 'u' which is most restrictive 
Hive,WITHOUT_CLASSIFICATION,//  been processed. 
Hive,WITHOUT_CLASSIFICATION,//  Consider the query: select ab count(1) from T group by ab with cube;   where it is being executed in a single map-reduce job   The plan is TableScan -> GroupBy1 -> ReduceSink -> GroupBy2 -> FileSink   GroupBy1 already added the grouping id as part of the row   This function is called for GroupBy2 to add grouping id as part of the groupby keys 
Hive,WITHOUT_CLASSIFICATION,//  no-arg ctor required for Kyro 
Hive,WITHOUT_CLASSIFICATION,//  TODO: we could also vectorize some formats based on hive.llap.io.encode.formats if LLAP IO         is enabled and we are going to run in LLAP. However we don't know if we end up in         LLAP or not at this stage so don't do this now. We may need to add a 'force' option. 
Hive,WITHOUT_CLASSIFICATION,//  Alter the table/partition stats and also notify truncate table event 
Hive,WITHOUT_CLASSIFICATION,//  byte. 
Hive,WITHOUT_CLASSIFICATION,//  It is assumed throughout the code that a reducer has a single child add a 
Hive,WITHOUT_CLASSIFICATION,//  reference HDFS based resource directly to use distribute cache efficiently. 
Hive,WITHOUT_CLASSIFICATION,//  Druid's time column is always not null. 
Hive,WITHOUT_CLASSIFICATION,//  Find the last stripe. 
Hive,WITHOUT_CLASSIFICATION,//  This means that we do not need a value generator. 
Hive,WITHOUT_CLASSIFICATION,//  hadoop might return null if it cannot locate the job.   we may still be able to retrieve the job status - so ignore 
Hive,WITHOUT_CLASSIFICATION,// For runtime query may have finished. 
Hive,WITHOUT_CLASSIFICATION,//  1 WriteEntity: default@acidtblpart@p=p2 Type=PARTITION WriteType=INSERT isDP=false 
Hive,WITHOUT_CLASSIFICATION,//  Determine maximum of all non-null long column values; maintain isGroupResultNull. 
Hive,WITHOUT_CLASSIFICATION,//  tests expect configuration changes applied directly to metastore 
Hive,WITHOUT_CLASSIFICATION,//  This piece of code runs in master node and gets necessary context. 
Hive,WITHOUT_CLASSIFICATION,//  Release the background thread. 
Hive,WITHOUT_CLASSIFICATION,//  We're dealing with input that is an array of strings 
Hive,WITHOUT_CLASSIFICATION,//  avoid allocation/copy of nulls because it potentially expensive.   branch instead. 
Hive,WITHOUT_CLASSIFICATION,//  All of the versions should be place in this list. 
Hive,WITHOUT_CLASSIFICATION,//  Drop a table/partition; corresponding records in TXN_COMPONENTS and COMPLETED_TXN_COMPONENTS should disappear 
Hive,WITHOUT_CLASSIFICATION,/*      * For multiplicands with scale 0 trim trailing zeroes.      */
Hive,WITHOUT_CLASSIFICATION,//  constant projection 
Hive,WITHOUT_CLASSIFICATION,//  The modification cannot affect an active plan. 
Hive,WITHOUT_CLASSIFICATION,//  For each of the GB op in the logical GB this should be called seperately; 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:SubmitWorkResponseProto) 
Hive,WITHOUT_CLASSIFICATION,//  1.b. Generate reduce sink and project operator 
Hive,WITHOUT_CLASSIFICATION,//  Both are partitioned tables. 
Hive,WITHOUT_CLASSIFICATION,//  Bucketing and sorting keys should exactly match 
Hive,WITHOUT_CLASSIFICATION,// 2 distinct partitions modified 
Hive,WITHOUT_CLASSIFICATION,//  We could derive the expected number of AMs to pass in.   Note: we pass a null token here; the tokens to talk to plugin endpoints will only be         known once the AMs register and they are different for every AM (unlike LLAP token). 
Hive,WITHOUT_CLASSIFICATION,//  Start a third batch abort everything don't properly close it 
Hive,WITHOUT_CLASSIFICATION,// Store credentials in a private hash map and not the udf context to 
Hive,WITHOUT_CLASSIFICATION,//  Overlay the SASL transport on top of the base socket transport (SSL or non-SSL) 
Hive,WITHOUT_CLASSIFICATION,/*  100 files x 1000 size for 10 splits  */
Hive,WITHOUT_CLASSIFICATION,//  filter disabled injection enabled exception not expected 
Hive,WITHOUT_CLASSIFICATION,//  Only used for semijoin with residual predicates 
Hive,WITHOUT_CLASSIFICATION,//  And UDF (rowId >= 'h' and (rowId <= 'd' or rowId >= 'q')) 
Hive,WITHOUT_CLASSIFICATION,//  All Sources are initialized up front. Events from different sources will end up getting added to the same list.   Pruning is disabled if either source sends in an event which causes pruning to be skipped 
Hive,WITHOUT_CLASSIFICATION,//  Rest of cases 
Hive,WITHOUT_CLASSIFICATION,//  get the OperationLog object from the operation 
Hive,WITHOUT_CLASSIFICATION,//  Do first comparison as unsigned. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#rollback()    */
Hive,WITHOUT_CLASSIFICATION,//  test that the all columns will be read by default 
Hive,WITHOUT_CLASSIFICATION,//  optional int64 first_attempt_start_time = 5; 
Hive,WITHOUT_CLASSIFICATION,/* 32M */
Hive,WITHOUT_CLASSIFICATION,//  test that setting read column ids set read all columns to false 
Hive,WITHOUT_CLASSIFICATION,/*      * process Wdw functions      */
Hive,WITHOUT_CLASSIFICATION,//  1.1 Add Column info for non partion cols (Object Inspector fields) 
Hive,WITHOUT_CLASSIFICATION,//  Optimizing for readField? 
Hive,WITHOUT_CLASSIFICATION,//  Create the event and send it tez. Tez will route it to appropriate processor 
Hive,WITHOUT_CLASSIFICATION,//  1 (test #readFully(3)): 
Hive,WITHOUT_CLASSIFICATION,//  Add maxLength parameter to UDFs that have CHAR or VARCHAR output. 
Hive,WITHOUT_CLASSIFICATION,//  change to TextInputFormat 
Hive,WITHOUT_CLASSIFICATION,//  Is the existing entry and newer entry are subset of one another ? 
Hive,WITHOUT_CLASSIFICATION,//  Projection mode is not yet supported for [NOT] BETWEEN. Return null so Vectorizer   knows to revert to row-at-a-time execution. 
Hive,WITHOUT_CLASSIFICATION,//  We trim the trailing zero fraction digits so we don't cause unnecessary precision   overflow later. 
Hive,WITHOUT_CLASSIFICATION,//  function class will not cause Exception 
Hive,WITHOUT_CLASSIFICATION,//  a vectorized row batch is being created. 
Hive,WITHOUT_CLASSIFICATION,//  1 anonymous element "array_element" 
Hive,WITHOUT_CLASSIFICATION,//  The position of this table 
Hive,WITHOUT_CLASSIFICATION,//  Verify scratch dir paths and permission 
Hive,WITHOUT_CLASSIFICATION,//  Uses a pattern 
Hive,WITHOUT_CLASSIFICATION,//  properties for remote driver RPC and yarn properties for Spark on YARN mode. 
Hive,WITHOUT_CLASSIFICATION,//  Convert to a MapReduce job id 
Hive,WITHOUT_CLASSIFICATION,//  The cached buffer is in the middle of the requested range.   The remaining tail of the latter may still be available further. 
Hive,WITHOUT_CLASSIFICATION,//  All good 
Hive,WITHOUT_CLASSIFICATION,//  leave work's output may be read in further SparkWork/FetchWork we should not combine   leave works without notifying further SparkWork/FetchWork. 
Hive,WITHOUT_CLASSIFICATION,//  filter enabled injection disabled exception expected 
Hive,WITHOUT_CLASSIFICATION,//  Not supported for MM tables for now. 
Hive,WITHOUT_CLASSIFICATION,//  scanning the filesystem to get file lengths. 
Hive,WITHOUT_CLASSIFICATION,//  sort-based aggregations 
Hive,WITHOUT_CLASSIFICATION,//  Our hash tables are immutable.  We can safely do by reference STRING CHAR/VARCHAR etc. 
Hive,WITHOUT_CLASSIFICATION,//  if this is an insert into statement we might need to add constraint check 
Hive,WITHOUT_CLASSIFICATION,//  we want to remove the DPP with bigger data size 
Hive,WITHOUT_CLASSIFICATION,//  This can only come from a brute force discard; for now we don't discard blocks larger   than the target block. We could discard it and add remainder to free lists.   By definition if we are fragmented there should be a smaller buffer somewhere. 
Hive,WITHOUT_CLASSIFICATION,//  Adjust right input fields in nonEquiConds if previous call modified the input 
Hive,WITHOUT_CLASSIFICATION,/*  HCat Input Format related errors 1000 - 1999  */
Hive,WITHOUT_CLASSIFICATION,//  Run an hcat expression and return just the json outout. 
Hive,WITHOUT_CLASSIFICATION,// looks as much as possible like original query 
Hive,WITHOUT_CLASSIFICATION,//  continue merging with next alias 
Hive,WITHOUT_CLASSIFICATION,//  Open the log file and read in a line. Then feed the line into 
Hive,WITHOUT_CLASSIFICATION,//  all rows from left side will be present in resultset 
Hive,WITHOUT_CLASSIFICATION,//  TODO: periodically reload a new HiveConf to check if stats reporting is enabled. 
Hive,WITHOUT_CLASSIFICATION,//  Regrettable that we have to wrap the HCatException into a RuntimeException   but throwing the exception is the appropriate result here and hasNext()   signature will only allow RuntimeExceptions. Iterator.hasNext() really   should have allowed IOExceptions 
Hive,WITHOUT_CLASSIFICATION,// 2 from insert + 1 for each update stmt 
Hive,WITHOUT_CLASSIFICATION,//  Some of the information in the source is complete. Don't need to fetch it from the context. 
Hive,WITHOUT_CLASSIFICATION,//  Back to seconds. 
Hive,WITHOUT_CLASSIFICATION,//  this internalName represents a constant parameter in aggregation parameters 
Hive,WITHOUT_CLASSIFICATION,//  its parents also 
Hive,WITHOUT_CLASSIFICATION,//  test with same schema with include 
Hive,WITHOUT_CLASSIFICATION,//  We at least know they are not equal.  The one with the larger scale has non-zero digits   below the other's scale (since the scale does not include trailing zeroes). 
Hive,WITHOUT_CLASSIFICATION,//  authorize for the old   location and new location 
Hive,WITHOUT_CLASSIFICATION,/*          * Get our Multi-Key hash map information for this specialized class.          */
Hive,WITHOUT_CLASSIFICATION,//  Today ACID tables are only ORC and that format is vectorizable.  Verify these   assumptions. 
Hive,WITHOUT_CLASSIFICATION,//  Add the Hadoop token back to the Job the configuration still has the necessary 
Hive,WITHOUT_CLASSIFICATION,//  TODO: for ordinal types you can produce a range (BETWEEN 1444442100 1444442107) 
Hive,WITHOUT_CLASSIFICATION,//  Make sure the Accumulo token is set in the Configuration (only a stub of the Accumulo   AuthentiationToken is serialized not the entire token). configureJobConf may be   called multiple times with the same JobConf which results in an error from Accumulo 
Hive,WITHOUT_CLASSIFICATION,//  Walk through the tree to decide value.   Example: skewed column: C1 C2 ;   index: (1a) ;   expression tree: ((c1=1) and (c2=a)) or ((c1=3) or (c2=b)) 
Hive,WITHOUT_CLASSIFICATION,//  If the size is present in the metastore use it 
Hive,WITHOUT_CLASSIFICATION,//  Do implicit conversion from source type to target type. 
Hive,WITHOUT_CLASSIFICATION,/*  In this branch we had already a cookie that did expire        therefore we need to resend a valid Kerberos challenge */
Hive,WITHOUT_CLASSIFICATION,// need a separate stmt for executeUpdate() otherwise it will close the ResultSet(HIVE-12725) 
Hive,WITHOUT_CLASSIFICATION,//  so aggregationIsDistinct is a boolean array instead of a single number. 
Hive,WITHOUT_CLASSIFICATION,//  Wrap around at the end of buffer. 
Hive,WITHOUT_CLASSIFICATION,// This is required otherwise correct work object on repl load wont be created. 
Hive,WITHOUT_CLASSIFICATION,//  10^-31 
Hive,WITHOUT_CLASSIFICATION,//  The last line didn't match a pattern it is probably an error message part of   a string of stack traces related to the same error message so add it to the stack   trace 
Hive,WITHOUT_CLASSIFICATION,//  Map of valid write ids list for all the tables read by the current txn 
Hive,WITHOUT_CLASSIFICATION,//  Send the DelegationToken down to the Configuration for Accumulo to use 
Hive,WITHOUT_CLASSIFICATION,//  For caching column stats for a partitioned table 
Hive,WITHOUT_CLASSIFICATION,//  if map tasks and reduce tasks are in finishable state then priority is given to the task in   the following order   1) Dag start time   2) Within dag priority   3) Attempt start time   4) Vertex parallelism 
Hive,WITHOUT_CLASSIFICATION,//  If order of events (i.e. dagstart and fragmentstart) was guaranteed we could just   create the cache when dag starts and blindly return it to execution here. 
Hive,WITHOUT_CLASSIFICATION,//  If the log4j.configuration property hasn't already been explicitly set   use Hive's default log4j configuration 
Hive,WITHOUT_CLASSIFICATION,//  if there is at least one record put it in the map 
Hive,WITHOUT_CLASSIFICATION,//  Add the entry in mapredwork 
Hive,WITHOUT_CLASSIFICATION,//  Now clean them and check that they are removed from the count. 
Hive,WITHOUT_CLASSIFICATION,//  we have found the colName 
Hive,WITHOUT_CLASSIFICATION,//  Its count(col) case 
Hive,WITHOUT_CLASSIFICATION,/*  GenericUDFCase and GenericUDFWhen are implemented with the UDF Adaptor because             * of their complexity and generality. In the future variations of these             * can be optimized to run faster for the vectorized code path. For example             * CASE col WHEN 1 then "one" WHEN 2 THEN "two" ELSE "other" END             * is an example of a GenericUDFCase that has all constant arguments             * except for the first argument. This is probably a common case and a             * good candidate for a fast special-purpose VectorExpression. Then             * the UDF Adaptor code path could be used as a catch-all for             * non-optimized general cases.              */
Hive,WITHOUT_CLASSIFICATION,//  start column # for DP columns   array of values corresponding to DP columns 
Hive,WITHOUT_CLASSIFICATION,//  level OB; top level OB will have RexCall kept in a map.) 
Hive,WITHOUT_CLASSIFICATION,//  Create ReduceSink operator 
Hive,WITHOUT_CLASSIFICATION,//  Interrupt the runner thread 
Hive,WITHOUT_CLASSIFICATION,//  Union is hard to handle. For instance the following case:    TS    TS    |      |    FIL   FIL    |      |    SEL   SEL      \   /      UNION        |        RS        |       JOIN   If we treat this as a MJ case then after the RS is removed we would   create two MapWorks for each of the TS. Each of these MapWork will contain   a MJ operator which is wrong.   Otherwise we could try to break the op tree at the UNION and create two MapWorks   for the branches above. Then MJ will be in the following ReduceWork. 
Hive,WITHOUT_CLASSIFICATION,//  The join alias is modified before being inserted for consumption by sort-merge   join queries. If the join is part of a sub-query the alias is modified to include 
Hive,WITHOUT_CLASSIFICATION,/*    * If this QB represents a  SubQuery predicate then this will point to the SubQuery object.    */
Hive,WITHOUT_CLASSIFICATION,//  We're dealing with input that is an array of arrays of strings 
Hive,WITHOUT_CLASSIFICATION,// cq_state 
Hive,WITHOUT_CLASSIFICATION,//  The join keys are available in the reduceSinkOperators before join 
Hive,WITHOUT_CLASSIFICATION,//  Setup the table column stats 
Hive,WITHOUT_CLASSIFICATION,//  Create database in specific location (absolute non-qualified path) 
Hive,WITHOUT_CLASSIFICATION,//  second table in union query with view as parent 
Hive,WITHOUT_CLASSIFICATION,//  Base means originals no longer matter. 
Hive,WITHOUT_CLASSIFICATION,//  Load from modified dump event directories. 
Hive,WITHOUT_CLASSIFICATION,//  optional 
Hive,WITHOUT_CLASSIFICATION,/*    * Amount of time a thread can be alive in thread pool before cleaning this up. Core threads   * will not be cleanup from thread pool.    */
Hive,WITHOUT_CLASSIFICATION,//  Create expressions for Project operators before and after the Sort 
Hive,WITHOUT_CLASSIFICATION,//  The map is overloaded to keep track of mapjoins also 
Hive,WITHOUT_CLASSIFICATION,// not found 
Hive,WITHOUT_CLASSIFICATION,//  10^-32 
Hive,WITHOUT_CLASSIFICATION,//  add added archives 
Hive,WITHOUT_CLASSIFICATION,/*  Remove a task from the pending list  */
Hive,WITHOUT_CLASSIFICATION,//  init output object inspectors 
Hive,WITHOUT_CLASSIFICATION,//  Indexes have only one entry per value could go linear from here if we want to   use this for any sorted table we'll need to continue the search 
Hive,WITHOUT_CLASSIFICATION,//  In cases where column expression map or row schema is missing just pass on the parent column   stats. This could happen in cases like TS -> FIL where FIL does not map input column names to 
Hive,WITHOUT_CLASSIFICATION,//  We need a new connection object as we'll check the cache size after connection close 
Hive,WITHOUT_CLASSIFICATION,//  future 
Hive,WITHOUT_CLASSIFICATION,//  Store the required fields information in the UDFContext so that we 
Hive,WITHOUT_CLASSIFICATION,//  the number of reducers (set by user or inferred) is <=1 
Hive,WITHOUT_CLASSIFICATION,//  If we are going to validate the schema make sure we don't create it 
Hive,WITHOUT_CLASSIFICATION,//  Object inspectors for the tags for the input and output unionss 
Hive,WITHOUT_CLASSIFICATION,//  Start the service 
Hive,WITHOUT_CLASSIFICATION,// when a token is created the renewer of the token is stored  as shortName in AbstractDelegationTokenIdentifier.setRenewer()  this seems like an inconsistency because while cancelling the token  it uses the shortname to compare the renewer while it does not use  shortname during token renewal. Use getShortUserName() until its fixed  in HADOOP-15068 
Hive,WITHOUT_CLASSIFICATION,//  fallback to mapjoin no bucket scaling 
Hive,WITHOUT_CLASSIFICATION,/*            * We convert to an array of TypeInfo using a library routine since it parses the           * information and can handle use of different separators etc.  We cannot use the           * raw type string for comparison in the map because of the different separators used.            */
Hive,WITHOUT_CLASSIFICATION,//  compute keys and values as StandardObjects. Use non-optimized key (MR). 
Hive,WITHOUT_CLASSIFICATION,//  If this file sink desc has been processed due to a linked file sink desc 
Hive,WITHOUT_CLASSIFICATION,//  Have to force a cleanup of all expired entries here because its possible that the   expired entries will still be counted in Cache.size().   Taken from: 
Hive,WITHOUT_CLASSIFICATION,//  Remove from all tables 
Hive,WITHOUT_CLASSIFICATION,//  null we just add it 
Hive,WITHOUT_CLASSIFICATION,//  Bootstrap test 
Hive,WITHOUT_CLASSIFICATION,//  The number of non-NULL keys.  They have associated hash codes and key data.  
Hive,WITHOUT_CLASSIFICATION,//  Create a temporary function using the jar 
Hive,WITHOUT_CLASSIFICATION,//  Query hooks that execute before compilation and after execution 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setDate(java.lang.String java.sql.Date   * java.util.Calendar)    */
Hive,WITHOUT_CLASSIFICATION,//  Creates the command-line parameters for distcp 
Hive,WITHOUT_CLASSIFICATION,//  This should not happen 
Hive,WITHOUT_CLASSIFICATION,// add shutdown hook to cleanup the beeline for smooth exit 
Hive,WITHOUT_CLASSIFICATION,//  Insert a row to ACID table 
Hive,WITHOUT_CLASSIFICATION,//  The mapping that doesn't exist still shouldn't work. 
Hive,WITHOUT_CLASSIFICATION,//  If we have eager evaluators anywhere below us then we are eager too. 
Hive,WITHOUT_CLASSIFICATION,//  Test select root.col1 from root:struct<col1:struct<a:booleanb:double>col2:double> 
Hive,WITHOUT_CLASSIFICATION,/*    * Return a short string with the parameters of the vector expression that will be   * shown in EXPLAIN output etc.    */
Hive,WITHOUT_CLASSIFICATION,//  Find one session dir to remove 
Hive,WITHOUT_CLASSIFICATION,// driverRun("insert overwrite table orc5318 select * from inpy"); 
Hive,WITHOUT_CLASSIFICATION,/*       we set progress bar to be completed when hive query execution has completed     */
Hive,WITHOUT_CLASSIFICATION,//  4. Warn user if we could get stats for required columns 
Hive,WITHOUT_CLASSIFICATION,//  skip the name and metadata 
Hive,WITHOUT_CLASSIFICATION,//  Expected exception - Remote MetaStore 
Hive,WITHOUT_CLASSIFICATION,//  OWNER_NAME 
Hive,WITHOUT_CLASSIFICATION,//  10^-37 
Hive,WITHOUT_CLASSIFICATION,//  error out. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure row-7 is in the output. 
Hive,WITHOUT_CLASSIFICATION,//  instance. 
Hive,WITHOUT_CLASSIFICATION,//  The cleaner will removed aborted txns data/metadata but cannot remove aborted txn2 from TXN_TO_WRITE_ID   as there is a open txn < aborted txn2. The aborted txn1 < open txn and will be removed.   Also committed txn > open txn is retained. 
Hive,WITHOUT_CLASSIFICATION,/*          * Cancelled the job request and return to client.          */
Hive,WITHOUT_CLASSIFICATION,//  The current element in a1   The current element in a2 
Hive,WITHOUT_CLASSIFICATION,//  Loading the extra configuration options 
Hive,WITHOUT_CLASSIFICATION,//  In case the query is served by HiveServer2 don't pad it with spaces   as HiveServer2 output is consumed by JDBC/ODBC clients. 
Hive,WITHOUT_CLASSIFICATION,//  non nulls 
Hive,WITHOUT_CLASSIFICATION,//  NOOP 
Hive,WITHOUT_CLASSIFICATION,//  Nothing to copy and cache. 
Hive,WITHOUT_CLASSIFICATION,/*        *  Restriction.7.h :: SubQuery predicates can appear only as top level conjuncts.        */
Hive,WITHOUT_CLASSIFICATION,//  if the Hive configs are received from WITH clause in REPL LOAD or REPL STATUS commands. 
Hive,WITHOUT_CLASSIFICATION,//  unknown | unknown 
Hive,WITHOUT_CLASSIFICATION,//  Restore the old path information back   This is just to prevent incompatibilities with previous versions Hive 
Hive,WITHOUT_CLASSIFICATION,//  Set dynamic partitioning to nonstrict so that queries do not need any partition   references.   todo: this may be a perf issue as it prevents the optimizer.. or not 
Hive,WITHOUT_CLASSIFICATION,//  1st level GB: create a GB(R1 on all keys + VCol + count() as c) for each 
Hive,WITHOUT_CLASSIFICATION,//  the task in. On MR: The cache is a no-op. 
Hive,WITHOUT_CLASSIFICATION,//  may be null 
Hive,WITHOUT_CLASSIFICATION,//  ok even if there is not data 
Hive,WITHOUT_CLASSIFICATION,/*    * Initialize the conversion related arrays.  Assumes initTopLevelField has already been called.    */
Hive,WITHOUT_CLASSIFICATION,//  We store CHAR and VARCHAR without pads so write with STRING. 
Hive,WITHOUT_CLASSIFICATION,//  The fastBigIntegerBytes method returns 3 56 bit (7 byte) words and a possible sign byte. 
Hive,WITHOUT_CLASSIFICATION,//  Send a state update for vertex1 completion. This triggers a status update to be sent out. 
Hive,WITHOUT_CLASSIFICATION,//  The join outputs a concatenation of all the inputs. 
Hive,WITHOUT_CLASSIFICATION,//  return positive modulo 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise handle like a normal generic UDF. 
Hive,WITHOUT_CLASSIFICATION,//  Regression test for defect reported in HIVE-6399 
Hive,WITHOUT_CLASSIFICATION,//  assume the archive is in the original dir check if it exists 
Hive,WITHOUT_CLASSIFICATION,//  10^-39 
Hive,WITHOUT_CLASSIFICATION,//  Tests may leave this unitialized so better set it to 1 
Hive,WITHOUT_CLASSIFICATION,/*    * Config name used to find the maximum time job request can be executed.    */
Hive,WITHOUT_CLASSIFICATION,//  join. 
Hive,WITHOUT_CLASSIFICATION,//  cast string group to string (varchar to string etc.) 
Hive,WITHOUT_CLASSIFICATION,//  Replace expression 
Hive,WITHOUT_CLASSIFICATION,//  VALUES 
Hive,WITHOUT_CLASSIFICATION,/*  1-replica memory  */
Hive,WITHOUT_CLASSIFICATION,//  10^-38 
Hive,WITHOUT_CLASSIFICATION,/*    * NOTE: There is an expectation that all fields will be read-thru.    */
Hive,WITHOUT_CLASSIFICATION,//  The mapjoin has the same schema as the join operator 
Hive,WITHOUT_CLASSIFICATION,//  For thread safety we allocate private writable objects for our use only. 
Hive,WITHOUT_CLASSIFICATION,//  Return true if the partition is bucketed/sorted by the specified positions   The number of buckets the sort order should also match along with the 
Hive,WITHOUT_CLASSIFICATION,//  double NOT BETWEEN 
Hive,WITHOUT_CLASSIFICATION,//  small table 
Hive,WITHOUT_CLASSIFICATION,// https://dev.mysql.com/doc/refman/5.5/en/error-messages-server.html 
Hive,WITHOUT_CLASSIFICATION,// minor comp so we ignore 'base_0000100' files so all Deletes end up first since 
Hive,WITHOUT_CLASSIFICATION,//  optional string hive_query_id = 4; 
Hive,WITHOUT_CLASSIFICATION,//  Update expectedEntries based on factor and minEntries configurations 
Hive,WITHOUT_CLASSIFICATION,/*  is 10^2^i.  Used to convert decimal  */
Hive,WITHOUT_CLASSIFICATION,//  Write the mutation 
Hive,WITHOUT_CLASSIFICATION,// Preliminary checks.  In the MR version of the code these used to be done via another walk  here it is done inline. 
Hive,WITHOUT_CLASSIFICATION,/*        * Get the job request time out value. If this configuration value is set to 0       * then job request will wait until it finishes.        */
Hive,WITHOUT_CLASSIFICATION,// 0 since base_x doesn't have a suffix (neither does pre acid write) 
Hive,WITHOUT_CLASSIFICATION,//  Now that bootstrap has dumped all objects related we have to account for the changes   that occurred while bootstrap was happening - i.e. we have to look through all events   during the bootstrap period and consolidate them with our dump. 
Hive,WITHOUT_CLASSIFICATION,//  3. We populate the filters and filterMap structure needed in the join descriptor 
Hive,WITHOUT_CLASSIFICATION,// template <ClassName> <ValueType> <IfDefined> 
Hive,WITHOUT_CLASSIFICATION,//  User specified a row limit set it on the Query 
Hive,WITHOUT_CLASSIFICATION,//  Nobody can see this exception on the threadpool; just log it. 
Hive,WITHOUT_CLASSIFICATION,// reached EndOfFile 
Hive,WITHOUT_CLASSIFICATION,//  The RPC library takes care of timing out this. 
Hive,WITHOUT_CLASSIFICATION,//  Add to the queue only the first time this is registered and on 
Hive,WITHOUT_CLASSIFICATION,/*    * {@link VectorizedOrcAcidRowBatchReader} is always used for vectorized reads of acid tables.   * In some cases this cannot be used from LLAP IO elevator because   * {@link RecordReader#getRowNumber()} is not (currently) available there but is required to   * generate ROW__IDs for "original" files   * @param hasDeletes - if there are any deletes that apply to this split   * todo: HIVE-17944    */
Hive,WITHOUT_CLASSIFICATION,//  Mark this small table as being processed 
Hive,WITHOUT_CLASSIFICATION,//  specified 
Hive,WITHOUT_CLASSIFICATION,//  Some columns from tables are not used. 
Hive,WITHOUT_CLASSIFICATION,//  If the previous character isn't an escape characters it's the separator 
Hive,WITHOUT_CLASSIFICATION,//  check that data has moved 
Hive,WITHOUT_CLASSIFICATION,//  all children are base classes 
Hive,WITHOUT_CLASSIFICATION,//  Its either count (*) or count() case 
Hive,WITHOUT_CLASSIFICATION,//  assigning higher priority than FileSystem shutdown hook so that streaming connection gets closed first before   filesystem close (to avoid ClosedChannelException) 
Hive,WITHOUT_CLASSIFICATION,//  Break if it encountered a union 
Hive,WITHOUT_CLASSIFICATION,//  toStandardDuration assumes days are always 24h and hours are always 60 minutes   which may not always be the case e.g if there are daylight saving changes. 
Hive,WITHOUT_CLASSIFICATION,//  Only refresh once. 
Hive,WITHOUT_CLASSIFICATION,//  Password must be present 
Hive,WITHOUT_CLASSIFICATION,//  Create the non-deferred realArgument 
Hive,WITHOUT_CLASSIFICATION,//  the mapjoin has already been handled 
Hive,WITHOUT_CLASSIFICATION,//  There should be 1 delta dir plus a base dir in the location 
Hive,WITHOUT_CLASSIFICATION,//  Set the table properties 
Hive,WITHOUT_CLASSIFICATION,/*  * An single long value hash map based on the BytesBytesMultiHashMultiSet. * * We serialize the long key into BinarySortable format into an output buffer accepted by * BytesBytesMultiHashMultiSet.  */
Hive,WITHOUT_CLASSIFICATION,//  doDisplayFields(newerFields newerClass); 
Hive,WITHOUT_CLASSIFICATION,//  Check if there already exists a semijoin branch 
Hive,WITHOUT_CLASSIFICATION,//  the row key column becomes a STRING 
Hive,WITHOUT_CLASSIFICATION,//  Now try it as the table owner and see if we get better luck. 
Hive,WITHOUT_CLASSIFICATION,//  Bail out ungracefully - we should never hit   this here - but would have hit it in SemanticAnalyzer 
Hive,WITHOUT_CLASSIFICATION,//  Already processed. See backtracking. 
Hive,WITHOUT_CLASSIFICATION,//  PRIVILEGES 
Hive,WITHOUT_CLASSIFICATION,//  Decrement batch size.  When this gets to 0 the batch will be executed 
Hive,WITHOUT_CLASSIFICATION,//  Handle remaining middle long word digits. 
Hive,WITHOUT_CLASSIFICATION,/*    * test LazyMap with bad entries e.g. empty key or empty entries   * where '[' and  ']' don't exist only for notation purpose   * STX with value of 2 as entry separator ETX with 3 as key/value separator   *  */
Hive,WITHOUT_CLASSIFICATION,// TOK_SUBQUERY_EXPR should have either 2 or 3 children 
Hive,WITHOUT_CLASSIFICATION,//  set memory threshold on memory used after GC 
Hive,WITHOUT_CLASSIFICATION,// test with predicates such that partition pruning doesn't kick in 
Hive,WITHOUT_CLASSIFICATION,// here means the last branch of the multi-insert is Cardinality Validation 
Hive,WITHOUT_CLASSIFICATION,//  Test a set of random subtracts at high precision. 
Hive,WITHOUT_CLASSIFICATION,//  we need to keep predicate kind e.g. EQUAL or NOT EQUAL   so that later while decorrelating LogicalCorrelate appropriate join predicate   is generated 
Hive,WITHOUT_CLASSIFICATION,//  infer PK-FK relationship in single attribute join case 
Hive,WITHOUT_CLASSIFICATION,//  initialize pathToTableInfo 
Hive,WITHOUT_CLASSIFICATION,//  add the property only if it exists in table properties 
Hive,WITHOUT_CLASSIFICATION,//  Ambiguous call: two methods with the same number of implicit 
Hive,WITHOUT_CLASSIFICATION,//  1. We extract the information necessary to create the predicate for the 
Hive,WITHOUT_CLASSIFICATION,//  if map tasks and reduce tasks are in finishable state then priority is given to the task   that has less number of pending tasks (shortest job) 
Hive,WITHOUT_CLASSIFICATION,//  we don't push down any expressions that refer to aliases that can;t   be pushed down per getQualifiedAliases 
Hive,WITHOUT_CLASSIFICATION,//  Serde may not have this optional annotation defined in which case be conservative   and say conversion is needed. 
Hive,WITHOUT_CLASSIFICATION,//  all we can handle is LimitOperator FilterOperator SelectOperator and final FS     for non-aggressive mode (minimal)   1. sampling is not allowed   2. for partitioned table all filters should be targeted to partition column 
Hive,WITHOUT_CLASSIFICATION,//  Backtrack SEL columns to pRS 
Hive,WITHOUT_CLASSIFICATION,//  remove the biggest key 
Hive,WITHOUT_CLASSIFICATION,//  Transient members initialized by transientInit method.   temporary location for building number string 
Hive,WITHOUT_CLASSIFICATION,//  Free output columns if inputs have non-leaf expression trees. 
Hive,WITHOUT_CLASSIFICATION,//  If it is a floor <date> operator we need to rewrite it 
Hive,WITHOUT_CLASSIFICATION,//  check null cols schemas for a partition 
Hive,WITHOUT_CLASSIFICATION,//  Column the record identifier is in -1 indicates no record id  unique within a transaction 
Hive,WITHOUT_CLASSIFICATION,//  Invalid paths 
Hive,WITHOUT_CLASSIFICATION,// load partition that doesn't exist in T 
Hive,WITHOUT_CLASSIFICATION,//  Do the per-batch setup for an inner big-only join. 
Hive,WITHOUT_CLASSIFICATION,//  All partitions should miss in target as it was marked virtually as dropped 
Hive,WITHOUT_CLASSIFICATION,//  need to either move tmp files or remove them 
Hive,WITHOUT_CLASSIFICATION,//  TODO Nothing else should be done for this task. Move on. 
Hive,WITHOUT_CLASSIFICATION,//  Drop connection without calling close. HMS thread deleteContext 
Hive,WITHOUT_CLASSIFICATION,//  Map key will be list of [typeInfo isEscaped escapeChar] 
Hive,WITHOUT_CLASSIFICATION,//  Note: this could be made more generic; it may be a common problem for the endpoints that         can move around dynamically. For now we only handle this for the update. 
Hive,WITHOUT_CLASSIFICATION,/*      * 2. convert from node.      */
Hive,WITHOUT_CLASSIFICATION,//  v[5] -- since left integer #5 is always 0 some products here are not included. 
Hive,WITHOUT_CLASSIFICATION,//  create hiveconf again to run initialization code to see if value changes 
Hive,WITHOUT_CLASSIFICATION,//  then we continue to use this perf logger 
Hive,WITHOUT_CLASSIFICATION,//  process map joins with no reducers pattern 
Hive,WITHOUT_CLASSIFICATION,//  if log4j configuration file found successfully use HiveConf property value 
Hive,WITHOUT_CLASSIFICATION,//  No conflicts. Module configuration is what will be used.   We've already verified that includes and excludes are not present at the same time for   individual modules. 
Hive,WITHOUT_CLASSIFICATION,//  Should not happen edit check is false. 
Hive,WITHOUT_CLASSIFICATION,//  If we fail to remove it's probably an internal error. We'd try to handle it the same way   as above - by restarting the session. We'd fail the caller to avoid exceeding parallelism. 
Hive,WITHOUT_CLASSIFICATION,//  At this point we're dealing with all return types except ScheduleResult.SCHEDULED. 
Hive,WITHOUT_CLASSIFICATION,//  Ignore errors cleaning up miniMR 
Hive,WITHOUT_CLASSIFICATION,//  so we don't create an extra SD in the metastore db that has no references. 
Hive,WITHOUT_CLASSIFICATION,//  Entries should be in LRU order in the keyset iterator. 
Hive,WITHOUT_CLASSIFICATION,//  check if a map-reduce job is needed to merge the files   If the current size is smaller than the target merge 
Hive,WITHOUT_CLASSIFICATION,//  Not much we can do about it here. 
Hive,WITHOUT_CLASSIFICATION,// generate enough delta files so that Initiator can trigger auto compaction 
Hive,WITHOUT_CLASSIFICATION,//  Append the separator if needed. 
Hive,WITHOUT_CLASSIFICATION,//  Test regular inputformat 
Hive,WITHOUT_CLASSIFICATION,//  LOG.info("Allocated " + allocCount + " of " + size + "; " + a.debugDump()); 
Hive,WITHOUT_CLASSIFICATION,//  Now multiply by 2 and add 1 sign bit. 
Hive,WITHOUT_CLASSIFICATION,/*    * STRUCT.    */
Hive,WITHOUT_CLASSIFICATION,// should've done several heartbeats 
Hive,WITHOUT_CLASSIFICATION,// fall through 
Hive,WITHOUT_CLASSIFICATION,//  The output column projection of the vectorized row batch.  And the type infos of the output 
Hive,WITHOUT_CLASSIFICATION,//  The createTime will be set on the server side so the comparison should skip it 
Hive,WITHOUT_CLASSIFICATION,//  TXN_HIGH_WATER_MARK 
Hive,WITHOUT_CLASSIFICATION,//  KEY_SEQ 
Hive,WITHOUT_CLASSIFICATION,//  Specific test for HIVE-18744 --   Tests Timestamp assignment. 
Hive,WITHOUT_CLASSIFICATION,//  Create only needed/included columns data columns. 
Hive,WITHOUT_CLASSIFICATION,//  Recurse over all the source tables 
Hive,WITHOUT_CLASSIFICATION,// if there is no prefix then we don't cut anything 
Hive,WITHOUT_CLASSIFICATION,//  Look for databases but do not find any 
Hive,WITHOUT_CLASSIFICATION,//  Set up codahale if enabled; we cannot tag the values so just prefix them for the JMX view. 
Hive,WITHOUT_CLASSIFICATION,//  Cached buffer has the same (or lower) offset as the requested buffer. 
Hive,WITHOUT_CLASSIFICATION,// each of these should fail 
Hive,WITHOUT_CLASSIFICATION,//  ///////////////////////////// 
Hive,WITHOUT_CLASSIFICATION,// now metastore connection should fail 
Hive,WITHOUT_CLASSIFICATION,//  Use the default separators [0 1 2 3 ... 7] 
Hive,WITHOUT_CLASSIFICATION,//  later... 
Hive,WITHOUT_CLASSIFICATION,//  tablename is either TABLENAME or DBNAME.TABLENAME if db is given 
Hive,WITHOUT_CLASSIFICATION,// OK so now we have a lock 
Hive,WITHOUT_CLASSIFICATION,/*    * A WindowFrame specifies the Range on which a Window Function should   * be applied for the 'current' row. Its is specified by a <i>start</i> and   * <i>end</i> Boundary.    */
Hive,WITHOUT_CLASSIFICATION,/*  Convert an integer value representing a timestamp in nanoseconds to one   * that represents a timestamp in seconds (since the epoch).    */
Hive,WITHOUT_CLASSIFICATION,//  Pairwise: ColumnHasNulls ColumnIsRepeating 
Hive,WITHOUT_CLASSIFICATION,//  Major compact to create a base that has ACID schema. 
Hive,WITHOUT_CLASSIFICATION,//  the seed port 
Hive,WITHOUT_CLASSIFICATION,//  blank " " (1 byte)   NEW TAI LUE LETTER LOW QA U+1981 (3 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  If the threshold is 100 percent then there is no throttling 
Hive,WITHOUT_CLASSIFICATION,//  It's not a column or a table alias. 
Hive,WITHOUT_CLASSIFICATION,//  GenericUDF 
Hive,WITHOUT_CLASSIFICATION,//  For some attempts check inheritance. 
Hive,WITHOUT_CLASSIFICATION,/*    * Verify table for Key: Long x Hash Table: HashMap    */
Hive,WITHOUT_CLASSIFICATION,//  assert that the table created still has no hcat instrumentation 
Hive,WITHOUT_CLASSIFICATION,//  TODO: call setRemoteUser in ExecuteStatementOperation or higher. 
Hive,WITHOUT_CLASSIFICATION,//  the data that we need for this RG. 
Hive,WITHOUT_CLASSIFICATION,//  A vectorized expression that selects no rows. 
Hive,WITHOUT_CLASSIFICATION,//  check that the agg is on the entire input 
Hive,WITHOUT_CLASSIFICATION,/*  We want abx to come from a finite field of size 0 to k where k is a prime number.   * 2^p - 1 is prime for p = 31. Hence bitvectorSize has to be 31. Pick k to be 2^p -1.   * If abx didn't come from a finite field ax1 + b mod k and ax2 + b mod k will not be pair wise   * independent. As a consequence the hash values will not distribute uniformly from 0 to 2^p-1   * thus introducing errors in the estimates.    */
Hive,WITHOUT_CLASSIFICATION,//  No-op -- this is needed to be able to instantiate the   class from the name. 
Hive,WITHOUT_CLASSIFICATION,//  SCHEMA_NAME 
Hive,WITHOUT_CLASSIFICATION,//  the corresponding ReduceSinkOperator. 
Hive,WITHOUT_CLASSIFICATION,//  Find the highest failure count 
Hive,WITHOUT_CLASSIFICATION,//  Always use index 0 so the write methods don't write a separator. 
Hive,WITHOUT_CLASSIFICATION,// look at top 3 bits and return appropriate enum 
Hive,WITHOUT_CLASSIFICATION,//  Validate resultset columns 
Hive,WITHOUT_CLASSIFICATION,//  Init fails but the session is also killed by WM before that. 
Hive,WITHOUT_CLASSIFICATION,//  If all of the agg expressions are distinct and have the same 
Hive,WITHOUT_CLASSIFICATION,//  The path to the tracking root 
Hive,WITHOUT_CLASSIFICATION,//  set the escape 
Hive,WITHOUT_CLASSIFICATION,//  get the table names out 
Hive,WITHOUT_CLASSIFICATION,//  Look for it under the old Hive name 
Hive,WITHOUT_CLASSIFICATION,//  Left pad longer strings with multi-byte characters. 
Hive,WITHOUT_CLASSIFICATION,//  find this parentColName in its parent's rs 
Hive,WITHOUT_CLASSIFICATION,// All the vectors have the same length 
Hive,WITHOUT_CLASSIFICATION,//  before making changes or copy-pasting these. 
Hive,WITHOUT_CLASSIFICATION,//  second time will complete silently 
Hive,WITHOUT_CLASSIFICATION,//  Whether there are more than 0 rows. 
Hive,WITHOUT_CLASSIFICATION,//  the partition doesn't qualify the global limit optimization for some reason 
Hive,WITHOUT_CLASSIFICATION,//  fail early if the columns specified for column statistics are not valid 
Hive,WITHOUT_CLASSIFICATION,//  Normalize the case for source of replication parameter 
Hive,WITHOUT_CLASSIFICATION,//  later. 
Hive,WITHOUT_CLASSIFICATION,/*        * Clip off one byte and expect to get an EOFException on the write field.        */
Hive,WITHOUT_CLASSIFICATION,//  test second IF argument repeating 
Hive,WITHOUT_CLASSIFICATION,//  End sync stuff. 
Hive,WITHOUT_CLASSIFICATION,// get the new nextKVReader with lowest key 
Hive,WITHOUT_CLASSIFICATION,//  From this point on session creation will wait for the default pool (if # of sessions > 0). 
Hive,WITHOUT_CLASSIFICATION,//  If sort does not contain a limit operation or limit is 0 we bail out 
Hive,WITHOUT_CLASSIFICATION,//  Test altering the table 
Hive,WITHOUT_CLASSIFICATION,//  Second branch should only have the MV 
Hive,WITHOUT_CLASSIFICATION,//  total characters = 3; byte length = 9 
Hive,WITHOUT_CLASSIFICATION,//  This is for transactional tables. 
Hive,WITHOUT_CLASSIFICATION,//  Drop the partitions and get a list of locations which need to be deleted 
Hive,WITHOUT_CLASSIFICATION,//  while we are in the process of setting it to valid. 
Hive,WITHOUT_CLASSIFICATION,//  issue a command with bad options 
Hive,WITHOUT_CLASSIFICATION,//  Given the data in a partition evaluate the result for the next row for   streaming and batch mode 
Hive,WITHOUT_CLASSIFICATION,//  no interpolation needed because lower position and higher position has the same key 
Hive,WITHOUT_CLASSIFICATION,/*  comment for reviewers -> updateTab2Cols needed to be separate from tab2cols because if I    pass tab2cols to getHivePrivObjects for the output case it will trip up insert/selects    since the insert will get passed the columns from the select.      */
Hive,WITHOUT_CLASSIFICATION,//  response is true 
Hive,WITHOUT_CLASSIFICATION,//  This is the vectorized row batch description of the output of the native vectorized PTF   operator.  It is based on the incoming vectorization context.  Its projection may include 
Hive,WITHOUT_CLASSIFICATION,//  Nothing updated yet. 
Hive,WITHOUT_CLASSIFICATION,//  clear the mask for array reuse (this is to avoid masks array allocation in inner loop) 
Hive,WITHOUT_CLASSIFICATION,//  ptf node form is:   ^(TOK_PTBLFUNCTION $name $alias? partitionTableFunctionSource partitioningSpec? expression*)   guaranteed to have an alias here: check done in processJoin 
Hive,WITHOUT_CLASSIFICATION,//  that if we do something we didn't expect to do it'd be more likely to fail. 
Hive,WITHOUT_CLASSIFICATION,//  run the operator pipeline 
Hive,WITHOUT_CLASSIFICATION,//  optional bytes work_spec_signature = 2; 
Hive,WITHOUT_CLASSIFICATION,//  And no metadata gets created. 
Hive,WITHOUT_CLASSIFICATION,//  all keys + VCol + c 
Hive,WITHOUT_CLASSIFICATION,/*      * todo: Longer term we should pass this from client somehow - this would be an optimization;  once     * that is in place make sure to build and test "writeSet" below using OperationType not LockType     * With Static Partitions we assume that the query modifies exactly the partitions it locked.  (not entirely     * realistic since Update/Delete may have some predicate that filters out all records out of     * some partition(s) but plausible).  For DP we acquire locks very wide (all known partitions)     * but for most queries only a fraction will actually be updated.  #addDynamicPartitions() tells     * us exactly which ones were written to.  Thus using this trick to kill a query early for     * DP queries may be too restrictive.      */
Hive,WITHOUT_CLASSIFICATION,//  do not put the TAB for the last column 
Hive,WITHOUT_CLASSIFICATION,//  {Small Value Bytes} 
Hive,WITHOUT_CLASSIFICATION,//  between has 4 args here but can be vectorized like this 
Hive,WITHOUT_CLASSIFICATION,//  Filters are using an index which should match 2 rows 
Hive,WITHOUT_CLASSIFICATION,//  i.e. this column is not appearing in keyExprs of the RS 
Hive,WITHOUT_CLASSIFICATION,//  Flush the last record when reader is out of records 
Hive,WITHOUT_CLASSIFICATION,//  rename based on output schema of join operator 
Hive,WITHOUT_CLASSIFICATION,//  only dealing with special join types here. 
Hive,WITHOUT_CLASSIFICATION,//  The AccumuloOutputFormat will look for it there. 
Hive,WITHOUT_CLASSIFICATION,//  in case of dynamic partitioning lock the table 
Hive,WITHOUT_CLASSIFICATION,//  Update max executors now that cluster info is definitely available. 
Hive,WITHOUT_CLASSIFICATION,//  Current replication state must be set on the Partition object only for bootstrap dump.   Event replication State will be null in case of bootstrap dump. 
Hive,WITHOUT_CLASSIFICATION,//  propagate nulls 
Hive,WITHOUT_CLASSIFICATION,//  Adjust the compression block position. 
Hive,WITHOUT_CLASSIFICATION,//  jobClose needs to execute successfully otherwise fail task 
Hive,WITHOUT_CLASSIFICATION,//  No stats to delete forgivable error. 
Hive,WITHOUT_CLASSIFICATION,//  Step 1 : Create a temp table object 
Hive,WITHOUT_CLASSIFICATION,//  Execute optimization 
Hive,WITHOUT_CLASSIFICATION,/*    * Tests single threaded implementation of checkMetastore    */
Hive,WITHOUT_CLASSIFICATION,// rename the data directory 
Hive,WITHOUT_CLASSIFICATION,// owner like ".*Owner.*" and owner like "test.*" 
Hive,WITHOUT_CLASSIFICATION,//  if there are union all operators it means that the walking context contains union all operators.   please see more details of context.currentUnionOperator in GenTezWorkWalker 
Hive,WITHOUT_CLASSIFICATION,//  base  = JAVA64_OBJECT + PRIMITIVES1 * 4 + JAVA64_FIELDREF * 3 + JAVA64_ARRAY;   entry = JAVA64_OBJECT + JAVA64_FIELDREF + PRIMITIVES1 
Hive,WITHOUT_CLASSIFICATION,//  For now we don't go higher than the default batch size unless we do more work   to verify every vectorized operator downstream can handle a larger batch size. 
Hive,WITHOUT_CLASSIFICATION,//  Rewriting cannot be performed 
Hive,WITHOUT_CLASSIFICATION,//  this matches the list structure that Hive writes 
Hive,WITHOUT_CLASSIFICATION,/*       This sets up dependencies such that a child task is dependant on the parent to be complete.    */
Hive,WITHOUT_CLASSIFICATION,//  hashMap += JAVA32_FIELDREF + PRIMITIVES1   hashMap.entry += JAVA32_FIELDREF * 2 
Hive,WITHOUT_CLASSIFICATION,//  we are in secure mode. Login using keytab 
Hive,WITHOUT_CLASSIFICATION,//  Join key exprs are represented in terms of the original table columns 
Hive,WITHOUT_CLASSIFICATION,//  concatenate. Keeping the old logic for non-MM tables with temp directories and stuff. 
Hive,WITHOUT_CLASSIFICATION,/*    * Infer Uniquenes if: - rowCount(col) = ndv(col) - TBD for numerics: max(col)   * - min(col) = rowCount(col)   *    * Why are we intercepting Project and not TableScan? Because if we   * have a method for TableScan it will not know which columns to check for.   * Inferring Uniqueness for all columns is very expensive right now. The flip   * side of doing this is it only works post Field Trimming.    */
Hive,WITHOUT_CLASSIFICATION,//  if there is nothing to project or if we are projecting everything   then no need to introduce another RelNode 
Hive,WITHOUT_CLASSIFICATION,//  Make sure it has a chance to dump it. 
Hive,WITHOUT_CLASSIFICATION,/*  Minimum value seen so far  */
Hive,WITHOUT_CLASSIFICATION,// vectorized because there is INPUT__FILE__NAME 
Hive,WITHOUT_CLASSIFICATION,//  At this point tablePath is part of HDFS and it is encrypted 
Hive,WITHOUT_CLASSIFICATION,/*  100 files x 1000 size for 1 splits  */
Hive,WITHOUT_CLASSIFICATION,//  total characters = 3; byte length = 5 
Hive,WITHOUT_CLASSIFICATION,//  for any exception in conversion to decimal produce NULL 
Hive,WITHOUT_CLASSIFICATION,//  LocalJobRunner does not work with mapreduce OutputCommitter. So need 
Hive,WITHOUT_CLASSIFICATION,//  Accumulo instance name with ZK quorum 
Hive,WITHOUT_CLASSIFICATION,//  Pad with empty rows if the number of values in group is less than TOP num 
Hive,WITHOUT_CLASSIFICATION,//  Default all columns that are not metrics or timestamp are treated as dimensions 
Hive,WITHOUT_CLASSIFICATION,//  Calculate the length of the UTF-8 strings in input vector and place results in output vector. 
Hive,WITHOUT_CLASSIFICATION,//  daemon 
Hive,WITHOUT_CLASSIFICATION,//  1. analyze and process the position alias   step processPositionAlias out of genResolvedParseTree 
Hive,WITHOUT_CLASSIFICATION,//  TXN_ID 
Hive,WITHOUT_CLASSIFICATION,//  Check common conditions for both Optimized and Fast Hash Tables. 
Hive,WITHOUT_CLASSIFICATION,//  If MM wants to create a new base for IOW (instead of delta dir) it should specify it here 
Hive,WITHOUT_CLASSIFICATION,//  Clear all in memory partitions first 
Hive,WITHOUT_CLASSIFICATION,//  check if a predicate is needed   predicate is needed if either input pruning is not enough   or if input pruning is not possible 
Hive,WITHOUT_CLASSIFICATION,//  Now checkFailedCompactions() will return true 
Hive,WITHOUT_CLASSIFICATION,//  Exhausted reading all records close the reader. 
Hive,WITHOUT_CLASSIFICATION,//  pass the message to the user - essentially something about   the table   information passed to HCatOutputFormat was not right 
Hive,WITHOUT_CLASSIFICATION,//  The delegation token is not applicable in the given deployment mode   such as HMS is not kerberos secured 
Hive,WITHOUT_CLASSIFICATION,//  3. attach this SEL to the operator right before FS 
Hive,WITHOUT_CLASSIFICATION,//  Create backtrack SelectOp 
Hive,WITHOUT_CLASSIFICATION,//  We want to send the heartbeat at an interval that is less than the timeout. 
Hive,WITHOUT_CLASSIFICATION,//  for negative tests which is succeeded.. no need to print the query string 
Hive,WITHOUT_CLASSIFICATION,//  Virtual columns start after the last partition column. 
Hive,WITHOUT_CLASSIFICATION,//  Get the id the Spark job that was launched returns -1 if no Spark job was launched 
Hive,WITHOUT_CLASSIFICATION,//  Do this check in case the decrypted plaintext actually makes sense in some way. 
Hive,WITHOUT_CLASSIFICATION,//  not map reduce task or not conditional task just skip 
Hive,WITHOUT_CLASSIFICATION,//  Go by position not field name as field names aren't guaranteed.  The order of fields   in RecordIdentifier is writeId bucketId rowId 
Hive,WITHOUT_CLASSIFICATION,//  check if column is defined or not 
Hive,WITHOUT_CLASSIFICATION,//  transition to Success state 
Hive,WITHOUT_CLASSIFICATION,//  MY_STRINGSET 
Hive,WITHOUT_CLASSIFICATION,//  check filter condition type First extract the correlation out   of the filter 
Hive,WITHOUT_CLASSIFICATION,//  Test that existing shared_write db with new shared_read coalesces to 
Hive,WITHOUT_CLASSIFICATION,//  PAYLOAD 
Hive,WITHOUT_CLASSIFICATION,//  create the index table if it does not exist 
Hive,WITHOUT_CLASSIFICATION,//  Netty defaults to no of processors * 2. Can be changed via -Dio.netty.eventLoopThreads 
Hive,WITHOUT_CLASSIFICATION,//  We cannot just deallocate the buffer as it can hypothetically have users. 
Hive,WITHOUT_CLASSIFICATION,//  Just give each table the same amount of memory. 
Hive,WITHOUT_CLASSIFICATION,/*  Remove the lock specified  */
Hive,WITHOUT_CLASSIFICATION,//  set some values to use for getting conf. vars 
Hive,WITHOUT_CLASSIFICATION,//  There should be no blocking operation in RecordProcessor creation   otherwise the abort operation will not register since they are synchronized on the same 
Hive,WITHOUT_CLASSIFICATION,//  empty list 
Hive,WITHOUT_CLASSIFICATION,//  partitions archived before introducing multiple archiving 
Hive,WITHOUT_CLASSIFICATION,//  if HIVE_TXN_TIMEOUT is defined heartbeat interval will be HIVE_TXN_TIMEOUT/2 
Hive,WITHOUT_CLASSIFICATION,//  List to maintain the incremental dumps for each operation 
Hive,WITHOUT_CLASSIFICATION,//  If the app state is running get additional information from YARN Service 
Hive,WITHOUT_CLASSIFICATION,//  use lowercase table name as prefix here as StatsTask get table name from metastore to fetch counter. 
Hive,WITHOUT_CLASSIFICATION,//  Nothing got modified 
Hive,WITHOUT_CLASSIFICATION,//  set the root of the temporary path where dynamic partition columns will populate 
Hive,WITHOUT_CLASSIFICATION,//  -p port 
Hive,WITHOUT_CLASSIFICATION,//  We can safely remove the condition by replacing it with "true" 
Hive,WITHOUT_CLASSIFICATION,//  We will increase the size of the array on demand 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) Namespace  */
Hive,WITHOUT_CLASSIFICATION,//  If any of the table requests are null then I need to pull all the 
Hive,WITHOUT_CLASSIFICATION,//  Test string 
Hive,WITHOUT_CLASSIFICATION,//  Friday 30th August 1985 02:47:00 AM 
Hive,WITHOUT_CLASSIFICATION,//  serialize dense/sparse registers. Dense registers are bitpacked whereas 
Hive,WITHOUT_CLASSIFICATION,// short 
Hive,WITHOUT_CLASSIFICATION,//  mergeIsDirectFlag need to merge isDirect flag even newInput does not have parent 
Hive,WITHOUT_CLASSIFICATION,//  A reference to the current row. 
Hive,WITHOUT_CLASSIFICATION,//  Adding mssql jdbc driver if exists 
Hive,WITHOUT_CLASSIFICATION,/*  100 files x 100 size for 111 splits  */
Hive,WITHOUT_CLASSIFICATION,//  Adjust all longs using power 10 division/remainder. 
Hive,WITHOUT_CLASSIFICATION,/*  * An multi-key hash multi-set optimized for vector map join. * * The key is stored as the provided bytes (uninterpreted).  */
Hive,WITHOUT_CLASSIFICATION,//  it out. 
Hive,WITHOUT_CLASSIFICATION,//  Buffer needed to bridge. 
Hive,WITHOUT_CLASSIFICATION,//  This handles the common logic for destroy and return - everything except   the invalid combination of destroy and return themselves as well as the actual   statement that destroys or returns it. 
Hive,WITHOUT_CLASSIFICATION,//  See if someone else evicted this in parallel. 
Hive,WITHOUT_CLASSIFICATION,//  1 1   NULL 0 
Hive,WITHOUT_CLASSIFICATION,// Verify vectorized expression 
Hive,WITHOUT_CLASSIFICATION,//  Should the cache size be updated here or after the result data has actually been deleted? 
Hive,WITHOUT_CLASSIFICATION,//  Test that exclusive lock blocks shared reads 
Hive,WITHOUT_CLASSIFICATION,//  Bug - the field has to be in ms not sec. Override only if set precisely to sec. 
Hive,WITHOUT_CLASSIFICATION,//  Now if there are more than 1 sources then we have a join case 
Hive,WITHOUT_CLASSIFICATION,//  Have to use this if-else since switch-case on String is supported Java 7 onwards 
Hive,WITHOUT_CLASSIFICATION,//  For static partitions values would be obtained from partition(key=value...) clause. 
Hive,WITHOUT_CLASSIFICATION,//  ptf node form is: ^(TOK_PTBLFUNCTION $name $alias?   partitionTableFunctionSource partitioningSpec? expression*)   guranteed to have an lias here: check done in processJoin 
Hive,WITHOUT_CLASSIFICATION,//  GCE settings 
Hive,WITHOUT_CLASSIFICATION,//  clear out the mapjoin set. we don't need it anymore. 
Hive,WITHOUT_CLASSIFICATION,//  located at the same position as the input newProject. 
Hive,WITHOUT_CLASSIFICATION,//  Primarily for debugging purposes a.t.m since there's some unexplained TASK_TIMEOUTS which are currently being observed. 
Hive,WITHOUT_CLASSIFICATION,//  To make it more explicit below that processHooks needs to be called last. 
Hive,WITHOUT_CLASSIFICATION,//  join positions for even index filter lengths for odd index 
Hive,WITHOUT_CLASSIFICATION,//  Fourth is lower priority as a result of canFinish being set to false. 
Hive,WITHOUT_CLASSIFICATION,//  c1-c10 
Hive,WITHOUT_CLASSIFICATION,//  1.1. Fix up the query for insert/ctas/materialized views 
Hive,WITHOUT_CLASSIFICATION,//  Don't use the userName member as it may or may not have been set.  Get the value from   conf which calls into getUGI to figure out who the process is running as. 
Hive,WITHOUT_CLASSIFICATION,//  Use GetTokenResponseProto.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,/*      * validate and setup resultExprStr      */
Hive,WITHOUT_CLASSIFICATION,//  No change. 
Hive,WITHOUT_CLASSIFICATION,//  date str 
Hive,WITHOUT_CLASSIFICATION,//  Heartbeat indicates task has a duck - this must be reverted. 
Hive,WITHOUT_CLASSIFICATION,//  If we have failed before building newCacheData deallocate other the allocated. 
Hive,WITHOUT_CLASSIFICATION,//  Test that two different partitions don't collide on their locks 
Hive,WITHOUT_CLASSIFICATION,//  Reset the previously stored rootNode string 
Hive,WITHOUT_CLASSIFICATION,/*  noscan uses hdfs apis to retrieve such information from Namenode.       */
Hive,WITHOUT_CLASSIFICATION,//  Create inline SQL operator 
Hive,WITHOUT_CLASSIFICATION,//  Number of columns in the aliases does not match with number of columns   generated by the lateral view 
Hive,WITHOUT_CLASSIFICATION,//  add column expression for bloom filter 
Hive,WITHOUT_CLASSIFICATION,/*    * This hashtable stores "references" in an array of longs;  index in the array is hash of   * the key; these references point into infinite byte buffer (see below). This buffer contains   * records written one after another. There are several simple record formats.   * - single record for the key   *    [key bytes][value bytes][vlong value length][vlong key length][padding]   *    We leave padding to ensure we have at least 5 bytes after key and value.   * - first of multiple records for the key (updated from "single value for the key")   *    [key bytes][value bytes][5-byte long offset to a list start record]   *  - list start record   *    [vlong value length][vlong key length][5-byte long offset to the 2nd list record]   *    Lengths are preserved from the first record. Offset is discussed above.   *  - subsequent values in the list   *    [value bytes][value length][vlong relative offset to next record].   *   * In summary because we have separate list record we have very little list overhead for   * the typical case of primary key join where there's no list for any key; large lists also   * don't have a lot of relative overhead (also see the todo below).   *   * So the record looks as follows for one value per key (hash is fixed 4 bytes and is   * stored to expand w/o rehashing and to more efficiently deal with collision   *   *             i = key hash   *           ._______.   * REFS: ... |offset | ....   *           `--\----'   *               `-------------.   *                            \|/   *          .______._____._____'__.__._.   * WBS: ... | hash | key | val |vl|kl| | ....   *          `------'-----'-----'--'--'-'   *   * After that refs don't change so they are not pictured.   * When we add the 2nd value we rewrite lengths with relative offset to the list start record.   * That way the first record points to the "list record".   *                         ref .---------.   *                         \|/ |        \|/   *       .______._____._____'__|___.     '__.__.______.   * WBS:  | hash | key | val |offset| ... |vl|kl|      |   *       `------'-----'-----'------'     '--'--'------'   * After that refs don't change so they are not pictured. List record points to the 2nd value.   *                         ref .---------.        .---------------.   *                         \|/ |        \|/       |              \|/   *       .______._____._____'__|___.     '__.__.__|___.     ._____'__._.   * WBS:  | hash | key | val |offset| ... |vl|kl|offset| ... | val |vl|0|   *       `------'-----'-----'------'     '--'--'------'     '-----'--'-'   * If we add another value we overwrite the list record.   * We don't need to overwrite any vlongs and suffer because of that.   *                         ref .---------.         .-------------------------------.   *                         \|/ |        \|/        |                              \|/   *       .______._____._____'__|___.     '__.__.___|__.     ._____.__._.     ._____'__.______.   * WBS:  | hash | key | val |offset| ... |vl|kl|offset| ... | val |vl|0| ... | val |vl|offset|   *       `------'-----'-----'------'     '--'--'------'     '-----:--'-'     '-----'--'--|---'   *                                                               /|\                     |   *                                                                `----------------------'   * And another value (for example)   * ... ---.         .-----------------------------------------------------.   *       \|/        |                                                    \|/   *        '__.__.___|__.     ._____.__._.     ._____.__.______.     ._____'__.______.   * ...    |vl|kl|offset| ... | val |vl|0| ... | val |vl|offset| ... | val |vl|offset|   *        '--'--'------'     '-----:--'-'     '-----'--:--|---'     '-----'--'--|---'   *                                /|\                 /|\ |                     |   *                                 `-------------------+--'                     |   *                                                     `------------------------'    */
Hive,WITHOUT_CLASSIFICATION,//  This loop fills up the selected[] vector with all the index positions that are selected. 
Hive,WITHOUT_CLASSIFICATION,//  Indicate that the query will use a cached result. 
Hive,WITHOUT_CLASSIFICATION,//  HIVE-16985: try to find the fake merge work for SMB join that is really another MapWork. 
Hive,WITHOUT_CLASSIFICATION,/*    * UNION.    */
Hive,WITHOUT_CLASSIFICATION,//  shouldl return nulls at end 
Hive,WITHOUT_CLASSIFICATION,//  Note : Not testing table rename because table rename replication is not supported for table-level repl. 
Hive,WITHOUT_CLASSIFICATION,//  Use a separate method to make it easier to create a SaslHandler without having to 
Hive,WITHOUT_CLASSIFICATION,//  Aggregation buffer definition and manipulation methods 
Hive,WITHOUT_CLASSIFICATION,//  verify number of digits is <= 38 and each number has 1 or more digits 
Hive,WITHOUT_CLASSIFICATION,//  current dest has no distinct keys. 
Hive,WITHOUT_CLASSIFICATION,//  for tez. used to remember which position maps to which logical input 
Hive,WITHOUT_CLASSIFICATION,//  Gather RS operators that 1) belong to root works i.e. works containing TS operators   and 2) share the same input operator.   These will be the first target for extended shared work optimization 
Hive,WITHOUT_CLASSIFICATION,//  Include column names from SerDe the partition and virtual columns. 
Hive,WITHOUT_CLASSIFICATION,//  we are checking to the desired action. 
Hive,WITHOUT_CLASSIFICATION,// verify the serialized format for dtype 
Hive,WITHOUT_CLASSIFICATION,//  A MuxDesc is only generated from a corresponding ReduceSinkDesc. 
Hive,WITHOUT_CLASSIFICATION,//  Cancel again if current thread also interrupted 
Hive,WITHOUT_CLASSIFICATION,//  Set the parameters 
Hive,WITHOUT_CLASSIFICATION,//  if CREATE or DROP priv requirement is there the owner should have WRITE permission on 
Hive,WITHOUT_CLASSIFICATION,//  The special case zero logic at the beginning should have caught this. 
Hive,WITHOUT_CLASSIFICATION,//  inverse of partSpecToFileMapping populated at runtime 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#isReadOnly()    */
Hive,WITHOUT_CLASSIFICATION,//  Update LRU 
Hive,WITHOUT_CLASSIFICATION,//  UNION_ENTRY 
Hive,WITHOUT_CLASSIFICATION,// this is helpful when Sqoop is installed on each node in the cluster to make sure  relevant jars (JDBC in particular) are present on the node running the command 
Hive,WITHOUT_CLASSIFICATION,//  Shared between threads (including SessionState!) 
Hive,WITHOUT_CLASSIFICATION,//  used for rehashing to get last set of values   " "   current array size   have minimum 40% fill factor 
Hive,WITHOUT_CLASSIFICATION,//  There should be 1 delta dir plus a base dir in the location   steve 
Hive,WITHOUT_CLASSIFICATION,//  no privileges to filter 
Hive,WITHOUT_CLASSIFICATION,//  into ORIGINAL_VERSION 
Hive,WITHOUT_CLASSIFICATION,//  check if hiveserver2 config gets loaded when HS2 is started 
Hive,WITHOUT_CLASSIFICATION,/*  * An single byte array value hash map optimized for vector map join.  */
Hive,WITHOUT_CLASSIFICATION,//  In normal case we evict the items from the list. 
Hive,WITHOUT_CLASSIFICATION,//  Special cases for Avro. As with ORC we make table properties that   Avro is interested in available in jobconf at runtime 
Hive,WITHOUT_CLASSIFICATION,//  E.SR: Lock we are examining is shared read 
Hive,WITHOUT_CLASSIFICATION,//  Write the output to temporary directory and move it to the final location at the end 
Hive,WITHOUT_CLASSIFICATION,//  There is hint but none of the operators removed. Throw error 
Hive,WITHOUT_CLASSIFICATION,//  If Non-Acid case then all files would be in the base data path. So just return it. 
Hive,WITHOUT_CLASSIFICATION,//  Sort the queue - we may have put items here out of order. 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.CLIServiceClient#getOperationStatus(org.apache.hive.service.cli.OperationHandle)    */
Hive,WITHOUT_CLASSIFICATION,//  work can still be null if there is no merge work for this input 
Hive,WITHOUT_CLASSIFICATION,//  This key evaluator translates from the vectorized VectorHashKeyWrapper format 
Hive,WITHOUT_CLASSIFICATION,//  Using parseInto() avoids throwing exception when parsing 
Hive,WITHOUT_CLASSIFICATION,//  Iterate thru the file cache. This is best-effort. 
Hive,WITHOUT_CLASSIFICATION,//  Get column names and sort order 
Hive,WITHOUT_CLASSIFICATION,//  Skip the 0-th column since it won't have a vector after reading the text source. 
Hive,WITHOUT_CLASSIFICATION,//  add x to it 
Hive,WITHOUT_CLASSIFICATION,// ************************************************************************************************   Decimal to Integer conversion. 
Hive,WITHOUT_CLASSIFICATION,//    Getters   
Hive,WITHOUT_CLASSIFICATION,//  Nothing to do if it is not a MapReduce task. 
Hive,WITHOUT_CLASSIFICATION,//  Reduce sink is needed if the query contains a cluster by distribute by 
Hive,WITHOUT_CLASSIFICATION,//  These DS are used to cache previously created String 
Hive,WITHOUT_CLASSIFICATION,//  optional .EntityDescriptorProto processor_descriptor = 9; 
Hive,WITHOUT_CLASSIFICATION,//               cost of transferring map outputs to Join operator 
Hive,WITHOUT_CLASSIFICATION,//  In the case of tablesample the input paths are pointing to files rather than directories.   We need to get the parent directory as the filtering path so that all files in the same   parent directory will be grouped into one pool but not files from different parent   directories. This guarantees that a split will combine all files in the same partition   but won't cross multiple partitions if the user has asked so.   path is not directory 
Hive,WITHOUT_CLASSIFICATION,//  Skip "standard_conforming_strings" command which is read-only in older   Postgres versions like 8.1   See: http://www.postgresql.org/docs/8.2/static/release-8-1.html 
Hive,WITHOUT_CLASSIFICATION,/*  write string itself  */
Hive,WITHOUT_CLASSIFICATION,//  template <ClassNamePrefix> <ReturnType> <OperandType> <FuncName> <OperandCast> 
Hive,WITHOUT_CLASSIFICATION,//  Now for each path that is for the given versionNumber delete the znode from ZooKeeper 
Hive,WITHOUT_CLASSIFICATION,//  For caching Database objects. Key is database name 
Hive,WITHOUT_CLASSIFICATION,//  command should be redacted to avoid to logging sensitive data 
Hive,WITHOUT_CLASSIFICATION,//  replace all ReduceSinkOperators which are not at the bottom of 
Hive,WITHOUT_CLASSIFICATION,//  tested 
Hive,WITHOUT_CLASSIFICATION,//  user has told us to run in local mode or doesn't want auto-local mode 
Hive,WITHOUT_CLASSIFICATION,//  Set the new value to the output string variable 
Hive,WITHOUT_CLASSIFICATION,//  getAllUrls will parse zkJdbcUrl and will plugin the active HS2's host:port 
Hive,WITHOUT_CLASSIFICATION,//  Now test tblproperties specified on ALTER TABLE .. COMPACT .. statement 
Hive,WITHOUT_CLASSIFICATION,//  must be TezWork 
Hive,WITHOUT_CLASSIFICATION,//  look for matches in vertex specific counters 
Hive,WITHOUT_CLASSIFICATION,//  stage 2 
Hive,WITHOUT_CLASSIFICATION,//  need a SEMI-SHARED. 
Hive,WITHOUT_CLASSIFICATION,//  create a dummy MapReduce task 
Hive,WITHOUT_CLASSIFICATION,//  Single-Column String specific imports. 
Hive,WITHOUT_CLASSIFICATION,//  Note that regular SerDe doesn't tolerate fewer columns. 
Hive,WITHOUT_CLASSIFICATION,//  1.3 Build row type from field <type name> 
Hive,WITHOUT_CLASSIFICATION,//  Max number of nodes when converting to CNF 
Hive,WITHOUT_CLASSIFICATION,//  check entries beyond first one 
Hive,WITHOUT_CLASSIFICATION,//  Need to override this one too or dropTable breaks because it doesn't find the table when checks 
Hive,WITHOUT_CLASSIFICATION,//  HiveDecimal -> Number -> Double 
Hive,WITHOUT_CLASSIFICATION,//  Note: both full-ACID and insert-only sinks. 
Hive,WITHOUT_CLASSIFICATION,//  trim off the ending "" if any 
Hive,WITHOUT_CLASSIFICATION,//  LOG.info("got "+t); 
Hive,WITHOUT_CLASSIFICATION,//  Test testing that the filters introduced by EventUtils are working correctly. 
Hive,WITHOUT_CLASSIFICATION,//  stage 1 
Hive,WITHOUT_CLASSIFICATION,//  the start/stop row conditions (HBASE-1829). 
Hive,WITHOUT_CLASSIFICATION,//  Using a previously cached result. 
Hive,WITHOUT_CLASSIFICATION,//  Size of bigtable 
Hive,WITHOUT_CLASSIFICATION,//  Calculate TypeInfo 
Hive,WITHOUT_CLASSIFICATION,//  If so we need not perform this optimization and we should bail out. 
Hive,WITHOUT_CLASSIFICATION,//  For queries using script the optimization cannot be applied without user's confirmation 
Hive,WITHOUT_CLASSIFICATION,//  the materialization was created. Otherwise query returns 0 rows. 
Hive,WITHOUT_CLASSIFICATION,//  Output from the script 
Hive,WITHOUT_CLASSIFICATION,//  convert the mapjoin to a bucketized mapjoin 
Hive,WITHOUT_CLASSIFICATION,//  Check if session files are removed 
Hive,WITHOUT_CLASSIFICATION,//  check that hook to disable transforms has been added 
Hive,WITHOUT_CLASSIFICATION,//  2.5 and later way of finding sasl property 
Hive,WITHOUT_CLASSIFICATION,//  Pass job to initialize metastore conf overrides for embedded metastore case   (hive.metastore.uris = ""). 
Hive,WITHOUT_CLASSIFICATION,//  If table is null on either of these then they are claiming to   lock the whole database and we need to check it.  Otherwise 
Hive,WITHOUT_CLASSIFICATION,//  Ignore all the other events; logged above. 
Hive,WITHOUT_CLASSIFICATION,//  By default TezSessionPoolManager handles this for both pool and non-pool session. 
Hive,WITHOUT_CLASSIFICATION,//  Add the Hadoop token to the JobConf 
Hive,WITHOUT_CLASSIFICATION,//  Overlord and coordinator both run in same JVM. 
Hive,WITHOUT_CLASSIFICATION,//  Also dependent on the UDFExampleAdd class within that JAR. 
Hive,WITHOUT_CLASSIFICATION,//  If child is not a RexCall instance we can bail out 
Hive,WITHOUT_CLASSIFICATION,//  XXX: this could easily become a hot-spot 
Hive,WITHOUT_CLASSIFICATION,//  Non-empty java opts with -Xmx specified in MB 
Hive,WITHOUT_CLASSIFICATION,//  The following code should be gone after HIVE-11075 using topological order 
Hive,WITHOUT_CLASSIFICATION,//  set load server conf booleans to false 
Hive,WITHOUT_CLASSIFICATION,//  These represent the sorted columns 
Hive,WITHOUT_CLASSIFICATION,//  in presence of grouping sets we can't remove sq_count_check 
Hive,WITHOUT_CLASSIFICATION,//  Expr is built by DDLSA it should only contain part cols and simple ops 
Hive,WITHOUT_CLASSIFICATION,//  Now try to find the file based on SHA and name. Currently we require   exact name match.   We could also allow cutting off versions and other stuff provided that 
Hive,WITHOUT_CLASSIFICATION,// process hosts from which doAs requests are authorized 
Hive,WITHOUT_CLASSIFICATION,//  for now 
Hive,WITHOUT_CLASSIFICATION,//  multi-threaded file statuses and split strategy 
Hive,WITHOUT_CLASSIFICATION,//  This should now go fine since we increased the configured header size 
Hive,WITHOUT_CLASSIFICATION,/*  * An bytes key hash map optimized for vector map join. * * This is the abstract base for the multi-key and string bytes key hash map implementations.  */
Hive,WITHOUT_CLASSIFICATION,//  Only select operators among the allowed operators can cause changes in the   column names 
Hive,WITHOUT_CLASSIFICATION,//  In future this may examine WriteEntity and/or config to return   appropriate HCatWriter 
Hive,WITHOUT_CLASSIFICATION,//  get the next byte 
Hive,WITHOUT_CLASSIFICATION,//  Is there integer room above? 
Hive,WITHOUT_CLASSIFICATION,//  load multiple random sets of Long values 
Hive,WITHOUT_CLASSIFICATION,//  2. Build RelOptAbstractTable 
Hive,WITHOUT_CLASSIFICATION,//  MockResultSet 
Hive,WITHOUT_CLASSIFICATION,//  Note that while this is an improvement over static initialization it is still not   technically valid cause nothing prevents us from connecting to several metastores in 
Hive,WITHOUT_CLASSIFICATION,//  Add this to the list of top operators - we always start from a table 
Hive,WITHOUT_CLASSIFICATION,//  Runtime.getRuntime().exec(wrappedCmdArgs); 
Hive,WITHOUT_CLASSIFICATION,//  verify that drops were replicated. This can either be from tables or ptns   not existing and thus throwing a NoSuchObjectException or returning nulls   or select * returning empty depending on what we're testing. 
Hive,WITHOUT_CLASSIFICATION,//  map-side aggregation should reduce the entries by at-least half 
Hive,WITHOUT_CLASSIFICATION,//  If this partition's set of columns is the same as the parent table's   use the parent table's so we do not create a duplicate column descriptor   thereby saving space 
Hive,WITHOUT_CLASSIFICATION,//  order of forwarded ips per X-Forwarded-For http spec (client proxy1 proxy2) 
Hive,WITHOUT_CLASSIFICATION,//  Special cases for ORC   We need to check table properties to see if a couple of parameters   such as compression parameters are defined. If they are then we copy   them to job properties so that it will be available in jobconf at runtime   See HIVE-5504 for details 
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.llap.plugin.rpc.LlapPluginProtocolProtos.UpdateQueryResponseProto.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,//  Although an instance of ObjectStore is accessed by one thread there may   be many threads with ObjectStore instances. So the static variables   pmf and prop need to be protected with locks. 
Hive,WITHOUT_CLASSIFICATION,//  Set insiderView so that we can skip the column authorization for this. 
Hive,WITHOUT_CLASSIFICATION,//  Check the location of the result partition. It should be located in the destination table 
Hive,WITHOUT_CLASSIFICATION,//  if no entries were added via conf we initiate our defaults 
Hive,WITHOUT_CLASSIFICATION,//  SQL standard - return null for zero or one elements 
Hive,WITHOUT_CLASSIFICATION,/*    * This method is invoked for unqualified column references in join conditions.   * This is passed in the Alias to Operator mapping in the QueryBlock so far.   * We try to resolve the unqualified column against each of the Operator Row Resolvers.   * - if the column is present in only one RowResolver we treat this as a reference to   *   that Operator.   * - if the column resolves with more than one RowResolver we treat it as an Ambiguous   *   reference.   * - if the column doesn't resolve with any RowResolver we treat this as an Invalid   *   reference.    */
Hive,WITHOUT_CLASSIFICATION,//  Verify no more invocations in case of success. 
Hive,WITHOUT_CLASSIFICATION,//  The total size of local tables may not be under   the limit after we merge mapJoinLocalWork and childLocalWork.   Do not merge. 
Hive,WITHOUT_CLASSIFICATION,// This means that the derived colAlias collides with existing ones. 
Hive,WITHOUT_CLASSIFICATION,//  Add the left hand side of the IN clause which contains the struct definition. 
Hive,WITHOUT_CLASSIFICATION,//  This can be relaxed in the future if there is a requirement. 
Hive,WITHOUT_CLASSIFICATION,//  Return true if this is a custom UDF or custom GenericUDF. 
Hive,WITHOUT_CLASSIFICATION,//  scalar/column IF 
Hive,WITHOUT_CLASSIFICATION,//  1. Trigger transformation 
Hive,WITHOUT_CLASSIFICATION,//  Then non-finishable must always precede finishable. 
Hive,WITHOUT_CLASSIFICATION,/*  Required to build against 0.23 Reporter and StatusReporter.  */
Hive,WITHOUT_CLASSIFICATION,//  3. Insert another row to newly-converted ACID table 
Hive,WITHOUT_CLASSIFICATION,/*    * Lookup an long in the hash map.   *   * @param key   *         The long key.   * @param hashMapResult   *         The object to receive small table value(s) information on a MATCH.   *         Or for SPILL it has information on where to spill the big table row.   *   * @return   *         Whether the lookup was a match no match or spilled (the partition with the key   *         is currently spilled).    */
Hive,WITHOUT_CLASSIFICATION,//  Lets see if this constant was folded because of optimization. 
Hive,WITHOUT_CLASSIFICATION,/*    * now a Column can have an alternate mapping.   * This captures the alternate mapping.   * The primary(first) mapping is still only held in   * invRslvMap.    */
Hive,WITHOUT_CLASSIFICATION,//  If the input table is bucketed choose the first bucket 
Hive,WITHOUT_CLASSIFICATION,//  Create an empty database to load 
Hive,WITHOUT_CLASSIFICATION,//  Validation has limited evaluatorInputExprNodeDescLists to size 1. 
Hive,WITHOUT_CLASSIFICATION,//  t1-> 1 entry and t2-> 2 entries (1 per partition) 
Hive,WITHOUT_CLASSIFICATION,//  Since skew join optimization makes a copy of the tree above joins and   there is no multi-query optimization in place let us not use skew join   optimizations for now. 
Hive,WITHOUT_CLASSIFICATION,// For now assume no partition may have > 10M files.  Perhaps better to count them. 
Hive,WITHOUT_CLASSIFICATION,/*    * Verify table for Key: byte[] x Hash Table: HashSet    */
Hive,WITHOUT_CLASSIFICATION,/*  Handle default case for isRepeating setting for output. This will be set to true     * later in the special cases where that is necessary.      */
Hive,WITHOUT_CLASSIFICATION,//  Used by serialization only 
Hive,WITHOUT_CLASSIFICATION,//  1. Create RS and backtrack Select operator on top 
Hive,WITHOUT_CLASSIFICATION,//  Explicit pool specification - invalid - there's no mapping that matches. 
Hive,WITHOUT_CLASSIFICATION,//  we convert the databaseNameOrPattern to lower case because events will have these names in lower case. 
Hive,WITHOUT_CLASSIFICATION,//  Part of lowest word survives. 
Hive,WITHOUT_CLASSIFICATION,//  get the key and value 
Hive,WITHOUT_CLASSIFICATION,//  test when second argument has nulls and repeats 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise for each child run this method recursively 
Hive,WITHOUT_CLASSIFICATION,//  drop table and check that trash works 
Hive,WITHOUT_CLASSIFICATION,//  Ordered columns are the output columns. 
Hive,WITHOUT_CLASSIFICATION,//  So far we have all the data from the beginning of the part. 
Hive,WITHOUT_CLASSIFICATION,/*  Not all messages are parametrized even those that should have been e.g {@link #INVALID_TABLE}.     INVALID_TABLE is usually used with {@link #getMsg(String)}.     This method can also be used with INVALID_TABLE and the like and will match getMsg(String) behavior.     Another example: {@link #INVALID_PARTITION}.  Ideally you want the message to have 2 parameters one for     partition name one for table name.  Since this is already defined w/o any parameters one can still call     {@code INVALID_PARTITION.format("<partName> <table Name>"}.  This way the message text will be slightly     different but at least the errorCode will match.  Note this should not be abused by adding anything other     than what should have been parameter names to keep msg text standardized.      */
Hive,WITHOUT_CLASSIFICATION,//  There should be no residual since we already negotiated that earlier in   HBaseStorageHandler.decomposePredicate. However with hive.optimize.index.filter   OpProcFactory#pushFilterToStorageHandler pushes the original filter back down again.   Since pushed-down filters are not omitted at the higher levels (and thus the   contract of negotiation is ignored anyway) just ignore the residuals.   Re-assess this when negotiation is honored and the duplicate evaluation is removed.   THIS IGNORES RESIDUAL PARSING FROM HBaseStorageHandler#decomposePredicate 
Hive,WITHOUT_CLASSIFICATION,//  This is the Job Tracker URL 
Hive,WITHOUT_CLASSIFICATION,/*      * Finally write out the pieces (sign power digits)      */
Hive,WITHOUT_CLASSIFICATION,//  captured by WritableComparableHiveObject.hashCode() function. 
Hive,WITHOUT_CLASSIFICATION,//  Parse the rewritten query string 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * This provides a LazyBoolean like class which can be initialized from data stored in a   * binary format.   *   * @see org.apache.hadoop.hive.serde2.lazy.LazyObject#init   *        (org.apache.hadoop.hive.serde2.lazy.ByteArrayRef int int)    */
Hive,WITHOUT_CLASSIFICATION,//  only one bucket file 
Hive,WITHOUT_CLASSIFICATION,// important to remove after unlock() in case it fails 
Hive,WITHOUT_CLASSIFICATION,//  There's no buffer and another move is reserving this. 
Hive,WITHOUT_CLASSIFICATION,//  Skip the 0th column that is the root structure. 
Hive,WITHOUT_CLASSIFICATION,//  Find out number of partitions for each small table (should be same across tables) 
Hive,WITHOUT_CLASSIFICATION,//  double IN 
Hive,WITHOUT_CLASSIFICATION,//  3) Add the expressions that correspond to the aggregation 
Hive,WITHOUT_CLASSIFICATION,//  binary join   n-way join first (biggest) small table   We unconditionally create a hashmap for the first hash partition 
Hive,WITHOUT_CLASSIFICATION,/*    * Sets the job state to FAILED. Returns true if FAILED status is set.   * Otherwise it returns false.    */
Hive,WITHOUT_CLASSIFICATION,//  finally add a project to project out the 1st column 
Hive,WITHOUT_CLASSIFICATION,//  Column stats in hiveColStats might not be in the same order as the columns in   nonPartColNamesThatRqrStats. reorder hiveColStats so we can build hiveColStatsMap   using nonPartColIndxsThatRqrStats as below 
Hive,WITHOUT_CLASSIFICATION,//  required string fragment_id = 1; 
Hive,WITHOUT_CLASSIFICATION,//  Make sure the partitions directory is not in hdfs. 
Hive,WITHOUT_CLASSIFICATION,//  Primary entry point is a factory method instead of ctor 
Hive,WITHOUT_CLASSIFICATION,//  Lock states 
Hive,WITHOUT_CLASSIFICATION,//  causing it to not sort the entire table due to not knowing how selective the filter is. 
Hive,WITHOUT_CLASSIFICATION,//  If there's no pending fragments queue some of the cleanup for a later point - locks log rolling. 
Hive,WITHOUT_CLASSIFICATION,//  deep copy a new mapred work 
Hive,WITHOUT_CLASSIFICATION,//  shared_read 
Hive,WITHOUT_CLASSIFICATION,//  Add another db via ObjectStore 
Hive,WITHOUT_CLASSIFICATION,//  tinyint 
Hive,WITHOUT_CLASSIFICATION,//  Now try with hive/_HOST principal 
Hive,WITHOUT_CLASSIFICATION,//  11 primitive1 fields 2 refs above with alignment 
Hive,WITHOUT_CLASSIFICATION,//  projRel 
Hive,WITHOUT_CLASSIFICATION,//  If something happened and we were not able to rename the temp file attempt to remove it 
Hive,WITHOUT_CLASSIFICATION,//  Try to fold if it is a constant expression 
Hive,WITHOUT_CLASSIFICATION,/*  one second before and after  */
Hive,WITHOUT_CLASSIFICATION,//  Strings test 
Hive,WITHOUT_CLASSIFICATION,//  add to list of running jobs to kill in case of abnormal shutdown 
Hive,WITHOUT_CLASSIFICATION,//  Indicates if this instance of beeline is running in compatibility mode or beeline mode 
Hive,WITHOUT_CLASSIFICATION,// dirs 1/ 2/ 3/ 
Hive,WITHOUT_CLASSIFICATION,//  Parse numrecords to an integer 
Hive,WITHOUT_CLASSIFICATION,//  A type timestamp (TimestampColumnVector) minus a type timestamp produces a 
Hive,WITHOUT_CLASSIFICATION,//  close the reader for this entry 
Hive,WITHOUT_CLASSIFICATION,//  if above returned a null then the db does not exist - probably a   "drop database if exists" clause - don't try to authorize then. 
Hive,WITHOUT_CLASSIFICATION,//  2. Get RexNodes for original Projections from below 
Hive,WITHOUT_CLASSIFICATION,//  Dropping by expressions. 
Hive,WITHOUT_CLASSIFICATION,//  We do not call endGroup on operators below because we are batching rows in   an output batch and the semantics will not work.   super.endGroup(); 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#releaseSavepoint(java.sql.Savepoint)    */
Hive,WITHOUT_CLASSIFICATION,//  column pruner 
Hive,WITHOUT_CLASSIFICATION,/*  system defaults (usually 3-replica disk)  */
Hive,WITHOUT_CLASSIFICATION,//  if the username is not already available in the URL add the one provided 
Hive,WITHOUT_CLASSIFICATION,//  Throw away lowest word. 
Hive,WITHOUT_CLASSIFICATION,//  The accessed columns of query 
Hive,WITHOUT_CLASSIFICATION,//  try the repeating case 
Hive,WITHOUT_CLASSIFICATION,//  Save the original selected vector 
Hive,WITHOUT_CLASSIFICATION,//  Assume including everything means the VRB will have everything.   TODO: this is rather brittle esp. in view of schema evolution (in abstract not as          currently implemented in Hive). The compile should supply the columns it expects         to see which is not "all of any schema". Is VRB row CVs the right mechanism         for that? Who knows. Perhaps resolve in schema evolution v2. 
Hive,WITHOUT_CLASSIFICATION,//  QUERY_ID 
Hive,WITHOUT_CLASSIFICATION,//  Make sure we can actually get a session still - parallelism/etc. should not be affected. 
Hive,WITHOUT_CLASSIFICATION,//  test LastColumnTakesRest 
Hive,WITHOUT_CLASSIFICATION,/*      * Generate a floating-point number that represents the exponent.     * Do this by processing the exponent one bit at a time to combine     * many powers of 2 of 10. Then combine the exponent with the     * fraction.      */
Hive,WITHOUT_CLASSIFICATION,//  The (pool-sized) list is being fully drained. 
Hive,WITHOUT_CLASSIFICATION,//  remove the pwd from conf file so that job tracker doesn't show this 
Hive,WITHOUT_CLASSIFICATION,//  We can't eliminate stripes if there are deltas because the   deltas may change the rows making them match the predicate. todo: See HIVE-14516. 
Hive,WITHOUT_CLASSIFICATION,//  Validate the first parameter which is the expression to compute over. This should be an   array of strings type or an array of arrays of strings. 
Hive,WITHOUT_CLASSIFICATION,//  Sort the files 
Hive,WITHOUT_CLASSIFICATION,//  Patch the optimized query back into original FROM clause. 
Hive,WITHOUT_CLASSIFICATION,//  uses default TZ 
Hive,WITHOUT_CLASSIFICATION,//  to store the partitions that are currently being processed 
Hive,WITHOUT_CLASSIFICATION,//  Create initialize and test the SerDe 
Hive,WITHOUT_CLASSIFICATION,//  \N or -1 (allow latter) 
Hive,WITHOUT_CLASSIFICATION,//  Map of dbName.TblName -> TSOperator 
Hive,WITHOUT_CLASSIFICATION,//  Union (extra fields) 
Hive,WITHOUT_CLASSIFICATION,/*    * Increased visibility of this method is only for providing better test coverage    */
Hive,WITHOUT_CLASSIFICATION,//  Check that the directory is created 
Hive,WITHOUT_CLASSIFICATION,//  for the UDTF operator 
Hive,WITHOUT_CLASSIFICATION,//  create formatter that includes all of the input patterns 
Hive,WITHOUT_CLASSIFICATION,/*  10 files x 1000 size for 11 splits  */
Hive,WITHOUT_CLASSIFICATION,//  additional bits to pad long array to block size 
Hive,WITHOUT_CLASSIFICATION,//  setup list of conf vars that are not allowed to change runtime 
Hive,WITHOUT_CLASSIFICATION,//  We can continue 
Hive,WITHOUT_CLASSIFICATION,//  is actually available for execution and will not potentially result in a RejectedExecution 
Hive,WITHOUT_CLASSIFICATION,//  for use as wildcard pattern to test LIKE 
Hive,WITHOUT_CLASSIFICATION,//  If there is a materialized view update desc we create introduce it at the end   of the tree. 
Hive,WITHOUT_CLASSIFICATION,//  add user metadata to footer in case of any 
Hive,WITHOUT_CLASSIFICATION,//  the path used above should not be used on a second try as each dump request is written to a unique location.   however if we want to keep the dump location clean we might want to delete the paths 
Hive,WITHOUT_CLASSIFICATION,//  Larger allocations will be special-cased and will not use the normal buffer.   buffer/nextFree will be set to a newly allocated array just for the current row. 
Hive,WITHOUT_CLASSIFICATION,//  used in the join(as field access). 
Hive,WITHOUT_CLASSIFICATION,//  transform the operator tree 
Hive,WITHOUT_CLASSIFICATION,//  For PARTIAL1 and COMPLETE: ObjectInspectors for original data 
Hive,WITHOUT_CLASSIFICATION,//  difference from standard File Appender:   locking is not supported and buffering cannot be switched off 
Hive,WITHOUT_CLASSIFICATION,//  Check and transform group by *. This will only happen for select distinct *.   Here the "genSelectPlan" is being leveraged.   The main benefits are (1) remove virtual columns that should   not be included in the group by; (2) add the fully qualified column names to unParseTranslator   so that view is supported. The drawback is that an additional SEL op is added. If it is   not necessary it will be removed by NonBlockingOpDeDupProc Optimizer because it will match 
Hive,WITHOUT_CLASSIFICATION,//  Remove all the entries from the parameters which are added by repl tasks internally. 
Hive,WITHOUT_CLASSIFICATION,//  Nothing to process. 
Hive,WITHOUT_CLASSIFICATION,//  The heap over the keys storing indexes in the array. 
Hive,WITHOUT_CLASSIFICATION,// do this before next update so that delte_delta is properly sorted 
Hive,WITHOUT_CLASSIFICATION,//  Set of GenericUDFs which require need implicit type casting of decimal parameters.   Vectorization for mathmatical functions currently depends on decimal params automatically   being converted to the return type (see getImplicitCastExpression()) which is not correct 
Hive,WITHOUT_CLASSIFICATION,// start a 2nd (overlapping) txn 
Hive,WITHOUT_CLASSIFICATION,//  child 3 is the optional constraint 
Hive,WITHOUT_CLASSIFICATION,//  found no files under a sub-directory under table base path; it is possible that the table   is empty and hence there are no partition sub-directories created under base path 
Hive,WITHOUT_CLASSIFICATION,//  check all elements are contained in g 
Hive,WITHOUT_CLASSIFICATION,//  same but repeating input is not null 
Hive,WITHOUT_CLASSIFICATION,/*        * The Vectorized Input File Format reader is responsible for setting the partition column       * values resetting and filling in the batch etc.        */
Hive,WITHOUT_CLASSIFICATION,// if here then we must be compacting 
Hive,WITHOUT_CLASSIFICATION,//  Insert the records in DB to simulate a hive table 
Hive,WITHOUT_CLASSIFICATION,//  Update the memory monitor info for LLAP. 
Hive,WITHOUT_CLASSIFICATION,// looking for map 100% reduce 100% 
Hive,WITHOUT_CLASSIFICATION,//  ascii string 
Hive,WITHOUT_CLASSIFICATION,/*      * 4. give Evaluator chance to setup for Output execution; setup Output shape.      */
Hive,WITHOUT_CLASSIFICATION,//  frac >= tezMaxReserveFraction 
Hive,WITHOUT_CLASSIFICATION,/* schema  */
Hive,WITHOUT_CLASSIFICATION,//  2^56 * 2^56 - 1 
Hive,WITHOUT_CLASSIFICATION,/*    * Attempts to make a connection using default HS2 connection config file if available   * if there connection is not made return false   *    */
Hive,WITHOUT_CLASSIFICATION,//  Tracks running fragments and completing fragments.   Completing since we have a race in the AM being notified and the task actually 
Hive,WITHOUT_CLASSIFICATION,//  Pass false for canRetainByteRef since we will NOT be keeping byte references to the input   bytes with the BytesColumnVector.setRef method. 
Hive,WITHOUT_CLASSIFICATION,//  User specified perms in invalid format. 
Hive,WITHOUT_CLASSIFICATION,//  configurations are always published to ServiceRecord. Read/apply configs to JDBC connection params 
Hive,WITHOUT_CLASSIFICATION,//  we always remove the condition by replacing it with "true" 
Hive,WITHOUT_CLASSIFICATION,//  couldn't find proper parent column expr 
Hive,WITHOUT_CLASSIFICATION,/*    * Returns the number of children on the stack in the current node scope.    */
Hive,WITHOUT_CLASSIFICATION,//  since local mode only runs with 1 reducers - make sure that the 
Hive,WITHOUT_CLASSIFICATION,//  introduce RS and EX before FS. If the operator tree already contains 
Hive,WITHOUT_CLASSIFICATION,/*    * SHORT.    */
Hive,WITHOUT_CLASSIFICATION,// create RexSubQuery node 
Hive,WITHOUT_CLASSIFICATION,/*    * NOTE: The VectorGroupByDesc has already been allocated and will be updated here.    */
Hive,WITHOUT_CLASSIFICATION,//  execute the driver locally? 
Hive,WITHOUT_CLASSIFICATION,// r = 31 * r + hashCode(listOI.getListElement(o ii) elemOI); 
Hive,WITHOUT_CLASSIFICATION,//  override 
Hive,WITHOUT_CLASSIFICATION,// don't combine if inputformat is a SymlinkTextInputFormat 
Hive,WITHOUT_CLASSIFICATION,//  "Tez Merge File Work" will become "Tez Merge File.." 
Hive,WITHOUT_CLASSIFICATION,//  CHAIN pattern 
Hive,WITHOUT_CLASSIFICATION,//  Make sure big table BytesColumnVectors have room for string values in the overflow batch... 
Hive,WITHOUT_CLASSIFICATION,//  This is necessary as sometimes semantic analyzer's mapping is different than operator's own alias. 
Hive,WITHOUT_CLASSIFICATION,//        for TOK_JOIN and TOK_FULLOUTERJOIN. 
Hive,WITHOUT_CLASSIFICATION,//  keep record all the input path for this alias 
Hive,WITHOUT_CLASSIFICATION,//  session vars 
Hive,WITHOUT_CLASSIFICATION,//  Whether any of the node outputs is unknown   Whether all of the node outputs are divided 
Hive,WITHOUT_CLASSIFICATION,//  Member variables 
Hive,WITHOUT_CLASSIFICATION,//  start exclusive to infinity inclusive 
Hive,WITHOUT_CLASSIFICATION,// traverse the given node to find all correlated variables   Note that correlated variables are supported in Filter only i.e. Where & Having 
Hive,WITHOUT_CLASSIFICATION,//  Initialize the first value in the delete reader. 
Hive,WITHOUT_CLASSIFICATION,// the first "split" is for base/ 
Hive,WITHOUT_CLASSIFICATION,//  set the regular provided qualifier names 
Hive,WITHOUT_CLASSIFICATION,//  This file is unknown to metastore. 
Hive,WITHOUT_CLASSIFICATION,//  create map join task and set big table as i 
Hive,WITHOUT_CLASSIFICATION,//  filter out the deleted records 
Hive,WITHOUT_CLASSIFICATION,//  Infer column stats state 
Hive,WITHOUT_CLASSIFICATION,//  Look for functions with empty pattern 
Hive,WITHOUT_CLASSIFICATION,//  whether any ACID table or Insert-only (mm) table is involved in a query 
Hive,WITHOUT_CLASSIFICATION,//  Lifted from org.apache.hadoop.util.hash.MurmurHash... but supports offset. 
Hive,WITHOUT_CLASSIFICATION,//  See Marker class comment. 
Hive,WITHOUT_CLASSIFICATION,//  We for these input with exponents we have at this point an intermediate decimal   an exponent power and a result:                         intermediate     input               decimal      exponent        result   701E+1            701 scale 0        +1            7010 scale 0   3E+4              3 scale 0          +4               3 scale 0   3.223E+9          3.223 scale 3      +9      3223000000 scale 0   0.009E+10         0.009 scale 4      +10       90000000 scale 0   0.3221E-2         0.3221 scale 4     -2               0.003221 scale 6   0.00223E-20       0.00223 scale 5    -20              0.0000000000000000000000223 scale 25   
Hive,WITHOUT_CLASSIFICATION,//  Sum all non-null decimal column values; maintain isGroupResultNull. 
Hive,WITHOUT_CLASSIFICATION,//  optional string aString = 2; 
Hive,WITHOUT_CLASSIFICATION,//  any of condition contains non-NS non-NS 
Hive,WITHOUT_CLASSIFICATION,/*    * close will move the temp files into the right place for the fetch   * task. If the job has failed it will clean up the files.    */
Hive,WITHOUT_CLASSIFICATION,//  Set other configurationOverlay parameters 
Hive,WITHOUT_CLASSIFICATION,/*      * We build up the Value Reference Word we will return that will be kept by the caller.      */
Hive,WITHOUT_CLASSIFICATION,//  reset defaults 
Hive,WITHOUT_CLASSIFICATION,//  If any of the children contains null then return a null 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: Currently read variations only apply to top level data types... 
Hive,WITHOUT_CLASSIFICATION,//  INVALID_WRITE_IDS 
Hive,WITHOUT_CLASSIFICATION,/*  first_name <> 'sue'  */
Hive,WITHOUT_CLASSIFICATION,//  be able to acquire the lock and finish successfully 
Hive,WITHOUT_CLASSIFICATION,//  Add shutdown hook. 
Hive,WITHOUT_CLASSIFICATION,//  2^32 -- needs 2 32 bit words 
Hive,WITHOUT_CLASSIFICATION,//  table is sampled. In some situation we really can leverage row   limit. In order to be safe we do not use it now. 
Hive,WITHOUT_CLASSIFICATION,//  this transformation needs to be first because it changes the work item itself. 
Hive,WITHOUT_CLASSIFICATION,/*      * This batch is used by vector/row deserializer readers.      */
Hive,WITHOUT_CLASSIFICATION,// Futureproofing: the parser will actually not allow this 
Hive,WITHOUT_CLASSIFICATION,// cleanup just in case something is left over from previous run 
Hive,WITHOUT_CLASSIFICATION,//  USER_DEFINED_TYPE_ENTRY 
Hive,WITHOUT_CLASSIFICATION,// ========================== 40000 range starts here ========================// 
Hive,WITHOUT_CLASSIFICATION,//  In case this has not been initialized elsewhere. 
Hive,WITHOUT_CLASSIFICATION,//  test for double type 
Hive,WITHOUT_CLASSIFICATION,//  the aliases that are allowed to map to a null scan. 
Hive,WITHOUT_CLASSIFICATION,//  Only this table has spilled big table rows 
Hive,WITHOUT_CLASSIFICATION,// <<<<<<< HEAD 
Hive,WITHOUT_CLASSIFICATION,// following matcher.group() would fail anyway and we don't want to skip files since that  may be a data loss scenario 
Hive,WITHOUT_CLASSIFICATION,// run Worker to execute compaction 
Hive,WITHOUT_CLASSIFICATION,//  We may not have an active resource plan in the start. 
Hive,WITHOUT_CLASSIFICATION,//  Restore the settings 
Hive,WITHOUT_CLASSIFICATION,/*      * Now suck up the digits in the mantissa.  Use two integers to     * collect 9 digits each (this is faster than using floating-point).     * If the mantissa has more than 18 digits ignore the extras since     * they can't affect the value anyway.      */
Hive,WITHOUT_CLASSIFICATION,//  America/Los_Angeles DST dates - 2015-03-08 02:00:00/2015-11-01 02:00:00 
Hive,WITHOUT_CLASSIFICATION,//  corresponding to the input file is stored to name the output bucket file appropriately. 
Hive,WITHOUT_CLASSIFICATION,//  No rows? 
Hive,WITHOUT_CLASSIFICATION,//  serialize some data in the schema after it is altered. 
Hive,WITHOUT_CLASSIFICATION,//  in theory the below call isn't needed in non thrift_mode but let's not 
Hive,WITHOUT_CLASSIFICATION,//  fetchColumns is not called because we had no columns to fetch 
Hive,WITHOUT_CLASSIFICATION,/*      * A note on retries.     *     * We've configured a total of 4 attempts.     * 5 - 4 == 1 connect failure simulation count left after this.      */
Hive,WITHOUT_CLASSIFICATION,//  delete a dependency only if no other resource depends on it. 
Hive,WITHOUT_CLASSIFICATION,//  NUM_BUCKETS 
Hive,WITHOUT_CLASSIFICATION,//  Close the PipedOutputStream before we close the outermost OutputStream. 
Hive,WITHOUT_CLASSIFICATION,//  The EXPLAIN VECTORIZATION option was specified. 
Hive,WITHOUT_CLASSIFICATION,/*    * If hive job credential provider is set but HIVE_JOB_CREDSTORE_PASSWORD is not set use   * HADOOP_CREDSTORE_PASSWORD in the jobConf    */
Hive,WITHOUT_CLASSIFICATION,//  genGroupByPlanMapAggrNoSkew 
Hive,WITHOUT_CLASSIFICATION,// https://dev.mysql.com/doc/refman/5.0/en/select.html 
Hive,WITHOUT_CLASSIFICATION,//  Set a scratch dir permission 
Hive,WITHOUT_CLASSIFICATION,//  Test EventUtils.getDbTblNotificationFilter - this is supposed to restrict   events to those that match the dbname and tblname provided to the filter.   If the tblname passed in to the filter is null then it restricts itself 
Hive,WITHOUT_CLASSIFICATION,//  Single-Column String hash table import. 
Hive,WITHOUT_CLASSIFICATION,//  there is a valid bucket pruning filter 
Hive,WITHOUT_CLASSIFICATION,//  Test an invalid case with multiple versions 
Hive,WITHOUT_CLASSIFICATION,/*  predicate is not deterministic  */
Hive,WITHOUT_CLASSIFICATION,//  We could not parse the view 
Hive,WITHOUT_CLASSIFICATION,//  Need to explicitly update ProxyUsers 
Hive,WITHOUT_CLASSIFICATION,//  the begin the real elements 
Hive,WITHOUT_CLASSIFICATION,/*      * Look at evaluator to get output type info.      */
Hive,WITHOUT_CLASSIFICATION,//  Retry from same dump when the database is empty is also not allowed. 
Hive,WITHOUT_CLASSIFICATION,//  Happens due to AM side pre-emption or the AM asking for a task to die.   There's no hooks at the moment to get information over. 
Hive,WITHOUT_CLASSIFICATION,// check that we get the right files on disk 
Hive,WITHOUT_CLASSIFICATION,//  Try to put the most common first 
Hive,WITHOUT_CLASSIFICATION,/*          * This code is a modified version of BinarySortableSerDe.deserializeText that lets us         * detect if we can return a reference to the bytes directly.          */
Hive,WITHOUT_CLASSIFICATION,//  Retry with same dump with which it was already loaded also fails. 
Hive,WITHOUT_CLASSIFICATION,//  2. Restart pool sessions. 
Hive,WITHOUT_CLASSIFICATION,//  should already be true 
Hive,WITHOUT_CLASSIFICATION,//  for these positions some variable primitive type (String) is used so size 
Hive,WITHOUT_CLASSIFICATION,//  Allow only keys that start with hive.* hdfs.* mapred.* for security   i.e. don't allow access to db password 
Hive,WITHOUT_CLASSIFICATION,//  hope this is respected properly 
Hive,WITHOUT_CLASSIFICATION,//  Verify that cleanNotificationEvents() cleans up all old notifications 
Hive,WITHOUT_CLASSIFICATION,//  when renaming a partition we should update   1) partition SD Location   2) partition column stats if there are any because of part_name field in HMS table PART_COL_STATS 
Hive,WITHOUT_CLASSIFICATION,//  the nanosecond part fits in 30 bits 
Hive,WITHOUT_CLASSIFICATION,//  Not used yet - since the Writable RPC engine does not support this policy. 
Hive,WITHOUT_CLASSIFICATION,//  public Long rdatetimeepoch; // The format Hive understands by default 
Hive,WITHOUT_CLASSIFICATION,//  SR.SW.acquired Lock we are examining is acquired;  We can acquire   because a read can share with a write and there must be 
Hive,WITHOUT_CLASSIFICATION,//  -1 means that there is no stats 
Hive,WITHOUT_CLASSIFICATION,//  blank " " (1 byte)   RING ABOVE U+02DA (2 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  reload if DS related configuration is changed 
Hive,WITHOUT_CLASSIFICATION,//  tests whether the RS needs automatic setting parallelism 
Hive,WITHOUT_CLASSIFICATION,//  Save the info that is required at query time to resolve dynamic/runtime values. 
Hive,WITHOUT_CLASSIFICATION,//  add a struct 
Hive,WITHOUT_CLASSIFICATION,//  We always need the base row 
Hive,WITHOUT_CLASSIFICATION,// SQLState for cancel operation 
Hive,WITHOUT_CLASSIFICATION,//  Generate the aggregate B (see the reference example above) 
Hive,WITHOUT_CLASSIFICATION,//  union consisted on a bunch of map-reduce jobs and it has been split at   the union 
Hive,WITHOUT_CLASSIFICATION,//  This is either an alter table add foreign key or add primary key command. 
Hive,WITHOUT_CLASSIFICATION,//  For unregistered patterns fail. 
Hive,WITHOUT_CLASSIFICATION,//  Class members for cookie based authentication. 
Hive,WITHOUT_CLASSIFICATION,//  Verify that the sourceTable was created successfully. 
Hive,WITHOUT_CLASSIFICATION,//  Do not allow embedded metastore in LLAP unless we are in test. 
Hive,WITHOUT_CLASSIFICATION,// todo: api changed in 3.0 
Hive,WITHOUT_CLASSIFICATION,//  We haven't processed all the parent sinks and we need   them to be done in order to compute the parallelism for this sink.   In this case skip. We should visit this again from another path. 
Hive,WITHOUT_CLASSIFICATION,// ? is Type - when implemented 
Hive,WITHOUT_CLASSIFICATION,//  jobConf will hold all the configuration for hadoop tez and hive 
Hive,WITHOUT_CLASSIFICATION,//  multiple hash tables with Hybrid Grace partitioning. 
Hive,WITHOUT_CLASSIFICATION,//  has to be a separate first step because we don't set the default values in the config object. 
Hive,WITHOUT_CLASSIFICATION,/*  Get the small table key/value container  */
Hive,WITHOUT_CLASSIFICATION,//  limit = 0 means that we do not need any task. 
Hive,WITHOUT_CLASSIFICATION,//  As we said before here we use genSelectLogicalPlan to rewrite AllColRef 
Hive,WITHOUT_CLASSIFICATION,//  operator 
Hive,WITHOUT_CLASSIFICATION,// but there should be no more active calls. 
Hive,WITHOUT_CLASSIFICATION,//  Run worker. 
Hive,WITHOUT_CLASSIFICATION,//  parsing elements one by one 
Hive,WITHOUT_CLASSIFICATION,/*  Set List Bucketing context.  */
Hive,WITHOUT_CLASSIFICATION,//  Drop one database see what remains 
Hive,WITHOUT_CLASSIFICATION,//  estimated hash table size 
Hive,WITHOUT_CLASSIFICATION,//  Clear the value of sparkCloneConfiguration 
Hive,WITHOUT_CLASSIFICATION,//  Per JDBC spec the request defines a hint to the driver to enable database optimizations.   The read-only mode for this connection is disabled and cannot be enabled (isReadOnly always returns false). 
Hive,WITHOUT_CLASSIFICATION,//  Set to start + 10000 which is the timeout 
Hive,WITHOUT_CLASSIFICATION,//  match 
Hive,WITHOUT_CLASSIFICATION,//  though we clone the op tree we're still using the same MapWork/ReduceWork. 
Hive,WITHOUT_CLASSIFICATION,// generate ID so that we can make an entry in COMPLETED_COMPACTIONS 
Hive,WITHOUT_CLASSIFICATION,//  Comma-separated intervals without brackets 
Hive,WITHOUT_CLASSIFICATION,//  TCP Server 
Hive,WITHOUT_CLASSIFICATION,//  ReduceSinkMapJoinProc logic does not work unless the ReduceSink is connected as   a parent of the MapJoin but at this point we have already removed all of the   parents from the MapJoin. 
Hive,WITHOUT_CLASSIFICATION,//  We just return in that case no drop needed. 
Hive,WITHOUT_CLASSIFICATION,//  For Serialization only. 
Hive,WITHOUT_CLASSIFICATION,// now that we let Calcite process subqueries we might have more than one 
Hive,WITHOUT_CLASSIFICATION,//  GenericUDAF 
Hive,WITHOUT_CLASSIFICATION,//  Typical line length 
Hive,WITHOUT_CLASSIFICATION,/*      * user grants      */
Hive,WITHOUT_CLASSIFICATION,//  toDigitsOnlyBytes. 
Hive,WITHOUT_CLASSIFICATION,/*  skewed value.  */
Hive,WITHOUT_CLASSIFICATION,//  a child of TableScan so there is no need to push this predicate. 
Hive,WITHOUT_CLASSIFICATION,//  get the join keys from old parent ReduceSink operators 
Hive,WITHOUT_CLASSIFICATION,//  Create a Standard java object Inspector 
Hive,WITHOUT_CLASSIFICATION,//  test February of non-leap year 2/31 is viewd as 3/3 due to 3 days diff 
Hive,WITHOUT_CLASSIFICATION,//  It's a table alias.   We will process that later in DOT. 
Hive,WITHOUT_CLASSIFICATION,//  We flip the highest-order bit of the seven-byte representation of seconds to make negative   values come before positive ones. 
Hive,WITHOUT_CLASSIFICATION,//  should have a new root now 
Hive,WITHOUT_CLASSIFICATION,//  The result of the comparison of the last row processed 
Hive,WITHOUT_CLASSIFICATION,// restore the original HDFS root 
Hive,WITHOUT_CLASSIFICATION,// this is needed specifcally for Hive on Tez (in addition to 
Hive,WITHOUT_CLASSIFICATION,//  End SqlSumAggFunction.java 
Hive,WITHOUT_CLASSIFICATION,// ************************************************************************************************   Take Integer or Fractional Portion. 
Hive,WITHOUT_CLASSIFICATION,// other writeTypes related to DMLs 
Hive,WITHOUT_CLASSIFICATION,//  The digits must fit without rounding. 
Hive,WITHOUT_CLASSIFICATION,//  NAME_TO_TYPE_PTR 
Hive,WITHOUT_CLASSIFICATION,//  resFile 
Hive,WITHOUT_CLASSIFICATION,//  call the method recursively over all the internal fields of the given avro 
Hive,WITHOUT_CLASSIFICATION,//  1. Determine Join Type   TODO: What about TOK_CROSSJOIN TOK_MAPJOIN 
Hive,WITHOUT_CLASSIFICATION,//  After processing all the group's batches with evaluateGroupBatch is the non-streaming 
Hive,WITHOUT_CLASSIFICATION,//  With this map we project the big table batch to make it look like an output batch. 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) ConstValue  */
Hive,WITHOUT_CLASSIFICATION,//  decaying where the batchSize keeps reducing by half 
Hive,WITHOUT_CLASSIFICATION,//  Both are non null.   First compare the table names. 
Hive,WITHOUT_CLASSIFICATION,// required for HiveRelDecorrelator 
Hive,WITHOUT_CLASSIFICATION,//  The default works no bug. 
Hive,WITHOUT_CLASSIFICATION,//  propagate this change till the next RS 
Hive,WITHOUT_CLASSIFICATION,//  TODO : jackson-streaming-iterable-redo this 
Hive,WITHOUT_CLASSIFICATION,//  Different instance same value 
Hive,WITHOUT_CLASSIFICATION,//  Used for logDir failure messages etc. 
Hive,WITHOUT_CLASSIFICATION,//  We can merge 
Hive,WITHOUT_CLASSIFICATION,//  It should not be a materialized view 
Hive,WITHOUT_CLASSIFICATION,//  CM path itself is missing cannot recover from this error 
Hive,WITHOUT_CLASSIFICATION,//  required   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  store data 
Hive,WITHOUT_CLASSIFICATION,/*      * This TableScanDesc flag is strictly set by the Vectorizer class for vectorized MapWork     * vertices.      */
Hive,WITHOUT_CLASSIFICATION,// the ref must be a table so look for column name as right child of DOT 
Hive,WITHOUT_CLASSIFICATION,//  This map records such information 
Hive,WITHOUT_CLASSIFICATION,// JobSubmissionConstants.TOKEN_FILE_ARG_PLACEHOLDER) 
Hive,WITHOUT_CLASSIFICATION,//  query should pass and create the table 
Hive,WITHOUT_CLASSIFICATION,//  Finish the last query. 
Hive,WITHOUT_CLASSIFICATION,/*    * StreamingEval: wrap regular eval. on getNext remove first row from values   * and return it.    */
Hive,WITHOUT_CLASSIFICATION,//  Determine the length of storage for value and key lengths of the first record. 
Hive,WITHOUT_CLASSIFICATION,//  schema/counter name validation will be done in grammar as part of HIVE-17622 
Hive,WITHOUT_CLASSIFICATION,//  No writable needed for this data type. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure all the numbers are converted to long for size estimation. 
Hive,WITHOUT_CLASSIFICATION,// --------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  Replication done we need to check if the new property is added 
Hive,WITHOUT_CLASSIFICATION,//  only red qualifies and it's in entry 0 
Hive,WITHOUT_CLASSIFICATION,//  start with the keywrapper itself 
Hive,WITHOUT_CLASSIFICATION,//  EVENTS_COUNT 
Hive,WITHOUT_CLASSIFICATION,//  [-offline|--offline] 
Hive,WITHOUT_CLASSIFICATION,//  Compute knownPending tasks. selfAndUpstream indicates task counts for current vertex and 
Hive,WITHOUT_CLASSIFICATION,//  Should allocate since H2 is not known. 
Hive,WITHOUT_CLASSIFICATION,//  MAX_EVENTS 
Hive,WITHOUT_CLASSIFICATION,//  only remove MVs first 
Hive,WITHOUT_CLASSIFICATION,//  check if there is capacity in dest pool if so move else kill the session 
Hive,WITHOUT_CLASSIFICATION,//  if table and all partitions have the same schema and serde no need to convert 
Hive,WITHOUT_CLASSIFICATION,//  Return session to the pool; we can do it directly here. 
Hive,WITHOUT_CLASSIFICATION,//  DEFAULT_CONSTRAINTS 
Hive,WITHOUT_CLASSIFICATION,//  Test deprecated mapred.dfsclient.parallelism.max 
Hive,WITHOUT_CLASSIFICATION,// do some operations with new format 
Hive,WITHOUT_CLASSIFICATION,//  Lateral view AST has the following shape:   ^(TOK_LATERAL_VIEW     ^(TOK_SELECT ^(TOK_SELEXPR ^(TOK_FUNCTION Identifier params) identifier* tableAlias))) 
Hive,WITHOUT_CLASSIFICATION,//  knows where to look to compact. 
Hive,WITHOUT_CLASSIFICATION,//  reduce sink does not have any kids - since the plan by now has been   broken up into multiple   tasks iterate over all tasks.   For each task go over all operators recursively 
Hive,WITHOUT_CLASSIFICATION,//  must be different 
Hive,WITHOUT_CLASSIFICATION,// if destPath's parent path doesn't exist we should mkdir it 
Hive,WITHOUT_CLASSIFICATION,//  Since we remove reduce sink parents replace original expressions 
Hive,WITHOUT_CLASSIFICATION,//  Rejected 
Hive,WITHOUT_CLASSIFICATION,//  The following two are public for any external users who wish to use them. 
Hive,WITHOUT_CLASSIFICATION,//  Are we running tests? 
Hive,WITHOUT_CLASSIFICATION,//  -------rwx   ----rwx---   -rwx------   -rwxr-xr-x   -rwxrwxrwx   --wx------   -r-x------   -r-xr-xr-x 
Hive,WITHOUT_CLASSIFICATION,//  Don't timeout because of retry delay 
Hive,WITHOUT_CLASSIFICATION,//  We only support pattern matching via jdo since pattern matching in Java   might be different than the one used by the metastore backends 
Hive,WITHOUT_CLASSIFICATION,// compare schemes 
Hive,WITHOUT_CLASSIFICATION,//  Patterns that match the middle/end of stack traces 
Hive,WITHOUT_CLASSIFICATION,//  in strict mode in the presence of order by limit must be specified 
Hive,WITHOUT_CLASSIFICATION,//  Deny if this is black-list filter (excludeMatches = true) and it   matched or if this is whitelist filter and it didn't match 
Hive,WITHOUT_CLASSIFICATION,//  Small table indices has priority over retain. 
Hive,WITHOUT_CLASSIFICATION,//  if partSpec doesn't exists in DB return a delegate one   and the actual partition is created in MoveTask 
Hive,WITHOUT_CLASSIFICATION,/*      * Can the LazyBinary format really tolerate writing fewer columns?      */
Hive,WITHOUT_CLASSIFICATION,//  first try to get it from select 
Hive,WITHOUT_CLASSIFICATION,//  return null; 
Hive,WITHOUT_CLASSIFICATION,//  The extra parameters will be added on server side so check that the required ones are 
Hive,WITHOUT_CLASSIFICATION,/*        * A Windowing specification get added as a child to a UDAF invocation to distinguish it       * from similar UDAFs but on different windows.       * The UDAF is translated to a WindowFunction invocation in the PTFTranslator.       * So here we just return null for tokens that appear in a Window Specification.       * When the traversal reaches up to the UDAF invocation its ExprNodeDesc is build using the       * ColumnInfo in the InputRR. This is similar to how UDAFs are handled in Select lists.       * The difference is that there is translation for Window related tokens so we just       * return null;        */
Hive,WITHOUT_CLASSIFICATION,//  2. Collect Grouping Set info 
Hive,WITHOUT_CLASSIFICATION,//  attempts at execute will be made using batchsizes 11 3 1 throws retry exception 
Hive,WITHOUT_CLASSIFICATION,//  Create the layout for the queryId appender 
Hive,WITHOUT_CLASSIFICATION,//  LATIN SMALL LETTER TURNED A U+0250 (2 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  If it is a column reference we will try to resolve it 
Hive,WITHOUT_CLASSIFICATION,//  group them into the chunks we want 
Hive,WITHOUT_CLASSIFICATION,// Query using the hive command line 
Hive,WITHOUT_CLASSIFICATION,//  Expression for the operation. e.g. N^2 > 10 
Hive,WITHOUT_CLASSIFICATION,//  each table creation itself takes more than one task give we are giving a max of 1 we should hit multiple runs. 
Hive,WITHOUT_CLASSIFICATION,//  Check case insensitive search 
Hive,WITHOUT_CLASSIFICATION,//  Reset this before calling positionToFirst. 
Hive,WITHOUT_CLASSIFICATION,//  Pow(col P) and Power(col P) are special cases implemented separately from this template 
Hive,WITHOUT_CLASSIFICATION,//  The caller is responsible for destroying the session. 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: Previously we did OldHiveDecimal.setScale(scale) called OldHiveDecimal         unscaledValue().toByteArray(). 
Hive,WITHOUT_CLASSIFICATION,//  Execute -i init files (always in silent mode) 
Hive,WITHOUT_CLASSIFICATION,//  initialize source table/partition 
Hive,WITHOUT_CLASSIFICATION,//  For dynamic partitioned hash join run the ReduceSinkMapJoinProc logic for any 
Hive,WITHOUT_CLASSIFICATION,//  The hive key and bytes writable value needed to pass the key and value to the collector. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see javax.sql.CommonDataSource#getLoginTimeout()    */
Hive,WITHOUT_CLASSIFICATION,//  populate definedRestrictedSet with parameters defined in hive.conf.restricted.list 
Hive,WITHOUT_CLASSIFICATION,/*  * This class annotates each operator with its traits. The OpTraits class * specifies the traits that are populated for each operator.  */
Hive,WITHOUT_CLASSIFICATION,//  NOTE: Multi Insert is not supported 
Hive,WITHOUT_CLASSIFICATION,//  PARTNAME 
Hive,WITHOUT_CLASSIFICATION,// being acquired now 
Hive,WITHOUT_CLASSIFICATION,//  themap might be reused by the Protocol. 
Hive,WITHOUT_CLASSIFICATION,//  The char type info need to be set prior to initialization   and must be preserved when the plan serialized to other processes. 
Hive,WITHOUT_CLASSIFICATION,// fall through; doesn't map to Hive/Hcat type; here for completeness 
Hive,WITHOUT_CLASSIFICATION,//  If a union occurs before the sort-merge join it is not useful to convert the the   sort-merge join to a mapjoin. The number of inputs for the union is more than 1 so   it would be difficult to figure out the big table for the mapjoin. 
Hive,WITHOUT_CLASSIFICATION,//  selectivity(RS-3) = numRows(RS-3)/numRows(JOIN) * selectivity(JOIN) 
Hive,WITHOUT_CLASSIFICATION,//  4. See if all the field expressions of the left hand side of IN are expressions    containing constants or only partition columns coming from same table. 
Hive,WITHOUT_CLASSIFICATION,//  All the tables/partitions columns should be sorted in the same order   For example if tables A and B are being joined on columns c1 c2 and c3   which are the sorted and bucketed columns. The join would work as long 
Hive,WITHOUT_CLASSIFICATION,//  Note: fullFromMResroucePlan needs to be called inside the txn otherwise we could have         deduplicated this with getActiveMWMResourcePlan. 
Hive,WITHOUT_CLASSIFICATION,//  continue on to the next exprNode to find a match 
Hive,WITHOUT_CLASSIFICATION,/*          * Get our Single-Column Long hash map information for this specialized class.          */
Hive,WITHOUT_CLASSIFICATION,// MAPPING: bucket_file_name_in_big_table->{alias_table->corresonding_bucket_file_names} 
Hive,WITHOUT_CLASSIFICATION,//  Cap WriteBufferSize to avoid large preallocations   We also want to limit the size of writeBuffer because we normally have 16 partitions that 
Hive,WITHOUT_CLASSIFICATION,//  Do division/remainder to get lower binary word; quotient will either be middle decimal   or be both high and middle decimal that requires another division/remainder. 
Hive,WITHOUT_CLASSIFICATION,// return the current block's compressed key length 
Hive,WITHOUT_CLASSIFICATION,//  first row/call or a new partition 
Hive,WITHOUT_CLASSIFICATION,//  Ignore the struct column and just copy all the following data columns. 
Hive,WITHOUT_CLASSIFICATION,//  Counter may exceed limitation 
Hive,WITHOUT_CLASSIFICATION,//  add_table 
Hive,WITHOUT_CLASSIFICATION,//  Add rounding and handle carry. 
Hive,WITHOUT_CLASSIFICATION,//  testing acid usage when no masking/filtering is present 
Hive,WITHOUT_CLASSIFICATION,//  Multi-Key hash table import. 
Hive,WITHOUT_CLASSIFICATION,//  i.e. Overflow. 
Hive,WITHOUT_CLASSIFICATION,//  To be compatible with the OldHiveDecimal version zero has factor 1. 
Hive,WITHOUT_CLASSIFICATION,/*      * Get the HIVE counters     *     * HIVE     *  CREATED_FILES=1     *  DESERIALIZE_ERRORS=0     *  RECORDS_IN_Map_1=550076554     *  RECORDS_OUT_INTERMEDIATE_Map_1=854987     *  RECORDS_OUT_Reducer_2=1      */
Hive,WITHOUT_CLASSIFICATION,//  Otherwise load lazily via StorageHandler at query time. 
Hive,WITHOUT_CLASSIFICATION,//  FIXME 
Hive,WITHOUT_CLASSIFICATION,/*      * Basic algorithm:     *     * 1. Scale away fractional digits if present.     * 2. Clear integer rounding portion.     *      */
Hive,WITHOUT_CLASSIFICATION,//  Lookup values needed for numeric arithmetic UDFs 
Hive,WITHOUT_CLASSIFICATION,//  union type currently not totally supported. See HIVE-2390 
Hive,WITHOUT_CLASSIFICATION,//  max heap size 
Hive,WITHOUT_CLASSIFICATION,//  set output vector 
Hive,WITHOUT_CLASSIFICATION,//  get acl provider for most outer path that is non-null 
Hive,WITHOUT_CLASSIFICATION,//  The number of map reduce tasks executed by the HiveServer2 since the last restart 
Hive,WITHOUT_CLASSIFICATION,//  no distinct processing at the reducer   A query like 'select count(distinct key) from T' is transformed into 
Hive,WITHOUT_CLASSIFICATION,/*  Get the in memory hashmap  */
Hive,WITHOUT_CLASSIFICATION,//  compatibility mode enabled 
Hive,WITHOUT_CLASSIFICATION,//  Validate the second parameter which is either a solitary double or an array of doubles. 
Hive,WITHOUT_CLASSIFICATION,// this seems odd but we wan to make sure that to run CompactionTxnHandler.cleanEmptyAbortedTxns() 
Hive,WITHOUT_CLASSIFICATION,//  Note: this is backward compat only. Should be removed with createUnallocated. 
Hive,WITHOUT_CLASSIFICATION,//  a common base class or not. 
Hive,WITHOUT_CLASSIFICATION,//  check split 
Hive,WITHOUT_CLASSIFICATION,//  validate/fill-in scheme and authority. this follows logic   identical to FileSystem.get(URI conf) - but doesn't actually   obtain a file system handle 
Hive,WITHOUT_CLASSIFICATION,//  finally move recovered file to actual file 
Hive,WITHOUT_CLASSIFICATION,//  use the serialization option switch to write primitive values as either a variable   length UTF8 string or a fixed width bytes if serializing in binary format 
Hive,WITHOUT_CLASSIFICATION,//  Things we log in the jobconf 
Hive,WITHOUT_CLASSIFICATION,//  Must set this key even if differences is empty otherwise client and AM will attempt 
Hive,WITHOUT_CLASSIFICATION,//  First value for next column 
Hive,WITHOUT_CLASSIFICATION,// HIVE-16952 
Hive,WITHOUT_CLASSIFICATION,//  create a new setop whose children are the filters created above 
Hive,WITHOUT_CLASSIFICATION,//  KILLED or FAILED state 
Hive,WITHOUT_CLASSIFICATION,//  optional string value = 2; 
Hive,WITHOUT_CLASSIFICATION,//  always round down to the previous period (for timestamps prior to origin) 
Hive,WITHOUT_CLASSIFICATION,/*    * Tests if null value returned when file is not present in any of the lookup locations    */
Hive,WITHOUT_CLASSIFICATION,//  we can set the traits for this join operator 
Hive,WITHOUT_CLASSIFICATION,//  precision 6 
Hive,WITHOUT_CLASSIFICATION,//  If it is not a SEL operator we bail out 
Hive,WITHOUT_CLASSIFICATION,/*            * Optionally the next value's small length could be a 2nd integer...            */
Hive,WITHOUT_CLASSIFICATION,/*  * This is a pluggable policy to chose the candidate map-join table for converting a join to a * sort merge join. The largest table is chosen based on the size of the tables.  */
Hive,WITHOUT_CLASSIFICATION,/*          * Initialize Multi-Key members for this specialized class.          */
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) FieldValue  */
Hive,WITHOUT_CLASSIFICATION,//  Per MapObjectInpsector.getMapSize() -1 length means null map. 
Hive,WITHOUT_CLASSIFICATION,// Get fields out of the lazy struct and check if they match expected   results 
Hive,WITHOUT_CLASSIFICATION,//  we want to signal an error if the table/view doesn't exist and we're   configured not to fail silently 
Hive,WITHOUT_CLASSIFICATION,//  store column name in map-targetWork 
Hive,WITHOUT_CLASSIFICATION,//  precision 5 
Hive,WITHOUT_CLASSIFICATION,//  Populate the names and order of columns for the first partition of the   first table 
Hive,WITHOUT_CLASSIFICATION,/*    * To be able to combine a parent join and its left input join child   * the left keys over which the parent join is executed need to be the same   * than those of the child join.   * Thus we iterate over the different inputs of the child checking if the   * keys of the parent are the same    */
Hive,WITHOUT_CLASSIFICATION,//  get the tmp URI path; it will be a hdfs path if not local mode 
Hive,WITHOUT_CLASSIFICATION,//  Cannot deserialize => throw the specific exception. 
Hive,WITHOUT_CLASSIFICATION,//  4. Get Join Condn 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#getMaxFieldSize()    */
Hive,WITHOUT_CLASSIFICATION,// bucket_num_reducers_acid.q TestTxnCommands.testMoreBucketsThanReducers() 
Hive,WITHOUT_CLASSIFICATION,//  For null and true values return every partition 
Hive,WITHOUT_CLASSIFICATION,//  maintain the stack of operators encountered 
Hive,WITHOUT_CLASSIFICATION,//     Configuration conf = context.getConfiguration();      Credentials creds = context.getCredentials(); 
Hive,WITHOUT_CLASSIFICATION,//  Database DDL 
Hive,WITHOUT_CLASSIFICATION,//  precision 4 
Hive,WITHOUT_CLASSIFICATION,//  update primary and secondaryKey 
Hive,WITHOUT_CLASSIFICATION,//  required. 
Hive,WITHOUT_CLASSIFICATION,//  Summary for top column values 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#getFetchDirection()    */
Hive,WITHOUT_CLASSIFICATION,//  This should fail with given HTTP response code 431 in error message since header is more 
Hive,WITHOUT_CLASSIFICATION,//  For now don't push anything into HBase nor store anything special in HBase 
Hive,WITHOUT_CLASSIFICATION,//  turn on db notification listener on metastore 
Hive,WITHOUT_CLASSIFICATION,//  MIN_OPEN_TXN 
Hive,WITHOUT_CLASSIFICATION,//  Prepare IN (blah) lists for the following queries. Cut off the final ''s. 
Hive,WITHOUT_CLASSIFICATION,//  Blocking execute 
Hive,WITHOUT_CLASSIFICATION,//  convert the filter to one that references the child of the project 
Hive,WITHOUT_CLASSIFICATION,//  use the parser to get the output operators of RS 
Hive,WITHOUT_CLASSIFICATION,//  Parse the rewritten query string   check if we need to ctx.setCmd(rewrittenQuery); 
Hive,WITHOUT_CLASSIFICATION,//  One fewer byte. 
Hive,WITHOUT_CLASSIFICATION,//  Not supported by CBO 
Hive,WITHOUT_CLASSIFICATION,//  We already have the TableScan for one side of the join. Check this now. 
Hive,WITHOUT_CLASSIFICATION,//  the correlated variables. 
Hive,WITHOUT_CLASSIFICATION,//  create N TableScans 
Hive,WITHOUT_CLASSIFICATION,//    trim=true 
Hive,WITHOUT_CLASSIFICATION,//  If metadata-only dump then the state of the dump shouldn't be the latest event id as   the data is not yet dumped and shall be dumped in future export. 
Hive,WITHOUT_CLASSIFICATION,//  Possible overflow once 
Hive,WITHOUT_CLASSIFICATION,//  create final load/move work 
Hive,WITHOUT_CLASSIFICATION,//  matching rows must be in the final block so we can end the binary search. 
Hive,WITHOUT_CLASSIFICATION,//  Drain the first Row which just contains column names 
Hive,WITHOUT_CLASSIFICATION,//  Do not give out the capacity of the initializing sessions to the running ones;   we expect init to be fast. 
Hive,WITHOUT_CLASSIFICATION,// noop 
Hive,WITHOUT_CLASSIFICATION,//  create a batch with two string ("Bytes") columns 
Hive,WITHOUT_CLASSIFICATION,//  Or UDF 
Hive,WITHOUT_CLASSIFICATION,//  close + write 
Hive,WITHOUT_CLASSIFICATION,//  Assuming TaskAttemptId and FragmentIdentifierString are the same. Verify this. 
Hive,WITHOUT_CLASSIFICATION,//  if the task is done all operators are done as well 
Hive,WITHOUT_CLASSIFICATION,//  Do not delete the data 
Hive,WITHOUT_CLASSIFICATION,//  add "execute" permission to downloaded resource file (needed when loading dll file) 
Hive,WITHOUT_CLASSIFICATION,//  standard ObjectInspector 
Hive,WITHOUT_CLASSIFICATION,//  negative number flip all bits 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.ICLIService#openSession(java.lang.String java.lang.String java.util.Map)    */
Hive,WITHOUT_CLASSIFICATION,//  The process method was not called -- no big table rows. 
Hive,WITHOUT_CLASSIFICATION,//  1 seconds wait until subsequent status   5 minutes timeout for watch mode 
Hive,WITHOUT_CLASSIFICATION,//  revert output cols of SEL(*) to ExprNodeColumnDesc 
Hive,WITHOUT_CLASSIFICATION,//  estimate size of aggregation buffer 
Hive,WITHOUT_CLASSIFICATION,//  is it a filter or a join condition   if it is filter see if it can be pushed above the join   filter cannot be pushed if   * join is full outer or   * join is left outer and filter is on left alias or   * join is right outer and filter is on right alias 
Hive,WITHOUT_CLASSIFICATION,//  We need to operate on sorted data to fully test BinarySortable. 
Hive,WITHOUT_CLASSIFICATION,//  chosen. 4 * 20% of noconditional task size will be oversubscribed 
Hive,WITHOUT_CLASSIFICATION,//  production is: Map<FieldType()FieldType()> 
Hive,WITHOUT_CLASSIFICATION,//  offsets 
Hive,WITHOUT_CLASSIFICATION,//  The user can specify the hadoop memory 
Hive,WITHOUT_CLASSIFICATION,//  ReduceSinkOperators. 
Hive,WITHOUT_CLASSIFICATION,//  Force the underlying db to initialize. 
Hive,WITHOUT_CLASSIFICATION,/*        * The issue with caching in case of bucket map join is that different tasks       * process different buckets and if the container is reused to join a different bucket       * join results can be incorrect. The cache is keyed on operator id and for bucket map join       * the operator does not change but data needed is different. For a proper fix this       * requires changes in the Tez API with regard to finding bucket id and       * also ability to schedule tasks to re-use containers that have cached the specific bucket.        */
Hive,WITHOUT_CLASSIFICATION,//  15% for io cache 
Hive,WITHOUT_CLASSIFICATION,//  nothing at the moment 
Hive,WITHOUT_CLASSIFICATION,//  Replace filter in current FIL with new FIL 
Hive,WITHOUT_CLASSIFICATION,/*  The result is empty string if a negative start is provided         * whose absolute value is greater than the string length.          */
Hive,WITHOUT_CLASSIFICATION,//  random sampling 
Hive,WITHOUT_CLASSIFICATION,/*        * The scratch column information was collected by the task VectorizationContext.  Go get it.        */
Hive,WITHOUT_CLASSIFICATION,//  we are going to eliminate 
Hive,WITHOUT_CLASSIFICATION,//  Here we rewrite the * and also the masking table 
Hive,WITHOUT_CLASSIFICATION,//  Hide this so it doesn't look like a simple property. 
Hive,WITHOUT_CLASSIFICATION,//  If the parameters does not define any transactional properties we return a default type. 
Hive,WITHOUT_CLASSIFICATION,/* cc_id is monotonically increasing so for any entity sorts in order of compaction history        thus this query groups by entity and withing group sorts most recent first */
Hive,WITHOUT_CLASSIFICATION,//  in multithreaded mode - do cleanup/initialization just once 
Hive,WITHOUT_CLASSIFICATION,//  find the branch on which this processor was invoked 
Hive,WITHOUT_CLASSIFICATION,//  Set a custom prefix for hdfs scratch dir path 
Hive,WITHOUT_CLASSIFICATION,//  Get checksum of a file 
Hive,WITHOUT_CLASSIFICATION,//  FetchWork's sink is used to hold results so each query needs a separate copy of FetchWork 
Hive,WITHOUT_CLASSIFICATION,//  New attempt path crated. Add a watch on it and scan it for existing files. 
Hive,WITHOUT_CLASSIFICATION,//  There should still now be 5 directories in the location 
Hive,WITHOUT_CLASSIFICATION,//  be sent over the wire from the AM and will take the place of AppId+dagId in QueryIdentifier. 
Hive,WITHOUT_CLASSIFICATION,//  If a file is copied from CM path then need to rename them using original source file name   This is needed to avoid having duplicate files in target if same event is applied twice 
Hive,WITHOUT_CLASSIFICATION,//  partition column value is null. 
Hive,WITHOUT_CLASSIFICATION,//  This lock is used to mutex commit/abort and heartbeat calls 
Hive,WITHOUT_CLASSIFICATION,//  HAS_MORE_ROWS 
Hive,WITHOUT_CLASSIFICATION,//  verify that flattening and unflattening "isRepeating" works 
Hive,WITHOUT_CLASSIFICATION,//  Fall back to regular API and create states without ID. 
Hive,WITHOUT_CLASSIFICATION,//  Tests for getTable in other catalogs are covered in TestTablesCreateDropAlterTruncate. 
Hive,WITHOUT_CLASSIFICATION,//  "jdbc:hive2://localhost:10000/default"   "hive"   "" 
Hive,WITHOUT_CLASSIFICATION,// write  baseSplit into output 
Hive,WITHOUT_CLASSIFICATION,//  set the default configs in whitelist 
Hive,WITHOUT_CLASSIFICATION,//  if zk HA is enabled get hosts property 
Hive,WITHOUT_CLASSIFICATION,//  in a vectorized row batch. 
Hive,WITHOUT_CLASSIFICATION,//  The return value of 0 indicates success 
Hive,WITHOUT_CLASSIFICATION,/*        * Single-Column Long specific declarations.        */
Hive,WITHOUT_CLASSIFICATION,//  Make sure we run through the loop once before checking to stop as this makes testing   much easier.  The stop value is only for testing anyway and not used when called from   HiveMetaStore. 
Hive,WITHOUT_CLASSIFICATION,//  If the 'metastore.partition.inherit.table.properties' property is set in the metastore   config the partition inherits the listed table parameters.   This property is not set in this test therefore the partition doesn't inherit the table   parameters. 
Hive,WITHOUT_CLASSIFICATION,//  a composite key class was provided. But neither the types   property was set and   neither the getParts() method of HBaseCompositeKey was   overidden in the   implementation. Flag exception. 
Hive,WITHOUT_CLASSIFICATION,//  First look for all the compactions that are waiting to be cleaned.  If we have not   seen an entry before look for all the locks held on that table or partition and   record them.  We will then only clean the partition once all of those locks have been   released.  This way we avoid removing the files while they are in use   while at the same time avoiding starving the cleaner as new readers come along.   This works because we know that any reader who comes along after the worker thread has   done the compaction will read the more up to date version of the data (either in a   newer delta or in a newer base). 
Hive,WITHOUT_CLASSIFICATION,//  do not need to update column stats if alter partition is not for rename or changing existing columns 
Hive,WITHOUT_CLASSIFICATION,//  Trigger query hooks after query completes its execution. 
Hive,WITHOUT_CLASSIFICATION,//  No exceptions expected 
Hive,WITHOUT_CLASSIFICATION,//  the raw data size. 
Hive,WITHOUT_CLASSIFICATION,//  Simple implementation for now this will later expand to do DAG evaluation. 
Hive,WITHOUT_CLASSIFICATION,// associated with a txn and is handled by performTimeOuts() 
Hive,WITHOUT_CLASSIFICATION,//  initialize output 
Hive,WITHOUT_CLASSIFICATION,// TODO: poll periodically 
Hive,WITHOUT_CLASSIFICATION,// ************************************************************************************************   Emulate BigInteger deserialization used by LazyBinary and others. 
Hive,WITHOUT_CLASSIFICATION,//  not using FieldSchema.equals as comments can be different 
Hive,WITHOUT_CLASSIFICATION,//  walk through the operator tree 
Hive,WITHOUT_CLASSIFICATION,//  Adding column types used later by org.apache.hadoop.hive.druid.serde.DruidSerDe 
Hive,WITHOUT_CLASSIFICATION,//  remember mapping of plan to input 
Hive,WITHOUT_CLASSIFICATION,// owner = "testOwner1" and (lastAccessTime = 30 or test_param_1 = "hi") 
Hive,WITHOUT_CLASSIFICATION,//  attempt retrieving the schema from the data 
Hive,WITHOUT_CLASSIFICATION,//  Reorder fields in record based on the order of columns in the table 
Hive,WITHOUT_CLASSIFICATION,//  existing 
Hive,WITHOUT_CLASSIFICATION,//  Generate the output column info's / row resolver using internal names. 
Hive,WITHOUT_CLASSIFICATION,/*           acid file would have schema like <op owid writerId rowid cwid <f1 ... fn>> so could          check it this way once/if OrcRecordUpdater.ACID_KEY_INDEX_NAME is removed          TypeDescription schema = reader.getSchema();          List<String> columns = schema.getFieldNames();          */
Hive,WITHOUT_CLASSIFICATION,//  at this point we have Druid segments from reducers but we need to atomically   rename and commit to metadata   Moving Druid segments and committing to druid metadata as one transaction. 
Hive,WITHOUT_CLASSIFICATION,// create 1 row in a file 000000_0_copy1 and 1 row in a file 000001_0_copy1 
Hive,WITHOUT_CLASSIFICATION,//  We've eliminated the highest digit already with HiveDecimal.MAX_PRECISION check above. 
Hive,WITHOUT_CLASSIFICATION,//  Atomically move temp file to the destination file 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   optional 
Hive,WITHOUT_CLASSIFICATION,//  This is primarily for testing to avoid the host lookup 
Hive,WITHOUT_CLASSIFICATION,//  an equivalent algorithm exists in   com.google.common.primitives.UnsingedLongs 
Hive,WITHOUT_CLASSIFICATION,//  round(Col N) is a special case and will be implemented separately from this template 
Hive,WITHOUT_CLASSIFICATION,// 'targetPath' is table root of un-partitioned table or partition  'sourcePath' result of 'select ...' part of CTAS statement 
Hive,WITHOUT_CLASSIFICATION,//  direct hand-off 
Hive,WITHOUT_CLASSIFICATION,//  customized log4j config log file to be: /${test.tmp.dir}/TestHiveLogging/hiveLog4jTest.log 
Hive,WITHOUT_CLASSIFICATION,//  test fields 
Hive,WITHOUT_CLASSIFICATION,//  non-vectorized record reader is created below. 
Hive,WITHOUT_CLASSIFICATION,//  If we are running tests we are going to verify that the contents of the cache   correspond with the contents of the plan and otherwise we fail.   This check always run when we are running in test mode independently on whether 
Hive,WITHOUT_CLASSIFICATION,//  vector expression doesn't support checked execution   hold on to it in case there is no available checked variant 
Hive,WITHOUT_CLASSIFICATION,//  don't go  through Initiator for user initiated compactions) 
Hive,WITHOUT_CLASSIFICATION,//  if last row group is set to true it means the above row group spans compression buffer 
Hive,WITHOUT_CLASSIFICATION,//  Need to instantiate the realInputFormat 
Hive,WITHOUT_CLASSIFICATION,/*     todo: parse     target/tmp/org.apache.hadoop.hive.upgrade.acid.TestUpgradeTool-1527286026461/convertToAcid_1527286063065.sql     make sure it has:    ALTER TABLE default.tacid SET TBLPROPERTIES ('transactional'='true');    ALTER TABLE default.tacidpart SET TBLPROPERTIES ('transactional'='true');      */
Hive,WITHOUT_CLASSIFICATION,//  Repeated NULL fill down column. 
Hive,WITHOUT_CLASSIFICATION,//  either input 1 or input 2 may have nulls 
Hive,WITHOUT_CLASSIFICATION,//  COMPATIBILITY 
Hive,WITHOUT_CLASSIFICATION,//  create matchers for custom path string as well as actual dynamic partition path created 
Hive,WITHOUT_CLASSIFICATION,//  walk operator tree to create expression tree for list bucketing 
Hive,WITHOUT_CLASSIFICATION,//  Rewrite the agg calls. Each distinct agg becomes a non-distinct call   to the corresponding field from the right; for example   "COUNT(DISTINCT e.sal)" becomes   "COUNT(distinct_e.sal)". 
Hive,WITHOUT_CLASSIFICATION,//  needed so that the file is actually loaded into configuration. 
Hive,WITHOUT_CLASSIFICATION,//  The name used in the service registry may not match the host name we're using.   Try hostname/canonical hostname/host address 
Hive,WITHOUT_CLASSIFICATION,//  LOCKS 
Hive,WITHOUT_CLASSIFICATION,//  Remove view-based rewriting rules from planner 
Hive,WITHOUT_CLASSIFICATION,//  if true return true 
Hive,WITHOUT_CLASSIFICATION,//  Ensure that we have the correct identifier as the column name 
Hive,WITHOUT_CLASSIFICATION,/*  useIncludeColumns  */
Hive,WITHOUT_CLASSIFICATION,//  Explicitly use {@link org.apache.hadoop.hive.ql.metadata.Table} when getting the schema   but store @{link org.apache.hadoop.hive.metastore.api.Table} as this class is serialized   into the job conf. 
Hive,WITHOUT_CLASSIFICATION,//  Wait for the initial resource plan to be applied. 
Hive,WITHOUT_CLASSIFICATION,//  MY_64BIT_INT 
Hive,WITHOUT_CLASSIFICATION,//  We check for two different classes below because initially the result   is IfExprLongColumnLongColumn but in the future if the system is enhanced 
Hive,WITHOUT_CLASSIFICATION,// try converting to the enum to verify that this is a valid privilege type 
Hive,WITHOUT_CLASSIFICATION,//  catch all errors (throwable and execptions to prevent subsequent tasks from being suppressed) 
Hive,WITHOUT_CLASSIFICATION,//  For join operators that can generate small table results reset their   (target) scratch columns. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#setClientInfo(java.util.Properties)    */
Hive,WITHOUT_CLASSIFICATION,//  for ValidCompactorWriteIdList everything in exceptions are aborted 
Hive,WITHOUT_CLASSIFICATION,/*  Last try to get a port.  Just use default 50111.   */
Hive,WITHOUT_CLASSIFICATION,//  Get the MWMTrigger object from DN 
Hive,WITHOUT_CLASSIFICATION,//  quoted string 
Hive,WITHOUT_CLASSIFICATION,//  The only concurrent change that can happen when we hold the heap lock is list removal; 
Hive,WITHOUT_CLASSIFICATION,//  NOSUCH 
Hive,WITHOUT_CLASSIFICATION,//  check if the grantor matches current user 
Hive,WITHOUT_CLASSIFICATION,//  We need to provide a different record reader for every type of Druid query.   The reason is that Druid results format is different for each type. 
Hive,WITHOUT_CLASSIFICATION,//  for casting integral types to boolean 
Hive,WITHOUT_CLASSIFICATION,//  Modify a copy not the original 
Hive,WITHOUT_CLASSIFICATION,//  For remote JDBC client try to set the hive var using 'set hivevar:key=value' 
Hive,WITHOUT_CLASSIFICATION,//  trigger bugs in anyone who uses this as a hostname 
Hive,WITHOUT_CLASSIFICATION,//  Table name or pattern 
Hive,WITHOUT_CLASSIFICATION,//  WriteID for table1 way in the future 
Hive,WITHOUT_CLASSIFICATION,//  get the column path   return column name if exists column could be DOT separated.   example: lintString.$elem$.myint 
Hive,WITHOUT_CLASSIFICATION,//  If the table/partition exist and is older than the event then just apply 
Hive,WITHOUT_CLASSIFICATION,// it is assumed that parent directory of the destf should already exist when this  method is called. when the replace value is true this method works a little different  from mv command if the destf is a directory it replaces the destf instead of moving under 
Hive,WITHOUT_CLASSIFICATION,//  v[9] -- since left integer #5 is always 0 some products here are not included. 
Hive,WITHOUT_CLASSIFICATION,//  nothing to register (return host-<hostname>) 
Hive,WITHOUT_CLASSIFICATION,/*  doWriteFewerColumns  */
Hive,WITHOUT_CLASSIFICATION,/*    * called during deserialization of a QueryDef during runtime.    */
Hive,WITHOUT_CLASSIFICATION,//  This would be the case for obscure tasks like truncate column (unsupported for MM). 
Hive,WITHOUT_CLASSIFICATION,//  Not matching the regex? 
Hive,WITHOUT_CLASSIFICATION,//  transactionalListener.onAddNotNullConstraint(addcheckConstraintEvent);  } 
Hive,WITHOUT_CLASSIFICATION,//  drop any partitions 
Hive,WITHOUT_CLASSIFICATION,/*  We are not starting zookeeper server here because     * QTestUtil already starts it.      */
Hive,WITHOUT_CLASSIFICATION,//  push down projections. 
Hive,WITHOUT_CLASSIFICATION,//  add it's locations to the list of paths to delete 
Hive,WITHOUT_CLASSIFICATION,//  Assigning can be a subset of columns so this is the projection --   the batch column numbers. 
Hive,WITHOUT_CLASSIFICATION,//  optional string queue = 6; 
Hive,WITHOUT_CLASSIFICATION,//  Verify privilege objects 
Hive,WITHOUT_CLASSIFICATION,// ************************************************************************************************   Decimal Scale Up/Down. 
Hive,WITHOUT_CLASSIFICATION,/*      * the rankValue of the last row output.      */
Hive,WITHOUT_CLASSIFICATION,//  Authorization DDL 
Hive,WITHOUT_CLASSIFICATION,//  We populate inputInspectors for all children of this DemuxOperator.   Those inputObjectInspectors are stored in childInputObjInspectors. 
Hive,WITHOUT_CLASSIFICATION,//  This will call one of the specific notifyEvicted overloads. 
Hive,WITHOUT_CLASSIFICATION,//  0. Collect AggRel output col Names 
Hive,WITHOUT_CLASSIFICATION,//  Backtrack key columns of cRS to pRS 
Hive,WITHOUT_CLASSIFICATION,//  Note: we are called after preReadUncompressedStream so it doesn't have to do nearly as much         as prepareRangesForCompressedRead does; e.g. every buffer is already a CacheChunk. 
Hive,WITHOUT_CLASSIFICATION,//  set the fetchSize 
Hive,WITHOUT_CLASSIFICATION,//  LOG.info("Get input " + a.getClass() + ":" + a + " " + b.getClass() + ":"   + b); 
Hive,WITHOUT_CLASSIFICATION,//  remove from HADOOP_CLIENT_OPTS any debug related options 
Hive,WITHOUT_CLASSIFICATION,//  If a system property that matches one of our conf value names is set then use the value 
Hive,WITHOUT_CLASSIFICATION,//  Column stats generates "select compute_stats() .." queries.   Disable caching for these. 
Hive,WITHOUT_CLASSIFICATION,//  Clean up System properties that were set by this test 
Hive,WITHOUT_CLASSIFICATION,//  folding the constant 
Hive,WITHOUT_CLASSIFICATION,/*        * if partition is smaller than the lagAmt;       * the entire partition is in lagValues.        */
Hive,WITHOUT_CLASSIFICATION,//  For the mapper processing C The SMJ is not initialized no need to close it either. 
Hive,WITHOUT_CLASSIFICATION,//  Note: do not cancel any user actions here; user actions actually interact with kills. 
Hive,WITHOUT_CLASSIFICATION,//  There should be 2 delta dirs plus a base dir in the location 
Hive,WITHOUT_CLASSIFICATION,//  The intermediate rename would've failed as bootstrap dump in progress 
Hive,WITHOUT_CLASSIFICATION,//  If any of the elements was not referenced by every operand we bail out 
Hive,WITHOUT_CLASSIFICATION,//  prefix = work.getAggKey(); 
Hive,WITHOUT_CLASSIFICATION,//  Table scan operators to DPP sources 
Hive,WITHOUT_CLASSIFICATION,//  Keys for all tables are the same so only the first has to deserialize them. 
Hive,WITHOUT_CLASSIFICATION,//  right border is the min 
Hive,WITHOUT_CLASSIFICATION,//  When we generate results into the overflow batch we may still end up with fewer rows   in the big table batch.  So nulSel and the batch's selected array will be rebuilt with   just the big table rows that need to be forwarded minus any rows processed with the 
Hive,WITHOUT_CLASSIFICATION,//  wish to add new line here. 
Hive,WITHOUT_CLASSIFICATION,//  Adjustment only needed when we exceed max precision 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setInt(int int)    */
Hive,WITHOUT_CLASSIFICATION,//  Assume it is not streamjng by default. 
Hive,WITHOUT_CLASSIFICATION,//  String including a surrogate pair character 
Hive,WITHOUT_CLASSIFICATION,//  The column names and order (ascending/descending) matched   The first 'n' sorted columns should be the same as the joinCols where   'n' is the size of join columns.   For eg: if the table is sorted by (abc) it is OK to convert if the join is   on (a) (ab) or any combination of (abc):     (abc) (acb) (cab) (cba) (bca) (bac) 
Hive,WITHOUT_CLASSIFICATION,//  Now we check if though the schemas are the same   the operator changes the order of columns in the   output 
Hive,WITHOUT_CLASSIFICATION,//  Converts the negative byte into positive index 
Hive,WITHOUT_CLASSIFICATION,//  Get the children of the set clause each of which should be a column assignment 
Hive,WITHOUT_CLASSIFICATION,//  QBJoinTree from innermost to outer 
Hive,WITHOUT_CLASSIFICATION,//  prune any nulls present in map values - this is the typical case. 
Hive,WITHOUT_CLASSIFICATION,//  Set fetch size 
Hive,WITHOUT_CLASSIFICATION,//  No need for this if all sub-queries are map-only queries 
Hive,WITHOUT_CLASSIFICATION,// --------------------------- Windowing handling: PTFInvocationSpec to PTFDesc -------------------- 
Hive,WITHOUT_CLASSIFICATION,//  generate the output records 
Hive,WITHOUT_CLASSIFICATION,//  Order on outputColumn. 
Hive,WITHOUT_CLASSIFICATION,// written by Major compaction 
Hive,WITHOUT_CLASSIFICATION,//  and a notification comes from the LlapTaskReporter 
Hive,WITHOUT_CLASSIFICATION,//  Assume 
Hive,WITHOUT_CLASSIFICATION,//  if orc table restrict changing the serde as it can break schema evolution 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setTimestamp(int java.sql.Timestamp   * java.util.Calendar)    */
Hive,WITHOUT_CLASSIFICATION,//  first load the defaults from spark-defaults.conf if available 
Hive,WITHOUT_CLASSIFICATION,//  optional bytes credentials_binary = 8; 
Hive,WITHOUT_CLASSIFICATION,//  part of the partition specified   Create a DummyPartition in this case. Since the metastore does not store partial   partitions currently we need to store dummy partitions 
Hive,WITHOUT_CLASSIFICATION,// standardize to lower case 
Hive,WITHOUT_CLASSIFICATION,//  execute and exit 
Hive,WITHOUT_CLASSIFICATION,//  If the caller is not within a mapper/reducer (if reading from the table via CliDriver)   then TaskAttemptID.forname() may return NULL. Fall back to using default constructor. 
Hive,WITHOUT_CLASSIFICATION,//  This is a test 
Hive,WITHOUT_CLASSIFICATION,//  one VInt with nanos 
Hive,WITHOUT_CLASSIFICATION,//  This is a root task 
Hive,WITHOUT_CLASSIFICATION,//  Also note that any delete_deltas in between a given delta_x_y range would be made   obsolete. For example a delta_30_50 would make delete_delta_40_40 obsolete.   This is valid because minor compaction always compacts the normal deltas and the delete   deltas for the same range. That is if we had 3 directories delta_30_30   delete_delta_40_40 and delta_50_50 then running minor compaction would produce   delta_30_50 and delete_delta_30_50. 
Hive,WITHOUT_CLASSIFICATION,//  Assuming the ObjectInspector represents exactly the same type as this   struct.   This assumption should be checked during query compile time. 
Hive,WITHOUT_CLASSIFICATION,//  Since we allow write operations on cache while prewarm is happening:   1. Don't add tables that were deleted while we were preparing list for prewarm 
Hive,WITHOUT_CLASSIFICATION,//  modified.  
Hive,WITHOUT_CLASSIFICATION,//  SMB Join. 
Hive,WITHOUT_CLASSIFICATION,//  More complex methods which may wrap multiple operations 
Hive,WITHOUT_CLASSIFICATION,//  The max for 18 - 1 digits. 
Hive,WITHOUT_CLASSIFICATION,//  Initialize the cookie based authentication related variables. 
Hive,WITHOUT_CLASSIFICATION,//  Following parameters slated for removal prefer usage of enum above that allows programmatic access. 
Hive,WITHOUT_CLASSIFICATION,//  this shouldn't happen 
Hive,WITHOUT_CLASSIFICATION,//  End of the record is part of the data 
Hive,WITHOUT_CLASSIFICATION,//  We must be able to take away the requisite number; if we can't where'd the ducks go? 
Hive,WITHOUT_CLASSIFICATION,//  row specific RecordWriters 
Hive,WITHOUT_CLASSIFICATION,//  test perfectly divisible batchsize and decaying factor 
Hive,WITHOUT_CLASSIFICATION,//  tells you what that mapping is. 
Hive,WITHOUT_CLASSIFICATION,//  1786135888657847525803324040144343378.09799306448796128931113691624 
Hive,WITHOUT_CLASSIFICATION,//  initialize with estimated element size 35 
Hive,WITHOUT_CLASSIFICATION,//  Just return the object. We need no further operation on it 
Hive,WITHOUT_CLASSIFICATION,//  TODO: potential DFS call 
Hive,WITHOUT_CLASSIFICATION,//  Go over all the children 
Hive,WITHOUT_CLASSIFICATION,//  There is an overlap of ranges - create combined range. 
Hive,WITHOUT_CLASSIFICATION,//  If the global limit optimization is triggered we will   estimate input data actually needed based on limit rows.   estimated Input = (num_limit * max_size_per_row) * (estimated_map + 2)   
Hive,WITHOUT_CLASSIFICATION,/*    * When neither HADOOP_CREDSTORE_PASSWORD nor HIVE_JOB_CREDSTORE_PASSWORD   * are not set jobConf should contain only the credential provider path    */
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:GroupInputSpecProto) 
Hive,WITHOUT_CLASSIFICATION,//  no pos change - no need since we've shrunk the string with same pos 
Hive,WITHOUT_CLASSIFICATION,//  A fair reentrant lock 
Hive,WITHOUT_CLASSIFICATION,// if still equal compare by lock ids 
Hive,WITHOUT_CLASSIFICATION,//  Not using SASL/Kerberos -- use the password 
Hive,WITHOUT_CLASSIFICATION,//  Set OUT parameters 
Hive,WITHOUT_CLASSIFICATION,//  If it contains non-equi join conditions we bail out 
Hive,WITHOUT_CLASSIFICATION,//  cars >= 2 
Hive,WITHOUT_CLASSIFICATION,//  After using selected to generate spills generate non-matches if any. 
Hive,WITHOUT_CLASSIFICATION,//  These parameters must match for all orc files involved in merging. If it   does not merge the file will be put into incompatible file set and will   not be merged. 
Hive,WITHOUT_CLASSIFICATION,//  get connection 
Hive,WITHOUT_CLASSIFICATION,//  Http transport mode. 
Hive,WITHOUT_CLASSIFICATION,/*      * joinCond represents a correlated predicate.     * leftIsRewritten rightIsRewritten indicates if either side has been replaced by a column alias.     *      * If a side is not rewritten we get its text from the tokenstream.      * For rewritten conditions we form the text based on the table and column reference.      */
Hive,WITHOUT_CLASSIFICATION,//  See: SPARK-21187 
Hive,WITHOUT_CLASSIFICATION,//  Finally. 
Hive,WITHOUT_CLASSIFICATION,/*    * Deserializes 64-bit decimals up to the maximum 64-bit precision (18 decimal digits).    */
Hive,WITHOUT_CLASSIFICATION,//  CONSIDER unwinding ValidatorVectorSelectOperator as a subclass of VectorSelectOperator. 
Hive,WITHOUT_CLASSIFICATION,//  PARTITION_ORDER 
Hive,WITHOUT_CLASSIFICATION,// traling '' 
Hive,WITHOUT_CLASSIFICATION,//  currently all Spark work is on the cluster 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.ICLIService#getOperationStatus(org.apache.hive.service.cli.OperationHandle)    */
Hive,WITHOUT_CLASSIFICATION,//  add new item to the tez work 
Hive,WITHOUT_CLASSIFICATION,//  run the script using SqlLine 
Hive,WITHOUT_CLASSIFICATION,//  check if the partition spec is valid 
Hive,WITHOUT_CLASSIFICATION,//  Note : List<Partition> getPartitions() removed with HIVE-9609 because it will result in OOM errors with large add_partitions. 
Hive,WITHOUT_CLASSIFICATION,//  get privileges for this user and its roles on this object 
Hive,WITHOUT_CLASSIFICATION,//  cancel. 
Hive,WITHOUT_CLASSIFICATION,/*    * This operator is allowed before mapjoin. Eventually mapjoin hint should be done away with.   * But since bucketized mapjoin and sortmerge join depend on it completely. it is needed.   * Check the operators which are allowed before mapjoin.    */
Hive,WITHOUT_CLASSIFICATION,/*      * 3. give Evaluator chance to setup for RawInput execution; setup RawInput shape      */
Hive,WITHOUT_CLASSIFICATION,//  otherwise return the arguments 
Hive,WITHOUT_CLASSIFICATION,//  Pop (struct union) 
Hive,WITHOUT_CLASSIFICATION,//  Try with with DECIMAL_64 input and desired output type. 
Hive,WITHOUT_CLASSIFICATION,//  Now do a union of the select operators: selectOp and selectOpClone   Store the operator that follows the select after the join we will be 
Hive,WITHOUT_CLASSIFICATION,//  rows will be 1 
Hive,WITHOUT_CLASSIFICATION,//  Both the handlers should be same 
Hive,WITHOUT_CLASSIFICATION,//  Compute the geometric average of the ratios of all of the factors   which are non-zero and finite. 
Hive,WITHOUT_CLASSIFICATION,// supports AcidInputFormat which uses the KEY pass ROW__ID info 
Hive,WITHOUT_CLASSIFICATION,//  Restart the sessions until one of them refuses to restart. 
Hive,WITHOUT_CLASSIFICATION,//  Restore the original selected vector 
Hive,WITHOUT_CLASSIFICATION,/*        * d. Construct PTF Operator.        */
Hive,WITHOUT_CLASSIFICATION,//  Test partition listing with a partial spec 
Hive,WITHOUT_CLASSIFICATION,// need the WHERE clause below to ensure consistent results with READ_COMMITTED 
Hive,WITHOUT_CLASSIFICATION,//  go over all aggregation buffers and see they implement estimable 
Hive,WITHOUT_CLASSIFICATION,//  check isRepeating propagation 
Hive,WITHOUT_CLASSIFICATION,//  Note: we only look at the schema here to deal with complex types. Somebody has set up the         reader with whatever ideas they had to the schema and we just trust the reader to         produce the CVBs that was asked for. However we only need to look at top level columns. 
Hive,WITHOUT_CLASSIFICATION,//  store a path prefix in this TestFilter 
Hive,WITHOUT_CLASSIFICATION,//  Attempt dynamic partitioned hash join   Since we don't have big table index yet must start with estimate of numReducers 
Hive,WITHOUT_CLASSIFICATION,//  All will be filtered out 
Hive,WITHOUT_CLASSIFICATION,//  Serialize AggBuffer 
Hive,WITHOUT_CLASSIFICATION,//  Not supported for MM tables right now. 
Hive,WITHOUT_CLASSIFICATION,//  read baseSplit from input 
Hive,WITHOUT_CLASSIFICATION,//  Check if this is table name is qualified or not 
Hive,WITHOUT_CLASSIFICATION,//  Short circuit and return the current number of rows if this is a 
Hive,WITHOUT_CLASSIFICATION,//  A failure here will cause this query to not be added to the cache. 
Hive,WITHOUT_CLASSIFICATION,//  tables in test db 
Hive,WITHOUT_CLASSIFICATION,//  increments file modification time 
Hive,WITHOUT_CLASSIFICATION,//  Exceeds max value 
Hive,WITHOUT_CLASSIFICATION,//  show table properties - populate the output stream 
Hive,WITHOUT_CLASSIFICATION,//  is well formed. 
Hive,WITHOUT_CLASSIFICATION,//  Configure http client for SSL 
Hive,WITHOUT_CLASSIFICATION,//  dummy for backtracking 
Hive,WITHOUT_CLASSIFICATION,//  string BETWEEN 
Hive,WITHOUT_CLASSIFICATION,//  intentionally corrupt some files 
Hive,WITHOUT_CLASSIFICATION,//  Literal double. 
Hive,WITHOUT_CLASSIFICATION,//  Try to find valid entry but settle for pending entry if that is all we have. 
Hive,WITHOUT_CLASSIFICATION,//  get a set of RecordWriter based on the DP column values 
Hive,WITHOUT_CLASSIFICATION,//  Add the queryId appender to the queryId based route 
Hive,WITHOUT_CLASSIFICATION,//  regular case of accessing nested field in a column 
Hive,WITHOUT_CLASSIFICATION,//  START_TIME 
Hive,WITHOUT_CLASSIFICATION,//  bad files don't pollute the filesystem 
Hive,WITHOUT_CLASSIFICATION,//  Locked or invalidated buffer was in the list - just drop it;   will be re-added on unlock. 
Hive,WITHOUT_CLASSIFICATION,//  remove all the candidate filter operators   when we get to the TS 
Hive,WITHOUT_CLASSIFICATION,//  enforce is required to retain the buffer sizes of old files instead of orc writer   inferring the optimal buffer size 
Hive,WITHOUT_CLASSIFICATION,//  repeated .GroupInputSpecProto grouped_input_specs = 12; 
Hive,WITHOUT_CLASSIFICATION,// should not matter which txnMgr is used here 
Hive,WITHOUT_CLASSIFICATION,//  Use url param indirectly - as the name of an env var that contains the url   If the urlParam is "default" we would look for a BEELINE_URL_DEFAULT url 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getSQLXML(java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  Testing multiByte string with reference set to mid array 
Hive,WITHOUT_CLASSIFICATION,// we don't need to cancel this token as the TokenRenewer for JT tokens  takes care of cancelling them 
Hive,WITHOUT_CLASSIFICATION,//  POSITION 
Hive,WITHOUT_CLASSIFICATION,//  We copy the join and the top sort operator 
Hive,WITHOUT_CLASSIFICATION,//  TEST - repeating NULL & no selection 
Hive,WITHOUT_CLASSIFICATION,//  Definitely a long; most longs fall here 
Hive,WITHOUT_CLASSIFICATION,//  Map-only subqueries can be optimized in future to not write to a file in 
Hive,WITHOUT_CLASSIFICATION,//  to the formulae in JLS Section 20.10.22. 
Hive,WITHOUT_CLASSIFICATION,//  If any table has bad size estimate we need to fall back to sizing each table equally 
Hive,WITHOUT_CLASSIFICATION,//  TODO HIVE-14042. abort handling: Handling of mergeMapOp 
Hive,WITHOUT_CLASSIFICATION,//  Now all the column values should always return NULL! 
Hive,WITHOUT_CLASSIFICATION,//  an exception 
Hive,WITHOUT_CLASSIFICATION,// Currently only column related changes can be cascaded in alter table 
Hive,WITHOUT_CLASSIFICATION,//  When people forget to quote a string op1/op2 is null.   For example select * from some_table where ds > 2012-12-1 or ds < 2012-12-2 . 
Hive,WITHOUT_CLASSIFICATION,//  gather statistics for the first time and the attach it to table scan operator 
Hive,WITHOUT_CLASSIFICATION,//  a new value so the last isn't clobbered 
Hive,WITHOUT_CLASSIFICATION,// now 4 
Hive,WITHOUT_CLASSIFICATION,/*        * the SubQuery predicate has been hoisted as a Join. The SubQuery predicate is replaced       * by a 'true' predicate in the Outer QB's where/having clause.        */
Hive,WITHOUT_CLASSIFICATION,//  If the current record needs to be returned based on the   filter conditions specified by the user increment the counter 
Hive,WITHOUT_CLASSIFICATION,//  Bad luck! Handle the corner cases where 3 bytes are in multiple blocks. 
Hive,WITHOUT_CLASSIFICATION,/*        * Do careful maintenance of the outputColVector.noNulls flag.        */
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setBlob(java.lang.String   * java.io.InputStream long)    */
Hive,WITHOUT_CLASSIFICATION,//  return a loaned session goes back to tez am pool 
Hive,WITHOUT_CLASSIFICATION,//  Return true if the remove was successful false otherwise 
Hive,WITHOUT_CLASSIFICATION,//  Distincts are not allowed with an additional mr job 
Hive,WITHOUT_CLASSIFICATION,//  This is likely a shutdown 
Hive,WITHOUT_CLASSIFICATION,//  even though there are only two delta_3_3 delta_4_4 and one delete_delta_5_5. 
Hive,WITHOUT_CLASSIFICATION,//  Type affinity does not help when type affinity does not match input args 
Hive,WITHOUT_CLASSIFICATION,// now 3 
Hive,WITHOUT_CLASSIFICATION,//  Tuesday 1st January 1985 12:00:00 AM 
Hive,WITHOUT_CLASSIFICATION,//  File named by path doesn't exist; nothing to validate. 
Hive,WITHOUT_CLASSIFICATION,//  Index into partitionSpecs. 
Hive,WITHOUT_CLASSIFICATION,//  NN_NAME 
Hive,WITHOUT_CLASSIFICATION,//  Number of variables declared with the same data type and default 
Hive,WITHOUT_CLASSIFICATION,//  isSame 
Hive,WITHOUT_CLASSIFICATION,//  2^p number of bytes for register 
Hive,WITHOUT_CLASSIFICATION,//  Everything should be same as before 
Hive,WITHOUT_CLASSIFICATION,//  Latin Capital Letter Z U+005A (1 bytes)   blank " " (1 byte) 
Hive,WITHOUT_CLASSIFICATION,//  Should we intercept here for a possible Decimal64 vector expression class? 
Hive,WITHOUT_CLASSIFICATION,//  If delegation token is passed from the client side do not set the principal 
Hive,WITHOUT_CLASSIFICATION,//  from ParentRunner retried under exception (notified only after exhausting retryCount) 
Hive,WITHOUT_CLASSIFICATION,//  Clear the thread locals 
Hive,WITHOUT_CLASSIFICATION,//  for these positions some variable primitive type (String) is used for the 
Hive,WITHOUT_CLASSIFICATION,//  iterate for the first time to get all the names of stages. 
Hive,WITHOUT_CLASSIFICATION,//  Cancel the maintenance thread. 
Hive,WITHOUT_CLASSIFICATION,//  partial column statistics on grouping attributes case.   if column statistics on grouping attribute is missing then   assume worst case.   GBY rule will emit half the number of rows if ndvProduct is 0 
Hive,WITHOUT_CLASSIFICATION,//  TODO: add allocate overload with an offset and length 
Hive,WITHOUT_CLASSIFICATION,//  TODO: parts of this should be moved out of TezSession to reuse the clients but there's         no good place for that right now (HIVE-13698). 
Hive,WITHOUT_CLASSIFICATION,//  This null check is specifically done as the same class is used to handle both incremental and   bootstrap replication scenarios for create function. When doing bootstrap we do not have   event id for this event but rather when bootstrap started and hence we pass in null dmd for   bootstrap.There should be a better way to do this but might required a lot of changes across   different handlers unless this is a common pattern that is seen leaving this here. 
Hive,WITHOUT_CLASSIFICATION,//  in dynamic usecase called through FileRecordWriterContainer 
Hive,WITHOUT_CLASSIFICATION,//  clone rhsSemijoin 
Hive,WITHOUT_CLASSIFICATION,//  Use the RowResolver from the input operator to generate a input   ObjectInspector that can be used to initialize the UDTF. Then the 
Hive,WITHOUT_CLASSIFICATION,/*    * @param conf /* @throws HCatExceptionConnectionFailureException   *   * @see   * org.apache.hive.hcatalog.api.HCatClient#initialize(org.apache.hadoop.conf.   * Configuration)    */
Hive,WITHOUT_CLASSIFICATION,//  give me more 
Hive,WITHOUT_CLASSIFICATION,//  if string can not be parsed converter will return null 
Hive,WITHOUT_CLASSIFICATION,//  allow NOT but throw an error for rest 
Hive,WITHOUT_CLASSIFICATION,// now 5 
Hive,WITHOUT_CLASSIFICATION,//  INPUT_FORMAT 
Hive,WITHOUT_CLASSIFICATION,//  Get all items into an array and sort them. 
Hive,WITHOUT_CLASSIFICATION,//  Now prepare partnames with only 5 partitions: [tab1part1...tab1part5] 
Hive,WITHOUT_CLASSIFICATION,//  use linear extrapolation. more complicated one can be added in the 
Hive,WITHOUT_CLASSIFICATION,//  Given that we do not delete an empty slot means no match.   LOG.debug("VectorMapJoinFastLongHashTable findReadSlot key " + key + " slot " + slot + " pairIndex " + pairIndex + " empty slot (i = " + i + ")"); 
Hive,WITHOUT_CLASSIFICATION,//  We will store all the new /changed properties in the job in the   udf context so the the HCatOutputFormat.setOutput and setSchema 
Hive,WITHOUT_CLASSIFICATION,//  --------------------------------------------------------- Private Methods 
Hive,WITHOUT_CLASSIFICATION,//  the owner will also have select with grant privileges on new view 
Hive,WITHOUT_CLASSIFICATION,//  Year granularity 
Hive,WITHOUT_CLASSIFICATION,// use only control chars that are very unlikely to be part of the string   the following might/likely to be used in text files for strings   9 (horizontal tab HT \t ^I)   10 (line feed LF \n ^J)   12 (form feed FF \f ^L)   13 (carriage return CR \r ^M)   27 (escape ESC \e [GCC only] ^[). 
Hive,WITHOUT_CLASSIFICATION,// disable the expandEvents for the purpose of backward compatibility 
Hive,WITHOUT_CLASSIFICATION,//  Also make sure it is a constant. 
Hive,WITHOUT_CLASSIFICATION,//  Process min/max 
Hive,WITHOUT_CLASSIFICATION,//  hash from the fetcher 
Hive,WITHOUT_CLASSIFICATION,//  We decompose an AND expression into its parts before checking if the   entire expression is a candidate because each part may be a candidate   for replicating transitively over an equijoin condition. 
Hive,WITHOUT_CLASSIFICATION,//  Remove cast of BOOLEAN NOT NULL to BOOLEAN or vice versa. Filter accepts   nullable and not-nullable conditions but a CAST might get in the way of 
Hive,WITHOUT_CLASSIFICATION,//  key = (key << 21) - key - 1; 
Hive,WITHOUT_CLASSIFICATION,/*  * Defines an interface for re-execution logics. * * FIXME: rethink methods.  */
Hive,WITHOUT_CLASSIFICATION,/*  Exponent read from "EX" field.  */
Hive,WITHOUT_CLASSIFICATION,//  input OI includes table columns + partition columns 
Hive,WITHOUT_CLASSIFICATION,//  Check that we have two deltas. 
Hive,WITHOUT_CLASSIFICATION,/*        * Repeating ELSE expression?        */
Hive,WITHOUT_CLASSIFICATION,//  Methods to set/reset getPartition modifier 
Hive,WITHOUT_CLASSIFICATION,//  During the DFS traversal of the AST a descendant of nd likely set an   error because a sub-tree of nd is unlikely to also be a group by   expression. For example in a query such as   SELECT *concat(key)* FROM src GROUP BY concat(key) 'key' will be   processed before 'concat(key)' and since 'key' is not a group by   expression an error will be set in ctx by ColumnExprProcessor. 
Hive,WITHOUT_CLASSIFICATION,//  TRIGGER 
Hive,WITHOUT_CLASSIFICATION,//  The following information is for creating VectorizedRowBatch and for helping with   knowing how the table is partitioned.     It will be stored in MapWork and ReduceWork. 
Hive,WITHOUT_CLASSIFICATION,//  1. Get file metadata from cache or create the reader and read it. 
Hive,WITHOUT_CLASSIFICATION,//  A map-only job can be optimized - instead of converting it to a   map-reduce job we can have another map   job to do the same to avoid the cost of sorting in the map-reduce phase.   A better approach would be to   write into a local file and then have a map-only job.   Add the limit operator to get the value fields 
Hive,WITHOUT_CLASSIFICATION,//  Stop as we won't be able to go forward. 
Hive,WITHOUT_CLASSIFICATION,//  Maintain count of outstanding requests for tokenIdentifier.   If count goes to 0 it is safe to remove the token. 
Hive,WITHOUT_CLASSIFICATION,//  ColumnizedDeleteEventRegistry reads all the delete events into memory during initialization   and it closes the delete event readers after it. If an exception gets thrown during   initialization we may have to close any readers that are still left open. 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: We do conditional vector expression so we do not call super.evaluateChildren(batch). 
Hive,WITHOUT_CLASSIFICATION,//  Calcite day-time interval is millis value as BigDecimal   Seconds converted to millis 
Hive,WITHOUT_CLASSIFICATION,//  if we've seen both root and child we can bail. 
Hive,WITHOUT_CLASSIFICATION,//  Should have files 
Hive,WITHOUT_CLASSIFICATION,//  Remove default partition from partition names and get aggregate 
Hive,WITHOUT_CLASSIFICATION,//                  123456789012345678901234567890123456789012345                            1         2         3         4 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise we tried .. 
Hive,WITHOUT_CLASSIFICATION,//  If anything remains this is where it starts. 
Hive,WITHOUT_CLASSIFICATION,//  Iterating through the buffer should not cause the next buffer to be fetched 
Hive,WITHOUT_CLASSIFICATION,// now 1 
Hive,WITHOUT_CLASSIFICATION,//  QUERY_TIMEOUT 
Hive,WITHOUT_CLASSIFICATION,//  Check for dynamic partitions. 
Hive,WITHOUT_CLASSIFICATION,//  Second check - the tasks we looked for must not have been accessed more than   once as a result of the traversal (note that we actually wind up accessing   2 times  because each visit counts twice once to check for existence and   once to visit. 
Hive,WITHOUT_CLASSIFICATION,//  add role privileges 
Hive,WITHOUT_CLASSIFICATION,//  How much can the fraction be moved up? 
Hive,WITHOUT_CLASSIFICATION,//  Check if any of the txns in the list is aborted. 
Hive,WITHOUT_CLASSIFICATION,//  Add another db via CachedStore 
Hive,WITHOUT_CLASSIFICATION,//  Tez internals may register the same task as completing multiple times. 
Hive,WITHOUT_CLASSIFICATION,/*      * The conversion to standard object inspector was necessitated by HIVE-5973. The issue     * happens when a select operator preceeds this operator as in the case of a subquery. The     * select operator does not allocate a new object to hold the deserialized row. This affects     * the operation of the SMB join which puts the object in a priority queue. Since all elements     * of the priority queue point to the same object the join was resulting in incorrect     * results.     *     * So the fix is to make a copy of the object as done in the processOp phase below. This     * however necessitates a change in the object inspector that can be used in processing the     * row downstream.      */
Hive,WITHOUT_CLASSIFICATION,//  provider setup 
Hive,WITHOUT_CLASSIFICATION,//  make sure delta files are written with no indexes no compression and no dictionary 
Hive,WITHOUT_CLASSIFICATION,//  Translate the positions of correlated variables to be relative to   the join output leaving room for valueGenFieldOffset because   valueGenerators are joined with the original left input of the rel 
Hive,WITHOUT_CLASSIFICATION,//  also test getting a table from a specific db 
Hive,WITHOUT_CLASSIFICATION,//  Let's try to parse it as timestamp with time zone and transform 
Hive,WITHOUT_CLASSIFICATION,//  Note that here we ignore nanos part of Hive Timestamp since nanos are dropped when   reading Hive from Pig by design. 
Hive,WITHOUT_CLASSIFICATION,/*    * is this PTFDesc for a Map-Side PTF Operation?    */
Hive,WITHOUT_CLASSIFICATION,// test with predicates such that partition pruning works 
Hive,WITHOUT_CLASSIFICATION,//  10^17 - 1 
Hive,WITHOUT_CLASSIFICATION,//  offer accepted r1 evicted 
Hive,WITHOUT_CLASSIFICATION,//  pick up unknown case 
Hive,WITHOUT_CLASSIFICATION,//  These remaining combinations below definitely result in overflow. 
Hive,WITHOUT_CLASSIFICATION,//  I don't entirely believe that everything is cleaned up   when close is called based on watching the TRACE logs 
Hive,WITHOUT_CLASSIFICATION,//  Replication dest will not be external - override if set 
Hive,WITHOUT_CLASSIFICATION,//  All join tables have 0 keys doesn't matter what we generate. 
Hive,WITHOUT_CLASSIFICATION,//  this will trigger the column pruner to collect view column   authorization info. 
Hive,WITHOUT_CLASSIFICATION,//  special handling for SQL "reload function" 
Hive,WITHOUT_CLASSIFICATION,// why even compute syntheticProps if !isOriginal??? 
Hive,WITHOUT_CLASSIFICATION,//  notifyReused implies that buffer is already locked; it's also called once for new   buffers that are not cached yet. Don't notify cache policy. 
Hive,WITHOUT_CLASSIFICATION,//  missing stripe stats (old format). If numRows is 0 then its an empty file and no statistics   is present. We have to differentiate no stats (empty file) vs missing stats (old format). 
Hive,WITHOUT_CLASSIFICATION,//  expected 
Hive,WITHOUT_CLASSIFICATION,//  check the VirtualColumn directly. 
Hive,WITHOUT_CLASSIFICATION,//  have to make sure there's slash after .har otherwise resolve doesn't work 
Hive,WITHOUT_CLASSIFICATION,//  Attempting to get the password should throw an exception 
Hive,WITHOUT_CLASSIFICATION,//  Try outer Row resolver 
Hive,WITHOUT_CLASSIFICATION,/*  Disregard nulls for processing. In other words     * the arithmetic operation is performed even if one or     * more inputs are null. This is to improve speed by avoiding     * conditional checks in the inner loop.      */
Hive,WITHOUT_CLASSIFICATION,// First non-null item. 
Hive,WITHOUT_CLASSIFICATION,//  call getsplits 
Hive,WITHOUT_CLASSIFICATION,//  Make sure we got the right implementation of a ColumnMapping 
Hive,WITHOUT_CLASSIFICATION,//  add the new entry 
Hive,WITHOUT_CLASSIFICATION,//  Return our mocked objects 
Hive,WITHOUT_CLASSIFICATION,//  Trigger an update if needed. 
Hive,WITHOUT_CLASSIFICATION,/*    * refactored out of the Equality case of parseJoinCondition   * so that this can be recursively called on its left tree in the case when   * only left sources are referenced in a Predicate    */
Hive,WITHOUT_CLASSIFICATION,//  Used for testing to simulate method timeout. 
Hive,WITHOUT_CLASSIFICATION,// newer versions (2012 and later) support OFFSET/FETCH  https://msdn.microsoft.com/en-us/library/ms189463.aspx 
Hive,WITHOUT_CLASSIFICATION,//  Mainly for verification 
Hive,WITHOUT_CLASSIFICATION,//  This object should be the same as in cache otherwise it must be removed due to init error 
Hive,WITHOUT_CLASSIFICATION,//  Build an input to output position map. 
Hive,WITHOUT_CLASSIFICATION,//  Test if rpc_server_address is configured 
Hive,WITHOUT_CLASSIFICATION,//  MODIFIER LETTER UP ARROWHEAD U+02C4 (2 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  Use the tableAlias to generate keyBaseAlias 
Hive,WITHOUT_CLASSIFICATION,//  replace SEL(*) to SEL(exprs) 
Hive,WITHOUT_CLASSIFICATION,//  t1=5+1(insert) and t2=5+2(insert) 
Hive,WITHOUT_CLASSIFICATION,//  clone filterMap 
Hive,WITHOUT_CLASSIFICATION,//  If we have a plan prefer its logical result schema if it's   available; otherwise try digging out a fetch task; failing that   give up. 
Hive,WITHOUT_CLASSIFICATION,//  acid 
Hive,WITHOUT_CLASSIFICATION,/*      * Instantiate Decimal64 vector expression.     *     * The instantiateExpression method sets the output column and type information.      */
Hive,WITHOUT_CLASSIFICATION,//  non-space character 
Hive,WITHOUT_CLASSIFICATION,//  Randomly pick the character corresponding to the field id and convert it to byte array 
Hive,WITHOUT_CLASSIFICATION,//  This string reader should simply redirect to its own seek (what other types already do). 
Hive,WITHOUT_CLASSIFICATION,// {"" : null} 
Hive,WITHOUT_CLASSIFICATION,//  stddev_pop(x) ==>     power(       (sum(x * x) - sum(x) * sum(x) / count(x))       / count(x)       .5)     stddev_samp(x) ==>     power(       (sum(x * x) - sum(x) * sum(x) / count(x)) 
Hive,WITHOUT_CLASSIFICATION,//                              1         2         3         4 
Hive,WITHOUT_CLASSIFICATION,//  optional bool is_external_submission = 14 [default = false]; 
Hive,WITHOUT_CLASSIFICATION,//  Flush any pending scheduler runs which may be blocked. Wait 2 seconds for the run to complete. 
Hive,WITHOUT_CLASSIFICATION,//  For now we don't support group by on DECIMAL_64 keys. 
Hive,WITHOUT_CLASSIFICATION,//  uppercase first letter 
Hive,WITHOUT_CLASSIFICATION,//  As above we enforce a certain order when we do the reutilization. 
Hive,WITHOUT_CLASSIFICATION,// if target table has cols c1c2c3 and p1 partition col and we had "SET c2 = 5 c1 = current_date()" we want to end up with  insert into target (p1) select current_date() 5 c3 p1 where .... 
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.LlapOutputSocketInitMessage.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,//  make sure we don't modify the config in RpcConfiguration 
Hive,WITHOUT_CLASSIFICATION,/*    * use to check if a set of columns are all partition columns. true only if: -   * all columns in BitSet are partition columns.    */
Hive,WITHOUT_CLASSIFICATION,//  This will only send update if it's necessary. 
Hive,WITHOUT_CLASSIFICATION,// disallow subqueries which HIVE doesn't currently support 
Hive,WITHOUT_CLASSIFICATION,//  If it went through correctly then s is also a HCatRecord   and also equal to the above and a deepcopy and this holds   through for multiple levels more of serialization as well. 
Hive,WITHOUT_CLASSIFICATION,//  Shuffle write metrics. 
Hive,WITHOUT_CLASSIFICATION,// txn X write to bucket1   txn X + 1 write to bucket0 + bucket1 
Hive,WITHOUT_CLASSIFICATION,//  run this rule at later stages since many calcite rules cant deal with semijoin 
Hive,WITHOUT_CLASSIFICATION,// Take a row from the current buffered batch 
Hive,WITHOUT_CLASSIFICATION,/*  * The general idea here is to create * /created/1 * /created/2 * /created/3 .... * for each job submitted.  The node number is generated by ZK (PERSISTENT_SEQUENTIAL) and the  * payload is the JobId. Basically this keeps track of the order in which jobs were submitted * and ZooKeeperCleanup uses this to purge old job info. * Since the /jobs/<id> node has a create/update timestamp  * (http://zookeeper.apache.org/doc/trunk/zookeeperProgrammers.html#sc_zkStatStructure) this whole * thing can be removed. */
Hive,WITHOUT_CLASSIFICATION,//  LOG.debug(CLASS_NAME + " processOp all " + displayBytes(keyBytes 0 keyLength)); 
Hive,WITHOUT_CLASSIFICATION,//  Incase the join has extra keys other than bucketed columns partition keys need to be updated   on small table(s). 
Hive,WITHOUT_CLASSIFICATION,//  Values within the column type bounds. 
Hive,WITHOUT_CLASSIFICATION,//  Init output object inspectors.     The return type for a partial aggregation is still a list of doubles as in   GenericUDAFHistogramNumeric but we add on the percentile values requested to the   end and handle serializing/deserializing before we pass things on to the parent   method.   The return type for FINAL and COMPLETE is a full aggregation result which is also 
Hive,WITHOUT_CLASSIFICATION,//  (all partitions and all but default) 
Hive,WITHOUT_CLASSIFICATION,//  ResultSet#next blocks until the async query is complete 
Hive,WITHOUT_CLASSIFICATION,//  green and red qualify 
Hive,WITHOUT_CLASSIFICATION,//  create map join task and set big table as bigTablePosition 
Hive,WITHOUT_CLASSIFICATION,//  String variable 
Hive,WITHOUT_CLASSIFICATION,//  and remind ourselves to perform incremental normalization 
Hive,WITHOUT_CLASSIFICATION,//  JAAS login from ticket cache to setup the client UserGroupInformation 
Hive,WITHOUT_CLASSIFICATION,//  value. Therefore it is always LogicalCorrelate's left input which is outer query 
Hive,WITHOUT_CLASSIFICATION,//  createDirectories creates all non-existent parent directories 
Hive,WITHOUT_CLASSIFICATION,//  Log a warning if hive-default.xml is found on the classpath 
Hive,WITHOUT_CLASSIFICATION,// add post script 
Hive,WITHOUT_CLASSIFICATION,//  number of output columns   array of path expressions each of which corresponds to a column   array of returned column values  object pool of non-null Text avoid creating objects all the time 
Hive,WITHOUT_CLASSIFICATION,//  We are now on some intersecting buffer find the first intersecting buffer. 
Hive,WITHOUT_CLASSIFICATION,//  replace stdout and run command 
Hive,WITHOUT_CLASSIFICATION,//  Set query timeout to 1 second 
Hive,WITHOUT_CLASSIFICATION,//  Reject any clauses that are against a column that isn't the rowId mapping or indexed 
Hive,WITHOUT_CLASSIFICATION,//  Do the per-batch setup for an inner join. 
Hive,WITHOUT_CLASSIFICATION,//  Swap column vectors to simulate change in data 
Hive,WITHOUT_CLASSIFICATION,//  For negative number initializing bits to 1 
Hive,WITHOUT_CLASSIFICATION,//  put it into the cache BEFORE it is initialized to make sure we can catch 
Hive,WITHOUT_CLASSIFICATION,//  If the fourth parameter -- precision factor 'pf' -- has been specified make sure it's 
Hive,WITHOUT_CLASSIFICATION,//  Splits are not shared across different partitions with different input formats. 
Hive,WITHOUT_CLASSIFICATION,//  If the database is newer than the drop event then noop it. 
Hive,WITHOUT_CLASSIFICATION,//  test set and append methods 
Hive,WITHOUT_CLASSIFICATION,//  Get the positions for sorted and bucketed columns   For sorted columns also get the order (ascending/descending) - that should   also match for this to be converted to a map-only job.   Get the positions for sorted and bucketed columns   For sorted columns also get the order (ascending/descending) - that should 
Hive,WITHOUT_CLASSIFICATION,//  done! 
Hive,WITHOUT_CLASSIFICATION,//  all other exceptions are considered as emanating from   unauthorized accesses 
Hive,WITHOUT_CLASSIFICATION,//  LocalClientProtocolProvider expects both parameters to be 'local'. 
Hive,WITHOUT_CLASSIFICATION,//  If location is specified - ensure that it is a full qualified name 
Hive,WITHOUT_CLASSIFICATION,//  COMMENT 
Hive,WITHOUT_CLASSIFICATION,//  Always allow the operation if it is not in replication scope. 
Hive,WITHOUT_CLASSIFICATION,//  need to add this branch to the key + value info 
Hive,WITHOUT_CLASSIFICATION,//  b.c 
Hive,WITHOUT_CLASSIFICATION,//  Implement vectorized function Hex(string) returning string 
Hive,WITHOUT_CLASSIFICATION,//  Move on to the next bit vector 
Hive,WITHOUT_CLASSIFICATION,//  Run without cascade 
Hive,WITHOUT_CLASSIFICATION,//  bucketing isn't consistent or there are >1 bucket columns   optimizer does not extract multiple column predicates for this 
Hive,WITHOUT_CLASSIFICATION,//  Debug display. 
Hive,WITHOUT_CLASSIFICATION,//  The number of reducer(s) should be used for those bottom layer ReduceSinkOperators 
Hive,WITHOUT_CLASSIFICATION,//  Copy all the histogram bins from us and 'other' into an overstuffed histogram 
Hive,WITHOUT_CLASSIFICATION,//  View already exists thus we should be replacing 
Hive,WITHOUT_CLASSIFICATION,//  Larger than max compile duration used in test 
Hive,WITHOUT_CLASSIFICATION,//  Delete any tables other than the source tables 
Hive,WITHOUT_CLASSIFICATION,//  Pass the row though the operator tree. It is guaranteed that not more than 1 row can   be produced from a input row. 
Hive,WITHOUT_CLASSIFICATION,//  First write chunk length 
Hive,WITHOUT_CLASSIFICATION,//  TODO: ExprNodeDesc is an expression tree we could just use that and be rid of Filter.g. 
Hive,WITHOUT_CLASSIFICATION,//  NULL 0   NULL 1 
Hive,WITHOUT_CLASSIFICATION,//  The update has failed; we'd try with another candidate first but only at the same priority. 
Hive,WITHOUT_CLASSIFICATION,//  Metrics are first dumped to a temp file which is then renamed to the destination 
Hive,WITHOUT_CLASSIFICATION,//  This is a mapping of the values in the small table hash table that will be copied to the   small table result portion of the output.  That is a mapping of the LazyBinary field order 
Hive,WITHOUT_CLASSIFICATION,// 1st and only stmt in implicit txn and uses acid resource 
Hive,WITHOUT_CLASSIFICATION,//  new input column numbers 
Hive,WITHOUT_CLASSIFICATION,//  check if it is a reduce vertex and its children is more than 1;   check if all the child ops are reduce output operators 
Hive,WITHOUT_CLASSIFICATION,//  High word must be zero.  Check for overflow digits in middle word. 
Hive,WITHOUT_CLASSIFICATION,/*    * Returns job status for list of input jobs as a list.    */
Hive,WITHOUT_CLASSIFICATION,/*            * Single-Column String outer null detection.            */
Hive,WITHOUT_CLASSIFICATION,//  6. Build Rel for OB Clause 
Hive,WITHOUT_CLASSIFICATION,//  all rows from both side will be present in resultset 
Hive,WITHOUT_CLASSIFICATION,//  The position in the column keys of the dummy grouping set id column. 
Hive,WITHOUT_CLASSIFICATION,//  Essentially partition values are represented as strings but we want the actual object type associated 
Hive,WITHOUT_CLASSIFICATION,//  Txn was committed (but notification was not received) or it was aborted.   Either case we can clean it up 
Hive,WITHOUT_CLASSIFICATION,//  using metrics.  Thus we should always check whether this is non-null before using. 
Hive,WITHOUT_CLASSIFICATION,//  16 without HIVE-19588 8 with HIVE-19588 
Hive,WITHOUT_CLASSIFICATION,//  Just move the marker according to delta.   We hit the limit - the list was exhausted. 
Hive,WITHOUT_CLASSIFICATION,//  1. If WM is not present just go to unmanaged. 
Hive,WITHOUT_CLASSIFICATION,//  Method that provides similar filter functionality to filter-holder above useful when 
Hive,WITHOUT_CLASSIFICATION,//  (Otherwise sub-directories produced by Hive UNION operations won't be readable.) 
Hive,WITHOUT_CLASSIFICATION,//  The current* members of deserializeRead have the field value. 
Hive,WITHOUT_CLASSIFICATION,//  We do not try to finish and flush an in-progress group because correct values require the   last group batch. 
Hive,WITHOUT_CLASSIFICATION,//  set one null value for possible later use 
Hive,WITHOUT_CLASSIFICATION,//  TODO: move into the if below; account for release call 
Hive,WITHOUT_CLASSIFICATION,//     runStatementOnDriver("delete from " + Table.ACIDTBL + " where a in(select a from " + Table.NONACIDORCTBL + ")"); 
Hive,WITHOUT_CLASSIFICATION,//  to use as the move operation that created it is atomic. 
Hive,WITHOUT_CLASSIFICATION,// This will work only if the files are local files on webhcat server   (which is not very useful since users might not have access to that file system).  This is likely the HIVE-5188 issue 
Hive,WITHOUT_CLASSIFICATION,// truncate on external table is not allowed 
Hive,WITHOUT_CLASSIFICATION,//  sleep twice the TTL interval - things should have been cleaned by then. 
Hive,WITHOUT_CLASSIFICATION,//  Get the key column names for each side of the join   and check if the keys are all constants 
Hive,WITHOUT_CLASSIFICATION,//  set resolver and resolver context 
Hive,WITHOUT_CLASSIFICATION,//  GSS name for server 
Hive,WITHOUT_CLASSIFICATION,//  See comments for next method. 
Hive,WITHOUT_CLASSIFICATION,//  we can generate multi-phase aggregates   one distinct aggregate   no filter   sum/min/max/count in non-distinct aggregate   one or more non-distinct aggregates 
Hive,WITHOUT_CLASSIFICATION,//  if password is available in url it needs to be striped 
Hive,WITHOUT_CLASSIFICATION,/*  Spot check correctness of decimal column subtract decimal scalar. The case for   * addition checks all the cases for the template so don't do that redundantly here.    */
Hive,WITHOUT_CLASSIFICATION,//  Need to get a Connector so we look up the user's authorizations if not otherwise specified 
Hive,WITHOUT_CLASSIFICATION,//  otherwise we find the row groups that were selected on the client 
Hive,WITHOUT_CLASSIFICATION,//        + "are not unique keys for " 
Hive,WITHOUT_CLASSIFICATION,//  is enabled. 
Hive,WITHOUT_CLASSIFICATION,//  For expr "*" aliases should be iterated in the order they are specified   in the query. 
Hive,WITHOUT_CLASSIFICATION,//  override this method to forward its outputs 
Hive,WITHOUT_CLASSIFICATION,//    Implementation notes.     1. Since only local file systems are supported there is no need to use Hadoop      version of Path class.   2. java.nio package provides modern implementation of file and directory operations      which is better then the traditional java.io so we are using it here.      In particular it supports atomic creation of temporary files with specified      permissions in the specified directory. This also avoids various attacks possible      when temp file name is generated first followed by file creation.      See http://www.oracle.com/technetwork/articles/javase/nio-139333.html for      the description of NIO API and      http://docs.oracle.com/javase/tutorial/essential/io/legacy.html for the      description of interoperability between legacy IO api vs NIO API.   3. To avoid race conditions with readers of the metrics file the implementation      dumps metrics to a temporary file in the same directory as the actual metrics      file and then renames it to the destination. Since both are located on the same      filesystem this rename is likely to be atomic (as long as the underlying OS      support atomic renames.     NOTE: This reporter is very similar to         org.apache.hadoop.hive.metastore.metrics.JsonReporter.         It would be good to unify the two.   
Hive,WITHOUT_CLASSIFICATION,//  Ok try the UDF. 
Hive,WITHOUT_CLASSIFICATION,//  PRINCIPAL_NAME 
Hive,WITHOUT_CLASSIFICATION,//  disallow udfs that can potentially allow untrusted code execution 
Hive,WITHOUT_CLASSIFICATION,// $NON-NLS-1$ 
Hive,WITHOUT_CLASSIFICATION,//  Task Hash Map 
Hive,WITHOUT_CLASSIFICATION,//  Perform any value expressions.  Results will go into scratch columns. 
Hive,WITHOUT_CLASSIFICATION,//  This is akin to CBO cumulative cardinality model 
Hive,WITHOUT_CLASSIFICATION,//  Child #1 is the IF boolean expression. 
Hive,WITHOUT_CLASSIFICATION,//  if all dp columns got constant folded then disable this optimization 
Hive,WITHOUT_CLASSIFICATION,//  The worker should remove the subdir for aborted transaction 
Hive,WITHOUT_CLASSIFICATION,//  Verify query result 
Hive,WITHOUT_CLASSIFICATION,// Check the union field's length and offset 
Hive,WITHOUT_CLASSIFICATION,//  test non-vectorized non-acid combine 
Hive,WITHOUT_CLASSIFICATION,//  close + abort 
Hive,WITHOUT_CLASSIFICATION,//  tez blurs the boundary between map and reduce thus it has it's own config 
Hive,WITHOUT_CLASSIFICATION,//  FILES_ADDED_CHECKSUM 
Hive,WITHOUT_CLASSIFICATION,//  number of rows for the key in the given table 
Hive,WITHOUT_CLASSIFICATION,//  WORKERID 
Hive,WITHOUT_CLASSIFICATION,//  for whatever failure reason including that trash has lower encryption zone   retry with force delete 
Hive,WITHOUT_CLASSIFICATION,// if acid write add to plan output else don't bother 
Hive,WITHOUT_CLASSIFICATION,//  56 bits minus 1 byte. 
Hive,WITHOUT_CLASSIFICATION,//  verify that driver fails due to older version schema 
Hive,WITHOUT_CLASSIFICATION,/*  Count of number of false values seen so far  */
Hive,WITHOUT_CLASSIFICATION,//  alter table with invalid column type 
Hive,WITHOUT_CLASSIFICATION,//  Get full objects. For Oracle/etc. do it in batches. 
Hive,WITHOUT_CLASSIFICATION,//  CAST AS INT does not work as expected (ID is still considered as STRING in ORDER BY for some reason) 
Hive,WITHOUT_CLASSIFICATION,//  Test that existing shared_read partition with new shared_read coalesces to 
Hive,WITHOUT_CLASSIFICATION,//  We will start a new key group. We can call flush the buffer   of children from lastChildIndex (inclusive) to the last child and   propagate processGroup to those children. 
Hive,WITHOUT_CLASSIFICATION,//  TODO HIVE-14042. Propagating abort to dummyOps. 
Hive,WITHOUT_CLASSIFICATION,//  A is maxed out on capacity so this move should fail the session 
Hive,WITHOUT_CLASSIFICATION,//  HiveServer2 auth configuration 
Hive,WITHOUT_CLASSIFICATION,//  for use by Column-Scalar and Scalar-Column arithmetic for null propagation 
Hive,WITHOUT_CLASSIFICATION,//  DB_NAME 
Hive,WITHOUT_CLASSIFICATION,//  Mapping from constraint name to list of foreign keys 
Hive,WITHOUT_CLASSIFICATION,//  remove any existing entries that are contained by the new one 
Hive,WITHOUT_CLASSIFICATION,/*      * If OrcSplit.isAcid returns true we know for sure it is ACID.      */
Hive,WITHOUT_CLASSIFICATION,// if here ther were no locks that blocked any locks in 'locksBeingChecked' - acquire them all 
Hive,WITHOUT_CLASSIFICATION,/*  256 files x 100 size for 11 splits  */
Hive,WITHOUT_CLASSIFICATION,//  If there are no inputs; the Execution engine skips the operator tree.   To prevent it from happening; an opaque  ZeroRows input is added here - when needed. 
Hive,WITHOUT_CLASSIFICATION,//  sp column names   dp column names   default partition name in case of null or empty value   maximum dynamic partitions created per mapper/reducer 
Hive,WITHOUT_CLASSIFICATION,//  Spark memory per task and total number of cores 
Hive,WITHOUT_CLASSIFICATION,//  We will always release copies at the end. 
Hive,WITHOUT_CLASSIFICATION,//  schema name 
Hive,WITHOUT_CLASSIFICATION,//  specifies db and pattern 
Hive,WITHOUT_CLASSIFICATION,//  There should be only 1 directory left: base_0000001. 
Hive,WITHOUT_CLASSIFICATION,//  Create the row resolver for this operator from the output columns 
Hive,WITHOUT_CLASSIFICATION,//  Create the db 
Hive,WITHOUT_CLASSIFICATION,//  The selected array is already filled in as we want it. 
Hive,WITHOUT_CLASSIFICATION,/*      * The sign is encoded as the least significant bit.     *     * We need to adjust our decimal before conversion to binary.     *     * Positive:     *   Multiply by 2.     *     * Negative:     *   Logic in SerializationUtils.writeBigInteger does a negate on the BigInteger. We     *   do not have to since FastHiveDecimal stores the numbers unsigned in fast0 fast1     *   and fast2.  We do need to subtract one though.     *     *   And then multiply by 2 and add in the 1 sign bit.     *     *   CONSIDER: This could be combined.      */
Hive,WITHOUT_CLASSIFICATION,//  Metastore SSL settings 
Hive,WITHOUT_CLASSIFICATION,//  An optional group containing a repeated anonymous group "map" containing 
Hive,WITHOUT_CLASSIFICATION,//  Set Checkpoint task as dependant to create table task. So if same dump is retried for 
Hive,WITHOUT_CLASSIFICATION,//  Set reducer parallelism 
Hive,WITHOUT_CLASSIFICATION,/*        Below are the properties that need to be set based on what database this test is going to be run      */
Hive,WITHOUT_CLASSIFICATION,//  Keep track of S[0..x] 
Hive,WITHOUT_CLASSIFICATION,//  Test that committing unlocks 
Hive,WITHOUT_CLASSIFICATION,//  For backwards compatibility reasons we honor the older   HIVEMAPJOINBUCKETCACHESIZE if set different from default. 
Hive,WITHOUT_CLASSIFICATION,//  tinyint   smallint   int   bigint   double   float   string   string   struct   array   map   bool   complex  decimal(52)  char(10)  varchar(20)  date  timestamp  binary 
Hive,WITHOUT_CLASSIFICATION,/*    * Gets file data for particular offsets. The range list is modified in place; it is then   * returned (since the list head could have changed). Ranges are replaced with cached ranges.   * In case of partial overlap with cached data full cache blocks are always returned;   * there's no capacity for partial matches in return type. The rules are as follows:   * 1) If the requested range starts in the middle of a cached range that cached range will not   *    be returned by default (e.g. if [100200) and [200300) are cached the request for   *    [150300) will only return [200300) from cache). This may be configurable in impls.   *    This is because we assume well-known range start offsets are used (rg/stripe offsets) so   *    a request from the middle of the start doesn't make sense.   * 2) If the requested range ends in the middle of a cached range that entire cached range will   *    be returned (e.g. if [100200) and [200300) are cached the request for [100250) will   *    return both ranges). It should really be same as #1 however currently ORC uses estimated   *    end offsets; we do in fact know in such cases that partially-matched cached block (rg)   *    can be thrown away the reader will never touch it; but we need code in the reader to   *    handle such cases to avoid disk reads for these "tails" vs real unmatched ranges.   *    Some sort of InvalidCacheChunk could be placed to avoid them. TODO   * @param base base offset for the ranges (stripe/stream offset in case of ORC).    */
Hive,WITHOUT_CLASSIFICATION,//  simple division.   Yes we should do something like this:   http://www.hackersdelight.org/divcMore.pdf   but later... (anyway this will be eventually replaced by   intrinsics in Java 8) 
Hive,WITHOUT_CLASSIFICATION,// ---------------------------------------------------------------------------   Process Single-Column String Inner Join on a vectorized row batch.   
Hive,WITHOUT_CLASSIFICATION,/*        *  Hashing the string is potentially expensive so is better to branch.       *  Additionally not looking at values for nulls allows us not reset the values.        */
Hive,WITHOUT_CLASSIFICATION,//  Create estimators 
Hive,WITHOUT_CLASSIFICATION,//  the stage that this vertex belongs to 
Hive,WITHOUT_CLASSIFICATION,//  Re-enable the node. If a task succeeded a slot may have become available.   Also reset commFailures since a task was able to communicate back and indicate success. 
Hive,WITHOUT_CLASSIFICATION,//  Don't use streaming for distinct cases 
Hive,WITHOUT_CLASSIFICATION,//  only persist input/output format to metadata when it is explicitly specified. 
Hive,WITHOUT_CLASSIFICATION,//  Some mix tests (STRING CHAR) (VARCHAR CHAR) (VARCHAR STRING)... 
Hive,WITHOUT_CLASSIFICATION,/*      * We need to use a cleanup interval which is how often the cleanup thread will kick in     * and go do a check to see if any of the connections can be expired. We don't want to     * do this too often because it'd be like having a mini-GC going off every so often     * so we limit it to a minimum of DEFAULT_HIVE_CACHE_EXPIRY_TIME_SECONDS. If the client     * has explicitly set a larger timeout on the cache though we respect that and use that      */
Hive,WITHOUT_CLASSIFICATION,//  avoid adding group by for correlated IN/EXISTS queries   since this is rewritting into semijoin 
Hive,WITHOUT_CLASSIFICATION,//  insert new filter between RS and parent of RS 
Hive,WITHOUT_CLASSIFICATION,//  unknown | F | unknown 
Hive,WITHOUT_CLASSIFICATION,//  not from this 
Hive,WITHOUT_CLASSIFICATION,//  See comments for sqlPrecision. 
Hive,WITHOUT_CLASSIFICATION,//  Insert the select operator in between. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure reuse changes the FIFO order of the session. 
Hive,WITHOUT_CLASSIFICATION,//  The first line check should handle the OOB. 
Hive,WITHOUT_CLASSIFICATION,// get the bucket id 
Hive,WITHOUT_CLASSIFICATION,//  Set the last query time 
Hive,WITHOUT_CLASSIFICATION,//  for output rows of this operator 
Hive,WITHOUT_CLASSIFICATION,//  Already used. Update the port and retry. 
Hive,WITHOUT_CLASSIFICATION,//  Delete all things. 
Hive,WITHOUT_CLASSIFICATION,/* the silly looking call to Builder below is to get the default value of session timeout    from Curator which itself exposes it as system property */
Hive,WITHOUT_CLASSIFICATION,/*    * We allow CTE definitions in views. So we can end up with a hierarchy of CTE definitions:   * - at the top level of a query statement   * - where a view is referenced.   * - views may refer to other views.   *   * The scoping rules we use are: to search for a CTE from the current QB outwards. In order to   * disambiguate between CTES are different levels we qualify(prefix) them with the id of the QB   * they appear in when adding them to the <code>aliasToCTEs</code> map.   *    */
Hive,WITHOUT_CLASSIFICATION,//  Keep partKeyValMap in synch as well. 
Hive,WITHOUT_CLASSIFICATION,//  partSpec is a mapping from partition column name to its value. 
Hive,WITHOUT_CLASSIFICATION,//  VALID_TXN_LIST 
Hive,WITHOUT_CLASSIFICATION,// Testing substring index starting with 0 and length equal to array length 
Hive,WITHOUT_CLASSIFICATION,//  init input object inspectors 
Hive,WITHOUT_CLASSIFICATION,//  Second check if this work has multiple reduceSinks. If so do split. 
Hive,WITHOUT_CLASSIFICATION,//  TODO enable MetadataFilter by using readFooter(Configuration configuration Path file   MetadataFilter filter) API 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getArray(java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  Return the settable equivalent object inspector for primitive categories   For eg: for table T containing partitions p1 and p2 (possibly different   from the table T) return the settable inspector for T. The inspector for 
Hive,WITHOUT_CLASSIFICATION,//  parsing the keys and values one by one 
Hive,WITHOUT_CLASSIFICATION,//  Reduce side of optimized plan) 
Hive,WITHOUT_CLASSIFICATION,//  set command is currently not authorized through the API 
Hive,WITHOUT_CLASSIFICATION,//  throw a HiveException if the table/partition is bucketized 
Hive,WITHOUT_CLASSIFICATION,/*  100 files x 1000 size for 9 splits  */
Hive,WITHOUT_CLASSIFICATION,//  Note: after this the caller MUST send the downgrade message to downgradedTask         (outside of the writeLock preferably) before exiting. 
Hive,WITHOUT_CLASSIFICATION,//  ERRORS 
Hive,WITHOUT_CLASSIFICATION,//  we're the only node just clear out the expression 
Hive,WITHOUT_CLASSIFICATION,//  user explicitly specified queue name 
Hive,WITHOUT_CLASSIFICATION,//  Obtain inspector for schema 
Hive,WITHOUT_CLASSIFICATION,//  get the size of cache AFTER 
Hive,WITHOUT_CLASSIFICATION,//  restore 
Hive,WITHOUT_CLASSIFICATION,//  Byte values. 
Hive,WITHOUT_CLASSIFICATION,//  Now test again with a seed. 
Hive,WITHOUT_CLASSIFICATION,//  EXPRS 
Hive,WITHOUT_CLASSIFICATION,//  skip the first which is always required 
Hive,WITHOUT_CLASSIFICATION,//  Convert millis result back to days 
Hive,WITHOUT_CLASSIFICATION,//  indexColumnVector includes the keys of Map 
Hive,WITHOUT_CLASSIFICATION,//  JAVA64_OBJECT + PRIMITIVES1 * 2 + JAVA64_ARRAY; 
Hive,WITHOUT_CLASSIFICATION,//  Populate the names and order of columns for the first table 
Hive,WITHOUT_CLASSIFICATION,//  Input files can be pruned 
Hive,WITHOUT_CLASSIFICATION,//  Please take a look at the instructions in HiveAuthorizer.java before 
Hive,WITHOUT_CLASSIFICATION,//  Allowed operations:   IntervalYearMonth + IntervalYearMonth = IntervalYearMonth   IntervalYearMonth + Date = Date (operands reversible)   IntervalYearMonth + Timestamp = Timestamp (operands reversible)   IntervalDayTime + IntervalDayTime = IntervalDayTime   IntervalDayTime + Date = Timestamp (operands reversible)   IntervalDayTime + Timestamp = Timestamp (operands reversible) 
Hive,WITHOUT_CLASSIFICATION,//  try using 2nd permanent function and verify its only 2nd one that shows up 
Hive,WITHOUT_CLASSIFICATION,//  The join task is converted to a mapjoin task. This can only happen if   hive.auto.convert.join.noconditionaltask is set to true. No conditional task was 
Hive,WITHOUT_CLASSIFICATION,//  TODO HIVE-10236 Report a fatal error over the umbilical 
Hive,WITHOUT_CLASSIFICATION,//  alias to filter mapping 
Hive,WITHOUT_CLASSIFICATION,//  inner Map 
Hive,WITHOUT_CLASSIFICATION,//  5. Extract rest of join predicate info. We infer the rest of join condition      that will be added to the filters (join conditions that are not part of 
Hive,WITHOUT_CLASSIFICATION,//  The expiring session may or may not be in the pool. 
Hive,WITHOUT_CLASSIFICATION,/*          * Hive treats names that start with '_c' as internalNames; so change         * the names so we don't run into this issue when converting back to         * Hive AST.          */
Hive,WITHOUT_CLASSIFICATION,//  We do not proactively remove locked items from the heap and opportunistically try to   remove from the list (since eviction is mostly from the list). If eviction stumbles upon   a locked item in either it will remove it from cache; when we unlock we are going to   put it back or update it depending on whether this has happened. This should cause   most of the expensive cache update work to happen in unlock not blocking processing. 
Hive,WITHOUT_CLASSIFICATION,//  for jackson 
Hive,WITHOUT_CLASSIFICATION,//  Don't remove the old entry - in SparkPartitionPruningSink it still   refers to the old TS and we need to lookup it later in   processPartitionPruningSink. 
Hive,WITHOUT_CLASSIFICATION,//  remove the pwd from conf file so that job tracker doesn't show this   logs 
Hive,WITHOUT_CLASSIFICATION,//  add to n-gram estimation only if the context matches 
Hive,WITHOUT_CLASSIFICATION,//  routines can't be used directly. 
Hive,WITHOUT_CLASSIFICATION,//  partition columns 
Hive,WITHOUT_CLASSIFICATION,//  when type is not set init hasn't been called yet 
Hive,WITHOUT_CLASSIFICATION,//  Don't wait for the thread. 
Hive,WITHOUT_CLASSIFICATION,//  create reduce 
Hive,WITHOUT_CLASSIFICATION,//  can happen if this operator does not carry forward the previous bucketing columns   for e.g. another join operator which does not carry one of the sides' key columns 
Hive,WITHOUT_CLASSIFICATION,//  Read lock for get operation 
Hive,WITHOUT_CLASSIFICATION,//  All the fields of this event are final so no reason to create a new one for each   listener 
Hive,WITHOUT_CLASSIFICATION,//  The SIMD optimized form of "a < b" is "(a - b) >>> 63" 
Hive,WITHOUT_CLASSIFICATION,//  Validation's been done at compile time. no validation is needed here. 
Hive,WITHOUT_CLASSIFICATION,//  single double value 
Hive,WITHOUT_CLASSIFICATION,//  TABLE_DB 
Hive,WITHOUT_CLASSIFICATION,//  check projRel only projects one expression   check this project only projects one expression i.e. scalar 
Hive,WITHOUT_CLASSIFICATION,//  Our reading is positioned to the key. 
Hive,WITHOUT_CLASSIFICATION,//  Get the MapredLocalWork 
Hive,WITHOUT_CLASSIFICATION,/*      * Restriction.13.m :: In the case of an implied Group By on a     * correlated SubQuery the SubQuery always returns 1 row.     * An exists on a SubQuery with an implied GBy will always return true.     * Whereas Algebraically transforming to a Join may not return true. See     * Specification doc for details.     * Similarly a not exists on a SubQuery with a implied GBY will always return false.      */
Hive,WITHOUT_CLASSIFICATION,//  'n' columns where 'n' is the length of the bucketed columns. 
Hive,WITHOUT_CLASSIFICATION,//  A config variable set via a System Property a config variable set in the CLI   a config variable not in the default List of config variables and a config variable in the   default list of config variables but which has not been overridden 
Hive,WITHOUT_CLASSIFICATION,//  At this point we are done processing the input. Close the record processor 
Hive,WITHOUT_CLASSIFICATION,//  Init output object inspectors.     The return type for a partial aggregation is still a list of doubles as in   GenericUDAFHistogramNumeric but we add on the percentile values requested to the   end and handle serializing/deserializing before we pass things on to the parent   method.   The return type for FINAL and COMPLETE is a full aggregation result which is a 
Hive,WITHOUT_CLASSIFICATION,//  a list of columns names and maps them to 0..n-1 indices. 
Hive,WITHOUT_CLASSIFICATION,//  3. Perform a major compaction. Nothing should change.   Both deltas and base dirs should have the same name. 
Hive,WITHOUT_CLASSIFICATION,//  This is the vectorized row batch description of the output of the native vectorized map join   operator.  It is based on the incoming vectorization context.  Its projection may include 
Hive,WITHOUT_CLASSIFICATION,// having a non null create table grants privileges causes problems in   the tests that compares underlying thrift Table object of created   table with a table object that was fetched from metastore.   This is because the fetch does not populate the privileges field in Table 
Hive,WITHOUT_CLASSIFICATION,//  TODO: the below assumes that all the arguments to IN are of the same type; 
Hive,WITHOUT_CLASSIFICATION,//  cancel the delegation token 
Hive,WITHOUT_CLASSIFICATION,//  if all drones where abandoned on a host try replacing them. 
Hive,WITHOUT_CLASSIFICATION,//  HBase API is convoluted. 
Hive,WITHOUT_CLASSIFICATION,//  There's always just one file that we have merged.   The union/DP/etc. should already be account for in the path. 
Hive,WITHOUT_CLASSIFICATION,//  Tell our super class FilterStringColumnInList it will be evaluating our scratch   BytesColumnVector. 
Hive,WITHOUT_CLASSIFICATION,//  Verify that field changes are consistent with what Hive does. Note: we could handle this. 
Hive,WITHOUT_CLASSIFICATION,//  Finalize the previous record. 
Hive,WITHOUT_CLASSIFICATION,//  find the firing rule   find the rule from the stack specified 
Hive,WITHOUT_CLASSIFICATION,//  Following is the main loop which iterates through all the cookies send by the client.   The HS2 generated cookies are of the format hive.server2.auth=<value>   A cookie which is identified as a hiveserver2 generated cookie is validated   by calling signer.verifyAndExtract(). If the validation passes send the   username for which the cookie is validated to the caller. If no client side 
Hive,WITHOUT_CLASSIFICATION,//  currently getImportedKeys always returns an empty resultset for Hive 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.ICLIService#getColumns(org.apache.hive.service.cli.SessionHandle)    */
Hive,WITHOUT_CLASSIFICATION,//  fallthrough 
Hive,WITHOUT_CLASSIFICATION,//  special case for handling false constants 
Hive,WITHOUT_CLASSIFICATION,//  UNDONE: Until Fast BinarySortable supports complex types -- disable. 
Hive,WITHOUT_CLASSIFICATION,//  update non-distinct key aggregations : "KEY._colx:t._coly" 
Hive,WITHOUT_CLASSIFICATION,//  Finally exclude preds that are already in the subtree as given by the metadata provider   Note: this is the last step trying to avoid the expensive call to the metadata provider 
Hive,WITHOUT_CLASSIFICATION,//  Lookup the state in the map. 
Hive,WITHOUT_CLASSIFICATION,//  Changing string value; getCharacterLength() should update accordingly 
Hive,WITHOUT_CLASSIFICATION,//  CREATE_TABLE EVENT on partitioned table 
Hive,WITHOUT_CLASSIFICATION,//  create a file in the folder to mark it 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#commit()    */
Hive,WITHOUT_CLASSIFICATION,//  We remove the discardable RS operator 
Hive,WITHOUT_CLASSIFICATION,// for jackson to instantiate 
Hive,WITHOUT_CLASSIFICATION,//  We need to use the OpParseContext of the child SelectOperator to replace the 
Hive,WITHOUT_CLASSIFICATION,//  Free up any previously allocated buffers that are referenced by vector 
Hive,WITHOUT_CLASSIFICATION,//  First apply configuration applicable to both Hive Cli and HiveServer2   Not adding any authorization related restrictions to hive cli   grant all privileges for table to its owner - set this in cli as well so that owner   has permissions via HiveServer2 as well. 
Hive,WITHOUT_CLASSIFICATION,//  generate n-grams wherever the context matches 
Hive,WITHOUT_CLASSIFICATION,//  First just check that this translates 
Hive,WITHOUT_CLASSIFICATION,//  this method contains various asserts to warn if environment variables are in a buggy state 
Hive,WITHOUT_CLASSIFICATION,//  Convert skewed table to non-skewed table. 
Hive,WITHOUT_CLASSIFICATION,//  OK fall through. 
Hive,WITHOUT_CLASSIFICATION,//  Aggr checks for sorted argList. 
Hive,WITHOUT_CLASSIFICATION,//  Executed if relevant and used to contain all the other details about the table if not. 
Hive,WITHOUT_CLASSIFICATION,//  metastore and so some partitions may have no data based on other filters. 
Hive,WITHOUT_CLASSIFICATION,//  CREATE TABLE AS SELECT statement 
Hive,WITHOUT_CLASSIFICATION,//  launch a tez job 
Hive,WITHOUT_CLASSIFICATION,//  no-op 
Hive,WITHOUT_CLASSIFICATION,//  A mapper can span multiple files/partitions.   The serializers need to be reset if the input file changed 
Hive,WITHOUT_CLASSIFICATION,//  Need to test this with LLAP settings which requires some additional configurations set. 
Hive,WITHOUT_CLASSIFICATION,//  Check single column for repeating. 
Hive,WITHOUT_CLASSIFICATION,//  this table is not good to be a big table. 
Hive,WITHOUT_CLASSIFICATION,//  an individual column becomes a STRING 
Hive,WITHOUT_CLASSIFICATION,//  Now we load data into the tables and see if an incremental   repl drop/load can duplicate it. 
Hive,WITHOUT_CLASSIFICATION,//  UNDONE: Performance problem with conversion to String then bytes... 
Hive,WITHOUT_CLASSIFICATION,//  0 1 
Hive,WITHOUT_CLASSIFICATION,//  large to fit into main memory. 
Hive,WITHOUT_CLASSIFICATION,//  after deserialization need to recreate the txnToWriteIdList as its not under JsonProperty. 
Hive,WITHOUT_CLASSIFICATION,/*  * Comment from BooleanWritable evaluate(DateWritable d) *     // date value to boolean doesn't make any sense. * So we always set the output to NULL.  */
Hive,WITHOUT_CLASSIFICATION,//  if a DPP is with MJ the tree won't be split and so we don't have to remove it 
Hive,WITHOUT_CLASSIFICATION,//  1) Don't call postRead - we will have checked everything here.   2) Ignore GenericUDFBridge it's checked separately in LlapUdfBridgeChecker.   Run post-hook. 
Hive,WITHOUT_CLASSIFICATION,//  this will abort initializeOp() 
Hive,WITHOUT_CLASSIFICATION,//  skip the first node which is always required 
Hive,WITHOUT_CLASSIFICATION,//  View DDL 
Hive,WITHOUT_CLASSIFICATION,/*    * The length of each field. If the value repeats for every entry then it is stored   * in vector[0] and isRepeating from the superclass is set to true.    */
Hive,WITHOUT_CLASSIFICATION,//  Following remote job may refer to classes in this jar and the remote job would be executed   in a different thread so we add this jar path to JobContext for further usage. 
Hive,WITHOUT_CLASSIFICATION,// failed 
Hive,WITHOUT_CLASSIFICATION,//  Add new residual preds 
Hive,WITHOUT_CLASSIFICATION,//  3. We will extract the literals to introduce in the IN clause. 
Hive,WITHOUT_CLASSIFICATION,// w/o order by likely currently running compactions will be first (LHS of Union) 
Hive,WITHOUT_CLASSIFICATION,//  Read aggregated stats for one column 
Hive,WITHOUT_CLASSIFICATION,//  NEW TAI LUE LETTER LOW XA U+1986 (3 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  Test basic truncate to vector. 
Hive,WITHOUT_CLASSIFICATION,//  0 0 
Hive,WITHOUT_CLASSIFICATION,//  We start with an empty wordlist and build it up 
Hive,WITHOUT_CLASSIFICATION,//  key index to nullsafe join flag 
Hive,WITHOUT_CLASSIFICATION,//  adjustment array 
Hive,WITHOUT_CLASSIFICATION,//  add constant object overhead for union 
Hive,WITHOUT_CLASSIFICATION,//  2019-01-02 00:00:00 GMT is 1546387200000 milliseconds after epoch 
Hive,WITHOUT_CLASSIFICATION,//  Check if the source file unmodified even after copy to see if we copied the right file 
Hive,WITHOUT_CLASSIFICATION,//  META_INFO 
Hive,WITHOUT_CLASSIFICATION,//  4. Run Cleaner. It should remove the 2 delta dirs. 
Hive,WITHOUT_CLASSIFICATION,//  We have some disk data. Separate it by column chunk and put into cache. 
Hive,WITHOUT_CLASSIFICATION,//  Create a list of top op nodes 
Hive,WITHOUT_CLASSIFICATION,//  There should be no rows in the delete_delta because there have been no delete events. 
Hive,WITHOUT_CLASSIFICATION,//  Count. 
Hive,WITHOUT_CLASSIFICATION,//  test mode in hive mode 
Hive,WITHOUT_CLASSIFICATION,// variable access should not be done and use exportRootDir() instead. 
Hive,WITHOUT_CLASSIFICATION,//  This means that the lock is being committed at this instant hence   the cleaner should not remove it even if it times out. If transaction 
Hive,WITHOUT_CLASSIFICATION,//  It is fired only once: on the original node 
Hive,WITHOUT_CLASSIFICATION,//  We have the UDF or we are in the session registry (or both). 
Hive,WITHOUT_CLASSIFICATION,//  Partition path can be null in the case of a new create partition - in this case   we try to default to checking the permissions of the parent table.   Partition itself can also be null in cases where this gets called as a generic 
Hive,WITHOUT_CLASSIFICATION,//  Not synchronizing creation of mapOp with an invocation. Check immediately   after creation in case abort has been set.   Relying on the regular flow to clean up the actual operator. i.e. If an exception is   thrown an attempt will be made to cleanup the op.   If we are here - exit out via an exception. If we're in the middle of the opeartor.initialize 
Hive,WITHOUT_CLASSIFICATION,// this is NULL for minor compaction  it may also be null if there is no base - only deltas 
Hive,WITHOUT_CLASSIFICATION,//  FOREIGN_SCHEMA_NAME 
Hive,WITHOUT_CLASSIFICATION,//  Replicate all the events happened so far. It should fail as the data files missing in 
Hive,WITHOUT_CLASSIFICATION,//  Remove default partition from partition names and get aggregate stats again 
Hive,WITHOUT_CLASSIFICATION,//            refs 
Hive,WITHOUT_CLASSIFICATION,//  Since the input 
Hive,WITHOUT_CLASSIFICATION,//  we are using oracle schema because it is simpler to parse no quotes or backticks etc 
Hive,WITHOUT_CLASSIFICATION,//  If ckeys or pkeys have constant node expressions avoid the merge. 
Hive,WITHOUT_CLASSIFICATION,//  TopN query results as records 
Hive,WITHOUT_CLASSIFICATION,//  Schedule Major compaction on all the partitions/table to clean aborted data 
Hive,WITHOUT_CLASSIFICATION,//  Iterate over each group of subqueries with the same group by/distinct keys 
Hive,WITHOUT_CLASSIFICATION,//  take one's complement' 
Hive,WITHOUT_CLASSIFICATION,//  If the driver context has been shutdown (due to query cancellation) kill the Spark job 
Hive,WITHOUT_CLASSIFICATION,//  99999999.99999999999999999999999999999949999 
Hive,WITHOUT_CLASSIFICATION,//  Tests wait queue behaviour for fragments which have reported to the AM but have not given up their executor slot. 
Hive,WITHOUT_CLASSIFICATION,//  / XXX: From o.a.zk.t.ClientBase 
Hive,WITHOUT_CLASSIFICATION,//  If we're updating add the ROW__ID expression then make the following column accesses   offset by 1 so that we don't try to convert the ROW__ID 
Hive,WITHOUT_CLASSIFICATION,//  does the query have a using clause 
Hive,WITHOUT_CLASSIFICATION,//  Now insert this record into the list. 
Hive,WITHOUT_CLASSIFICATION,//  Serialize the rest of the values in the AggBuffer 
Hive,WITHOUT_CLASSIFICATION,//  This block exists for debugging purposes: we want to check whether   the col stats cache is working properly and we are retrieving the 
Hive,WITHOUT_CLASSIFICATION,//  1 means asc could really use enum here in the thrift if 
Hive,WITHOUT_CLASSIFICATION,//  TODO: For now only support sampling on up to two columns   Need to change it to list of columns 
Hive,WITHOUT_CLASSIFICATION,//  errored 
Hive,WITHOUT_CLASSIFICATION,//  Error getting children of node -- probably node has been deleted 
Hive,WITHOUT_CLASSIFICATION,//  3. Download resources dir 
Hive,WITHOUT_CLASSIFICATION,//  token was not a storage format token 
Hive,WITHOUT_CLASSIFICATION,//  Argh HCatRecord doesnt implement equals() 
Hive,WITHOUT_CLASSIFICATION,//  x events to insert last repl ID: replDumpId+3x 
Hive,WITHOUT_CLASSIFICATION,//  add the move task 
Hive,WITHOUT_CLASSIFICATION,//  All small writes to the first buffer should be in contiguous memory 
Hive,WITHOUT_CLASSIFICATION,// here if start of explicit txn 
Hive,WITHOUT_CLASSIFICATION,//  output OI should have varchar type params 
Hive,WITHOUT_CLASSIFICATION,//     Table tbl = client.getTable(MetaStoreUtils.DEFAULT_DATABASE_NAME likeTbl);      assertEquals(likeTbltbl.getTableName());      List<FieldSchema> cols = tbl.getSd().getCols();      assertEquals(1 cols.size());      assertEquals(new FieldSchema("a" "int" null) cols.get(0));      assertEquals("org.apache.hadoop.hive.ql.io.RCFileInputFormat"tbl.getSd().getInputFormat());      assertEquals("org.apache.hadoop.hive.ql.io.RCFileOutputFormat"tbl.getSd().getOutputFormat());      Map<String String> tblParams = tbl.getParameters();      assertEquals("org.apache.hadoop.hive.hcat.rcfile.RCFileInputStorageDriver" tblParams.get("hcat.isd"));      assertEquals("org.apache.hadoop.hive.hcat.rcfile.RCFileOutputStorageDriver" tblParams.get("hcat.osd"));        hcatDriver.run("drop table junit_sem_analysis");      hcatDriver.run("drop table "+likeTbl); 
Hive,WITHOUT_CLASSIFICATION,//  the serdes for the partition columns 
Hive,WITHOUT_CLASSIFICATION,//  For example      SELECT deptno COUNT(DISTINCT sal) SUM(DISTINCT sal)      FROM emp      GROUP BY deptno     becomes        SELECT deptno COUNT(distinct_sal) SUM(distinct_sal)      FROM (        SELECT DISTINCT deptno sal AS distinct_sal        FROM EMP GROUP BY deptno)      GROUP BY deptno 
Hive,WITHOUT_CLASSIFICATION,//  unsupported conversion 
Hive,WITHOUT_CLASSIFICATION,//  Assign ids to all vertices   targets at first then sources. 
Hive,WITHOUT_CLASSIFICATION,//  Values needed for numeric arithmetic UDFs 
Hive,WITHOUT_CLASSIFICATION,//  Size of string buffer in bytes 
Hive,WITHOUT_CLASSIFICATION,//  4. Gen RS 
Hive,WITHOUT_CLASSIFICATION,//  Load the column stats and table params with 30 TB scale 
Hive,WITHOUT_CLASSIFICATION,//  and retry 
Hive,WITHOUT_CLASSIFICATION,/*    * @return A new hash multi-set result implementation specific object.   *   * The object can be used to access the *count* of values when the key is contained in the   * multi-set or access spill information when the partition with the key is currently spilled.    */
Hive,WITHOUT_CLASSIFICATION,//  Handle type casts that may contain type parameters 
Hive,WITHOUT_CLASSIFICATION,//  instance of shared utils 
Hive,WITHOUT_CLASSIFICATION,//  INTEGER_BITMASK 
Hive,WITHOUT_CLASSIFICATION,//  No specifications default to UTF8 String storage for backwards compatibility 
Hive,WITHOUT_CLASSIFICATION,//  test using loadTableWork 
Hive,WITHOUT_CLASSIFICATION,//  2nd condition occurs when the input has 0 rows (possible due to   filtering joins etc). 
Hive,WITHOUT_CLASSIFICATION,//  1. Create column schema 
Hive,WITHOUT_CLASSIFICATION,// Map column number to type (this is always non-null for a useful vec context) 
Hive,WITHOUT_CLASSIFICATION,//  This is not a config that users set in hive-site. It's only use is to share information   between the java component of the service driver and the python component. 
Hive,WITHOUT_CLASSIFICATION,/*  * breakup the original WindowingSpec into a set of WindowingSpecs. * Each WindowingSpec is executed in an instance of PTFOperator * preceded by ReduceSink and Extract. * The logic to componentize is straightforward: * - distribute Window Fn. Specs from original Window Spec into a set of WindowSpecs *   based on their Partitioning. * - A Group of WindowSpecs is a subset of the Window Fn Invocations in the QueryBlock that *   have the same Partitioning(Partition + Order spec). * - Each Group is put in a new WindowingSpec and is evaluated in its own PTFOperator instance. * - the order of computation is then inferred based on the dependency between Groups. *   If 2 groups have the same dependency then the Group with the function that is *   earliest in the SelectList is executed first.  */
Hive,WITHOUT_CLASSIFICATION,//  Example handling of dirs with a .   shims/hadoop-2.6     -> moduleName=shims.hadoop-.2.6 
Hive,WITHOUT_CLASSIFICATION,//  used for the analyze command (statistics)   used for the analyze command (statistics) (noscan) 
Hive,WITHOUT_CLASSIFICATION,//  reset rowcontainer's serde objectinspector and tableDesc. 
Hive,WITHOUT_CLASSIFICATION,//  Find the closest pair of bins in terms of x coordinates. Break ties randomly. 
Hive,WITHOUT_CLASSIFICATION,//  Reopening (close + open) allowed in opened state: 
Hive,WITHOUT_CLASSIFICATION,//  no NOT keyword 
Hive,WITHOUT_CLASSIFICATION,//  write to file 
Hive,WITHOUT_CLASSIFICATION,//  for local directory - we always write to map-red intermediate   store and then copy to local fs 
Hive,WITHOUT_CLASSIFICATION,//  The source table 
Hive,WITHOUT_CLASSIFICATION,//  Prepare future cache buffer. 
Hive,WITHOUT_CLASSIFICATION,// Since the user running the test belongs to the group  obtained above the call to getDelegationTokenStr will succeed 
Hive,WITHOUT_CLASSIFICATION,//        See setLoadFileType and setIsAcidIow calls elsewhere for an example. 
Hive,WITHOUT_CLASSIFICATION,//  True if this statement creates or replaces a materialized view 
Hive,WITHOUT_CLASSIFICATION,/*  * An single LONG key hash multi-set optimized for vector map join.  */
Hive,WITHOUT_CLASSIFICATION,//  Concurrent force-eviction - ignore. 
Hive,WITHOUT_CLASSIFICATION,//  Lost the duck. 
Hive,WITHOUT_CLASSIFICATION,/*            * last_value: when an Sort Key is specified then last_value should return the           * last value among rows with the same Sort Key value.            */
Hive,WITHOUT_CLASSIFICATION,//  Break if iteration times out 
Hive,WITHOUT_CLASSIFICATION,//  Cleanup the scratch dir before starting 
Hive,WITHOUT_CLASSIFICATION,//  size for each input alias. 
Hive,WITHOUT_CLASSIFICATION,//  This records how many rows have been inserted or deleted.  It is separate from insertedRows 
Hive,WITHOUT_CLASSIFICATION,//  Reader-specific incompatibility like SMB or schema evolution. 
Hive,WITHOUT_CLASSIFICATION,// this is not used for DELETE commands (partitionEval is not set up correctly   (or needed) for that 
Hive,WITHOUT_CLASSIFICATION,//  If there's no lock we don't need to do heartbeat   Start heartbeat for read-only queries which don't open transactions but requires locks.   For those that require transactions the heartbeat has already been started in openTxn. 
Hive,WITHOUT_CLASSIFICATION,//  Since there is no concept of a group we don't invoke   startGroup/endGroup for a mapper 
Hive,WITHOUT_CLASSIFICATION,// This implementation completely and exhaustively reverses the addGauge method above. 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:org.apache.hadoop.hive.ql.hooks.proto.HiveHookEventProto) 
Hive,WITHOUT_CLASSIFICATION,//  Row format (SerDe) 
Hive,WITHOUT_CLASSIFICATION,//  Is smbJoin possible? We need correct bucketing 
Hive,WITHOUT_CLASSIFICATION,//  revert partSpecToFileMapping to inputToPartSpecMapping 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#clearBatch()    */
Hive,WITHOUT_CLASSIFICATION,//  that SemanticAnalyzer finds are in use 
Hive,WITHOUT_CLASSIFICATION,//  double scalar/column IF 
Hive,WITHOUT_CLASSIFICATION,//  only create bucket files only if no dynamic partitions   buckets of dynamic partitions will be created for each newly created partition  todo IOW integration. Full Acid uses the else if block to create Acid's RecordUpdater (HiveFileFormatUtils)   and that will set writingBase(conf.getInsertOverwrite()) 
Hive,WITHOUT_CLASSIFICATION,//  Drop the table if it exists 
Hive,WITHOUT_CLASSIFICATION,//  Note: we assume that workers run on the same threads repeatedly so we can set up         the session here and it will be reused without explicitly storing in the worker. 
Hive,WITHOUT_CLASSIFICATION,/*  1 files x 100 size for 11 splits  */
Hive,WITHOUT_CLASSIFICATION,//  no metrics gathered by default 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hadoop.hive.ql.security.authorization.plugin.HiveAuthorizer#getHiveAuthorizationTranslator()    */
Hive,WITHOUT_CLASSIFICATION,//  Parameters used for JMX 
Hive,WITHOUT_CLASSIFICATION,//  We have to create a new object because the object o belongs   to the code that creates it and may get its value changed. 
Hive,WITHOUT_CLASSIFICATION,//  Preserve operator before the GBY - we'll use it to resolve '*' 
Hive,WITHOUT_CLASSIFICATION,//  Determine minimum of all non-null long column values; maintain isGroupResultNull. 
Hive,WITHOUT_CLASSIFICATION,//  Checks whether txn list has been invalidated while planning the query.   This would happen if query requires exclusive/semi-shared lock and there   has been a committed transaction on the table over which the lock is 
Hive,WITHOUT_CLASSIFICATION,//  hashMap += JAVA64_OBJECT 
Hive,WITHOUT_CLASSIFICATION,//  isDynamicFunction used to indicate the function is not deterministic between queries. 
Hive,WITHOUT_CLASSIFICATION,//  Date + day-time interval = timestamp 
Hive,WITHOUT_CLASSIFICATION,//  This semijoin optimization should be removed. Do it after we're done iterating 
Hive,WITHOUT_CLASSIFICATION,//  For now just small table values... 
Hive,WITHOUT_CLASSIFICATION,//  if column statistics for a column is already found then merge the statistics 
Hive,WITHOUT_CLASSIFICATION,// if here it maybe compaction or regular read or Delete event sorter  in the later 2 cases we should do:  HIVE-17320: we should compute a SARG to push down min/max key to delete_delta 
Hive,WITHOUT_CLASSIFICATION,//  commit the changes 
Hive,WITHOUT_CLASSIFICATION,//  or if this is the last key-value pair 
Hive,WITHOUT_CLASSIFICATION,// ---------------------------------------------------------------------------   Single-Column String specific members.   
Hive,WITHOUT_CLASSIFICATION,//  FMSketch treats the ndv of all nulls as 1 but hll treates the ndv as 0.   In order to get rid of divide by 0 problem we follow FMSketch 
Hive,WITHOUT_CLASSIFICATION,//  Allocate write ids for both tables t1 and t2 for all txns 
Hive,WITHOUT_CLASSIFICATION,//  set the number of instances on which llap should run 
Hive,WITHOUT_CLASSIFICATION,//  already registered 
Hive,WITHOUT_CLASSIFICATION,//  Clarification of terms:   - The originalDir directory represents the original directory of the     partitions' files. They now contain an archived version of those files     eg. hdfs:/warehouse/myTable/ds=1/   - The source directory is the directory containing all the files that     should be in the partitions. e.g. har:/warehouse/myTable/ds=1/myTable.har/     Note the har:/ scheme 
Hive,WITHOUT_CLASSIFICATION,//  if nothing matches try creating a custom counter 
Hive,WITHOUT_CLASSIFICATION,//  when it executes a non-ResultSet query (like create) 
Hive,WITHOUT_CLASSIFICATION,//  The following method introduces a cast if x or y is DECIMAL_64 and parent expression (x % y) is DECIMAL. 
Hive,WITHOUT_CLASSIFICATION,//  set to true 
Hive,WITHOUT_CLASSIFICATION,//  Create the SerDe 
Hive,WITHOUT_CLASSIFICATION,//  check whether operation log file is deleted. 
Hive,WITHOUT_CLASSIFICATION,//  this might seem counter intuitive but some queries like query   SELECT YEAR(Calcs.date0) AS yr_date0_ok FROM druid_tableau.calcs Calcs WHERE (YEAR(Calcs.date0) IS NULL)   LIMIT 1   is planed in a way where we only push a filter down and keep the project of null as hive project. Thus empty   columns 
Hive,WITHOUT_CLASSIFICATION,//  If we are getting the resources externally don't relocalize anything. 
Hive,WITHOUT_CLASSIFICATION,//  negative numbers flip all bits 
Hive,WITHOUT_CLASSIFICATION,/*      * Fallback for the case when OrcSplit flags do not contain hasBase and deltas      */
Hive,WITHOUT_CLASSIFICATION,//  TABLE_TYPE 
Hive,WITHOUT_CLASSIFICATION,// small table file size 
Hive,WITHOUT_CLASSIFICATION,//  optional int32 underscore_int = 3; 
Hive,WITHOUT_CLASSIFICATION,//  Make this method final to improve performance. 
Hive,WITHOUT_CLASSIFICATION,//  ANALYZE TABLE T [PARTITION (...)] COMPUTE STATISTICS noscan; 
Hive,WITHOUT_CLASSIFICATION,//  sub-tree). 
Hive,WITHOUT_CLASSIFICATION,//  workaround for DN bug in persisting nulls in pg bytea column   instead set empty bit vector with header. 
Hive,WITHOUT_CLASSIFICATION,//  1st pass at marking invalid candidates   Checks based on variance and TTL 
Hive,WITHOUT_CLASSIFICATION,//  Package visible so that HMSMetricsListener can see them. 
Hive,WITHOUT_CLASSIFICATION,//  Add granularity to the row schema 
Hive,WITHOUT_CLASSIFICATION,//  5% tolerance for long range bias and 3% for short range bias 
Hive,WITHOUT_CLASSIFICATION,//  long scalar/scalar IF 
Hive,WITHOUT_CLASSIFICATION,// In the case of truncate table we set the stats to be 0. 
Hive,WITHOUT_CLASSIFICATION,//  The divided-by-2 logic is consistent to MapJoinOperator.reloadHashTable 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:PurgeCacheResponseProto) 
Hive,WITHOUT_CLASSIFICATION,//  Hive normalizes partition spec for dates to yyyy-mm-dd format. Some versions of Java will   accept other formats for Date.valueOf e.g. yyyy-m-d and who knows what else in the future;   some will not accept other formats so we cannot test normalization with them - type check   will fail before it can ever happen. Thus test in isolation. 
Hive,WITHOUT_CLASSIFICATION,//  end while 
Hive,WITHOUT_CLASSIFICATION,//  trigger failover on miniHS2_1 and make sure the connections are closed 
Hive,WITHOUT_CLASSIFICATION,/*    * Uses DeleteDelegator to kill a job and ignores all exceptions.    */
Hive,WITHOUT_CLASSIFICATION,/*  * A console SQL shell with command completion. * <p> * TODO: * <ul> * <li>User-friendly connection prompts</li> * <li>Page results</li> * <li>Handle binary data (blob fields)</li> * <li>Implement command aliases</li> * <li>Stored procedure execution</li> * <li>Binding parameters to prepared statements</li> * <li>Scripting language</li> * <li>XA transactions</li> * </ul> *  */
Hive,WITHOUT_CLASSIFICATION,//  then this is considered like the metastore server case 
Hive,WITHOUT_CLASSIFICATION,//  production is: string 
Hive,WITHOUT_CLASSIFICATION,//  check for two way join 
Hive,WITHOUT_CLASSIFICATION,//  Request :          "{\"queryType\":\"segmentMetadata\"\"dataSource\":{\"type\":\"table\"\"name\":\"wikipedia\"}"          + "\"intervals\":{\"type\":\"intervals\""          + "\"intervals\":[\"-146136543-09-08T00:30:34.096-07:52:58/146140482-04-24T08:36:27.903-07:00\"]}"          + "\"toInclude\":{\"type\":\"all\"}\"merge\":true\"context\":null\"analysisTypes\":[]"          + "\"usingDefaultInterval\":true\"lenientAggregatorMerge\":false\"descending\":false}"; 
Hive,WITHOUT_CLASSIFICATION,//  we need to keep the path part only because the Hadoop CombineFileInputFormat will   pass the path part only to accept().   Trailing the path with a separator to prevent partial matching. 
Hive,WITHOUT_CLASSIFICATION,//  into the row-mode MapJoinKey 
Hive,WITHOUT_CLASSIFICATION,//  now add pre-configured users to admin role 
Hive,WITHOUT_CLASSIFICATION,//  Stats setup: 
Hive,WITHOUT_CLASSIFICATION,//  Delete the data in the partitions which have other locations 
Hive,WITHOUT_CLASSIFICATION,/*    * Generate the GroupByOperator for the Query Block (parseInfo.getXXX(dest)).   * The new GroupByOperator will be a child of the reduceSinkOperatorInfo.   *   * @param parseInfo   * @param dest   * @param reduceSinkOperatorInfo   * @param mode   *          The mode of the aggregation (MERGEPARTIAL PARTIAL2)   * @param genericUDAFEvaluators   *          The mapping from Aggregation StringTree to the   *          genericUDAFEvaluator.   * @param groupingSets   *          list of grouping sets   * @param groupingSetsPresent   *          whether grouping sets are present in this query   * @param groupingSetsNeedAdditionalMRJob   *          whether grouping sets are consumed by this group by   * @return the new GroupByOperator    */
Hive,WITHOUT_CLASSIFICATION,//  Commit each partition so it gets moved out of the job work   dir 
Hive,WITHOUT_CLASSIFICATION,/*  Patterns that are excluded in verbose logging level.     * Filter out messages coming from log processing classes or we'll run an infinite loop.      */
Hive,WITHOUT_CLASSIFICATION,//  Set signum before; if result is zero fastMultiply will set signum to 0. 
Hive,WITHOUT_CLASSIFICATION,/*  16 > id or  */
Hive,WITHOUT_CLASSIFICATION,// obtain delegation tokens for the job 
Hive,WITHOUT_CLASSIFICATION,//  In case we are stuck in consume. 
Hive,WITHOUT_CLASSIFICATION,//  compare the column names and the order with the first table/partition. 
Hive,WITHOUT_CLASSIFICATION,// By the time we enter here the byteValues.lentgh and isNull must have already been compared 
Hive,WITHOUT_CLASSIFICATION,//  It is enough to compare the last level sub-directory which has the name as event ID 
Hive,WITHOUT_CLASSIFICATION,//  Request LLAP splits for a table. 
Hive,WITHOUT_CLASSIFICATION,//  Set the catalog name if it hasn't been set in the new table 
Hive,WITHOUT_CLASSIFICATION,// will fail 
Hive,WITHOUT_CLASSIFICATION,//  POOL 
Hive,WITHOUT_CLASSIFICATION,//  Construct list bucketing location mappings from sub-directory name. 
Hive,WITHOUT_CLASSIFICATION,//  1. Generate Resolved Parse tree from syntax tree 
Hive,WITHOUT_CLASSIFICATION,//  test the connection metastore using the config property 
Hive,WITHOUT_CLASSIFICATION,//  Else return it as it is. 
Hive,WITHOUT_CLASSIFICATION,//  Run Join releated optimizations 
Hive,WITHOUT_CLASSIFICATION,//  4. Build Rel for GB Having Clause 
Hive,WITHOUT_CLASSIFICATION,//  Need to initialize to 0 to make sure if nobody modified this table then current txn   shouldn't read any data.   If there is a conversion from non-acid to acid table then by default 0 would be assigned as 
Hive,WITHOUT_CLASSIFICATION,/*    * A definite node is constructed from a specified number of children. That   * number of nodes are popped from the stack and made the children of the   * definite node. Then the definite node is pushed on to the stack.    */
Hive,WITHOUT_CLASSIFICATION,//  initialize the converter 
Hive,WITHOUT_CLASSIFICATION,//  create filters on top of each setop child modifying the filter   condition to reference each setop child 
Hive,WITHOUT_CLASSIFICATION,//  two VInt without nanos 
Hive,WITHOUT_CLASSIFICATION,//  should not occur since second parameter to getTableWithQN is false 
Hive,WITHOUT_CLASSIFICATION,//  subsequent requests 
Hive,WITHOUT_CLASSIFICATION,//  Start the timer thread for cancelling the query when query timeout is reached 
Hive,WITHOUT_CLASSIFICATION,//  Successfully scheduled. 
Hive,WITHOUT_CLASSIFICATION,//  4) the cumulative cardinality is equal but the size is bigger 
Hive,WITHOUT_CLASSIFICATION,//  We keep flushing until the memory is under threshold 
Hive,WITHOUT_CLASSIFICATION,//  Since we merge multiple operation paths we assign new tags to bottom layer   ReduceSinkOperators. This mapping is used to map new tags to original tags associated 
Hive,WITHOUT_CLASSIFICATION,//  Found the proper columns. 
Hive,WITHOUT_CLASSIFICATION,//  D6. Add back - probability is 2**(-31). R += D. Q[digit] -= 1 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:PurgeCacheRequestProto) 
Hive,WITHOUT_CLASSIFICATION,//  Copy credentials 
Hive,WITHOUT_CLASSIFICATION,//  write out integer part first   then write out fractional part 
Hive,WITHOUT_CLASSIFICATION,//  There are many ways to have AUX jars in Hive... sigh 
Hive,WITHOUT_CLASSIFICATION,//  Make sure the new partition has the catalog value set 
Hive,WITHOUT_CLASSIFICATION,//  Verify that the schema now within the configuration is the one passed 
Hive,WITHOUT_CLASSIFICATION,//  Write the current set of valid transactions into the conf file 
Hive,WITHOUT_CLASSIFICATION,//  read-only maps (initialized once) 
Hive,WITHOUT_CLASSIFICATION,//  through Hive 
Hive,WITHOUT_CLASSIFICATION,//  dummy HS2 instance just to trigger failover 
Hive,WITHOUT_CLASSIFICATION,//  Expected events not updated yet - vertex SUCCESS notification not received. 
Hive,WITHOUT_CLASSIFICATION,//  Nothing needs to be done. 
Hive,WITHOUT_CLASSIFICATION,//  Now vary isRepeating   nulls possible only on right 
Hive,WITHOUT_CLASSIFICATION,//  Get key element information 
Hive,WITHOUT_CLASSIFICATION,//  Check the affinity of the argument passed in with the accepted argument   based on the PrimitiveGrouping 
Hive,WITHOUT_CLASSIFICATION,//  are any of the new transactions ones that we care about? 
Hive,WITHOUT_CLASSIFICATION,//  back-check to force at least 1 output; and this should have a partial which is empty 
Hive,WITHOUT_CLASSIFICATION,//  All the tables/partitions columns should be sorted in the same order   For example if tables A and B are being joined on columns c1 c2 and c3   which are the sorted and bucketed columns. The join would work as long   c1 c2 and c3 are sorted in the same order. 
Hive,WITHOUT_CLASSIFICATION,//  If this is a trivial query block return 
Hive,WITHOUT_CLASSIFICATION,//  No existing ranges just accept the current 
Hive,WITHOUT_CLASSIFICATION,//  UGI for the http/_HOST (SPNego) principal 
Hive,WITHOUT_CLASSIFICATION,//  The real expression 
Hive,WITHOUT_CLASSIFICATION,//  2. Perform a MINOR compaction. Since nothing was aborted subdirs should stay. 
Hive,WITHOUT_CLASSIFICATION,//  In vector mode we store CHAR as unpadded. 
Hive,WITHOUT_CLASSIFICATION,//  reduce only if the parameters are significant 
Hive,WITHOUT_CLASSIFICATION,//  Tests that in the absence of stats for partitions and/or absence of columns 
Hive,WITHOUT_CLASSIFICATION,//  Only accept parse results if we parsed the entire string 
Hive,WITHOUT_CLASSIFICATION,//  org.apache.hadoop.hive.ql.parse.MetaDataExportListener preevent listener 
Hive,WITHOUT_CLASSIFICATION,//  Must be struct because List and Map need to be ParameterizedType 
Hive,WITHOUT_CLASSIFICATION,//  can be boolean column in which case return true count 
Hive,WITHOUT_CLASSIFICATION,//  init output object inspectors   The output of a partial aggregation is a list 
Hive,WITHOUT_CLASSIFICATION,/*    * Test retries when InvocationException wrapped in MetaException wrapped in JDOException   * is thrown    */
Hive,WITHOUT_CLASSIFICATION,//  initialize QB 
Hive,WITHOUT_CLASSIFICATION,//  add spark job metrics. 
Hive,WITHOUT_CLASSIFICATION,//  Only proceed if the THEN/ELSE types were aligned. 
Hive,WITHOUT_CLASSIFICATION,//  this path points to a symlink path 
Hive,WITHOUT_CLASSIFICATION,//  When we have repeating values we can unset the whole bitset at once   if the repeating value is not a valid write id. 
Hive,WITHOUT_CLASSIFICATION,//  if grantee is a role check if it exists 
Hive,WITHOUT_CLASSIFICATION,//  needed to avoid file name conflict when big table is partitioned 
Hive,WITHOUT_CLASSIFICATION,//  If same return one of them 
Hive,WITHOUT_CLASSIFICATION,//  Every 8 fields we write a NULL byte. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure the catalog name is set in the new partition 
Hive,WITHOUT_CLASSIFICATION,//  Note that the code removes the data from the field as it's passed to the consumer   so we expect to have stuff remaining in there only in case of errors. 
Hive,WITHOUT_CLASSIFICATION,/*  allowRounding  */
Hive,WITHOUT_CLASSIFICATION,//  Update the number of entries that can fit in the hash table 
Hive,WITHOUT_CLASSIFICATION,//  Further the DPP value needs to be generated from same subtree 
Hive,WITHOUT_CLASSIFICATION,/*    * Returns true of thread pool is created and can be used for executing a job request.   * Otherwise returns false.    */
Hive,WITHOUT_CLASSIFICATION,//  change smallint and tinyint to int 
Hive,WITHOUT_CLASSIFICATION,/*  * An single STRING key hash set optimized for vector map join. * * The key will be deserialized and just the bytes will be stored.  */
Hive,WITHOUT_CLASSIFICATION,//  Initialize column buffers 
Hive,WITHOUT_CLASSIFICATION,//  The dispatcher fires the processor corresponding to the closest 
Hive,WITHOUT_CLASSIFICATION,//  The boolean predicate. 
Hive,WITHOUT_CLASSIFICATION,//  validate is false by default if we disable the constraint 
Hive,WITHOUT_CLASSIFICATION,//  Create and add AST node with position of grouping function input   in group by clause 
Hive,WITHOUT_CLASSIFICATION,//  Simple case - CB fits entirely in the disk range. 
Hive,WITHOUT_CLASSIFICATION,//  Cancel should be a no-op in either cases 
Hive,WITHOUT_CLASSIFICATION,//  empty out side file 
Hive,WITHOUT_CLASSIFICATION,//  F | T 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see org.apache.hadoop.hive.ql.lib.Node#getChildren()    */
Hive,WITHOUT_CLASSIFICATION,//  We recursively create the exprNodeDesc. Base cases: when we encounter   a column ref we convert that into an exprNodeColumnDesc; when we   encounter   a constant we convert that into an exprNodeConstantDesc. For others we   just 
Hive,WITHOUT_CLASSIFICATION,//  Need to reconnect 
Hive,WITHOUT_CLASSIFICATION,//  If we have a valid batchIter and it has more elements return them. 
Hive,WITHOUT_CLASSIFICATION,//  Add a sort by clause so that the row ids come out in the correct order 
Hive,WITHOUT_CLASSIFICATION,//  Drop one table see what remains 
Hive,WITHOUT_CLASSIFICATION,//  Add the semijoin branch to the map 
Hive,WITHOUT_CLASSIFICATION,//  This version of Hadoop does not support HdfsAdmin.getEncryptionZoneForPath().   Hadoop 2.6.0 introduces this new method. 
Hive,WITHOUT_CLASSIFICATION,//  to be a CONSTANT node with value to be the agreed result. 
Hive,WITHOUT_CLASSIFICATION,//  Key definitions related to replication 
Hive,WITHOUT_CLASSIFICATION,//  LOG.info(queryPlan); 
Hive,WITHOUT_CLASSIFICATION,//  We disable web UI in tests unless the test is explicitly setting a   unique web ui port so that we don't mess up ptests. 
Hive,WITHOUT_CLASSIFICATION,//  precision 9 
Hive,WITHOUT_CLASSIFICATION,//  Note: Hive ops do not use the normal Future failure path so this will not happen         in case of actual failure; the Future will just be done.   The background operation thread was aborted 
Hive,WITHOUT_CLASSIFICATION,//  parse the schema file to determine the tables that are expected to exist 
Hive,WITHOUT_CLASSIFICATION,//  We replace the path in the file status by the input path as Parquet   may use the path in the file status to open the file 
Hive,WITHOUT_CLASSIFICATION,//  the output position should not change since there are no corVars 
Hive,WITHOUT_CLASSIFICATION,//  Close the connection as soon as the error message is sent. 
Hive,WITHOUT_CLASSIFICATION,//  LOG.info("First tail offset to create list record is " + firstTailOffset); 
Hive,WITHOUT_CLASSIFICATION,//  Get the name of a file and look at its properties to see if orc.compress.size was respected. 
Hive,WITHOUT_CLASSIFICATION,//  copy is a nop so skip it--this is important for avoiding   spurious overlap assertions 
Hive,WITHOUT_CLASSIFICATION,//  Enable or disable test scheduling control. 
Hive,WITHOUT_CLASSIFICATION,//  Add HiveConf variable with 3 modes:     1) adaptor: Always use VectorUDFAdaptor for IF statements.       2) good: Vectorize but don't optimize conditional expressions       3) better: Vectorize and Optimize conditional expressions.   
Hive,WITHOUT_CLASSIFICATION,//  but we should have already checked for that before this point. 
Hive,WITHOUT_CLASSIFICATION,//  EVENT_TYPE 
Hive,WITHOUT_CLASSIFICATION,//  update the target map work of the second 
Hive,WITHOUT_CLASSIFICATION,//  Process --failover 
Hive,WITHOUT_CLASSIFICATION,//  The threshold where we should use a repeating vectorized row batch optimization for 
Hive,WITHOUT_CLASSIFICATION,//  4. Construct JoinPredicateInfo 
Hive,WITHOUT_CLASSIFICATION,//  precision 8 
Hive,WITHOUT_CLASSIFICATION,//  if table is already in there don't recreate. 
Hive,WITHOUT_CLASSIFICATION,//        RightInputRel 
Hive,WITHOUT_CLASSIFICATION,//  never includes a join condition. The code was not modified for brevity. 
Hive,WITHOUT_CLASSIFICATION,//  Desired schema does not include virtual columns or partition columns. 
Hive,WITHOUT_CLASSIFICATION,//  create the dummy operators 
Hive,WITHOUT_CLASSIFICATION,//  if user is not an admin user allow the request only if the user is   requesting for privileges for themselves or a role they belong to 
Hive,WITHOUT_CLASSIFICATION,//  two VInt with nanos 
Hive,WITHOUT_CLASSIFICATION,//  Set the option for tolerating corruptions. The read should succeed. 
Hive,WITHOUT_CLASSIFICATION,//  ss can be null in unit tests 
Hive,WITHOUT_CLASSIFICATION,//  table is newer leave it be. 
Hive,WITHOUT_CLASSIFICATION,//  Unsecure case? 
Hive,WITHOUT_CLASSIFICATION,//  Clean post-conditions 
Hive,WITHOUT_CLASSIFICATION,//  Error out & exit - we were not able to parse the args successfully 
Hive,WITHOUT_CLASSIFICATION,// Pig which uses HCat will pass this to HCat so that it can find the metastore 
Hive,WITHOUT_CLASSIFICATION,//  Write some garbage to the buffer that should be erased 
Hive,WITHOUT_CLASSIFICATION,/*  * When constructing the Evaluator Tree from an ExprNode Tree * - look for any descendant LeadLag Function Expressions * - if they are found: *   - add them to the LLInfo.leadLagExprs and *   - add a mapping from the Expr Tree root to the LLFunc Expr in LLInfo.mapTopExprToLLFunExprs  */
Hive,WITHOUT_CLASSIFICATION,//  precision 7 
Hive,WITHOUT_CLASSIFICATION,//  Suppress the STAGES if vectorization is off. 
Hive,WITHOUT_CLASSIFICATION,//  For types with parameters (like varchar) we need to determine the type parameters   that should be added to this type based on the original 2 TypeInfos. 
Hive,WITHOUT_CLASSIFICATION,//  validate all tasks 
Hive,WITHOUT_CLASSIFICATION,/*      * We always set the null flag to false when there is a value.      */
Hive,WITHOUT_CLASSIFICATION,//  Update the queryId to use the generated applicationId. See comment below about   why this is done. 
Hive,WITHOUT_CLASSIFICATION,// aid in testing 
Hive,WITHOUT_CLASSIFICATION,//  Some value is set. 
Hive,WITHOUT_CLASSIFICATION,// first see if it is gbkeys 
Hive,WITHOUT_CLASSIFICATION,//  Import table t1 to C 
Hive,WITHOUT_CLASSIFICATION,//  So need not validate inpPartSpec here. 
Hive,WITHOUT_CLASSIFICATION,//  which will cause the scheduler loop to continue. 
Hive,WITHOUT_CLASSIFICATION,//  use partition level authorization 
Hive,WITHOUT_CLASSIFICATION,//  The 'magic' bytes at the beginning of the RCFile 
Hive,WITHOUT_CLASSIFICATION,//  Check if work has an explain annotation 
Hive,WITHOUT_CLASSIFICATION,//  print attr 
Hive,WITHOUT_CLASSIFICATION,//  change these parameters 
Hive,WITHOUT_CLASSIFICATION,//  this should be database usage privilege once it is supported 
Hive,WITHOUT_CLASSIFICATION,//  should honor the ordering of records provided by ORDER BY in SELECT statement 
Hive,WITHOUT_CLASSIFICATION,//  exhausted the batch no longer have to heartbeat 
Hive,WITHOUT_CLASSIFICATION,//  lists of clauses. 
Hive,WITHOUT_CLASSIFICATION,//  unlink connection between FS and its parent 
Hive,WITHOUT_CLASSIFICATION,//  Fill the child of ListColumnVector with valueList 
Hive,WITHOUT_CLASSIFICATION,//  If the line doesn't end with the delimiter or if the line is empty add the cmd part 
Hive,WITHOUT_CLASSIFICATION,//  Grab sign bit and shift it away. 
Hive,WITHOUT_CLASSIFICATION,//  The HiveDecimalWritable set method will quickly copy the deserialized decimal writable fields. 
Hive,WITHOUT_CLASSIFICATION,//  This is a test calling. 
Hive,WITHOUT_CLASSIFICATION,//  Padding leading zeroes/ones. 
Hive,WITHOUT_CLASSIFICATION,//  test stats deletion at partition level 
Hive,WITHOUT_CLASSIFICATION,//  Create the list of serialized splits for each bucket. 
Hive,WITHOUT_CLASSIFICATION,//  joins alias1 alias2 alias3 (alias1 was not eligible for big pos)   Must be deterministic order map for consistent q-test output across Java versions 
Hive,WITHOUT_CLASSIFICATION,// Buffer one batch at a time for row retrieval 
Hive,WITHOUT_CLASSIFICATION,//  Test that existing shared_read db with new shared_read coalesces to 
Hive,WITHOUT_CLASSIFICATION,//  First allocation of write id should add the table to the next_write_id meta table   The initial value for write id should be 1 and hence we add 1 with number of write ids allocated here 
Hive,WITHOUT_CLASSIFICATION,//  there are 2 survivor spaces 
Hive,WITHOUT_CLASSIFICATION,//  Offset to where this RG begins. 
Hive,WITHOUT_CLASSIFICATION,//  This method implementation is preserved for backward compatibility. 
Hive,WITHOUT_CLASSIFICATION,//  offer accepted and r4 gets evicted 
Hive,WITHOUT_CLASSIFICATION,//  can't do much expression is not in context of filter so we can't treat null as equivalent to false here. 
Hive,WITHOUT_CLASSIFICATION,//  plus any correlated variables the input wants to pass along. 
Hive,WITHOUT_CLASSIFICATION,//  TOK_SKEWED_LOCATION_LIST 
Hive,WITHOUT_CLASSIFICATION,//  Add struct field data to the Row 
Hive,WITHOUT_CLASSIFICATION,//  priority = 10 / (200 - 100) = 0.01 
Hive,WITHOUT_CLASSIFICATION,//  Short 
Hive,WITHOUT_CLASSIFICATION,//  Log error if the acid table is missing from the ValidWriteIdList conf 
Hive,WITHOUT_CLASSIFICATION,//  are associated with a transaction then heartbeat on that as well. 
Hive,WITHOUT_CLASSIFICATION,//  set list task 
Hive,WITHOUT_CLASSIFICATION,//  call process once we have a full batch 
Hive,WITHOUT_CLASSIFICATION,//  found a unused port exit 
Hive,WITHOUT_CLASSIFICATION,//  Do not put the unused duck back; we'd run the tasks below then assign it by priority. 
Hive,WITHOUT_CLASSIFICATION,//  We merge filters from previous scan by ORing with filters from current scan 
Hive,WITHOUT_CLASSIFICATION,// ensures txn is still there and in expected state 
Hive,WITHOUT_CLASSIFICATION,//  We are only vectorizing Reduce under Tez/Spark. 
Hive,WITHOUT_CLASSIFICATION,//  If partition is specified get pruned partition list 
Hive,WITHOUT_CLASSIFICATION,//  the constant value into it and add the struct as part of exprNodeStructs. 
Hive,WITHOUT_CLASSIFICATION,// Environment Variables long values 
Hive,WITHOUT_CLASSIFICATION,//  'or' nodes need to be merged 
Hive,WITHOUT_CLASSIFICATION,//  Success! 
Hive,WITHOUT_CLASSIFICATION,//  remove all TOK tokens 
Hive,WITHOUT_CLASSIFICATION,/*      *  if there was a pre-existing work generated for the big-table mapjoin side     *  we need to hook the work generated for the RS (associated with the RS-MJ pattern)     *  with the pre-existing work.     *     *  Otherwise we need to associate that the mapjoin op     *  to be linked to the RS work (associated with the RS-MJ pattern).     *      */
Hive,WITHOUT_CLASSIFICATION,/*  * TODO:<br> * 1. Could we use combined RR instead of list of RR ?<br> * 2. Why not use GB expr ?  */
Hive,WITHOUT_CLASSIFICATION,//  Error; default value 
Hive,WITHOUT_CLASSIFICATION,//  if the size is unavailable we need to assume a size 1 greater than   localTableTotalSizeLimit this implies that merge cannot happen   so we will return false. 
Hive,WITHOUT_CLASSIFICATION,//  The only case where duplicate elements matter... the others are handled by the below. 
Hive,WITHOUT_CLASSIFICATION,//  Create scratch columns to hold small table results. 
Hive,WITHOUT_CLASSIFICATION,//  If the parsed statement contained a db.tablename specification prefer that. 
Hive,WITHOUT_CLASSIFICATION,//  Primitive Writable class? 
Hive,WITHOUT_CLASSIFICATION,//  failed to infer PK-FK relationship for row count estimation fall-back on default logic   compute denominator  max(V(Ry1) V(Sy1)) * max(V(Ry2) V(Sy2))   in case of multi-attribute join 
Hive,WITHOUT_CLASSIFICATION,//  Mandatory Property 
Hive,WITHOUT_CLASSIFICATION,//  If CBO did not optimize the query we might need to replace grouping function 
Hive,WITHOUT_CLASSIFICATION,//  Check multi-set count. 
Hive,WITHOUT_CLASSIFICATION,//  Secondary DropTableCommand test for testing repl-drop-tables' effect on partitions inside a partitioned table   when there exist partitions inside the table which are older than the drop event.   Our goal is this : Create a table t with repl.last.id=157 say.   Create 2 partitions inside it with repl.last.id=150 and 160 say.   Now process a drop table command with eventid=155.   It should result in the table and the partition with repl.last.id=160 continuing to exist   but dropping the partition with repl.last.id=150. 
Hive,WITHOUT_CLASSIFICATION,//  do nothing by default 
Hive,WITHOUT_CLASSIFICATION,//  it doesn't seem like you should have to do this but java serialization is wacky and doesn't call the default constructor. 
Hive,WITHOUT_CLASSIFICATION,//  DP in the form of T   partition (ds hr) 
Hive,WITHOUT_CLASSIFICATION,//  stripe position within file 
Hive,WITHOUT_CLASSIFICATION,//  server sets createtime 
Hive,WITHOUT_CLASSIFICATION,//  Create KV result cache object add one (kv) pair and retrieve them. 
Hive,WITHOUT_CLASSIFICATION,//  Threshold percentage to trigger the GC warning 
Hive,WITHOUT_CLASSIFICATION,//  Convert to lowercase for the comparison 
Hive,WITHOUT_CLASSIFICATION,//  Use the keytab if one was provided 
Hive,WITHOUT_CLASSIFICATION,//  ^(TOK_CREATEFUNCTION identifier StringLiteral ({isTempFunction}? => TOK_TEMPORARY)) 
Hive,WITHOUT_CLASSIFICATION,//  Two events: one for create db and other for drop db 
Hive,WITHOUT_CLASSIFICATION,// directory to output results to 
Hive,WITHOUT_CLASSIFICATION,//  Create GroupingID column 
Hive,WITHOUT_CLASSIFICATION,//  print job stages. 
Hive,WITHOUT_CLASSIFICATION,//  nulls and repeating 
Hive,WITHOUT_CLASSIFICATION,//  complain about the deprecated syntax -- but still run 
Hive,WITHOUT_CLASSIFICATION,/*  Get row size of small table  */
Hive,WITHOUT_CLASSIFICATION,// check elements of the innermost array 
Hive,WITHOUT_CLASSIFICATION,// delete the bucket files so now we have empty delta dirs 
Hive,WITHOUT_CLASSIFICATION,//  Load next batch from disk 
Hive,WITHOUT_CLASSIFICATION,//  We pretend to add trailing zeroes EVEN WHEN it would exceed the HiveDecimal.MAX_PRECISION. 
Hive,WITHOUT_CLASSIFICATION,//  Right now the work graph is pretty simple. If there is no   Preceding work we have a root and will generate a map   vertex. If there is a preceding work we will generate 
Hive,WITHOUT_CLASSIFICATION,//  Create table in database without location clause 
Hive,WITHOUT_CLASSIFICATION,//  Convert all NaN and optionally infinity values in vector v to NULL. 
Hive,WITHOUT_CLASSIFICATION,//  Have we already set the enabled conditions not met? 
Hive,WITHOUT_CLASSIFICATION,//  at the table level and the storage handler level. 
Hive,WITHOUT_CLASSIFICATION,// clear the username 
Hive,WITHOUT_CLASSIFICATION,//  This is not needed beyond compilation so it is transient. 
Hive,WITHOUT_CLASSIFICATION,//  Initialize the result. 
Hive,WITHOUT_CLASSIFICATION,//  not all argument elements need to hold true 
Hive,WITHOUT_CLASSIFICATION,//  used by the framework at runtime. initialize is the real initializer at runtime 
Hive,WITHOUT_CLASSIFICATION,//  SetOp Rel 
Hive,WITHOUT_CLASSIFICATION,//  Commit the open txn which lets the cleanup on TXN_TO_WRITE_ID. 
Hive,WITHOUT_CLASSIFICATION,//  close any open readers if there was some exception during initialization.   rethrow the exception so that the caller can handle. 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.ICLIService#closeOperation(org.apache.hive.service.cli.OperationHandle)    */
Hive,WITHOUT_CLASSIFICATION,//  Create default route where events go without queryId 
Hive,WITHOUT_CLASSIFICATION,//  application-specific typecodes 
Hive,WITHOUT_CLASSIFICATION,//  Prepare StringBuilder for "PART_ID in (...)" to use in future queries. 
Hive,WITHOUT_CLASSIFICATION,//  The reason why we can get a list of split strategies here is because for ACID split-update   case when we have a mix of original base files & insert deltas we will produce two   independent split strategies for them. There is a global flag 'isOriginal' that is set 
Hive,WITHOUT_CLASSIFICATION,//  so this is set by DriverContext in runtime 
Hive,WITHOUT_CLASSIFICATION,//  optional string requestUser = 5; 
Hive,WITHOUT_CLASSIFICATION,//  extract the values. 
Hive,WITHOUT_CLASSIFICATION,//  CONSIDER: For large n fill n or all of isNull array and use the tighter ELSE loop. 
Hive,WITHOUT_CLASSIFICATION,//  Chose the table descriptor if none of the partitions is present.   For eg: consider the query:   select /*+mapjoin(T1)*/ count(*) from T1 join T2 on T1.key=T2.key   Both T1 and T2 and partitioned tables but T1 does not have any partitions   FetchOperator is invoked for T1 and listParts is empty. In that case   use T1's schema to get the ObjectInspector. 
Hive,WITHOUT_CLASSIFICATION,//  Happens in case of TezDummyStoreOperator 
Hive,WITHOUT_CLASSIFICATION,//  Current number of open txns 
Hive,WITHOUT_CLASSIFICATION,//  Adds the missing scheme/authority for the new partition location 
Hive,WITHOUT_CLASSIFICATION,//  Helper class to submit fragments to LLAP and retry rejected submissions. 
Hive,WITHOUT_CLASSIFICATION,//  This is map of which vectorized row batch columns are the key columns. 
Hive,WITHOUT_CLASSIFICATION,//  The math.min and the fact that maxAllocation is an int ensures we don't overflow. 
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.UserPayloadProto.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,//  validate close/reopen 
Hive,WITHOUT_CLASSIFICATION,//  Metrics throws an Exception if we don't do this when the key already exists 
Hive,WITHOUT_CLASSIFICATION,// easier to read logs 
Hive,WITHOUT_CLASSIFICATION,//  Indicates whether cache statistics should be collected. 
Hive,WITHOUT_CLASSIFICATION,//  exactly the same. 
Hive,WITHOUT_CLASSIFICATION,//  Use magic length value to indicate big. 
Hive,WITHOUT_CLASSIFICATION,/*    * init method in HMSHandler should not be retried if there are no exceptions    */
Hive,WITHOUT_CLASSIFICATION,//  we can save ourselves from spilling once we have join emit interval worth of rows. 
Hive,WITHOUT_CLASSIFICATION,//  One Writable per row. 
Hive,WITHOUT_CLASSIFICATION,//  privileges obtained indirectly via roles 
Hive,WITHOUT_CLASSIFICATION,//  Override what's placed in the Configuration by setup() 
Hive,WITHOUT_CLASSIFICATION,//  immutable maps 
Hive,WITHOUT_CLASSIFICATION,//  Generates plan for min/max when dynamic partition pruning is ruled out. 
Hive,WITHOUT_CLASSIFICATION,//  The fastRoundInteger* methods remove all fractional digits set fastIntegerDigitCount and 
Hive,WITHOUT_CLASSIFICATION,//  re-instantiate the parent expression with new arguments 
Hive,WITHOUT_CLASSIFICATION,//  smallint 
Hive,WITHOUT_CLASSIFICATION,//  GRANTOR_PRINCIPAL_TYPE 
Hive,WITHOUT_CLASSIFICATION,//  Regardless of our matching result we keep that information to make multiple use   of it for a possible series of equal keys. 
Hive,WITHOUT_CLASSIFICATION,//  FUTURE: We be more sophisticated in our conversion check. 
Hive,WITHOUT_CLASSIFICATION,//  for short range use linear counting 
Hive,WITHOUT_CLASSIFICATION,//  Release buffers as we are done with all the streams... also see toRelease comment.\ 
Hive,WITHOUT_CLASSIFICATION,//  Heartbeat is from a task that we are not currently tracking. 
Hive,WITHOUT_CLASSIFICATION,//  1 static partition created during setup + 10 dynamic partitions 
Hive,WITHOUT_CLASSIFICATION,//  Output top values 
Hive,WITHOUT_CLASSIFICATION,//  stores datastore (jpox) properties 
Hive,WITHOUT_CLASSIFICATION,//  Let's not guess which one is correct. 
Hive,WITHOUT_CLASSIFICATION,//  create table and pupulate with kv1.txt 
Hive,WITHOUT_CLASSIFICATION,//  lengths stream could be empty stream or already reached end of stream before present stream.   This can happen if all values in stream are nulls or last row group values are all null. 
Hive,WITHOUT_CLASSIFICATION,//  publish DP columns to its subscribers 
Hive,WITHOUT_CLASSIFICATION,/*    * Responsible for capturing SubQuery rewrites and providing the rewritten query   * as SQL.    */
Hive,WITHOUT_CLASSIFICATION,//  start offset of compression buffer corresponding to above row group 
Hive,WITHOUT_CLASSIFICATION,//  DAG scratch dir. We get a session from the pool so it may be different from Tez one. 
Hive,WITHOUT_CLASSIFICATION,/*    * if {@code true} it means current transaction is started via START TRANSACTION which means it cannot   * include any Operations which cannot be rolled back (drop partition; write to  non-acid table).   * If false it's a single statement transaction which can include any statement.  This is not a   * contradiction from the user point of view who doesn't know anything about the implicit txn   * and cannot call rollback (the statement of course can fail in which case there is nothing to   * rollback (assuming the statement is well implemented)).   *   * This is done so that all commands run in a transaction which simplifies implementation and   * allows a simple implementation of multi-statement txns which don't require a lock manager   * capable of deadlock detection.  (todo: not fully implemented; elaborate on how this LM works)   *   * Also critically important ensuring that everything runs in a transaction assigns an order   * to all operations in the system - needed for replication/DR.   *   * We don't want to allow non-transactional statements in a user demarcated txn because the effect   * of such statement is "visible" immediately on statement completion but the user may   * issue a rollback but the action of the statement can't be undone (and has possibly already been   * seen by another txn).  For example   * start transaction   * insert into transactional_table values(1);   * insert into non_transactional_table select * from transactional_table;   * rollback   *   * The user would be in for a surprise especially if they are not aware of transactional   * properties of the tables involved.   *   * As a side note: what should the lock manager do with locks for non-transactional resources?   * Should it it release them at the end of the stmt or txn?   * Some interesting thoughts: http://mysqlmusings.blogspot.com/2009/02/mixing-engines-in-transactions.html.    */
Hive,WITHOUT_CLASSIFICATION,//  Guaranteed to be just 1 because each DummyStoreOperator can be part of only one work. 
Hive,WITHOUT_CLASSIFICATION,// ---------------------------------------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  Filter does not change the input ordering.   Filter rel does not permute the input.   All corvars produced by filter will have the same output positions in the 
Hive,WITHOUT_CLASSIFICATION,//  increment cursor for per-query IN-clause list 
Hive,WITHOUT_CLASSIFICATION,//  Note : edge-case here in interaction with table-level REPL LOAD where that nukes out   tablesUpdated. However we explicitly don't support repl of that sort and error out above 
Hive,WITHOUT_CLASSIFICATION,//  1) The set of operators in the works that we are merging need to meet   some requirements. In particular:   1.1. None of the works that we are merging can contain a Union   operator. This is not supported yet as we might end up with cycles in   the Tez DAG.   1.2. There cannot be more than one DummyStore operator in the new resulting   work when the operators are merged. This is due to an assumption in   MergeJoinProc that needs to be further explored.   If any of these conditions are not met we cannot merge. 
Hive,WITHOUT_CLASSIFICATION,//  Used by sort-based GroupBy: Mode = COMPLETE PARTIAL1 PARTIAL2 
Hive,WITHOUT_CLASSIFICATION,//  Set up zookeeper dynamic service discovery configs 
Hive,WITHOUT_CLASSIFICATION,//  The current record should not be included in the output detailList. 
Hive,WITHOUT_CLASSIFICATION,//  set the values of totalInputFileSize and totalInputNumFiles estimating them   if percentage block sampling is being used 
Hive,WITHOUT_CLASSIFICATION,//  total characters = 10; byte length = 26 
Hive,WITHOUT_CLASSIFICATION,//  flatten OR 
Hive,WITHOUT_CLASSIFICATION,//  partition   column 
Hive,WITHOUT_CLASSIFICATION,//  STORED_AS_SUB_DIRECTORIES 
Hive,WITHOUT_CLASSIFICATION,// insert data in "legacy" format 
Hive,WITHOUT_CLASSIFICATION,//  example code 
Hive,WITHOUT_CLASSIFICATION,//  if this operator is a Map Join Operator or a Merge Join Operator 
Hive,WITHOUT_CLASSIFICATION,//  first hash is used to locate start of the block (blockBaseOffset) 
Hive,WITHOUT_CLASSIFICATION,//  child operator --> object inspector (converted OI if it's needed) 
Hive,WITHOUT_CLASSIFICATION,//  the tableDesc will be null in the case that all columns in that table   is not used. we use a dummy row to denote all rows in that table and   the dummy row is added by caller. 
Hive,WITHOUT_CLASSIFICATION,//  this operator can be removed. 
Hive,WITHOUT_CLASSIFICATION,//  AccumuloInputFormat complains if you re-set an already set value. We just don't care. 
Hive,WITHOUT_CLASSIFICATION,//  for DELETE statements NOT NULL constraint need not be checked 
Hive,WITHOUT_CLASSIFICATION,//  Bootstrap dump with open txn timeout as 1s. 
Hive,WITHOUT_CLASSIFICATION,//  write totalMonths to DataOutput 
Hive,WITHOUT_CLASSIFICATION,//  Now change the resource plan - change the mapping for the user. 
Hive,WITHOUT_CLASSIFICATION,//  Only columns and constants can be selected 
Hive,WITHOUT_CLASSIFICATION,//  CASCADE 
Hive,WITHOUT_CLASSIFICATION,/*            * Determine the data and partition columns using the first partition descriptor's           * partition count.  In other words how to split the schema columns -- the           * allColumnNameList and allTypeInfoList variables -- into the data and partition columns.            */
Hive,WITHOUT_CLASSIFICATION,//  skip map-aggr GBY 
Hive,WITHOUT_CLASSIFICATION,//  RuleRegExp rules are used to match operators anywhere in the tree   RuleExactMatch rules are used to specify exactly what the tree should look like   In particular this guarantees that the first operator is the reducer   (and its parent(s) are ReduceSinkOperators) since it begins walking the tree from 
Hive,WITHOUT_CLASSIFICATION,//  Check additional constraint. 
Hive,WITHOUT_CLASSIFICATION,//  Stay with MULTI_KEY 
Hive,WITHOUT_CLASSIFICATION,//  encoded filename/checksum of files write into _files 
Hive,WITHOUT_CLASSIFICATION,//  The join is the root but we should always end up with a Project operator 
Hive,WITHOUT_CLASSIFICATION,/*    * State of the Rolling Partition   *    * x0 x1 x2 x3 x4 x5 x6 x7 x8 x9 x10 x11 x12 x13 x14 x15 x16 x17   * ^                    ^                                     ^   * |                    |                                     |   * |--preceding span--numRowsProcessed---followingSpan --numRowsRecived   *    * a. index x7 : represents the last output row   * b. so preceding span rows before that are still held on for subsequent rows processing.   * c. The #of rows beyond numRowsProcessed = followingSpan    */
Hive,WITHOUT_CLASSIFICATION,//  A HiveDecimalWritable version. 
Hive,WITHOUT_CLASSIFICATION,//  FUNCTIONS 
Hive,WITHOUT_CLASSIFICATION,// set the configuration up such that proxyUser can act on  behalf of all users belonging to the group foo_bar_group ( 
Hive,WITHOUT_CLASSIFICATION,//  get the table from the client verify the name is correct 
Hive,WITHOUT_CLASSIFICATION,//  This relies on findKeyRefToRead doing key equality check and leaving read ptr where needed. 
Hive,WITHOUT_CLASSIFICATION,/*        This is used to print the progress information as pure text  a sample is as below:          Map 1: 0/1	Reducer 2: 0/1          Map 1: 0(+1)/1	Reducer 2: 0/1          Map 1: 1/1	Reducer 2: 0(+1)/1          Map 1: 1/1	Reducer 2: 1/1      */
Hive,WITHOUT_CLASSIFICATION,/*      * Limit can be pushed down to Map-side if all Window Functions need access     * to rows before the current row. This is true for:     * 1. Rank DenseRank and Lead Fns. (the window doesn't matter for lead fn).     * 2. If the Window for the function is Row based and the End Boundary doesn't     * reference rows past the Current Row.      */
Hive,WITHOUT_CLASSIFICATION,//  check if any of the roles of this user is an owner 
Hive,WITHOUT_CLASSIFICATION,//  The BinarySortable serialization of the saved key for a possible series of equal keys. 
Hive,WITHOUT_CLASSIFICATION,//  x events to insert last repl ID: replDumpId+2x 
Hive,WITHOUT_CLASSIFICATION,//  Does it require a new MR job for grouping sets 
Hive,WITHOUT_CLASSIFICATION,//  temporarily mark it as child of all the TS 
Hive,WITHOUT_CLASSIFICATION,//  should not affect schema conversion 
Hive,WITHOUT_CLASSIFICATION,/*    * Lookup an long in the hash multi-set.   *   * @param key   *         The long key.   * @param hashMultiSetResult   *         The object to receive small table value(s) information on a MATCH.   *         Or for SPILL it has information on where to spill the big table row.   *   * @return   *         Whether the lookup was a match no match or spilled (the partition with the key   *         is currently spilled).    */
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getRef(java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  We ignore refcounts (and errors) for now. 
Hive,WITHOUT_CLASSIFICATION,//  surprise) that at midnight UTC it was 20:00 in local. So far we are on firm ground. 
Hive,WITHOUT_CLASSIFICATION,//  Bootstrap Repl B -> C 
Hive,WITHOUT_CLASSIFICATION,//  Cache indexList 
Hive,WITHOUT_CLASSIFICATION,/*      * Use common conversion method we share with fastSerializationUtilsWrite.      */
Hive,WITHOUT_CLASSIFICATION,//  For primitive object serialize to plain string 
Hive,WITHOUT_CLASSIFICATION,//  Split starting at row start will not read that row. 
Hive,WITHOUT_CLASSIFICATION,//  Test a single high-precision multiply of random inputs.   Arguments must be integers with optional - sign represented as strings.   Arguments must have 1 to 37 digits and the number of total digits 
Hive,WITHOUT_CLASSIFICATION,//  Handle decimal separately. 
Hive,WITHOUT_CLASSIFICATION,//  Remove operator   Add ops of new collection 
Hive,WITHOUT_CLASSIFICATION,//  Concurrent increase and termination increase fails. 
Hive,WITHOUT_CLASSIFICATION,//  Exchange single partitions using complete partition-spec (all partition columns) 
Hive,WITHOUT_CLASSIFICATION,//  column in the target table that will be pruned against 
Hive,WITHOUT_CLASSIFICATION,//  we need a column expression on other side. 
Hive,WITHOUT_CLASSIFICATION,//  call-5: open - mock:/mocktbl1/0_1 
Hive,WITHOUT_CLASSIFICATION,//  Always collect input file formats. 
Hive,WITHOUT_CLASSIFICATION,// if not using position alias and it is a number. 
Hive,WITHOUT_CLASSIFICATION,//  Make a new big table scratch column for the small table value. 
Hive,WITHOUT_CLASSIFICATION,//  Nope so look to see if Hive's conf dir has been explicitly set 
Hive,WITHOUT_CLASSIFICATION,//  UNDONE: Currently negative exponent is not supported. 
Hive,WITHOUT_CLASSIFICATION,//  months) produces a type timestamp via a calendar calculation. 
Hive,WITHOUT_CLASSIFICATION,//  An optional long array of length FastHiveDecimal.FAST_SCRATCH_LONGS_LEN. 
Hive,WITHOUT_CLASSIFICATION,//  UNDONE: For now a 1-element list with a null element is a null list... 
Hive,WITHOUT_CLASSIFICATION,//  Use IOSpecProto.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,//        but for now just rely on the cache put to lock them before we send them over. 
Hive,WITHOUT_CLASSIFICATION,//  references. 
Hive,WITHOUT_CLASSIFICATION,//  A type timestamp (TimestampColumnVector) plus/minus a type interval_day_time (TimestampColumnVector 
Hive,WITHOUT_CLASSIFICATION,/*        * See if the execution thread has just completed operation and result is available.       * If result is available then return the result. Otherwise raise exception.        */
Hive,WITHOUT_CLASSIFICATION,//  Monotonic iff its first argument is but not strict. 
Hive,WITHOUT_CLASSIFICATION,//  leap year 
Hive,WITHOUT_CLASSIFICATION,//  globStatus() API returns empty FileStatus[] when the specified path   does not exist. But getFileStatus() throw IOException. To mimic the   similar behavior we will return empty array on exception. For external   tables the path of the table will not exists during table creation 
Hive,WITHOUT_CLASSIFICATION,/*               Implicit assumption here is that database level is processed first before table level              which will depend on the iterator used since it should provide the higher level directory              listing before providing the lower level listing. This is also required such that              the dbTracker /  tableTracker are setup correctly always.            */
Hive,WITHOUT_CLASSIFICATION,//  If any table/partition directory is not owned by hive   then assume table is using storage-based auth - set external.   Transactional tables should still remain transactional 
Hive,WITHOUT_CLASSIFICATION,//  already stopped or else it was never   started (eg another service failing canceled startup) 
Hive,WITHOUT_CLASSIFICATION,//  nothing to start 
Hive,WITHOUT_CLASSIFICATION,//  set up temporary path to communicate between the small/big table 
Hive,WITHOUT_CLASSIFICATION,//  3. Destroy the sessions that we don't need anymore. 
Hive,WITHOUT_CLASSIFICATION,//  Filters are not over the rowid therefore scan everything 
Hive,WITHOUT_CLASSIFICATION,//  Switching tables between catalogs is not allowed. 
Hive,WITHOUT_CLASSIFICATION,//    throw new HiveException("difference is not in sort order and unique");   } 
Hive,WITHOUT_CLASSIFICATION,//  According to the Java documentation this does nothing but just in case 
Hive,WITHOUT_CLASSIFICATION,/* next call will eventually end up in HiveEndPoint.createPartitionIfNotExists() which    makes an operation on Driver    * and starts it's own CliSessionState and then closes it which removes it from ThreadLoacal;    * thus the session    * created in this class is gone after this; I fixed it in HiveEndPoint */
Hive,WITHOUT_CLASSIFICATION,// see Arrays.binarySearch() JavaDoc 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:EntityDescriptorProto) 
Hive,WITHOUT_CLASSIFICATION,//  get non-SSL socket transport 
Hive,WITHOUT_CLASSIFICATION,// Compactor generated a split for a bucket that has no data? 
Hive,WITHOUT_CLASSIFICATION,//  create a row per database name 
Hive,WITHOUT_CLASSIFICATION,//  add the last one 
Hive,WITHOUT_CLASSIFICATION,//  2. If the outputOI has all fields settable return it 
Hive,WITHOUT_CLASSIFICATION,//  in case we decided to run everything in local mode restore the 
Hive,WITHOUT_CLASSIFICATION,//  before failover check if we are getting connection from miniHS2_1 
Hive,WITHOUT_CLASSIFICATION,//  Naked dot. 
Hive,WITHOUT_CLASSIFICATION,//  DROP (DATABASE|SCHEMA) [IF EXISTS] database_name [RESTRICT|CASCADE]; 
Hive,WITHOUT_CLASSIFICATION,//  Get credentials using the configuration instance which has HBase properties 
Hive,WITHOUT_CLASSIFICATION,// deserialize path offset length using FileSplit 
Hive,WITHOUT_CLASSIFICATION,//  Test that adding multiple versions of the same schema 
Hive,WITHOUT_CLASSIFICATION,//  Authenticate or deny based on its context completion 
Hive,WITHOUT_CLASSIFICATION,//  No operation emitter will be used by some internal druid classes. 
Hive,WITHOUT_CLASSIFICATION,//  set all properties specified on the command line 
Hive,WITHOUT_CLASSIFICATION,/*      * Once enough rows have been output there is no need to process input rows.      */
Hive,WITHOUT_CLASSIFICATION,// it's key that this is a per HCatStorer instance object 
Hive,WITHOUT_CLASSIFICATION,//  Can't add NULL. 
Hive,WITHOUT_CLASSIFICATION,/*            * No other columns provided non-NULL values.  We *may* be able to finish all rows           * with this input column...            */
Hive,WITHOUT_CLASSIFICATION,//  http (over thrift) transport settings 
Hive,WITHOUT_CLASSIFICATION,//  Set child expressions 
Hive,WITHOUT_CLASSIFICATION,//  Make sure the bucketId is at max the numBuckets 
Hive,WITHOUT_CLASSIFICATION,// run major compaction 
Hive,WITHOUT_CLASSIFICATION,//  no need to look further for a checked variant of this expression 
Hive,WITHOUT_CLASSIFICATION,//  TODO Is it possible for heartbeats to come in from lost tasks - those should be told to die which   is likely already happening. 
Hive,WITHOUT_CLASSIFICATION,//  just 1 VInt 
Hive,WITHOUT_CLASSIFICATION,//  if there is anything wrong happen we bail out. 
Hive,WITHOUT_CLASSIFICATION,//  -select- should return a ResultSet 
Hive,WITHOUT_CLASSIFICATION,//  AND hash with mask to 0 out sign bit to make sure it's positive.   Then we know taking the result mod n is in the range (0..n-1).   Include salt as argument so this hash function can be varied   if we need to rehash. 
Hive,WITHOUT_CLASSIFICATION,// produce this sequence 
Hive,WITHOUT_CLASSIFICATION,//  scSize == 1 
Hive,WITHOUT_CLASSIFICATION,//  Working on the assumption that a single DAG runs at a time per AM. 
Hive,WITHOUT_CLASSIFICATION,//  Now create a delete delta that has rowIds divisible by both 3 and 2. This will produce 
Hive,WITHOUT_CLASSIFICATION,//  Make sure the allocation is transfered correctly on return. 
Hive,WITHOUT_CLASSIFICATION,//  example file names are input1.q.out_mr_0.17 or input2.q.out_0.17 
Hive,WITHOUT_CLASSIFICATION,//  Jersey uses java.util.logging - bridge to slf4 
Hive,WITHOUT_CLASSIFICATION,//  seek directly to first record 
Hive,WITHOUT_CLASSIFICATION,//  not (e.g.: group by) 
Hive,WITHOUT_CLASSIFICATION,//  Currently there is no way to stop the MetaStore service. It will be stopped when the   test JVM exits. This is how other tests are also using MetaStore server. 
Hive,WITHOUT_CLASSIFICATION,//  Note that it shouldn't show t14 from db2 
Hive,WITHOUT_CLASSIFICATION,//  Open a session 
Hive,WITHOUT_CLASSIFICATION,//  if it is a reference to a boolean column covert it to a truth test. 
Hive,WITHOUT_CLASSIFICATION,//  Set up CredentialProvider 
Hive,WITHOUT_CLASSIFICATION,//  Rows we looked up as one repeated key need to spill.  But filtered out rows   need to be generated as non-matches too. 
Hive,WITHOUT_CLASSIFICATION,//  For operator the function name is the operator text unless it's in   our special dictionary 
Hive,WITHOUT_CLASSIFICATION,//  Iterate over the Path -> Partition descriptions to find the partition   that matches our input split. 
Hive,WITHOUT_CLASSIFICATION,//  The character set name starts with a _ so strip that 
Hive,WITHOUT_CLASSIFICATION,//  Check for an escape character before the colon 
Hive,WITHOUT_CLASSIFICATION,//  this colon is escaped search again after it 
Hive,WITHOUT_CLASSIFICATION,/*      * No joining condition.      */
Hive,WITHOUT_CLASSIFICATION,//  l4j.info("ReduceRecordSource processVectorGroup keyBytes " + keyLength + " " +       VectorizedBatchUtil.displayBytes(keyBytes 0 keyLength)); 
Hive,WITHOUT_CLASSIFICATION,//  (1) Because we have operator.supportUnionRemoveOptimization() for   true only in SEL and FIL operators   this rule will actually only match UNION%(SEL%|FIL%)*FS%   (2) The assumption here is that if   operator.getChildOperators().size() > 1 we are going to have   multiple FS operators i.e. multiple inserts.   Current implementation does not support this. More details please   see HIVE-9217. 
Hive,WITHOUT_CLASSIFICATION,//  http mode 
Hive,WITHOUT_CLASSIFICATION,//  Parse digits. 
Hive,WITHOUT_CLASSIFICATION,//  This will throw an exception in case of the response from druid is not an array   this case occurs if for instance druid query execution returns an exception instead of array of results. 
Hive,WITHOUT_CLASSIFICATION,//  Remove all parts that are not partition columns. See javadoc for details. 
Hive,WITHOUT_CLASSIFICATION,//  Only keep the most significant decimalDigits digits. 
Hive,WITHOUT_CLASSIFICATION,//  we copy all of the values to avoid creating more objects   TODO: it might be cheaper to always preserve data or reset existing objects 
Hive,WITHOUT_CLASSIFICATION,//  them 
Hive,WITHOUT_CLASSIFICATION,//  prepare arguments for createVectorExpression 
Hive,WITHOUT_CLASSIFICATION,//  composite key types is a comma separated list of different parts of the   composite keys in   order in which they appear in the key 
Hive,WITHOUT_CLASSIFICATION,//  Note: this should never happen for mm tables. 
Hive,WITHOUT_CLASSIFICATION,//  if data size still could not be determined then fall back to filesytem to get file 
Hive,WITHOUT_CLASSIFICATION,//  We currently include all data partition and any vectorization available   virtual columns in the VRB. 
Hive,WITHOUT_CLASSIFICATION,//  for use in DDL operations that only need a shared lock such as creating a table   for use in DDL statements that do not require a lock 
Hive,WITHOUT_CLASSIFICATION,//  Set up the rules for the graph walker for group by and join operators 
Hive,WITHOUT_CLASSIFICATION,//  We're hijacking the big table evaluators and replacing them with our own custom ones 
Hive,WITHOUT_CLASSIFICATION,//  if there are no files/partitions to read we need to skip trying to read 
Hive,WITHOUT_CLASSIFICATION,//  EXPR AS (ALIAS...) parses but is only allowed for UDTF's   This check is not needed and invalid when there is a transform b/c the 
Hive,WITHOUT_CLASSIFICATION,//  Add the additional postprocessing transformations needed if 
Hive,WITHOUT_CLASSIFICATION,/*   uses the authorizer from SessionState will need some more work to get this to run in parallel  however this should not be a bottle neck so might not need to parallelize this.    */
Hive,WITHOUT_CLASSIFICATION,//  ReduceSink parents that we missed. 
Hive,WITHOUT_CLASSIFICATION,//  Note: we assume here that the data that was returned to the caller from cache will not   be passed back in via put. Right now it's safe since we don't do anything. But if we   evict proactively we will have to compare objects all the way down. 
Hive,WITHOUT_CLASSIFICATION,//  wrong expression: 
Hive,WITHOUT_CLASSIFICATION,//  Capacity exists. 
Hive,WITHOUT_CLASSIFICATION,//  Allow implicit String to Double conversion 
Hive,WITHOUT_CLASSIFICATION,//  Couldn't determine common type don't cast 
Hive,WITHOUT_CLASSIFICATION,//  When we have yet another child beyond the current one... save unselected. 
Hive,WITHOUT_CLASSIFICATION,//  object overhead + 4 bytes for int (nanos) + 4 bytes of padding 
Hive,WITHOUT_CLASSIFICATION,//  Set UGI to use Kerberos   Have to use the string constant to support hadoop 1 
Hive,WITHOUT_CLASSIFICATION,//  The creation time is changed so we do not check that 
Hive,WITHOUT_CLASSIFICATION,//  Ensure that we get the right concrete ColumnMapping 
Hive,WITHOUT_CLASSIFICATION,//  cast only needed for Hadoop 0.17 compatibility 
Hive,WITHOUT_CLASSIFICATION,//  If it has a limit we use it and we do not distribute the query 
Hive,WITHOUT_CLASSIFICATION,//  TYPE_NAME   DATA_TYPE   PRECISION   LITERAL_PREFIX   LITERAL_SUFFIX   CREATE_PARAMS   NULLABLE   CASE_SENSITIVE   SEARCHABLE   UNSIGNED_ATTRIBUTE   FIXED_PREC_SCALE   AUTO_INCREMENT   LOCAL_TYPE_NAME   MINIMUM_SCALE   MAXIMUM_SCALE   SQL_DATA_TYPE unused   SQL_DATETIME_SUB unused  NUM_PREC_RADIX 
Hive,WITHOUT_CLASSIFICATION,//  optional string fragment_identifier_string = 2; 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: To support pruning the grouping set id dummy key by VectorGroupbyOpeator MERGE_PARTIAL   case we use the keyCount passed to the constructor and not keyExpressions.length. 
Hive,WITHOUT_CLASSIFICATION,//  We can proceed with the conversion 
Hive,WITHOUT_CLASSIFICATION,//  We expect evicted but not failed. 
Hive,WITHOUT_CLASSIFICATION,//  Boolean is special case. 
Hive,WITHOUT_CLASSIFICATION,//  read each child node add to results 
Hive,WITHOUT_CLASSIFICATION,//  looks like some network outrage reset the file system object and retry. 
Hive,WITHOUT_CLASSIFICATION,//  HiveServer2 WebUI 
Hive,WITHOUT_CLASSIFICATION,//  Only do the lightweight stuff in ctor; by default LLAP coordinator is created during 
Hive,WITHOUT_CLASSIFICATION,//  Current usage looks like it's only for metadata columns but if that changes then   this method may need to require a type qualifiers aruments. 
Hive,WITHOUT_CLASSIFICATION,//  timeout 
Hive,WITHOUT_CLASSIFICATION,//  Boolean must come before the integer family. It's a special case. 
Hive,WITHOUT_CLASSIFICATION,//  cascade only occurs with partitioned table 
Hive,WITHOUT_CLASSIFICATION,//  the function should support both string and binary input types 
Hive,WITHOUT_CLASSIFICATION,//  TODO: For LLAP assumption is off-heap cache. 
Hive,WITHOUT_CLASSIFICATION,//  No match 
Hive,WITHOUT_CLASSIFICATION,//  Hash is ineffective disable. 
Hive,WITHOUT_CLASSIFICATION,//  authorize drops if there was a drop privilege requirement and   table is not external (external table data is not dropped) or   "hive.metastore.authorization.storage.check.externaltable.drop" 
Hive,WITHOUT_CLASSIFICATION,//  other rewrites. 
Hive,WITHOUT_CLASSIFICATION,//  (1ax) (2bx) (1cx) (2ay) 
Hive,WITHOUT_CLASSIFICATION,//  Verify corrupted cache value gets replaced. 
Hive,WITHOUT_CLASSIFICATION,//  then remove the table 
Hive,WITHOUT_CLASSIFICATION,//  colStatIndex=121314 respond to "AVG_LONG" "AVG_DOUBLE" 
Hive,WITHOUT_CLASSIFICATION,//  a>0 && 2a=b 
Hive,WITHOUT_CLASSIFICATION,//  number of register bits 
Hive,WITHOUT_CLASSIFICATION,//  Preparation for hybrid grace hash join 
Hive,WITHOUT_CLASSIFICATION,//  override the db name if provided in repl load command 
Hive,WITHOUT_CLASSIFICATION,//  oldDbName and newDbName *will* be the same if we're here 
Hive,WITHOUT_CLASSIFICATION,// this needs to be manually set under normal circumstances MR Task does this 
Hive,WITHOUT_CLASSIFICATION,//  For each file figure out which bucket it is. 
Hive,WITHOUT_CLASSIFICATION,// should never happen 
Hive,WITHOUT_CLASSIFICATION,//  Discard context that is cached for reuse per thread to avoid allocating lots of arrays   and then resizing them down the line if we need a bigger size. 
Hive,WITHOUT_CLASSIFICATION,/*      * all filters were executed during partition pruning      */
Hive,WITHOUT_CLASSIFICATION,//  nothing in front of this one to prevent acquisition. 
Hive,WITHOUT_CLASSIFICATION,//  set the file owner to hive (or the id metastore run as) 
Hive,WITHOUT_CLASSIFICATION,/*    * This method must return the decimal TypeInfo for what getCastToDecimal will produce.    */
Hive,WITHOUT_CLASSIFICATION,//  clean test space 
Hive,WITHOUT_CLASSIFICATION,/* |------+----------------+----------------+----------+-------+-----------------------------------|| Use  | Boundary1.type | Boundary1. amt | Sort Key | Order | Behavior                          || Case |                |                |          |       |                                   ||------+----------------+----------------+----------+-------+-----------------------------------||   1. | PRECEDING      | UNB            | ANY      | ANY   | start = 0                         ||   2. | CURRENT ROW    |                | ANY      | ANY   | scan backwards until row R2       ||      |                |                |          |       | such R2.sk != R.sk                ||      |                |                |          |       | start = R2.idx + 1                ||------+----------------+----------------+----------+-------+-----------------------------------|    */
Hive,WITHOUT_CLASSIFICATION,//  This no longer does expansions of run commands in the files as it used to.  Instead it   depends on the developers to have already unrolled those in the files. 
Hive,WITHOUT_CLASSIFICATION,//  Find out if this synthetic predicate belongs to the current cycle 
Hive,WITHOUT_CLASSIFICATION,//  special entry for non-DP case 
Hive,WITHOUT_CLASSIFICATION,//  If pruning sink operator is with map join then pruning sink need not be split to a   separate tree.  Add the pruning sink operator to context and return 
Hive,WITHOUT_CLASSIFICATION,//  If there is one and only one limit starting at op return the limit   If there is no limit return 0 
Hive,WITHOUT_CLASSIFICATION,//  2 original files 1 original directory 1 base directory and 1 delta directory 
Hive,WITHOUT_CLASSIFICATION,//  First pass will drop the materialized views 
Hive,WITHOUT_CLASSIFICATION,//  Deserialize 
Hive,WITHOUT_CLASSIFICATION,//  check null handling 
Hive,WITHOUT_CLASSIFICATION,// normalize name for mapping 
Hive,WITHOUT_CLASSIFICATION,//  Currently the long must fit 2 markers. Setting these bit sizes determines the balance   between max pool size allowed and max concurrency allowed. This balance here is not what we   want (up to 254 of each op while only 65535 objects limit) but it uses whole bytes and is   good for now. Delta and RC take the same number of bits; usually it doesn't make sense to   have more delta. 
Hive,WITHOUT_CLASSIFICATION,//  Cartesian product 
Hive,WITHOUT_CLASSIFICATION,//  Cache the hints before CBO runs and removes them. 
Hive,WITHOUT_CLASSIFICATION,//  Error because of thrift client we have to recreate base object 
Hive,WITHOUT_CLASSIFICATION,//  let's see if we can convert aggregate into projects 
Hive,WITHOUT_CLASSIFICATION,//  null or NULL 
Hive,WITHOUT_CLASSIFICATION,//  base since the presence of a base will make the originals obsolete. 
Hive,WITHOUT_CLASSIFICATION,//  This registration has to be done after knownTasks has been populated.   Register for state change notifications so that the waitQueue can be re-ordered correctly   if the fragment moves in or out of the finishable state. 
Hive,WITHOUT_CLASSIFICATION,//  require db ownership if there is a file require SELECT  INSERT and DELETE 
Hive,WITHOUT_CLASSIFICATION,// test for and or precedence 
Hive,WITHOUT_CLASSIFICATION,//  When split-update is enabled for ACID we initialize a separate deleteEventWriter   that is used to write all the delete events (in case of minor compaction only). For major   compaction history is not required to be maintained hence the delete events are processed   but not re-written separately. 
Hive,WITHOUT_CLASSIFICATION,//  read the null byte again 
Hive,WITHOUT_CLASSIFICATION,// in both cases this will be the next day in GMT 
Hive,WITHOUT_CLASSIFICATION,//  figure out which factory we're instantiating from HiveConf iff it's not been set on us directly. 
Hive,WITHOUT_CLASSIFICATION,//  blank " " (1 byte)   blank " " (1 byte)   blank " " (1 byte)   hyphen-minus "-" U-002D (1 byte)   blank " " (1 byte)   grave accent "-" U-0060 (1 byte)   BLACK SUN WITH RAYS U+2600 (3 bytes) 
Hive,WITHOUT_CLASSIFICATION,/*  * JavaCC - OriginalChecksum=67039445e12d18e18e63124a33879cd3 (do not edit this * line)  */
Hive,WITHOUT_CLASSIFICATION,//  Check repeating 
Hive,WITHOUT_CLASSIFICATION,//  ////////////////////////   Command methods follow   //////////////////////// 
Hive,WITHOUT_CLASSIFICATION,//  Make sure that the '#' wasn't escaped 
Hive,WITHOUT_CLASSIFICATION,//  add any other header info 
Hive,WITHOUT_CLASSIFICATION,//  If table doesn't exist allow creating a new one only if the database state is older than the update.   This in-turn applicable for partitions creation as well. 
Hive,WITHOUT_CLASSIFICATION,//  DPP work is considered a descendant because work needs   to finish for it to execute 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.ICLIService#getCatalogs(org.apache.hive.service.cli.SessionHandle)    */
Hive,WITHOUT_CLASSIFICATION,//  64 bytes is the overhead for a reference 
Hive,WITHOUT_CLASSIFICATION,// using target.a breaks this 
Hive,WITHOUT_CLASSIFICATION,//  COMPONENT 
Hive,WITHOUT_CLASSIFICATION,//  update the parentOp 
Hive,WITHOUT_CLASSIFICATION,//  If column is not column reference  we bail out 
Hive,WITHOUT_CLASSIFICATION,//  make sure b will have less digits than A 
Hive,WITHOUT_CLASSIFICATION,//  This port is already in use try to use another. 
Hive,WITHOUT_CLASSIFICATION,//  ensure size is >= 1 otherwise try again 
Hive,WITHOUT_CLASSIFICATION,//  sleep half a second 
Hive,WITHOUT_CLASSIFICATION,//  Table exists and is older than the update. Now need to ensure if update allowed on the   partition. 
Hive,WITHOUT_CLASSIFICATION,//  Handled via adminPrivOps (see above). 
Hive,WITHOUT_CLASSIFICATION,// /////////////////////////////////////////////  ////////////////// correct testcase  ////////////////// executed twice: once with the typed ps setters once with the generic setObject 
Hive,WITHOUT_CLASSIFICATION,//  the Map vertex. 
Hive,WITHOUT_CLASSIFICATION,//  these are non standard version numbers. can't perform the   comparison on these so assume that they are incompatible 
Hive,WITHOUT_CLASSIFICATION,//  Test that locking a table prevents locking of partitions of the table 
Hive,WITHOUT_CLASSIFICATION,//  input and output are the same 
Hive,WITHOUT_CLASSIFICATION,// don't create splits for anything past logical EOF 
Hive,WITHOUT_CLASSIFICATION,//  Pinged before. Log only occasionally.   5 seconds elapsed. Log again. 
Hive,WITHOUT_CLASSIFICATION,// this implies that no locks are needed for such a command 
Hive,WITHOUT_CLASSIFICATION,//  its value if provided 
Hive,WITHOUT_CLASSIFICATION,//  used to load columns' value into memory 
Hive,WITHOUT_CLASSIFICATION,//  Add as is; it would become a recursive split. 
Hive,WITHOUT_CLASSIFICATION,//  call-2: open to read - split 2 => mock:/mocktable3/0_1 
Hive,WITHOUT_CLASSIFICATION,//  note that we do not set location - for repl load we want that auto-created. 
Hive,WITHOUT_CLASSIFICATION,/*          * Get our Single-Column String hash set information for this specialized class.          */
Hive,WITHOUT_CLASSIFICATION,//  or the old_pruner_pred and the new_ppr_pred 
Hive,WITHOUT_CLASSIFICATION,//  get delegation token for the given proxy user 
Hive,WITHOUT_CLASSIFICATION,//  Node disable timeout higher than locality delay. 
Hive,WITHOUT_CLASSIFICATION,//  If the query contains windowing processing 
Hive,WITHOUT_CLASSIFICATION,//  If not we will start to transform the operator tree. 
Hive,WITHOUT_CLASSIFICATION,//  Deep one is bigger i.e. less to the top 
Hive,WITHOUT_CLASSIFICATION,//  Allow create table only on t1. Create should fail for rest of the tables and hence constraints 
Hive,WITHOUT_CLASSIFICATION,/* Here we want to encode the error in machine readable way (e.g. JSON)     * Ideally errorCode would always be set to a canonical error defined in ErrorMsg.     * In practice that is rarely the case so the messy logic below tries to tease     * out canonical error code if it can.  Exclude stack trace from output when     * the error is a specific/expected one.     * It's written to stdout for backward compatibility (WebHCat consumes it). */
Hive,WITHOUT_CLASSIFICATION,//  Sum all non-null double column values for avg; maintain isGroupResultNull; after last row of   last group batch compute the group avg when sum is non-null. 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise it returns the expression that originated the column 
Hive,WITHOUT_CLASSIFICATION,//  get task associated with this union 
Hive,WITHOUT_CLASSIFICATION,//  Verify integerDigitCount given fastScale. 
Hive,WITHOUT_CLASSIFICATION,//  Return value modulo n but always in the positive range (0..n-1).   Since n is prime this gives good spread for numbers that are multiples   of one billion which is important since timestamps internally   are stored as a number of nanoseconds and the fractional seconds   part is often 0. 
Hive,WITHOUT_CLASSIFICATION,/*  container reuse  */
Hive,WITHOUT_CLASSIFICATION,//  Timestamp Scalar case becomes use long/double scalar class. 
Hive,WITHOUT_CLASSIFICATION,/*      * If after classifying filters there is more than 1 joining predicate we     * don't handle this. Return null.      */
Hive,WITHOUT_CLASSIFICATION,//  creating new jars for classes that have already been packaged. 
Hive,WITHOUT_CLASSIFICATION,//  D8. Unnormalize: Divide R to get result 
Hive,WITHOUT_CLASSIFICATION,//  Find the new database id 
Hive,WITHOUT_CLASSIFICATION,//  Get the internal map structure (MAP_KEY_VALUE) 
Hive,WITHOUT_CLASSIFICATION,// txnid 3 was committed and thus not open 
Hive,WITHOUT_CLASSIFICATION,//  unique the list 
Hive,WITHOUT_CLASSIFICATION,//  Get our own instance of the transaction handler 
Hive,WITHOUT_CLASSIFICATION,//  using such an aggregate fileId cache is not bulletproof and should be disable-able. 
Hive,WITHOUT_CLASSIFICATION,//  Try with chunked stream. Here the chunked output didn't get a chance to write the end-of-data 
Hive,WITHOUT_CLASSIFICATION,//  The pruner should not have completed. 
Hive,WITHOUT_CLASSIFICATION,//  distKeyLength doesn't include tag but includes buckNum in cachedKeys[0] 
Hive,WITHOUT_CLASSIFICATION,//  Perform decorrelation. 
Hive,WITHOUT_CLASSIFICATION,//  If there is mismatch in bucketingVersion then it should be set to   -1 that way SMB will be disabled. 
Hive,WITHOUT_CLASSIFICATION,//  drop a stats parameter which triggers recompute stats update automatically 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:QueryIdentifierProto) 
Hive,WITHOUT_CLASSIFICATION,//  Select all with the is null and is not null as 2 child expressions and then   expect the 3rd child to not be invoked. 
Hive,WITHOUT_CLASSIFICATION,//  optional string operationId = 8; 
Hive,WITHOUT_CLASSIFICATION,//  if current pos is larger than shrinkedLength which is calculated for   each split by table sampling stop fetching any more (early exit) 
Hive,WITHOUT_CLASSIFICATION,//  write this out to a file and import it into hive 
Hive,WITHOUT_CLASSIFICATION,// create 2 rows in a file 000000_0_copy1 and 2 rows in a file 000001_0_copy1 
Hive,WITHOUT_CLASSIFICATION,//  http path should begin with "/" 
Hive,WITHOUT_CLASSIFICATION,//  They aren't the same but we may be able to do a cast 
Hive,WITHOUT_CLASSIFICATION,//  Whether to show a link to the most failed task + debugging tips 
Hive,WITHOUT_CLASSIFICATION,//  Remember the condition variables for EXPLAIN regardless of whether we specialize or not. 
Hive,WITHOUT_CLASSIFICATION,//  reason we compute interim row count where join type isn't considered is because later 
Hive,WITHOUT_CLASSIFICATION,//  Some of these tests require intercepting System.exit() using the SecurityManager.   It is safer to  register/unregister our SecurityManager during setup/teardown instead   of doing it within the individual test cases. 
Hive,WITHOUT_CLASSIFICATION,// throw if file already exists as that should never happen 
Hive,WITHOUT_CLASSIFICATION,//  that the other locker hasn't checked yet and he could lock as well. 
Hive,WITHOUT_CLASSIFICATION,//  test long->double version 
Hive,WITHOUT_CLASSIFICATION,//  Unsupported for the test case 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getObject(java.lang.String java.util.Map)    */
Hive,WITHOUT_CLASSIFICATION,//  CLear the output 
Hive,WITHOUT_CLASSIFICATION,//  Enabling grouping on the payload. 
Hive,WITHOUT_CLASSIFICATION,//  need to handle offset with single digital hour see JDK-8066806 
Hive,WITHOUT_CLASSIFICATION,//  array<null> is compatible with any other array<type> 
Hive,WITHOUT_CLASSIFICATION,//  'and' nodes need to be intersected 
Hive,WITHOUT_CLASSIFICATION,//  All zeroes. 
Hive,WITHOUT_CLASSIFICATION,/*    * Debug.    */
Hive,WITHOUT_CLASSIFICATION,//  Since we don't have an explicit AM end signal yet - we're going to create   and discard AMNodeInfo instances per query. 
Hive,WITHOUT_CLASSIFICATION,//  If the UDF depends on any external resources we can't fold because the   resources may not be available at compile time. 
Hive,WITHOUT_CLASSIFICATION,//  if it is to create view we do not use table alias 
Hive,WITHOUT_CLASSIFICATION,//  Tokens cannot be used for the management protocol (for now). 
Hive,WITHOUT_CLASSIFICATION,//  likely unsupported combination of params   https://bugs.openjdk.java.net/browse/CODETOOLS-7901296 is not available yet to skip benchmark cleanly 
Hive,WITHOUT_CLASSIFICATION,//  only need to execute it to get db Lock 
Hive,WITHOUT_CLASSIFICATION,//  We assume one request is only for one file. 
Hive,WITHOUT_CLASSIFICATION,/*  Convert a skewed table to non-skewed table.  */
Hive,WITHOUT_CLASSIFICATION,//  For calcite isDeterministic just matters for within the query. 
Hive,WITHOUT_CLASSIFICATION,//  Nothing to do this is EOF 
Hive,WITHOUT_CLASSIFICATION,//  If the input is already present make sure the new parent is added to the input. 
Hive,WITHOUT_CLASSIFICATION,//  This operator has not been removed include it in the list of existing operators 
Hive,WITHOUT_CLASSIFICATION,//  Set http path 
Hive,WITHOUT_CLASSIFICATION,//  Submit the Spark job 
Hive,WITHOUT_CLASSIFICATION,//  Now test with repeating flag 
Hive,WITHOUT_CLASSIFICATION,/*    * Based on the Paper by Daniel Lemire: Streaming Max-Min filter using no more   * than 3 comparisons per elem.   *   * 1. His algorithm works on fixed size windows up to the current row. For row   * 'i' and window 'w' it computes the min/max for window (i-w i). 2. The core   * idea is to keep a queue of (max idx) tuples. A tuple in the queue   * represents the max value in the range (prev tuple.idx idx). Using the   * queue data structure and following 2 operations it is easy to see that   * maxes can be computed: - on receiving the ith row; drain the queue from the   * back of any entries whose value is less than the ith entry; add the ith   * value as a tuple in the queue (i-val i) - on the ith step check if the   * element at the front of the queue has reached its max range of influence;   * i.e. frontTuple.idx + w > i. If yes we can remove it from the queue. - on   * the ith step o/p the front of the queue as the max for the ith entry.   *   * Here we modify the algorithm: 1. to handle window's that are of the form   * (i-p i+f) where p is numPrecedingf = numFollowing - we start outputing   * rows only after receiving f rows. - the formula for 'influence range' of an   * idx accounts for the following rows. 2. optimize for the case when   * numPreceding is Unbounded. In this case only 1 max needs to be tarcked at   * any given time.    */
Hive,WITHOUT_CLASSIFICATION,//  row 1 - results should be null 
Hive,WITHOUT_CLASSIFICATION,//  Only set up the updater for insert.  For update and delete we don't know unitl we see   the row. 
Hive,WITHOUT_CLASSIFICATION,/*  simplified from (position + (i - prefix) + sync.length) - SYNC_SIZE  */
Hive,WITHOUT_CLASSIFICATION,//  try to instantiate the old replv1 task generation on every event produced. 
Hive,WITHOUT_CLASSIFICATION,//  For each partition in each table drop the partitions and get a list of 
Hive,WITHOUT_CLASSIFICATION,//  Value count rows. 
Hive,WITHOUT_CLASSIFICATION,//  loading of metastore stats is async; execute a simple to ensure they are loaded 
Hive,WITHOUT_CLASSIFICATION,//  Since there was an allocation failure - don't try assigning tasks at the next priority. 
Hive,WITHOUT_CLASSIFICATION,// execute a query 
Hive,WITHOUT_CLASSIFICATION,//  Permissions for the metrics file 
Hive,WITHOUT_CLASSIFICATION,//  remove Auth cookie 
Hive,WITHOUT_CLASSIFICATION,//  Prefix for top level properties. 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise this is not a sampling predicate and we need to 
Hive,WITHOUT_CLASSIFICATION,//  No Cookies for requested URI authenticate user and add authentication header 
Hive,WITHOUT_CLASSIFICATION,//  We need to use the expanded text for the materialized view as it will contain 
Hive,WITHOUT_CLASSIFICATION,/*  there are nulls in our column  */
Hive,WITHOUT_CLASSIFICATION,//  The types for ROWS BETWEEN or RANGE BETWEEN windowing spec 
Hive,WITHOUT_CLASSIFICATION,//          (* and $expr) 
Hive,WITHOUT_CLASSIFICATION,//  Start of the split is before this slice.   Simple case - we will read cache from the split start offset. 
Hive,WITHOUT_CLASSIFICATION,//  Someone else replaced/removed a stale value try again. 
Hive,WITHOUT_CLASSIFICATION,//  The ArgumentCompletor allows us to match multiple tokens 
Hive,WITHOUT_CLASSIFICATION,//  Now create SparkTasks from the SparkWorks also set up dependency 
Hive,WITHOUT_CLASSIFICATION,//  Determines if we should cache a table (& its partitions stats etc) 
Hive,WITHOUT_CLASSIFICATION,//  the schema for intersect distinct is like this   R3 on all attributes + count(c) as cnt   finally add a project to project out the last column 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise fall through and proceed with non-Decimal64 vector expression classes... 
Hive,WITHOUT_CLASSIFICATION,//  generate the serialized keys of the batch. 
Hive,WITHOUT_CLASSIFICATION,//  Indexes of those equivalent columns 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *    * @see   * org.apache.hadoop.hive.ql.udf.ptf.TableFunctionEvaluator#processRow(java   * .lang.Object)   *    * - hand row to each Function provided there are enough rows for Function's   * window. - call getNextObject on each Function. - output as many rows as   * possible based on minimum sz of Output List    */
Hive,WITHOUT_CLASSIFICATION,//  relations involved in JOIN 
Hive,WITHOUT_CLASSIFICATION,//  If we have not added to this column before we bail out 
Hive,WITHOUT_CLASSIFICATION,//  precision is char length 
Hive,WITHOUT_CLASSIFICATION,//  returns single row/column 
Hive,WITHOUT_CLASSIFICATION,//  double 
Hive,WITHOUT_CLASSIFICATION,//  Even if we are just setting the scale when newScale is greater than the current scale 
Hive,WITHOUT_CLASSIFICATION,//  Note: hypothetically a generic WM-aware-session should not know about guaranteed tasks.         We should have another subclass for a WM-aware-session-implemented-using-ducks.         However since this is the only type of WM for now this can live here. 
Hive,WITHOUT_CLASSIFICATION,// principal name can be a user group or role 
Hive,WITHOUT_CLASSIFICATION,// update clause 
Hive,WITHOUT_CLASSIFICATION,//  Fast check if the next day directory exists return it. 
Hive,WITHOUT_CLASSIFICATION,/*  first_name = 'john'  */
Hive,WITHOUT_CLASSIFICATION,//  make compile happy 
Hive,WITHOUT_CLASSIFICATION,//  Check if the function can be short cut. 
Hive,WITHOUT_CLASSIFICATION,//  Don't strip quotes. 
Hive,WITHOUT_CLASSIFICATION,//  we start from sq2 end up with sq1. 
Hive,WITHOUT_CLASSIFICATION,//  Reopen implies the use of the reopened session for the same query that we gave it out   for; so as we would have failed an active query fail the user before it's started. 
Hive,WITHOUT_CLASSIFICATION,//  Set the session key token (Base64 encoded) in the headers 
Hive,WITHOUT_CLASSIFICATION,//  Not much we can do about it honestly 
Hive,WITHOUT_CLASSIFICATION,/*  TODO HIVE-18991    List<String> materializedViews = client.getMaterializedViewsForRewriting(dbName);    Assert.assertEquals(1 materializedViews.size());    Assert.assertEquals(tableNames[3] materializedViews.get(0));     */
Hive,WITHOUT_CLASSIFICATION,//  proper index of a dummy. 
Hive,WITHOUT_CLASSIFICATION,//  deal with dynamic partitions 
Hive,WITHOUT_CLASSIFICATION,//  Store away the keystore. 
Hive,WITHOUT_CLASSIFICATION,//  Verify that the correct methods are invoked on AccumuloInputFormat 
Hive,WITHOUT_CLASSIFICATION,//  Alter unpartitioned table set table property 
Hive,WITHOUT_CLASSIFICATION,//  Based on SecurityUtil. 
Hive,WITHOUT_CLASSIFICATION,//  Setup InBloomFilter() UDF 
Hive,WITHOUT_CLASSIFICATION,//  Set transportMode 
Hive,WITHOUT_CLASSIFICATION,//  A thread is spun up to start these other threads.  That's because we can't start them   until after the TServer has started but once TServer.serve is called we aren't given back   control. 
Hive,WITHOUT_CLASSIFICATION,// both delete events land in corresponding buckets to the original row-ids 
Hive,WITHOUT_CLASSIFICATION,//  First we extract the information that the query provides 
Hive,WITHOUT_CLASSIFICATION,//  500ms   50ms 
Hive,WITHOUT_CLASSIFICATION,/*      * Add these 3 values:     *     * mixedUp     * green     * NULL     * <4 char string with mult-byte chars>      */
Hive,WITHOUT_CLASSIFICATION,//  A struct column can have a null child column 
Hive,WITHOUT_CLASSIFICATION,//  Build OI with timestamp granularity column 
Hive,WITHOUT_CLASSIFICATION,//  if active passive HA enabled use default HA namespace 
Hive,WITHOUT_CLASSIFICATION,//  Need to send the splits to multiple buckets 
Hive,WITHOUT_CLASSIFICATION,//  Determine maximum of all non-null double column values; maintain isGroupResultNull. 
Hive,WITHOUT_CLASSIFICATION,//  Create queryId based route 
Hive,WITHOUT_CLASSIFICATION,//  Check that the bit at the given index is '1' or '0' 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getObject(java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  nodeOfInterest is the query 
Hive,WITHOUT_CLASSIFICATION,//  ignore files of 0 length 
Hive,WITHOUT_CLASSIFICATION,//  TODO: make add asynchronous: add shouldn't block the higher level calls 
Hive,WITHOUT_CLASSIFICATION,//  Adding name of the log file in an extra log line so it is easier to find   the original if there is a test error 
Hive,WITHOUT_CLASSIFICATION,//  if the schemaDestf is null it means the destination is not in the local file system 
Hive,WITHOUT_CLASSIFICATION,//  exit 
Hive,WITHOUT_CLASSIFICATION,// since we may have both Update and Delete branches Auth needs to know 
Hive,WITHOUT_CLASSIFICATION,//  verify that partition rename succeded. 
Hive,WITHOUT_CLASSIFICATION,//  match found! use it   update the tables. 
Hive,WITHOUT_CLASSIFICATION,//  the constructor wasn't defined in the implementation class. Flag error 
Hive,WITHOUT_CLASSIFICATION,//  Create the list record copy first record value/key lengths there. 
Hive,WITHOUT_CLASSIFICATION,/*    * This number is a safety limit for 32MB of writables.    */
Hive,WITHOUT_CLASSIFICATION,//  Get the GenericUDFStructField to process the field of Struct type 
Hive,WITHOUT_CLASSIFICATION,//  1 asc 0 desc 
Hive,WITHOUT_CLASSIFICATION,//  multi-line 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:NotTezEvent) 
Hive,WITHOUT_CLASSIFICATION,//  add dependencies for the jars 
Hive,WITHOUT_CLASSIFICATION,//  Save the actual values from each row as opposed to the String representation. 
Hive,WITHOUT_CLASSIFICATION,//  Note: Regardless of what the Input File Format returns we have determined   with VectorAppendRow.initConversion that only currentDataColumnCount columns   have values we want.     Any extra columns needed by the table schema were set to repeating null   in the batch by setupPartitionContextVars. 
Hive,WITHOUT_CLASSIFICATION,//  Make binary integer value in the bytearray 
Hive,WITHOUT_CLASSIFICATION,//  Use table-dir as root-dir. 
Hive,WITHOUT_CLASSIFICATION,//  No further checks if not a file split. Return equality. 
Hive,WITHOUT_CLASSIFICATION,//  Convert PARENT -> RS -> SEL -> FS to PARENT -> FS 
Hive,WITHOUT_CLASSIFICATION,//  only left input repeating 
Hive,WITHOUT_CLASSIFICATION,//  Offset trims. 
Hive,WITHOUT_CLASSIFICATION,//  Inject a behaviour where it repeats the INSERT event twice with different event IDs 
Hive,WITHOUT_CLASSIFICATION,//  returns whether a record was forwarded 
Hive,WITHOUT_CLASSIFICATION,//  Ordered columns are the source columns. 
Hive,WITHOUT_CLASSIFICATION,//  Note that in theory we are guaranteed to have a session waiting for us here but   the expiration failures etc. may cause one to be missing pending restart. 
Hive,WITHOUT_CLASSIFICATION,//  MY_ENUM_STRUCT_MAP 
Hive,WITHOUT_CLASSIFICATION,//  verify NULL output in entry 0 is correct 
Hive,WITHOUT_CLASSIFICATION,//  For a given table and its bucket full file path list   only keep the base file name (remove file path etc).   And put the new list into the new mapping. 
Hive,WITHOUT_CLASSIFICATION,//  Get the "transactional_properties" tblproperties value 
Hive,WITHOUT_CLASSIFICATION,//  Insert overwrite on dynamic partition 
Hive,WITHOUT_CLASSIFICATION,//  Make sure get on a table with no key returns empty list 
Hive,WITHOUT_CLASSIFICATION,/*    * This operator is allowed after mapjoin. Eventually mapjoin hint should be done away with.   * But since bucketized mapjoin and sortmerge join depend on it completely. it is needed.   * Check the operators which are allowed after mapjoin.    */
Hive,WITHOUT_CLASSIFICATION,//  tokens 
Hive,WITHOUT_CLASSIFICATION,//  IDS 
Hive,WITHOUT_CLASSIFICATION,//  construct dummy null row (indicating empty table) and   construct spill table serde which is used if input is too 
Hive,WITHOUT_CLASSIFICATION,//  The request has succeeded but we failed to add these partitions. 
Hive,WITHOUT_CLASSIFICATION,//  Don't move this code to the parent class. There's a binary   incompatibility between hadoop 1 and 2 wrt MiniDFSCluster and we   need to have two different shim classes even though they are 
Hive,WITHOUT_CLASSIFICATION,//  process   a   sync entry   minus SYNC_ESCAPE's length   read syncCheck 
Hive,WITHOUT_CLASSIFICATION,//  Add jars that are already in the tmpjars variable 
Hive,WITHOUT_CLASSIFICATION,//  2 running. 
Hive,WITHOUT_CLASSIFICATION,/*  2. doesn't have all skewed values within its data  */
Hive,WITHOUT_CLASSIFICATION,//  We only accept a struct which means that we're already nested one level deep 
Hive,WITHOUT_CLASSIFICATION,//  treat all inputs as string the return value will be converted to the appropriate type. 
Hive,WITHOUT_CLASSIFICATION,//  10000000. 
Hive,WITHOUT_CLASSIFICATION,//  script operator is a black-box to hive so no optimization here   assuming that nothing can be pushed above the script op   same with LIMIT op   create a filter with all children predicates 
Hive,WITHOUT_CLASSIFICATION,//  DEVENAGARI LETTER KA U+0915 (3 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  handle null on both sizes (not repeating) 
Hive,WITHOUT_CLASSIFICATION,//  Read paths from each symlink file. 
Hive,WITHOUT_CLASSIFICATION,/*           * Change the current thread name to include parent thread Id if it is executed          * in thread pool. Useful to extract logs specific to a job request and helpful          * to debug job issues.           */
Hive,WITHOUT_CLASSIFICATION,//  Get the total available memory from memory manager 
Hive,WITHOUT_CLASSIFICATION,//  Pre-fill the pool halfway. 
Hive,WITHOUT_CLASSIFICATION,//  ready to start execution on the cluster 
Hive,WITHOUT_CLASSIFICATION,//  The DPP sink has no target remove the subtree. 
Hive,WITHOUT_CLASSIFICATION,//  first hash is used to locate start of the block (blockBaseOffset)   subsequent K hashes are used to generate K bits within a block of words   To avoid branches during probe a separate masks array is used for each longs/words within a block. 
Hive,WITHOUT_CLASSIFICATION,//  Populate list of exclusive splits for every sampled alias 
Hive,WITHOUT_CLASSIFICATION,//  The expression can be any one of Double Long and Integer. We   try to parse the expression in that order to ensure that the   most specific type is used for conversion. 
Hive,WITHOUT_CLASSIFICATION,//  Close files 
Hive,WITHOUT_CLASSIFICATION,//  Update the topOps appropriately 
Hive,WITHOUT_CLASSIFICATION,//  Retrieve generator 
Hive,WITHOUT_CLASSIFICATION,//  Make sure dbName and tblName are valid. 
Hive,WITHOUT_CLASSIFICATION,//  if read is not direct we do not need to check its autho. 
Hive,WITHOUT_CLASSIFICATION,//  this means we are hitting nested subquery so don't   need to go further 
Hive,WITHOUT_CLASSIFICATION,// so that we only allocate a writeId only if actually adding data   (vs. adding a partition w/o data) 
Hive,WITHOUT_CLASSIFICATION,//  modify the options to reflect the event instead of the base row 
Hive,WITHOUT_CLASSIFICATION,//  Remember to remove this when we're out of the loop   we can't do it in the loop or we'll get a concurrent modification exception. 
Hive,WITHOUT_CLASSIFICATION,//  Setup 
Hive,WITHOUT_CLASSIFICATION,//  if scalar query has aggregate and no windowing and no gby avoid adding sq_count_check 
Hive,WITHOUT_CLASSIFICATION,//  {Big Value Len} {Big Value Bytes} 
Hive,WITHOUT_CLASSIFICATION,//  unprocessed role: get its parents add it to processed and call this   function recursively 
Hive,WITHOUT_CLASSIFICATION,//  returns a map<bucketNum list<record> > 
Hive,WITHOUT_CLASSIFICATION,//  Swap to get reference on the left side 
Hive,WITHOUT_CLASSIFICATION,//  There's no point adding a task with forceLocality set - since that will never exit the queue.   Add other tasks if they are not already in the queue. 
Hive,WITHOUT_CLASSIFICATION,//  used to indicate the input is sorted and so a BinarySearchRecordReader shoudl be used 
Hive,WITHOUT_CLASSIFICATION,//  lastInputPath should be changed by the root of the operator tree ExecMapper.map() 
Hive,WITHOUT_CLASSIFICATION,//  if there isn't already a session name go ahead and create it. 
Hive,WITHOUT_CLASSIFICATION,//  ASIA_INDIA 
Hive,WITHOUT_CLASSIFICATION,// subqueries will need outer query's row resolver 
Hive,WITHOUT_CLASSIFICATION,//  Test that 2 separate tables don't coalesce. 
Hive,WITHOUT_CLASSIFICATION,/*  allowVoidProjection  */
Hive,WITHOUT_CLASSIFICATION,//  only release the related resources ctx driverContext as normal 
Hive,WITHOUT_CLASSIFICATION,// This can happen as we are querying the getFunctions before we are getting the actual function  in between there can be a drop function by a user in which case our call will fail. 
Hive,WITHOUT_CLASSIFICATION,//  Iterate over partition columns to figure out partition name 
Hive,WITHOUT_CLASSIFICATION,//  Set two dummy classes as authorizatin managers. Two instances should get created. 
Hive,WITHOUT_CLASSIFICATION,//  Invalid if table is partitioned but endPoint's partitionVals is empty 
Hive,WITHOUT_CLASSIFICATION,//  a reader schema was provided 
Hive,WITHOUT_CLASSIFICATION,//  rename 
Hive,WITHOUT_CLASSIFICATION,/* newline */
Hive,WITHOUT_CLASSIFICATION,//  Empty new database name 
Hive,WITHOUT_CLASSIFICATION,//  The caller remembers the small value length. 
Hive,WITHOUT_CLASSIFICATION,//  set internal input format for all partition descriptors 
Hive,WITHOUT_CLASSIFICATION,//  Comparison to null will always return false 
Hive,WITHOUT_CLASSIFICATION,//  With multiple users concurrently issuing insert statements on the same partition has   a side effect that some queries may not see a partition at the time when they're issued   but will realize the partition is actually there when it is trying to add such partition   to the metastore and thus get AlreadyExistsException because some earlier query just created it (race condition).   For example imagine such a table is created:    create table T (name char(50)) partitioned by (ds string);   and the following two queries are launched at the same time from different sessions:    insert into table T partition (ds) values ('Bob' 'today'); -- creates the partition 'today'    insert into table T partition (ds) values ('Joe' 'today'); -- will fail with AlreadyExistsException   In that case we want to retry with alterPartition. 
Hive,WITHOUT_CLASSIFICATION,//  In replication if source file does not exist try cmroot 
Hive,WITHOUT_CLASSIFICATION,//  Now we have a complete statement process it   write the line to buffer 
Hive,WITHOUT_CLASSIFICATION,//  UNDONE: more! 
Hive,WITHOUT_CLASSIFICATION,//  create the MapJoinOperator 
Hive,WITHOUT_CLASSIFICATION,//  IF conditional expression 
Hive,WITHOUT_CLASSIFICATION,//  for a better insertion performance values are added to temporary unsorted   list which will be merged to sparse map after a threshold 
Hive,WITHOUT_CLASSIFICATION,//  spot check 
Hive,WITHOUT_CLASSIFICATION,//  JDBC says that 0 means return all which is the default 
Hive,WITHOUT_CLASSIFICATION,//  Validate the row values 
Hive,WITHOUT_CLASSIFICATION,//  ID 5 has been committed all others open 
Hive,WITHOUT_CLASSIFICATION,//  Drop table ignore error. 
Hive,WITHOUT_CLASSIFICATION,//  create a mocked metastore client that returns 3 table objects every time it is called   will use same size for TableIterable batch fetch size 
Hive,WITHOUT_CLASSIFICATION,//  rows forwarded will be received by ListSinkOperator which is replacing FS 
Hive,WITHOUT_CLASSIFICATION,//  1 Ensure columnNames are unique - CALCITE-411 
Hive,WITHOUT_CLASSIFICATION,//  unregister functions from local system registry that are not in getAllFunctions() 
Hive,WITHOUT_CLASSIFICATION,//  delete all the objects created 
Hive,WITHOUT_CLASSIFICATION,// todo: side note on the above: LockRequestBuilder combines the both default@acidtblpart entries to 1 
Hive,WITHOUT_CLASSIFICATION,//  Enums are one of two types we fudge for Hive. Enums go in Strings come out. 
Hive,WITHOUT_CLASSIFICATION,//  Struct 
Hive,WITHOUT_CLASSIFICATION,//  Get the sizes from the key buffer and aggregate 
Hive,WITHOUT_CLASSIFICATION,//  Use UpdateFragmentResponseProto.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,//  Update buffer 
Hive,WITHOUT_CLASSIFICATION,// map-side join aliases 
Hive,WITHOUT_CLASSIFICATION,//  Copy the text 
Hive,WITHOUT_CLASSIFICATION,//  some small alias is not known or too big 
Hive,WITHOUT_CLASSIFICATION,/*  * Adapts an Arrow batch reader to a row reader  */
Hive,WITHOUT_CLASSIFICATION,//  1 ptf invocation may entail multiple PTF operators) 
Hive,WITHOUT_CLASSIFICATION,//  option to bypass task cleanup task was introduced in hadoop-23 (MAPREDUCE-2206) 
Hive,WITHOUT_CLASSIFICATION,//  output positions. 
Hive,WITHOUT_CLASSIFICATION,//  This was the only predicate set filter expression to null 
Hive,WITHOUT_CLASSIFICATION,//  TCTLSeparatedProtocol is not done yet. 
Hive,WITHOUT_CLASSIFICATION,//  Finally verify the key bytes match. 
Hive,WITHOUT_CLASSIFICATION,//  optional   optional   optional   optional   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  For binary join firstSmallTable is the only small table; it has reference to spilled big   table rows;   For n-way join since we only spill once when processing the first small table so only the   firstSmallTable has reference to the spilled big table rows. 
Hive,WITHOUT_CLASSIFICATION,//  PartitionPruner may create more folding opportunities run ConstantPropagate again. 
Hive,WITHOUT_CLASSIFICATION,//  Will swap in the Vectors from underlying row batch. 
Hive,WITHOUT_CLASSIFICATION,//  ==== Hive command operation types starts here ==== // 
Hive,WITHOUT_CLASSIFICATION,//  We need to know if it is CTE or not.   A CTE may have the same name as a table.   For example   with select TAB1 [masking] as TAB2   select * from TAB2 [no masking] 
Hive,WITHOUT_CLASSIFICATION,//     them as they come back from restarts. 
Hive,WITHOUT_CLASSIFICATION,/*    * The abstract context for the 3 kinds of vectorized reading.    */
Hive,WITHOUT_CLASSIFICATION,//  We need the size above to take effect. 
Hive,WITHOUT_CLASSIFICATION,/*        * if the current table function has no partition info specified: inherit it from the PTF up       * the chain.        */
Hive,WITHOUT_CLASSIFICATION,//  When split-update is enabled we do not need to account for buckets that aren't covered.   This is a huge performance benefit of split-update. And the reason why we are able to   do so is because the 'deltas' here are actually only the delete_deltas. All the insert_deltas   with valid user payload data has already been considered as base for the covered buckets. 
Hive,WITHOUT_CLASSIFICATION,//  SEMI_SHARED can share with SHARED but not with itself 
Hive,WITHOUT_CLASSIFICATION,//  allow anything. 
Hive,WITHOUT_CLASSIFICATION,//  attempt made to save partition values in non-partitioned table - throw error. 
Hive,WITHOUT_CLASSIFICATION,//  2. We merge IN expressions 
Hive,WITHOUT_CLASSIFICATION,//  If the user is explicitly importing a new external table clear txn flags from the spec. 
Hive,WITHOUT_CLASSIFICATION,//  ceil(numSplits / numPaths) so we can get at least numSplits splits. 
Hive,WITHOUT_CLASSIFICATION,//  We do not vectorize MR Reduce. 
Hive,WITHOUT_CLASSIFICATION,//  #4 - We apply the granularity function 
Hive,WITHOUT_CLASSIFICATION,//  SOURCE_TABLE_NAME 
Hive,WITHOUT_CLASSIFICATION,//  Check if number of distinct keys is greater than given max number of entries 
Hive,WITHOUT_CLASSIFICATION,//  We can wrap inputs if the execution is vectorized or if we use a wrapper. 
Hive,WITHOUT_CLASSIFICATION,//  Ascending 
Hive,WITHOUT_CLASSIFICATION,/*  Maximum value seen so far  */
Hive,WITHOUT_CLASSIFICATION,//  all external file systems 
Hive,WITHOUT_CLASSIFICATION,//  ANALYZE TABLE 
Hive,WITHOUT_CLASSIFICATION,//  Rule cannot be applied if there are GroupingSets 
Hive,WITHOUT_CLASSIFICATION,//  original read block 
Hive,WITHOUT_CLASSIFICATION,// since set autocommit starts an implicit txn close it 
Hive,WITHOUT_CLASSIFICATION,//  Wipe out partition columns 
Hive,WITHOUT_CLASSIFICATION,// make sure we get the right data back before/after compactions 
Hive,WITHOUT_CLASSIFICATION,//  No ACID in code path -- set ROW__ID to NULL. 
Hive,WITHOUT_CLASSIFICATION,//  Inadequate total resources - will never succeed / wait for new executors to become available 
Hive,WITHOUT_CLASSIFICATION,//  Does the same thing as getFunctionInfo except for getting the function info. 
Hive,WITHOUT_CLASSIFICATION,//  FileMetadata 
Hive,WITHOUT_CLASSIFICATION,//  When the same node goes away and comes back... the old entry will be lost - which means   we don't know how many fragments we have actually scheduled on this node. 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) Start  */
Hive,WITHOUT_CLASSIFICATION,//  fallback to old mechanism which serves SMB Joins. 
Hive,WITHOUT_CLASSIFICATION,//  Expected to fail due to old schema 
Hive,WITHOUT_CLASSIFICATION,//  Run an hcat expression and return just the json outout.  No 
Hive,WITHOUT_CLASSIFICATION,//  null means the method does not accept number of arguments passed. 
Hive,WITHOUT_CLASSIFICATION,//  miss in locality request try picking consistent location with fallback to random selection 
Hive,WITHOUT_CLASSIFICATION,//  In case of success trigger a scheduling run for pending tasks. 
Hive,WITHOUT_CLASSIFICATION,//  Double the size of the array if needed 
Hive,WITHOUT_CLASSIFICATION,//  combine splits only from same tables and same partitions. Do not combine splits from multiple   tables or multiple partitions. 
Hive,WITHOUT_CLASSIFICATION,//  order in which the results should   be output 
Hive,WITHOUT_CLASSIFICATION,//  Generic settings 
Hive,WITHOUT_CLASSIFICATION,//  Now flush/forward all keys/rows except the last (current) one 
Hive,WITHOUT_CLASSIFICATION,//  Returns true if columns could be inferred false otherwise 
Hive,WITHOUT_CLASSIFICATION,//  slightly different depending on where the test is run specifically due to file size estimation 
Hive,WITHOUT_CLASSIFICATION,//  dynamic partitions 
Hive,WITHOUT_CLASSIFICATION,//  Merge the files in the destination table/partitions by creating Map-only merge job   If underlying data is RCFile a RCFileBlockMerge task would be created. 
Hive,WITHOUT_CLASSIFICATION,//  Shutdown Metrics 
Hive,WITHOUT_CLASSIFICATION,//  flag for no scan during analyze ... compute statistics 
Hive,WITHOUT_CLASSIFICATION,//  LLAP not enabled no-op. 
Hive,WITHOUT_CLASSIFICATION,//  This assumes that Grouping will always be used. 
Hive,WITHOUT_CLASSIFICATION,//  Note that hive does not support UDFToDouble etc in the query text. 
Hive,WITHOUT_CLASSIFICATION,// ************************************************************************************************   Decimal Multiply. 
Hive,WITHOUT_CLASSIFICATION,//  HOSTNAME 
Hive,WITHOUT_CLASSIFICATION,//  Remove the resource plan - disable WM. All the queries die. 
Hive,WITHOUT_CLASSIFICATION,//  we should have been able to reach the union from only one side. 
Hive,WITHOUT_CLASSIFICATION,//  Call super VectorMapJoinOuterFilteredOperator which calls super MapJoinOperator with 
Hive,WITHOUT_CLASSIFICATION,//  Set the semijoin hints in parse context 
Hive,WITHOUT_CLASSIFICATION,/*      * Strip off leading blanks and check for a sign.      */
Hive,WITHOUT_CLASSIFICATION,//  Hits misses tracked for a candidate node 
Hive,WITHOUT_CLASSIFICATION,//  best effort 
Hive,WITHOUT_CLASSIFICATION,//  Parse out the context and make sure it isn't empty 
Hive,WITHOUT_CLASSIFICATION,//  create table like <tbl_name> 
Hive,WITHOUT_CLASSIFICATION,//  Add the input 'newInput' to the set of inputs for the query.   The input may or may not be already present.   The ReadEntity also contains the parents from it is derived (only populated   in case of views). The equals method for ReadEntity does not compare the parents   so that the same input with different parents cannot be added twice. If the input   is already present make sure the parents are added.   Consider the query:   select * from (select * from V2 union all select * from V3) subq;   where both V2 and V3 depend on V1 (eg V2 : select * from V1 V3: select * from V1)   addInput would be called twice for V1 (one with parent V2 and the other with parent V3).   When addInput is called for the first time for V1 V1 (parent V2) is added to inputs.   When addInput is called for the second time for V1 the input V1 from inputs is picked up   and it's parents are enhanced to include V2 and V3   The inputs will contain: (V2 no parent) (V3 no parent) (V1 parents(V2 v3))     If the ReadEntity is already present and another ReadEntity with same name is   added then the isDirect flag is updated to be the OR of values of both. 
Hive,WITHOUT_CLASSIFICATION,//  bounded by max executors 
Hive,WITHOUT_CLASSIFICATION,// for Insert Overwrite 
Hive,WITHOUT_CLASSIFICATION,//  find first operator upstream with valid (non-null) column expression map 
Hive,WITHOUT_CLASSIFICATION,//  execute session hooks 
Hive,WITHOUT_CLASSIFICATION,//  If getNameToSplitSample is not empty at least one of the source   tables is being sampled and we can not optimize. 
Hive,WITHOUT_CLASSIFICATION,//  For the children we populate the NewToOldExprMap to keep track of   the original condition before rewriting it for this operator 
Hive,WITHOUT_CLASSIFICATION,//  cost must be positive so nudge it 
Hive,WITHOUT_CLASSIFICATION,//  BitSet for flagging aborted write ids. Bit is true if aborted false if open  default value means there are no open write ids in the snapshot 
Hive,WITHOUT_CLASSIFICATION,// exercise a broad range of timestamps close to the present. 
Hive,WITHOUT_CLASSIFICATION,//  2. Is this distinct UDAF 
Hive,WITHOUT_CLASSIFICATION,//  Not an analyze table column compute statistics statement - don't do any rewrites 
Hive,WITHOUT_CLASSIFICATION,//  So make sure that argLists is of size one. 
Hive,WITHOUT_CLASSIFICATION,/*    * Convert mapjoin to a bucketed mapjoin.   * The operator tree is not changed but the mapjoin descriptor in the big table is   * enhanced to keep the big table bucket -> small table buckets mapping.    */
Hive,WITHOUT_CLASSIFICATION,//  Factor includes scale. 
Hive,WITHOUT_CLASSIFICATION,//  Roughly based on BigInteger code. 
Hive,WITHOUT_CLASSIFICATION,//  What is the ColumnVector type of the aggregation result? 
Hive,WITHOUT_CLASSIFICATION,// Need to make sure that we are using segment identifier 
Hive,WITHOUT_CLASSIFICATION,// do not authorize temporary uris 
Hive,WITHOUT_CLASSIFICATION,/*    * Common generate join results from hash maps used by Inner and Outer joins.    */
Hive,WITHOUT_CLASSIFICATION,//  whose constructor would not have been called 
Hive,WITHOUT_CLASSIFICATION,/*          * Get our Multi-Key hash set information for this specialized class.          */
Hive,WITHOUT_CLASSIFICATION,//  Create the Select Operator 
Hive,WITHOUT_CLASSIFICATION,//  'select count(key) from T' as far as the reducer is concerned. 
Hive,WITHOUT_CLASSIFICATION,//  In the states where a background operation is in progress wait for the callback.   Also ignore any duplicate calls; also don't kill failed ones - handled elsewhere. 
Hive,WITHOUT_CLASSIFICATION,//  No status change for active resource plan first activate another plan. 
Hive,WITHOUT_CLASSIFICATION,//  Return false if categories are not equal 
Hive,WITHOUT_CLASSIFICATION,//  RCFile supports a configurable SerDe 
Hive,WITHOUT_CLASSIFICATION,//  this tests the case where older data has an ambiguous list and is not   named indicating that the source considered the group significant 
Hive,WITHOUT_CLASSIFICATION,//  The mapJoinTaskFileSinkOperator writes to a different directory 
Hive,WITHOUT_CLASSIFICATION,//  NumHashFunctions (1 byte) + bitset array length (4 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  packing into a vertex typically a table scan union or join 
Hive,WITHOUT_CLASSIFICATION,/*        * We will get "regular" single rows from the Input File Format reader that we will need       * to {vector|row} deserialize.        */
Hive,WITHOUT_CLASSIFICATION,//  PARAMETERS 
Hive,WITHOUT_CLASSIFICATION,//  CAN_EVOLVE 
Hive,WITHOUT_CLASSIFICATION,//  clear parameters in last-invoke 
Hive,WITHOUT_CLASSIFICATION,//  This should go fine since header should be less than the configured header size 
Hive,WITHOUT_CLASSIFICATION,//  since we are walking backwards seek back a buffer width so that   we load the previous buffer of rows 
Hive,WITHOUT_CLASSIFICATION,//  Test string "0" 
Hive,WITHOUT_CLASSIFICATION,//  batch already in memory anyway so we will bypass the memory checks. 
Hive,WITHOUT_CLASSIFICATION,//  Verify the content of subdirs 
Hive,WITHOUT_CLASSIFICATION,//  True if we are running test and the extra test file should be used when the logs are 
Hive,WITHOUT_CLASSIFICATION,//  and set the pattern and excludeMatches accordingly. 
Hive,WITHOUT_CLASSIFICATION,//  Create ORC file with small stripe size so we can write multiple stripes. 
Hive,WITHOUT_CLASSIFICATION,//  Without Data 
Hive,WITHOUT_CLASSIFICATION,//  ABORTED 
Hive,WITHOUT_CLASSIFICATION,//  This relies heavily on what method determineSplits ... calls and doesn't. 
Hive,WITHOUT_CLASSIFICATION,//  Add to metastore 
Hive,WITHOUT_CLASSIFICATION,//  Got an error might be there anyway due to a   permissions problem. 
Hive,WITHOUT_CLASSIFICATION,//  Get the first live service instance 
Hive,WITHOUT_CLASSIFICATION,//  @formatter:on 
Hive,WITHOUT_CLASSIFICATION,//  Convert input row to standard objects. 
Hive,WITHOUT_CLASSIFICATION,//  If they are both types of strings that should be fine 
Hive,WITHOUT_CLASSIFICATION,//  Consider generating a column group equal value series? 
Hive,WITHOUT_CLASSIFICATION,//  equivalent works must have dpp lists of same size 
Hive,WITHOUT_CLASSIFICATION,//  Only the IO threads need this so there'd be at most few dozen objects. 
Hive,WITHOUT_CLASSIFICATION,// this should error at analyze scope 
Hive,WITHOUT_CLASSIFICATION,//  Va Syllable MEE U+A521 (3 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  Figure out if there are any currently running compactions on the same table or partition. 
Hive,WITHOUT_CLASSIFICATION,//  Nothing to close here. 
Hive,WITHOUT_CLASSIFICATION,//  add the merge MR job 
Hive,WITHOUT_CLASSIFICATION,//  Create Select Operator 
Hive,WITHOUT_CLASSIFICATION,//  No nulls case not repeating 
Hive,WITHOUT_CLASSIFICATION,//  The reason we poll here is that a blocking queue causes the query thread to spend   non-trivial amount of time signaling when an element is added; we'd rather that the   time was wasted on this background thread. 
Hive,WITHOUT_CLASSIFICATION,//  length of each value in the map. 
Hive,WITHOUT_CLASSIFICATION,//  Writes the TimestampTZ's serialized value to the internal byte array. 
Hive,WITHOUT_CLASSIFICATION,//  verify the config 
Hive,WITHOUT_CLASSIFICATION,//  Last singleton or range? 
Hive,WITHOUT_CLASSIFICATION,//  This table has not been modified since materialization was created   nothing to do 
Hive,WITHOUT_CLASSIFICATION,// In DbTxnManager.acquireLocks() we have   2 ReadEntity: [default@acidtblpart@p=p1 default@acidtblpart] 
Hive,WITHOUT_CLASSIFICATION,//  Current buffer size should be larger than initial size 
Hive,WITHOUT_CLASSIFICATION,//  The group by keys and distinct keys should be the same for all dests so using the first 
Hive,WITHOUT_CLASSIFICATION,//  can't get any info without a plan 
Hive,WITHOUT_CLASSIFICATION,//  supposed dump path does not exist. 
Hive,WITHOUT_CLASSIFICATION,/*  Returns true if it passes the test false otherwise.  */
Hive,WITHOUT_CLASSIFICATION,//  Get cost of the subset best rel may have been chosen or not 
Hive,WITHOUT_CLASSIFICATION,//  If the txnid is 0 then there are no transactions in this heartbeat 
Hive,WITHOUT_CLASSIFICATION,//  Is this the first keyValueSeparator in this entry? 
Hive,WITHOUT_CLASSIFICATION,//  For fields in descending order do a bit flip first. 
Hive,WITHOUT_CLASSIFICATION,//  returns non-null FetchTask instance when succeeded 
Hive,WITHOUT_CLASSIFICATION,//  reported once so break 
Hive,WITHOUT_CLASSIFICATION,//  Make a Connection object that will throw an exception 
Hive,WITHOUT_CLASSIFICATION,//  Bucket MapJoin in LLAP 
Hive,WITHOUT_CLASSIFICATION,//  invariant: p > hll.p 
Hive,WITHOUT_CLASSIFICATION,//  Sort-merge join 
Hive,WITHOUT_CLASSIFICATION,//  We have evicted the entire list. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setNCharacterStream(int java.io.Reader)    */
Hive,WITHOUT_CLASSIFICATION,//  Prepare data for Client Stat Publishers (if any present) and execute them 
Hive,WITHOUT_CLASSIFICATION,//  extract the correlation out of the filter 
Hive,WITHOUT_CLASSIFICATION,//  If multiple rules can be matched with same cost last rule will be choosen as a processor 
Hive,WITHOUT_CLASSIFICATION,//  localize hive-exec.jar as well. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure for existing destination we return false as per FileSystem api contract 
Hive,WITHOUT_CLASSIFICATION,//  A runtime that launches runnable tasks as separate Threads through   TaskRunners   As soon as a task isRunnable it is put in a queue   At any time at most maxthreads tasks can be running   The main thread polls the TaskRunners to check if they have finished. 
Hive,WITHOUT_CLASSIFICATION,//  for BETWEEN clause 
Hive,WITHOUT_CLASSIFICATION,//  Read configuration parameters 
Hive,WITHOUT_CLASSIFICATION,//  Update sum of the length of the values seen so far 
Hive,WITHOUT_CLASSIFICATION,//  No need to add not null filter for a constant. 
Hive,WITHOUT_CLASSIFICATION,//  Step1: rename tmp output folder to intermediate path. After this   point updates from speculative tasks still writing to tmpPath   will not appear in finalPath. 
Hive,WITHOUT_CLASSIFICATION,//  Some existing chunk Find max 
Hive,WITHOUT_CLASSIFICATION,// save some info for webUI for use after plan is freed 
Hive,WITHOUT_CLASSIFICATION,// now run as if it's a major Compaction so we collapse events 
Hive,WITHOUT_CLASSIFICATION,//  Now a duplicated field name.  Should fail 
Hive,WITHOUT_CLASSIFICATION,//  (num of distinct vals for col in IN clause  / num of distinct vals for col ) 
Hive,WITHOUT_CLASSIFICATION,/*      * Do careful maintenance of NULLs.      */
Hive,WITHOUT_CLASSIFICATION,//  If grant option specified only update the privilege don't remove it.   Grant option has already been removed from the privileges in the section above 
Hive,WITHOUT_CLASSIFICATION,//  via a hint. 
Hive,WITHOUT_CLASSIFICATION,//  MAX_PARTS 
Hive,WITHOUT_CLASSIFICATION,/*      * after a lead and lag call allow Object associated with SerDe and writable associated with     * partition to be reset     * to the value for the current Index.      */
Hive,WITHOUT_CLASSIFICATION,//  the element type is not a tuple - so no subschema 
Hive,WITHOUT_CLASSIFICATION,//  Text 
Hive,WITHOUT_CLASSIFICATION,//  First value is repeated for all batches. 
Hive,WITHOUT_CLASSIFICATION,//  end of digits 
Hive,WITHOUT_CLASSIFICATION,//  JobClose has already been performed on this operator 
Hive,WITHOUT_CLASSIFICATION,//  Simulate renaming via another metastore Thrift server or another Hive CLI instance 
Hive,WITHOUT_CLASSIFICATION,//  Data structures specific for vectorized operators. 
Hive,WITHOUT_CLASSIFICATION,//  call. 
Hive,WITHOUT_CLASSIFICATION,//  VARCHAR BETWEEN 
Hive,WITHOUT_CLASSIFICATION,//  the client to direct all calls to a catalog that does not yet exist. 
Hive,WITHOUT_CLASSIFICATION,//  Copy into the current union task plan if 
Hive,WITHOUT_CLASSIFICATION,//  We could do a wrapper with only size() and get() methods instead of List to be sure. 
Hive,WITHOUT_CLASSIFICATION,//  Create function desc 
Hive,WITHOUT_CLASSIFICATION,//  for non-singular args count can include null i.e. () is counted as 1 
Hive,WITHOUT_CLASSIFICATION,//  get buffer size and stripe size for base writer 
Hive,WITHOUT_CLASSIFICATION,//  start_date is Sat 3 letters day name 
Hive,WITHOUT_CLASSIFICATION,//  For now keep the old logic for non-MM non-DP union case. Should probably be unified. 
Hive,WITHOUT_CLASSIFICATION,//  check for number of created files 
Hive,WITHOUT_CLASSIFICATION,//  these are from ColumnPrunerSelectProc 
Hive,WITHOUT_CLASSIFICATION,//  DataNucleus wants us to auto-create but we shall do no such thing. 
Hive,WITHOUT_CLASSIFICATION,//  Caller will set signum. 
Hive,WITHOUT_CLASSIFICATION,//  Reset the iter to start. 
Hive,WITHOUT_CLASSIFICATION,//  columns and originalRR is the original generated select 
Hive,WITHOUT_CLASSIFICATION,//  TODO: Should be checked on server side. On Embedded metastore it throws MetaException   on Remote metastore it throws TTransportException 
Hive,WITHOUT_CLASSIFICATION,//  max ndv across all column references from both sides of table 
Hive,WITHOUT_CLASSIFICATION,//  trailing spaces are not significant 
Hive,WITHOUT_CLASSIFICATION,//  The leaves could be shared in the tree. Use Set to remove the duplicates. 
Hive,WITHOUT_CLASSIFICATION,//  Source directory is specified so treat the target as a directory  
Hive,WITHOUT_CLASSIFICATION,//  top of the operator tree this could also reduce the amount of data going to the reducer 
Hive,WITHOUT_CLASSIFICATION,//  The children are input. 
Hive,WITHOUT_CLASSIFICATION,//  done with this operator 
Hive,WITHOUT_CLASSIFICATION,//  This is also used for MM table conversion. 
Hive,WITHOUT_CLASSIFICATION,//  Tests for the Partition exchange_partition(Map<String String> partitionSpecs String   sourceDb String sourceTable String destdb String destTableName) method 
Hive,WITHOUT_CLASSIFICATION,//  Set some conf vars 
Hive,WITHOUT_CLASSIFICATION,//  mapping of the fieldid to the field 
Hive,WITHOUT_CLASSIFICATION,//  For views the entities can be nested - by default entities are at the top level 
Hive,WITHOUT_CLASSIFICATION,//  multi-GBY single-RS (TODO) 
Hive,WITHOUT_CLASSIFICATION,//  Bogus encoding. 
Hive,WITHOUT_CLASSIFICATION,//  Initialize with 0 for non-ACID and non-MM tables. 
Hive,WITHOUT_CLASSIFICATION,//  clone postJoinFilters 
Hive,WITHOUT_CLASSIFICATION,// shouldn't be any others 
Hive,WITHOUT_CLASSIFICATION,//  These are the filters which are common for every QTest. 
Hive,WITHOUT_CLASSIFICATION,//  Tasks can exist in the delayed queue even after they have been scheduled.   Trigger scheduling only if the task is still in PENDING state. 
Hive,WITHOUT_CLASSIFICATION,//  Starting from the startNodes add the children whose parents have been   included in the list. 
Hive,WITHOUT_CLASSIFICATION,//  PARTS_FOUND 
Hive,WITHOUT_CLASSIFICATION,//  Test adding a constraint 
Hive,WITHOUT_CLASSIFICATION,//  Print the value 
Hive,WITHOUT_CLASSIFICATION,//  Execute "set" command and retrieve values for the conf & vars specified above 
Hive,WITHOUT_CLASSIFICATION,//  Don't reset anything we are reusing column vectors. 
Hive,WITHOUT_CLASSIFICATION,//  Provide an instance of the code doesn't try to make a real Instance   We just want to test that we fail before trying to make a connector   with null username 
Hive,WITHOUT_CLASSIFICATION,//     specify them by the rules in {@link effectiveWindowFrame} 
Hive,WITHOUT_CLASSIFICATION,//  part of the big table portion of the join output result. 
Hive,WITHOUT_CLASSIFICATION,// Passing query spec column names and column types to be used as part of Hive Physical execution 
Hive,WITHOUT_CLASSIFICATION,//  process reduce sink added by hive.enforce.bucketing or hive.enforce.sorting 
Hive,WITHOUT_CLASSIFICATION,//  resultSchema will be null if   (1) cbo is disabled;   (2) or cbo is enabled with AST return path (whether succeeded or not   resultSchema will be re-initialized)   It will only be not null if cbo is enabled with new return path and it   succeeds. 
Hive,WITHOUT_CLASSIFICATION,//  After reading the batch reset the pointer to beginning. 
Hive,WITHOUT_CLASSIFICATION,//  Preserve existing return type behavior for division:   Non-decimal division should return double 
Hive,WITHOUT_CLASSIFICATION,//  Clusters (Buckets) 
Hive,WITHOUT_CLASSIFICATION,//  optional string am_host = 6; 
Hive,WITHOUT_CLASSIFICATION,//  be false and hence if db Not found we should error out. 
Hive,WITHOUT_CLASSIFICATION,//  DPHJ is disabled only attempt BMJ or mapjoin 
Hive,WITHOUT_CLASSIFICATION,//  test zero-divide to show it results in NULL 
Hive,WITHOUT_CLASSIFICATION,//  When DAG specific cleanup happens it'll be better to link this to a DAG though. 
Hive,WITHOUT_CLASSIFICATION,//  update should take place such as with replication. 
Hive,WITHOUT_CLASSIFICATION,//  check IF/OF/Serde 
Hive,WITHOUT_CLASSIFICATION,/*      * NOTE: We do not alter the projectedColumns / projectionSize of the batches to just be     * the included columns (+ partition columns).     *     * For now we need to model the object inspector rows because there are still several     * vectorized operators that use them.     *     * We need to continue to model the Object[] as having null objects for not included columns     * until the following has been fixed:     *    o When we have to output a STRUCT for AVG we switch to row GroupBy operators.     *    o Some variations of VectorMapOperator VectorReduceSinkOperator VectorFileSinkOperator     *      use the row super class to process rows.      */
Hive,WITHOUT_CLASSIFICATION,//  total size of each hash entry 
Hive,WITHOUT_CLASSIFICATION,//  requestLine 
Hive,WITHOUT_CLASSIFICATION,//  The current plan can be thrown away after being merged with the   original plan 
Hive,WITHOUT_CLASSIFICATION,//  Ensure this explicitly since versions before 2.7 read doesn't do it. 
Hive,WITHOUT_CLASSIFICATION,//  if external table and custom root specified update the parent path 
Hive,WITHOUT_CLASSIFICATION,//  Remove the DDL time so that it gets refreshed 
Hive,WITHOUT_CLASSIFICATION,//  Base name (varchar vs fully qualified name such as varchar(200)). 
Hive,WITHOUT_CLASSIFICATION,//  we are putting join keys at last part of the spilled table 
Hive,WITHOUT_CLASSIFICATION,//  If the table is bucketed on a partition column not valid for bucketing 
Hive,WITHOUT_CLASSIFICATION,//  Granularity column 
Hive,WITHOUT_CLASSIFICATION,//  hence need not allow if same event is applied twice. 
Hive,WITHOUT_CLASSIFICATION,//  validate the first parameter which is the expression to compute over 
Hive,WITHOUT_CLASSIFICATION,//  Decide default directory selection. 
Hive,WITHOUT_CLASSIFICATION,//  committed baseTxnId 
Hive,WITHOUT_CLASSIFICATION,//  Close the underlying stream if we own it... 
Hive,WITHOUT_CLASSIFICATION,//  Prior singleton or range? 
Hive,WITHOUT_CLASSIFICATION,//  instead of multiple times 
Hive,WITHOUT_CLASSIFICATION,//  Data columns. 
Hive,WITHOUT_CLASSIFICATION,//  Parameter 1 was an array of arrays so make sure that the inner arrays contain   primitive strings. 
Hive,WITHOUT_CLASSIFICATION,//  Byte.MAX_VALUE 
Hive,WITHOUT_CLASSIFICATION,//  We have selected a port as a client port.  Update clientPortList if necessary.   it is not in the list add the port 
Hive,WITHOUT_CLASSIFICATION,// Calendar.getInstance calculates the current-time needlessly so cache an instance. 
Hive,WITHOUT_CLASSIFICATION,//  Position of distinct column in aggregator list of map Gby before rewrite. 
Hive,WITHOUT_CLASSIFICATION,//  This can happen for truncate table case for non-MM tables. 
Hive,WITHOUT_CLASSIFICATION,//  Create a barrier task for dependency collection of import tasks 
Hive,WITHOUT_CLASSIFICATION,/*      * Gather up big and small table output result information from the MapJoinDesc.      */
Hive,WITHOUT_CLASSIFICATION,//  if bitpacking is disabled all register values takes 8 bits and hence   we can be more flexible with the threshold. For p=14 16K/5 = 3200   entries in sparse map can be allowed. 
Hive,WITHOUT_CLASSIFICATION,// if no other SD references this CD we can throw it out. 
Hive,WITHOUT_CLASSIFICATION,//  Copy the files out of the archive into the temporary directory 
Hive,WITHOUT_CLASSIFICATION,//  Unsupported types - error 
Hive,WITHOUT_CLASSIFICATION,//  Save to connectionMap so it can be closed at user's convenience. 
Hive,WITHOUT_CLASSIFICATION,//  TABLES 
Hive,WITHOUT_CLASSIFICATION,//  if the default was decided by the serde 
Hive,WITHOUT_CLASSIFICATION,/*   Here is the layout we expecttarget/tmp/org.apache.hadoop.hive.ql.TestTxnCommands-1521148657811/├── export│   ├── _metadata│   └── p=1│       ├── q=1│       │   └── 000002_0│       └── q=2│           └── 000001_0└── warehouse    ├── acidtbl    ├── acidtblpart    ├── nonacidnonbucket    ├── nonacidorctbl    ├── nonacidorctbl2    ├── t    │   ├── p=1    │   │   ├── q=1    │   │   │   └── delta_0000001_0000001_0000    │   │   │       ├── _orc_acid_version    │   │   │       └── bucket_00000    │   │   └── q=2    │   │       └── delta_0000001_0000001_0000    │   │           ├── _orc_acid_version    │   │           └── bucket_00000    │   └── p=2    │       └── q=2    │           └── delta_0000001_0000001_0000    │               ├── _orc_acid_version    │               └── bucket_00000    └── timport        └── p=1            ├── q=1            │   └── 000002_0            └── q=2                └── 000001_023 directories 11 files */
Hive,WITHOUT_CLASSIFICATION,//  This assumes all struct cols immediately follow struct 
Hive,WITHOUT_CLASSIFICATION,//  Analyze and create tbl properties object 
Hive,WITHOUT_CLASSIFICATION,//  Not needed without semi-join reduction 
Hive,WITHOUT_CLASSIFICATION,//  To know if we need to bail out 
Hive,WITHOUT_CLASSIFICATION,//  Create a http client with a retry mechanism when the server returns a status code of 401. 
Hive,WITHOUT_CLASSIFICATION,//  We only need to promote if comp.type is > existing.type.  For   efficiency we check if existing is exclusive (in which case we   need never promote) or if comp is exclusive or shared_write (in   which case we can promote even though they may both be shared   write).  If comp is shared_read there's never a need to promote. 
Hive,WITHOUT_CLASSIFICATION,// Since we cannot know what columns will be needed by a PTF chain  we do not prune columns on PTFOperator for PTF chains. 
Hive,WITHOUT_CLASSIFICATION,//  Copy limit 
Hive,WITHOUT_CLASSIFICATION,//  tolerance to check double equality 
Hive,WITHOUT_CLASSIFICATION,// set where derby logs 
Hive,WITHOUT_CLASSIFICATION,//  create a new table similar to previous one. 
Hive,WITHOUT_CLASSIFICATION,// didn't find any lock with extLockId but at ReadCommitted there is a possibility that  it existed when above delete ran but it didn't have the expected state. 
Hive,WITHOUT_CLASSIFICATION,//  set r.convertedParameters 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setCharacterStream(java.lang.String   * java.io.Reader)    */
Hive,WITHOUT_CLASSIFICATION,//  For cases where the table is external 
Hive,WITHOUT_CLASSIFICATION,//  as long as we add them to a list order is preserved from now on. 
Hive,WITHOUT_CLASSIFICATION,//  Oracle) doesn't exhibit this problem. 
Hive,WITHOUT_CLASSIFICATION,//  Compare timestamp to timestamp. 
Hive,WITHOUT_CLASSIFICATION,//  The bucketingVersion is not relevant here as it is never used.   For SMB we look at the parent tables' bucketing versions and for 
Hive,WITHOUT_CLASSIFICATION,//  Week granularity 
Hive,WITHOUT_CLASSIFICATION,//  Create the object inspector and the lazy binary struct object 
Hive,WITHOUT_CLASSIFICATION,//  check if oozie has set up a hcat deleg. token - if so use it 
Hive,WITHOUT_CLASSIFICATION,//  Move past separator. 
Hive,WITHOUT_CLASSIFICATION,//  as indicated by selectedInUse and the sel array. 
Hive,WITHOUT_CLASSIFICATION,//  will trigger cleanup 
Hive,WITHOUT_CLASSIFICATION,//  Simplify vector by brute-force flattening noNulls and isRepeating   This can be used to reduce combinatorial explosion of code paths in VectorExpressions 
Hive,WITHOUT_CLASSIFICATION,//  if we are on viewfs we don't want to use /tmp as tmp dir since rename from /tmp/..   to final /user/hive/warehouse/ will fail later so instead pick tmp dir   on same namespace as tbl dir. 
Hive,WITHOUT_CLASSIFICATION,//  Get the named url from user specific config file if present 
Hive,WITHOUT_CLASSIFICATION,//  Only used for testing. 
Hive,WITHOUT_CLASSIFICATION,//  cast(.... as string) 
Hive,WITHOUT_CLASSIFICATION,//  We do not filter when PTF is in reducer. 
Hive,WITHOUT_CLASSIFICATION,//  collection separator 
Hive,WITHOUT_CLASSIFICATION,//  If it is a case operator we need to rewrite it 
Hive,WITHOUT_CLASSIFICATION,//  Execute query in Druid 
Hive,WITHOUT_CLASSIFICATION,//  compute count only if the register values are updated else return the   cached count 
Hive,WITHOUT_CLASSIFICATION,// 6 partitions 
Hive,WITHOUT_CLASSIFICATION,//  Create a GSS context 
Hive,WITHOUT_CLASSIFICATION,//  0 1   1 0 
Hive,WITHOUT_CLASSIFICATION,//  check if table with the new name already exists 
Hive,WITHOUT_CLASSIFICATION,//  invoked for test classes 
Hive,WITHOUT_CLASSIFICATION,/*  * when adding support for new types we should try to use classes of Hive value system to keep  * things more readable (though functionally it should not make a difference).   */
Hive,WITHOUT_CLASSIFICATION,/*    * Maximum number of decimal digits in a decimal64 long.    */
Hive,WITHOUT_CLASSIFICATION,//  single-row case there's no next 
Hive,WITHOUT_CLASSIFICATION,//  prefix for column names auto generated by hive 
Hive,WITHOUT_CLASSIFICATION,//  Location is not set we utilize METASTOREWAREHOUSE together with database name 
Hive,WITHOUT_CLASSIFICATION,//  -1 when negative; 0 when decimal is zero; 1 when positive. 
Hive,WITHOUT_CLASSIFICATION,//  ANALYZE TABLE T [PARTITION (...)] COMPUTE STATISTICS;   The plan consists of a simple TezTask followed by a StatsTask.   The Tez task is just a simple TableScanOperator 
Hive,WITHOUT_CLASSIFICATION,//  execute statement with the conf overlay 
Hive,WITHOUT_CLASSIFICATION,//        that fractions or query parallelism add up etc. 
Hive,WITHOUT_CLASSIFICATION,//  whether we have to enforce sort anyway e.g. in case of RS deduplication 
Hive,WITHOUT_CLASSIFICATION,//  2 more variations of callbacks; increase + decrease and decrease + increase the 2nd call coming   before the message is sent; no message should ever be sent. 
Hive,WITHOUT_CLASSIFICATION,//  Using MetaStore running in an existing cluster 
Hive,WITHOUT_CLASSIFICATION,//  Test normal drop should drop unconditionally. 
Hive,WITHOUT_CLASSIFICATION,//  then groups (this is arbitrary). 
Hive,WITHOUT_CLASSIFICATION,//  Asserts the class invariant. (Same types.) 
Hive,WITHOUT_CLASSIFICATION,//  Test andFilter operation. 
Hive,WITHOUT_CLASSIFICATION,//  Where to write our key and value pairs. 
Hive,WITHOUT_CLASSIFICATION,//  Long.MAX_VALUE 
Hive,WITHOUT_CLASSIFICATION,//  will return back the original token (which we know is insufficient) 
Hive,WITHOUT_CLASSIFICATION,// covers both streaming api and post compaction style. 
Hive,WITHOUT_CLASSIFICATION,//  We will unset s on i=0 and t on i=1. Only these should be updated; and nothing for 2. 
Hive,WITHOUT_CLASSIFICATION,//  If any destination partition is present then throw a Semantic Exception. 
Hive,WITHOUT_CLASSIFICATION,//  Add only dynamic partition columns to the temp table (input data file). 
Hive,WITHOUT_CLASSIFICATION,//  This should fail 
Hive,WITHOUT_CLASSIFICATION,//  Sleep for 100ms 
Hive,WITHOUT_CLASSIFICATION,//  set now so we can verify it changed 
Hive,WITHOUT_CLASSIFICATION,//  Rare case of buffer boundary. Unfortunately we'd have to copy some bytes. 
Hive,WITHOUT_CLASSIFICATION,//  this is effectively the same as the dense register impl. 
Hive,WITHOUT_CLASSIFICATION,//  It sorts 
Hive,WITHOUT_CLASSIFICATION,//  Before the ownerType exists in an old Hive schema USER was the default type for owner.   Let's set the default to USER to keep backward compatibility. 
Hive,WITHOUT_CLASSIFICATION,//  Test the InputFormat execution path 
Hive,WITHOUT_CLASSIFICATION,//  Just fetch one blob if we've serialized thrift objects in final tasks 
Hive,WITHOUT_CLASSIFICATION,//  llap-common   llap-tez   llap-server   hive-exec   hive-common (https deps)   Jetty rewrite class   ZK registry 
Hive,WITHOUT_CLASSIFICATION,//  SELECT statement or dynamic SQL 
Hive,WITHOUT_CLASSIFICATION,//  timeout in 5 minutes 
Hive,WITHOUT_CLASSIFICATION,//  operator tree for processing row further (optional) 
Hive,WITHOUT_CLASSIFICATION,//  Test adding multiple partitions in a single partition-set atomically. 
Hive,WITHOUT_CLASSIFICATION,/*    * By default the list is empty - if an operator wants to add more counters   * it should override this method and provide the new list. Counter names returned   * by this method should be wrapped counter names (i.e the strings should be passed   * through getWrappedCounterName).    */
Hive,WITHOUT_CLASSIFICATION,//  add 10 partitions on the filesystem 
Hive,WITHOUT_CLASSIFICATION,// upload archive file to hdfs 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise we'd create a NullWritable and that isn't what we want. 
Hive,WITHOUT_CLASSIFICATION,//  We keep the hash multi-set result for its spill information. 
Hive,WITHOUT_CLASSIFICATION,//  Check if giving invalid address causes retry in connection attempt 
Hive,WITHOUT_CLASSIFICATION,//  tag 
Hive,WITHOUT_CLASSIFICATION,//  To remain consistent we need to set input and output formats both 
Hive,WITHOUT_CLASSIFICATION,// Start Metrics for Standalone (Remote) Mode 
Hive,WITHOUT_CLASSIFICATION,//  success only if all the commands were successful 
Hive,WITHOUT_CLASSIFICATION,//  Update max length if new length is greater than the ones seen so   far 
Hive,WITHOUT_CLASSIFICATION,//  Thread pool for actual execution of work. 
Hive,WITHOUT_CLASSIFICATION,//  Create join RR: we need to check whether we need to update left RR in case 
Hive,WITHOUT_CLASSIFICATION,//  parition column case.   partition filter will be evaluated by partition pruner so   we will not evaluate partition filter here. 
Hive,WITHOUT_CLASSIFICATION,//  Give it a LOT of slack since on low numbers consistent hashing is very imprecise. 
Hive,WITHOUT_CLASSIFICATION,//  6. Run aggregate-join transpose (cost based)      If it failed because of missing stats we continue with 
Hive,WITHOUT_CLASSIFICATION,//  Concurrent revocation and increase - before the message is sent. 
Hive,WITHOUT_CLASSIFICATION,//  LocalJobRunner does not work with mapreduce OutputCommitter. So need   to use MiniMRCluster. MAPREDUCE-2350 
Hive,WITHOUT_CLASSIFICATION,// 2 distinct partitions created  txnid+1 because we want txn used by previous driver.run("insert....) 
Hive,WITHOUT_CLASSIFICATION,/*      * STRING:     *   Range values empty strings.      */
Hive,WITHOUT_CLASSIFICATION,//  Call rename_partition without an environment context. 
Hive,WITHOUT_CLASSIFICATION,//  Run value expressions over original (whole) input batch. 
Hive,WITHOUT_CLASSIFICATION,// / CREATE TABLE scenarios 
Hive,WITHOUT_CLASSIFICATION,//  Nothing to do here. 
Hive,WITHOUT_CLASSIFICATION,//  remember the original parent list before we start modifying it. 
Hive,WITHOUT_CLASSIFICATION,//  Initialize the execution engine based on cluster type 
Hive,WITHOUT_CLASSIFICATION,//  Prefer numeric type arguments over other method signatures 
Hive,WITHOUT_CLASSIFICATION,//  Nearly C/P from OrcInputFormat; there are too many statics everywhere to sort this out. 
Hive,WITHOUT_CLASSIFICATION,//  assume the index is bad and do a full scan 
Hive,WITHOUT_CLASSIFICATION,//  batch size from input and decaying factor of 2 
Hive,WITHOUT_CLASSIFICATION,//  Indicates a type was derived from the deserializer rather than Hive's metadata. 
Hive,WITHOUT_CLASSIFICATION,//  ((R1.x=R2.x) and R1.z=10)) and rand(1) < 0.1 order by R1.x limit 10 
Hive,WITHOUT_CLASSIFICATION,//  find 10^37 
Hive,WITHOUT_CLASSIFICATION,//  only last 2 rows qualify 
Hive,WITHOUT_CLASSIFICATION,//  Delayed to find a local match 
Hive,WITHOUT_CLASSIFICATION,//  This check isn't absolutely mandatory given the aborted check outside of the 
Hive,WITHOUT_CLASSIFICATION,//  run a query in a loop so that we hit a 401 occasionally 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Wrapper#unwrap(java.lang.Class)    */
Hive,WITHOUT_CLASSIFICATION,//  Find the bucket id and switch buckets if need to 
Hive,WITHOUT_CLASSIFICATION,//  just return stats gathering should not block the main query. 
Hive,WITHOUT_CLASSIFICATION,//  create session test if the hook got fired by checking the expected property 
Hive,WITHOUT_CLASSIFICATION,//  sets the env variable HIVE_JOB_CREDSTORE_PASSWORD to value defined by 
Hive,WITHOUT_CLASSIFICATION,//  For Java serialization only 
Hive,WITHOUT_CLASSIFICATION,//  UNDONE   Assert.assertTrue(vectorizer.validateMapWorkOperator(map null false)); 
Hive,WITHOUT_CLASSIFICATION,//  Special case handling for Multi-OR and Multi-AND. 
Hive,WITHOUT_CLASSIFICATION,//  setup dynamic partition pruning where possible 
Hive,WITHOUT_CLASSIFICATION,//  need to add filter   create tableOp to be filterDesc and set as child to 'top' 
Hive,WITHOUT_CLASSIFICATION,//  Throwing InvalidObjectException would be more appropriate but we do not change the API 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#registerOutParameter(int int)    */
Hive,WITHOUT_CLASSIFICATION,//  Skip from block to block since we only need the header 
Hive,WITHOUT_CLASSIFICATION,//  filter operator has the same output columns as its parent 
Hive,WITHOUT_CLASSIFICATION,//  Calculate unselected ones in last evaluate. 
Hive,WITHOUT_CLASSIFICATION,//  will fail 
Hive,WITHOUT_CLASSIFICATION,//  Neither open nor opening. 
Hive,WITHOUT_CLASSIFICATION,//  authorize the revoke and get the set of privileges to be revoked 
Hive,WITHOUT_CLASSIFICATION,//  Nothing to do. No registration involved. 
Hive,WITHOUT_CLASSIFICATION,//  Serialize the keys and append the tag 
Hive,WITHOUT_CLASSIFICATION,//  add all UDTF columns 
Hive,WITHOUT_CLASSIFICATION,//  build the new list 
Hive,WITHOUT_CLASSIFICATION,//  Optimize plan 
Hive,WITHOUT_CLASSIFICATION,//  used for create mapJoinDesc should be in order 
Hive,WITHOUT_CLASSIFICATION,//  Handle NULL we return the type of pcA 
Hive,WITHOUT_CLASSIFICATION,// since we have no base there must be at least 1 delta which must a result of acid write  so it must be immediate child of the partition 
Hive,WITHOUT_CLASSIFICATION,//  dumpFile(INPUT_FILE_NAME); 
Hive,WITHOUT_CLASSIFICATION,//  <Parent Ops>-SEL-GB1-RS1-GB2-RS2 
Hive,WITHOUT_CLASSIFICATION,//  UNDONE: Don't reuse for now.   rowBytesContainer.resetWrite(); 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise value may be too long convert to appropriate value based on params 
Hive,WITHOUT_CLASSIFICATION,//  Reduce sink of group by operator 
Hive,WITHOUT_CLASSIFICATION,//  add user privileges 
Hive,WITHOUT_CLASSIFICATION,// check if 30 Julian Days between Jan 1 2005 and Jan 31 2005. 
Hive,WITHOUT_CLASSIFICATION,//  First row determines isGroupResultNull and long firstValue; stream fill result as repeated. 
Hive,WITHOUT_CLASSIFICATION,// to make insert into non-acid take shared lock 
Hive,WITHOUT_CLASSIFICATION,//  0 NULL   1 NULL 
Hive,WITHOUT_CLASSIFICATION,//  Handle NULL we return the type of pcB 
Hive,WITHOUT_CLASSIFICATION,//  Create a delete delta that has rowIds divisible by 2 but not by 3. This will produce 
Hive,WITHOUT_CLASSIFICATION,/*  mergeCount  */
Hive,WITHOUT_CLASSIFICATION,//  optional bytes initial_event_signature = 11; 
Hive,WITHOUT_CLASSIFICATION,// props = new Properties();  props.setProperty("fs.default.name" cluster.getProperties().getProperty("fs.default.name")); 
Hive,WITHOUT_CLASSIFICATION,//  DIRECT encoding 
Hive,WITHOUT_CLASSIFICATION,//  begin + write + abort 
Hive,WITHOUT_CLASSIFICATION,//  join with group-by having order-by 
Hive,WITHOUT_CLASSIFICATION,//  Try to deserialize using DeserializeRead our Writable row objects created by SerializeWrite. 
Hive,WITHOUT_CLASSIFICATION,//  must be called last 
Hive,WITHOUT_CLASSIFICATION,//  Get the last valid row in the batch still available. 
Hive,WITHOUT_CLASSIFICATION,//  type_name used to be tbl.getProperty(META_TABLE_NAME).   However now the value is DBName.TableName. To make it backward compatible   we take the TableName part as type_name.   
Hive,WITHOUT_CLASSIFICATION,//  set up the java key provider for encrypted hdfs cluster 
Hive,WITHOUT_CLASSIFICATION,//  Safeguard against potential issues in CBO RowResolver construction. Disable CBO for now. 
Hive,WITHOUT_CLASSIFICATION,//  Input #2 is type date (epochDays). 
Hive,WITHOUT_CLASSIFICATION,//  Execute 
Hive,WITHOUT_CLASSIFICATION,//     ve = vc.getVectorExpression(exprDesc);      assertTrue(ve instanceof IfExprCharScalarCharScalar); 
Hive,WITHOUT_CLASSIFICATION,//  Note: WmFragmentCounters are created before Tez counters are created. 
Hive,WITHOUT_CLASSIFICATION,//  For import statement require uri rwx+owner privileges on input uri and   necessary privileges on the output table and database   NOTE : privileges are only checked if the object of that type is marked as part of ReadEntity or WriteEntity   So if a table is present Import will mark a table as a WriteEntity and we'll authorize for that and if not present 
Hive,WITHOUT_CLASSIFICATION,//  Rounding results in 10^N. 
Hive,WITHOUT_CLASSIFICATION,//  VectorInBloomFilterColDynamicValue should have all of the necessary information to vectorize. 
Hive,WITHOUT_CLASSIFICATION,//  has also been adjusted to point to these buffers instead of compressed data for the ranges. 
Hive,WITHOUT_CLASSIFICATION,//  Thread reading the ATS GUID 
Hive,WITHOUT_CLASSIFICATION,//  We need to iterate to detect original directories that are supported in MM but not ACID. 
Hive,WITHOUT_CLASSIFICATION,//  Partial partition spec supplied. Make sure this is allowed. 
Hive,WITHOUT_CLASSIFICATION,//  if column name is not contained in needed column list then it   is a partition column. We do not need to evaluate partition columns 
Hive,WITHOUT_CLASSIFICATION,//  IS_FORCE_DEACTIVATE 
Hive,WITHOUT_CLASSIFICATION,// now generate insert statement 
Hive,WITHOUT_CLASSIFICATION,//  Variable-length arguments 
Hive,WITHOUT_CLASSIFICATION,/*    * {@inheritDoc}    */
Hive,WITHOUT_CLASSIFICATION,//  in all hadoop versions. 
Hive,WITHOUT_CLASSIFICATION,// this error should really be produced by Hive (DDLTask) 
Hive,WITHOUT_CLASSIFICATION,//  reposition at the begining 
Hive,WITHOUT_CLASSIFICATION,// gets X lock on T 
Hive,WITHOUT_CLASSIFICATION,//  possible if all children have same expressions but not likely. 
Hive,WITHOUT_CLASSIFICATION,//  Use old timestamp writable hash code for backwards compatibility 
Hive,WITHOUT_CLASSIFICATION,//  binary transport settings 
Hive,WITHOUT_CLASSIFICATION,//  didn't set the last repl ID due to some failure. 
Hive,WITHOUT_CLASSIFICATION,//  Adding these job properties will make them available to the OutputFormat in checkOutputSpecs 
Hive,WITHOUT_CLASSIFICATION,//  we pass null for aliases here because mergeWithChildrenPred filters   aliases in the children node context and we need to filter them in   the current JoinOperator's context 
Hive,WITHOUT_CLASSIFICATION,//  Create a Table object 
Hive,WITHOUT_CLASSIFICATION,//  todo: constant op constant 
Hive,WITHOUT_CLASSIFICATION,//  If the table is not external and it might not be in a subdirectory of the database 
Hive,WITHOUT_CLASSIFICATION,/*  * Looks for a hive-site.xml from the classpath. If found this class parses the hive-site.xml * to return a set of connection properties which can be used to construct the connection url * for Beeline connection  */
Hive,WITHOUT_CLASSIFICATION,//  Common case - the segment is in one buffer. 
Hive,WITHOUT_CLASSIFICATION,// if here after commit()/abort() but before next beginNextTransaction() currentTxnIndex still 
Hive,WITHOUT_CLASSIFICATION,/*    * When supported read a field by field number (i.e. random access).   *   * Currently only LazySimpleDeserializeRead supports this.   *   * @return  Return true when the field was not null and data is put in the appropriate   *          current* member.   *          Otherwise false when the field is null.    */
Hive,WITHOUT_CLASSIFICATION,//  return the column numbers of the bucketed columns 
Hive,WITHOUT_CLASSIFICATION,//  POOLS 
Hive,WITHOUT_CLASSIFICATION,// ignore 
Hive,WITHOUT_CLASSIFICATION,//  Inform the shuffle handler 
Hive,WITHOUT_CLASSIFICATION,//  used to cleanup cache 
Hive,WITHOUT_CLASSIFICATION,//  Past the timeout. 
Hive,WITHOUT_CLASSIFICATION,//  Tracks requests executing per node 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.CLIServiceClient#getInfo(org.apache.hive.service.cli.SessionHandle java.util.List)    */
Hive,WITHOUT_CLASSIFICATION,//  1.3.2 process the actual join 
Hive,WITHOUT_CLASSIFICATION,//  Verify if the configs are merged 
Hive,WITHOUT_CLASSIFICATION,//  count characters forward 
Hive,WITHOUT_CLASSIFICATION,/*  Referring to job tracker in 0.20 and resource manager in 0.23  */
Hive,WITHOUT_CLASSIFICATION,//  5. Check if select involves UDTF 
Hive,WITHOUT_CLASSIFICATION,//  Overwrite if the remote file already exists. Whether the file can be added   on executor is up to spark i.e. spark.files.overwrite 
Hive,WITHOUT_CLASSIFICATION,// Global config of vectorized input format is enabled; check if these inputformats are excluded 
Hive,WITHOUT_CLASSIFICATION,//  This input rel does produce the cor var referenced.   Assume fieldAccess has the correct type info. 
Hive,WITHOUT_CLASSIFICATION,//  Native vectorization supported. 
Hive,WITHOUT_CLASSIFICATION,//  make sure miniHS2_2 is the new leader 
Hive,WITHOUT_CLASSIFICATION,//  Allow implicit conversion from Byte -> Integer -> Long -> Float -> Double 
Hive,WITHOUT_CLASSIFICATION,//  at start-up we may be unable to get number of executors 
Hive,WITHOUT_CLASSIFICATION,//  Based on actual timing. 
Hive,WITHOUT_CLASSIFICATION,//  a reduce vertex 
Hive,WITHOUT_CLASSIFICATION,//  checked in SemanticAnalyzer. Should not happen 
Hive,WITHOUT_CLASSIFICATION,//  Write the first part of the array 
Hive,WITHOUT_CLASSIFICATION,//  Test deprecated HCatAddPartitionsDesc API. 
Hive,WITHOUT_CLASSIFICATION,//  All good. 
Hive,WITHOUT_CLASSIFICATION,//  analyzeCreateTable uses this.ast but doPhase1 doesn't so only reset it   here. 
Hive,WITHOUT_CLASSIFICATION,//  In case we're searching through an especially large set of data send a heartbeat in   order to avoid timeout 
Hive,WITHOUT_CLASSIFICATION,//  Case 4: column stats hash aggregation grouping sets 
Hive,WITHOUT_CLASSIFICATION,//  check stripHiddenConfigurations removes the property 
Hive,WITHOUT_CLASSIFICATION,//  the partition column we're interested in 
Hive,WITHOUT_CLASSIFICATION,//  Table in non 'hive' catalog 
Hive,WITHOUT_CLASSIFICATION,//  If no Run times present then set -1 indicating no values 
Hive,WITHOUT_CLASSIFICATION,//  We assume the existing vector is always valid. 
Hive,WITHOUT_CLASSIFICATION,//  3. Update Update Join Key to List<JoinLeafPredicateInfo> to use 
Hive,WITHOUT_CLASSIFICATION,//  First find first record for the key. 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:org.apache.hadoop.hive.serde2.proto.test.Complex) 
Hive,WITHOUT_CLASSIFICATION,//  The join keys cannot be transformed in the sub-query currently.   TableAccessAnalyzer.genRootTableScan will only return the base table scan   if the join keys are constants or a column. Even a simple cast of the join keys   will result in a null table scan operator. In case of constant join keys they would 
Hive,WITHOUT_CLASSIFICATION,//  non-deterministic functions as well as runtime constants are not materializable. 
Hive,WITHOUT_CLASSIFICATION,/*  * Specialized class for native vectorized reduce sink that is reducing on a Uniform Hash * single long key column.  */
Hive,WITHOUT_CLASSIFICATION,//  All but decimal. 
Hive,WITHOUT_CLASSIFICATION,//  in via the properties 
Hive,WITHOUT_CLASSIFICATION,/*      * roles grants      */
Hive,WITHOUT_CLASSIFICATION,//  Now only string text int long byte and boolean comparisons are   treated as special cases.   For other types we reuse ObjectInspectorUtils.compare() 
Hive,WITHOUT_CLASSIFICATION,//  It is NULL value with different type we need to introduce a CAST   to keep it 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: this method MUST call distributeGuaranteedOnTaskCompletion before exiting. 
Hive,WITHOUT_CLASSIFICATION,//  of any other queries running in the session 
Hive,WITHOUT_CLASSIFICATION,//  All getXXX needs toLowerCase() because they are directly called from   SemanticAnalyzer   All setXXX does not need it because they are called from QB which already   lowercases   the aliases. 
Hive,WITHOUT_CLASSIFICATION,// ************************************************************************************************   Decimal Debugging. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure it compiles with both Hadoop 2 and Hadoop 3. 
Hive,WITHOUT_CLASSIFICATION,//  we just created this directory - it's not a case of pre-creation so we nuke. 
Hive,WITHOUT_CLASSIFICATION,//  Test EventUtils.restrictByMessageFormat - this restricts events generated to those   that match a provided message format 
Hive,WITHOUT_CLASSIFICATION,/*  isTezOrSpark  */
Hive,WITHOUT_CLASSIFICATION,//  make this client wait if job trcker is not behaving well. 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:SourceStateUpdatedResponseProto) 
Hive,WITHOUT_CLASSIFICATION,//  Start is blocking so run one of the tasks on the main thread. 
Hive,WITHOUT_CLASSIFICATION,//  These are the columns in the big and small table that are ByteColumnVector columns. 
Hive,WITHOUT_CLASSIFICATION,//  get both tableAlias and column name from columnOrigin 
Hive,WITHOUT_CLASSIFICATION,//  Try with an extra base. 
Hive,WITHOUT_CLASSIFICATION,//  Replication case: export table <tbl> to <location> for replication 
Hive,WITHOUT_CLASSIFICATION,//  FileSinkOperator knows how to properly write to it. 
Hive,WITHOUT_CLASSIFICATION,/*  no reason to retry if the challenge ticket is not valid.  */
Hive,WITHOUT_CLASSIFICATION,//  No valid inputs - possible in MM case. 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: wh.getFileStatusesForUnpartitionedTable() can be REALLY slow 
Hive,WITHOUT_CLASSIFICATION,//  Alter a table in the wrong catalog 
Hive,WITHOUT_CLASSIFICATION,//  c7:map<stringstring>   c8:struct<r:strings:intt:double>   c9:tinyint   c10:smallint   c11:float   c12:bigint 
Hive,WITHOUT_CLASSIFICATION,//  4. Construct SortRel 
Hive,WITHOUT_CLASSIFICATION,//  first stripe will satisfy the predicate and will be a single split last stripe will be a 
Hive,WITHOUT_CLASSIFICATION,/*    * Initialize string table in a lazy fashion.    */
Hive,WITHOUT_CLASSIFICATION,//  They cancel each other. 
Hive,WITHOUT_CLASSIFICATION,//  Hive doesn't support a currency type 
Hive,WITHOUT_CLASSIFICATION,//  3. Walk through the Join Condition Building NDV for selectivity 
Hive,WITHOUT_CLASSIFICATION,//  First go through and set all our values for datanucleus and javax.jdo parameters.  This 
Hive,WITHOUT_CLASSIFICATION,//  Store the mapping -> path bucket number   This is needed since for the map-only job any mapper can process any file.   For eg: if mapper 1 is processing the file corresponding to bucket 2 it should   also output the file corresponding to bucket 2 of the output. 
Hive,WITHOUT_CLASSIFICATION,/*    * Left semi join (hash set).    */
Hive,WITHOUT_CLASSIFICATION,//  Break the client 
Hive,WITHOUT_CLASSIFICATION,// verify 
Hive,WITHOUT_CLASSIFICATION,//  dirName uniquely identifies destination directory of a FileSinkOperator.   If more than one FileSinkOperator write to the same partition this dirName   should be different. 
Hive,WITHOUT_CLASSIFICATION,// ignored 
Hive,WITHOUT_CLASSIFICATION,//  make sure credential provider path points to HIVE_SERVER2_JOB_CREDSTORE_LOCATION 
Hive,WITHOUT_CLASSIFICATION,//  this method's main use is to help unit testing this class 
Hive,WITHOUT_CLASSIFICATION,/*    * Common one time setup by native vectorized map join operator's processOp.    */
Hive,WITHOUT_CLASSIFICATION,//  Test select root from root:struct<col1:struct<a:booleanb:double>col2:double> 
Hive,WITHOUT_CLASSIFICATION,//  transaction batch size > 1 case 
Hive,WITHOUT_CLASSIFICATION,//  The underlying database field is varchar we need to compare numbers. 
Hive,WITHOUT_CLASSIFICATION,//  this is the bit where we make sure we don't group across partition   schema boundaries 
Hive,WITHOUT_CLASSIFICATION,//  The set of pruning sinks 
Hive,WITHOUT_CLASSIFICATION,//  Node1 now has free capacity. task1 should be allocated to it. 
Hive,WITHOUT_CLASSIFICATION,//  User can override value of sparkCloneConfiguration in Hive config to true 
Hive,WITHOUT_CLASSIFICATION,//  use the existing TableInfo object. Else create a new one. 
Hive,WITHOUT_CLASSIFICATION,//  Immutable causes #copy(obj) to return the original object 
Hive,WITHOUT_CLASSIFICATION,//  -(2^32-1) 
Hive,WITHOUT_CLASSIFICATION,//  1 for comma 
Hive,WITHOUT_CLASSIFICATION,//  Assume the high watermark can be used as maximum transaction ID. 
Hive,WITHOUT_CLASSIFICATION,//  This case possible if CM path is not enabled. 
Hive,WITHOUT_CLASSIFICATION,//  codes and messages. This should be fixed. 
Hive,WITHOUT_CLASSIFICATION,//  Compile internal query to capture underlying table partition dependencies 
Hive,WITHOUT_CLASSIFICATION,//  Create/Delete/Write/Admin to the authenticated user 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setCharacterStream(int java.io.Reader   * int)    */
Hive,WITHOUT_CLASSIFICATION,//  Run a self-test query. If it doesn't work we will self-disable. What a PITA... 
Hive,WITHOUT_CLASSIFICATION,//  ImmutableList 
Hive,WITHOUT_CLASSIFICATION,//  selectively used by fetch formatter 
Hive,WITHOUT_CLASSIFICATION,//  revert configs to not affect other tests 
Hive,WITHOUT_CLASSIFICATION,//  SubQuery was just one conjunct 
Hive,WITHOUT_CLASSIFICATION,/*    * Test if single-threaded implementation checker throws HiveException when the there is a dummy   * directory present in the nested level    */
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:EntityDescriptorProto) 
Hive,WITHOUT_CLASSIFICATION,//  3. Let a transaction be aborted 
Hive,WITHOUT_CLASSIFICATION,//  cancel given delegation token 
Hive,WITHOUT_CLASSIFICATION,// H1 - no capacity if force should allocate otherwise 
Hive,WITHOUT_CLASSIFICATION,//  as done 
Hive,WITHOUT_CLASSIFICATION,/*      * The callable shouldn't be null to execute. The thread pool also should be configured     * to execute requests.      */
Hive,WITHOUT_CLASSIFICATION,//  LOG.info("Writing value at " + valueOffset + " length " + (tailOffset - valueOffset)); 
Hive,WITHOUT_CLASSIFICATION,//  sans header row 
Hive,WITHOUT_CLASSIFICATION,//  Check the output of FixAcidKeyIndex - it should indicate the index was valid. 
Hive,WITHOUT_CLASSIFICATION,// table or partition's statistics and table or partition's column statistics are accurate or not. 
Hive,WITHOUT_CLASSIFICATION,//  cannot be performed as a map-only job 
Hive,WITHOUT_CLASSIFICATION,//  number of digits to mask from the end 
Hive,WITHOUT_CLASSIFICATION,/*  Switch from a 1-based start offset (the Hive end user convention) to a 0-based start offset     * (the internal convention).      */
Hive,WITHOUT_CLASSIFICATION,//  Try to allocate from target-sized free list maybe we'll get lucky. 
Hive,WITHOUT_CLASSIFICATION,//  Put shuffle version into http header 
Hive,WITHOUT_CLASSIFICATION,//  vertex is a mergejoin 
Hive,WITHOUT_CLASSIFICATION,//  This means the exception was caused by something other than a race condition   in creating the partition since the partition still doesn't exist. 
Hive,WITHOUT_CLASSIFICATION,//  Find the skew information corresponding to the table 
Hive,WITHOUT_CLASSIFICATION,//  boundary. Length will span two compression buffers. 
Hive,WITHOUT_CLASSIFICATION,//  requesting for the stats source will implicitly initialize it 
Hive,WITHOUT_CLASSIFICATION,// simulate partition update 
Hive,WITHOUT_CLASSIFICATION,/*  * Specialized class for doing a vectorized map join that is an left semi join on a Single-Column String * using a hash set.  */
Hive,WITHOUT_CLASSIFICATION,//  MD-ONLY table alter 
Hive,WITHOUT_CLASSIFICATION,//  We skip first child as is not involved (is the revert boolean)   The target type needs to account for all 3 operands 
Hive,WITHOUT_CLASSIFICATION,//  Need to find the tables and data as drop is not part of this dump 
Hive,WITHOUT_CLASSIFICATION,//  Handle the status change. 
Hive,WITHOUT_CLASSIFICATION,//  to cause any problem the cleaner thread will remove this when this jar expires. 
Hive,WITHOUT_CLASSIFICATION,//  Determine the transactional_properties of the table from the job conf stored in context.   The table properties are copied to job conf at HiveInputFormat::addSplitsForGroup()   & therefore we should be able to retrieve them here and determine appropriate behavior.   Note that this will be meaningless for non-acid tables & will be set to null. 
Hive,WITHOUT_CLASSIFICATION,//  c11-c20   c21-c23 
Hive,WITHOUT_CLASSIFICATION,//  Return true to retain an item and false to filter it out. 
Hive,WITHOUT_CLASSIFICATION,//  thought of creating template for each shims but I couldn't generate proper mvn script 
Hive,WITHOUT_CLASSIFICATION,/*  id <=> 30  */
Hive,WITHOUT_CLASSIFICATION,//  Set the big table position. Both the reduce work and merge join operator   should be set with the same value. 
Hive,WITHOUT_CLASSIFICATION,//  Create a minimalistic table 
Hive,WITHOUT_CLASSIFICATION,//  silent overflow 
Hive,WITHOUT_CLASSIFICATION,//  boolean invert (not)   expression   left expression   right expression 
Hive,WITHOUT_CLASSIFICATION,//  Add the new paths to the znodes list. We'll try for their removal as well. 
Hive,WITHOUT_CLASSIFICATION,//  If all the queries are map-only anyway the query is most optimized 
Hive,WITHOUT_CLASSIFICATION,//  inject properties from the main App that matches allowedPrefix 
Hive,WITHOUT_CLASSIFICATION,//  The name should not be changed so reload the db with the original name 
Hive,WITHOUT_CLASSIFICATION,//  End SemiJoinRule.java 
Hive,WITHOUT_CLASSIFICATION,// such base is created by 1st compaction in case of non-acid to acid table conversion  By definition there are no open txns with id < 1. 
Hive,WITHOUT_CLASSIFICATION,//  verify that a multi byte LIKE expression doesn't match a non-matching string 
Hive,WITHOUT_CLASSIFICATION,//  fail similarly when memory allocations fail 
Hive,WITHOUT_CLASSIFICATION,//  this means we have just created a table and are specifying partition in the   load statement (without pre-creating the partition) in which case lets use   table input format class. inheritTableSpecs defaults to true so when a new   partition is created later it will automatically inherit input format   from table object 
Hive,WITHOUT_CLASSIFICATION,//  remove count(distinct) in map-side gby 
Hive,WITHOUT_CLASSIFICATION,//  Create scratch dirs for this session 
Hive,WITHOUT_CLASSIFICATION,//  o depends on this 
Hive,WITHOUT_CLASSIFICATION,//  order by or a sort by clause. 
Hive,WITHOUT_CLASSIFICATION,//  Extract the actual row from row batch 
Hive,WITHOUT_CLASSIFICATION,//   In 'nobucket' table we capture bucketid from streamedtable to workaround a hive bug that prevents joins two identically bucketed tables 
Hive,WITHOUT_CLASSIFICATION,//  Move past pair separator. 
Hive,WITHOUT_CLASSIFICATION,//  Float 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) TypeString  */
Hive,WITHOUT_CLASSIFICATION,//  TODO: Clean up SessionState/Driver/TezSession on exit 
Hive,WITHOUT_CLASSIFICATION,//  Check dead session get cleared 
Hive,WITHOUT_CLASSIFICATION,/*    * See {@link #next(NullWritable VectorizedRowBatch)} first and   * {@link OrcRawRecordMerger.OriginalReaderPair}.   * When reading a split of an "original" file and we need to decorate data with ROW__ID.   * This requires treating multiple files that are part of the same bucket (tranche for unbucketed   * tables) as a single logical file to number rowids consistently.   *   * todo: This logic is executed per split of every "original" file.  The computed result is the   * same for every split form the same file so this could be optimized by moving it to   * before/during split computation and passing the info in the split.  (HIVE-17917)    */
Hive,WITHOUT_CLASSIFICATION,//  not backward compatible 
Hive,WITHOUT_CLASSIFICATION,//  Handle remaining lower long word digits as integer digits. 
Hive,WITHOUT_CLASSIFICATION,//  look for bean style accessors get_fieldName and is_fieldName 
Hive,WITHOUT_CLASSIFICATION,//  HTTPS cannot be done with zero copy. 
Hive,WITHOUT_CLASSIFICATION,//  subqueries. 
Hive,WITHOUT_CLASSIFICATION,//  And finally save the VectorizationContext. 
Hive,WITHOUT_CLASSIFICATION,//  For now leave DECIMAL precision/scale in the name so DecimalColumnVector scratch columns   don't need their precision/scale adjusted... 
Hive,WITHOUT_CLASSIFICATION,//  Go to task details fetch task tracker url 
Hive,WITHOUT_CLASSIFICATION,//  This should eventually hang in the delay code. 
Hive,WITHOUT_CLASSIFICATION,//  Get http service port # 
Hive,WITHOUT_CLASSIFICATION,//  Find the SourceInfo to put values in. 
Hive,WITHOUT_CLASSIFICATION,//  (in this case a missing specification) of UTF String storage 
Hive,WITHOUT_CLASSIFICATION,//  getGenericUDF() actually clones the UDF. Just call it once and reuse. 
Hive,WITHOUT_CLASSIFICATION,//  New key. 
Hive,WITHOUT_CLASSIFICATION,// return 0xD8000000 + lowSurrogate; 
Hive,WITHOUT_CLASSIFICATION,//  User can override value for sparkCloneConfiguration in Hive config to false 
Hive,WITHOUT_CLASSIFICATION,//  Ignore the exception and fall through the default currentStateId 
Hive,WITHOUT_CLASSIFICATION,//  empty String args:  
Hive,WITHOUT_CLASSIFICATION,//  Note: Hadoop metric reporter does not support tags. We create a single reporter for all metrics. 
Hive,WITHOUT_CLASSIFICATION,//  if we autosave then save 
Hive,WITHOUT_CLASSIFICATION,/*    * cache of rows; guaranteed to contain precedingSpan rows before   * nextRowToProcess.    */
Hive,WITHOUT_CLASSIFICATION,//  UDFArgumentTypeException is expected 
Hive,WITHOUT_CLASSIFICATION,//  Stream variables. 
Hive,WITHOUT_CLASSIFICATION,//  Calculation below is consistent with BloomFilter.optimalNumOfBits().   Also we are capping the BloomFilter size below 100 MB (800000000/8) 
Hive,WITHOUT_CLASSIFICATION,//  Across MR process boundary tz is normalized and stored in type   and is not carried in data for each row. 
Hive,WITHOUT_CLASSIFICATION,//  2. If we need to generate limit 
Hive,WITHOUT_CLASSIFICATION,//  leverage TEZ-3437: Improve synchronization and the progress report behavior. 
Hive,WITHOUT_CLASSIFICATION,//  single threaded scheduler for tasks from wait queue to executor threads 
Hive,WITHOUT_CLASSIFICATION,//  The SIMD optimized form of "a >= b" is "((a - b) >>> 63) ^ 1" 
Hive,WITHOUT_CLASSIFICATION,//  scale down. does rounding 
Hive,WITHOUT_CLASSIFICATION,//     to do with the sessions after we go thru all the concurrent user actions. 
Hive,WITHOUT_CLASSIFICATION,//  Secure ZK is only set up by the registering service; anyone can read the registrations. 
Hive,WITHOUT_CLASSIFICATION,//  Replacing it is the right thing to do though since we expect the AM to kill all the fragments running on the node via timeouts.   De-allocate messages coming in from the old node are sent to the NodeInfo instance for the old node. 
Hive,WITHOUT_CLASSIFICATION,//  handled below 
Hive,WITHOUT_CLASSIFICATION,//  Use the serialization scale and create a BigInteger with trailing zeroes (or   round the decimal) if necessary.     Since we are emulating old behavior and recommending the use of HiveDecimal.bigIntegerBytesScaled   instead just do it the slow way.  Get the BigDecimal.setScale value and return the   BigInteger.   
Hive,WITHOUT_CLASSIFICATION,// add the columns in residual filters 
Hive,WITHOUT_CLASSIFICATION,//  Make a copy since we intend to mutate sum. 
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.QueryCompleteResponseProto.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,//  Inherit the environment variables 
Hive,WITHOUT_CLASSIFICATION,//  Eventually enough small writes should result in another buffer getting created 
Hive,WITHOUT_CLASSIFICATION,/*  Get all locks  */
Hive,WITHOUT_CLASSIFICATION,//  admin check -   allows when hadoop.security.instrumentation.requires.admin is set to false   when hadoop.security.instrumentation.requires.admin is set to true checks if hadoop.security.authorization   is true and if the logged in user (via PAM or SPNEGO + kerberos) is in hive.users.in.admin.role list 
Hive,WITHOUT_CLASSIFICATION,// where missing columns are NULL-filled 
Hive,WITHOUT_CLASSIFICATION,//  without extra structs 
Hive,WITHOUT_CLASSIFICATION,//  Parse out 'n' and 'k' if we haven't already done so and while we're at it   also parse out the precision factor 'pf' if the user has supplied one. 
Hive,WITHOUT_CLASSIFICATION,//  LOG is not static to make debugging easier (being able to identify which sub-class 
Hive,WITHOUT_CLASSIFICATION,//  Null path => unmanaged 
Hive,WITHOUT_CLASSIFICATION,//  11. put accessed columns to readEntity 
Hive,WITHOUT_CLASSIFICATION,//  Requesting more partitions than allowed should throw an exception 
Hive,WITHOUT_CLASSIFICATION,/*    * Helper to setup default environment for a task in YARN.    */
Hive,WITHOUT_CLASSIFICATION,//  add -v and --verbose to print verbose message 
Hive,WITHOUT_CLASSIFICATION,//  timestamp 
Hive,WITHOUT_CLASSIFICATION,//  3rd query's session has compile lock timeout of 100 secs so it should 
Hive,WITHOUT_CLASSIFICATION,//  first check if we will allow the user to create table. 
Hive,WITHOUT_CLASSIFICATION,//  to a sort-merge join 
Hive,WITHOUT_CLASSIFICATION,//  Number of variables and assignment expressions 
Hive,WITHOUT_CLASSIFICATION,//  Use session registry - see Registry.isPermanentFunc() 
Hive,WITHOUT_CLASSIFICATION,//  if we are collapsing figure out if this is a new row 
Hive,WITHOUT_CLASSIFICATION,//  events are processed. Otherwise task metrics may get lost. See HIVE-13525. 
Hive,WITHOUT_CLASSIFICATION,//  Spot check only. Non-standard cases are checked for the same template in another test. 
Hive,WITHOUT_CLASSIFICATION,//  If we are currently performing a binary search on the input don't forward the results   Currently this value is set when a query is optimized using a compact index.  The map reduce   job responsible for scanning and filtering the index sets this value.  It remains set   throughout the binary search executed by the HiveBinarySearchRecordResder until a starting 
Hive,WITHOUT_CLASSIFICATION,//  Extracted from FunctionRegistry 
Hive,WITHOUT_CLASSIFICATION,//  partial partition spec has null partHandle 
Hive,WITHOUT_CLASSIFICATION,//  Use MapFieldEntry.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,//  This means that the lock is ready to be cleaned hence it cannot 
Hive,WITHOUT_CLASSIFICATION,//  CDs are reused; go thry partition SDs detach all CDs from SDs then remove unused CDs. 
Hive,WITHOUT_CLASSIFICATION,//  This Oid for Kerberos GSS-API mechanism. 
Hive,WITHOUT_CLASSIFICATION,//  advance the reader until we reach the minimum key 
Hive,WITHOUT_CLASSIFICATION,//  expect readReader return same Key & Value objects (common case) 
Hive,WITHOUT_CLASSIFICATION,//  as well as a Set (for all others) to ensure determinism. 
Hive,WITHOUT_CLASSIFICATION,//  Not sequential with previous. 
Hive,WITHOUT_CLASSIFICATION,//  add whether the row is filtered or not   this value does not matter for the dummyObj   because the join values are already null 
Hive,WITHOUT_CLASSIFICATION,//  Logger attempts 
Hive,WITHOUT_CLASSIFICATION,// doing a SELECT first is less efficient but makes it easier to debug things 
Hive,WITHOUT_CLASSIFICATION,/* in UTs there is no standalone HMS running to kick off compaction so it's done via runWorker()     but in normal usage 'concatenate' is blocking  */
Hive,WITHOUT_CLASSIFICATION,//  Table properties 
Hive,WITHOUT_CLASSIFICATION,//  MetadataStore 
Hive,WITHOUT_CLASSIFICATION,//  We need a input object inspector that is for the row we will extract out of the 
Hive,WITHOUT_CLASSIFICATION,//  no-op for non-test mode for now 
Hive,WITHOUT_CLASSIFICATION,//  a flag that helps to set the correct driver state in finally block by tracking if   the method has been returned by an error or not. 
Hive,WITHOUT_CLASSIFICATION,//  Rewrite the load to launch an insert job. 
Hive,WITHOUT_CLASSIFICATION,//  Hive will always require user to specify exact sizes for char varchar;   Binary doesn't need any sizes; Decimal has the default of 10. 
Hive,WITHOUT_CLASSIFICATION,//  Re-using the TokenRewriteStream map for views so we do not overwrite the current TokenRewriteStream 
Hive,WITHOUT_CLASSIFICATION,//  most common scenario 
Hive,WITHOUT_CLASSIFICATION,//  inside! 
Hive,WITHOUT_CLASSIFICATION,//  find which column contains the raw data size (both partitioned and non partitioned 
Hive,WITHOUT_CLASSIFICATION,/*      * VARCHAR: string length beyond max      */
Hive,WITHOUT_CLASSIFICATION,// Allocate new Vectorization context to reset the intermediate columns. 
Hive,WITHOUT_CLASSIFICATION,//  There should be 1 new directory: base_-9223372036854775808 
Hive,WITHOUT_CLASSIFICATION,//  If the parent is same as the ts then we have a cycle. 
Hive,WITHOUT_CLASSIFICATION,//  We have to get mtable again because DataNucleus. 
Hive,WITHOUT_CLASSIFICATION,//  this is for basic stats 
Hive,WITHOUT_CLASSIFICATION,//  All key input columns are repeating.  Generate key once.  Lookup once. 
Hive,WITHOUT_CLASSIFICATION,//  don't need to merge add the move job 
Hive,WITHOUT_CLASSIFICATION,/*        * Currently VectorizedParquetRecordReader cannot handle nested complex types.        */
Hive,WITHOUT_CLASSIFICATION,//  timestamp +/- interval_day_time   interval_day_time + timestamp 
Hive,WITHOUT_CLASSIFICATION,//  Use SourceStateUpdatedResponseProto.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,//  HIVE-19588 removes listStatus from the code path so there should only be one read ops (open) after HIVE-19588 
Hive,WITHOUT_CLASSIFICATION,//  Avro only allows maps with Strings for keys so we only have to worry   about deserializing the values 
Hive,WITHOUT_CLASSIFICATION,//  In case we need it for the other case. 
Hive,WITHOUT_CLASSIFICATION,//  Segment Metadata query that retrieves all columns present in   the data source (dimensions and metrics). 
Hive,WITHOUT_CLASSIFICATION,//  find all the indexes of the sub byte[] 
Hive,WITHOUT_CLASSIFICATION,//  UNDONE: No for List and Map; Yes for Struct and Union when field count different... 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#setSavepoint(java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  a path for a split unqualified the split from being sampled if:   1. it serves more than one alias   2. the alias it serves is not sampled   3. it serves different alias than another path for the same split 
Hive,WITHOUT_CLASSIFICATION,//  Update the partition col stats for a table in cache 
Hive,WITHOUT_CLASSIFICATION,/*  * An single long value hash map based on the BytesBytesMultiHashMap. * * We serialize the long key into BinarySortable format into an output buffer accepted by * BytesBytesMultiHashMap.  */
Hive,WITHOUT_CLASSIFICATION,//  executeUpdate() of Prepared statement 
Hive,WITHOUT_CLASSIFICATION,// convert BytesWritable to byte[] 
Hive,WITHOUT_CLASSIFICATION,//  if oldPath is destf or its subdir its should definitely be deleted otherwise its   existing content might result in incorrect (extra) data.   But not sure why we changed not to delete the oldPath in HIVE-8750 if it is   not the destf or its subdir? 
Hive,WITHOUT_CLASSIFICATION,//  Set the context attribute to true which will be interpreted by the request   interceptor 
Hive,WITHOUT_CLASSIFICATION,//  HS2 connections guard rails 
Hive,WITHOUT_CLASSIFICATION,//  For now we disable the test attempts. 
Hive,WITHOUT_CLASSIFICATION,//  Gather output works operators 
Hive,WITHOUT_CLASSIFICATION,//  Not currently supported. 
Hive,WITHOUT_CLASSIFICATION,//  Assign values from the row to local variables 
Hive,WITHOUT_CLASSIFICATION,//  expressions for project operator 
Hive,WITHOUT_CLASSIFICATION,//  expressions. These comparisons are AND'ed together. 
Hive,WITHOUT_CLASSIFICATION,//  Even in large (say VARCHAR(2000)) columns most strings are small 
Hive,WITHOUT_CLASSIFICATION,//  optional .SubmissionStateProto submission_state = 1; 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see javax.sql.CommonDataSource#setLoginTimeout(int)    */
Hive,WITHOUT_CLASSIFICATION,//  the last field is the union field if any 
Hive,WITHOUT_CLASSIFICATION,// the token file location comes after mainClass as a -D prop=val 
Hive,WITHOUT_CLASSIFICATION,//  Test integer 
Hive,WITHOUT_CLASSIFICATION,//  if outPath does not exist then it means all paths within combine split are skipped as   they are incompatible for merge (for example: files without stripe stats).   Those files will be added to incompatFileSet 
Hive,WITHOUT_CLASSIFICATION,//  Stop on non-existent option. 
Hive,WITHOUT_CLASSIFICATION,//  First try temp table 
Hive,WITHOUT_CLASSIFICATION,//  Replication done we need to check if new value is set for existing property 
Hive,WITHOUT_CLASSIFICATION,//  Use HiveVarchar's internal Text member to read the value. 
Hive,WITHOUT_CLASSIFICATION,//  remove them 
Hive,WITHOUT_CLASSIFICATION,//  3.2 Add column info corresponding to partition columns 
Hive,WITHOUT_CLASSIFICATION,//  create map local operators 
Hive,WITHOUT_CLASSIFICATION,//  Counter for rows emitted 
Hive,WITHOUT_CLASSIFICATION,// share the code with RecordReader. 
Hive,WITHOUT_CLASSIFICATION,// for fullAcid we don't want to delete any files even for OVERWRITE see HIVE-14988/HIVE-17361 
Hive,WITHOUT_CLASSIFICATION,//  setup whitelist 
Hive,WITHOUT_CLASSIFICATION,//  MapJoin and SMBJoin not supported 
Hive,WITHOUT_CLASSIFICATION,//  The plan consists of a StatsTask only. 
Hive,WITHOUT_CLASSIFICATION,//  We may not own the table object create a copy 
Hive,WITHOUT_CLASSIFICATION,//  Now get from cache 
Hive,WITHOUT_CLASSIFICATION,//  Find the table we will be working with. 
Hive,WITHOUT_CLASSIFICATION,//  Wrap up the current query string since we can not add another "inList" element value. 
Hive,WITHOUT_CLASSIFICATION,//  Also MIN_HISTORY_LEVEL will have 1 entry for the open txn. 
Hive,WITHOUT_CLASSIFICATION,//  Proportion of extra space to provide when allocating more buffer space. 
Hive,WITHOUT_CLASSIFICATION,//  Map from integer tag to distinct aggrs 
Hive,WITHOUT_CLASSIFICATION,//  Initialize container to use for storing tuples before emitting them 
Hive,WITHOUT_CLASSIFICATION,//  4. Otherwise we create a new condition 
Hive,WITHOUT_CLASSIFICATION,//  If source is already CM path the checksum will be always matching 
Hive,WITHOUT_CLASSIFICATION,//  we scale up sumNulls based on the number of partitions 
Hive,WITHOUT_CLASSIFICATION,// check that partition keys have not changed except for virtual views 
Hive,WITHOUT_CLASSIFICATION,//  Use old value reference word.   LOG.debug("VectorMapJoinFastLongHashTable expandAndRehash key " + tableKey + " slot " + newSlot + " newPairIndex " + newPairIndex + " empty slot (i = " + i + ")"); 
Hive,WITHOUT_CLASSIFICATION,//  In compatibility mode we need to hook to set and use 
Hive,WITHOUT_CLASSIFICATION,//  first check all (1) tables 
Hive,WITHOUT_CLASSIFICATION,//  See serialization of decimal for explanation (below) 
Hive,WITHOUT_CLASSIFICATION,//  and any databases other than the default database. 
Hive,WITHOUT_CLASSIFICATION,//  update statistics based on column statistics.   OR conditions keeps adding the stats independently this may   result in number of rows getting more than the input rows in 
Hive,WITHOUT_CLASSIFICATION,//  Create a file system handle 
Hive,WITHOUT_CLASSIFICATION,// and do a Load Data into the same table which should now land in a delta/ 
Hive,WITHOUT_CLASSIFICATION,//  Remove any parents from MapJoin again 
Hive,WITHOUT_CLASSIFICATION,//  Determine the lock type to acquire 
Hive,WITHOUT_CLASSIFICATION,//  Initial write (small value) 
Hive,WITHOUT_CLASSIFICATION,//  input long[] is set as such without copying so any modification to the source will affect bloom filter 
Hive,WITHOUT_CLASSIFICATION,//   value might have been changed because of the normalization in conversion 
Hive,WITHOUT_CLASSIFICATION,//  is set to bootstrap dump location used in C. 
Hive,WITHOUT_CLASSIFICATION,//  Already exists. 
Hive,WITHOUT_CLASSIFICATION,//  tests setting maxRows to 0 
Hive,WITHOUT_CLASSIFICATION,//  First calculate the length of the output string 
Hive,WITHOUT_CLASSIFICATION,//  Since metaVars are all of different types use string for comparison 
Hive,WITHOUT_CLASSIFICATION,/*      * Count input and output are LONG.     *     * Just modes (PARTIAL2 FINAL).      */
Hive,WITHOUT_CLASSIFICATION,//  Check if there are column stats available for these columns 
Hive,WITHOUT_CLASSIFICATION,//  derived classes can set this to different object if needed 
Hive,WITHOUT_CLASSIFICATION,//  the plan file should always be in local directory 
Hive,WITHOUT_CLASSIFICATION,//  We must iterate over all the delete records until we find one record with 
Hive,WITHOUT_CLASSIFICATION,//  Get the valid write id list for all the tables read by the current txn 
Hive,WITHOUT_CLASSIFICATION,//  Don't user uber in "all" mode - everything can go into LLAP which is better than uber. 
Hive,WITHOUT_CLASSIFICATION,/*  isOriginalMapJoin  */
Hive,WITHOUT_CLASSIFICATION,//  if it is not analyze command and not column stats then do not gatherstats 
Hive,WITHOUT_CLASSIFICATION,//  Converts negative byte to positive index 
Hive,WITHOUT_CLASSIFICATION,//  Not possible to expand since we have more than one chunk with a single segment.   This is the case when user wants to append a segment with coarser granularity.   e.g If metadata storage already has segments for with granularity HOUR and segments to append have DAY granularity.   Druid shard specs does not support multiple partitions for same interval with different granularity. 
Hive,WITHOUT_CLASSIFICATION,//  this is the last branch and it is always false   We assume alwaysFalse filter will get pushed down to TS so this   branch so it won't read any data. 
Hive,WITHOUT_CLASSIFICATION,//  repeated .IOSpecProto input_specs = 10; 
Hive,WITHOUT_CLASSIFICATION,//  to get at least 10 splits 
Hive,WITHOUT_CLASSIFICATION,//  Integer.MIN_VALUE 
Hive,WITHOUT_CLASSIFICATION,//  finally make sure the file sink operators are set up right 
Hive,WITHOUT_CLASSIFICATION,// now check that stats for partition we didn't modify did not change 
Hive,WITHOUT_CLASSIFICATION,//  we need to edit the configuration to setup cmdline. clone it first 
Hive,WITHOUT_CLASSIFICATION,//  ### NOTE: fix for sf.net bug 879425.   Working around an issue in jline-2.1.2 see https://github.com/jline/jline/issues/10   by appending a newline to the end of inputstream 
Hive,WITHOUT_CLASSIFICATION,//  parameters of the form : KEY.colx:t.coly 
Hive,WITHOUT_CLASSIFICATION,//  need to reset the monitor as operation handle is not available down stream Ideally the   monitor should be associated with the operation handle. 
Hive,WITHOUT_CLASSIFICATION,//  Usually this means we've already created the tables so clean them and then try again 
Hive,WITHOUT_CLASSIFICATION,//  Use magic value to indicating we are writing the big value length. 
Hive,WITHOUT_CLASSIFICATION,//  There will be 4 data nodes   There will be 4 task tracker nodes 
Hive,WITHOUT_CLASSIFICATION,// For BC ignore this for now but leave a log message 
Hive,WITHOUT_CLASSIFICATION,//  default implementation 
Hive,WITHOUT_CLASSIFICATION,//  When fraction is exactly 0.5 and lowest new digit is odd go towards even. 
Hive,WITHOUT_CLASSIFICATION,// get override compression properties via "tblproperties" clause if it is set 
Hive,WITHOUT_CLASSIFICATION,//  Use GroupInputSpecProto.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,//  Do not create predicate if the leaf is not on the passed schema. 
Hive,WITHOUT_CLASSIFICATION,//  Clear value arrays. 
Hive,WITHOUT_CLASSIFICATION,//  Read all values. 
Hive,WITHOUT_CLASSIFICATION,//  If map type contains schema of the value element. 
Hive,WITHOUT_CLASSIFICATION,//  Postgres specific parser 
Hive,WITHOUT_CLASSIFICATION,//  push the context on to the end of the serialized n-gram estimation 
Hive,WITHOUT_CLASSIFICATION,//  For this variation we serialize the key without caring if it single Long   single String multi-key etc. 
Hive,WITHOUT_CLASSIFICATION,//  if so. If that should ever change this will need reworking. 
Hive,WITHOUT_CLASSIFICATION,//   throw new RuntimeException("varchar type used without type params");  } 
Hive,WITHOUT_CLASSIFICATION,/*      * How many data columns is the partition reader actually supplying?      */
Hive,WITHOUT_CLASSIFICATION,//  no checks for non-secure hadoop installations 
Hive,WITHOUT_CLASSIFICATION,//  Set up the JDBC connection pool 
Hive,WITHOUT_CLASSIFICATION,//  It is assumed the caller have already allocated write id for adding/updating data to   the acid tables. However DDL operatons won't allocate write id and hence this query   may return empty result sets.   Get the write id allocated by this txn for the given table writes 
Hive,WITHOUT_CLASSIFICATION,//  Report success for all other cases. 
Hive,WITHOUT_CLASSIFICATION,/*  (id between 23 and 45) and       first_name = 'alan' and       substr('xxxxx' 3) == first_name and       'smith' = last_name and       substr(first_name 3) == 'yyy'  */
Hive,WITHOUT_CLASSIFICATION,/*    * INTERVAL_DAY_TIME.    */
Hive,WITHOUT_CLASSIFICATION,/*  Construct a string of column names based on the number of column types  */
Hive,WITHOUT_CLASSIFICATION,// this is actually a ALTER TABLE DROP PARITITION statement 
Hive,WITHOUT_CLASSIFICATION,//  if serde is null the input doesn't need to be spilled out 
Hive,WITHOUT_CLASSIFICATION,//  Ignore. 
Hive,WITHOUT_CLASSIFICATION,/*        * Not able to find thread to execute the job request. Raise Busy exception and client       * can retry the operation.        */
Hive,WITHOUT_CLASSIFICATION,//  check the mere mortals! 
Hive,WITHOUT_CLASSIFICATION,//  We can clear the global error when we see that it was set in a   descendant node of a group by expression because   processGByExpr() returns a ExprNodeDesc that effectively ignores   its children. Although the error can be set multiple times by   descendant nodes DFS traversal ensures that the error only needs to   be cleared once. Also for a case like   SELECT concat(value concat(value))... the logic still works as the   error is only set with the first 'value'; all node processors quit   early if the global error is set. 
Hive,WITHOUT_CLASSIFICATION,// this does "Path.uri.compareTo(that.uri)" 
Hive,WITHOUT_CLASSIFICATION,//  DROP_TABLE EVENT to partitioned table 
Hive,WITHOUT_CLASSIFICATION,//  reached the end of the result file 
Hive,WITHOUT_CLASSIFICATION,//  if the data is not escaped simply copy the data. 
Hive,WITHOUT_CLASSIFICATION,//  We cache the values 
Hive,WITHOUT_CLASSIFICATION,//  else do the common code at the end. 
Hive,WITHOUT_CLASSIFICATION,//  Various final services configs etc. 
Hive,WITHOUT_CLASSIFICATION,/*            * We previously assigned *some* rows with non-NULL values. The batch indices of           * the unassigned row were tracked.            */
Hive,WITHOUT_CLASSIFICATION,//  with HIVE-11304 hive.root.logger cannot have both logger name and log level.   if we still see it split logger and level separately for hive.root.logger   and hive.log.level respectively 
Hive,WITHOUT_CLASSIFICATION,//  Failed to dump the side-table remove the partial file 
Hive,WITHOUT_CLASSIFICATION,//  Merge the two into the lateral view join   The cols of the merged result will be the combination of both the   cols of the UDTF path and the cols of the all path. The internal   names have to be changed to avoid conflicts 
Hive,WITHOUT_CLASSIFICATION,//  HADOOP_JOB_ID 
Hive,WITHOUT_CLASSIFICATION,//  Used to support a.b where a is a list of struct that contains a field   called b.   a.b will return an array that contains field b of all elements of array a. 
Hive,WITHOUT_CLASSIFICATION,// no rows match 
Hive,WITHOUT_CLASSIFICATION,//  Timeout for nodes is larger than delay - immediate allocation 
Hive,WITHOUT_CLASSIFICATION,// rename partition 
Hive,WITHOUT_CLASSIFICATION,//  if we are working on a stripe over the min stripe size and   crossed a block boundary cut the input split here. 
Hive,WITHOUT_CLASSIFICATION,//  if one of the child conditions is true/false. 
Hive,WITHOUT_CLASSIFICATION,//  Read the list 
Hive,WITHOUT_CLASSIFICATION,// initialize mapwork with smbMapJoin information. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setBinaryStream(java.lang.String   * java.io.InputStream long)    */
Hive,WITHOUT_CLASSIFICATION,//  A pending update is not done.   The task has terminated out of date heartbeat. 
Hive,WITHOUT_CLASSIFICATION,/*    * Setup our left semi join specific members.    */
Hive,WITHOUT_CLASSIFICATION,//  Methods summary 
Hive,WITHOUT_CLASSIFICATION,//  Current nodes in the cache 
Hive,WITHOUT_CLASSIFICATION,// find all Acid FileSinkOperatorS 
Hive,WITHOUT_CLASSIFICATION,//  union is encountered for the first time 
Hive,WITHOUT_CLASSIFICATION,//  if there is any partition column (in static partition or dynamic 
Hive,WITHOUT_CLASSIFICATION,//  This is not a new key; we'll overwrite the key and hash bytes - not needed anymore. 
Hive,WITHOUT_CLASSIFICATION,//  this should throw ClassCastException 
Hive,WITHOUT_CLASSIFICATION,//  we need side file for this test so we create 2 txn batch and test with only one 
Hive,WITHOUT_CLASSIFICATION,//  returns Set<?> 
Hive,WITHOUT_CLASSIFICATION,//  Do not support MM tables either at this point. We could do it with some extra logic. 
Hive,WITHOUT_CLASSIFICATION,//  Ensure that it is a full qualified path (in most cases it will be since tbl.getPath() is full qualified) 
Hive,WITHOUT_CLASSIFICATION,//  2) Get locks that are relevant:   - Exclusive for INSERT OVERWRITE. 
Hive,WITHOUT_CLASSIFICATION,//  All other primitive types are simple 
Hive,WITHOUT_CLASSIFICATION,//  Verify if HWM is properly set after REPL LOAD 
Hive,WITHOUT_CLASSIFICATION,/*    * build:   *    ^(TOK FROM   *        ^(TOK_SUBQUERY   *            {the input SubQuery with correlation removed}   *            subQueryAlias    *          )    *     )    */
Hive,WITHOUT_CLASSIFICATION,//  Do semantic analysis and plan generation 
Hive,WITHOUT_CLASSIFICATION,//  StandardList uses ArrayList to store the row. 
Hive,WITHOUT_CLASSIFICATION,// T2 is an acid table so this should fail 
Hive,WITHOUT_CLASSIFICATION,//  do row resolve once more because the ColumnInfo in row resolver is already removed 
Hive,WITHOUT_CLASSIFICATION,//  Replicate only 2 INSERT INTO operations. 
Hive,WITHOUT_CLASSIFICATION,/*  256 files x 1000 size for 99 splits  */
Hive,WITHOUT_CLASSIFICATION,//  Where a List<Partitions is already provided   Where we want to fetch Partitions lazily when they're needed. 
Hive,WITHOUT_CLASSIFICATION,//  Create source table. 
Hive,WITHOUT_CLASSIFICATION,//  get current mapred work and its local work 
Hive,WITHOUT_CLASSIFICATION,//  Test with remote metastore service 
Hive,WITHOUT_CLASSIFICATION,//  Note: this tableExport is actually never used other than for auth and another one is 
Hive,WITHOUT_CLASSIFICATION,//  Not efficient but we don't expect this to be called frequently. 
Hive,WITHOUT_CLASSIFICATION,//  Propagate this value from HS2; don't allow users to set it.   In HS2 initConf will be set; it won't be set otherwise as noone calls setupPool. 
Hive,WITHOUT_CLASSIFICATION,//  If we are doing an acid operation they will always all be true as RecordUpdaters always   collect stats 
Hive,WITHOUT_CLASSIFICATION,//  Misc DDL 
Hive,WITHOUT_CLASSIFICATION,//  We are waiting for next block. Either we will get it or be told we are done. 
Hive,WITHOUT_CLASSIFICATION,//  Validate input to ReduceWork. 
Hive,WITHOUT_CLASSIFICATION,//  push not through between... 
Hive,WITHOUT_CLASSIFICATION,// which is not tracked directly but available on /jobs/<id> node via "mtime" in Stat 
Hive,WITHOUT_CLASSIFICATION,//  There is an extra dependency on MetricsRegistry for snapshot IF. 
Hive,WITHOUT_CLASSIFICATION,//  There was a parallel deallocate; it didn't account for the memory. 
Hive,WITHOUT_CLASSIFICATION,//  Check if table/partition in C doesn't have ckpt property 
Hive,WITHOUT_CLASSIFICATION,// the alias 
Hive,WITHOUT_CLASSIFICATION,//  set database specific parameters 
Hive,WITHOUT_CLASSIFICATION,//  add to the map 
Hive,WITHOUT_CLASSIFICATION,//  Irrelevant. 
Hive,WITHOUT_CLASSIFICATION,//  also populate with StorageDescriptor->SerDe.Parameters 
Hive,WITHOUT_CLASSIFICATION,//  print out the location of the log file for the user so 
Hive,WITHOUT_CLASSIFICATION,//  Create the configuration hadoop-site.xml file 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setNull(java.lang.String int)    */
Hive,WITHOUT_CLASSIFICATION,//  Wait for all invocations to complete. 
Hive,WITHOUT_CLASSIFICATION,//  Gobble up the exception. Message delivery is best effort. 
Hive,WITHOUT_CLASSIFICATION,//  Alias 
Hive,WITHOUT_CLASSIFICATION,//  Now expand the view definition with extras such as explicit column   references; this expanded form is what we'll re-parse when the view is 
Hive,WITHOUT_CLASSIFICATION,// the split is from something other than the 1st file of the logical bucket - compute offset 
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.NotTezEvent.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,//  perform data operation 
Hive,WITHOUT_CLASSIFICATION,// check it has expected version marker 
Hive,WITHOUT_CLASSIFICATION,//  There should really only be one line with "Script failed..." 
Hive,WITHOUT_CLASSIFICATION,//  unequal strings 
Hive,WITHOUT_CLASSIFICATION,//  Bootstrap dump/load 
Hive,WITHOUT_CLASSIFICATION,//  select first 100 and last 100 rows 
Hive,WITHOUT_CLASSIFICATION,//  reduce side work 
Hive,WITHOUT_CLASSIFICATION,//  executed on too small number of reducers. 
Hive,WITHOUT_CLASSIFICATION,//  Use DFS to traverse all the branches until RS or DPP is hit. 
Hive,WITHOUT_CLASSIFICATION,//  first write on a table will allocate write id and rest of the writes should re-use it. 
Hive,WITHOUT_CLASSIFICATION,// ================ 
Hive,WITHOUT_CLASSIFICATION,//  We do not need Zookeeper at the moment 
Hive,WITHOUT_CLASSIFICATION,//  This has to be done synchronously to avoid the caller getting this session again.   Ideally we'd get rid of this thread-local nonsense. 
Hive,WITHOUT_CLASSIFICATION,//  initialize stats publishing table 
Hive,WITHOUT_CLASSIFICATION,//  last item 
Hive,WITHOUT_CLASSIFICATION,//  TS operator 
Hive,WITHOUT_CLASSIFICATION,//  For the case no implicit type conversion e.g. varchar(5) and varchar(10)   pick the common type for all the keys since during run-time same key type is assumed. 
Hive,WITHOUT_CLASSIFICATION,//  let's say that passing null in will not do any filtering. 
Hive,WITHOUT_CLASSIFICATION,//  Has the table changed since the query was cached?   For transactional tables can compare the table writeIDs of the current/cached query. 
Hive,WITHOUT_CLASSIFICATION,// (assume) not a temp table - Try underlying client 
Hive,WITHOUT_CLASSIFICATION,//  Bloom Filter uses binary 
Hive,WITHOUT_CLASSIFICATION,//  We should have some QUERY; and also its parent because by supposition we are in subq. 
Hive,WITHOUT_CLASSIFICATION,//  Skip for tests if WM is not present. 
Hive,WITHOUT_CLASSIFICATION,// driverRun("insert overwrite table rc5318 select * from inpy"); 
Hive,WITHOUT_CLASSIFICATION,//  6.2. Ensure we have stripe metadata. We might have read it before for RG filtering. 
Hive,WITHOUT_CLASSIFICATION,//  a column family become a MAP 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) Xception  */
Hive,WITHOUT_CLASSIFICATION,//  should never come here 
Hive,WITHOUT_CLASSIFICATION,// Plan is using DummyPartition so can only lock the table... unfortunately 
Hive,WITHOUT_CLASSIFICATION,//  This is a catch all state - when containers have not started yet or LLAP has not started yet. 
Hive,WITHOUT_CLASSIFICATION,//  SIGNED comparison to Long.MIN_VALUE decimal. 
Hive,WITHOUT_CLASSIFICATION,//  Cache column-list from this.sd. 
Hive,WITHOUT_CLASSIFICATION,//  if the hostname doesn't contain a port add the configured port to hostname 
Hive,WITHOUT_CLASSIFICATION,/*    * BINARY.    */
Hive,WITHOUT_CLASSIFICATION,//  Null out final members. 
Hive,WITHOUT_CLASSIFICATION,//  beware of any implementation whose hashcode is mutable by reference   inserting into a Map and then changing the hashcode can make it    disappear out of the Map during lookups 
Hive,WITHOUT_CLASSIFICATION,// this simulates the completion of txnid:2 
Hive,WITHOUT_CLASSIFICATION,//  Constructor useful making a projection vectorization context.  E.g. VectorSelectOperator.   Use with resetProjectionColumns and addProjectionColumn. 
Hive,WITHOUT_CLASSIFICATION,//  class Iterator; 
Hive,WITHOUT_CLASSIFICATION,//  If rootNotModified is false then startIndx and endIndx will be stale. 
Hive,WITHOUT_CLASSIFICATION,//  Missing class setting field 
Hive,WITHOUT_CLASSIFICATION,//  The table should also be considered a part of inputs even if the table is a   partitioned table and whether any partition is selected or not 
Hive,WITHOUT_CLASSIFICATION,//  add a fake partition dir on fs 
Hive,WITHOUT_CLASSIFICATION,//  3.2 Rank functions type is 'int'/'double' 
Hive,WITHOUT_CLASSIFICATION,//  Add the path to alias mapping 
Hive,WITHOUT_CLASSIFICATION,//  return array of 6 fields where the last field has the actual data 
Hive,WITHOUT_CLASSIFICATION,//  output column of the ReduceSink operator 
Hive,WITHOUT_CLASSIFICATION,//  write totalSeconds nanos to DataOutput 
Hive,WITHOUT_CLASSIFICATION,//  Serialize context. 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:NotTezEvent) 
Hive,WITHOUT_CLASSIFICATION,//  RequestManager will catch this and handle like any other error. 
Hive,WITHOUT_CLASSIFICATION,/*  if client is requesting fetch-from-start and its not the first time reading from this operation       * then reset the fetch position to beginning        */
Hive,WITHOUT_CLASSIFICATION,//  Necessary to compare against HiveConf defaults as hive-site.xml is not available on task nodes (like AM). 
Hive,WITHOUT_CLASSIFICATION,//  precision 10 
Hive,WITHOUT_CLASSIFICATION,//  add needed columns 
Hive,WITHOUT_CLASSIFICATION,//  Kryo setter 
Hive,WITHOUT_CLASSIFICATION,//  This is dealing with tasks from a different submission and cause the kill   to go out before the previous submissions has completed. Handled in the AM 
Hive,WITHOUT_CLASSIFICATION,//  In strict mode in the presence of order by limit must be specified. 
Hive,WITHOUT_CLASSIFICATION,//  1. Extract join type 
Hive,WITHOUT_CLASSIFICATION,//  a single call to get all column stats for all partitions 
Hive,WITHOUT_CLASSIFICATION,//  ignore the predicate in case it is not a sampling predicate 
Hive,WITHOUT_CLASSIFICATION,//  Duplicates logic in TextMetaDataFormatter 
Hive,WITHOUT_CLASSIFICATION,//  precision 11 
Hive,WITHOUT_CLASSIFICATION,//  Before any activity on the table no open IDs 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * This provides a LazyLong like class which can be initialized from data stored in a   * binary format.   *   * @see org.apache.hadoop.hive.serde2.lazy.LazyObject#init   *        (org.apache.hadoop.hive.serde2.lazy.ByteArrayRef int int)    */
Hive,WITHOUT_CLASSIFICATION,//  The first group. 
Hive,WITHOUT_CLASSIFICATION,//  Start all the Outputs. 
Hive,WITHOUT_CLASSIFICATION,//  Open a txn with no writes. 
Hive,WITHOUT_CLASSIFICATION,//  set hive-site.xml to default hive-site.xml that has embedded metastore 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: here we should use the new partition predicate pushdown API to get a list of pruned list 
Hive,WITHOUT_CLASSIFICATION,//  the max size of memory for buffering records before writes them out 
Hive,WITHOUT_CLASSIFICATION,//  Verify schema 
Hive,WITHOUT_CLASSIFICATION,//  decimalToTimestamp should be consistent with doubleToTimestamp for this level of   precision. 
Hive,WITHOUT_CLASSIFICATION,//  has reached the end of the current batch. Let's fetch the next batch. 
Hive,WITHOUT_CLASSIFICATION,//  Sets the sticky bit on stickyBitDir - now removing file kv1.txt from stickyBitDir by   unprivileged user will result in a DFS error. 
Hive,WITHOUT_CLASSIFICATION,/* ACID tables have complex directory layout and require merging of delta files          * on read thus we should not try to read bucket files directly */
Hive,WITHOUT_CLASSIFICATION,//  ExprNodeColumnDesc ExprNodeConstantDesc ExprNodeDynamicValueDesc etc do not have   LEAD/LAG inside. 
Hive,WITHOUT_CLASSIFICATION,//  If it is not an INSERT we do not need to anything 
Hive,WITHOUT_CLASSIFICATION,//  CAPABILITIES 
Hive,WITHOUT_CLASSIFICATION,//  existsOrdering AND existsPartitioning should be false. 
Hive,WITHOUT_CLASSIFICATION,//  LOG.debug(CLASS_NAME + " logical " + logical + " batchIndex " + batchIndex + " NULL"); 
Hive,WITHOUT_CLASSIFICATION,//  \1 followed by each key and then each value 
Hive,WITHOUT_CLASSIFICATION,//  Append task specific info to stagingPathName instead of creating a sub-directory.   This way we don't have to worry about deleting the stagingPathName separately at   end of query execution. 
Hive,WITHOUT_CLASSIFICATION,//  because divisor is negative quotient is at most 1.   remainder must be dividend itself (quotient=0) or dividend -   divisor 
Hive,WITHOUT_CLASSIFICATION,//  f(0) is always 1 
Hive,WITHOUT_CLASSIFICATION,//  F | unknown | unknown 
Hive,WITHOUT_CLASSIFICATION,//  Empty value too. 
Hive,WITHOUT_CLASSIFICATION,//  System.err.println(c.requesturi); 
Hive,WITHOUT_CLASSIFICATION,/*  * Cache of delegation tokens.  When {@link TempletonControllerJob} submits a job that requires * metastore access and this access should be secure TCJ will add a delegation token to the * submitted job.  When the job completes we need to cancel the token since by default the token * lives for 7 days and over time can cause OOM (if not cancelled).  Cancelling from  * TempletonControllerJob.LauchMapper mapper (via custom OutputCommitter for example) requires * the jar containing HiveMetastoreClient (and any dependent jars) to be available on the node * running LaunchMapper.  Specifying transitive closure of the necessary jars is  * configuration/maintenance headache for each release.  Caching the token means cancellation is  * done from WebHCat server and thus has Hive jars on the classpath. *  * While it's possible that WebHCat crashes and looses this in-memory state but this would be an * exceptional condition and since tokens will automatically be cancelled after 7 days  * the fact that this info is not persisted is OK.  (Persisting it also complicates things  * because that needs to be done securely) * @see TempletonControllerJob  */
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setNClob(java.lang.String java.sql.NClob)    */
Hive,WITHOUT_CLASSIFICATION,//  search for the key 
Hive,WITHOUT_CLASSIFICATION,//  RENAME_TABLE EVENT to unpartitioned table 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) Service  */
Hive,WITHOUT_CLASSIFICATION,//  first find out if any of the jobs needs to run non-locally 
Hive,WITHOUT_CLASSIFICATION,// sort for readability 
Hive,WITHOUT_CLASSIFICATION,//  it matters only for permanent functions 
Hive,WITHOUT_CLASSIFICATION,//  keep a mapping from tag to the fetch operator alias 
Hive,WITHOUT_CLASSIFICATION,//  COL_NAMES 
Hive,WITHOUT_CLASSIFICATION,/*  storage of table could be on any storage system: hbase cassandra etc.  */
Hive,WITHOUT_CLASSIFICATION,//  The results of this query execution might be cacheable.   Add a placeholder entry in the cache so other queries know this result is pending. 
Hive,WITHOUT_CLASSIFICATION,/*    * If this task contains a join it can be converted to a map-join task if this operator is   * present in the mapper. For eg. if a sort-merge join operator is present followed by a regular   * join it cannot be converted to a auto map-join.    */
Hive,WITHOUT_CLASSIFICATION,//  (and those from IN(...) follow it) 
Hive,WITHOUT_CLASSIFICATION,//  UNDONE: Inner count 
Hive,WITHOUT_CLASSIFICATION,//  No multi-parameter aggregations supported. 
Hive,WITHOUT_CLASSIFICATION,//  Attempt to delete temp file if this fails not much can be done about it. 
Hive,WITHOUT_CLASSIFICATION,//  check this because "123 << 32" will be 123. 
Hive,WITHOUT_CLASSIFICATION,/*    * Inner join (hash map).    */
Hive,WITHOUT_CLASSIFICATION,/*    * Allocate the source conversion related arrays (optional).    */
Hive,WITHOUT_CLASSIFICATION,// Test regular outputformat 
Hive,WITHOUT_CLASSIFICATION,//  5. Create Join rel 
Hive,WITHOUT_CLASSIFICATION,//  merge should update registers and hence the count 
Hive,WITHOUT_CLASSIFICATION,//  hive conf 
Hive,WITHOUT_CLASSIFICATION,//  Do not check the state - this is coming from the updater under epic lock. 
Hive,WITHOUT_CLASSIFICATION,//  Pre-allocated member for storing the (physical) batch index of matching row (single- or 
Hive,WITHOUT_CLASSIFICATION,//  First determine whether rounding is necessary based on rounding point which is inside   integer part.  And get rid of any fractional digits.  The result scale will be 0. 
Hive,WITHOUT_CLASSIFICATION,//  Now check QB in more detail. canHandleQbForCbo returns null if query can 
Hive,WITHOUT_CLASSIFICATION,//  an error occurred re-try 
Hive,WITHOUT_CLASSIFICATION,//  TODO: the only reason this is done this way is because we want unique Subject-s so that         the FS.get gives different FS objects to different fragments. 
Hive,WITHOUT_CLASSIFICATION,// todo: make these like OperationType and remove above char constatns 
Hive,WITHOUT_CLASSIFICATION,//  We recursively create the exprNodeDesc. Base cases: when we encounter   a column ref we convert that into an exprNodeColumnDesc; when we   encounter   a constant we convert that into an exprNodeConstantDesc. For others we   just   build the exprNodeFuncDesc with recursively built children. 
Hive,WITHOUT_CLASSIFICATION,//  verify when second argument is repeating 
Hive,WITHOUT_CLASSIFICATION,// no exception should be thrown 
Hive,WITHOUT_CLASSIFICATION,//  We provide a faster way to write a hive interval year month without a HiveIntervalYearMonth object. 
Hive,WITHOUT_CLASSIFICATION,//  strip off the STOP marker which may be left if all the fields were in   the serialization 
Hive,WITHOUT_CLASSIFICATION,//  have different settings from those of HiveServer2. 
Hive,WITHOUT_CLASSIFICATION,//  Prepare prefix and suffix 
Hive,WITHOUT_CLASSIFICATION,//  all table column names 
Hive,WITHOUT_CLASSIFICATION,//  uri is added later 
Hive,WITHOUT_CLASSIFICATION,//  We assume the caller will handle extra columns default with nulls etc. 
Hive,WITHOUT_CLASSIFICATION,//  this is only useful for the daemons to know themselves 
Hive,WITHOUT_CLASSIFICATION,//  TODO: check defaults: maxTimeout keepalive maxBodySize   bodyRecieveDuration etc. 
Hive,WITHOUT_CLASSIFICATION,//  Currently we support LazySimple deserialization:        org.apache.hadoop.mapred.TextInputFormat      org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe     AND        org.apache.hadoop.mapred.SequenceFileInputFormat      org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe 
Hive,WITHOUT_CLASSIFICATION,//  set permissions for current user on DAG 
Hive,WITHOUT_CLASSIFICATION,/*      * 1. On encountering a DOT we attempt to resolve the leftmost name     *    to the Parent Query.     * 2. An unqualified name is assumed to be a SubQuery reference.     *    We don't attempt to resolve this to the Parent; because     *    we require all Parent column references to be qualified.     * 3. All other expressions have a Type based on their children.     *    An Expr w/o children is assumed to refer to neither.      */
Hive,WITHOUT_CLASSIFICATION,//  + ")"; 
Hive,WITHOUT_CLASSIFICATION,//  Update table stats. For partitioned table we update stats in alterPartition() 
Hive,WITHOUT_CLASSIFICATION,//  A: 1/1 running 1 queued; B: 2/2 running C: 1/2 running D: 1/1 running 1 queued. 
Hive,WITHOUT_CLASSIFICATION,//  verify NULL output in entry 1 is correct 
Hive,WITHOUT_CLASSIFICATION,/*    * The JDBC spec says when you have duplicate column names   * the first one should be returned.    */
Hive,WITHOUT_CLASSIFICATION,//  leftFast2 != 0 && leftFast1 == 0. 
Hive,WITHOUT_CLASSIFICATION,//  try to find the file on the include path 
Hive,WITHOUT_CLASSIFICATION,//  Find the buddy of the header at list level. We don't know what list it is actually in. 
Hive,WITHOUT_CLASSIFICATION,//  We are in a stack trace 
Hive,WITHOUT_CLASSIFICATION,//  Move all the partition columns at the end of table columns. 
Hive,WITHOUT_CLASSIFICATION,//  no errors are tolerated 
Hive,WITHOUT_CLASSIFICATION,/*  1 files x 1000 size for 111 splits  */
Hive,WITHOUT_CLASSIFICATION,//  If there's a delegation token available then use token based connection 
Hive,WITHOUT_CLASSIFICATION,//  Use that as the "current user" 
Hive,WITHOUT_CLASSIFICATION,//  Start a third batch abortTransaction everything don't properly close it 
Hive,WITHOUT_CLASSIFICATION,//  We call copyFromLocal below so we basically assume src is a local file. 
Hive,WITHOUT_CLASSIFICATION,//  We cannot push limit; bail out 
Hive,WITHOUT_CLASSIFICATION,/*  *  */
Hive,WITHOUT_CLASSIFICATION,/*    * This TableScanDesc flag is strictly set by the Vectorizer class for vectorized MapWork   * vertices.    */
Hive,WITHOUT_CLASSIFICATION,//  most likely this value should not exist 
Hive,WITHOUT_CLASSIFICATION,//  Clear away any residue from our optimizations. 
Hive,WITHOUT_CLASSIFICATION,//  If inputs are not equal we could zip up till here 
Hive,WITHOUT_CLASSIFICATION,//  Void can go to anything 
Hive,WITHOUT_CLASSIFICATION,//  #2 - UTC epoch for instant 
Hive,WITHOUT_CLASSIFICATION,//  Configure getPassword() to fall back to conf if credential doesn't have entry  
Hive,WITHOUT_CLASSIFICATION,//  Batch is full AND we have at least 1 more row... 
Hive,WITHOUT_CLASSIFICATION,// change value of a metavar config param in new hive conf 
Hive,WITHOUT_CLASSIFICATION,//  else create a new one 
Hive,WITHOUT_CLASSIFICATION,//  read logs 
Hive,WITHOUT_CLASSIFICATION,//  No valid inputs. 
Hive,WITHOUT_CLASSIFICATION,//  Start delegation token manager 
Hive,WITHOUT_CLASSIFICATION,//  For reasons that are completely incomprehensible to me the semantic   analyzers often ask for multiple locks on the same entity (for example   a shared_read and an exlcusive lock).  The db locking system gets confused   by this and dead locks on it.  To resolve that we'll make sure in the   request that multiple locks are coalesced and promoted to the higher   level of locking.  To do this we put all locks components in trie based   on dbname tablename partition name and handle the promotion as new   requests come in.  This structure depends on the fact that null is a   valid key in a LinkedHashMap.  So a database lock will map to (dbname null   null). 
Hive,WITHOUT_CLASSIFICATION,//  Non-empty java opts without -Xmx specified 
Hive,WITHOUT_CLASSIFICATION,//  100 < x   start exclusive to infinity 
Hive,WITHOUT_CLASSIFICATION,// in the clientUgi 
Hive,WITHOUT_CLASSIFICATION,//  this command has terminated 
Hive,WITHOUT_CLASSIFICATION,//  6. Iterate over all expression (after SELECT) 
Hive,WITHOUT_CLASSIFICATION,//  Delete the data in the table 
Hive,WITHOUT_CLASSIFICATION,//  Server thread pool   Start with minWorkerThreads expand till maxWorkerThreads and reject 
Hive,WITHOUT_CLASSIFICATION,// i.e. it's the 1st WHEN MATCHED 
Hive,WITHOUT_CLASSIFICATION,// Tag of union field is the first byte to be parsed 
Hive,WITHOUT_CLASSIFICATION,//  Update our counts for the last key. 
Hive,WITHOUT_CLASSIFICATION,//  initialize the lazy object 
Hive,WITHOUT_CLASSIFICATION,/*   */
Hive,WITHOUT_CLASSIFICATION,//  that we will propagate to the inputs of the join 
Hive,WITHOUT_CLASSIFICATION,//  In "select * from table" situations (non-MR) we can add things to the job   It's safe to add this to the job since it's not *actually* a mapred job. 
Hive,WITHOUT_CLASSIFICATION,// Protect against a bad location being requested. 
Hive,WITHOUT_CLASSIFICATION,/*  New method that distributes the Select query by creating splits containing   * information about different Druid nodes that have the data for the given   * query.  */
Hive,WITHOUT_CLASSIFICATION,//  ARRAY_ENTRY 
Hive,WITHOUT_CLASSIFICATION,//  step 2 (ANALYZE_STATE.ANALYZING) explain the query and provide the runtime #rows collected. 
Hive,WITHOUT_CLASSIFICATION,//  Now try to find the file based on SHA and name. Currently we require exact name match. 
Hive,WITHOUT_CLASSIFICATION,//  dummy ops need to be updated to the cloned ones. 
Hive,WITHOUT_CLASSIFICATION,//  tablescan and join operators. 
Hive,WITHOUT_CLASSIFICATION,//  Any more left? 
Hive,WITHOUT_CLASSIFICATION,//  MAP_ENTRY 
Hive,WITHOUT_CLASSIFICATION,//  When overwriting we just start with empty timeline 
Hive,WITHOUT_CLASSIFICATION,// Expand the array 
Hive,WITHOUT_CLASSIFICATION,// when set to true use the overflow checked vector expressions 
Hive,WITHOUT_CLASSIFICATION,//  Doesn't support creating VRBs. 
Hive,WITHOUT_CLASSIFICATION,//  Generate result within big table batch itself. 
Hive,WITHOUT_CLASSIFICATION,//  dummy alias: just use the input path 
Hive,WITHOUT_CLASSIFICATION,//  We've found something that matches what we're trying to lock 
Hive,WITHOUT_CLASSIFICATION,//  if numPartitions could not be obtained from ORM filters then get number partitions names and count them 
Hive,WITHOUT_CLASSIFICATION,//  -yyyyyyy-mm  : should be more than enough 
Hive,WITHOUT_CLASSIFICATION,//  5. Gather GB Physical pipeline (based on user config & Grping Sets size) 
Hive,WITHOUT_CLASSIFICATION,// read friendly string: ak[EXT]av[STX]bk[ETX]bv[STX]ck[ETX]cv[STX]dk[ETX]dv 
Hive,WITHOUT_CLASSIFICATION,// Set HADOOP_USER_NAME env variable for child process so that   it also runs with hadoop permissions for the user the job is running as 
Hive,WITHOUT_CLASSIFICATION,//  add -r and --dry-run to generate list only 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc) we should ideally not modify the tree we traverse. However   * since we need to walk the tree at any time when we modify the operator we   * might as well do it here.    */
Hive,WITHOUT_CLASSIFICATION,//  This function should be overriden in every sub class   And the sub class should call super.init(m parameters) to get mode set. 
Hive,WITHOUT_CLASSIFICATION,//  we failed to submit after retrying. Destroy session and bail. 
Hive,WITHOUT_CLASSIFICATION,//  Negative power with range -- adjust the scale. 
Hive,WITHOUT_CLASSIFICATION,//  should copy properties first 
Hive,WITHOUT_CLASSIFICATION,// https://commons.apache.org/proper/commons-pool/api-1.6/org/apache/commons/pool/impl/GenericObjectPool.html#setMaxActive(int) 
Hive,WITHOUT_CLASSIFICATION,//  converted to sort-merge join 
Hive,WITHOUT_CLASSIFICATION,// List<RolePrincipalGrant> roleGrantsList = getRolePrincipalGrants(roleMaps); 
Hive,WITHOUT_CLASSIFICATION,//  Second incremental dump 
Hive,WITHOUT_CLASSIFICATION,//  queryDirectory should not be null 
Hive,WITHOUT_CLASSIFICATION,//  Go over all the destination structures and populate the related 
Hive,WITHOUT_CLASSIFICATION,//  Append prefix 
Hive,WITHOUT_CLASSIFICATION,//  exhausted the batch no longer have to heartbeat for current txn batch 
Hive,WITHOUT_CLASSIFICATION,//  involving constant true/false values. 
Hive,WITHOUT_CLASSIFICATION,//  replace the "commar" to finish a 'IN' clause string. 
Hive,WITHOUT_CLASSIFICATION,/*  there are nulls  */
Hive,WITHOUT_CLASSIFICATION,//  Any redirect handlers need to be added first 
Hive,WITHOUT_CLASSIFICATION,//  To avoid reading the footer twice we will cache it first and then read from cache.   Parquet calls protobuf methods directly on the stream and we can't get bytes after the fact. 
Hive,WITHOUT_CLASSIFICATION,// create failed compactions 
Hive,WITHOUT_CLASSIFICATION,//  GBY without distinct keys is not prepared to process distinct key structured rows. 
Hive,WITHOUT_CLASSIFICATION,//  it is a column i.e. a column-family with column-qualifier 
Hive,WITHOUT_CLASSIFICATION,//  Evaluate the keys 
Hive,WITHOUT_CLASSIFICATION,//  Replicate all the events except DROP 
Hive,WITHOUT_CLASSIFICATION,//  TODO: Maybe throw AlreadyExistsException. 
Hive,WITHOUT_CLASSIFICATION,//                c 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise notify about Spark jobs after the state notification. 
Hive,WITHOUT_CLASSIFICATION,/*    * Grouping sets members.    */
Hive,WITHOUT_CLASSIFICATION,//  Do nothing 
Hive,WITHOUT_CLASSIFICATION,// this code doesn't propagate      Assert.assertEquals("Wrong msg" ErrorMsg.CTAS_PARCOL_COEXISTENCE.getErrorCode() cpr.getErrorCode()); 
Hive,WITHOUT_CLASSIFICATION,//  Note: it's rather important that this (and other methods) catch Exception not Throwable;   in combination with HiveSessionProxy.invoke code perhaps unintentionally it used   to also catch all errors; and now it allows OOMs only to propagate. 
Hive,WITHOUT_CLASSIFICATION,//  not an event dump not a table dump - thus a db dump 
Hive,WITHOUT_CLASSIFICATION,//  Last try: we try to parse it as date and transform 
Hive,WITHOUT_CLASSIFICATION,//  walk. 
Hive,WITHOUT_CLASSIFICATION,//  Re-setting the queue config is an old hack that we may remove in future. 
Hive,WITHOUT_CLASSIFICATION,//  to trigger vectorForward 
Hive,WITHOUT_CLASSIFICATION,//  non-verbose pattern is %-5p : %m%n. Look for " : " 
Hive,WITHOUT_CLASSIFICATION,//  Make sure result precision/scale matches the input prec/scale 
Hive,WITHOUT_CLASSIFICATION,//  optimize this newWork given the big table position 
Hive,WITHOUT_CLASSIFICATION,//  Someone is allocating this arena. Wait a bit and recheck. 
Hive,WITHOUT_CLASSIFICATION,//  to disk for the Hybrid Grace hash partitioning. 
Hive,WITHOUT_CLASSIFICATION,//  will trigger 2 spills 
Hive,WITHOUT_CLASSIFICATION,//  The child tasks may be null in case of a select 
Hive,WITHOUT_CLASSIFICATION,//  Going through file list and make the retry list 
Hive,WITHOUT_CLASSIFICATION,//  verifying that method is supported 
Hive,WITHOUT_CLASSIFICATION,//  5. We create the new filter that might be pushed down 
Hive,WITHOUT_CLASSIFICATION,//  dummy operator (for not increasing seqId) 
Hive,WITHOUT_CLASSIFICATION,//  join keys dont match the bucketing keys 
Hive,WITHOUT_CLASSIFICATION,//  get current input file name 
Hive,WITHOUT_CLASSIFICATION,//  nothing needed here by default 
Hive,WITHOUT_CLASSIFICATION,//  set yarn queue name 
Hive,WITHOUT_CLASSIFICATION,//  go into the doAs below. 
Hive,WITHOUT_CLASSIFICATION,//  V1 to V2 conversion. 
Hive,WITHOUT_CLASSIFICATION,//  _hive.tmp_table_space _hive.hdfs.session.path and _hive.local.session.path are respectively   saved in hdfsTmpTableSpace hdfsSessionPath and localSessionPath.  Saving them as conf   variables is useful to expose them to end users.  But end users shouldn't change them. 
Hive,WITHOUT_CLASSIFICATION,//  Test new HCatAddPartitionsDesc API. 
Hive,WITHOUT_CLASSIFICATION,//  Chooses a representative alias and index to use as the String the first is used because   it is set in the constructor 
Hive,WITHOUT_CLASSIFICATION,//  This won't go into checkAndSend. 
Hive,WITHOUT_CLASSIFICATION,//  A statement should be open even after ResultSet#close 
Hive,WITHOUT_CLASSIFICATION,//  2. CPU cost = sorting cost 
Hive,WITHOUT_CLASSIFICATION,//  Last batch can sometimes have less number of elements 
Hive,WITHOUT_CLASSIFICATION,/*  Spot check correctness of decimal scalar multiply decimal column. The case for   * addition checks all the cases for the template so don't do that redundantly here.    */
Hive,WITHOUT_CLASSIFICATION,//  create conditional task and insert conditional task into task tree 
Hive,WITHOUT_CLASSIFICATION,/*  trimBlanks  */
Hive,WITHOUT_CLASSIFICATION,//  Add a mapping from the table scan operator to Table 
Hive,WITHOUT_CLASSIFICATION,//  Relying on watchService.close to clean up all pending watches 
Hive,WITHOUT_CLASSIFICATION,//  bypass for explain queries for now 
Hive,WITHOUT_CLASSIFICATION,//  Exclude all standard table properties. 
Hive,WITHOUT_CLASSIFICATION,//  Now the most important check - when we query this record for its schema 
Hive,WITHOUT_CLASSIFICATION,//  These schemata are used in other tests 
Hive,WITHOUT_CLASSIFICATION,/*  Get a [NOT] BETWEEN filter expression. This is treated as a special case   * because the NOT is actually specified in the expression tree as the first argument   * and we don't want any runtime cost for that. So creating the VectorExpression   * needs to be done differently than the standard way where all arguments are   * passed to the VectorExpression constructor.    */
Hive,WITHOUT_CLASSIFICATION,//  When selectedInUse is set to false everything in the batch is selected. 
Hive,WITHOUT_CLASSIFICATION,//  This is effectively DAG completed and can be used to reset statistics being tracked. 
Hive,WITHOUT_CLASSIFICATION,//  get the object inspector for MyRow 
Hive,WITHOUT_CLASSIFICATION,//  Note: Enhance showResourcePlan to display all the pools triggers and mappings. 
Hive,WITHOUT_CLASSIFICATION,//  Not HiveInputFormat or a custom VertexManager will take care of grouping splits 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#execute(java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,/*      * If the query was the result of analyze table column compute statistics rewrite create     * a column stats task instead of a fetch task to persist stats to the metastore.     * As per HIVE-15903 we will also collect table stats when user computes column stats.     * That means if isCStats || !pCtx.getColumnStatsAutoGatherContexts().isEmpty()     * We need to collect table stats     * if isCStats we need to include a basic stats task     * else it is ColumnStatsAutoGather which should have a move task with a stats task already.      */
Hive,WITHOUT_CLASSIFICATION,//  that follows it. This is used for connecting them later. 
Hive,WITHOUT_CLASSIFICATION,//  allow +/- 
Hive,WITHOUT_CLASSIFICATION,//  verify cm.recycle(db table part) api moves file to cmroot dir 
Hive,WITHOUT_CLASSIFICATION,//  this means no partition exists for the given partition   key value pairs - thrift cannot handle null return values hence   getPartition() throws NoSuchObjectException to indicate null partition 
Hive,WITHOUT_CLASSIFICATION,//  Try to read the default named url from the connection configuration file 
Hive,WITHOUT_CLASSIFICATION,//  We already retrieved the incoming info check without UGI. 
Hive,WITHOUT_CLASSIFICATION,//  We need to track this as some listeners pass it through our config and we need to honor 
Hive,WITHOUT_CLASSIFICATION,// Work 
Hive,WITHOUT_CLASSIFICATION,//  Notification is generated for newly created partitions only. The subset of partitions 
Hive,WITHOUT_CLASSIFICATION,//  DB-level REPL LOADs testing done now moving on to table level repl loads.   In each of these cases the table-level repl.last.id must move forward but the   db-level last.repl.id must not. 
Hive,WITHOUT_CLASSIFICATION,// may flood the log 
Hive,WITHOUT_CLASSIFICATION,//  By hive 0.13 we should remove this code. 
Hive,WITHOUT_CLASSIFICATION,// this creates an ORC data file with correct schema under table root 
Hive,WITHOUT_CLASSIFICATION,//  End RelMdParallelism.java 
Hive,WITHOUT_CLASSIFICATION,//  check aggOutputProject projects only one expression 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#prepareStatement(java.lang.String int int int)    */
Hive,WITHOUT_CLASSIFICATION,//  Wait for all threads to be ready. 
Hive,WITHOUT_CLASSIFICATION,//  log a warning incase no reporters were successfully added 
Hive,WITHOUT_CLASSIFICATION,//  This is a true DROP TABLE 
Hive,WITHOUT_CLASSIFICATION,//  is the left was at the left side of a right outer join? 
Hive,WITHOUT_CLASSIFICATION,//  metastore schema only allows maximum 255 for constraint value column 
Hive,WITHOUT_CLASSIFICATION,//  different or duplicate some other function). 
Hive,WITHOUT_CLASSIFICATION,//  LogicalProject maps a set of rows to a different set;   Without knowledge of the mapping function(whether it   preserves uniqueness) it is only safe to derive uniqueness   info from the child of a project when the mapping is f(a) => a.     Further more the unique bitset coming from the child needs   to be mapped to match the output of the project. 
Hive,WITHOUT_CLASSIFICATION,//  test third IF argument repeating 
Hive,WITHOUT_CLASSIFICATION,//  At this point we don't have to do anything special. Just   run through the regular paces w/o creating a new task. 
Hive,WITHOUT_CLASSIFICATION,//  if partition is not found   it is DESCRIBE table partition 
Hive,WITHOUT_CLASSIFICATION,//  No customization of this API is done for most Authorization implementations. It is meant    to be used for special cases in Apache Sentry (incubating)   null is to be returned when no customization is needed for the translator   see javadoc in interface for details. 
Hive,WITHOUT_CLASSIFICATION,//  create OperationLog object with above log file 
Hive,WITHOUT_CLASSIFICATION,//  test long->string version 
Hive,WITHOUT_CLASSIFICATION,//  this input rel does not produce the cor var needed 
Hive,WITHOUT_CLASSIFICATION,//  Inject a behavior where REPL LOAD failed when try to load table "t2" it fails. 
Hive,WITHOUT_CLASSIFICATION,//  for set role ALL reset roles to default roles. 
Hive,WITHOUT_CLASSIFICATION,//  num executors is less than max executors per query (which is not expected case) default executors will be 
Hive,WITHOUT_CLASSIFICATION,//  make sure that they have the same type 
Hive,WITHOUT_CLASSIFICATION,//  When selectedInUse is true start with every bit set to false and selectively set   certain bits to true based on the selected[] vector. 
Hive,WITHOUT_CLASSIFICATION,/*    * LIST.    */
Hive,WITHOUT_CLASSIFICATION,//  Fits in one longword. 
Hive,WITHOUT_CLASSIFICATION,//  38 decimal maximum - 32 digits in 2 lower longs (6 digits here). 
Hive,WITHOUT_CLASSIFICATION,/*  isLastGroupBatch  */
Hive,WITHOUT_CLASSIFICATION,//  precision 12 
Hive,WITHOUT_CLASSIFICATION,//  We are going to serialize using the 4 basic types. 
Hive,WITHOUT_CLASSIFICATION,//  If the first shot fails then we log the waiting messages. 
Hive,WITHOUT_CLASSIFICATION,//  Now filter. 
Hive,WITHOUT_CLASSIFICATION,//  Now serialize 
Hive,WITHOUT_CLASSIFICATION,//  Note that we cache each slice separately. We could cache them together at the end but   then we won't be able to pass them to users without inc-refing explicitly. 
Hive,WITHOUT_CLASSIFICATION,//  2. Walk through OB exprs and extract field collations and additional 
Hive,WITHOUT_CLASSIFICATION,//  Start by only serializing primitives as-is 
Hive,WITHOUT_CLASSIFICATION,//  If no join then there should only be either 1 TS or 1 SubQuery 
Hive,WITHOUT_CLASSIFICATION,//  Various errors when creating Spark client 
Hive,WITHOUT_CLASSIFICATION,//  its children's parents lists also see childOperatorsTag in Operator) at here. 
Hive,WITHOUT_CLASSIFICATION,// Expecting NOT to change the size of internal structures 
Hive,WITHOUT_CLASSIFICATION,//  initialize destination table/partition 
Hive,WITHOUT_CLASSIFICATION,//  set the bit to 1 if a key is not null 
Hive,WITHOUT_CLASSIFICATION,// There is another batch to buffer 
Hive,WITHOUT_CLASSIFICATION,//  CHECK_CONSTRAINTS 
Hive,WITHOUT_CLASSIFICATION,//  If the first child is a TOK_TABLE_OR_COL and nodeOutput[0] is NULL 
Hive,WITHOUT_CLASSIFICATION,//  Friday 30th August 1985 02:00:00 AM 
Hive,WITHOUT_CLASSIFICATION,//   This optimizer will serialize all filters that made it to the    table scan operator to avoid having to do it multiple times on    the backend. If you have a physical optimization that changes    table scans or filters you have to invoke it before this one. 
Hive,WITHOUT_CLASSIFICATION,//  if it does not end with " then it is line continuation 
Hive,WITHOUT_CLASSIFICATION,//  if tbl location is available use it   else derive the tbl location from database location 
Hive,WITHOUT_CLASSIFICATION,//  precision 13 
Hive,WITHOUT_CLASSIFICATION,//  MY_STRING_STRING_MAP 
Hive,WITHOUT_CLASSIFICATION,//  Database name or pattern 
Hive,WITHOUT_CLASSIFICATION,//  this shouldn't happen. The parser should have converted the union to be   contained in a subquery. Just in case we keep the error as a fallback. 
Hive,WITHOUT_CLASSIFICATION,//  column list 
Hive,WITHOUT_CLASSIFICATION,//  Update cached aggregate stats for all partitions of a table and for all 
Hive,WITHOUT_CLASSIFICATION,//  prefix for window functions to discern LEAD/LAG UDFs from window functions with the same name 
Hive,WITHOUT_CLASSIFICATION,//  its either a file or glob 
Hive,WITHOUT_CLASSIFICATION,/*  wantWritable  */
Hive,WITHOUT_CLASSIFICATION,//  these anyway. 
Hive,WITHOUT_CLASSIFICATION,//  0 0   0 1 
Hive,WITHOUT_CLASSIFICATION,//  Exclude constants. Aggregate({true}) occurs because Aggregate({})   would generate 1 row even when applied to an empty table. 
Hive,WITHOUT_CLASSIFICATION,//  required   required 
Hive,WITHOUT_CLASSIFICATION,//  Verify the writeId of this committed txn should be invalid for test txn. 
Hive,WITHOUT_CLASSIFICATION,//  if data size is still 0 then get file size 
Hive,WITHOUT_CLASSIFICATION,//  select from  the new table should pass 
Hive,WITHOUT_CLASSIFICATION,//  For pfile calculate the checksum for use in testing 
Hive,WITHOUT_CLASSIFICATION,//  Optimize: whole decimal fits in two binary words. 
Hive,WITHOUT_CLASSIFICATION,//  If semijoin keys and ts keys completely unrelated the cardinality of both sets   could be obtained by adding both cardinalities. Would there be an average case? 
Hive,WITHOUT_CLASSIFICATION,//  selPair.getKey() is the operator right before OB   selPair.getValue() is RR which only contains columns needed in result   set. Extra columns needed by order by will be absent from it. 
Hive,WITHOUT_CLASSIFICATION,//  precision 14 
Hive,WITHOUT_CLASSIFICATION,//  No validation. 
Hive,WITHOUT_CLASSIFICATION,//  remember which mapjoin operator links with which work 
Hive,WITHOUT_CLASSIFICATION,//  2. deal with static partition columns 
Hive,WITHOUT_CLASSIFICATION,//  Check all the operators in the stack. Currently only SELECTs and FILTERs 
Hive,WITHOUT_CLASSIFICATION,//  Examine all digits being thrown away to determine if result is 0 or 1. 
Hive,WITHOUT_CLASSIFICATION,//  5. Let Cleaner delete obsolete files/dirs 
Hive,WITHOUT_CLASSIFICATION,//  generate the local work for the big table alias 
Hive,WITHOUT_CLASSIFICATION,//  in the absence of column statistics compute data size based on   based on average row size 
Hive,WITHOUT_CLASSIFICATION,//  Project the columns of the GROUP BY plus the arguments   to the agg function. 
Hive,WITHOUT_CLASSIFICATION,//  Calcite expects the grouping sets sorted and without duplicates 
Hive,WITHOUT_CLASSIFICATION,/*      * group grants      */
Hive,WITHOUT_CLASSIFICATION,//  LFU extreme order of accesses should be ignored only frequency matters.   We touch first elements later but do it less times so they will be evicted first. 
Hive,WITHOUT_CLASSIFICATION,// since setStructFieldData and create return a list getStructFieldData should be able to  handle list data. This is required when table serde is ParquetHiveSerDe and partition serde  is something else. 
Hive,WITHOUT_CLASSIFICATION,//  Bootstrap Repl A -> B 
Hive,WITHOUT_CLASSIFICATION,/*   we handle three types of scenarios with special case.  1. handling of db Level _metadata  2. handling of subsequent loadTask which will start running from the previous replicationState  3. other events : these can only be either table / function _metadata.    */
Hive,WITHOUT_CLASSIFICATION,//  n-way join   It has been calculated in HashTableLoader earlier so just need to retrieve that number 
Hive,WITHOUT_CLASSIFICATION,//  partitioned input not sorted. 
Hive,WITHOUT_CLASSIFICATION,// --------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  We assume millisLocal is midnight of some date. What we are basically trying to do   here is go from local-midnight to UTC-midnight (or whatever time that happens to be). 
Hive,WITHOUT_CLASSIFICATION,//  Read the configuration parameters 
Hive,WITHOUT_CLASSIFICATION,//  precision 15 
Hive,WITHOUT_CLASSIFICATION,//  grant 
Hive,WITHOUT_CLASSIFICATION,//  1. If it is not an OR operator we bail out. 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   required   required   required   required   required   required   required   required   required   required   required   optional 
Hive,WITHOUT_CLASSIFICATION,//  Use TerminateFragmentRequestProto.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,//  Re-map arguments. 
Hive,WITHOUT_CLASSIFICATION,//  No static partition specified 
Hive,WITHOUT_CLASSIFICATION,//  the bottom aggregate has converted the DISTINCT aggregate to a group by clause. 
Hive,WITHOUT_CLASSIFICATION,//  mapping of bucket id to number of required tasks to run 
Hive,WITHOUT_CLASSIFICATION,//  using different code blocks so that jdbc variables are not accidently re-used   between the actions. Different connection/statement object should be used for each action. 
Hive,WITHOUT_CLASSIFICATION,//  future only takes final or seemingly final values. Make a final copy of taskId 
Hive,WITHOUT_CLASSIFICATION,/*  * The equality is implemented fully the implementation sorts the maps * by their keys to provide a transitive compare.   */
Hive,WITHOUT_CLASSIFICATION,// from the map jobs) 
Hive,WITHOUT_CLASSIFICATION,//  Grand-parent works - we need to set these to be the parents of the cloned works. 
Hive,WITHOUT_CLASSIFICATION,//  Save last longword. 
Hive,WITHOUT_CLASSIFICATION,//  precision 16 
Hive,WITHOUT_CLASSIFICATION,//  Nothing to update if everything is the same 
Hive,WITHOUT_CLASSIFICATION,//  Sequence of TableScan operators to be walked 
Hive,WITHOUT_CLASSIFICATION,//  resFile   pCtx   RootTasks   FetchTask   analyzer  explainConfig   cboInfo 
Hive,WITHOUT_CLASSIFICATION,// Update table schema to add the newly added columns 
Hive,WITHOUT_CLASSIFICATION,//                   ----------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  Delete the data 
Hive,WITHOUT_CLASSIFICATION,//  Add the setRCols to the input list 
Hive,WITHOUT_CLASSIFICATION,//  Don't eat and wrap RuntimeExceptions because the ObjectBuffer.write...   handles SerializationException specifically (resizing the buffer)... 
Hive,WITHOUT_CLASSIFICATION,//  that something is blocking it that would not block a read. 
Hive,WITHOUT_CLASSIFICATION,//  Re-throw without losing original stack trace. 
Hive,WITHOUT_CLASSIFICATION,//  Create the root of the operator tree 
Hive,WITHOUT_CLASSIFICATION,//  flip the boolean variable 
Hive,WITHOUT_CLASSIFICATION,//  copy the DP column values from the input row to dpVals 
Hive,WITHOUT_CLASSIFICATION,//  Template expansion logic is the same for both column-scalar and scalar-column cases. 
Hive,WITHOUT_CLASSIFICATION,//  precision 17 
Hive,WITHOUT_CLASSIFICATION,//  SparkWork dependency graph - from a SparkWork with MJ operators to all 
Hive,WITHOUT_CLASSIFICATION,//  Don't bother cleaning from the txns table.  A separate call will do that.  We don't   know here which txns still have components from other tables or partitions in the   table so we don't know which ones we can and cannot clean. 
Hive,WITHOUT_CLASSIFICATION,//  Record this change in the metastore 
Hive,WITHOUT_CLASSIFICATION,//  if the TEST*.xml was not generated or was corrupt let someone know 
Hive,WITHOUT_CLASSIFICATION,// assert false; 
Hive,WITHOUT_CLASSIFICATION,//  Get delegation token for user from filesystem and write the token along with   metastore tokens into a file 
Hive,WITHOUT_CLASSIFICATION,//  Pass job to initialize metastore conf overrides 
Hive,WITHOUT_CLASSIFICATION,//  precision 18 
Hive,WITHOUT_CLASSIFICATION,//  We can process this batch immediately. 
Hive,WITHOUT_CLASSIFICATION,/*  256 files x 100 size for 99 splits  */
Hive,WITHOUT_CLASSIFICATION,//  These calls are to see how much data there is. The setFromBytes call below will do the same   readVInt reads but actually unpack the decimal. 
Hive,WITHOUT_CLASSIFICATION,//  if const is first argument then evaluate the result 
Hive,WITHOUT_CLASSIFICATION,//  Note: we could use RW lock to allow concurrent calls for different sessions however all         those calls do is add elements to lists and maps; and we'd need to sync those separately         separately plus have an object to notify because RW lock does not support conditions 
Hive,WITHOUT_CLASSIFICATION,//  Do not merge if the MapredWork of MapJoin has multiple input aliases. 
Hive,WITHOUT_CLASSIFICATION,//  the client requested that an extra map-reduce step be performed 
Hive,WITHOUT_CLASSIFICATION,// The code inside the attribute getter threw an exception so log it and   skip outputting the attribute 
Hive,WITHOUT_CLASSIFICATION,/*          * Get our Multi-Key hash multi-set information for this specialized class.          */
Hive,WITHOUT_CLASSIFICATION,//  trigger lazy read of metadata to make sure serialized data is not corrupted and readable 
Hive,WITHOUT_CLASSIFICATION,//  Blindly add this as a integer list should be sufficient for the test case.   Use the non-settable list object inspector. 
Hive,WITHOUT_CLASSIFICATION,//  Thread is being interrupted. 
Hive,WITHOUT_CLASSIFICATION,// Add hbase properties 
Hive,WITHOUT_CLASSIFICATION,//  We want to wait for the iteration to finish and set the cluster fraction. 
Hive,WITHOUT_CLASSIFICATION,//  End the root rp object. 
Hive,WITHOUT_CLASSIFICATION,//  To be consistent with the behavior of listPartitionNames if the   table or db does not exist we return an empty list 
Hive,WITHOUT_CLASSIFICATION,//  No char length available copy whole string value here. 
Hive,WITHOUT_CLASSIFICATION,//  after recovery there shouldn'table be any *_flush_length files 
Hive,WITHOUT_CLASSIFICATION,/*    * Captures how the Input should be Ordered. This is captured as a list   * of ASTNodes that are the expressions in the Sort By clause in a   * PTF invocation.    */
Hive,WITHOUT_CLASSIFICATION,//  operators with no 
Hive,WITHOUT_CLASSIFICATION,//  Decimal 
Hive,WITHOUT_CLASSIFICATION,//  initialize the array 
Hive,WITHOUT_CLASSIFICATION,//  initialize aliasToWork 
Hive,WITHOUT_CLASSIFICATION,//  Spot check decimal column-column subtract 
Hive,WITHOUT_CLASSIFICATION,//  we did not get token set up by oozie let's get them ourselves here.   we essentially get a token per unique Output HCatTableInfo - this is   done because through Pig setOutput() method is called multiple times   We want to only get the token once per unique output HCatTableInfo -   we cannot just get one token since in multi-query case (> 1 store in 1 job)   or the case when a single pig script results in > 1 jobs the single   token will get cancelled by the output committer and the subsequent   stores will fail - by tying the token with the concatenation of   dbname tablename and partition keyvalues of the output   TableInfo we can have as many tokens as there are stores and the TokenSelector   will correctly pick the right tokens which the committer will use and 
Hive,WITHOUT_CLASSIFICATION,//  First check if the table dir exists (could have been deleted for some reason in pre-commit tests) 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.ICLIService#getInfo(org.apache.hive.service.cli.SessionHandle java.util.List)    */
Hive,WITHOUT_CLASSIFICATION,//  Look for interfaces on both the class and all base classes. 
Hive,WITHOUT_CLASSIFICATION,//  Table creation with a long table name causes ConnectionFailureException 
Hive,WITHOUT_CLASSIFICATION,//  try recursive folding 
Hive,WITHOUT_CLASSIFICATION,/*  This method inserts the right profiles into profiles CBO depending   * on the query characteristics.  */
Hive,WITHOUT_CLASSIFICATION,/*    * Scratch arrays used in fastBigIntegerBytes calls for better performance.    */
Hive,WITHOUT_CLASSIFICATION,// If kerberos security is enabled and HS2 doAs is enabled   then additional params need to be set so that the command is run as   intended user 
Hive,WITHOUT_CLASSIFICATION,//  rewrite value index for mapjoin 
Hive,WITHOUT_CLASSIFICATION,//  Initially all deltas and rcs are 0; empty list starts at 0; there are no objects to take. 
Hive,WITHOUT_CLASSIFICATION,//  If there are previous nodes then AND the current node with the previous one 
Hive,WITHOUT_CLASSIFICATION,//  SMALLINT 
Hive,WITHOUT_CLASSIFICATION,//  input key is bigger than any of keys in hash 
Hive,WITHOUT_CLASSIFICATION,//  run queries 
Hive,WITHOUT_CLASSIFICATION,//  number of reducers. 
Hive,WITHOUT_CLASSIFICATION,//  ADJACENCY_TYPE 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setObject(java.lang.String   * java.lang.Object)    */
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:SubmitWorkRequestProto) 
Hive,WITHOUT_CLASSIFICATION,//  first see if there is a direct match 
Hive,WITHOUT_CLASSIFICATION,/*    * A Boundary specifies how many rows back/forward a WindowFrame extends from the   * current row. A Boundary is specified as:   * - Range Boundary :: as the number of rows to go forward or back from                    the Current Row.   * - Current Row :: which implies the Boundary is at the current row.   * - Value Boundary :: which is specified as the amount the value of an                    Expression must decrease/increase    */
Hive,WITHOUT_CLASSIFICATION,//  If the command has no schema make sure nothing is printed 
Hive,WITHOUT_CLASSIFICATION,// completion of txnid:idTxnUpdate2 
Hive,WITHOUT_CLASSIFICATION,/*    * Return vector expression for a custom (i.e. not built-in) UDF.    */
Hive,WITHOUT_CLASSIFICATION,//  Strip trailing carriage return on input   Ignore changes whose lines are all blank 
Hive,WITHOUT_CLASSIFICATION,//  pRS-pJOIN-cRS-cGBY 
Hive,WITHOUT_CLASSIFICATION,//  dynamic partition pruning pipeline doesn't have multiple children 
Hive,WITHOUT_CLASSIFICATION,//  RQST 
Hive,WITHOUT_CLASSIFICATION,//  we need to copy to standard object otherwise deserializer overwrites the values 
Hive,WITHOUT_CLASSIFICATION,//  we have a storage specification for a map column type 
Hive,WITHOUT_CLASSIFICATION,// because 1 txn may include different partitions/tables even in auto commit mode 
Hive,WITHOUT_CLASSIFICATION,//  optional int64 dag_start_time = 4; 
Hive,WITHOUT_CLASSIFICATION,/*      * Try to resolve a qualified name as a column reference on the Parent Query's RowResolver.     * Apply this logic on the leftmost(first) dot in an AST tree.      */
Hive,WITHOUT_CLASSIFICATION,//  Recall that the sequence must be pRS-SEL*-cRS 
Hive,WITHOUT_CLASSIFICATION,//  Set up the dynamic values in the childWork. 
Hive,WITHOUT_CLASSIFICATION,//  KEY 
Hive,WITHOUT_CLASSIFICATION,//  Finalize the last record. 
Hive,WITHOUT_CLASSIFICATION,//  Return proper response 
Hive,WITHOUT_CLASSIFICATION,//  setup DB 
Hive,WITHOUT_CLASSIFICATION,/*      * Calculate the variance result when count > 1.  Public so vectorization code can use it etc.      */
Hive,WITHOUT_CLASSIFICATION,//  min() needed in the case that entire string is whitespace 
Hive,WITHOUT_CLASSIFICATION,//  Finally if we do not reduce the input size we bail out 
Hive,WITHOUT_CLASSIFICATION,//  Find TS operators with partition pruning enabled in plan   because these TS may potentially read different data for   different pipeline.   These can be:   1) TS with DPP.   2) TS with semijoin DPP. 
Hive,WITHOUT_CLASSIFICATION,//  expand ALL privileges if any 
Hive,WITHOUT_CLASSIFICATION,//  8. convert SemiJoin + GBy to SemiJoin 
Hive,WITHOUT_CLASSIFICATION,//  initialize the task and execute 
Hive,WITHOUT_CLASSIFICATION,//  Set the leftmost header of the base and its buddy (that are now being merged). 
Hive,WITHOUT_CLASSIFICATION,//  figure out if there is group by 
Hive,WITHOUT_CLASSIFICATION,//  find out CPU msecs   In the case that we can't find out this number we just skip the step to print 
Hive,WITHOUT_CLASSIFICATION,/*    * The hash table slots.  For a bytes key hash table each slot is 3 longs and the array is   * 3X sized.   *   * The slot triple is 1) a non-zero reference word to the key bytes 2) the key hash code and   * 3) a non-zero reference word to the first value bytes.    */
Hive,WITHOUT_CLASSIFICATION,//  No capacity. Check if an element needs to be evicted. 
Hive,WITHOUT_CLASSIFICATION,//  else - this means pig's optimizer never invoked the pushProjection   method - so we need all fields and hence we should not call the   setOutputSchema on HCatInputFormat 
Hive,WITHOUT_CLASSIFICATION,//  External table should also check the underlying file size. 
Hive,WITHOUT_CLASSIFICATION,//  We create the timeline for the existing and new segments 
Hive,WITHOUT_CLASSIFICATION,// completion of txnid:idTxnUpdate4 
Hive,WITHOUT_CLASSIFICATION,//  The pending query we were waiting on failed but there might still be another   pending or completed entry in the cache that can satisfy this query. Lookup again. 
Hive,WITHOUT_CLASSIFICATION,//  Find the PrivRequirements that match on IOType ActionType and HivePrivilegeObjectType add   the privilege required to reqPrivs 
Hive,WITHOUT_CLASSIFICATION,//        ROW__ID 
Hive,WITHOUT_CLASSIFICATION,//  TODO: we either have to kill HS2 or as the non-actor model would implicitly         hope for the best and continue on other threads. Do the latter for now. 
Hive,WITHOUT_CLASSIFICATION,/*    * An always on bit to insure the key reference non-zero.    */
Hive,WITHOUT_CLASSIFICATION,//  exponent=-7 
Hive,WITHOUT_CLASSIFICATION,//  LlapDaemonMXBean methods. Will be exposed via JMX 
Hive,WITHOUT_CLASSIFICATION,//  The size of deserialized partition shouldn't exceed half of memory limit 
Hive,WITHOUT_CLASSIFICATION,//  Binary (TCP) mode 
Hive,WITHOUT_CLASSIFICATION,//  The reason we do this guard is because when we do not have a good way of initializing   the config to the handler's thread local config until this call so we do it then.   Once done though we need not repeat this linking we simply call setMetaStoreHandler   and let the AuthorizationProvider and AuthenticationProvider do what they want. 
Hive,WITHOUT_CLASSIFICATION,// When using -e command is always a single line 
Hive,WITHOUT_CLASSIFICATION,//  add the default SQL completions 
Hive,WITHOUT_CLASSIFICATION,//  Configured warehouse FS is local don't need to bother checking. 
Hive,WITHOUT_CLASSIFICATION,//  Must be held by same thread 
Hive,WITHOUT_CLASSIFICATION,//  if cascade=true then we need to authorize the drop table action as well 
Hive,WITHOUT_CLASSIFICATION,//  Ignore the exception because we are not comparing Long vs. String here.   There should never be an exception 
Hive,WITHOUT_CLASSIFICATION,//  12.2.  Introduce exchange operators below join/multijoin operators 
Hive,WITHOUT_CLASSIFICATION,//  start inclusive to end inclusive 
Hive,WITHOUT_CLASSIFICATION,//  Trim off lower fractional digits but with NO ROUNDING. 
Hive,WITHOUT_CLASSIFICATION,//  Use toString which will have exponents instead of toPlainString. 
Hive,WITHOUT_CLASSIFICATION,//  In MR mapreduce.task.attempt.id is same as mapred.task.id. Go figure. 
Hive,WITHOUT_CLASSIFICATION,//  Test that when a transaction is aborted the heartbeat fails 
Hive,WITHOUT_CLASSIFICATION,//  Prevent hive configurations from being visible in Spark. 
Hive,WITHOUT_CLASSIFICATION,//  The setupPartitionContextVars uses the prior read type to flush the prior deserializerBatch   so set it here to none. 
Hive,WITHOUT_CLASSIFICATION,//  it's non-deterministic 
Hive,WITHOUT_CLASSIFICATION,//  Test that existing shared_write db with new exclusive coalesces to 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setCharacterStream(int java.io.Reader)    */
Hive,WITHOUT_CLASSIFICATION,//  make everything qualify and ensure selected is not in use 
Hive,WITHOUT_CLASSIFICATION,//  Commit has succeeded (since no exceptions have been thrown.) 
Hive,WITHOUT_CLASSIFICATION,//  SparkSubmit will take care of that for us. 
Hive,WITHOUT_CLASSIFICATION,/*      * Get configuration parameters.      */
Hive,WITHOUT_CLASSIFICATION,//  hence grouppingSetsPresent is true only at map side 
Hive,WITHOUT_CLASSIFICATION,//  are columns used by this select operator. 
Hive,WITHOUT_CLASSIFICATION,//  Set up client port - if we have already had a list of valid ports use it. 
Hive,WITHOUT_CLASSIFICATION,//  THEN NULL ELSE NULL: An unusual "case" but possible. 
Hive,WITHOUT_CLASSIFICATION,//  since after various rules original relnode could have different   corref (or might not have at all) we need to traverse the new node   to figure out new cor refs and put that into map 
Hive,WITHOUT_CLASSIFICATION,//  Test with table name which does not exists in the given database 
Hive,WITHOUT_CLASSIFICATION,//  Will be called before closing the ORC file to stop writing any additional information   to the acid key index. 
Hive,WITHOUT_CLASSIFICATION,//  Turn the tree set into an array so we can move back and forth easily 
Hive,WITHOUT_CLASSIFICATION,//  For conditional expressions 
Hive,WITHOUT_CLASSIFICATION,//  all partitions have been statically removed 
Hive,WITHOUT_CLASSIFICATION,//  verify extension of values in the array 
Hive,WITHOUT_CLASSIFICATION,//  special handling for set role r1 statement 
Hive,WITHOUT_CLASSIFICATION,// make the table ACID 
Hive,WITHOUT_CLASSIFICATION,//  Checking state per node for future failure handling scenarios where an update 
Hive,WITHOUT_CLASSIFICATION,//  Create a thread pool with #poolSize threads   Threads terminate when they are idle for more than the keepAliveTime   A bounded blocking queue is used to queue incoming operations if #operations > poolSize 
Hive,WITHOUT_CLASSIFICATION,//  Try with DECIMAL_64 input and DECIMAL_64 output. 
Hive,WITHOUT_CLASSIFICATION,//  The row consists of some string columns some Array<int> columns. 
Hive,WITHOUT_CLASSIFICATION,//  ANALYZE command 
Hive,WITHOUT_CLASSIFICATION,//  For MM table we only want to delete delta dirs for aborted txns. 
Hive,WITHOUT_CLASSIFICATION,//  ==== HiveServer2 metadata api types start here ==== //   these corresponds to various java.sql.DatabaseMetaData calls. 
Hive,WITHOUT_CLASSIFICATION,//  4. Insert ReduceSide GB2 
Hive,WITHOUT_CLASSIFICATION,/*  Largest possible base 10 exponent.  Any				 * exponent larger than this will already				 * produce underflow or overflow so there's				 * no need to worry about additional digits.				  */
Hive,WITHOUT_CLASSIFICATION,//        into LlapNodeId. We get node info from registry; that should (or can) include it. 
Hive,WITHOUT_CLASSIFICATION,//  Float loses some precisions 
Hive,WITHOUT_CLASSIFICATION,//  re-use old object to prevent needless expr cloning 
Hive,WITHOUT_CLASSIFICATION,//  to support names like _colx:1._coly 
Hive,WITHOUT_CLASSIFICATION,/*    * The following tests spot-check that vectorized functions with signature   * DOUBLE func(DOUBLE) that came from template ColumnUnaryFunc.txt   * get the right result. Null propagation isRepeating   * propagation will be checked once for a single expansion of the template   * (for FuncRoundDoubleToDouble).    */
Hive,WITHOUT_CLASSIFICATION,//  but do a count on inner side before that to make sure it generates atmost 1 row. 
Hive,WITHOUT_CLASSIFICATION,//  be a separate split 
Hive,WITHOUT_CLASSIFICATION,//  to reverse this. 
Hive,WITHOUT_CLASSIFICATION,/*      * Basic algorithm:     *     * 1. Determine if rounding digit is >= 5 for rounding.     * 2. Scale away fractional digits if present.     * 3. If rounding clear integer rounding portion and add 1.     *      */
Hive,WITHOUT_CLASSIFICATION,// txn (if there is one started) is not finished 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:QueryIdentifierProto) 
Hive,WITHOUT_CLASSIFICATION,// get Tokens for default FS.  Not all FSs support delegation tokens e.g. WASB 
Hive,WITHOUT_CLASSIFICATION,//  Convert the group by to a map-side group by 
Hive,WITHOUT_CLASSIFICATION,//  silly little pager 
Hive,WITHOUT_CLASSIFICATION,//  test backward scan 
Hive,WITHOUT_CLASSIFICATION,//  serialization is the option selected 
Hive,WITHOUT_CLASSIFICATION,//  Create the thread pool for the web server to handle HTTP requests 
Hive,WITHOUT_CLASSIFICATION,//  bootstrap case 
Hive,WITHOUT_CLASSIFICATION,//  if a table is inside view we do not care about its authorization. 
Hive,WITHOUT_CLASSIFICATION,// Druid Json timestamp column name 
Hive,WITHOUT_CLASSIFICATION,//  required   required   optional   required   required   optional   optional   optional   optional   optional   optional   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  Round without digits 
Hive,WITHOUT_CLASSIFICATION,/*            * Equal key series checking.            */
Hive,WITHOUT_CLASSIFICATION,//  result privilege 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) FieldType  */
Hive,WITHOUT_CLASSIFICATION,/*  Dynamic partition pruning is enabled in some or all cases if either   * hive.spark.dynamic.partition.pruning is true or   * hive.spark.dynamic.partition.pruning.map.join.only is true    */
Hive,WITHOUT_CLASSIFICATION,//  Auth specific confs 
Hive,WITHOUT_CLASSIFICATION,//  Test not-equals operator for strings and integers. 
Hive,WITHOUT_CLASSIFICATION,/*  Get total number of rows from all in memory partitions  */
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setNCharacterStream(java.lang.String   * java.io.Reader)    */
Hive,WITHOUT_CLASSIFICATION,//  Run the last combined strategy if any. 
Hive,WITHOUT_CLASSIFICATION,/*  fastIntegerDigitCount  */
Hive,WITHOUT_CLASSIFICATION,//  Because we use parentheses in addition to whitespace   as a keyword delimiter we need to define a new ArgumentDelimiter 
Hive,WITHOUT_CLASSIFICATION,// float 
Hive,WITHOUT_CLASSIFICATION,//  slide the column names down by 6 for the name array 
Hive,WITHOUT_CLASSIFICATION,/*        * Just in case we deserialize a decimal with trailing zeroes...        */
Hive,WITHOUT_CLASSIFICATION,//  Build a map of Hive column Names (ExprNodeColumnDesc Name)   to the positions of those projections in the input 
Hive,WITHOUT_CLASSIFICATION,// x= 
Hive,WITHOUT_CLASSIFICATION,//  make sure it is a struct record 
Hive,WITHOUT_CLASSIFICATION,// Test for publish with invalid partition key name 
Hive,WITHOUT_CLASSIFICATION,//  Incomplete message in buffer. 
Hive,WITHOUT_CLASSIFICATION,//  avoid double casting to preserve original string representation of constant. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#getCatalog()    */
Hive,WITHOUT_CLASSIFICATION,//  Should have printed out the header for the field schema 
Hive,WITHOUT_CLASSIFICATION,//  for a table we explicitly try to load partitions as there is no separate partitions events. 
Hive,WITHOUT_CLASSIFICATION,//  Handle COUNT/SUM/AVG function for the case of COUNT(*) and COUNT(DISTINCT) 
Hive,WITHOUT_CLASSIFICATION,/*  Calculate the function result for row i of the batch and   * set the output column vector entry i to the result.    */
Hive,WITHOUT_CLASSIFICATION,//  but that Set is immutable 
Hive,WITHOUT_CLASSIFICATION,//  Note: as per our current constraints the behavior of two parallel activates is         undefined; although only one will succeed and the other will receive exception.         We need proper (semi-)transactional modifications to support this without hacks. 
Hive,WITHOUT_CLASSIFICATION,//  If we are asked to start from begining clear the current fetched resultset 
Hive,WITHOUT_CLASSIFICATION,//  Remove op from all its parents' child list. 
Hive,WITHOUT_CLASSIFICATION,//  Break out and try executing. 
Hive,WITHOUT_CLASSIFICATION,//  each newInput. 
Hive,WITHOUT_CLASSIFICATION,//  Null qualifier would mean all qualifiers in that family want an empty qualifier 
Hive,WITHOUT_CLASSIFICATION,//  Have to use the length instead of the actual prefix because the prefix is location dependent   17 is 16 (16 byte MD5 hash) + 1 for the path separator   Can be less than 17 due to unicode characters 
Hive,WITHOUT_CLASSIFICATION,//  Now abort 3.   Compact 4 and 5. 
Hive,WITHOUT_CLASSIFICATION,//  need to do full scan 
Hive,WITHOUT_CLASSIFICATION,//  JOIN we need to update the state information accordingly 
Hive,WITHOUT_CLASSIFICATION,//  Row offsets will be determined from the reader (we could set the first from last). 
Hive,WITHOUT_CLASSIFICATION,//  [cababc] 
Hive,WITHOUT_CLASSIFICATION,//  Check if list element and value are of same type 
Hive,WITHOUT_CLASSIFICATION,//  Should have been replaced. 
Hive,WITHOUT_CLASSIFICATION,//  Connecting to HS2 as foo. 
Hive,WITHOUT_CLASSIFICATION,//  Generate the columns according to the column mapping provided 
Hive,WITHOUT_CLASSIFICATION,//  this should never happen 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#isClosed()    */
Hive,WITHOUT_CLASSIFICATION,/*    * A TableFunction may be able to accept its input as a stream.   * In this case the contract is:   * - startPartition must be invoked to give the PTF a chance to initialize stream processing.   * - each input row is passed in via a processRow(or processRows) invocation. processRow    *   can return 0 or more o/p rows.   * - finishPartition is invoked to give the PTF a chance to finish processing and return any    *   remaining o/p rows.    */
Hive,WITHOUT_CLASSIFICATION,//  If we cannot lock remove this from cache and continue. 
Hive,WITHOUT_CLASSIFICATION,//  look at hivesubqueryremoverule to see how is this filter created 
Hive,WITHOUT_CLASSIFICATION,//  a subscriber accept the feed and do something depending on the Task type 
Hive,WITHOUT_CLASSIFICATION,//  Return remaining records (if any) from last processed input record. 
Hive,WITHOUT_CLASSIFICATION,//  Duration is an estimate; if the size of the map changes it can be very different. 
Hive,WITHOUT_CLASSIFICATION,//  Add all. 
Hive,WITHOUT_CLASSIFICATION,//  Tailing zeroes difference ok. 
Hive,WITHOUT_CLASSIFICATION,//  connection. However we retry one more time on NoHttpResponseException 
Hive,WITHOUT_CLASSIFICATION,//  1.3 process join 
Hive,WITHOUT_CLASSIFICATION,//  Root Task cannot depend on any other task therefore childTask cannot be 
Hive,WITHOUT_CLASSIFICATION,//  virtual columns 
Hive,WITHOUT_CLASSIFICATION,//  select query 
Hive,WITHOUT_CLASSIFICATION,//  struct<col1:struct<a:booleanb:double>col2:double> 
Hive,WITHOUT_CLASSIFICATION,//  MySQL returns 0 if the string is not a well-formed numeric value.   return LongWritable.valueOf(0);   But we decided to return NULL instead which is more conservative. 
Hive,WITHOUT_CLASSIFICATION,//  initialize buffer to read the entire stripe. 
Hive,WITHOUT_CLASSIFICATION,//  group_b: user2 
Hive,WITHOUT_CLASSIFICATION,//  keep the parent id correct 
Hive,WITHOUT_CLASSIFICATION,//  GRANT_REQUEST 
Hive,WITHOUT_CLASSIFICATION,/*      * Repeating IF expression?      */
Hive,WITHOUT_CLASSIFICATION,//  remove all parameters that are tested.  if the parameter is tested it is part of 
Hive,WITHOUT_CLASSIFICATION,//  Loop while you either have tasks running or tasks queued up 
Hive,WITHOUT_CLASSIFICATION,/*  Multiply by the same power of ten to shift the decimal point back to     * the original place. Places to the right of the decimal will be zero.      */
Hive,WITHOUT_CLASSIFICATION,//  Test string column to string literal comparison 
Hive,WITHOUT_CLASSIFICATION,// base has 10 rows so 5 splits 1 delta has 2 rows so 1 split and 1 delta has 3 so 2 splits 
Hive,WITHOUT_CLASSIFICATION,//  get partitionFilterString stored in the UDFContext - it would have   been stored there by an earlier call to setPartitionFilter   call setInput on HCatInputFormat only in the frontend because internally   it makes calls to the hcat server - we don't want these to happen in   the backend   in the hadoop front end mapred.task.id property will not be set in 
Hive,WITHOUT_CLASSIFICATION,//  compute product of distinct values of grouping columns 
Hive,WITHOUT_CLASSIFICATION,//  Someone else is also trying to append 
Hive,WITHOUT_CLASSIFICATION,//  Columns 
Hive,WITHOUT_CLASSIFICATION,//  add this dummy op to the dummp operator list 
Hive,WITHOUT_CLASSIFICATION,//  Splice the section that we have evicted out of the list.   We have already updated the state above so no need to do that again. 
Hive,WITHOUT_CLASSIFICATION,//  Unregister the functions as well 
Hive,WITHOUT_CLASSIFICATION,// After processing subqueries and source tables process   partitioned table functions 
Hive,WITHOUT_CLASSIFICATION,//  Attempt to cleanup stack trace elements that vary by VM. 
Hive,WITHOUT_CLASSIFICATION,// grape expects excludes key in args map 
Hive,WITHOUT_CLASSIFICATION,/* It's imperative that {@code acquireLocks()} is called for all commands so that      HiveTxnManager can transition its state machine correctly */
Hive,WITHOUT_CLASSIFICATION,//  Delegate updates over to the source state tracker. 
Hive,WITHOUT_CLASSIFICATION,//  Bootstrap load in replica 
Hive,WITHOUT_CLASSIFICATION,//  know if merge MR2 will be triggered at execution time 
Hive,WITHOUT_CLASSIFICATION,//  before each test 
Hive,WITHOUT_CLASSIFICATION,//  Create a znode under the rootNamespace parent for this instance of the server 
Hive,WITHOUT_CLASSIFICATION,/*      * All ROW__IDs are unique on read after conversion to acid     * ROW__IDs are exactly the same before and after compaction     * Also check the file name (only) after compaction for completeness     * Note: order of rows in a file ends up being the reverse of order in values clause (why?!)      */
Hive,WITHOUT_CLASSIFICATION,//  If the url passed to us is a valid url with a protocol we use it as-is   Otherwise we assume it is a name of parameter that we have to get the url from 
Hive,WITHOUT_CLASSIFICATION,/*      * Create our vectorized copy row and deserialize row helper objects.      */
Hive,WITHOUT_CLASSIFICATION,/*  * Specialized class for doing a vectorized map join that is an inner join on a Single-Column Long * and only big table columns appear in the join result so a hash multi-set is used.  */
Hive,WITHOUT_CLASSIFICATION,// adjust counters and buffer limit 
Hive,WITHOUT_CLASSIFICATION,//  in type system for this. 
Hive,WITHOUT_CLASSIFICATION,//  Adding the reducers run time statistics for the job in the QueryPlan 
Hive,WITHOUT_CLASSIFICATION,/*  Validate the operation of renaming a column name.  */
Hive,WITHOUT_CLASSIFICATION,/*    * called if the SubQuery is Agg and Correlated.   * if SQ doesn't have a GroupBy it is added to the SQ AST.    */
Hive,WITHOUT_CLASSIFICATION,//  If an insert event is found then return null hence no event is dumped. 
Hive,WITHOUT_CLASSIFICATION,//  loop until the value is correct or we run out of tries 
Hive,WITHOUT_CLASSIFICATION,//  Outer joins with post-filtering conditions cannot be merged 
Hive,WITHOUT_CLASSIFICATION,//  Load each incremental dump from the list. Each dump have only one operation. 
Hive,WITHOUT_CLASSIFICATION,//  coming from below. 
Hive,WITHOUT_CLASSIFICATION,//  Create the table 
Hive,WITHOUT_CLASSIFICATION,//  enable the hook check after the server startup 
Hive,WITHOUT_CLASSIFICATION,//  From the above checks we know fast2 is zero. 
Hive,WITHOUT_CLASSIFICATION,/*    * Get optional read variations for fields.    */
Hive,WITHOUT_CLASSIFICATION,//      .5) 
Hive,WITHOUT_CLASSIFICATION,//  c11-c20 
Hive,WITHOUT_CLASSIFICATION,//  Underflow. 
Hive,WITHOUT_CLASSIFICATION,//  Change lock manager to embedded mode 
Hive,WITHOUT_CLASSIFICATION,//  if uncompressedOffset is in a middle of integer encoding runs (RLE Delta etc.) consume 
Hive,WITHOUT_CLASSIFICATION,// Handle table schema 
Hive,WITHOUT_CLASSIFICATION,// this could be expensive when there are a lot of compactions.... 
Hive,WITHOUT_CLASSIFICATION,//  expressions. 
Hive,WITHOUT_CLASSIFICATION,// the current split should use the preceding split's footerbuffer in order to skip footer correctly. 
Hive,WITHOUT_CLASSIFICATION,//  Make one partitioned 
Hive,WITHOUT_CLASSIFICATION,//  fastScale + absPower > HiveDecimal.MAX_SCALE 
Hive,WITHOUT_CLASSIFICATION,//  collect 
Hive,WITHOUT_CLASSIFICATION,//  Select query 
Hive,WITHOUT_CLASSIFICATION,//  list overhead + (configured number of element in list * size of element) 
Hive,WITHOUT_CLASSIFICATION,//  short 
Hive,WITHOUT_CLASSIFICATION,//  If it is a RIGHT / FULL OUTER JOIN we need to iterate through the row container   that contains all the right records that did not produce results. Then for each   of those records we replace the left side with NULL values and produce the   records.   Observe that we only enter this block when we have finished iterating through   all the left and right records (aliasNum == numAliases - 2) and thus we have   tried to evaluate the post-filter condition on every possible combination.   NOTE: the left records that do not produce results (for LEFT / FULL OUTER JOIN)   will always be caught in the genObject method 
Hive,WITHOUT_CLASSIFICATION,//  We can offer ECB even with some streams not discarded; reset() will clear the arrays. 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: this is to work around Hive Calcite Limitations w.r.t OB.   1. Calcite can not accept expressions in OB; instead it needs to be expressed   as VC in input Select.   2. Hive can not preserve ordering through select boundaries.   3. This map is used for outermost OB to migrate the VC corresponding OB   expressions from input select.   4. This is used by ASTConverter after we are done with Calcite Planning 
Hive,WITHOUT_CLASSIFICATION,//  scratch cols are) 
Hive,WITHOUT_CLASSIFICATION,/*  id <> 12  */
Hive,WITHOUT_CLASSIFICATION,//  No updates before it's running. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure the referenced Schema exists 
Hive,WITHOUT_CLASSIFICATION,//  Sort columns specified by table 
Hive,WITHOUT_CLASSIFICATION,//  3. Construct new Row Resolver with everything from below. 
Hive,WITHOUT_CLASSIFICATION,//  byte[] bytes = Arrays.copyOf(output.getData() output.getLength()); 
Hive,WITHOUT_CLASSIFICATION,//  This create and publish the segment to be overwritten 
Hive,WITHOUT_CLASSIFICATION,// get the local path of downloaded jars. 
Hive,WITHOUT_CLASSIFICATION,//  update key with assigned identifier 
Hive,WITHOUT_CLASSIFICATION,//  useMinMax = minMaxEnabled; 
Hive,WITHOUT_CLASSIFICATION,//  optional int32 dag_index = 2; 
Hive,WITHOUT_CLASSIFICATION,//  Timestamp strings should parse ok 
Hive,WITHOUT_CLASSIFICATION,//  Compactor should only schedule compaction for ttp2 (delta.num.threshold=4) not ttp1 
Hive,WITHOUT_CLASSIFICATION,/*      * additions to the Group By Clause.      */
Hive,WITHOUT_CLASSIFICATION,//  adding columns and limited integer type promotion is supported for ORC schema evolution 
Hive,WITHOUT_CLASSIFICATION,//  CONSIDER: For now recompute integerDigitCount... 
Hive,WITHOUT_CLASSIFICATION,//  Temp HDFS path for Spark HashTable sink 
Hive,WITHOUT_CLASSIFICATION,//  AM is responsive again (recovery?) 
Hive,WITHOUT_CLASSIFICATION,//        somewhere like ZK? Try to randomize it a bit for now... 
Hive,WITHOUT_CLASSIFICATION,//  Schedule task to cleanup dangling scratch dir periodically   initial wait for a random time between 0-10 min to 
Hive,WITHOUT_CLASSIFICATION,//  Use table descriptor for columns. 
Hive,WITHOUT_CLASSIFICATION,/*    * same comment as OI applies here.    */
Hive,WITHOUT_CLASSIFICATION,//  AND hash with mask to 0 out sign bit to make sure it's positive.   Then we know taking the result mod n is in the range (0..n-1). 
Hive,WITHOUT_CLASSIFICATION,//  original toString takes too much space 
Hive,WITHOUT_CLASSIFICATION,//  create new MapWork 
Hive,WITHOUT_CLASSIFICATION,//  test that the values we added are there 
Hive,WITHOUT_CLASSIFICATION,//  This "global" allows various validation methods to set the "not vectorized" reason. 
Hive,WITHOUT_CLASSIFICATION,//  The table location already exists and may contain data. 
Hive,WITHOUT_CLASSIFICATION,//  Search for any SparkPartitionPruningSinkOperator in the SparkTask 
Hive,WITHOUT_CLASSIFICATION,//  ------------------------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  ////// 1. Generate ReduceSinkOperator 
Hive,WITHOUT_CLASSIFICATION,/*  Rewrite only analyze table <> column <> compute statistics; Don't rewrite analyze table     * command - table stats are collected by the table scan operator and is not rewritten to     * an aggregation.      */
Hive,WITHOUT_CLASSIFICATION,//  Add the task to the delayed task queue if it does not already exist. 
Hive,WITHOUT_CLASSIFICATION,//  Check column type 
Hive,WITHOUT_CLASSIFICATION,//  Now prepare partnames with 9 partitions: [tab1part1...tab1part8] which are contained in the 
Hive,WITHOUT_CLASSIFICATION,//  Tez/LLAP requires RPC query plan 
Hive,WITHOUT_CLASSIFICATION,// waits for SS lock on T8 from fifer 
Hive,WITHOUT_CLASSIFICATION,//  all children expression should be resolved 
Hive,WITHOUT_CLASSIFICATION,//  This call sets the default ssl params including the correct keystore in the server config 
Hive,WITHOUT_CLASSIFICATION,//  current Key ObjectInspectors are standard ObjectInspectors 
Hive,WITHOUT_CLASSIFICATION,//  check if the file exists 
Hive,WITHOUT_CLASSIFICATION,//  make sure the schema mapping is right 
Hive,WITHOUT_CLASSIFICATION,//  This will break the iterator. However this is the last task we can add the way this currently   runs (only one duck is distributed when failedUpdate is present) so that should be ok. 
Hive,WITHOUT_CLASSIFICATION,/*  1 files x 1000 size for 11 splits  */
Hive,WITHOUT_CLASSIFICATION,//  Currently only functions columns and scalars supported. 
Hive,WITHOUT_CLASSIFICATION,//  pass the row rather than recordValue. 
Hive,WITHOUT_CLASSIFICATION,//  Prefer methods with a closer signature based on the primitive grouping of each argument.   Score each method based on its similarity to the passed argument types. 
Hive,WITHOUT_CLASSIFICATION,//  get-set methods 
Hive,WITHOUT_CLASSIFICATION,/*  100 files x 100 size for 99 splits  */
Hive,WITHOUT_CLASSIFICATION,// Test outputformat with compression 
Hive,WITHOUT_CLASSIFICATION,//  This is a vectorized aware evaluator 
Hive,WITHOUT_CLASSIFICATION,//  Single column unnamed primary key in default catalog and database 
Hive,WITHOUT_CLASSIFICATION,//  We check whether merging the works would cause the size of   the data in memory grow too large. 
Hive,WITHOUT_CLASSIFICATION,//  may get treated as base if split-update is enabled for ACID. (See HIVE-14035 for details) 
Hive,WITHOUT_CLASSIFICATION,/*    * Called to transform tasks into local tasks where possible/desirable    */
Hive,WITHOUT_CLASSIFICATION,//  Warning note : HMSHandler.getHiveConf() is not thread-unique .getConf() is. 
Hive,WITHOUT_CLASSIFICATION,/*    * Test the validation of incorrect NULL values in the tables   * @throws Exception    */
Hive,WITHOUT_CLASSIFICATION,//  This method parses the custom dynamic path and replaces each occurrence 
Hive,WITHOUT_CLASSIFICATION,//  Could not find an allowed path to a table scan operator   hence we are done 
Hive,WITHOUT_CLASSIFICATION,//    1. create the operator tree 
Hive,WITHOUT_CLASSIFICATION,//  Must be deterministic order map for consistent q-test output across   Java versions 
Hive,WITHOUT_CLASSIFICATION,//  Tests for dropPartition(String db_name String tbl_name String name   boolean deleteData) method 
Hive,WITHOUT_CLASSIFICATION,//  Validate the second parameter which should be an integer 
Hive,WITHOUT_CLASSIFICATION,//  Should never happen. 
Hive,WITHOUT_CLASSIFICATION,//  scaling up so o is definitely larger 
Hive,WITHOUT_CLASSIFICATION,//  All the split strategies are done so it must be safe to access splitFutures. 
Hive,WITHOUT_CLASSIFICATION,//  if we do not force script execution abort   when a failure occurs. 
Hive,WITHOUT_CLASSIFICATION,//  Methods that create relational expressions 
Hive,WITHOUT_CLASSIFICATION,//  input file name (big) to bucket number 
Hive,WITHOUT_CLASSIFICATION,/*    * Use this constructor when there is NO output column.    */
Hive,WITHOUT_CLASSIFICATION,//  this value should get over-written with correct value   ditto 
Hive,WITHOUT_CLASSIFICATION,//  handles the case like line = show tables; --test comment 
Hive,WITHOUT_CLASSIFICATION,//  there should be only one parent. 
Hive,WITHOUT_CLASSIFICATION,// Make sure it itereated through all possible ConnParams 
Hive,WITHOUT_CLASSIFICATION,/*  TODO HIVE-18991    CreationMetadata cm = client.getTable(dbName tableNames[3]).getCreationMetadata();    cm.addToTablesUsed(dbName + "." + tableNames[1]);    client.updateCreationMetadata(dbName tableNames[3] cm);     */
Hive,WITHOUT_CLASSIFICATION,//  Set remaining fractional portion to nanos 
Hive,WITHOUT_CLASSIFICATION,//  We shall have enough time to synchronize privileges during loading   information schema 
Hive,WITHOUT_CLASSIFICATION,//  Create a FileSink operator 
Hive,WITHOUT_CLASSIFICATION,//  Return directly if last value is null 
Hive,WITHOUT_CLASSIFICATION,//  Must at least be able to return ti back. 
Hive,WITHOUT_CLASSIFICATION,//  No conversion. 
Hive,WITHOUT_CLASSIFICATION,//  helper methods 
Hive,WITHOUT_CLASSIFICATION,//  Are we consuming too much memory 
Hive,WITHOUT_CLASSIFICATION,//  backtrack can be null when input is script operator 
Hive,WITHOUT_CLASSIFICATION,//  We want to use metricsDir in the same directory as the destination file to support atomic   move of temp file to the destination metrics file 
Hive,WITHOUT_CLASSIFICATION,//  We need to compare partition name with requested name since some DBs   (like MySQL Derby) considers 'a' = 'a ' whereas others like (Postgres 
Hive,WITHOUT_CLASSIFICATION,//  If copy fails fall through the retry logic 
Hive,WITHOUT_CLASSIFICATION,//  Lock the lowest priority buffer; try to evict - we'll evict some other buffer. 
Hive,WITHOUT_CLASSIFICATION,//  Logger the callstack from which the error has been set. 
Hive,WITHOUT_CLASSIFICATION,//  [ONLY] 
Hive,WITHOUT_CLASSIFICATION,//  Generate MapredLocalWorks for MJ and HTS 
Hive,WITHOUT_CLASSIFICATION,//  HIVE-14444 pending rename: afterClass 
Hive,WITHOUT_CLASSIFICATION,//  3.2 if conjunctive predicate elements are more than one then walk   through them one by one. Compute cross product of NDV. Cross product is   computed by multiplying the largest NDV of all of the conjunctive   predicate   elements with degraded NDV of rest of the conjunctive predicate   elements. NDV is   degraded using log function.Finally the ndvCrossProduct is fenced at   the join   cross product to ensure that NDV can not exceed worst case join   cardinality.<br>   NDV of a conjunctive predicate element is the max NDV of all arguments   to lhs rhs expressions.   NDV(JoinCondition) = min (left cardinality * right cardinality   ndvCrossProduct(JoinCondition))   ndvCrossProduct(JoinCondition) = ndv(pex)*log(ndv(pe1))*log(ndv(pe2))   where pex is the predicate element of join condition with max ndv.   ndv(pe) = max(NDV(left.Expr) NDV(right.Expr)) 
Hive,WITHOUT_CLASSIFICATION,//  It's not likely if there is no bug. But in case it happens we must   have found a wrong filter operator. We skip the optimization then. 
Hive,WITHOUT_CLASSIFICATION,//  process join 
Hive,WITHOUT_CLASSIFICATION,// run Major compaction 
Hive,WITHOUT_CLASSIFICATION,//  constant add them to colToConstants as half-deterministic columns. 
Hive,WITHOUT_CLASSIFICATION,//  native vector map join hash table setup. 
Hive,WITHOUT_CLASSIFICATION,//  in the cancel case where the driver state is INTERRUPTED destroy will be deferred to   the query process 
Hive,WITHOUT_CLASSIFICATION,//  MapReduce API. Catch the error log a debug message and just keep going 
Hive,WITHOUT_CLASSIFICATION,// todo: rename files case 
Hive,WITHOUT_CLASSIFICATION,//  Reconnect is only supported for MR and Streaming jobs at this time 
Hive,WITHOUT_CLASSIFICATION,//  Where 0 is the highest longword; 1 is middle longword etc. 
Hive,WITHOUT_CLASSIFICATION,//  fill in colstatus 
Hive,WITHOUT_CLASSIFICATION,//  Errors are handled on the way over. FAIL/SUCCESS is informed via regular heartbeats. Killed   via a kill message when a task kill is requested by the daemon. 
Hive,WITHOUT_CLASSIFICATION,// now make sure delete deltas are present 
Hive,WITHOUT_CLASSIFICATION,//  for demo purposes) 
Hive,WITHOUT_CLASSIFICATION,//  This hook verifies that the location of every partition in the inputs and outputs starts with   the location of the table.  It is a very simple check to make sure it is a subdirectory. 
Hive,WITHOUT_CLASSIFICATION,/*      * There are 3 modes of reading for vectorization:     *     *   1) One for the Vectorized Input File Format which returns VectorizedRowBatch as the row.     *     *   2) One for using VectorDeserializeRow to deserialize each row into the VectorizedRowBatch.     *      Currently these Input File Formats:     *        TEXTFILE     *        SEQUENCEFILE     *     *   3) And one using the regular partition deserializer to get the row object and assigning     *      the row object into the VectorizedRowBatch with VectorAssignRow.     *      This picks up Input File Format not supported by the other two.      */
Hive,WITHOUT_CLASSIFICATION,/*  exponents into floating-point numbers.  */
Hive,WITHOUT_CLASSIFICATION,//  IMPORT statement specified EXTERNAL 
Hive,WITHOUT_CLASSIFICATION,//  a state that the driver enters after close() has been called to clean the query results   and release the resources after the query has been executed 
Hive,WITHOUT_CLASSIFICATION,//  Periodically report progress on the Context object   to prevent TaskTracker from killing the Templeton   Controller task 
Hive,WITHOUT_CLASSIFICATION,//  llap cluster info does not need admin privilege since it is read only assigning privilege same as 
Hive,WITHOUT_CLASSIFICATION,//  Get key columns 
Hive,WITHOUT_CLASSIFICATION,// convert BytesWritable to byte][ 
Hive,WITHOUT_CLASSIFICATION,//  LazySimpleSerDe can convert any types to String type using   JSON-format. However we may add more operators.   Thus we still keep the conversion. 
Hive,WITHOUT_CLASSIFICATION,//  Add an interceptor to add in an XSRF header 
Hive,WITHOUT_CLASSIFICATION,//  Come ride the API roller-coaster! 
Hive,WITHOUT_CLASSIFICATION,//  add a map 
Hive,WITHOUT_CLASSIFICATION,//  The source table now has 2 partitions one in TEXTFILE the other in ORC.   Test adding these partitions to the target-table *without* replicating the table-change. 
Hive,WITHOUT_CLASSIFICATION,//  Must be deterministic order map for consistent test output across Java versions 
Hive,WITHOUT_CLASSIFICATION,//  first we try to split the task 
Hive,WITHOUT_CLASSIFICATION,//  this should never happen.   provide a good error message in case there's a bug 
Hive,WITHOUT_CLASSIFICATION,//  SELECT * or SELECT TRANSFORM(*) 
Hive,WITHOUT_CLASSIFICATION,//  If there is a failure from here to until when the metadata is changed   the partition will be empty or throw errors on read. 
Hive,WITHOUT_CLASSIFICATION,//  Expression splits of each part of the partition 
Hive,WITHOUT_CLASSIFICATION,//  10^32 - 1 
Hive,WITHOUT_CLASSIFICATION,//  make sure they are not public. 
Hive,WITHOUT_CLASSIFICATION,//  Verify cleanup functionality.   Open a new session since this case needs to close the session in the end. 
Hive,WITHOUT_CLASSIFICATION,//  We found some old value but couldn't incRef it; remove it. 
Hive,WITHOUT_CLASSIFICATION,//  if location specified set in partition 
Hive,WITHOUT_CLASSIFICATION,//  If no partition cols just distribute the data uniformly   to provide better load balance. If the requirement is to have a single reducer we should   set the number of reducers to 1. Use a constant seed to make the code deterministic. 
Hive,WITHOUT_CLASSIFICATION,//  Link import tasks to the barrier task which will in-turn linked with repl state update tasks 
Hive,WITHOUT_CLASSIFICATION,//  actualBatchSize 
Hive,WITHOUT_CLASSIFICATION,//  SUM and COUNT are rolled up as SUM hence SUM represents both here 
Hive,WITHOUT_CLASSIFICATION,//  Use internal text member to read value 
Hive,WITHOUT_CLASSIFICATION,//  Because TABLE_NO_AUTO_COMPACT was originally assumed to be NO_AUTO_COMPACT and then was moved 
Hive,WITHOUT_CLASSIFICATION,//  Join or Filter does not change the old input ordering. All   input fields from newLeftInput(i.e. the original input to the old 
Hive,WITHOUT_CLASSIFICATION,//  The unit of caching for ORC is (rg x column) (see OrcBatchKey). 
Hive,WITHOUT_CLASSIFICATION,//  No nulls not repeating 
Hive,WITHOUT_CLASSIFICATION,//  Check interrupt at the last moment in case we get cancelled quickly. 
Hive,WITHOUT_CLASSIFICATION,//  If jar file is in the hdfs it should be downloaded first. 
Hive,WITHOUT_CLASSIFICATION,//  reducers from the parent operators. 
Hive,WITHOUT_CLASSIFICATION,//  Direct access interfaces. 
Hive,WITHOUT_CLASSIFICATION,//  The syntax should not allow these fields to be null but lets verify 
Hive,WITHOUT_CLASSIFICATION,//  USERNAME 
Hive,WITHOUT_CLASSIFICATION,//  first remove all the membership the membership that this role has   been granted 
Hive,WITHOUT_CLASSIFICATION,// this returns the source of corVar i.e. Rel which produces cor var 
Hive,WITHOUT_CLASSIFICATION,//  Show Tracking URL for remotely running jobs. 
Hive,WITHOUT_CLASSIFICATION,// make sure Driver returns all results   drop and recreate the necessary databases and tables 
Hive,WITHOUT_CLASSIFICATION,//  DOUBLE_STATS 
Hive,WITHOUT_CLASSIFICATION,// ---------------------------------------------------------------------------   Inner join specific members.   
Hive,WITHOUT_CLASSIFICATION,//  Find table which name contains _to_find_ in the dummy database 
Hive,WITHOUT_CLASSIFICATION,/*              * The RowResolver setup for Select drops Table associations. So             * setup ASTNode on unqualified name.              */
Hive,WITHOUT_CLASSIFICATION,//  If the spark job finishes before this listener is called the QUEUED status will not be set 
Hive,WITHOUT_CLASSIFICATION,//  ACCUMULO-3015 Like the above RangeInputSplit should have the table name 
Hive,WITHOUT_CLASSIFICATION,//  static Pattern regexrid = Pattern.compile("x-id=([-0-9a-f]{36})");   static SimpleDateFormat dateparser = new   SimpleDateFormat("dd/MMM/yyyy:hh:mm:ss ZZZZZ"); 
Hive,WITHOUT_CLASSIFICATION,//  set state as CLOSE as long as all parents are closed 
Hive,WITHOUT_CLASSIFICATION,//  Try to readlock the candidateList; timeout after maxReaderWaitTime 
Hive,WITHOUT_CLASSIFICATION,//  * implies all properties needs to be inherited 
Hive,WITHOUT_CLASSIFICATION,//  Initialize 0.7.0 schema 
Hive,WITHOUT_CLASSIFICATION,//  argument descriptors 
Hive,WITHOUT_CLASSIFICATION,//  The input is sorted by alias so if we are already in the last join   operand   we can emit some results now.   Note this has to be done before adding the current row to the   storage   to preserve the correctness for outer joins. 
Hive,WITHOUT_CLASSIFICATION,// each items is a "key=value" format 
Hive,WITHOUT_CLASSIFICATION,//  Get column names 
Hive,WITHOUT_CLASSIFICATION,// 2. get the rewritten AST 
Hive,WITHOUT_CLASSIFICATION,//  In test setup we append '/next' to hive.repl.rootdir and use that as the dump location 
Hive,WITHOUT_CLASSIFICATION,//  there were no exception. Batchsize doesn't change until there is an exception 
Hive,WITHOUT_CLASSIFICATION,//  match or UNKNOWN 
Hive,WITHOUT_CLASSIFICATION,//  Decimal -> String 
Hive,WITHOUT_CLASSIFICATION,//  optional   optional   required   required   optional 
Hive,WITHOUT_CLASSIFICATION,//  float types require no conversion so use a no-op 
Hive,WITHOUT_CLASSIFICATION,//  4. Build operator 
Hive,WITHOUT_CLASSIFICATION,//  found files under currentPath add them to the queue if it is a directory 
Hive,WITHOUT_CLASSIFICATION,// Full test 
Hive,WITHOUT_CLASSIFICATION,//  Update location 
Hive,WITHOUT_CLASSIFICATION,//  There could be several big table input files   mapping to the same small input file.   Find that one with the lowest bucket id. 
Hive,WITHOUT_CLASSIFICATION,//  No need to evaluate just forward it. 
Hive,WITHOUT_CLASSIFICATION,/*    * This class captures the information about a   * conjunct in the where clause of the SubQuery.   * For a equality predicate it capture for each side:   * - the AST   * - the type of Expression (basically what columns are referenced)   * - for Expressions that refer the parent it captures the   *   parent's ColumnInfo. In case of outer Aggregation expressions   *   we need this to introduce a new mapping in the OuterQuery   *   RowResolver. A join condition must use qualified column references   *   so we generate a new name for the aggr expression and use it in the   *   joining condition.   *   For e.g.   *   having exists ( select x from R2 where y = min(R1.z) )   *   where the expression 'min(R1.z)' is from the outer Query.   *   We give this expression a new name like 'R1._gby_sq_col_1'   *   and use the join condition: R1._gby_sq_col_1 = R2.y    */
Hive,WITHOUT_CLASSIFICATION,//  Format is <table_name>:<hwm>:<minOpenWriteId>:<open_writeids>:<abort_writeids> 
Hive,WITHOUT_CLASSIFICATION,//  in the form of T partition (ds="2010-03-03") 
Hive,WITHOUT_CLASSIFICATION,//  If there are async requests satisfy them first. 
Hive,WITHOUT_CLASSIFICATION,//  Order 
Hive,WITHOUT_CLASSIFICATION,//  Expect the correct OIs 
Hive,WITHOUT_CLASSIFICATION,//  Assign repeated value (index 0) over and over. 
Hive,WITHOUT_CLASSIFICATION,//  HAS_RESULT_SET 
Hive,WITHOUT_CLASSIFICATION,//  Only copy data values if entry is not null. The string value   at position 0 is undefined if the position 0 value is null. 
Hive,WITHOUT_CLASSIFICATION,//  clear out any parents as reducer is the root 
Hive,WITHOUT_CLASSIFICATION,//  Turn off skew if an additional MR job is required anyway for grouping sets. 
Hive,WITHOUT_CLASSIFICATION,// with HIVE-15032 this should use static parts and thus not need addDynamicPartitions 
Hive,WITHOUT_CLASSIFICATION,//  The call to ATS appears to block indefinitely blocking the ATS thread while   the hook continues to submit work to the ExecutorService with each query.   Over time the queued items can cause OOM as the HookContext seems to contain   some items which use a lot of memory.   Prevent this situation by creating executor with bounded capacity - 
Hive,WITHOUT_CLASSIFICATION,//  only ask for the views. 
Hive,WITHOUT_CLASSIFICATION,//  Go through each target column generate the lineage edges. 
Hive,WITHOUT_CLASSIFICATION,//  If necessary copy the big table key into the overflow batch's small table   result "area". 
Hive,WITHOUT_CLASSIFICATION,//  Always include headers since they contain non-vectorized objects too. 
Hive,WITHOUT_CLASSIFICATION,//  1. collect information about CTE if there is any.   The base table of CTE should be masked.   The CTE itself should not be masked in the references in the following main query. 
Hive,WITHOUT_CLASSIFICATION,//  Set one of the partitions to be skipped so that a command is created for every other one. 
Hive,WITHOUT_CLASSIFICATION,/*            * We may have missed the start of the vertex due to the 3 seconds interval            */
Hive,WITHOUT_CLASSIFICATION,//  We register it so we do not fire the rule on it again 
Hive,WITHOUT_CLASSIFICATION,//  Each qfile may include at most one INCLUDE or EXCLUDE directive.     If a qfile contains an INCLUDE directive and hadoopVer does   not appear in the list of versions to include then the qfile   is skipped.     If a qfile contains an EXCLUDE directive and hadoopVer is   listed in the list of versions to EXCLUDE then the qfile is   skipped.     Otherwise the qfile is included. 
Hive,WITHOUT_CLASSIFICATION,//  Stub AccumuloConnectionParameters actions 
Hive,WITHOUT_CLASSIFICATION,/*  The row matches skewed column names.  */
Hive,WITHOUT_CLASSIFICATION,//  2.1 Translate Grouping set col bitset 
Hive,WITHOUT_CLASSIFICATION,//  append the trailing path string if any 
Hive,WITHOUT_CLASSIFICATION,//  This function is not a deterministic function but a runtime constant.   The return value is constant within a query but can be different between queries. 
Hive,WITHOUT_CLASSIFICATION,//  9 is the length of "tblprops.". We only keep the rest 
Hive,WITHOUT_CLASSIFICATION,//  aggregate operator 
Hive,WITHOUT_CLASSIFICATION,/*      * Windows that are unbounded following don't benefit from Streaming.      */
Hive,WITHOUT_CLASSIFICATION,//  struct<map1:map<stringstring>map2:map<stringstring>>string 
Hive,WITHOUT_CLASSIFICATION,//  Estimation larger than max 
Hive,WITHOUT_CLASSIFICATION,//  LINT_STRING 
Hive,WITHOUT_CLASSIFICATION,//  All partitions with blurb="isLocatedInTablePath" should have 2 columns 
Hive,WITHOUT_CLASSIFICATION,//  only contain multi-sourced because multi-sourced cannot be hashed or direct readable 
Hive,WITHOUT_CLASSIFICATION,//  if phase1Result false return 
Hive,WITHOUT_CLASSIFICATION,//  the partition directory. e.g. .../hr=12-intermediate-archived 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise we have to wait until after the masking/filtering step. 
Hive,WITHOUT_CLASSIFICATION,//  get map operator and initialize it 
Hive,WITHOUT_CLASSIFICATION,//  Set appropriate Acid readers/writers based on the table properties. 
Hive,WITHOUT_CLASSIFICATION,//  add a list 
Hive,WITHOUT_CLASSIFICATION,//  If not then create a set of hanging readers that do sort-merge to find the next smallest   delete event on-demand. Caps the memory consumption to (some_const * no. of readers). 
Hive,WITHOUT_CLASSIFICATION,//  DateColumnArithmeticIntervalYearMonthColumn.txt   DateScalarArithmeticIntervalYearMonthColumn.txt   DateColumnArithmeticIntervalYearMonthScalar.txt     IntervalYearMonthColumnArithmeticDateColumn.txt   IntervalYearMonthScalarArithmeticDateColumn.txt   IntervalYearMonthColumnArithmeticDateScalar.txt     TimestampColumnArithmeticIntervalYearMonthColumn.txt   TimestampScalarArithmeticIntervalYearMonthColumn.txt   TimestampColumnArithmeticIntervalYearMonthScalar.txt     IntervalYearMonthColumnArithmeticTimestampColumn.txt   IntervalYearMonthScalarArithmeticTimestampColumn.txt   IntervalYearMonthColumnArithmeticTimestampScalar.txt 
Hive,WITHOUT_CLASSIFICATION,//  TRIGGERS 
Hive,WITHOUT_CLASSIFICATION,//  TODO HIVE-14042. In case of an abort request throw an InterruptedException 
Hive,WITHOUT_CLASSIFICATION,//  delete jar added using query1 
Hive,WITHOUT_CLASSIFICATION,//  Aliases for Java Class Names 
Hive,WITHOUT_CLASSIFICATION,//  The union is already initialized. However the union is walked from   another input   initUnionPlan is idempotent 
Hive,WITHOUT_CLASSIFICATION,//  FUTURE: We could check arg2ColVector.noNulls and optimize these loops. 
Hive,WITHOUT_CLASSIFICATION,//  first violation for the session 
Hive,WITHOUT_CLASSIFICATION,//  get custom path string 
Hive,WITHOUT_CLASSIFICATION,//  value>) 
Hive,WITHOUT_CLASSIFICATION,//  the basic idea is similar to unparseTranslator. 
Hive,WITHOUT_CLASSIFICATION,//  Can be a ref cursor variable 
Hive,WITHOUT_CLASSIFICATION,// when txnid is <> 0 the lock is 
Hive,WITHOUT_CLASSIFICATION,//  If the task cannot finish and if no slots are available then don't schedule it.   Also don't wait if we have a task and we just killed something to schedule it. 
Hive,WITHOUT_CLASSIFICATION,//  resolved task 
Hive,WITHOUT_CLASSIFICATION,//  Ignore. Safe if it does not exist. 
Hive,WITHOUT_CLASSIFICATION,//  check if the character array has the character 
Hive,WITHOUT_CLASSIFICATION,//  5 is the head 1<<p means the number of bytes for register 
Hive,WITHOUT_CLASSIFICATION,//  Default executor when no option is specified 
Hive,WITHOUT_CLASSIFICATION,//  Step2: remove any tmp file or double-committed output files 
Hive,WITHOUT_CLASSIFICATION,//  Event 22 23 24 
Hive,WITHOUT_CLASSIFICATION,//  implement RelOptRule 
Hive,WITHOUT_CLASSIFICATION,//  Invalidate cached aggregate stats 
Hive,WITHOUT_CLASSIFICATION,//  Currently partition spec can only be static partition. 
Hive,WITHOUT_CLASSIFICATION,//  Load using same dump to a DB with table. It should fail as DB is not empty. 
Hive,WITHOUT_CLASSIFICATION,//  If it is a CASE or WHEN we need to check that children do not contain stateful functions   as they are not allowed 
Hive,WITHOUT_CLASSIFICATION,//  Regular insert: export some MM deltas then import into a new table. 
Hive,WITHOUT_CLASSIFICATION,//  Note : ptnDesc can be null or empty for non-ptn table 
Hive,WITHOUT_CLASSIFICATION,//  Construct a sorted Map of Partition Dir - Partition Descriptor; ordering is based on   patition dir (map key)   Assumption: there is a 1-1 mapping between partition dir and partition descriptor lists 
Hive,WITHOUT_CLASSIFICATION,//  Iterate thru the cols and load the batch 
Hive,WITHOUT_CLASSIFICATION,//  If there is no authorization anybody has administrator access. 
Hive,WITHOUT_CLASSIFICATION,//  This node was parsed while loading the definition of another view   being referenced by the one being created and we don't want   to track any expansions for the underlying view. 
Hive,WITHOUT_CLASSIFICATION,//  Remove expression node descriptor and children of it for a given predicate   from mapping if it's already on RS keys. 
Hive,WITHOUT_CLASSIFICATION,//  no-op authentication 
Hive,WITHOUT_CLASSIFICATION,//  now compact and see if compaction still preserves the data correctness 
Hive,WITHOUT_CLASSIFICATION,//  Convert to millis 
Hive,WITHOUT_CLASSIFICATION,//  Now look in the current Hive config value.  Again avoiding getting defaults 
Hive,WITHOUT_CLASSIFICATION,//  If the new numReducer is less than minReducer we will not consider   ReduceSinkOperator with this newNumReducer as a correlated ReduceSinkOperator 
Hive,WITHOUT_CLASSIFICATION,//  Add a dummy aggregate stats object for the above parts (part1...part9) of tab1 for col1 
Hive,WITHOUT_CLASSIFICATION,//  5. Same as 3. Also emit extra records from a separate thread. 
Hive,WITHOUT_CLASSIFICATION,//  if mode is all just run it 
Hive,WITHOUT_CLASSIFICATION,//  Case 5: Test with originals compacted_base insert_deltas delete_deltas (exhaustive test) 
Hive,WITHOUT_CLASSIFICATION,//  check. 
Hive,WITHOUT_CLASSIFICATION,//  Since we're passing the object output by the UDTF directly to the next 
Hive,WITHOUT_CLASSIFICATION,//  which is the minimum non-0 value 0.01 in this case. 
Hive,WITHOUT_CLASSIFICATION,//  Set pending to false since scheduling is about to run. Any triggers up to this point   will be handled in the next run.   A new request may come in right after this is set to false but before the actual scheduling.   This will be handled in this run but will cause an immediate run after which is harmless.   This is mainly to handle a trySchedue request while in the middle of a run - since the event   which triggered it may not be processed for all tasks in the run. 
Hive,WITHOUT_CLASSIFICATION,//  2. Handle sessions that are being destroyed by users. Destroy implies return. 
Hive,WITHOUT_CLASSIFICATION,//  unless already installed on all the cluster nodes we'll have to 
Hive,WITHOUT_CLASSIFICATION,//  Repeated NULL permutations. 
Hive,WITHOUT_CLASSIFICATION,//  Will also read the last row. 
Hive,WITHOUT_CLASSIFICATION,//  __HIVE_DEFAULT_NULL__ is the system default value for null and empty string.   TODO: we should allow user to specify default partition or HDFS file location. 
Hive,WITHOUT_CLASSIFICATION,//  so wrap it in a big catch Throwable statement. 
Hive,WITHOUT_CLASSIFICATION,/*    * for inner joins push a 'is not null predicate' to the join sources for   * every non nullSafe predicate.    */
Hive,WITHOUT_CLASSIFICATION,//  The default equals provided by thrift compares the comments too for   equality thus we need to compare the relevant fields here. 
Hive,WITHOUT_CLASSIFICATION,//  Return node 
Hive,WITHOUT_CLASSIFICATION,//  LOG.info("Read hash code for " + Utils.toStringBinary(key 0 length) 
Hive,WITHOUT_CLASSIFICATION,//  we need to set the merge work that has been created as part of the dummy store walk. If a   merge work already exists for this merge join operator add the dummy store work to the 
Hive,WITHOUT_CLASSIFICATION,// CombineHiveInputFormat may produce FileSplit that is not OrcSplit 
Hive,WITHOUT_CLASSIFICATION,/*    * STRING.   *    * Can be used to write CHAR and VARCHAR when the caller takes responsibility for   * truncation/padding issues.    */
Hive,WITHOUT_CLASSIFICATION,//  Lead on the whole partition not the iterator range 
Hive,WITHOUT_CLASSIFICATION,// for fullAcid tables we don't delete files for commands with OVERWRITE - we create a new   base_x.  (there is Insert Overwrite and Load Data Overwrite) 
Hive,WITHOUT_CLASSIFICATION,// add the privileges supported in authorization mode V1 
Hive,WITHOUT_CLASSIFICATION,//  construct the list of columns that need to be projected 
Hive,WITHOUT_CLASSIFICATION,//  this is guaranteed to be positive because types only have children   ids greater than their own id. 
Hive,WITHOUT_CLASSIFICATION,//  properties file used to configure log4j2 
Hive,WITHOUT_CLASSIFICATION,//  SR.SW.wait Lock we are examining is waiting.  In this case we keep   looking as it's possible that something in front is blocking it or   that the other locker hasn't checked yet and he could lock as well or 
Hive,WITHOUT_CLASSIFICATION,//  We've already locked the table as the input don't relock it as the output. 
Hive,WITHOUT_CLASSIFICATION,//  if the event is already replayed then no need to replay it again. 
Hive,WITHOUT_CLASSIFICATION,//  constant byte arrays 
Hive,WITHOUT_CLASSIFICATION,//  The partition location already existed and may contain data. Lets try to   populate those statistics that don't require a full scan of the data. 
Hive,WITHOUT_CLASSIFICATION,//  earlier implementation have quoted boolean values...so the new implementation should preserve this 
Hive,WITHOUT_CLASSIFICATION,//  Translated includes may be a superset of writer includes due to cache. 
Hive,WITHOUT_CLASSIFICATION,//  Create table in database in specific location 
Hive,WITHOUT_CLASSIFICATION,//  this is the small table side. 
Hive,WITHOUT_CLASSIFICATION,//  verify that partitioned table partition property set worked. 
Hive,WITHOUT_CLASSIFICATION,//  Check an edge case where the DIRECT_SQL_MAX_QUERY_LENGTH does not allow one 'IN' clause with single value. 
Hive,WITHOUT_CLASSIFICATION,//  if this parent does not contain a constant at this position we   continue to look at other positions. 
Hive,WITHOUT_CLASSIFICATION,//  Construct a KerberosToken -- relies on ProxyUser configuration. Will be the client making   the request on top of the HS2's user. Accumulo will require proper proxy-user auth configs. 
Hive,WITHOUT_CLASSIFICATION,//  if orc table restrict changing the file format as it can break schema evolution 
Hive,WITHOUT_CLASSIFICATION,//  Null last 
Hive,WITHOUT_CLASSIFICATION,//  it must be the server uri added by an older version HS2 
Hive,WITHOUT_CLASSIFICATION,//  Add ColumnStatistics for tbl to metastore DB via ObjectStore 
Hive,WITHOUT_CLASSIFICATION,/*      * Add a vector partition descriptor to partition descriptor removing duplicate object.     *     * If the same vector partition descriptor has already been allocated share that object.      */
Hive,WITHOUT_CLASSIFICATION,//  avoid processing the same config multiple times check marker 
Hive,WITHOUT_CLASSIFICATION,/* For reads whatever SARG maybe applicable to base it's not applicable to delete_delta since it has no      * user columns.  For Compaction there is never a SARG.      *  */
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setTime(java.lang.String java.sql.Time   * java.util.Calendar)    */
Hive,WITHOUT_CLASSIFICATION,//  Single-Column Long specific imports. 
Hive,WITHOUT_CLASSIFICATION,//  Find the location of the table 
Hive,WITHOUT_CLASSIFICATION,//  Sin(double) 
Hive,WITHOUT_CLASSIFICATION,//  Pretend we are in HS2. 
Hive,WITHOUT_CLASSIFICATION,//  If logging is disabled deny everything. 
Hive,WITHOUT_CLASSIFICATION,//  We started with a single DRL so we assume there will be no consecutive missing blocks   after the cache has inserted cache data. We also assume all the missing parts will   represent one or several column chunks since we always cache on column chunk boundaries. 
Hive,WITHOUT_CLASSIFICATION,// in order for this to work hive-site.xml must be on the classpath 
Hive,WITHOUT_CLASSIFICATION,//  A branch is hit. 
Hive,WITHOUT_CLASSIFICATION,/*      * set outputFromWdwFnProcessing      */
Hive,WITHOUT_CLASSIFICATION,//  Go over childPullUpPredicates. If a predicate only contains columns in   'columnsMapped' construct a new predicate based on mapping. 
Hive,WITHOUT_CLASSIFICATION,//  init keyFields 
Hive,WITHOUT_CLASSIFICATION,//  We will iterate through the children: if it is an INSERT we will traverse 
Hive,WITHOUT_CLASSIFICATION,//  We use BytesWritable because it supports Comparable for our TreeMap. 
Hive,WITHOUT_CLASSIFICATION,//  renew the metastore since the cluster type is unencrypted 
Hive,WITHOUT_CLASSIFICATION,//  if MSB is set to 1 then next qPrime MSB bits contains the value of   number of zeroes.   if MSB is set to 0 then number of zeroes is contained within pPrime - p   bits. 
Hive,WITHOUT_CLASSIFICATION,//  get the ndv 
Hive,WITHOUT_CLASSIFICATION,//     If the patterns OR-AND-EqOp or OR-EqOp are not matched we bail out 
Hive,WITHOUT_CLASSIFICATION,//  TODO: shut down HS2? 
Hive,WITHOUT_CLASSIFICATION,/*        * Why cannot we just use the ExprNodeEvaluator on the column?       * - because on the reduce-side it is initialized based on the rowOI of the HiveTable       *   and not the OI of the parent of this Operator on the reduce-side        */
Hive,WITHOUT_CLASSIFICATION,//  shut down all the zk servers 
Hive,WITHOUT_CLASSIFICATION,//  multiple udfs with the same max type. Unless we find a lower one   we'll give up. 
Hive,WITHOUT_CLASSIFICATION,//  Type interval_year_month (LongColumnVector storing months). 
Hive,WITHOUT_CLASSIFICATION,//  3: Create a partitioned table T2 => 1 event 
Hive,WITHOUT_CLASSIFICATION,//  parse command line 
Hive,WITHOUT_CLASSIFICATION,//  schema of the map-reduce 'value' object - this is heterogeneous 
Hive,WITHOUT_CLASSIFICATION,//  That is guaranteed to fit any maximum allocation. 
Hive,WITHOUT_CLASSIFICATION,// sort ascending by resource nulls first 
Hive,WITHOUT_CLASSIFICATION,//  n-gram estimator object 
Hive,WITHOUT_CLASSIFICATION,//  Convert children to aggParameters 
Hive,WITHOUT_CLASSIFICATION,//  corRel.getCondition was here however Correlate was updated so it 
Hive,WITHOUT_CLASSIFICATION,//  RESOURCE_TYPE 
Hive,WITHOUT_CLASSIFICATION,//  LastAnalyzed is stored per column but thrift object has it per multiple columns.   Luckily nobody actually uses it so we will set to lowest value of all columns for now. 
Hive,WITHOUT_CLASSIFICATION,//  copy cloneToWork to ensure RDD cache still works 
Hive,WITHOUT_CLASSIFICATION,// was false 
Hive,WITHOUT_CLASSIFICATION,//  The output files of a FileSink can be merged if they are either not being written to a table   or are being written to a table which is not bucketed 
Hive,WITHOUT_CLASSIFICATION,//  test if we need group-by shuffle 
Hive,WITHOUT_CLASSIFICATION,//  0 Pending task which is not finishable 
Hive,WITHOUT_CLASSIFICATION,//  dummy vertex is treated as a branch of a join operator 
Hive,WITHOUT_CLASSIFICATION,// Try to parse ms where there is no millisecond part in input expected to return .000 as ms 
Hive,WITHOUT_CLASSIFICATION,//  checks if a resource has to be uploaded to HDFS for yarn-cluster mode 
Hive,WITHOUT_CLASSIFICATION,//  Case 1- find rows which belong to write Ids that are not valid. 
Hive,WITHOUT_CLASSIFICATION,//  total size of the inputs 
Hive,WITHOUT_CLASSIFICATION,//  connection properties 
Hive,WITHOUT_CLASSIFICATION,//  Creating a new connection is expensive so we'll reuse this object 
Hive,WITHOUT_CLASSIFICATION,//  test both inputs repeating 
Hive,WITHOUT_CLASSIFICATION,//  Add back the non-expired session. No need to notify we are the only ones waiting. 
Hive,WITHOUT_CLASSIFICATION,//  The state has changed between this and previous check within this method.   The failed update was rendered irrelevant so we just exit. 
Hive,WITHOUT_CLASSIFICATION,//  Should ignore the failure 
Hive,WITHOUT_CLASSIFICATION,/*            * Self-Describing Input Format will convert its data to the table schema. So there           * will be no VectorMapOperator conversion needed.            */
Hive,WITHOUT_CLASSIFICATION,//  Then scale back. 
Hive,WITHOUT_CLASSIFICATION,/*  * convert a RexNode to an ExprNodeDesc  */
Hive,WITHOUT_CLASSIFICATION,//  use the object pool rather than creating a new object 
Hive,WITHOUT_CLASSIFICATION,//  The response will have one entry per table and hence we get only one ValidWriteIdList 
Hive,WITHOUT_CLASSIFICATION,//  Can only happens w/zcr for a single input buffer. 
Hive,WITHOUT_CLASSIFICATION,/*    * These members have information for assigning a row column objects into the VectorizedRowBatch   * columns.   *   * We say "target" because when there is conversion the data type being converted is the source.    */
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.UpdateFragmentResponseProto.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,//  invalid inflation factor 
Hive,WITHOUT_CLASSIFICATION,//  Compare the field names using ignore-case semantics 
Hive,WITHOUT_CLASSIFICATION,//  Run with --check-index and save the output to file so it can be checked. 
Hive,WITHOUT_CLASSIFICATION,//  TXN_TO_WRITE_IDS 
Hive,WITHOUT_CLASSIFICATION,//  static class Iterator; 
Hive,WITHOUT_CLASSIFICATION,//  For efficiency alpha is multiplied by m^2 
Hive,WITHOUT_CLASSIFICATION,//  If there are more cores use the number of cores 
Hive,WITHOUT_CLASSIFICATION,//  Data needs deletion. Check if trash may be skipped.   Trash may be skipped iff:    1. deleteData == true obviously.    2. tbl is external.    3. Either      3.1. User has specified PURGE from the commandline and if not      3.2. User has set the table to auto-purge. 
Hive,WITHOUT_CLASSIFICATION,//  Determine who to run as 
Hive,WITHOUT_CLASSIFICATION,//  upgrade from 2.0.0 schema and re-validate 
Hive,WITHOUT_CLASSIFICATION,//  value based compare.. remove first 
Hive,WITHOUT_CLASSIFICATION,// make sure both buckets are not empty 
Hive,WITHOUT_CLASSIFICATION,//  a Field contains a FieldType which in turn contains a type 
Hive,WITHOUT_CLASSIFICATION,//  Bootstrap dump shouldn't fail if the table is dropped/renamed while dumping it.   Just log a debug message and skip it. 
Hive,WITHOUT_CLASSIFICATION,//  tables and tables inside view. Otherwise Calcite will treat them as the same. 
Hive,WITHOUT_CLASSIFICATION,//  output is bucketed 
Hive,WITHOUT_CLASSIFICATION,// is present only in the ql/test directory 
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.SignableVertexSpec.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,//  SQL is 1-indexed Druid is 0-indexed. 
Hive,WITHOUT_CLASSIFICATION,//  use the tez grouper to combine splits once per bucket 
Hive,WITHOUT_CLASSIFICATION,//  no matter STATS_GENERATED is USER or TASK all need to re-calculate the stats:   USER: alter table .. update statistics   TASK: from some sql operation which could collect and compute stats 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:UpdateFragmentResponseProto) 
Hive,WITHOUT_CLASSIFICATION,//  Missing fields? 
Hive,WITHOUT_CLASSIFICATION,/*  Pushes a node on to the stack.  */
Hive,WITHOUT_CLASSIFICATION,//  ensure metatore site.xml does not get to override this 
Hive,WITHOUT_CLASSIFICATION,// create a delta directory 
Hive,WITHOUT_CLASSIFICATION,//  heartbeats can only be sent for open transactions.   there is a race between committing/aborting a transaction and heartbeat.   Example: If a heartbeat is sent for committed txn exception will be thrown.   Similarly if we don't send a heartbeat metastore server might abort a txn   for missed heartbeat right before commit txn call. 
Hive,WITHOUT_CLASSIFICATION,//  string representation of folding constant. 
Hive,WITHOUT_CLASSIFICATION,//  The length of the scratch byte array that needs to be passed to bigIntegerBytes etc. 
Hive,WITHOUT_CLASSIFICATION,// do nothing as it's not a partitioned table 
Hive,WITHOUT_CLASSIFICATION,//  Division by 0. 
Hive,WITHOUT_CLASSIFICATION,//  Changes the owner to a user and verify the change 
Hive,WITHOUT_CLASSIFICATION,//  START_ROW_OFFSET 
Hive,WITHOUT_CLASSIFICATION,//  If the conf does not define any transactional properties the parseInt() should receive   a value of 1 which will set AcidOperationalProperties to a default type and return that. 
Hive,WITHOUT_CLASSIFICATION,//    construct object of above type   
Hive,WITHOUT_CLASSIFICATION,//  Create the http/https url   JDBC driver will set up an https url if ssl is enabled otherwise http 
Hive,WITHOUT_CLASSIFICATION,//  The split ends within (and would read) the last row of this slice. Exact match. 
Hive,WITHOUT_CLASSIFICATION,//   LOG.debug("spillSerializeRow spilled batchIndex " + batchIndex + " length " + length); 
Hive,WITHOUT_CLASSIFICATION,//  For whatever reason reserve failed. 
Hive,WITHOUT_CLASSIFICATION,//  An error or couldn't find the task - lastSetGuaranteed does not change. The logic here   does not account for one special case - we have updated the task but the response was   lost and we have received a network error. The state could be inconsistent making 
Hive,WITHOUT_CLASSIFICATION,//  output format string is not supported anymore warn user of deprecation 
Hive,WITHOUT_CLASSIFICATION,//  This is a test. The parameter hive.test.dummystats.publisher's value   denotes the method which needs to throw an error. 
Hive,WITHOUT_CLASSIFICATION,// one call by init one called here. 
Hive,WITHOUT_CLASSIFICATION,//  c1:int   c2:boolean   c3:double   c4:string   c5:array<int> 
Hive,WITHOUT_CLASSIFICATION,// do nothing to handle RU/D if we add another status 
Hive,WITHOUT_CLASSIFICATION,//  Try fixing this should result in new fixed file. 
Hive,WITHOUT_CLASSIFICATION,//  For permanent functions check for any resources from local filesystem. 
Hive,WITHOUT_CLASSIFICATION,//  Check if ckpt property set in table/partition in B after bootstrap load. 
Hive,WITHOUT_CLASSIFICATION,//  Call the different round flavor. 
Hive,WITHOUT_CLASSIFICATION,//  Test the idempotent behavior of CREATE FUNCTION 
Hive,WITHOUT_CLASSIFICATION,// setting success to false to make sure that if the listener fails rollback happens. 
Hive,WITHOUT_CLASSIFICATION,//  Only create a map-join if the user explicitly gave a join (without a mapjoin hint) 
Hive,WITHOUT_CLASSIFICATION,//  context for list bucketing. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setCharacterStream(java.lang.String   * java.io.Reader int)    */
Hive,WITHOUT_CLASSIFICATION,// this only responds to ^C 
Hive,WITHOUT_CLASSIFICATION,//  verify the column name 
Hive,WITHOUT_CLASSIFICATION,//  plumb the KryoMessageCodec instance through the constructors. 
Hive,WITHOUT_CLASSIFICATION,// ========================== 30000 range starts here ========================// 
Hive,WITHOUT_CLASSIFICATION,//  The lateral view forward operator has 2 children a SELECT(*) and   a SELECT(cols) (for the UDTF operator) The child at index 0 is the   SELECT(*) because that's the way that the DAG was constructed. We   only want to get the predicates from the SELECT(*). 
Hive,WITHOUT_CLASSIFICATION,//  MATERIALIZATION_TIME 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#cancel()    */
Hive,WITHOUT_CLASSIFICATION,//  throw a HiveException for other than rcfile and orcfile. 
Hive,WITHOUT_CLASSIFICATION,//  unparseTranslator. 
Hive,WITHOUT_CLASSIFICATION,//  and return the ones which have a marked column 
Hive,WITHOUT_CLASSIFICATION,//  This Project will be what the old input maps to 
Hive,WITHOUT_CLASSIFICATION,//  Return defaultName if selExpr is not a simple xx.yy.zz 
Hive,WITHOUT_CLASSIFICATION,//  If table cache is not yet prewarmed add this to a set which the prewarm thread can check   so that the prewarm thread does not add it back 
Hive,WITHOUT_CLASSIFICATION,//  Joda parsing only supports up to millisecond precision 
Hive,WITHOUT_CLASSIFICATION,//  Use exact byte array which might generate array out of bounds... 
Hive,WITHOUT_CLASSIFICATION,//  total characters = 4; byte length = 10 
Hive,WITHOUT_CLASSIFICATION,//  Check the other side of the join using the DynamicListContext 
Hive,WITHOUT_CLASSIFICATION,//  We assume this hashtable is loaded only when tez is enabled 
Hive,WITHOUT_CLASSIFICATION,//  Do first comparison as UNSIGNED. 
Hive,WITHOUT_CLASSIFICATION,//  Then master commits if everything goes well. 
Hive,WITHOUT_CLASSIFICATION,//  no join no groupby no distinct no lateral view no subq   no CTAS or insert not analyze command and single sourced. 
Hive,WITHOUT_CLASSIFICATION,//  Don't cache the filesystem object for now; Tez closes it and FS cache will fix all that 
Hive,WITHOUT_CLASSIFICATION,//  Check mapred 
Hive,WITHOUT_CLASSIFICATION,//  test basic case 
Hive,WITHOUT_CLASSIFICATION,//  Make sure the FunctionInfo is listed as PERSISTENT (rather than TEMPORARY) 
Hive,WITHOUT_CLASSIFICATION,//  Started ok; initialize context for new batch. 
Hive,WITHOUT_CLASSIFICATION,//  operation 
Hive,WITHOUT_CLASSIFICATION,//  we don't need to add this new entry since there's already an overlapping one 
Hive,WITHOUT_CLASSIFICATION,//  There are several Hive RelNode types which do not have their own visit() method   defined in the HiveRelShuttle interface which need to be handled appropriately here.   Per jcamachorodriguez we should not encounter HiveMultiJoin/HiveSortExchange   during these checks so no need to add those here. 
Hive,WITHOUT_CLASSIFICATION,//  TODO: Make expr traversal recursive. Extend to traverse inside   elements of DNF/CNF & extract more deterministic pieces out. 
Hive,WITHOUT_CLASSIFICATION,//  Utility methods used to store pairs of ints as long. 
Hive,WITHOUT_CLASSIFICATION,//  test-specific 
Hive,WITHOUT_CLASSIFICATION,//  Instantiate the ValueProcessor based on the input type 
Hive,WITHOUT_CLASSIFICATION,//  MY_ENUMSET 
Hive,WITHOUT_CLASSIFICATION,//  Test is dependent on getting a new buffer within 1MB. 
Hive,WITHOUT_CLASSIFICATION,//  Key is full table name string of format <db_name>.<table_name> 
Hive,WITHOUT_CLASSIFICATION,//     the rest of optimizations 
Hive,WITHOUT_CLASSIFICATION,//  only used for materialized views   only used for materialized views   only used for materialized views   only used for materialized views   only used for materialized views 
Hive,WITHOUT_CLASSIFICATION,/*     With bucketed target table Union All is not removed    ekoifman:apache-hive-3.0.0-SNAPSHOT-bin ekoifman$ tree  ~/dev/hiverwgit/itests/hive-unit/target/tmp/org.apache.hadoop.hive.ql.TestAcidOnTez-1505510130462/warehouse/t/.hive-staging_hive_2017-09-15_14-16-32_422_4626314315862498838-1//Users/ekoifman/dev/hiverwgit/itests/hive-unit/target/tmp/org.apache.hadoop.hive.ql.TestAcidOnTez-1505510130462/warehouse/t/.hive-staging_hive_2017-09-15_14-16-32_422_4626314315862498838-1/└── -ext-10000    ├── 000000_0    │   ├── _orc_acid_version    │   └── delta_0000001_0000001_0000    │       └── bucket_00000    └── 000001_0        ├── _orc_acid_version        └── delta_0000001_0000001_0000            └── bucket_000015 directories 4 files */
Hive,WITHOUT_CLASSIFICATION,//  interfere with the view creation). So skip the rest of this method. 
Hive,WITHOUT_CLASSIFICATION,//  check all the arguments 
Hive,WITHOUT_CLASSIFICATION,//  field to find record identifier in   field bucket is in in record id   OI for inspecting record id   OI for inspecting bucket id 
Hive,WITHOUT_CLASSIFICATION,//  Only first or second operator contains DPP pruning 
Hive,WITHOUT_CLASSIFICATION,//  Closing the chunked output stream early gives an error 
Hive,WITHOUT_CLASSIFICATION,//  since we don't clone jobConf per alias 
Hive,WITHOUT_CLASSIFICATION,//  TODO: Allocate work to remove the temporary files and make that   dependent on the redTask 
Hive,WITHOUT_CLASSIFICATION,//  Evaluate 
Hive,WITHOUT_CLASSIFICATION,//  Cannot have SCALAR SCALAR. 
Hive,WITHOUT_CLASSIFICATION,/*          * Common repeated join result processing.          */
Hive,WITHOUT_CLASSIFICATION,//  may have been   created by   baseCommitter.commitJob() 
Hive,WITHOUT_CLASSIFICATION,//  Check for this pattern.   The pattern matching could be simplified if rules can be applied   during decorrelation.     CorrelateRel(left correlation condition = true)     LeftInputRel     Aggregate (groupby (0) single_value())       Project-A (may reference coVar) 
Hive,WITHOUT_CLASSIFICATION,//  If not in test mode then do no create the appender 
Hive,WITHOUT_CLASSIFICATION,//  Always validate ACLs 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#getQueryTimeout()    */
Hive,WITHOUT_CLASSIFICATION,//  For backward compatibility: fieldNames can also be integer Strings. 
Hive,WITHOUT_CLASSIFICATION,//  Replace VOID type with string when the output is a temp table or   local files.   A VOID type can be generated under the query:     select NULL from tt;   or   insert overwrite local directory "abc" select NULL from tt;     where there is no column type to which the NULL value should be   converted. 
Hive,WITHOUT_CLASSIFICATION,//  a string of pathnames   the path separator   the file separator in a directory 
Hive,WITHOUT_CLASSIFICATION,//  test null propagation 
Hive,WITHOUT_CLASSIFICATION,/*  * DropTableDesc. * TODO: this is currently used for both drop table and drop partitions.  */
Hive,WITHOUT_CLASSIFICATION,//  make sure REDUCE task environment points to HADOOP_CREDSTORE_PASSWORD 
Hive,WITHOUT_CLASSIFICATION,//  We need some initial values in case user don't call initialize() 
Hive,WITHOUT_CLASSIFICATION,//  Config settings 
Hive,WITHOUT_CLASSIFICATION,/*    * If a QB is such that the aggregation expressions need to be handled by   * the Windowing PTF; we invoke this function to clear the AggExprs on the dest.    */
Hive,WITHOUT_CLASSIFICATION,//  Add the DP path to the list of input paths 
Hive,WITHOUT_CLASSIFICATION,//  Get all the stuff for SD. Don't do empty-list check - we expect partitions do have SDs. 
Hive,WITHOUT_CLASSIFICATION,//  see if we need to fetch default constraints from metastore 
Hive,WITHOUT_CLASSIFICATION,//  the alias is modified to subq1:a and subq2:a from a to identify the right sub-query. 
Hive,WITHOUT_CLASSIFICATION,//  scale down/up the column statistics based on the changes in number of   rows from each parent. For ex: If there are 2 parents for JOIN operator   with 1st parent having 200 rows and 2nd parent having 2000 rows. Now if   the new number of rows after applying join rule is 10 then the column   stats for columns from 1st parent should be scaled down by 200/10 = 20x   and stats for columns from 2nd parent should be scaled down by 200x 
Hive,WITHOUT_CLASSIFICATION,//  Check the stats 
Hive,WITHOUT_CLASSIFICATION,//  If any table/partition is updated then update repl state in db object 
Hive,WITHOUT_CLASSIFICATION,//  make sure the schemas of both sides are the same 
Hive,WITHOUT_CLASSIFICATION,//  Verify if no create table on t1. Only table t2 should  be created in retry. 
Hive,WITHOUT_CLASSIFICATION,//  Signature for wrapped loader see comments in LoadFuncBasedInputDriver.initialize 
Hive,WITHOUT_CLASSIFICATION,// as --properties-file contains the spark.* keys that are meant for SparkConf object. 
Hive,WITHOUT_CLASSIFICATION,//  check if this user has necessary privileges (reqPrivs) on this object 
Hive,WITHOUT_CLASSIFICATION,//  We will requeue and not kill the queries that are not running yet. 
Hive,WITHOUT_CLASSIFICATION,//  update the create table descriptor with the resulting schema. 
Hive,WITHOUT_CLASSIFICATION,//  Optimize inner join keys of small table results. 
Hive,WITHOUT_CLASSIFICATION,//  The middle and lowest longwords highest digit number is LONGWORD_DECIMAL_DIGITS. 
Hive,WITHOUT_CLASSIFICATION,//  Note: this code would be invalid for transactional tables of any kind. 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise fall through and process the what we saw before possible trailing blanks. 
Hive,WITHOUT_CLASSIFICATION,//  Use hive type name. 
Hive,WITHOUT_CLASSIFICATION,//  whether session is running in silent mode or not 
Hive,WITHOUT_CLASSIFICATION,//  optional int64 purged_memory_bytes = 1; 
Hive,WITHOUT_CLASSIFICATION,/*      * Partition and order by.      */
Hive,WITHOUT_CLASSIFICATION,//  Mixed source (all types) 
Hive,WITHOUT_CLASSIFICATION,//  if not boolean column return half the number of rows 
Hive,WITHOUT_CLASSIFICATION,//  fill in coltype 
Hive,WITHOUT_CLASSIFICATION,//  the column positions in the operator should be like this   <----non-partition columns---->|<--static partition columns-->|<--dynamic partition columns-->          ExprNodeColumnDesc      |      ExprNodeConstantDesc    |     ExprNodeColumnDesc             from input           |         generate itself      |        from input                                  | 
Hive,WITHOUT_CLASSIFICATION,//  If Keep alive is enabled do not close the connection. 
Hive,WITHOUT_CLASSIFICATION,//  this is our row to test expressions on 
Hive,WITHOUT_CLASSIFICATION,//  Buffer is at the top of the heap. 
Hive,WITHOUT_CLASSIFICATION,//  make the new join rel 
Hive,WITHOUT_CLASSIFICATION,//  3) We annotate the Aggregate operator with this info 
Hive,WITHOUT_CLASSIFICATION,// this table needs to be converted to CRUD Acid 
Hive,WITHOUT_CLASSIFICATION,//  Should make (100 +inf) 
Hive,WITHOUT_CLASSIFICATION,//  Get or create Context object. If we create it we have to clean it later as well. 
Hive,WITHOUT_CLASSIFICATION,//  disable feature 
Hive,WITHOUT_CLASSIFICATION,//  Set to true by default.  Only actively set in the multiple key case to support Outer Join. 
Hive,WITHOUT_CLASSIFICATION,//  Add new entry for this table 
Hive,WITHOUT_CLASSIFICATION,//  Flush current group batch as last batch of group. 
Hive,WITHOUT_CLASSIFICATION,//  infer if any column can be primary key based on column statistics 
Hive,WITHOUT_CLASSIFICATION,//  Value. 
Hive,WITHOUT_CLASSIFICATION,//  First the cross join 
Hive,WITHOUT_CLASSIFICATION,//  Keys 
Hive,WITHOUT_CLASSIFICATION,//  Partition can't have this name 
Hive,WITHOUT_CLASSIFICATION,// this covers backward compat cases where this prop may have been set already 
Hive,WITHOUT_CLASSIFICATION,//  If this is the first time the table is being initialized to 'transactional=true'   any valid value can be set for the 'transactional_properties'. 
Hive,WITHOUT_CLASSIFICATION,//  expand to all supported privileges 
Hive,WITHOUT_CLASSIFICATION,//  a normal column is also a string 
Hive,WITHOUT_CLASSIFICATION,// char(x)varchar(x) types 
Hive,WITHOUT_CLASSIFICATION,//  Merge and sort result 
Hive,WITHOUT_CLASSIFICATION,//  Check isShutdown opportunistically; it's never unset. 
Hive,WITHOUT_CLASSIFICATION,//  query per mbean attribute 
Hive,WITHOUT_CLASSIFICATION,//  so it doesn't make sense to have both and make sure one matches the other. 
Hive,WITHOUT_CLASSIFICATION,//  Build regular expression for operator rule. 
Hive,WITHOUT_CLASSIFICATION,//  First check - we should not have repeats in results 
Hive,WITHOUT_CLASSIFICATION,//  finally connect the union work with work 
Hive,WITHOUT_CLASSIFICATION,//  get compatible taskId for bucket-name 
Hive,WITHOUT_CLASSIFICATION,//  If we have the optional fourth parameter make sure it's also an integer 
Hive,WITHOUT_CLASSIFICATION,//  Empty value. 
Hive,WITHOUT_CLASSIFICATION,/*  base this on HiveOperation instead?  this and DDL_NO_LOCK is peppered all over the code...         Seems much cleaner if each stmt is identified as a particular HiveOperation (which I'd think         makes sense everywhere).  This however would be problematic for merge... */
Hive,WITHOUT_CLASSIFICATION,//  Not a flattened struct no need to unflatten 
Hive,WITHOUT_CLASSIFICATION,//  Redo create-table/view analysis because it's not part of   doPhase1. 
Hive,WITHOUT_CLASSIFICATION,//  Explain type 
Hive,WITHOUT_CLASSIFICATION,//  We want to make sure this runs at a low priority in the background 
Hive,WITHOUT_CLASSIFICATION,//  set of input to the join that should be   omitted by the output 
Hive,WITHOUT_CLASSIFICATION,//  For the tab.* case add all the columns to the fieldList   from the input schema 
Hive,WITHOUT_CLASSIFICATION,//  Note Hadoop 2.7.1 onwards includes a RestCsrfPreventionFilter class that is   usable as-is. However since we have to work on a multitude of hadoop versions   including very old ones we either duplicate their code here or not support   an XSRFFilter on older versions of hadoop So we duplicate to minimize evil(ugh).   See HADOOP-12691 for details of what this is doing.   This method should never be called if Hadoop 2.7+ is available. 
Hive,WITHOUT_CLASSIFICATION,//  no more rows 
Hive,WITHOUT_CLASSIFICATION,//  found dynamic partition pruning operator 
Hive,WITHOUT_CLASSIFICATION,//  In light of results from union queries we need to be aware that   sub-directories can exist in the partition directory. We want to   ignore these sub-directories and promote merged files to the   partition directory. 
Hive,WITHOUT_CLASSIFICATION,//  production is: bool 
Hive,WITHOUT_CLASSIFICATION,//  template <ClassName> <ValueType> <VarianceFormula> <DescriptionName> 
Hive,WITHOUT_CLASSIFICATION,//  time part of the timestamp should not be skipped 
Hive,WITHOUT_CLASSIFICATION,//  OrcInputFormat will get a mock fs from FileSystem.get; add global files. 
Hive,WITHOUT_CLASSIFICATION,//  2a=b 
Hive,WITHOUT_CLASSIFICATION,//  The options --principal/--keypad do not work with --proxy-user in spark-submit.sh   (see HIVE-15485 SPARK-5493 SPARK-19143) so Hive could only support doAs or   delegation token renewal but not both. Since doAs is a more common case if both   are needed we choose to favor doAs. So when doAs is enabled we use kinit command   otherwise we pass the principal/keypad to spark to support the token renewal for 
Hive,WITHOUT_CLASSIFICATION,//  Form a truncated boolean include array for our vector/row deserializers. 
Hive,WITHOUT_CLASSIFICATION,//  if this is not a HASH groupby return 
Hive,WITHOUT_CLASSIFICATION,//  If the parents have already been created create the last child only 
Hive,WITHOUT_CLASSIFICATION,//  Check that the hcat result is valid and or has a valid json 
Hive,WITHOUT_CLASSIFICATION,//  If lock response is ACQUIRED we can create the heartbeater 
Hive,WITHOUT_CLASSIFICATION,//  If op has parents it is guaranteed to be 1. 
Hive,WITHOUT_CLASSIFICATION,//  randomUUID is slow since its cryptographically secure only first query will take time. 
Hive,WITHOUT_CLASSIFICATION,//  Drop table after dump 
Hive,WITHOUT_CLASSIFICATION,//  Get the sorted children expr strings 
Hive,WITHOUT_CLASSIFICATION,//  Disallow update and delete on non-acid tables 
Hive,WITHOUT_CLASSIFICATION,//  rest of the data is serialized long values for the bitset which are supposed to be bitwise-ORed. 
Hive,WITHOUT_CLASSIFICATION,//  For a vertex group all Outputs use the same Key-class Val-class and partitioner.   Pick any one source vertex to figure out the Edge configuration. 
Hive,WITHOUT_CLASSIFICATION,/*  Allow use of external byte[] for efficiency  */
Hive,WITHOUT_CLASSIFICATION,//  The one join column for this specialized class. 
Hive,WITHOUT_CLASSIFICATION,// use FsShell to change group permissions and extended ACL's recursively 
Hive,WITHOUT_CLASSIFICATION,//  we need to convert the jobContext into a jobConf   0.18 jobConf (Hive) vs 0.20+ jobContext (HCat) 
Hive,WITHOUT_CLASSIFICATION,//  No next partition.   No next partition.   Do nothing. 
Hive,WITHOUT_CLASSIFICATION,//  Optimize the query: select count(distinct keys) from T where   T is bucketized and sorted by T   Partial aggregation can be done by the mappers in this scenario 
Hive,WITHOUT_CLASSIFICATION,//  check the properties expected in hive client without metastore 
Hive,WITHOUT_CLASSIFICATION,//  Test with empty array 
Hive,WITHOUT_CLASSIFICATION,//  unknown | F | F 
Hive,WITHOUT_CLASSIFICATION,/*      * For now use Calcite' default formulas for propagating NDVs up the Query     * Tree.      */
Hive,WITHOUT_CLASSIFICATION,//  The output stream of serialized objects 
Hive,WITHOUT_CLASSIFICATION,//  This is to avoid getting notified of low memory too often and flushing too often. 
Hive,WITHOUT_CLASSIFICATION,//  store the byte every eight elements or 
Hive,WITHOUT_CLASSIFICATION,//  We create data buffers for these columns so we can copy strings into those columns by value. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure we pad the right amount of spaces; valLength is in terms of code points   while StringUtils.rpad() is based on the number of java chars. 
Hive,WITHOUT_CLASSIFICATION,//  nothing to do if there is no user HS2 connection configuration file   or beeline-site.xml in the path 
Hive,WITHOUT_CLASSIFICATION,//  Also convert to/from binary-sortable representation. 
Hive,WITHOUT_CLASSIFICATION,//  there are no nulls in either input vector 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: UDAF is not included in ExprColMap 
Hive,WITHOUT_CLASSIFICATION,//  Pairwise: Column1HasNulls Column1IsRepeating Column2HasNulls Column2IsRepeating 
Hive,WITHOUT_CLASSIFICATION,//  This can happen for numbers less than 0.1   For 0.001234: bdPrecision=4 bdScale=6   In this case we'll set the type to have the same precision as the scale. 
Hive,WITHOUT_CLASSIFICATION,//  Same Query   Within dag priority - lower values indicate higher priority. 
Hive,WITHOUT_CLASSIFICATION,//  We update twice to accurately detect if cache is dirty or not 
Hive,WITHOUT_CLASSIFICATION,//  add constant struct field names references overhead 
Hive,WITHOUT_CLASSIFICATION,//  Divide it by 2 so that we can have more reducers 
Hive,WITHOUT_CLASSIFICATION,//  Parse until key separator (currentLevel + 1). 
Hive,WITHOUT_CLASSIFICATION,//  rethrow the SQLException as is 
Hive,WITHOUT_CLASSIFICATION,//  Create non-existent path for 0-row results 
Hive,WITHOUT_CLASSIFICATION,//  introduce RS and EX before FS 
Hive,WITHOUT_CLASSIFICATION,//  Sanity check to make sure there is no alias conflict after merge. 
Hive,WITHOUT_CLASSIFICATION,//  Quote if the database requires it 
Hive,WITHOUT_CLASSIFICATION,//  Left side 
Hive,WITHOUT_CLASSIFICATION,//  Fail heartbeater so that we can get a RuntimeException from the query.   More specifically it's the original IOException thrown by either MR's or Tez's progress monitoring loop. 
Hive,WITHOUT_CLASSIFICATION,//  Print only the errors the operation log and the query results. 
Hive,WITHOUT_CLASSIFICATION,/*        * Use the input RR of TableScanOperator in case there is no map-side       * reshape of input.       * If the parent of ReduceSinkOperator is PTFOperator use it's       * output RR.        */
Hive,WITHOUT_CLASSIFICATION,//  HIVE-13625 
Hive,WITHOUT_CLASSIFICATION,//  the threshold should be less than 12K bytes for p = 14.   The reason to divide by 5 is in sparse mode after serialization the   entriesin sparse map are compressed and delta encoded as varints. The   worst case size of varints are 5 bytes. Hence 12K/5 ~= 2400 entries in 
Hive,WITHOUT_CLASSIFICATION,//  As this is called from replication task the user is the user who has fired the repl command.   This is required for standalone metastore authentication. 
Hive,WITHOUT_CLASSIFICATION,//  column/scalar IF 
Hive,WITHOUT_CLASSIFICATION,//  Mapping from column name to default value 
Hive,WITHOUT_CLASSIFICATION,//  We only expect -5 here because we'll get whichever of the partitions published its stats   last. 
Hive,WITHOUT_CLASSIFICATION,//  Each ValidWriteIdList is separated with "$" and each one maps to one table 
Hive,WITHOUT_CLASSIFICATION,// first set basic stats to true 
Hive,WITHOUT_CLASSIFICATION,//  memory pressure. 
Hive,WITHOUT_CLASSIFICATION,//  With uncompressed streams we know we are done earlier. 
Hive,WITHOUT_CLASSIFICATION,// return the current block's key length 
Hive,WITHOUT_CLASSIFICATION,//  Always set the semijoin optimization as victim. 
Hive,WITHOUT_CLASSIFICATION,//  Locations for each of the storage types 
Hive,WITHOUT_CLASSIFICATION,//  Case when there are changes in multiple table properties. 
Hive,WITHOUT_CLASSIFICATION,//  If the default pool is not disabled override the size with the specified parallelism. 
Hive,WITHOUT_CLASSIFICATION,//  Always keep transactional tables as managed tables. 
Hive,WITHOUT_CLASSIFICATION,/*      * Basic algorithm:     *     * 1. Determine if rounding part meets banker's rounding rules for rounding.     * 2. Scale away fractional digits if present.     * 3. If rounding clear integer rounding portion and add 1.     *      */
Hive,WITHOUT_CLASSIFICATION,//  Test in http mode 
Hive,WITHOUT_CLASSIFICATION,//  Add to self. 
Hive,WITHOUT_CLASSIFICATION,//  write out the buffer into a file. Add beeline commands for autocommit and close 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:LlapOutputSocketInitMessage) 
Hive,WITHOUT_CLASSIFICATION,//  Set bitvector[index] := 1 
Hive,WITHOUT_CLASSIFICATION,//  Reset the driver 
Hive,WITHOUT_CLASSIFICATION,//  Use the defalut methods for next in the child class 
Hive,WITHOUT_CLASSIFICATION,//  CREATION_METADATA 
Hive,WITHOUT_CLASSIFICATION,//  Use its conversion ability. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setSQLXML(java.lang.String   * java.sql.SQLXML)    */
Hive,WITHOUT_CLASSIFICATION,//  add new token to shared store   need to persist expiration along with password 
Hive,WITHOUT_CLASSIFICATION,//  Now generate the matchs.  Single small table values will be put into the big table   batch and come back in matchs.  Any multiple small table value results will go into 
Hive,WITHOUT_CLASSIFICATION,//  The only time this condition should be false is in the case of dynamic partitioning 
Hive,WITHOUT_CLASSIFICATION,//  test null on left 
Hive,WITHOUT_CLASSIFICATION,//  sparse-sparse overload to dense 
Hive,WITHOUT_CLASSIFICATION,//  FS 
Hive,WITHOUT_CLASSIFICATION,//  Verify batch size 
Hive,WITHOUT_CLASSIFICATION,//  the new table is rhs table 
Hive,WITHOUT_CLASSIFICATION,//  restrict instantiation 
Hive,WITHOUT_CLASSIFICATION,//  If the task hasn't started - inform about fragment completion immediately. It's possible for   the callable to never run. 
Hive,WITHOUT_CLASSIFICATION,/*        * This is a column that we don't want (i.e. not included) -- we are done.        */
Hive,WITHOUT_CLASSIFICATION,/*    * HiveHistory Object    */
Hive,WITHOUT_CLASSIFICATION,//  we don't support using multiple chars as delimiters within complex types 
Hive,WITHOUT_CLASSIFICATION,//  The c'tor should throw the error 
Hive,WITHOUT_CLASSIFICATION,//  Find the positions/order of the sorted columns in the table corresponding 
Hive,WITHOUT_CLASSIFICATION,//  Iterate through the line and invoke the addCmdPart method whenever the delimiter is seen that is not inside a 
Hive,WITHOUT_CLASSIFICATION,//  The number of integer digits in the decimal.  When the integer portion is zero this is 0. 
Hive,WITHOUT_CLASSIFICATION,//  Cancel existing watches 
Hive,WITHOUT_CLASSIFICATION,//  check if no compaction set for this table 
Hive,WITHOUT_CLASSIFICATION,//  Add the value to the ArrayList 
Hive,WITHOUT_CLASSIFICATION,//  Include state for cached columns 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: We keep the TypeInfo and dataTypePhysicalVariation arrays. 
Hive,WITHOUT_CLASSIFICATION,//  -u <database url> 
Hive,WITHOUT_CLASSIFICATION,//  But note that any sql error will also result in a return of false. 
Hive,WITHOUT_CLASSIFICATION,//  The most correct behavior is to throw only if the request tries to enable the read-only mode. 
Hive,WITHOUT_CLASSIFICATION,//  Start a third batch but don't close it. 
Hive,WITHOUT_CLASSIFICATION,//  Should generate ['q' +inf) 
Hive,WITHOUT_CLASSIFICATION,//  To indicate whether the pages should be thrown away or not. 
Hive,WITHOUT_CLASSIFICATION,/*  BLOBSTORE section  */
Hive,WITHOUT_CLASSIFICATION,//  Passing char/varchar arguments should prefer the version of evaluate() with Text args. 
Hive,WITHOUT_CLASSIFICATION,/*      * For a predicate check if it is a candidate for pushing down as limit optimization.     * The expression must be of the form rankFn <|<= constant.      */
Hive,WITHOUT_CLASSIFICATION,//  When doing updates and deletes we always want to sort on the rowid because the ACID   reader will expect this sort order when doing reads.  So   ignore whatever comes from the table and enforce this sort order instead. 
Hive,WITHOUT_CLASSIFICATION,//  stats from the record writer and store in the previous fsp that is cached 
Hive,WITHOUT_CLASSIFICATION,// keep track of subqueries which are scalar correlated and contains aggregate   subquery expression. This will later be special cased in Subquery remove rule   for correlated scalar queries with aggregate we have take care of the case where   inner aggregate happens on empty result 
Hive,WITHOUT_CLASSIFICATION,//  We do not need to evaluate the input row for this parent.   So we can just forward it to the child of this MuxOperator. 
Hive,WITHOUT_CLASSIFICATION,//  In general case can have unlimited # of branches   we currently only handle either 1 or 2 branch. 
Hive,WITHOUT_CLASSIFICATION,//  check column order and types 
Hive,WITHOUT_CLASSIFICATION,//  input.get(i+1) since input.get(0) is the schema; 
Hive,WITHOUT_CLASSIFICATION,//  DynamicSerDe always writes out BytesWritable 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setInt(java.lang.String int)    */
Hive,WITHOUT_CLASSIFICATION,// Use destination table's db location. 
Hive,WITHOUT_CLASSIFICATION,//  Other format pattern should also work 
Hive,WITHOUT_CLASSIFICATION,//  Pass null to complete a batch 
Hive,WITHOUT_CLASSIFICATION,//  partcol=... AND nonpartcol=...   is replaced with partcol=... AND TRUE   which will be folded to partcol=...   This cannot be done also for OR 
Hive,WITHOUT_CLASSIFICATION,//  Maybe someone removed the field; probably ok to ignore. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setTimestamp(java.lang.String   * java.sql.Timestamp)    */
Hive,WITHOUT_CLASSIFICATION,//  optional parameter 
Hive,WITHOUT_CLASSIFICATION,//  Read the template into a string; 
Hive,WITHOUT_CLASSIFICATION,//  optional int64 timestamp = 3; 
Hive,WITHOUT_CLASSIFICATION,//  get the input expression 
Hive,WITHOUT_CLASSIFICATION,//  write ID with additional uncommitted IDs. Should match. 
Hive,WITHOUT_CLASSIFICATION,//  join keys have difference sizes? 
Hive,WITHOUT_CLASSIFICATION,//  Setup vectorized deserialization for the key and value. 
Hive,WITHOUT_CLASSIFICATION,//  fourth group 
Hive,WITHOUT_CLASSIFICATION,//  1) to partitioned table 
Hive,WITHOUT_CLASSIFICATION,//  The Deadline Exception needs no retry and be thrown immediately. 
Hive,WITHOUT_CLASSIFICATION,//  check if path conforms to Hive's file name convention. Hive expects filenames to be in specific format   like 000000_0 but "LOAD DATA" commands can let you add any files to any partitions/tables without   renaming. This can cause MoveTask to remove files in some cases where MoveTask assumes the files are   are generated by speculatively executed tasks.   Example: MoveTask thinks the following files are same   part-m-00000_1417075294718   part-m-00001_1417075294718   Assumes 1417075294718 as taskId and retains only large file supposedly generated by speculative execution.   This can result in data loss in case of CONCATENATE/merging. Filter out files that does not match Hive's   filename convention. 
Hive,WITHOUT_CLASSIFICATION,//  Serde info 
Hive,WITHOUT_CLASSIFICATION,//  If it was a merge task or a local map reduce task nothing can be inferred 
Hive,WITHOUT_CLASSIFICATION,//  Hang onto a byte array for holding smaller byte values 
Hive,WITHOUT_CLASSIFICATION,//  This particular test doesn't care which of the lower pri tasks gets the duck. 
Hive,WITHOUT_CLASSIFICATION,//  Have to do this in reverse order so that we drop the materialized view first. 
Hive,WITHOUT_CLASSIFICATION,// hive.spark.* keys are passed down to the RemoteDriver via --conf 
Hive,WITHOUT_CLASSIFICATION,//  Private methods should never catch SQLException and then throw MetaException.  The public   methods depend on SQLException coming back so they can detect and handle deadlocks.  Private   methods should only throw MetaException when they explicitly know there's a logic error and   they want to throw past the public methods.     All public methods that write to the database have to check for deadlocks when a SQLException   comes back and handle it if they see one.  This has to be done with the connection pooling   in mind.  To do this they should call checkRetryable() AFTER rolling back the db transaction   and then they should catch RetryException and call themselves recursively. See commitTxn for an example. 
Hive,WITHOUT_CLASSIFICATION,//  override this for using extended FieldObject 
Hive,WITHOUT_CLASSIFICATION,//  run given query and validate expecated result 
Hive,WITHOUT_CLASSIFICATION,//  Only update someone waiting for info if we have the info. 
Hive,WITHOUT_CLASSIFICATION,//  We're going to wait for the session to be abandoned. 
Hive,WITHOUT_CLASSIFICATION,//  Inform the scheduler that this fragment has been killed.   If the kill failed - that means the task has already hit a final condition 
Hive,WITHOUT_CLASSIFICATION,// sd.setBucketCols(new ArrayList<String>(2));  sd.getBucketCols().add("name"); 
Hive,WITHOUT_CLASSIFICATION,//  Found 
Hive,WITHOUT_CLASSIFICATION,//  ^(TOK_DROPFUNCTION identifier ifExists? $temp?) 
Hive,WITHOUT_CLASSIFICATION,//  Check if DB in B have ckpt property is set to bootstrap dump location used in B and missing for table/partition. 
Hive,WITHOUT_CLASSIFICATION,//  set values by reference copy the data out and verify equality 
Hive,WITHOUT_CLASSIFICATION,//  Find a free port 
Hive,WITHOUT_CLASSIFICATION,//  Move the query results to the query cache directory. 
Hive,WITHOUT_CLASSIFICATION,//  Partitioned table:   Need to get the old stats of the partition   and update the table stats based on the old and new stats. 
Hive,WITHOUT_CLASSIFICATION,//  query column stats for column whose stats were updated in the previous call 
Hive,WITHOUT_CLASSIFICATION,//  Move past key separator. 
Hive,WITHOUT_CLASSIFICATION,//  2nd split is for delta_200_200 which is filtered out entirely by "txns" 
Hive,WITHOUT_CLASSIFICATION,//  Jump to the end of current line. When a multiple line query is executed with -e parameter   it is passed in as one line string separated with '\n' 
Hive,WITHOUT_CLASSIFICATION,// nothing to be done 
Hive,WITHOUT_CLASSIFICATION,//  Case of analyze command 
Hive,WITHOUT_CLASSIFICATION,//  this should never happen. however we want to make sure we propagate the exception 
Hive,WITHOUT_CLASSIFICATION,/*    * Verify table for Key: row and byte[] x Hash Table: HashMap    */
Hive,WITHOUT_CLASSIFICATION,/*  List of partitions that are required - populated from processing each event  */
Hive,WITHOUT_CLASSIFICATION,//  We buffer in a org.apache.hadoop.hive.serde2.ByteStream.Output since that is what   is used by VectorSerializeRow / SerializeWrite.  Periodically we flush this buffer   to disk. 
Hive,WITHOUT_CLASSIFICATION,//  LAST_EVENT 
Hive,WITHOUT_CLASSIFICATION,//  A udf which sleeps for some number of ms to simulate a long running query 
Hive,WITHOUT_CLASSIFICATION,//  There are 2 paths from the TS operator (or a previous LVJ operator)   to the same LateralViewJoinOperator.   TS -> SelectOperator(*) -> LateralViewJoinOperator   TS -> SelectOperator (gets cols for UDTF) -> UDTFOperator0   -> LateralViewJoinOperator   
Hive,WITHOUT_CLASSIFICATION,//  source file system   list of source paths 
Hive,WITHOUT_CLASSIFICATION,//  Nothing to prune for this MapWork 
Hive,WITHOUT_CLASSIFICATION,//  No escaping happened so we are already done. 
Hive,WITHOUT_CLASSIFICATION,//  Small table values are set to null. 
Hive,WITHOUT_CLASSIFICATION,/*    * Verify table for Key: Long x Hash Table: HashSet    */
Hive,WITHOUT_CLASSIFICATION,//  Error in the script itself - likely caused by an incompatible change or new functionality / states added. 
Hive,WITHOUT_CLASSIFICATION,/*  n/a  */
Hive,WITHOUT_CLASSIFICATION,//  Not setting a payload since the MRInput payload is the same and can be accessed. 
Hive,WITHOUT_CLASSIFICATION,//  if low memory canary is set and if records after set canary exceeds threshold trigger a flush. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#setMaxRows(int)    */
Hive,WITHOUT_CLASSIFICATION,// initialize all the dummy ops 
Hive,WITHOUT_CLASSIFICATION,//  Used by DatumWriter.  Applications should not call.  
Hive,WITHOUT_CLASSIFICATION,//  in case of udtf selectOutputRR may be null. 
Hive,WITHOUT_CLASSIFICATION,//  ~ Constructors ----------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  tiemestamp 
Hive,WITHOUT_CLASSIFICATION,//  MAX_TABLES 
Hive,WITHOUT_CLASSIFICATION,//  keep track of the principals on which privileges have been checked for   this object 
Hive,WITHOUT_CLASSIFICATION,//  count(distinct x y) count(distinct y x) we find the correct mapping. 
Hive,WITHOUT_CLASSIFICATION,//  query per mbean 
Hive,WITHOUT_CLASSIFICATION,//  metaListeners in HiveMetaStore#cleanupRawStore 
Hive,WITHOUT_CLASSIFICATION,//  Do not mess with Table instance 
Hive,WITHOUT_CLASSIFICATION,//  Retrieve the tables from the metastore in batches. Some databases like 
Hive,WITHOUT_CLASSIFICATION,//  Do not assign the input value object to the timestampValues array element.   Always copy value using set* methods. 
Hive,WITHOUT_CLASSIFICATION,//  reduced by 1 
Hive,WITHOUT_CLASSIFICATION,//  Map precision to the number bytes needed for binary conversion. 
Hive,WITHOUT_CLASSIFICATION,//  Hive can't handle select rank() over(order by sum(c1)/sum(c2)) from t1 group by c3   but can handle    select rank() over (order by c4) from   (select sum(c1)/sum(c2)  as c4 from t1 group by c3) t2;   so introduce a project on top of this gby. 
Hive,WITHOUT_CLASSIFICATION,//  Get the input table and make sure the keys match 
Hive,WITHOUT_CLASSIFICATION,//  no harProcessor regular operation 
Hive,WITHOUT_CLASSIFICATION,/*    * Creates a job request object and sets up execution environment. Creates a thread pool   * to execute job requests.   *   * @param requestType   *          Job request type   *   * @param concurrentRequestsConfigName   *          Config name to be used to extract number of concurrent requests to be serviced.   *   * @param jobTimeoutConfigName   *          Config name to be used to extract maximum time a task can execute a request.   *   * @param enableCancelTask   *          A flag to indicate whether to cancel the task when exception TimeoutException   *          or InterruptedException or CancellationException raised.   *    */
Hive,WITHOUT_CLASSIFICATION,//  LlapInputFormat needs to know the file schema to decide if schema evolution is supported. 
Hive,WITHOUT_CLASSIFICATION,//  Is this required ? 
Hive,WITHOUT_CLASSIFICATION,//  (specific to the multi group by optimization) 
Hive,WITHOUT_CLASSIFICATION,//  not retrying when user explicitly stops the test 
Hive,WITHOUT_CLASSIFICATION,//  event loads will behave similar to table loads with one crucial difference   precursor order is strict and each event must be processed after the previous one.   The way we handle this strict order is as follows:   First we start with a taskChainTail which is a dummy noop task (a DependecyCollectionTask)   at the head of our event chain. For each event we process we tell analyzeTableLoad to   create tasks that use the taskChainTail as a dependency. Then we collect all those tasks   and introduce a new barrier task(also a DependencyCollectionTask) which depends on all   these tasks. Then this barrier task becomes our new taskChainTail. Thus we get a set of   tasks as follows:                     --->ev1.task1--                          --->ev2.task1--                  /               \                        /               \    evTaskRoot-->*---->ev1.task2---*--> ev1.barrierTask-->*---->ev2.task2---*->evTaskChainTail                  \               /                   --->ev1.task3--     Once this entire chain is generated we add evTaskRoot to rootTasks so as to execute the   entire chain 
Hive,WITHOUT_CLASSIFICATION,//  For toString the time does not matter 
Hive,WITHOUT_CLASSIFICATION,/*  this is only used in the error code path  */
Hive,WITHOUT_CLASSIFICATION,//  As open txn doesn't allocate writeid the 2 entries for aborted and committed should be retained. 
Hive,WITHOUT_CLASSIFICATION,//  Repair metadata in HMS 
Hive,WITHOUT_CLASSIFICATION,// the time currentCompactions is generated and now 
Hive,WITHOUT_CLASSIFICATION,// throw new IllegalStateException(msg); 
Hive,WITHOUT_CLASSIFICATION,//  Instantiate the underlying output format  since there is no way to parametrize instance of Class 
Hive,WITHOUT_CLASSIFICATION,//  If writing delta dirs we need to make a clone of original options to avoid polluting it for 
Hive,WITHOUT_CLASSIFICATION,//  LATIN SMALL LETTER TURNED M U+026F (2 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  Connect using the JDBC URL and user/pass from conf 
Hive,WITHOUT_CLASSIFICATION,//  convert logs to RowSet 
Hive,WITHOUT_CLASSIFICATION,//  Trigger a scheduling run - in case there's some task which was waiting for this node to 
Hive,WITHOUT_CLASSIFICATION,//  If the cookie based authentication is not enabled or the request does   not have a valid cookie use the kerberos or password based authentication 
Hive,WITHOUT_CLASSIFICATION,// excluded overrides included 
Hive,WITHOUT_CLASSIFICATION,// The selected vector represents selected rows.  Clone the selected vector 
Hive,WITHOUT_CLASSIFICATION,//  Not final since it may change later due to DECIMAL_64. 
Hive,WITHOUT_CLASSIFICATION,//  Re-serialize the splits after grouping. 
Hive,WITHOUT_CLASSIFICATION,//  Get all data out. 
Hive,WITHOUT_CLASSIFICATION,//  CONCERN: We currently differentiate DECIMAL columns by their precision and scale... 
Hive,WITHOUT_CLASSIFICATION,//  we first use t.getParameters() to prune the stats 
Hive,WITHOUT_CLASSIFICATION,//  In that case we just pick one and spill. 
Hive,WITHOUT_CLASSIFICATION,//  this work is now moved to the parentWork thus we should 
Hive,WITHOUT_CLASSIFICATION,//  r--r--r-- 
Hive,WITHOUT_CLASSIFICATION,//  Add udfData to UDF if necessary 
Hive,WITHOUT_CLASSIFICATION,//  kids of reduce sink operator or mapjoin operators merged into root task 
Hive,WITHOUT_CLASSIFICATION,// Set filter expression 
Hive,WITHOUT_CLASSIFICATION,//  Catch throwables in a best-effort to report job status back to the client. It's   re-thrown so that the executor can destroy the affected thread (or the JVM can   die or whatever would happen if the throwable bubbled up). 
Hive,WITHOUT_CLASSIFICATION,//  Ignore this particular error is expected. 
Hive,WITHOUT_CLASSIFICATION,//  NULL NULL 
Hive,WITHOUT_CLASSIFICATION,//  merge it with children predicates 
Hive,WITHOUT_CLASSIFICATION,//  DB opereations none of them are enforced by Hive right now. 
Hive,WITHOUT_CLASSIFICATION,//  Statistics to track allocations 
Hive,WITHOUT_CLASSIFICATION,//  Trigger bootstrap replication 
Hive,WITHOUT_CLASSIFICATION,//  KEY_TYPE_PTR 
Hive,WITHOUT_CLASSIFICATION,/*    * fastSetFromBigIntegerBytes high word multiplier is 2^(56 + 56)   *   *    (2^56)*(2^56) =   *      5192296858534827628530496329220096 or   *     (1234567890123456789012345678901234)   *     (         1         2         3    )   *      5192296858534827628530496329220096 or   *      5192296858534827628530496329220096  (16 digit comma'd)    */
Hive,WITHOUT_CLASSIFICATION,//  Normally on import trying to create a table or a partition in a db that does not yet exist   is a error condition. However in the case of a REPL LOAD it is possible that we are trying   to create tasks to create a table inside a db that as-of-now does not exist but there is   a precursor Task waiting that will create it before this is encountered. Thus we instantiate   defaults and do not error out in that case.   the above will change now since we are going to split replication load in multiple execution   tasks and hence we could have created the database earlier in which case the waitOnPrecursor will 
Hive,WITHOUT_CLASSIFICATION,//  Encode 
Hive,WITHOUT_CLASSIFICATION,//  Fix the non-printable chars 
Hive,WITHOUT_CLASSIFICATION,//  Put the filter "skewed column = skewed keys" in op 
Hive,WITHOUT_CLASSIFICATION,//  Pull the output schema out of the TaskAttemptContext 
Hive,WITHOUT_CLASSIFICATION,//  2. Generate backtrack Select operator 
Hive,WITHOUT_CLASSIFICATION,// verify if the filter is correct and returns 2 rows and contains 2 columns and the contents match 
Hive,WITHOUT_CLASSIFICATION,/*    * Does the move task involve moving to a local file system    */
Hive,WITHOUT_CLASSIFICATION,//  In LLAP only mode grace hash join will be disabled later on by the LlapDispatcher anyway.   Since the presence of Grace Hash Join disables some "native" vectorization optimizations   we will disable the grace hash join now before vectorization is done. 
Hive,WITHOUT_CLASSIFICATION,//  if compile is being called multiple times clear the old shutdownhook 
Hive,WITHOUT_CLASSIFICATION,//  \0 to terminate 
Hive,WITHOUT_CLASSIFICATION,//  attach the original predicate to the table scan operator for index   optimizations that require the pushed predicate before pcr & later   optimizations are applied 
Hive,WITHOUT_CLASSIFICATION,//  Retrieve *all* partitions from the table. 
Hive,WITHOUT_CLASSIFICATION,// RecordReader rr = reader.rows(); 
Hive,WITHOUT_CLASSIFICATION,//  reassign a new port just in case if one of the MR services grabbed the last one 
Hive,WITHOUT_CLASSIFICATION,//  Test select root.col1.a from root:struct<col1:struct<a:booleanb:double>col2:double> 
Hive,WITHOUT_CLASSIFICATION,//  should have no more rows 
Hive,WITHOUT_CLASSIFICATION,//  We do not call startGroup on operators below because we are batching rows in   an output batch and the semantics will not work.   super.startGroup(); 
Hive,WITHOUT_CLASSIFICATION,//  listOfNeedFetchNext contains all tables that we have joined data in their   candidateStorage and we need to clear candidate storage and promote their   nextGroupStorage to candidateStorage and fetch data until we reach a   new group. 
Hive,WITHOUT_CLASSIFICATION,//  Set the newly-constructed ranges as the current state 
Hive,WITHOUT_CLASSIFICATION,//  Make sure we don't get stuck at 0 time however unlikely that is. 
Hive,WITHOUT_CLASSIFICATION,//  However if the above query contains dynamic partitions subQ1 and   subQ2 have to write to directories: Parent/DynamicPartition/Child_1   and Parent/DynamicPartition/Child_1 respectively.   The movetask that follows subQ1 and subQ2 tasks still moves the directory   'Parent' 
Hive,WITHOUT_CLASSIFICATION,//  Now update this record as being worked on by this worker. 
Hive,WITHOUT_CLASSIFICATION,//  The numerator of the TABLESAMPLE clause 
Hive,WITHOUT_CLASSIFICATION,//  Also if dynamic partitioning is being used we want to   set appropriate list of columns for the columns to be dynamically specified.   These would be partition keys too so would also need to be removed from   output schema and partcols 
Hive,WITHOUT_CLASSIFICATION,//  NEW_FUNC 
Hive,WITHOUT_CLASSIFICATION,// check 1st batch 
Hive,WITHOUT_CLASSIFICATION,// SQL2REL_LOGGER.fine("There are no unique keys for " + left); 
Hive,WITHOUT_CLASSIFICATION,// if acid is off post upgrade you can't make any tables acid - will throw 
Hive,WITHOUT_CLASSIFICATION,//  may be processed by a thread which ends up executing before a task. 
Hive,WITHOUT_CLASSIFICATION,//  replicate the incremental drops 
Hive,WITHOUT_CLASSIFICATION,//  Copy string value as-is 
Hive,WITHOUT_CLASSIFICATION,//  if kerberos is not enabled 
Hive,WITHOUT_CLASSIFICATION,//  constant char projection 
Hive,WITHOUT_CLASSIFICATION,//  Only selects and filters are allowed 
Hive,WITHOUT_CLASSIFICATION,//  We are skipping calling checkOutputSpecs() for each partition   As it can throw a FileAlreadyExistsException when more than one   mapper is writing to a partition.   See HCATALOG-490 also to avoid contacting the namenode for each new   FileOutputFormat instance.   In general this should be ok for most FileOutputFormat implementations   but may become an issue for cases when the method is used to perform   other setup tasks. 
Hive,WITHOUT_CLASSIFICATION,//  Use a large capacity that doesn't require expansion yet. 
Hive,WITHOUT_CLASSIFICATION,// if destf is an existing directory:  if replace is true delete followed by rename(mv) is equivalent to replace  if replace is false rename (mv) actually move the src under dest dir  if destf is an existing file rename is actually a replace and do not need   to delete the file first 
Hive,WITHOUT_CLASSIFICATION,//  classloader as parent can pollute the session. See HIVE-11878 
Hive,WITHOUT_CLASSIFICATION,//  try reading table2 as user2 - should succeed 
Hive,WITHOUT_CLASSIFICATION,/*  10 files x 1000 size for 1 splits  */
Hive,WITHOUT_CLASSIFICATION,//  COLUMN_STATS_ACCURATE in params is set to correct value 
Hive,WITHOUT_CLASSIFICATION,//  Exceeds MAX_VALUE 
Hive,WITHOUT_CLASSIFICATION,//  ignore and use UUID instead 
Hive,WITHOUT_CLASSIFICATION,//  If it's a non-deterministic UDF set unknown to true 
Hive,WITHOUT_CLASSIFICATION,//  ignore as this is expected 
Hive,WITHOUT_CLASSIFICATION,//  no need to go further down for a select op with all file sink or script   child since all cols are needed for these ops   However if one of the children is not file sink or script we still go down. 
Hive,WITHOUT_CLASSIFICATION,//  No need to run CBO (table ref or virtual table) or not supported 
Hive,WITHOUT_CLASSIFICATION,//  Ignore the exception 
Hive,WITHOUT_CLASSIFICATION,//  Revert the projected columns back because batch can be re-used by our parent operators. 
Hive,WITHOUT_CLASSIFICATION,//  Start the protocol server after properly authenticating with daemon keytab. 
Hive,WITHOUT_CLASSIFICATION,// create an empty priv set 
Hive,WITHOUT_CLASSIFICATION,//  Make sure we don't give out more than allowed due to double/rounding artifacts. 
Hive,WITHOUT_CLASSIFICATION,//  The small table hash table for the native vectorized map join operator. 
Hive,WITHOUT_CLASSIFICATION,/*              * Common left-semi join result processing.              */
Hive,WITHOUT_CLASSIFICATION,//  don't need this anymore 
Hive,WITHOUT_CLASSIFICATION,//  MODIFIER LETTER SMALL L U+02E1 (2 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  Retries will be done till decaying factor reduces to 0.  Decaying Factor is 2.   So log to base 2 of batchSize plus 1 or Most Significant Bit   of batchsize plus 1 will give the number of expected calls 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#registerOutParameter(java.lang.String int   * java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  no matter loc is the table location or part location it must be a   directory. 
Hive,WITHOUT_CLASSIFICATION,/*    * traverse a path of Filter Projects to get to the TableScan.   * In case of Unique keys stop if you reach a Project it will be handled   * by the invocation on the Project.   * In case of getting the base rowCount of a Path keep going past a Project.    */
Hive,WITHOUT_CLASSIFICATION,//  For PARTIAL2 and FINAL: ObjectInspectors for partial aggregations 
Hive,WITHOUT_CLASSIFICATION,//  whole value is copied including spaces 
Hive,WITHOUT_CLASSIFICATION,//  The table is not yet loaded in cache 
Hive,WITHOUT_CLASSIFICATION,//  If this is an insert originalWriteId should be set to this transaction.  If not   it will be reset by the following if anyway. 
Hive,WITHOUT_CLASSIFICATION,//  VARCHAR tests 
Hive,WITHOUT_CLASSIFICATION,//  memoize decorator for getOutputSizeInternal 
Hive,WITHOUT_CLASSIFICATION,//  traverse the aborted txns list starting at first aborted txn index 
Hive,WITHOUT_CLASSIFICATION,/*        * Create a thread pool with no queue wait time to execute the operation. This will ensure       * that job requests are rejected if there are already maximum number of threads busy.        */
Hive,WITHOUT_CLASSIFICATION,//  Some parts of the system can't handle rows with zero fields so 
Hive,WITHOUT_CLASSIFICATION,//  template <ClassNamePrefix> <ReturnType> <OperandType> <FuncName> <OperandCast> <ResultCast> 
Hive,WITHOUT_CLASSIFICATION,//  if this is a delimiter directive reset our delimiter 
Hive,WITHOUT_CLASSIFICATION,//  preventing empty ctor from being callable 
Hive,WITHOUT_CLASSIFICATION,//  An AccessControlException may be caused for other different errors   but we take it as if our path is read-only 
Hive,WITHOUT_CLASSIFICATION,//  All qfiles handled via this... 
Hive,WITHOUT_CLASSIFICATION,//  We'd like to move this to HiveMetaStore for any non-native table but   first we need to support storing NULL for location on a table 
Hive,WITHOUT_CLASSIFICATION,//  We initialize the cache 
Hive,WITHOUT_CLASSIFICATION,//  NOSASL 
Hive,WITHOUT_CLASSIFICATION,//  fastIsLong returns false. 
Hive,WITHOUT_CLASSIFICATION,//  do nothing here we will throw an exception in the following block 
Hive,WITHOUT_CLASSIFICATION,//  with many arguments. 
Hive,WITHOUT_CLASSIFICATION,//  Try getObjectInspector 
Hive,WITHOUT_CLASSIFICATION,//  the currAliasId and CurrTopOp is not valid any more 
Hive,WITHOUT_CLASSIFICATION,//  3. See if the IN (STRUCT(EXP1 EXP2..) has atleast one expression with partition   column with single table alias. If not bail out.   We might have expressions containing only partitioning columns say T1.A + T2.B   where T1.A and T2.B are both partitioning columns. 
Hive,WITHOUT_CLASSIFICATION,// so with 2 FileSinks and 4 buckets FS1 should see (01)(22)(03)(24) since data is sorted by ROW__ID where tnxid is the first component  FS2 should see (11)(32)(13)(34) 
Hive,WITHOUT_CLASSIFICATION,//  String className = this.getClass().getName(); 
Hive,WITHOUT_CLASSIFICATION,//  Binary search to find the closest bucket that v should go into.   'bin' should be interpreted as the bin to shift right in order to accomodate   v. As a result bin is in the range [0N] where N means that the value v is   greater than all the N bins currently in the histogram. It is also possible that 
Hive,WITHOUT_CLASSIFICATION,//  Generate dummy pre-upgrade scripts with valid SQL 
Hive,WITHOUT_CLASSIFICATION,//  groupingSets are known at map/reducer side; but have to do real processing 
Hive,WITHOUT_CLASSIFICATION,//  Report size to the extent possible. 
Hive,WITHOUT_CLASSIFICATION,//  Comparing on time is not sufficient since two may be created at the same time   in which case inserting into a TreeSet/Map would break 
Hive,WITHOUT_CLASSIFICATION,//  determine class 
Hive,WITHOUT_CLASSIFICATION,//  Descending sort based on split size| Followed by file name. Followed by startPosition. 
Hive,WITHOUT_CLASSIFICATION,//  optional string connected_vertex_name = 1; 
Hive,WITHOUT_CLASSIFICATION,//  The following data should be changed 
Hive,WITHOUT_CLASSIFICATION,// ship additional artifacts for example for Tez 
Hive,WITHOUT_CLASSIFICATION,//  query has run capture the time 
Hive,WITHOUT_CLASSIFICATION,//  HIVE-14444 pending rename: after 
Hive,WITHOUT_CLASSIFICATION,//  create a fetch operator 
Hive,WITHOUT_CLASSIFICATION,//  This value should go into smallBuffer. 
Hive,WITHOUT_CLASSIFICATION,//  TaskInfo instances for two different tasks will not be the same. Only a single instance should 
Hive,WITHOUT_CLASSIFICATION,//  Test that write can acquire after read 
Hive,WITHOUT_CLASSIFICATION,//  make both scaling up as follows   unscaledValue = significand * 5**(scale) *   2**(scale-twoScaleDown) 
Hive,WITHOUT_CLASSIFICATION,//  2nd task requested host1 got host1 
Hive,WITHOUT_CLASSIFICATION,//  3 Check data distribution in  buckets 
Hive,WITHOUT_CLASSIFICATION,// This class provides and implementation for a case insensitive token checker  for the lexical analysis part of antlr. By converting the token stream into  upper case at the time when lexical rules are checked this class ensures that the  lexical rules need to just match the token with upper case letters as opposed to  combination of upper case and lower case characteres. This is purely used for matching lexical  rules. The actual token text is stored in the same way as the user input without  actually converting it into an upper case. The token values are generated by the consume()  function of the super class ANTLRStringStream. The LA() function is the lookahead funtion  and is purely used for matching lexical rules. This also means that the grammar will only  accept capitalized tokens in case it is run from other tools like antlrworks which  do not have the ANTLRNoCaseStringStream implementation. 
Hive,WITHOUT_CLASSIFICATION,//  TableSpec ts is got from the query (user specified)   which means the user didn't specify partitions in their query 
Hive,WITHOUT_CLASSIFICATION,//  this map should map columnInfo to ExprConstantNodeDesc 
Hive,WITHOUT_CLASSIFICATION,//  If we couldn't find an asterisk it's not a prefix 
Hive,WITHOUT_CLASSIFICATION,//  state byte in the first record 
Hive,WITHOUT_CLASSIFICATION,//  Encode a schema with v0 write out. 
Hive,WITHOUT_CLASSIFICATION,//  Dont remove the operator for distincts 
Hive,WITHOUT_CLASSIFICATION,//  ... and where the transaction has already been committed as per snapshot taken 
Hive,WITHOUT_CLASSIFICATION,//  Now create a delete delta that has rowIds divisible by 3 but not by 2. This will produce 
Hive,WITHOUT_CLASSIFICATION,//  3/ write the null bytes 
Hive,WITHOUT_CLASSIFICATION,//  For all other data types use int conversion.  At some point we should have all   conversions make sure the value fits. 
Hive,WITHOUT_CLASSIFICATION,//  conversions 
Hive,WITHOUT_CLASSIFICATION,//  remember the dummy ops we created 
Hive,WITHOUT_CLASSIFICATION,//  This indicates we logged an inconsistency (from our point-of-view) and will not make this 
Hive,WITHOUT_CLASSIFICATION,//  optional .UserPayloadProto user_payload = 2; 
Hive,WITHOUT_CLASSIFICATION,//  CREATE_TIME 
Hive,WITHOUT_CLASSIFICATION,//  no alias to stage.. no local task 
Hive,WITHOUT_CLASSIFICATION,//  do nothing 
Hive,WITHOUT_CLASSIFICATION,// H2 - should allocate 
Hive,WITHOUT_CLASSIFICATION,//  Note that this method assumes you have already decided this is an Acid table.  It cannot 
Hive,WITHOUT_CLASSIFICATION,//  Due to reflection the jdo exception is wrapped in   invocationTargetException 
Hive,WITHOUT_CLASSIFICATION,//  Test dryrun of schema upgrade 
Hive,WITHOUT_CLASSIFICATION,//  be handled. 
Hive,WITHOUT_CLASSIFICATION,//  This could be due to either URI syntax error or File constructor   illegal arg; we don't really care which one it is. 
Hive,WITHOUT_CLASSIFICATION,//  This is fast path for query optimizations if we can find this info   quickly using   directSql do it. No point in failing back to slow path here. 
Hive,WITHOUT_CLASSIFICATION,//  We currently evaluate the IN (..) constants in special ways. 
Hive,WITHOUT_CLASSIFICATION,//  note - the row mapping is not relevant when aggregationBatchInfo::getDistinctBufferSetCount() == 1 
Hive,WITHOUT_CLASSIFICATION,//  compare if they are the same constant. 
Hive,WITHOUT_CLASSIFICATION,//  GroupBy query results as records (types defined by metastore) 
Hive,WITHOUT_CLASSIFICATION,//  if the driver registered in the driver manager get the connection via the driver manager 
Hive,WITHOUT_CLASSIFICATION,//  prevent equals from being overridden in sub-classes   always use ExprNodeDescEqualityWrapper   if you need any other equality than Object.equals() 
Hive,WITHOUT_CLASSIFICATION,// check empty DB 
Hive,WITHOUT_CLASSIFICATION,//  Get the string value and convert to a Date value. 
Hive,WITHOUT_CLASSIFICATION,//  verify that a multi byte LIKE expression matches a matching string 
Hive,WITHOUT_CLASSIFICATION,//  ok even if the data is not deleted 
Hive,WITHOUT_CLASSIFICATION,//  start index of -n means give the last n characters of the string 
Hive,WITHOUT_CLASSIFICATION,//  PRIMARY_KEYS 
Hive,WITHOUT_CLASSIFICATION,//  ELAPSED_MS 
Hive,WITHOUT_CLASSIFICATION,/*  * This is a pluggable policy to chose the candidate map-join table for converting a join to a * sort merge join. The leftmost table is chosen as the join table.  */
Hive,WITHOUT_CLASSIFICATION,//  4.1 Create structs 
Hive,WITHOUT_CLASSIFICATION,// we can get the number of rows from the first vector 
Hive,WITHOUT_CLASSIFICATION,//  timestamp/date is higher precedence than String_GROUP 
Hive,WITHOUT_CLASSIFICATION,//  IN clauses need to be combined by keeping all elements 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) SenumDefList  */
Hive,WITHOUT_CLASSIFICATION,//  If we have fired it already once we return and the test will fail 
Hive,WITHOUT_CLASSIFICATION,//  work.getTableSpecs() == null means it is not analyze command   and then if it is not followed by column stats we should clean   column stats 
Hive,WITHOUT_CLASSIFICATION,//  nice message 
Hive,WITHOUT_CLASSIFICATION,// not making this configurable best effort 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:IOSpecProto) 
Hive,WITHOUT_CLASSIFICATION,//  Delete the data in the tables which have other locations 
Hive,WITHOUT_CLASSIFICATION,// For some reason even with an MBeanException available to them Runtime exceptions  can still find their way through so treat them the same as MBeanException 
Hive,WITHOUT_CLASSIFICATION,//  4. Reopen is essentially just destroy + get a new session for a session in use. 
Hive,WITHOUT_CLASSIFICATION,//  We're only considering the first element of the IN list for the type 
Hive,WITHOUT_CLASSIFICATION,//  Use org.apache.hadoop.io.Text as our helper to go from byte[] to String. 
Hive,WITHOUT_CLASSIFICATION,//  In some places (e.g. FileInputFormat) this BlockLocation is used to   figure out sizes/offsets and so a completely blank one will not work. 
Hive,WITHOUT_CLASSIFICATION,//  don't fetch the footer PPD happens in MS. 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.CLIServiceClient#getResultSetMetadata(org.apache.hive.service.cli.OperationHandle)    */
Hive,WITHOUT_CLASSIFICATION,//  Now only string text int long byte and boolean comparisons   are treated as special cases.   For other types we reuse ObjectInspectorUtils.compare() 
Hive,WITHOUT_CLASSIFICATION,//  to writing an instrumentation agent for object size estimation 
Hive,WITHOUT_CLASSIFICATION,//  do nothing fall through and verify the data 
Hive,WITHOUT_CLASSIFICATION,//  Exclusives can never pass 
Hive,WITHOUT_CLASSIFICATION,/*       This denotes listing of any directories where during replication we want to take care of      db level operations first namely in our case its only during db creation on the replica      warehouse.    */
Hive,WITHOUT_CLASSIFICATION,//  char to binary conversion: include trailing spaces? 
Hive,WITHOUT_CLASSIFICATION,//  add the column only if the family has not already been added 
Hive,WITHOUT_CLASSIFICATION,//  Make new client since transport was closed for the last one. 
Hive,WITHOUT_CLASSIFICATION,//  Create some ACID tables: T10 T11 - unpartitioned table T12p T13p - partitioned table 
Hive,WITHOUT_CLASSIFICATION,//  Test various scenarios 
Hive,WITHOUT_CLASSIFICATION,//  Ignoring and continuing to watch for additional elements in the dir. 
Hive,WITHOUT_CLASSIFICATION,//  Leading spaces are significant 
Hive,WITHOUT_CLASSIFICATION,//  recreate table as external drop partition and it should 
Hive,WITHOUT_CLASSIFICATION,//  Test HiveConf property variable substitution in hive-site.xml 
Hive,WITHOUT_CLASSIFICATION,/*    * Computes the temporal run time statistics of the reducers   * for a specific JobId.    */
Hive,WITHOUT_CLASSIFICATION,//  Stores the temporal statistics in milliseconds for reducers   specific to a Job 
Hive,WITHOUT_CLASSIFICATION,// complete T2 txn 
Hive,WITHOUT_CLASSIFICATION,//  bail on mux operator because currently the mux operator masks the emit keys   of the constituent reduce sinks. 
Hive,WITHOUT_CLASSIFICATION,//  -i <init-query-file> 
Hive,WITHOUT_CLASSIFICATION,//  TBL 
Hive,WITHOUT_CLASSIFICATION,/*    * Initialize using target data type names.   * No projection -- the column range 0 .. types.size()-1    */
Hive,WITHOUT_CLASSIFICATION,//  check if there is data in the resultset 
Hive,WITHOUT_CLASSIFICATION,//  duplicate function with possibly replaced children 
Hive,WITHOUT_CLASSIFICATION,//  Find context for current input file 
Hive,WITHOUT_CLASSIFICATION,//  Yay! We short-circuited skip everything remaining in the batch and return. 
Hive,WITHOUT_CLASSIFICATION,//  Fetch the bucketing version from table scan operator 
Hive,WITHOUT_CLASSIFICATION,/*      * track the input ColumnInfos that are added to the output.     * if a columnInfo has multiple mappings; then add the column only once     * but carry the mappings forward.      */
Hive,WITHOUT_CLASSIFICATION,//  There should be 2 original bucket files (000000_0 and 000001_0) plus a new delta directory. 
Hive,WITHOUT_CLASSIFICATION,//  For dynamic partitioned hash join ReduceSinkMapJoinProc rule may not get run for all   of the ReduceSink parents because the parents of the MapJoin operator get   removed later on in this method. Keep track of the parent to mapjoin mapping 
Hive,WITHOUT_CLASSIFICATION,//  return immediately if batch is empty 
Hive,WITHOUT_CLASSIFICATION,//  INSERT EVENT to unpartitioned table 
Hive,WITHOUT_CLASSIFICATION,//  If we are here it means user is requesting a role he doesn't belong to. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#getMoreResults(int)    */
Hive,WITHOUT_CLASSIFICATION,//  Move data file to backup path 
Hive,WITHOUT_CLASSIFICATION,//  The error codes are Hive-specific and partitioned into the following ranges:   10000 to 19999: Errors occurring during semantic analysis and compilation of the query.   20000 to 29999: Runtime errors where Hive believes that retries are unlikely to succeed.   30000 to 39999: Runtime errors which Hive thinks may be transient and retrying may succeed.   40000 to 49999: Errors where Hive is unable to advise about retries.   In addition to the error code ErrorMsg also has a SQLState field.   SQLStates are taken from Section 22.1 of ISO-9075.   See http://www.contrib.andrew.cmu.edu/~shadow/sql/sql1992.txt   Most will just rollup to the generic syntax error state of 42000 but   specific errors can override the that state.   See this page for how MySQL uses SQLState codes: 
Hive,WITHOUT_CLASSIFICATION,//  when we start miniHS2_1 will be leader (sequential start) 
Hive,WITHOUT_CLASSIFICATION,//  Repeated non-NULL permutations. 
Hive,WITHOUT_CLASSIFICATION,//  AccumuloInputFormat expects 
Hive,WITHOUT_CLASSIFICATION,//  anything else indicates failure 
Hive,WITHOUT_CLASSIFICATION,//  Don't close the socket - the stream already does that if needed. 
Hive,WITHOUT_CLASSIFICATION,//  Load all of the default config values from HiveConf. 
Hive,WITHOUT_CLASSIFICATION,/*    * A finder finds the first index of its pattern in a given byte array.   * Its thread-safety depends on its implementation.    */
Hive,WITHOUT_CLASSIFICATION,//  Mapping from constraint name to list of not null columns 
Hive,WITHOUT_CLASSIFICATION,//  OutputFormat 
Hive,WITHOUT_CLASSIFICATION,// executionResult will be ERRNO_OK only if all initFiles execute successfully 
Hive,WITHOUT_CLASSIFICATION,//  find the base files (original or new style) 
Hive,WITHOUT_CLASSIFICATION,//  Get the all path by making a select(*). 
Hive,WITHOUT_CLASSIFICATION,//  Extrapolation is not needed for this column if   count(\"PARTITION_NAME\")==partNames.size()   Or extrapolation is not possible for this column if   count(\"PARTITION_NAME\")<2 
Hive,WITHOUT_CLASSIFICATION,//  Note: not actually used for pool sessions; verify some things like doAs are not set. 
Hive,WITHOUT_CLASSIFICATION,//  create a dummy select - This select is needed by the walker to split the   mapJoin later on 
Hive,WITHOUT_CLASSIFICATION,//  partitions are not added as write entries in drop partitions in Hive 
Hive,WITHOUT_CLASSIFICATION,//  ignore all other chars outside the enclosure 
Hive,WITHOUT_CLASSIFICATION,//  LazyObject can only be binary when it's not a string as well      return LazyFactory.createLazyObject(inspector              ColumnEncoding.BINARY == rowIdMapping.getEncoding()); 
Hive,WITHOUT_CLASSIFICATION,//  Build the supported formats list 
Hive,WITHOUT_CLASSIFICATION,//  Mostly dup of genIncludedColumns 
Hive,WITHOUT_CLASSIFICATION,// use bigint 
Hive,WITHOUT_CLASSIFICATION,//  Require all the directories to be present with some values. 
Hive,WITHOUT_CLASSIFICATION,//  The order of processing is as follows. We'd reclaim or kill all the sessions that we can   reclaim from various user actions and errors then apply the new plan if any   then give out all we can give out (restart get and reopen callers) and rebalance the   resource allocations in all the affected pools.   For every session we'd check all the concurrent things happening to it. 
Hive,WITHOUT_CLASSIFICATION,//  (return all) 
Hive,WITHOUT_CLASSIFICATION,//  Validate the value. 
Hive,WITHOUT_CLASSIFICATION,//  10000500....00 
Hive,WITHOUT_CLASSIFICATION,//  TODO fucntionCache 
Hive,WITHOUT_CLASSIFICATION,//  then all output will be null 
Hive,WITHOUT_CLASSIFICATION,// can't do much if outputTypeInfo is not set 
Hive,WITHOUT_CLASSIFICATION,//  Let Driver strip comments using sql parser 
Hive,WITHOUT_CLASSIFICATION,//  Working in the assumption that the user here will be the hive user if doAs = false we'll make it past this false check. 
Hive,WITHOUT_CLASSIFICATION,//  this method 
Hive,WITHOUT_CLASSIFICATION,// first column exists 
Hive,WITHOUT_CLASSIFICATION,//  Next user did specify perms. 
Hive,WITHOUT_CLASSIFICATION,//  Transport mode 
Hive,WITHOUT_CLASSIFICATION,//  Returns a list of the distinct exprs without duplicates for a given clause name 
Hive,WITHOUT_CLASSIFICATION,//  Remove the znodes we've already tried from this list 
Hive,WITHOUT_CLASSIFICATION,//  UTF-8 continuation bytes have 2 high bits equal to 0x80. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#setCatalog(java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  pause so we don't get banned 
Hive,WITHOUT_CLASSIFICATION,//  Lets use a timeout more than the socket lifetime to simulate a reconnect 
Hive,WITHOUT_CLASSIFICATION,//  Delete any stale log files left around from previous failed tests 
Hive,WITHOUT_CLASSIFICATION,// ---------------------------------------------------------------------------   Process Single-Column Long Inner Big-Only Join on a vectorized row batch.   
Hive,WITHOUT_CLASSIFICATION,//  Get the query string from the conf file as the compileInternal() method might   hide sensitive information during query redaction. 
Hive,WITHOUT_CLASSIFICATION,//  Check if any of the txns in the list is committed. 
Hive,WITHOUT_CLASSIFICATION,//  Whether characters such as 't/T' 'f/F' and '1/0' are interpreted as valid boolean literals. 
Hive,WITHOUT_CLASSIFICATION,/*    * Test if the environment variables can be set. If this test fails   * all the other tests will also fail because environment is not getting setup    */
Hive,WITHOUT_CLASSIFICATION,//  copy default aux classes (json/hbase) 
Hive,WITHOUT_CLASSIFICATION,//  call the tests 
Hive,WITHOUT_CLASSIFICATION,//  Format a Column for a create statement 
Hive,WITHOUT_CLASSIFICATION,//  With trim=true parsing can handle spaces 
Hive,WITHOUT_CLASSIFICATION,/* OrcRecordUpdater is inconsistent about when it creates empty files and when it does not.      This creates an empty bucket. HIVE-17138 */
Hive,WITHOUT_CLASSIFICATION,//  Not ok to run CBO build error message. 
Hive,WITHOUT_CLASSIFICATION,//  Remove the branches 
Hive,WITHOUT_CLASSIFICATION,//  Normally trailing fractional digits are removed.  But to emulate the   OldHiveDecimal setScale and OldHiveDecimalWritable internalStorage we need to trailing zeroes   here.     NOTE: This can cause a decimal that has too many decimal digits (because of trailing zeroes)         for us to represent.  In that case we punt and convert with a BigInteger alternate         code. 
Hive,WITHOUT_CLASSIFICATION,//  count only on the keys 
Hive,WITHOUT_CLASSIFICATION,//  Just examine the middle and lower words. 
Hive,WITHOUT_CLASSIFICATION,//  get available map memory 
Hive,WITHOUT_CLASSIFICATION,//  Can fail with NoSuchObjectException. 
Hive,WITHOUT_CLASSIFICATION,//  Do not create counter if it does not exist - 
Hive,WITHOUT_CLASSIFICATION,/*  Add list bucketing location mappings.  */
Hive,WITHOUT_CLASSIFICATION,// streaming ingest dir - cannot have update/delete events 
Hive,WITHOUT_CLASSIFICATION,//  Test that two different databases don't collide on their locks 
Hive,WITHOUT_CLASSIFICATION,//  if counter name starts with VERTEX_ then we just return max value across all vertex since trigger   validation is only interested in violation that are greater than limit (*any* vertex violation).   Use case: If SHUFFLE_BYTES for any single vertex is > limit perform action 
Hive,WITHOUT_CLASSIFICATION,//  get token info to check renew date 
Hive,WITHOUT_CLASSIFICATION,//  If we cannot combine any of the children we bail out 
Hive,WITHOUT_CLASSIFICATION,//  We keep the hash set result for its spill information. 
Hive,WITHOUT_CLASSIFICATION,//  Case 2: Test with originals and base => Single split strategy with two splits on compacted 
Hive,WITHOUT_CLASSIFICATION,//  3. The result should have a project on top otherwise we 
Hive,WITHOUT_CLASSIFICATION,//  Set a watch on the znode 
Hive,WITHOUT_CLASSIFICATION,//  DROP_PARTITION EVENT to partitioned table 
Hive,WITHOUT_CLASSIFICATION,//  VectorizedBatchUtil.debugDisplayOneRow(batch batchIndex taskName + " " + getOperatorId() + " candidate " + CLASS_NAME + " batch"); 
Hive,WITHOUT_CLASSIFICATION,//  At this point we may have parsed an integer. 
Hive,WITHOUT_CLASSIFICATION,//  For a partition key type this will be a primitive typeinfo. 
Hive,WITHOUT_CLASSIFICATION,//  codes 
Hive,WITHOUT_CLASSIFICATION,//  Data needs deletion. Check if trash may be skipped. 
Hive,WITHOUT_CLASSIFICATION,//  The rule has been applied we bail out 
Hive,WITHOUT_CLASSIFICATION,//  using old table object hence reset the owner to current user for new table. 
Hive,WITHOUT_CLASSIFICATION,/* && srcs[0].getPath().getName().equals(EximUtil.DATA_PATH_NAME) -  still broken for partitions */
Hive,WITHOUT_CLASSIFICATION,//  the createTable() above does not update the location in the 'tbl'   object when the client is a thrift client and the code below relies   on the location being present in the 'tbl' object - so get the table   from the metastore 
Hive,WITHOUT_CLASSIFICATION,//  Num of total and completed tasks 
Hive,WITHOUT_CLASSIFICATION,//  Check that the added partitions are as expected. 
Hive,WITHOUT_CLASSIFICATION,//  Alter table ... partition column ( column newtype) only takes one column at a time. 
Hive,WITHOUT_CLASSIFICATION,//  Hadoop Conf Var Names 
Hive,WITHOUT_CLASSIFICATION,//  add count(KEY._col0) to replace distinct 
Hive,WITHOUT_CLASSIFICATION,//  GBYRSGBY... (top to bottom) 
Hive,WITHOUT_CLASSIFICATION,//  Supports random access. 
Hive,WITHOUT_CLASSIFICATION,//  Get aggregate stats for all partitions of a table and for all but default 
Hive,WITHOUT_CLASSIFICATION,//  Configuration and things set from it. 
Hive,WITHOUT_CLASSIFICATION,//  Look at comments in DummyStoreOperator for additional explanation. 
Hive,WITHOUT_CLASSIFICATION,//  We bypass the OR clause and select the second disjunct 
Hive,WITHOUT_CLASSIFICATION,//  Force local cache if we have deltas. 
Hive,WITHOUT_CLASSIFICATION,//  The child operators cleanup if input file has changed 
Hive,WITHOUT_CLASSIFICATION,//  Attach the resources to the session cleanup. 
Hive,WITHOUT_CLASSIFICATION,//  Special case for 0 because java doesn't strip zeros correctly on that number. 
Hive,WITHOUT_CLASSIFICATION,//  ////// 4. Generate GroupbyOperator2 
Hive,WITHOUT_CLASSIFICATION,//  non-null only for writing (server-side) 
Hive,WITHOUT_CLASSIFICATION,/*   Set the umask in conf such that files/dirs get created with table-dir      * permissions. Following three assumptions are made:      * 1. Actual files/dirs creation is done by RecordWriter of underlying      * output format. It is assumed that they use default permissions while creation.      * 2. Default Permissions = FsPermission.getDefault() = 777.      * 3. UMask is honored by underlying filesystem.       */
Hive,WITHOUT_CLASSIFICATION,//  registry for system functions 
Hive,WITHOUT_CLASSIFICATION,//  Tracks new additions via add while the loop is processing existing ones. 
Hive,WITHOUT_CLASSIFICATION,//  required   required   optional 
Hive,WITHOUT_CLASSIFICATION,//  2. Apply pre-join order optimizations 
Hive,WITHOUT_CLASSIFICATION,//  Try to force-evict the fragments of the requisite size. 
Hive,WITHOUT_CLASSIFICATION,//  register this comparator 
Hive,WITHOUT_CLASSIFICATION,/*  10 files x 100 size for 9 splits  */
Hive,WITHOUT_CLASSIFICATION,//  total 10 entries (2 valid + 8 fake) 
Hive,WITHOUT_CLASSIFICATION,//  such as dropping a table or partition 
Hive,WITHOUT_CLASSIFICATION,/*    * tracks number of exprs from correlated predicates added to SQ select list.    */
Hive,WITHOUT_CLASSIFICATION,//  For left semi joins we may apply the filter(s) now. 
Hive,WITHOUT_CLASSIFICATION,//  Compute stats 
Hive,WITHOUT_CLASSIFICATION,//     GROUP BY deptno                        // Aggregate A 
Hive,WITHOUT_CLASSIFICATION,//  checkMetastore call will fill in result with partitions that are present in filesystem   and missing in metastore - accessed through getPartitionsNotInMs   And partitions that are not present in filesystem and metadata exists in metastore -   accessed through getPartitionNotOnFS 
Hive,WITHOUT_CLASSIFICATION,//  No metadata => no ppd. 
Hive,WITHOUT_CLASSIFICATION,//  Datanucleus throws NPE when we try to serialize a table object   retrieved from metastore. To workaround that we reset following objects 
Hive,WITHOUT_CLASSIFICATION,//  Struct column such as root? 
Hive,WITHOUT_CLASSIFICATION,//  DatabaseMetaData.getCatalogs()  catalogs are actually not supported in 
Hive,WITHOUT_CLASSIFICATION,//  MERGE statement 
Hive,WITHOUT_CLASSIFICATION,//  Each listener called above might set a different parameter on the event.   This write permission is allowed on the listener side to avoid breaking compatibility if we change the API   method calls. 
Hive,WITHOUT_CLASSIFICATION,/*  fill array with a pattern that will never match sync  */
Hive,WITHOUT_CLASSIFICATION,//  now that URI and times are set correctly set the original table's uri and times 
Hive,WITHOUT_CLASSIFICATION,//  (54 % 4) << 62   54/4 
Hive,WITHOUT_CLASSIFICATION,//  Don't exceed the range if we have one. 
Hive,WITHOUT_CLASSIFICATION,//  Get the count of txns from the given list are in open state. If the returned count is same as   the input number of txns then it means all are in open state. 
Hive,WITHOUT_CLASSIFICATION,// see HIVE-18154 
Hive,WITHOUT_CLASSIFICATION,//  THEN CAST(NULL AS newInputTypeNullable) 
Hive,WITHOUT_CLASSIFICATION,//  negate it 
Hive,WITHOUT_CLASSIFICATION,// reducer.setGroupKeyObjectInspector(keyObjectInspector); 
Hive,WITHOUT_CLASSIFICATION,//  Some other process is probably writing the file. Just sleep. 
Hive,WITHOUT_CLASSIFICATION,/*     So Union All removal kicks in and we get 3 subdirs in staging.ekoifman:apache-hive-3.0.0-SNAPSHOT-bin ekoifman$ tree /Users/ekoifman/dev/hiverwgit/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnNoBuckets-1505516390532/warehouse/t/.hive-staging_hive_2017-09-15_16-05-06_895_1123322677843388168-1/└── -ext-10000    ├── HIVE_UNION_SUBDIR_19    │   └── 000000_0    │       ├── _orc_acid_version    │       └── delta_0000016_0000016_0001    ├── HIVE_UNION_SUBDIR_20    │   └── 000000_0    │       ├── _orc_acid_version    │       └── delta_0000016_0000016_0002    └── HIVE_UNION_SUBDIR_21        └── 000000_0            ├── _orc_acid_version            └── delta_0000016_0000016_0003 */
Hive,WITHOUT_CLASSIFICATION,//  double scalar/scalar IF 
Hive,WITHOUT_CLASSIFICATION,//  initialize mapredWork 
Hive,WITHOUT_CLASSIFICATION,//  groupSetPosition includes all the positions 
Hive,WITHOUT_CLASSIFICATION,//  Main path 2 - created a new file cache.   Someone created one in parallel.   Someone created one in parallel and then it went stale. 
Hive,WITHOUT_CLASSIFICATION,// test minor compaction 
Hive,WITHOUT_CLASSIFICATION,//  Reached end of file 
Hive,WITHOUT_CLASSIFICATION,//  Unique rows. 
Hive,WITHOUT_CLASSIFICATION,//  Does this hashcode belong to this reducer 
Hive,WITHOUT_CLASSIFICATION,//  If a task failed fetch its error code (if available).   Also keep track of the total number of failures for that 
Hive,WITHOUT_CLASSIFICATION,//  merge should convert hll2 to DENSE 
Hive,WITHOUT_CLASSIFICATION,// verify the data is the same 
Hive,WITHOUT_CLASSIFICATION,//  to merge (only useful for extended merging as TS do not have inputs). 
Hive,WITHOUT_CLASSIFICATION,//  Obtained from the HiveException thrown 
Hive,WITHOUT_CLASSIFICATION,/*    * This number is carefully chosen to minimize overhead and typically allows   * one VectorizedRowBatch to fit in cache.    */
Hive,WITHOUT_CLASSIFICATION,//  8. Merge remove and reduce Project if possible 
Hive,WITHOUT_CLASSIFICATION,//  to avoid concurrent modify the hashmap 
Hive,WITHOUT_CLASSIFICATION,// this gives an easy way to get at compaction ID so we can only wait for those this  utility started 
Hive,WITHOUT_CLASSIFICATION,//  check if all record writers implement statistics. if atleast one RW   doesn't implement stats interface we will fallback to conventional way 
Hive,WITHOUT_CLASSIFICATION,//  print primary key containing parents 
Hive,WITHOUT_CLASSIFICATION,//  TaskDisplay doesn't have a toString using json 
Hive,WITHOUT_CLASSIFICATION,/*      * Needed virtual columns are those used in the query.      */
Hive,WITHOUT_CLASSIFICATION,// other alter operations are already supported by Hive 
Hive,WITHOUT_CLASSIFICATION,//  static partition 
Hive,WITHOUT_CLASSIFICATION,// Token is available so replace the placeholder 
Hive,WITHOUT_CLASSIFICATION,//  We get a semi join at here.   This map-side GroupByOperator needs to be removed 
Hive,WITHOUT_CLASSIFICATION,//  No corresponding Writable classes for the following 3 in hadoop 0.17.0 
Hive,WITHOUT_CLASSIFICATION,//  PARTITIONS 
Hive,WITHOUT_CLASSIFICATION,//  rowFilterExpression is applied to the whole table i.e. dbname.objectName   For example rowFilterExpression can be "key % 2 = 0 and key < 10" and it 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#getGeneratedKeys()    */
Hive,WITHOUT_CLASSIFICATION,//  Operand | Not   T | F 
Hive,WITHOUT_CLASSIFICATION,// we have WHEN MATCHED AND <boolean expr> THEN DELETE 
Hive,WITHOUT_CLASSIFICATION,// prec 5 scale 2 
Hive,WITHOUT_CLASSIFICATION,//  ID 
Hive,WITHOUT_CLASSIFICATION,//  Update the tables in cache 
Hive,WITHOUT_CLASSIFICATION,//  ------r--   rwxrwxrwx 
Hive,WITHOUT_CLASSIFICATION,//  try again with left input also having no nulls 
Hive,WITHOUT_CLASSIFICATION,//  Computes the skew for all the MapReduce irrespective   of Success or Failure 
Hive,WITHOUT_CLASSIFICATION,//  check if there's at least some degree of stats available 
Hive,WITHOUT_CLASSIFICATION,//  spill the current block to tmp file 
Hive,WITHOUT_CLASSIFICATION,//  Sort order (+|-) 
Hive,WITHOUT_CLASSIFICATION,//  Convert the n-gram list to a format suitable for Hive 
Hive,WITHOUT_CLASSIFICATION,/*          * Get our Single-Column String hash multi-set information for this specialized class.          */
Hive,WITHOUT_CLASSIFICATION,//  The TS rule for headers is - a header and buffer array element for some freeList   can only be modified if the corresponding freeList lock is held. 
Hive,WITHOUT_CLASSIFICATION,//  compare register values and store the max register value 
Hive,WITHOUT_CLASSIFICATION,//  load the schema version stored in metastore db 
Hive,WITHOUT_CLASSIFICATION,//  compile and execute can get called from different threads in case of HS2 
Hive,WITHOUT_CLASSIFICATION,//  ROLE 
Hive,WITHOUT_CLASSIFICATION,//  2b-3a 
Hive,WITHOUT_CLASSIFICATION,//  QueryId for the query in current transaction 
Hive,WITHOUT_CLASSIFICATION,//  Generic http server error. 
Hive,WITHOUT_CLASSIFICATION,// now check that stats were updated 
Hive,WITHOUT_CLASSIFICATION,//  replace existing blanks with new blanks 
Hive,WITHOUT_CLASSIFICATION,//  This value is always in seconds and includes an 's' suffix. 
Hive,WITHOUT_CLASSIFICATION,//  Create the Group by Operator 
Hive,WITHOUT_CLASSIFICATION,//  Create the corresponding client 
Hive,WITHOUT_CLASSIFICATION,//  Contains explicit field "a" and partition "b". 
Hive,WITHOUT_CLASSIFICATION,//  validate the DDL is a valid operation on the table. 
Hive,WITHOUT_CLASSIFICATION,//  update the childOp of selectOp 
Hive,WITHOUT_CLASSIFICATION,//  if we've read 63 bits roll them into the result 
Hive,WITHOUT_CLASSIFICATION,//  stream data into streaming table with N buckets then copy the data into another bucketed table 
Hive,WITHOUT_CLASSIFICATION,//  Keep connection open to hang on to associated resources (temp tables locks). 
Hive,WITHOUT_CLASSIFICATION,//  String including a '\u0000' style literal characters (\u732B is a cat in Kanji). 
Hive,WITHOUT_CLASSIFICATION,//  in case jackson is able to deserialize...it may use a different implementation for the map - which may not preserve order 
Hive,WITHOUT_CLASSIFICATION,//  Retrieve the additional HttpHeaders 
Hive,WITHOUT_CLASSIFICATION,//  At least one partition per expression if not ifExists 
Hive,WITHOUT_CLASSIFICATION,/*    * Expr translation helper methods    */
Hive,WITHOUT_CLASSIFICATION,//  Deserialize and test 
Hive,WITHOUT_CLASSIFICATION,//  DETAILS:     PIG-1429 added support for boolean fields which shipped in 0.10.0;   this version of Pig depends on antlr 3.4.     HCatalog depends heavily on Hive which at this time uses antlr 3.0.1.     antlr 3.0.1 and 3.4 are incompatible so Pig 0.10.0 and Hive cannot be depended on in the   same project. Pig 0.8.0 did not use antlr for its parser and can coexist with Hive   so that Pig version is depended on by HCatalog at this time. 
Hive,WITHOUT_CLASSIFICATION,//  rcfile 
Hive,WITHOUT_CLASSIFICATION,//  repeat again 
Hive,WITHOUT_CLASSIFICATION,//  <DescriptionValue> 
Hive,WITHOUT_CLASSIFICATION,//  Map this key back to the ConfVars it is associated with. 
Hive,WITHOUT_CLASSIFICATION,//  miniHS2_1 will become leader 
Hive,WITHOUT_CLASSIFICATION,//  New array cannot contain the records w/the same key so just advance don't check. 
Hive,WITHOUT_CLASSIFICATION,// try out some metastore operations 
Hive,WITHOUT_CLASSIFICATION,//  now oldOrdinal is relative to oldInput 
Hive,WITHOUT_CLASSIFICATION,//  OldHiveDecimal returns the hash code of its internal BigDecimal.  Our TestHiveDecimal   verifies the OldHiveDecimal.bigDecimalValue() matches (new) HiveDecimal.bigDecimalValue(). 
Hive,WITHOUT_CLASSIFICATION,//  do not fold named_struct only struct() 
Hive,WITHOUT_CLASSIFICATION,//  column/scalar 
Hive,WITHOUT_CLASSIFICATION,//  Three different cases 
Hive,WITHOUT_CLASSIFICATION,//  count query 
Hive,WITHOUT_CLASSIFICATION,//  taskKill() should also be received during a rejected submission   we will let that logic handle retries. 
Hive,WITHOUT_CLASSIFICATION,//  Cannot be 0. 
Hive,WITHOUT_CLASSIFICATION,//  Create schema with no serde then map it 
Hive,WITHOUT_CLASSIFICATION,//  2. Construct JoinLeafPredicateInfo 
Hive,WITHOUT_CLASSIFICATION,//  would only apply after the callback for the current message. 
Hive,WITHOUT_CLASSIFICATION,//  Set up scratch directory 
Hive,WITHOUT_CLASSIFICATION,//  Partitioned table - delete specific partitions a0 a2 
Hive,WITHOUT_CLASSIFICATION,//  call-2: open to read - split 2 => mock:/mocktable1/0_1 
Hive,WITHOUT_CLASSIFICATION,// create 1 delta file bucket_00000 
Hive,WITHOUT_CLASSIFICATION,//  Note: the metadata cache may deallocate additional buffers but not this one. 
Hive,WITHOUT_CLASSIFICATION,//  get the path corresponding to the dynamic partition columns 
Hive,WITHOUT_CLASSIFICATION,/*          * Validate the column names that are present are the same.  Missing columns will be         * implicitly defaulted to null.          */
Hive,WITHOUT_CLASSIFICATION,//  convert to HCatNotificationEvent and then try to instantiate a ReplicationTask on it. 
Hive,WITHOUT_CLASSIFICATION,//  into same work y. 
Hive,WITHOUT_CLASSIFICATION,//  if any of join participants is from other MR it has alias like '[pos:]$INTNAME'   which of size should be caculated for each resolver. 
Hive,WITHOUT_CLASSIFICATION,// If the decendants contains LimitOperatorreturn false 
Hive,WITHOUT_CLASSIFICATION,//  Create the folder and its parents if not there 
Hive,WITHOUT_CLASSIFICATION,/*    * A TableFunction may be able to provide its Output as an Iterator.   * In case it can then for Map-side processing and for the last PTF in a Reduce-side chain   * we can forward rows one by one. This will save the time/space to populate and read an Output   * Partition.    */
Hive,WITHOUT_CLASSIFICATION,//  create the create table grants with new config 
Hive,WITHOUT_CLASSIFICATION,//  Parse the message field 
Hive,WITHOUT_CLASSIFICATION,//  For PPD we need a column to expression map so that during the walk   the processor knows how to transform the internal col names.   Following steps are dependant on the fact that we called 
Hive,WITHOUT_CLASSIFICATION,//  create dir for /mpart5 
Hive,WITHOUT_CLASSIFICATION,//  init objectInspectors 
Hive,WITHOUT_CLASSIFICATION,//  Executor to create the ATS events. 
Hive,WITHOUT_CLASSIFICATION,//  swallow exception 
Hive,WITHOUT_CLASSIFICATION,//  2. Simulate emitting records in processNextRecord() with small memory usage limit. 
Hive,WITHOUT_CLASSIFICATION,//  return partition metadata 
Hive,WITHOUT_CLASSIFICATION,//  Any (repeated) null key column is no match for whole batch. 
Hive,WITHOUT_CLASSIFICATION,//  is updated the count will be computed again. 
Hive,WITHOUT_CLASSIFICATION,//  Remaining batches. 
Hive,WITHOUT_CLASSIFICATION,//  a map from each BaseWork to its cloned JobConf 
Hive,WITHOUT_CLASSIFICATION,// if here we already saw current file and now found another file for the same bucket  so the current file is not the last file of the logical bucket 
Hive,WITHOUT_CLASSIFICATION,//  Tag if we want to remain in trash after deletion.   If multiple files share the same content then 
Hive,WITHOUT_CLASSIFICATION,//  get list of events matching dbPattern & tblPattern 
Hive,WITHOUT_CLASSIFICATION,//  There should be 1 delta dir per partition location 
Hive,WITHOUT_CLASSIFICATION,//  if all chunks have been processed nothing more to do. 
Hive,WITHOUT_CLASSIFICATION,//  We copied the entire buffer.    else there's more data to process; will be handled in next call. 
Hive,WITHOUT_CLASSIFICATION,//  5. Delete GBY - RS - GBY - SEL from the pipeline. 
Hive,WITHOUT_CLASSIFICATION,// release the X lock on T7.p=1 
Hive,WITHOUT_CLASSIFICATION,/*  Tests with queries which can be pushed down and executed with directSQL  */
Hive,WITHOUT_CLASSIFICATION,//  This is select for update query which takes a lock if the table entry is already there in NEXT_WRITE_ID 
Hive,WITHOUT_CLASSIFICATION,//  No inversion or escaping happened so we are can reference directly. 
Hive,WITHOUT_CLASSIFICATION,/*        * Single-Column String check for repeating.        */
Hive,WITHOUT_CLASSIFICATION,// use sampled partitioning 
Hive,WITHOUT_CLASSIFICATION,//  Record what type of write this is.  Default is non-ACID (ie old style). 
Hive,WITHOUT_CLASSIFICATION,//  setting file length to Long.MAX_VALUE will let orc reader read file length from file system 
Hive,WITHOUT_CLASSIFICATION,//  drop table is already enforced by Hive. We only check for table level location even if the   table is partitioned. 
Hive,WITHOUT_CLASSIFICATION,//  max txn id does not change for a transaction batch 
Hive,WITHOUT_CLASSIFICATION,//  TODO: add tez session reconnect after TEZ-3875 
Hive,WITHOUT_CLASSIFICATION,/*      * alias      */
Hive,WITHOUT_CLASSIFICATION,//  Set an explicit session name to control the download directory name 
Hive,WITHOUT_CLASSIFICATION,//  check if table exists. 
Hive,WITHOUT_CLASSIFICATION,// set the values to i+1 so they are different in the new stats 
Hive,WITHOUT_CLASSIFICATION,//  Set foreign key name if null before sending to listener 
Hive,WITHOUT_CLASSIFICATION,//  For intermediate sum field 
Hive,WITHOUT_CLASSIFICATION,//  CREATE MV ... AS 
Hive,WITHOUT_CLASSIFICATION,//  Create the ObjectInspectors for the fields. Note: Currently   ColumnarObject uses same ObjectInpector as LazyStruct 
Hive,WITHOUT_CLASSIFICATION,//  If we're loading into a db instead of into the warehouse then the oldDbName and   newDbName must be the same 
Hive,WITHOUT_CLASSIFICATION,//  colList will be null for FS operators. 
Hive,WITHOUT_CLASSIFICATION,//  We have filled HiveDecimal.MAX_PRECISION digits and have no more room in our limit precision   fast decimal. 
Hive,WITHOUT_CLASSIFICATION,//  set list work 
Hive,WITHOUT_CLASSIFICATION,//  1.2. Adjust GroupingSet Position GBKeys for GroupingSet Position if   needed. NOTE: GroupingID is added to map side GB only if we don't GrpSet 
Hive,WITHOUT_CLASSIFICATION,/*      * Calculate the variance sample result when count > 1.  Public so vectorization code can     * use it etc.      */
Hive,WITHOUT_CLASSIFICATION,//  If we are using a shared database then remove not known databases tables views. 
Hive,WITHOUT_CLASSIFICATION,//  Empty list case 
Hive,WITHOUT_CLASSIFICATION,//  test timestamp string 
Hive,WITHOUT_CLASSIFICATION,//  Move past parent field separator. 
Hive,WITHOUT_CLASSIFICATION,//  Add the test-null-appender to the default route 
Hive,WITHOUT_CLASSIFICATION,//  we converted the expression to a search condition so 
Hive,WITHOUT_CLASSIFICATION,//  native or not would be decided by annotation. need to evaluate that first 
Hive,WITHOUT_CLASSIFICATION,//  Not strictly necessary; do the whole queue check again. 
Hive,WITHOUT_CLASSIFICATION,//  Don't create a new object if we are already out of memory 
Hive,WITHOUT_CLASSIFICATION,//  Now add all the default handlers 
Hive,WITHOUT_CLASSIFICATION,//  Skipping through comments 
Hive,WITHOUT_CLASSIFICATION,//  1.a. Extract order for each column from collation 
Hive,WITHOUT_CLASSIFICATION,//  for each sub-query. Also these different filesinks need to be linked to each other 
Hive,WITHOUT_CLASSIFICATION,/*  skewed column names.  */
Hive,WITHOUT_CLASSIFICATION,//  no need to look at token info 
Hive,WITHOUT_CLASSIFICATION,//  IF_NOT_EXISTS 
Hive,WITHOUT_CLASSIFICATION,//  Neither input has nulls. Verify that this propagates to output. 
Hive,WITHOUT_CLASSIFICATION,//  Check cases for arr[i].f and map[key].v   For these we should not generate paths like arr.f or map.v   Otherwise we would have a mismatch between type info and path 
Hive,WITHOUT_CLASSIFICATION,// make sure to check format  is this right? 
Hive,WITHOUT_CLASSIFICATION,//  Schema validation enforces that the Key is a String 
Hive,WITHOUT_CLASSIFICATION,// Ignored the attribute was not found which should never happen because the bean  just told us that it has this attribute but if this happens just don't output  the attribute. 
Hive,WITHOUT_CLASSIFICATION,//  sort both the lists 
Hive,WITHOUT_CLASSIFICATION,//  Default column storage specification inherits from table level default 
Hive,WITHOUT_CLASSIFICATION,/*    * Allocate overflow batch columns by hand.    */
Hive,WITHOUT_CLASSIFICATION,//  Arithmetic operations rely on getting conf from SessionState need to initialize here. 
Hive,WITHOUT_CLASSIFICATION,//  spin until it resolves; extremely rare 
Hive,WITHOUT_CLASSIFICATION,//  This may happen if ACID state is absent from config. 
Hive,WITHOUT_CLASSIFICATION,//  Must be manually set with setMaxLength. 
Hive,WITHOUT_CLASSIFICATION,//  Create NullAppender 
Hive,WITHOUT_CLASSIFICATION,//  Only columns can be sorted/bucketed in particular applying a function to a column   voids any assumptions 
Hive,WITHOUT_CLASSIFICATION,//  user unsets queue name will fallback to default session queue 
Hive,WITHOUT_CLASSIFICATION,//  2. Reset the pointer. 
Hive,WITHOUT_CLASSIFICATION,//  No valid HS2 generated cookies found return null 
Hive,WITHOUT_CLASSIFICATION,//  The set object containing the IN list. 
Hive,WITHOUT_CLASSIFICATION,//  1.3.1 process hints 
Hive,WITHOUT_CLASSIFICATION,//  S_INT_STRING 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * This processor addresses the RS-MJ case that occurs in tez on the small/hash   * table side of things. The work that RS will be a part of must be connected   * to the MJ work via be a broadcast edge.   * We should not walk down the tree when we encounter this pattern because:   * the type of work (map work or reduce work) needs to be determined   * on the basis of the big table side because it may be a mapwork (no need for shuffle)   * or reduce work.    */
Hive,WITHOUT_CLASSIFICATION,// bail here to make the operation idempotent 
Hive,WITHOUT_CLASSIFICATION,// lets check that side files exist etc 
Hive,WITHOUT_CLASSIFICATION,//  Update NDV of joined columns to be min(V(Ry) V(Sy)) 
Hive,WITHOUT_CLASSIFICATION,//  Add an alternative alias for the column this instance represents and its index in the 
Hive,WITHOUT_CLASSIFICATION,//  first batch is always based on batch size 
Hive,WITHOUT_CLASSIFICATION,//  alphaMM value for 128 bits hash seems to perform better for default 64 hash bits 
Hive,WITHOUT_CLASSIFICATION,//  so it won't be updated. 
Hive,WITHOUT_CLASSIFICATION,// compare ports 
Hive,WITHOUT_CLASSIFICATION,//  Lower this for big value testing. 
Hive,WITHOUT_CLASSIFICATION,//  estimated number of reducers 
Hive,WITHOUT_CLASSIFICATION,//  Since we did not remove reduce sink parents keep the original value expressions 
Hive,WITHOUT_CLASSIFICATION,//  RS for join SEL(*) for lateral view   SEL for union does not count (should be copied to both sides) 
Hive,WITHOUT_CLASSIFICATION,//  This should ideally happen in a separate thread 
Hive,WITHOUT_CLASSIFICATION,//  To test the SortMergedDeleteEventRegistry we need to explicitly set the   HIVE_TRANSACTIONAL_NUM_EVENTS_IN_MEMORY constant to a smaller value. 
Hive,WITHOUT_CLASSIFICATION,//  if false return false 
Hive,WITHOUT_CLASSIFICATION,//  currOp now points to the top-most tablescan operator 
Hive,WITHOUT_CLASSIFICATION,//  automatic conversion to double is done here 
Hive,WITHOUT_CLASSIFICATION,//  data with the separator bytes before creating a "Put" object 
Hive,WITHOUT_CLASSIFICATION,//  since the file is read by Pig we need to make sure the values are in format that Pig   understands   otherwise it will turn the value to NULL on read 
Hive,WITHOUT_CLASSIFICATION,//  Get the bucket positions for the table 
Hive,WITHOUT_CLASSIFICATION,//  Add insert event twice with different event ID to allow apply of both events. 
Hive,WITHOUT_CLASSIFICATION,//  if not match copy again from cm 
Hive,WITHOUT_CLASSIFICATION,//  convert any nulls present in map values to empty strings - this is done in the case   of backing dbs like oracle which persist empty strings as nulls. 
Hive,WITHOUT_CLASSIFICATION,//  only one table let's check all partitions 
Hive,WITHOUT_CLASSIFICATION,//  Use NotTezEvent.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,//  setop 
Hive,WITHOUT_CLASSIFICATION,//  that appear in the small table portion of the join output for outer joins. 
Hive,WITHOUT_CLASSIFICATION,/*      * If there are deletes and reading original file we must produce synthetic ROW_IDs in order     * to see if any deletes apply      */
Hive,WITHOUT_CLASSIFICATION,//  no-op default 
Hive,WITHOUT_CLASSIFICATION,//  Sign. 
Hive,WITHOUT_CLASSIFICATION,//  Additional work for union operator see union27.q 
Hive,WITHOUT_CLASSIFICATION,//  This next section repeats the tests of testRightTrimWithOffset with a maxLength parameter that is   less than the number of current characters in the string and thus affects the trim. 
Hive,WITHOUT_CLASSIFICATION,// mostly this indicates that the Initiator is paying attention to some table even though 
Hive,WITHOUT_CLASSIFICATION,//  Prior none singleton or range? 
Hive,WITHOUT_CLASSIFICATION,/*  n != batch.size when isRepeating  */
Hive,WITHOUT_CLASSIFICATION,//  combine equivalent work into single one in SparkWork's work graph. 
Hive,WITHOUT_CLASSIFICATION,//  Not included in equals. 
Hive,WITHOUT_CLASSIFICATION,//  Create SelectDesc 
Hive,WITHOUT_CLASSIFICATION,//  Try to allocate using brute force approach from each arena. 
Hive,WITHOUT_CLASSIFICATION,//  USER 
Hive,WITHOUT_CLASSIFICATION,//  Evaluate subsequent child expression over unselected ones only. 
Hive,WITHOUT_CLASSIFICATION,//  authorization setup using SessionState should be revisited eventually as   authorization and authentication are not session specific settings 
Hive,WITHOUT_CLASSIFICATION,//  Grouping ID reference 
Hive,WITHOUT_CLASSIFICATION,//  Verify the number of buckets equals the number of files   This will not hold for dynamic partitions where not every reducer produced a file for   those partitions.  In this case the table is not bucketed as Hive requires a files for 
Hive,WITHOUT_CLASSIFICATION,//  ThriftStructObjectInspector will override and ignore __isset fields. 
Hive,WITHOUT_CLASSIFICATION,//  all rows are filtered if repeating null otherwise no rows are filtered 
Hive,WITHOUT_CLASSIFICATION,/*  * An implementation of MetaStoreInitListener to verify onInit is called when * HMSHandler is initialized  */
Hive,WITHOUT_CLASSIFICATION,//  Validate 
Hive,WITHOUT_CLASSIFICATION,// the 'isOriginal' file is at the root of the partition (or table) thus it is  from a pre-acid conversion write and belongs to primordial writeid:0. 
Hive,WITHOUT_CLASSIFICATION,//  This is not a cast; process the function. 
Hive,WITHOUT_CLASSIFICATION,//  Fallback to picking up the value from environment. 
Hive,WITHOUT_CLASSIFICATION,//  Move the record from txn_components into completed_txn_components so that the compactor 
Hive,WITHOUT_CLASSIFICATION,//  ERROR_CODE 
Hive,WITHOUT_CLASSIFICATION,//  'data' is created by export command/ 
Hive,WITHOUT_CLASSIFICATION,//  This should also trigger meta listener notification via TServerEventHandler#deleteContext 
Hive,WITHOUT_CLASSIFICATION,//  Cache if the client asks for it else just return the value 
Hive,WITHOUT_CLASSIFICATION,//  This assume no round up... 
Hive,WITHOUT_CLASSIFICATION,//  ALLOC_FRACTION 
Hive,WITHOUT_CLASSIFICATION,//  TODO: This should be making use of confDir to load configs setup for Tez etc. 
Hive,WITHOUT_CLASSIFICATION,//  An optional group containing a repeated anonymous group "bag" containing 
Hive,WITHOUT_CLASSIFICATION,//  use HiveInputFormat so that we can control the number of map tasks 
Hive,WITHOUT_CLASSIFICATION,//  otherwise continue to get the group type until MAP_DEFINITION_LEVEL_MAX. 
Hive,WITHOUT_CLASSIFICATION,/*      * 4. GBy      */
Hive,WITHOUT_CLASSIFICATION,//  Mapping from constraint name to list of Check constraints 
Hive,WITHOUT_CLASSIFICATION,/*    * At the Metadata level there are no restrictions on Column Names.    */
Hive,WITHOUT_CLASSIFICATION,//  there was an authorization issue 
Hive,WITHOUT_CLASSIFICATION,//  Subscriber can get notification about drop of a table in HCAT   by listening on a topic named "HCAT" and message selector string   as "HCAT_EVENT = HCAT_DROP_TABLE" 
Hive,WITHOUT_CLASSIFICATION,// This read entity is a direct read entity and not an indirect read (that is when 
Hive,WITHOUT_CLASSIFICATION,//  show table information 
Hive,WITHOUT_CLASSIFICATION,//  First try without qualifiers - would resolve builtin/temp functions 
Hive,WITHOUT_CLASSIFICATION,// if HiveConf has not changed same object should be returned 
Hive,WITHOUT_CLASSIFICATION,//  this method is called by the RCFile.Reader constructor overwritten   so we can access the opened file 
Hive,WITHOUT_CLASSIFICATION,//  Finds all contextual n-grams in a sequence of words and passes the n-grams to the 
Hive,WITHOUT_CLASSIFICATION,//  slight hack to communicate to DynamicSerDe that the field ids are not   being set but things are ordered. 
Hive,WITHOUT_CLASSIFICATION,//  and submit method of RemoteHiveSparkClient when the job config is created 
Hive,WITHOUT_CLASSIFICATION,//  good 
Hive,WITHOUT_CLASSIFICATION,// -----------------------------------------------------------------------------------------------   Create methods.  ----------------------------------------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  Database 
Hive,WITHOUT_CLASSIFICATION,//  LOW_VALUE 
Hive,WITHOUT_CLASSIFICATION,//  division by inverse multiplication. 
Hive,WITHOUT_CLASSIFICATION,//  None of the group expressions are constant. Nothing to do. 
Hive,WITHOUT_CLASSIFICATION,//    Type-specific implementations   
Hive,WITHOUT_CLASSIFICATION,//  Output types. They will be the concatenation of the input refs types and 
Hive,WITHOUT_CLASSIFICATION,//  Raise error if user has specified partition column for stats 
Hive,WITHOUT_CLASSIFICATION,//  Create planner and copy context 
Hive,WITHOUT_CLASSIFICATION,//  enable SSL support for HMS 
Hive,WITHOUT_CLASSIFICATION,//  connect all small dir map work to the big dir map work 
Hive,WITHOUT_CLASSIFICATION,//  add all the dependencies to a list 
Hive,WITHOUT_CLASSIFICATION,//  find min NDV for joining columns 
Hive,WITHOUT_CLASSIFICATION,//  add a filter count(c) = #branches 
Hive,WITHOUT_CLASSIFICATION,//  in case of exception assume unknown type (256 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  Can't access metadata carry on. 
Hive,WITHOUT_CLASSIFICATION,//  Blindly add this as a integer list! Should be sufficient for the test case. 
Hive,WITHOUT_CLASSIFICATION,//  batch statements? 
Hive,WITHOUT_CLASSIFICATION,//  also not loaded. 
Hive,WITHOUT_CLASSIFICATION,//  Look at everything in front of this lock to see if it should block 
Hive,WITHOUT_CLASSIFICATION,//  add original entries 
Hive,WITHOUT_CLASSIFICATION,//  Then we merge the operators of the works we are going to merge 
Hive,WITHOUT_CLASSIFICATION,//  The FS can be closed from under us if the task is interrupted. Release cache buffers.   We are assuming here that toRelease will not be present in such cases. 
Hive,WITHOUT_CLASSIFICATION,// NULL if any of the args are nulls 
Hive,WITHOUT_CLASSIFICATION,//  at least 2 checkers always 
Hive,WITHOUT_CLASSIFICATION,//  TODO Even out the batch sizes (i.e. 20/20/1 should be replaced by 14/14/13) 
Hive,WITHOUT_CLASSIFICATION,//  nothing to do 
Hive,WITHOUT_CLASSIFICATION,//  The original partition files are deleted after the metadata change   because the presence of those files are used to indicate whether   the original partition directory contains archived or unarchived files. 
Hive,WITHOUT_CLASSIFICATION,//  need to set up output name for reduce sink now that we know the name   of the downstream work 
Hive,WITHOUT_CLASSIFICATION,/*    * Allocate the target related arrays.    */
Hive,WITHOUT_CLASSIFICATION,// make sure currently running txn is considered aborted by housekeeper 
Hive,WITHOUT_CLASSIFICATION,//  Still the same column 
Hive,WITHOUT_CLASSIFICATION,//  each column has height of 2: 
Hive,WITHOUT_CLASSIFICATION,/*        * add list bucketing predicate to to the table scan operator        */
Hive,WITHOUT_CLASSIFICATION,//  create fetch work 
Hive,WITHOUT_CLASSIFICATION,//  If the file name to bucket number mapping is maintained store the bucket number   in the execution context. This is needed for the following scenario:   insert overwrite table T1 select * from T2;   where T1 and T2 are sorted/bucketed by the same keys into the same number of buckets   Although one mapper per file is used (BucketizedInputHiveInput) it is possible that   any mapper can pick up any file (depending on the size of the files). The bucket number   corresponding to the input file is stored to name the output bucket file appropriately. 
Hive,WITHOUT_CLASSIFICATION,//  provide us with a new URL to access the datastore. 
Hive,WITHOUT_CLASSIFICATION,//  and \0 to terminate 
Hive,WITHOUT_CLASSIFICATION,//  a sampling filter then we ignore the current filter 
Hive,WITHOUT_CLASSIFICATION,//  Create a database with a table 
Hive,WITHOUT_CLASSIFICATION,//  set default location if not specified and this is   a physical table partition (not a view) 
Hive,WITHOUT_CLASSIFICATION,//  parse the struct using multi-char delimiter 
Hive,WITHOUT_CLASSIFICATION,//  Drop dest4_sequencefile 
Hive,WITHOUT_CLASSIFICATION,//  No timestamp format specified just use default lazy inspector 
Hive,WITHOUT_CLASSIFICATION,// no files found for example empty table/partition 
Hive,WITHOUT_CLASSIFICATION,//  Verify that the table was created successfully. 
Hive,WITHOUT_CLASSIFICATION,//  Update the null counter 
Hive,WITHOUT_CLASSIFICATION,//  All the partitions need to be updated; a single command can be used. 
Hive,WITHOUT_CLASSIFICATION,//  connect using principal via Beeline with inputStream 
Hive,WITHOUT_CLASSIFICATION,//  comment column is empty 
Hive,WITHOUT_CLASSIFICATION,//  Remove any parallel edge between semijoin and mapjoin. 
Hive,WITHOUT_CLASSIFICATION,//  Unlike RandomAccessFileAppender do not append log when stopped. 
Hive,WITHOUT_CLASSIFICATION,//  Will properly set string or binary serialization via createLazyField(...) 
Hive,WITHOUT_CLASSIFICATION,//  Send some status periodically 
Hive,WITHOUT_CLASSIFICATION,//  Stick back into result variables... 
Hive,WITHOUT_CLASSIFICATION,//  Partition spec was already validated by caller when create TableSpec object. 
Hive,WITHOUT_CLASSIFICATION,//  If this is a source table we do not copy it out 
Hive,WITHOUT_CLASSIFICATION,//  set job name 
Hive,WITHOUT_CLASSIFICATION,//  It is a Java class 
Hive,WITHOUT_CLASSIFICATION,//  max # of rows can be put into one block 
Hive,WITHOUT_CLASSIFICATION,//  string types get converted to double 
Hive,WITHOUT_CLASSIFICATION,//  If the skew keys match the join keys then add it to the list 
Hive,WITHOUT_CLASSIFICATION,//  Either tableHandle isn't partitioned => null or repl-export after ts becomes null => null.   or this is a noop-replication export so we can skip looking at ptns. 
Hive,WITHOUT_CLASSIFICATION,//  max length for the char/varchar then the return type reverts to string. 
Hive,WITHOUT_CLASSIFICATION,//  the OpParseContext of the parent SelectOperator. 
Hive,WITHOUT_CLASSIFICATION,//  Key. 
Hive,WITHOUT_CLASSIFICATION,//  indicator so the chunked input does not know to stop reading. 
Hive,WITHOUT_CLASSIFICATION,//  Compute the size of a query when the 'nextValue' is added to the current query. 
Hive,WITHOUT_CLASSIFICATION,/*    * Test bad args to getXXX()   * @throws SQLException    */
Hive,WITHOUT_CLASSIFICATION,//  Check whether the materialized view is invalidated 
Hive,WITHOUT_CLASSIFICATION,//  Compare the value to each element of array until a match is found 
Hive,WITHOUT_CLASSIFICATION,//  Set up task. 
Hive,WITHOUT_CLASSIFICATION,//  Expectation here is not to run into a timeout 
Hive,WITHOUT_CLASSIFICATION,//  any name it does not   matter. 
Hive,WITHOUT_CLASSIFICATION,/*    * Information on a field.  Made a class to allow readField to be agnostic to whether a top level   * or field within a complex type is being read    */
Hive,WITHOUT_CLASSIFICATION,//  unfortunately we seem to get instances of varchar object inspectors without params   when an old-style UDF has an evaluate() method with varchar arguments.   If we disallow varchar in old-style UDFs and only allow GenericUDFs to be defined   with varchar arguments then we might be able to enforce this properly. 
Hive,WITHOUT_CLASSIFICATION,//  Note all maps and lists have to be absolutely sorted.  Otherwise we'll produce different   results for hashes based on the OS or JVM being used. 
Hive,WITHOUT_CLASSIFICATION,/*  * The interface for a single byte array key hash multi-set contains method.  */
Hive,WITHOUT_CLASSIFICATION,/*      * Guava versions <12.0 have stats collection enabled by default and do not expose a recordStats method.     * Check for newer versions of the library and ensure that stats collection is enabled by default.      */
Hive,WITHOUT_CLASSIFICATION,//  Update to previous comment: there does seem to be one place that uses this   and that is to authorize "show databases" in hcat commandline which is used   by webhcat. And user-level auth seems to be a reasonable default in this case.   The now deprecated HdfsAuthorizationProvider in hcatalog approached this in   another way and that was to see if the user had said above appropriate requested   privileges for the hive root warehouse directory. That seems to be the best   mapping for user level privileges to storage. Using that strategy here. 
Hive,WITHOUT_CLASSIFICATION,//  create map and fetch operators 
Hive,WITHOUT_CLASSIFICATION,//  Trim down the total number of n-grams if we've exceeded the maximum amount of memory allowed     NOTE: Although 'k'*'pf' specifies the size of the estimation buffer we don't want to keep         performing N.log(N) trim operations each time the maximum hashmap size is exceeded.         To handle this we *actually* maintain an estimation buffer of size 2*'k'*'pf' and         trim down to 'k'*'pf' whenever the hashmap size exceeds 2*'k'*'pf'. This really has 
Hive,WITHOUT_CLASSIFICATION,//  If the bucket is in the valid range mark it as covered.   I wish Hive actually enforced bucketing all of the time. 
Hive,WITHOUT_CLASSIFICATION,//  we used half the mem for small joins now let's scale the rest 
Hive,WITHOUT_CLASSIFICATION,//  BuddyAllocatorMXBean 
Hive,WITHOUT_CLASSIFICATION,/*  * An single STRING key hash map optimized for vector map join. * * The key will be deserialized and just the bytes will be stored.  */
Hive,WITHOUT_CLASSIFICATION,//  Use the current directory if it is not specified 
Hive,WITHOUT_CLASSIFICATION,// this consistently works locally but never in ptest.... 
Hive,WITHOUT_CLASSIFICATION,//  Test that 2 exclusive table locks coalesce to one 
Hive,WITHOUT_CLASSIFICATION,//  Get tables make sure the locations are correct 
Hive,WITHOUT_CLASSIFICATION,//  Build VectorizedParquetColumnReader via Hive typeInfo and Parquet schema 
Hive,WITHOUT_CLASSIFICATION,//  Get FieldSchema stuff if any. 
Hive,WITHOUT_CLASSIFICATION,//  Set provider options 
Hive,WITHOUT_CLASSIFICATION,//  test with and without specifying schema randomly 
Hive,WITHOUT_CLASSIFICATION,// convert to the types needed for plugin api 
Hive,WITHOUT_CLASSIFICATION,//  0 (lowest) 1 (middle) or 2 (high). 
Hive,WITHOUT_CLASSIFICATION,//  Log summary every ~15 seconds. 
Hive,WITHOUT_CLASSIFICATION,//  picks topN K:V pairs from input. 
Hive,WITHOUT_CLASSIFICATION,/*    * Initialize one column's source deserializtion information.    */
Hive,WITHOUT_CLASSIFICATION,//  we'd need to sleep once per round instead. 
Hive,WITHOUT_CLASSIFICATION,//  the directory this move task is moving 
Hive,WITHOUT_CLASSIFICATION,//  other operators or functions 
Hive,WITHOUT_CLASSIFICATION,//  TS-1      TS-2    |          |   RS-1      RS-2      \      /        JOIN          |         FIL          |         RS-3     For the above complex operator tree   selectivity(JOIN) = selectivity(RS-1) * selectivity(RS-2) and 
Hive,WITHOUT_CLASSIFICATION,//  read the keys before the delta is flushed 
Hive,WITHOUT_CLASSIFICATION,//  there are no elements in the map 
Hive,WITHOUT_CLASSIFICATION,//  return the variable length from config 
Hive,WITHOUT_CLASSIFICATION,//  Pattern to look for in the hive query and whether it matched 
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.TerminateFragmentRequestProto.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,//  3. Perform a major compaction. 
Hive,WITHOUT_CLASSIFICATION,//  ensure hiveserver2 site.xml does not get to override this 
Hive,WITHOUT_CLASSIFICATION,/*    * We need the base (operator.java) implementation of start/endGroup.   * The parent class has functionality in those that map join can't use.   * Note: The mapjoin can be run in the reducer only on Tez.    */
Hive,WITHOUT_CLASSIFICATION,//  Evaluate batch1 so that temporary arrays in the expression   have residual values to interfere in later computation 
Hive,WITHOUT_CLASSIFICATION,//  100-200 byte string. Maybe replace with a local-dir-id and construct on the fly.   3 longs + reference overheads. 
Hive,WITHOUT_CLASSIFICATION,/*    * Union    */
Hive,WITHOUT_CLASSIFICATION,//  Authorize individually. 
Hive,WITHOUT_CLASSIFICATION,//  Fail the 2nd update too to get rid of the duck for the next test. 
Hive,WITHOUT_CLASSIFICATION,//  if hash aggregation is not behaving properly disable it 
Hive,WITHOUT_CLASSIFICATION,//  if stripe offset is outside the split boundary then ignore the current   stripe as it will be handled by some other mapper. 
Hive,WITHOUT_CLASSIFICATION,//  If still files remains to be copied due to failure/checksum mismatch after several attempts then throw error 
Hive,WITHOUT_CLASSIFICATION,//  directory does not exist create it 
Hive,WITHOUT_CLASSIFICATION,//  Find any constraints and drop them 
Hive,WITHOUT_CLASSIFICATION,//  Verify that we have got correct set of delete_deltas also 
Hive,WITHOUT_CLASSIFICATION,//  First generate all the opInfos for the elements in the from clause 
Hive,WITHOUT_CLASSIFICATION,// fakePart path partition is added since the defined partition keys are valid 
Hive,WITHOUT_CLASSIFICATION,//  OPERATION_HANDLE 
Hive,WITHOUT_CLASSIFICATION,//  if this is a replication spec then replace-mode semantics might apply. 
Hive,WITHOUT_CLASSIFICATION,//  internal usage only   if length of variable length data type cannot be determined this length will be used. 
Hive,WITHOUT_CLASSIFICATION,//  Create the column descriptors 
Hive,WITHOUT_CLASSIFICATION,// return null only if the file system in schema is not recognized 
Hive,WITHOUT_CLASSIFICATION,//  CREATE_TABLE - 5 TRUNCATE - 20(20 <= Id < 100) INSERT - 100 
Hive,WITHOUT_CLASSIFICATION,//  we have to setup this again as the underlying PMF keeps getting reinitialized with original   reference closed 
Hive,WITHOUT_CLASSIFICATION,//  Now set other column nullable too 
Hive,WITHOUT_CLASSIFICATION,//  tezJsonParser 
Hive,WITHOUT_CLASSIFICATION,//  Now the relevant TableScanOperators are known find if there exists   a semijoin filter on any of them if so remove it. 
Hive,WITHOUT_CLASSIFICATION,//  Right now we do not handle the case that either of them is bucketed.   We should relax this constraint with a follow-up jira. 
Hive,WITHOUT_CLASSIFICATION,//  the hashCode() and equals() methods of the key class. 
Hive,WITHOUT_CLASSIFICATION,// No location - should allocate if force no capacity otherwise 
Hive,WITHOUT_CLASSIFICATION,//  This is the case when we've encountered a decimal separator. The fractional   part will not change the number but we will verify that the fractional part 
Hive,WITHOUT_CLASSIFICATION,//  Dryrun checks are meaningless for mutable table - we should always succeed   unless there is a runtime IOException. 
Hive,WITHOUT_CLASSIFICATION,//  whether there's spilled data to be processed   used to hold restored 
Hive,WITHOUT_CLASSIFICATION,// find dynamic partition columns  relies on consistent order via LinkedHashMap 
Hive,WITHOUT_CLASSIFICATION,//  SessionState is not available in runtime and Hive.get().getConf() is not safe to call 
Hive,WITHOUT_CLASSIFICATION,//  These are all values that we put here just for testing 
Hive,WITHOUT_CLASSIFICATION,//  types get initialized in case they need to setup any   internal data structures - e.g. DynamicSerDeStructBase 
Hive,WITHOUT_CLASSIFICATION,//  4. Keep track of colname-to-posmap && RR for new select 
Hive,WITHOUT_CLASSIFICATION,//  If we can get them from HDFS add group and permission 
Hive,WITHOUT_CLASSIFICATION,//  1. Split leaf join predicate to expressions from left right 
Hive,WITHOUT_CLASSIFICATION,//  if project has any correlated reference make sure they are also   provided by the current correlate. They will be projected out of the LHS 
Hive,WITHOUT_CLASSIFICATION,//  a special property starting with mapreduce that we would also like to effect if it changes 
Hive,WITHOUT_CLASSIFICATION,//  In that case Executors.newFixedThreadPool will fail. 
Hive,WITHOUT_CLASSIFICATION,//  Re-process spilled data 
Hive,WITHOUT_CLASSIFICATION,//  Add Spark job handle id to the Hive History 
Hive,WITHOUT_CLASSIFICATION,//  Prefix operator 
Hive,WITHOUT_CLASSIFICATION,//  It is ok ignore 
Hive,WITHOUT_CLASSIFICATION,//  The user asked for stats to be collected.   Some stats like number of rows require a scan of the data   However some other stats like number of files do not require a complete scan 
Hive,WITHOUT_CLASSIFICATION,//  input paths. 
Hive,WITHOUT_CLASSIFICATION,//  This ensures we don't create skew e.g. with 8 ducks and 5 queries with simple rounding   we'd produce 2-2-2-2-0 as we round 1.6; whereas adding the last delta to the next query   we'd round 1.6-1.2-1.8-1.4-2.0 and thus give out 2-1-2-1-2 as intended.   Note that fractions don't have to all be the same like in this example. 
Hive,WITHOUT_CLASSIFICATION,//  expect to fail since the time component is not 0 
Hive,WITHOUT_CLASSIFICATION,//  verify syntax error 
Hive,WITHOUT_CLASSIFICATION,//  fastIsInt returns false. 
Hive,WITHOUT_CLASSIFICATION,// old partition does not exist 
Hive,WITHOUT_CLASSIFICATION,//  use Kryo to serialize hashmap 
Hive,WITHOUT_CLASSIFICATION,/*          * Caller is responsible for setting children and input type information.          */
Hive,WITHOUT_CLASSIFICATION,//  "cause" is a root cause and "e"/"first" is a useless   exception it's wrapped in. 
Hive,WITHOUT_CLASSIFICATION,/*                * Multi-key specific lookup key.                */
Hive,WITHOUT_CLASSIFICATION,//  storagehandler passed as table params 
Hive,WITHOUT_CLASSIFICATION,//  Cast the input to decimal   If castType is decimal try not to lose precision for numeric types. 
Hive,WITHOUT_CLASSIFICATION,//  -- HIVE-4149 
Hive,WITHOUT_CLASSIFICATION,//  this is only for the purpose of authorization only the name matters. 
Hive,WITHOUT_CLASSIFICATION,//  Specify an OrcSplit that starts beyond the offset of the last stripe. 
Hive,WITHOUT_CLASSIFICATION,//  PROPERTIES 
Hive,WITHOUT_CLASSIFICATION,// Transformation is to left join for correlated predicates and inner join otherwise 
Hive,WITHOUT_CLASSIFICATION,//  vertex's parent connections. 
Hive,WITHOUT_CLASSIFICATION,//  Should generate [fm] 
Hive,WITHOUT_CLASSIFICATION,//  out of range probes 
Hive,WITHOUT_CLASSIFICATION,//  set the key 
Hive,WITHOUT_CLASSIFICATION,//  schema of the map-reduce 'key' object - this is homogeneous 
Hive,WITHOUT_CLASSIFICATION,//  Crucial here that we don't reset the overflow batch or we will loose the small table 
Hive,WITHOUT_CLASSIFICATION,/*  * Convert tasks involving JOIN into MAPJOIN. * If hive.auto.convert.join is true the tasks involving join are converted. * Consider the query: * select .... from T1 join T2 on T1.key = T2.key join T3 on T1.key = T3.key * * There is a map-reduce task which performs a 3-way join (T1 T2 T3). * The task would be converted to a conditional task which would have 4 children * a. Mapjoin considering T1 as the big table * b. Mapjoin considering T2 as the big table * c. Mapjoin considering T3 as the big table * d. Map-reduce join (the original task). * *  Note that the sizes of all the inputs may not be available at compile time. At runtime it is *  determined which branch we want to pick up from the above. * * However if hive.auto.convert.join.noconditionaltask is set to true and * the sum of any n-1 tables is smaller than hive.auto.convert.join.noconditionaltask.size * then a mapjoin is created instead of the conditional task. For the above if the size of * T1 + T2 is less than the threshold then the task is converted to a mapjoin task with T3 as * the big table. * * In this case further optimization is performed by merging 2 consecutive map-only jobs. * Consider the query: * select ... from T1 join T2 on T1.key1 = T2.key1 join T3 on T1.key2 = T3.key2 * * Initially the plan would consist of 2 Map-reduce jobs (1 to perform join for T1 and T2) * followed by another map-reduce job (to perform join of the result with T3). After the * optimization both these tasks would be converted to map-only tasks. These 2 map-only jobs * are then merged into a single map-only job. As a followup (HIVE-3952) it would be possible to * merge a map-only task with a map-reduce task. * Consider the query: * select T1.key2 count(*) from T1 join T2 on T1.key1 = T2.key1 group by T1.key2; * Initially the plan would consist of 2 Map-reduce jobs (1 to perform join for T1 and T2) * followed by another map-reduce job (to perform groupby of the result). After the * optimization the join task would be converted to map-only tasks. After HIVE-3952 the map-only * task would be merged with the map-reduce task to create a single map-reduce task.  */
Hive,WITHOUT_CLASSIFICATION,// @formatter:on 
Hive,WITHOUT_CLASSIFICATION,//  then add any cor var from the left input. Do not need to change 
Hive,WITHOUT_CLASSIFICATION,//  missing one partition on fs 
Hive,WITHOUT_CLASSIFICATION,//  A hash map which stores job credentials. The key is a signature passed by Pig which is 
Hive,WITHOUT_CLASSIFICATION,//  create selection operator 
Hive,WITHOUT_CLASSIFICATION,//  restore the reducer 
Hive,WITHOUT_CLASSIFICATION,//  negative Unix time 
Hive,WITHOUT_CLASSIFICATION,/*           This should be removed eventually. HIVE-17814 gives more detail          explanation of whats happening and HIVE-17815 as to why this is done.          Briefly for replication the graph is huge and so memory pressure is going to be huge if          we keep a lot of references around.         */
Hive,WITHOUT_CLASSIFICATION,//  will cause underflow for result at position 0 must yield NULL 
Hive,WITHOUT_CLASSIFICATION,//  can add .verboseLogging() to cause Mockito to log invocations 
Hive,WITHOUT_CLASSIFICATION,/*  fast0  */
Hive,WITHOUT_CLASSIFICATION,//  scale up/down 
Hive,WITHOUT_CLASSIFICATION,//  Note: this may use additional inputs from the caller e.g. maximum query   parallelism in the cluster based on physical constraints. 
Hive,WITHOUT_CLASSIFICATION,// run Compaction 
Hive,WITHOUT_CLASSIFICATION,//  Then we need to set up the graph connection. Especially:   1 we need to connect this cloned parent work with all the grand-parent works. 
Hive,WITHOUT_CLASSIFICATION,//  ORC writer reuses streams so we need to clean them here and extract data. 
Hive,WITHOUT_CLASSIFICATION,//  TODO: this makes many assumptions e.g. on how generic args are done 
Hive,WITHOUT_CLASSIFICATION,// nuke trailing " or " 
Hive,WITHOUT_CLASSIFICATION,//  v1 is top level view we should care about its access info. 
Hive,WITHOUT_CLASSIFICATION,//  fetch table ablias 
Hive,WITHOUT_CLASSIFICATION,/*    * build:   *         ^(TOK_SELECT   *             ^(TOK_SELECTEXPR {ast tree for count *}   *          )    */
Hive,WITHOUT_CLASSIFICATION,//  trigger and action expressions are not validated here since counters are not 
Hive,WITHOUT_CLASSIFICATION,//  this might be a little bit too much...but in most cases this should be true 
Hive,WITHOUT_CLASSIFICATION,//  the first time. 
Hive,WITHOUT_CLASSIFICATION,//  use TextFile by default 
Hive,WITHOUT_CLASSIFICATION,//  We will rewrite it to include the filters on transaction list   so we can produce partial rewritings 
Hive,WITHOUT_CLASSIFICATION,//  Invalid character in new database name 
Hive,WITHOUT_CLASSIFICATION,//  confirm the batch sizes were 5 4 in the two calls to create partitions 
Hive,WITHOUT_CLASSIFICATION,//  single predicate condition 
Hive,WITHOUT_CLASSIFICATION,/*        * If the current table function has no order info specified;        */
Hive,WITHOUT_CLASSIFICATION,//  miniHS2_1 will be leader 
Hive,WITHOUT_CLASSIFICATION,//  We will try to merge this clause into one of the previously added ones. 
Hive,WITHOUT_CLASSIFICATION,//  We have released the session by trying to reuse it and going back into queue s3 can start. 
Hive,WITHOUT_CLASSIFICATION,//  This bit should not be on for valid value references.  We use -1 for a no value marker. 
Hive,WITHOUT_CLASSIFICATION,//  logRefreshError always throws. 
Hive,WITHOUT_CLASSIFICATION,//  Do nothing but count the batch size. 
Hive,WITHOUT_CLASSIFICATION,//  just remember it for later processing 
Hive,WITHOUT_CLASSIFICATION,// http://www.postgresql.org/docs/8.1/static/errcodes-appendix.html 
Hive,WITHOUT_CLASSIFICATION,//  check that the mapping schema is right;   check that the "column-family:" is mapped to  Map<key?>   where key extends LazyPrimitive<? ?> and thus has type Category.PRIMITIVE 
Hive,WITHOUT_CLASSIFICATION,//  replace original STDDEV_SAMP(x) with     SQRT(       (SUM(x * x) - SUM(x) * SUM(x) / COUNT(x))       / CASE COUNT(x) WHEN 1 THEN NULL ELSE COUNT(x) - 1 END) 
Hive,WITHOUT_CLASSIFICATION,//  SEL%SEL% rule. 
Hive,WITHOUT_CLASSIFICATION,//  a signature string to associate with a HCatTableInfo - essentially 
Hive,WITHOUT_CLASSIFICATION,//  if extended desc table then show the complete details of the table 
Hive,WITHOUT_CLASSIFICATION,//  so that it produces multiple queries. For that we need at least 290. 
Hive,WITHOUT_CLASSIFICATION,//  Insert overwrite on existing partition 
Hive,WITHOUT_CLASSIFICATION,//  retValue is transient so store this separately. 
Hive,WITHOUT_CLASSIFICATION,//  Sort only references field positions in collations field.   The collations field in the newRel now need to refer to the   new output positions in its input.   Its output does not change the input ordering so there's no   need to call propagateExpr. 
Hive,WITHOUT_CLASSIFICATION,//  Create the appender 
Hive,WITHOUT_CLASSIFICATION,//  lock correctly. See the comment on the lock field - the locking needs to be reworked. 
Hive,WITHOUT_CLASSIFICATION,//  to the small table result portion of the output for outer join. 
Hive,WITHOUT_CLASSIFICATION,//  to prompt 
Hive,WITHOUT_CLASSIFICATION,//  Not supported at all. 
Hive,WITHOUT_CLASSIFICATION,//  Deserialize the HCatPartitionSpec using the target HCatClient instance. 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise queue the session and make sure we update this pool. 
Hive,WITHOUT_CLASSIFICATION,//  Scan through any remaining digits... 
Hive,WITHOUT_CLASSIFICATION,//  If the original location exists here then it must be the extracted files   because in the previous step we moved the previous original location 
Hive,WITHOUT_CLASSIFICATION,//  mapping of bucket id to size of all splits in bucket in bytes 
Hive,WITHOUT_CLASSIFICATION,//  Tez requires us to use RPC for the query plan 
Hive,WITHOUT_CLASSIFICATION,//  Compactor types 
Hive,WITHOUT_CLASSIFICATION,//  When inserting into a new partition the add partition event takes care of insert event 
Hive,WITHOUT_CLASSIFICATION,//  If any events were queued by the responder give them to the record reader now. 
Hive,WITHOUT_CLASSIFICATION,//  In the end update free list head. 
Hive,WITHOUT_CLASSIFICATION,//  Configure export work 
Hive,WITHOUT_CLASSIFICATION,//  the server sends 401 very frequently 
Hive,WITHOUT_CLASSIFICATION,//  Read one field by one field 
Hive,WITHOUT_CLASSIFICATION,//  This should be removed when authenticator and the 2-username mess is cleaned up. 
Hive,WITHOUT_CLASSIFICATION,//  Release the unreleased buffers. See class comment about refcounts. 
Hive,WITHOUT_CLASSIFICATION,//  Expiration queue is synchronized and notified upon when adding elements. Without jitter we   wouldn't need this and could simple look at the first element and sleep for the wait time.   However when many things are added at once it may happen that we will see the one that   expires later first and will sleep past the earlier expiration times. When we wake up we   may kill many sessions at once. To avoid this we will add to queue under lock and recheck   time before we wait. We don't have to worry about removals; at worst we'd wake up in vain.   Example: expirations of 1:03:00 1:00:00 1:02:00 are added (in this order due to jitter).   If the expiration threads sees that 1:03 first it will sleep for 1:03 then wake up and   kill all 3 sessions at once because they all have expired removing any effect from jitter.   Instead expiration thread rechecks the first queue item and waits on the queue. If nothing   is added to the queue the item examined is still the earliest to be expired. If someone   adds to the queue while it is waiting it will notify the thread and it would wake up and   recheck the queue. 
Hive,WITHOUT_CLASSIFICATION,//  Replication destination will not be external - override if set 
Hive,WITHOUT_CLASSIFICATION,// create 2 rows in a file 00000_0 
Hive,WITHOUT_CLASSIFICATION,//  There should only be a single split line... 
Hive,WITHOUT_CLASSIFICATION,//  Filter files starts with ".". Note Hadoop consider files starts with   "." or "_" as hidden file. However we need to replicate files starts   with "_". We find at least 2 use cases:   1. For har files _index and _masterindex is required files 
Hive,WITHOUT_CLASSIFICATION,//  Up to nanos 
Hive,WITHOUT_CLASSIFICATION,//  Retrieve the acidOperationalProperties for the table initialized in HiveInputFormat. 
Hive,WITHOUT_CLASSIFICATION,//  Don't request any locks here as the table has already been locked. 
Hive,WITHOUT_CLASSIFICATION,//  -insert table as select- should not return a ResultSet 
Hive,WITHOUT_CLASSIFICATION,/*      * Generate GB plan.     *     * @param qb     * @param srcRel     * @return TODO: 1. Grouping Sets (roll up..)     * @throws SemanticException      */
Hive,WITHOUT_CLASSIFICATION,//  all keywrappers must be EmptyVectorHashKeyWrapper 
Hive,WITHOUT_CLASSIFICATION,// do nothing to hanlde future RU/D where we may want to add new state types 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   optional   optional   optional   optional   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  If structs recursively compare the fields 
Hive,WITHOUT_CLASSIFICATION,//  Only altering the database property and owner is currently supported 
Hive,WITHOUT_CLASSIFICATION,//  pRS-cGBYm-cRS-cGBYr (map aggregation) --> pRS-cGBYr(COMPLETE)   copies desc of cGBYm to cGBYr and remove cGBYm and cRS 
Hive,WITHOUT_CLASSIFICATION,//  we do not use BytesWritable here to avoid the byte-copy from 
Hive,WITHOUT_CLASSIFICATION,//  first_name = 'john' or    'greg' < first_name or    'alan' > first_name or    id > 12 or    13 < id or    id < 15 or    16 > id or    (id <=> 30 and first_name <=> 'owen') 
Hive,WITHOUT_CLASSIFICATION,//  List bucketed table cannot be converted to transactional 
Hive,WITHOUT_CLASSIFICATION,//  Create key/value structs and add the respective fields to each one 
Hive,WITHOUT_CLASSIFICATION,//  6. Now apply a resource plan if any. This is expected to be pretty rare. 
Hive,WITHOUT_CLASSIFICATION,//  verify that udf not in whitelist fails 
Hive,WITHOUT_CLASSIFICATION,//  If this isn't equal then bogus key values have been inserted error out. 
Hive,WITHOUT_CLASSIFICATION,//  for getPos() 
Hive,WITHOUT_CLASSIFICATION,//  if schema size cannot be matched then it could be because of constant folding   converting partition column expression to constant expression. The constant   expression will then get pruned by column pruner since it will not reference to   any columns. 
Hive,WITHOUT_CLASSIFICATION,//  The situation here and in other readers is currently as such - setBuffers is never called   in SerDe reader case and SerDe reader case is the only one that uses vector-s.   When the readers are created with vectors streams are actually not created at all.   So if we could have a set of vectors then set of buffers we'd be in trouble here;   we may need to implement that if this scenario is ever supported. 
Hive,WITHOUT_CLASSIFICATION,//  Expected exception 
Hive,WITHOUT_CLASSIFICATION,//  Column type 
Hive,WITHOUT_CLASSIFICATION,//  for any exception in conversion to integer produce NULL 
Hive,WITHOUT_CLASSIFICATION,//  Set the DB_NOTIFICATION_EVENT_ID for future reference by other listeners. 
Hive,WITHOUT_CLASSIFICATION,//  identd 
Hive,WITHOUT_CLASSIFICATION,//  Can't assume JDK 1.8 so implementing this explicitly.   return Long.compare(x + Long.MIN_VALUE y + Long.MIN_VALUE); 
Hive,WITHOUT_CLASSIFICATION,//        That could be especially valuable given that this almost always the same set. 
Hive,WITHOUT_CLASSIFICATION,//  TOK_QUERY above insert 
Hive,WITHOUT_CLASSIFICATION,//  for each alias add object inspector for short as the last element 
Hive,WITHOUT_CLASSIFICATION,//  We need to send the state update again (the state has changed since the last one). 
Hive,WITHOUT_CLASSIFICATION,//  Might not exist 
Hive,WITHOUT_CLASSIFICATION,/*    * Ordinals for various reasons why an Error of this type can be thrown.    */
Hive,WITHOUT_CLASSIFICATION,// When columns is 0 the union operator is empty. 
Hive,WITHOUT_CLASSIFICATION,// check elements of the innermost struct 
Hive,WITHOUT_CLASSIFICATION,//  param did not parse as a URL so not a URL 
Hive,WITHOUT_CLASSIFICATION,/*    * An extension to AcidOutputFormat that allows users to add additional   * options.   *   * todo: since this is only used for testing could we not control the writer some other way?   * to simplify {@link #OrcRecordUpdater(Path AcidOutputFormat.Options)}    */
Hive,WITHOUT_CLASSIFICATION,//  We have to initialize the thread pool before we start this one as it uses it 
Hive,WITHOUT_CLASSIFICATION,//  There are a couple of possibilities to consider here to see if we should recurse or not.   a) Path is a regex and may match multiple entries - if so this is likely a load and          we should listStatus for all relevant matches and recurse-check each of those.          Simply passing the filestatus on as recurse=true makes sense for this.   b) Path is a singular directory/file and exists          recurse=true to check all its children if applicable   c) Path is a singular entity that does not exist          recurse=false to check its parent - this is likely a case of          needing to create a dir that does not exist yet. 
Hive,WITHOUT_CLASSIFICATION,//  Is output type a BOOLEAN? 
Hive,WITHOUT_CLASSIFICATION,//  If the record writer provides stats get it from there instead of the serde 
Hive,WITHOUT_CLASSIFICATION,//  Return join collations 
Hive,WITHOUT_CLASSIFICATION,//  Only one send can be active at the same time. 
Hive,WITHOUT_CLASSIFICATION,// Grouping sets expressions 
Hive,WITHOUT_CLASSIFICATION,//  for all the other aggregations we set the mode to PARTIAL2 
Hive,WITHOUT_CLASSIFICATION,//  walk the other part of ast 
Hive,WITHOUT_CLASSIFICATION,//  Wait for the first item to arrive at the queue and process it. 
Hive,WITHOUT_CLASSIFICATION,//  Abandon the reuse attempt. 
Hive,WITHOUT_CLASSIFICATION,//  Assert.assertEquals(1 resultDec.integerDigitCount()); 
Hive,WITHOUT_CLASSIFICATION,// The FileSplit() constructor in hadoop 0.20 and 1.x is package private so can't use it.  This constructor is used to create the object and then call readFields()   so just pass nulls to this super constructor. 
Hive,WITHOUT_CLASSIFICATION,/*      * See org.apache.hadoop.hive.ql.parse.TestMergeStatement for some examples of the merge AST      For example given:      merge into acidTbl using nonAcidPart2 source ON acidTbl.a = source.a2      WHEN MATCHED THEN UPDATE set b = source.b2      WHEN NOT MATCHED THEN INSERT VALUES(source.a2 source.b2)      We get AST like this:      "(tok_merge " +        "(tok_tabname acidtbl) (tok_tabref (tok_tabname nonacidpart2) source) " +        "(= (. (tok_table_or_col acidtbl) a) (. (tok_table_or_col source) a2)) " +        "(tok_matched " +        "(tok_update " +        "(tok_set_columns_clause (= (tok_table_or_col b) (. (tok_table_or_col source) b2))))) " +        "(tok_not_matched " +        "tok_insert " +        "(tok_value_row (. (tok_table_or_col source) a2) (. (tok_table_or_col source) b2))))");        And need to produce a multi-insert like this to execute:        FROM acidTbl right outer join nonAcidPart2 ON acidTbl.a = source.a2        Insert into table acidTbl select nonAcidPart2.a2 nonAcidPart2.b2 where acidTbl.a is null        INSERT INTO TABLE acidTbl select target.ROW__ID nonAcidPart2.a2 nonAcidPart2.b2 where nonAcidPart2.a2=acidTbl.a sort by acidTbl.ROW__ID     */
Hive,WITHOUT_CLASSIFICATION,//  create a table with a unique name in testDb 
Hive,WITHOUT_CLASSIFICATION,//  If the field corresponds to a column family in HBase 
Hive,WITHOUT_CLASSIFICATION,//  Use Case 1.   amt == UNBOUNDED is caught during translation 
Hive,WITHOUT_CLASSIFICATION,//  year   month 
Hive,WITHOUT_CLASSIFICATION,//  If newSortColList had a null value it means that at least one of the input sort   columns did not have a representative found in the output columns so assume the data   is no longer sorted 
Hive,WITHOUT_CLASSIFICATION,//  6. Return the new join as a replacement 
Hive,WITHOUT_CLASSIFICATION,//  Not bothering with removing the entry. There's a limited number of hosts and a good   chance that the entry will make it back in when the AM is used for a long duration. 
Hive,WITHOUT_CLASSIFICATION,//  [A: 0 B: 2] 
Hive,WITHOUT_CLASSIFICATION,//  Push the node in the stack 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:PurgeCacheResponseProto) 
Hive,WITHOUT_CLASSIFICATION,//  Query parallelism might be fubar. 
Hive,WITHOUT_CLASSIFICATION,//  Create test-null-appender to drop events without queryId 
Hive,WITHOUT_CLASSIFICATION,// set dest name mapping on new context; 1st chid is TOK_FROM 
Hive,WITHOUT_CLASSIFICATION,/*  * With an aim to consolidate the join algorithms to either hash based joins (MapJoinOperator) or * sort-merge based joins this operator is being introduced. This operator executes a sort-merge * based algorithm. It replaces both the JoinOperator and the SMBMapJoinOperator for the tez side of * things. It works in either the map phase or reduce phase. * * The basic algorithm is as follows: * * 1. The processOp receives a row from a "big" table. * 2. In order to process it the operator does a fetch for rows from the other tables. * 3. Once we have a set of rows from the other tables (till we hit a new key) more rows are *    brought in from the big table and a join is performed.  */
Hive,WITHOUT_CLASSIFICATION,//  Get the final state of the Spark job and parses its job info 
Hive,WITHOUT_CLASSIFICATION,//  alias3 only can be selected 
Hive,WITHOUT_CLASSIFICATION,// here we need to see if remaining columns are dynamic partition columns 
Hive,WITHOUT_CLASSIFICATION,//  convert to Text and write it 
Hive,WITHOUT_CLASSIFICATION,//  if join-key is null process each row in different group. 
Hive,WITHOUT_CLASSIFICATION,//  Third value. 
Hive,WITHOUT_CLASSIFICATION,//  1. Build Column Names 
Hive,WITHOUT_CLASSIFICATION,//  Finally write the hash code. 
Hive,WITHOUT_CLASSIFICATION,/*        * If threads are not configured then they will be executed in current thread itself.        */
Hive,WITHOUT_CLASSIFICATION,// conf.set("hadoop.job.history.location"new File(workDir).getAbsolutePath()+"/history"); 
Hive,WITHOUT_CLASSIFICATION,//  Go through all bytes in the byte[] 
Hive,WITHOUT_CLASSIFICATION,//  Create the LazyObject for storing the rows 
Hive,WITHOUT_CLASSIFICATION,//  overflow 
Hive,WITHOUT_CLASSIFICATION,//  for now check only table & db 
Hive,WITHOUT_CLASSIFICATION,//  since for LEFT join we are only interested in rows from LEFT we can get rid of right side 
Hive,WITHOUT_CLASSIFICATION,// column stats will be inaccurate 
Hive,WITHOUT_CLASSIFICATION,//  Move the hfiles file(s) from the task output directory to the   location specified by the user. 
Hive,WITHOUT_CLASSIFICATION,//  all nulls are now explicit 
Hive,WITHOUT_CLASSIFICATION,//  mysql postgres sql server 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see org.apache.hadoop.hive.ql.optimizer.Transform#transform(org.apache.hadoop.hive.ql.parse.   * ParseContext)    */
Hive,WITHOUT_CLASSIFICATION,//  It might just be the default in which case we can drop that one if it's empty 
Hive,WITHOUT_CLASSIFICATION,//  set the arguments for GenericUDFStructField 
Hive,WITHOUT_CLASSIFICATION,//  Set up the base class 
Hive,WITHOUT_CLASSIFICATION,//  Process the bytes that can be escaped (the last one can't be). 
Hive,WITHOUT_CLASSIFICATION,//  create a dummy select to select all columns 
Hive,WITHOUT_CLASSIFICATION,//  Intentionally using the deprecated method to make sure it returns correct results. 
Hive,WITHOUT_CLASSIFICATION,//  All fields have been parsed or bytes have been parsed.   We need to set the startPositions of fields.length to ensure we   can use the same formula to calculate the length of each field.   For missing fields their starting positions will all be the same   which will make their lengths to be -1 and uncheckedGetField will   return these fields as NULLs. 
Hive,WITHOUT_CLASSIFICATION,//  Run with --recover and save the output to a file so it can be checked. 
Hive,WITHOUT_CLASSIFICATION,//  this scales down o.v[0] to 0 because 2^32 = 4.2E9. No   possibility of rounding. 
Hive,WITHOUT_CLASSIFICATION,//  change the children of the original join operator to point to the map 
Hive,WITHOUT_CLASSIFICATION,//  Wait for all threads to be ready.   Release them at the same time. 
Hive,WITHOUT_CLASSIFICATION,/*     nonacidnonbucket/    ├── 000000_0    ├── 000000_0_copy_1    ├── 000000_0_copy_2    ├── base_0000004    │   └── bucket_00000    ├── delete_delta_0000002_0000002_0000    │   └── bucket_00000    ├── delete_delta_0000004_0000004_0000    │   └── bucket_00000    ├── delta_0000001_0000001_0000    │   └── bucket_00000    ├── delta_0000002_0000002_0000    │   └── bucket_00000    └── delta_0000003_0000003_0000        └── bucket_00000    6 directories 9 files     */
Hive,WITHOUT_CLASSIFICATION,//  This is only needed if a new grouping set key is being created 
Hive,WITHOUT_CLASSIFICATION,//  Check for the escaped colon to remove before doing the expensive regex replace 
Hive,WITHOUT_CLASSIFICATION,//  Make one a materialized view 
Hive,WITHOUT_CLASSIFICATION,//  The scale of the decimal. 
Hive,WITHOUT_CLASSIFICATION,//  The offset in the destination array for the beginning of this missing range. 
Hive,WITHOUT_CLASSIFICATION,//  Test EventUtils.getEventBoundaryFilter - this is supposed to only allow events 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.ICLIService#cancelOperation(org.apache.hive.service.cli.OperationHandle)    */
Hive,WITHOUT_CLASSIFICATION,//  in the for loop below 
Hive,WITHOUT_CLASSIFICATION,//  Note that for temp tables there is no need to rename directories 
Hive,WITHOUT_CLASSIFICATION,//  they don't seem to work. The IPC timeout needs to be set instead. 
Hive,WITHOUT_CLASSIFICATION,//  source: HiveEvents.proto 
Hive,WITHOUT_CLASSIFICATION,//  If we have cases where we are running a query like count(key) or count(*)   in such cases the readColIDs is either empty(for count(*)) or has just the   key column in it. In either case nothing gets added to the scan. So if readAllColumns is   true we are going to add all columns. Else we are just going to add a key filter to run a 
Hive,WITHOUT_CLASSIFICATION,//  OBJECT_TYPE_PTR 
Hive,WITHOUT_CLASSIFICATION,//  generate data file for test 
Hive,WITHOUT_CLASSIFICATION,//  3. Input Output Row Resolvers 
Hive,WITHOUT_CLASSIFICATION,//  2. Generate the vertex/submit information for all events. 
Hive,WITHOUT_CLASSIFICATION,//  partitioned table we expect partition values   convert user specified map to have lower case key names 
Hive,WITHOUT_CLASSIFICATION,//  Fallback to integer parsing 
Hive,WITHOUT_CLASSIFICATION,//  Save so we can verify end of stream   We need mark support - wrap with BufferedInputStream. 
Hive,WITHOUT_CLASSIFICATION,// we don't expect corr vars withing JOIN or UNION for now   we only expect cor vars in top level filter 
Hive,WITHOUT_CLASSIFICATION,//  Get the maximum of the number of tasks in the stages of the job and cancel the job if it goes beyond the limit. 
Hive,WITHOUT_CLASSIFICATION,/*      * Bail if having clause uses Select Expression aliases for Aggregation     * expressions. We could do what Hive does. But this is non standard     * behavior. Making sure this doesn't cause issues when translating through     * Calcite is not worth it.      */
Hive,WITHOUT_CLASSIFICATION,//  We don't care about these. 
Hive,WITHOUT_CLASSIFICATION,//  If the user hasn't been reading by row use the fast path. 
Hive,WITHOUT_CLASSIFICATION,//  we assert only if we expected to assert with this call. 
Hive,WITHOUT_CLASSIFICATION,//  5/ update the list byte size 
Hive,WITHOUT_CLASSIFICATION,//  Close the writer to finalize the metadata. 
Hive,WITHOUT_CLASSIFICATION,//  since we may need to split the task let's walk the graph bottom-up 
Hive,WITHOUT_CLASSIFICATION,//  grouping happens in execution phase. The input payload should not enable grouping here 
Hive,WITHOUT_CLASSIFICATION,//  note: v[0] ^ v[1] ^ v[2] ^ v[3] would cause too many hash collisions 
Hive,WITHOUT_CLASSIFICATION,//  Don't throw an exception if the target location only contains the staging-dirs 
Hive,WITHOUT_CLASSIFICATION,//  suffix first 
Hive,WITHOUT_CLASSIFICATION,// with split update new version of the row is a new insert 
Hive,WITHOUT_CLASSIFICATION,//  Junk after trailing blank padding. 
Hive,WITHOUT_CLASSIFICATION,//  production is:   [this.fieldid :] Requiredness() FieldType() this.name FieldValue()   [CommaOrSemicolon()] 
Hive,WITHOUT_CLASSIFICATION,/*  enable zero copy record reader  */
Hive,WITHOUT_CLASSIFICATION,//  Consider a query like:   select a b count(distinct c) from T group by ab with rollup;   Assume that hive.map.aggr is set to true and hive.groupby.skewindata is false   in which case the group by would execute as a single map-reduce job.   For the group-by the group by keys should be: abgroupingSet(for rollup) c 
Hive,WITHOUT_CLASSIFICATION,/*      * If the form is Dim loj F or Fact roj Dim or Dim semij Fact then return     * null.      */
Hive,WITHOUT_CLASSIFICATION,//  The job configuration is passed in so the configuration will be cloned   from the pig job configuration. This is necessary for overriding   metastore configuration arguments like the metastore jdbc connection string   and password in the case of an embedded metastore which you get when   hive.metastore.uris = "". 
Hive,WITHOUT_CLASSIFICATION,//  Turn off metastore-side authorization 
Hive,WITHOUT_CLASSIFICATION,//  masking and filtering should be created here 
Hive,WITHOUT_CLASSIFICATION,//  Copy info that may be required in the new copy.   The SettableUDF calls below could be replaced using this mechanism as well. 
Hive,WITHOUT_CLASSIFICATION,//  on the task generated in the first pass. 
Hive,WITHOUT_CLASSIFICATION,//  This is only required to support the deprecated methods in HCatAddPartitionDesc.Builder. 
Hive,WITHOUT_CLASSIFICATION,//  m = 2^p 
Hive,WITHOUT_CLASSIFICATION,//     hiveConf.setBoolVar(HiveConf.ConfVars.HIVE_IN_TEST hiveInTest);   turn on db notification listener on meta store 
Hive,WITHOUT_CLASSIFICATION,//  Remove entries from completed_txn_components as well so we don't start looking there   again but only up to the highest write ID include in this compaction job.  highestWriteId will be NULL in upgrade scenarios 
Hive,WITHOUT_CLASSIFICATION,//  TODO: add interval and complex types 
Hive,WITHOUT_CLASSIFICATION,//  A join is eligible for a sort-merge join only if it is eligible for   a bucketized map join. So we dont need to check for bucketized map   join here. We are guaranteed that the join keys contain all the 
Hive,WITHOUT_CLASSIFICATION,//  still null 
Hive,WITHOUT_CLASSIFICATION,//  type with padded spaces. 
Hive,WITHOUT_CLASSIFICATION,//  or from expressions. 
Hive,WITHOUT_CLASSIFICATION,//  the columns correspond. 
Hive,WITHOUT_CLASSIFICATION,//  In case the query is served by HiveServer2 don't pad it with spaces 
Hive,WITHOUT_CLASSIFICATION,//  Set the security key provider so that the MiniDFS cluster is initialized   with encryption 
Hive,WITHOUT_CLASSIFICATION,//  This ends up being set to "test" | mvn ${testCasePropertyName} for instance 
Hive,WITHOUT_CLASSIFICATION,//  So let's not use them anywhere unless absolutely necessary. 
Hive,WITHOUT_CLASSIFICATION,//  Parser has done some verification so the order of tokens doesn't need to be verified here. 
Hive,WITHOUT_CLASSIFICATION,//  Find the new delta file and make sure it has the right contents 
Hive,WITHOUT_CLASSIFICATION,//  Overflow.  Use slower alternate. 
Hive,WITHOUT_CLASSIFICATION,//  consistent with other APIs like makeExpressionTree null is returned to indicate that   the filter could not pushed down due to parsing issue etc 
Hive,WITHOUT_CLASSIFICATION,//  EXPR 
Hive,WITHOUT_CLASSIFICATION,//  test both repeating 
Hive,WITHOUT_CLASSIFICATION,//  NonZeroExitCodeExceptions can have long messages and should be   trimmable when published to the JIRA via the JiraService 
Hive,WITHOUT_CLASSIFICATION,//  Append is not supported in the cluster try to use create 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) ConstListContents  */
Hive,WITHOUT_CLASSIFICATION,//  Use our specialized hash table loader. 
Hive,WITHOUT_CLASSIFICATION,//  update config in Hive thread local as well and init the metastore client 
Hive,WITHOUT_CLASSIFICATION,//  For last stripe we need to get the last trasactionId/bucket/rowId from the last row. 
Hive,WITHOUT_CLASSIFICATION,//  Go through the set of partition columns and find their representatives in the values 
Hive,WITHOUT_CLASSIFICATION,//  Table is partitioned by single key 
Hive,WITHOUT_CLASSIFICATION,//  double column/scalar IF 
Hive,WITHOUT_CLASSIFICATION,//  Expected row count of the join query we'll run 
Hive,WITHOUT_CLASSIFICATION,//  Finish the current 'IN'/'NOT IN' clause and start a new clause.   replace the "commar". 
Hive,WITHOUT_CLASSIFICATION,//  SHA matches... 
Hive,WITHOUT_CLASSIFICATION,//  First PK 
Hive,WITHOUT_CLASSIFICATION,//  Try with an extra delta. 
Hive,WITHOUT_CLASSIFICATION,//  of histogram bins to use in the percentile approximation. 
Hive,WITHOUT_CLASSIFICATION,//  Re-order the wait queue. Note: we assume that noone will take our capacity based   on the fact that we are doing this under the epic lock. If the epic lock is removed   we'd need to do the steps under the queue lock; we could pass in a f() to update state. 
Hive,WITHOUT_CLASSIFICATION,//  Try to load the composite factory if one was provided 
Hive,WITHOUT_CLASSIFICATION,//  check for the operators who will process rows coming to this Map Operator 
Hive,WITHOUT_CLASSIFICATION,//  Call the real methods for these 
Hive,WITHOUT_CLASSIFICATION,//  This can happen e.g. for a data stream when all the values are null. 
Hive,WITHOUT_CLASSIFICATION,//  No complex type support for now. 
Hive,WITHOUT_CLASSIFICATION,//  PersistentEphemeralNode will make sure the ephemeral node created on server will be present   even under connection or session interruption (will automatically handle retries) 
Hive,WITHOUT_CLASSIFICATION,//  This must be called after all the explicit register calls. 
Hive,WITHOUT_CLASSIFICATION,//  Try again with a value that won't fit in 5 digits to make 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.CLIServiceClient#openSession(java.lang.String java.lang.String java.util.Map)    */
Hive,WITHOUT_CLASSIFICATION,/*    * 1. Find out if the operator is invoked at Map-Side or Reduce-side   * 2. Get the deserialized QueryDef   * 3. Reconstruct the transient variables in QueryDef   * 4. Create input partition to store rows coming from previous operator    */
Hive,WITHOUT_CLASSIFICATION,//  verify both am get node heartbeat 
Hive,WITHOUT_CLASSIFICATION,//  Test HCatContext 
Hive,WITHOUT_CLASSIFICATION,//  Verify individual arguments 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise throw FileAlreadyExistsException which means the file owner is   dead 
Hive,WITHOUT_CLASSIFICATION,//  Read the items from the input stream and confirm they match 
Hive,WITHOUT_CLASSIFICATION,//  If bucket map join only a split goes in memory 
Hive,WITHOUT_CLASSIFICATION,//  Semijoin DPP work is considered a child because work needs 
Hive,WITHOUT_CLASSIFICATION,//  2) The dimension columns 
Hive,WITHOUT_CLASSIFICATION,//  Push each aggregate function down to each side that contains all of its   arguments. Note that COUNT(*) because it has no arguments can go to 
Hive,WITHOUT_CLASSIFICATION,// we do this for Update/Delete (incl Merge) because we introduce this column into the query  as part of rewrite 
Hive,WITHOUT_CLASSIFICATION,//  A few situations where we need the default table path without a DB object 
Hive,WITHOUT_CLASSIFICATION,// Repeating non null 
Hive,WITHOUT_CLASSIFICATION,//  end of else - i.e. could not allocate 
Hive,WITHOUT_CLASSIFICATION,//  if the clause contains any expression. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure we actually go the table name 
Hive,WITHOUT_CLASSIFICATION,//  This method will only return full resource plan when activating one   to give the caller the result atomically with the activation. 
Hive,WITHOUT_CLASSIFICATION,//  Wait for the server to bootup 
Hive,WITHOUT_CLASSIFICATION,//  Create a Hadoop configuration without inheriting default settings. 
Hive,WITHOUT_CLASSIFICATION,//        we need to set the global to null to do that this "reuse" may be pointless. 
Hive,WITHOUT_CLASSIFICATION,// noinspection ConstantConditions 
Hive,WITHOUT_CLASSIFICATION,//  We do this because if function returns null   the mapping for key is removed i.e. the table is mutated. 
Hive,WITHOUT_CLASSIFICATION,//  Note : This implements HttpRequestInterceptor rather than extending   HttpRequestInterceptorBase because that class is an auth-specific   class and refactoring would kludge too many things that are potentially   public api.     At the base though what we do is a very simple thing to protect   against CSRF attacks and that is to simply add another header. If   HS2 is running with an XSRF filter enabled then it will reject all   requests that do not contain this. Thus we add this in here on the   client-side. This simple check prevents random other websites from   redirecting a browser that has login credentials from making a   request to HS2 on their behalf. 
Hive,WITHOUT_CLASSIFICATION,//  Scopes of execution (code blocks) with own local variables parameters and exception handlers 
Hive,WITHOUT_CLASSIFICATION,//  BIT_VECTOR_SIZE is 31 we can use 32 bits i.e. 4 bytes to represent a 
Hive,WITHOUT_CLASSIFICATION,//  SEL(no-compute)-SEL. never seen this condition   and also removing parent is not safe in current graph walker 
Hive,WITHOUT_CLASSIFICATION,//  we can't handle distinct 
Hive,WITHOUT_CLASSIFICATION,// otherwise it is the case of analyze table T compute statistics for columns; 
Hive,WITHOUT_CLASSIFICATION,//  Create a TableScan operator 
Hive,WITHOUT_CLASSIFICATION,//  MSB 64 - p bits 
Hive,WITHOUT_CLASSIFICATION,//  serialize path offset length using FileSplit 
Hive,WITHOUT_CLASSIFICATION,//  connect using token via Beeline using script 
Hive,WITHOUT_CLASSIFICATION,//  Determine the keys for the current clause. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#getMoreResults()    */
Hive,WITHOUT_CLASSIFICATION,//  ENABLE_CSTR 
Hive,WITHOUT_CLASSIFICATION,//  getWritableObject() will convert LazyPrimitive to actual primitive   writable objects. 
Hive,WITHOUT_CLASSIFICATION,//  Pack the output into the scratch longs. 
Hive,WITHOUT_CLASSIFICATION,//  Run Cleaner. 
Hive,WITHOUT_CLASSIFICATION,//  The dispatcher fires the processor corresponding to the closest matching rule and passes 
Hive,WITHOUT_CLASSIFICATION,//  Need reset during re-open when needed 
Hive,WITHOUT_CLASSIFICATION,//  We might generate other types that are not recognized e.g. a field reference   if it is a nested field but since this is just an additional optimization   we bail out without introducing the Select + GroupBy below the right input   of the left semijoin 
Hive,WITHOUT_CLASSIFICATION,//  Make sure nanos are preserved 
Hive,WITHOUT_CLASSIFICATION,//  off so we don't sit and hammer the metastore in a tight loop 
Hive,WITHOUT_CLASSIFICATION,//  Finish the scheduled compaction for ttp2 and manually compact ttp1 to make them comparable again 
Hive,WITHOUT_CLASSIFICATION,//  If the current subExpression is pre-calculated as in Group-By etc. 
Hive,WITHOUT_CLASSIFICATION,//  parsing statement is now done on to logic. 
Hive,WITHOUT_CLASSIFICATION,// until change is made to use the admin option. Default to false with V2 authorization 
Hive,WITHOUT_CLASSIFICATION,//  Corresponds to SemAnalyzer genGroupByPlan1MR   Corresponds to SemAnalyzer genGroupByPlan2MR   Corresponds to SemAnalyzer 
Hive,WITHOUT_CLASSIFICATION,//  If table doesn't exist allow creating a new one only if the database state is older than the update. 
Hive,WITHOUT_CLASSIFICATION,//  New batch has been fetched. If it's not empty we have more elements to process. 
Hive,WITHOUT_CLASSIFICATION,//  Maximum number of paritions aggregated per cache node 
Hive,WITHOUT_CLASSIFICATION,//  Bottom operator does not contain offset/fetch 
Hive,WITHOUT_CLASSIFICATION,//  Heartbeat only for active tasks. Errors etc will be reported directly. 
Hive,WITHOUT_CLASSIFICATION,//  Tests for dropPartition(String db_name String tbl_name List<String> part_vals   PartitionDropOptions options) method 
Hive,WITHOUT_CLASSIFICATION,//  And a mutable read position for thread safety when sharing a hash map. 
Hive,WITHOUT_CLASSIFICATION,// result could be cached if this object were to be made immutable...  
Hive,WITHOUT_CLASSIFICATION,//  the "has decimal or second VInt" flag is not set 
Hive,WITHOUT_CLASSIFICATION,//  append the stripe buffer to the new ORC file 
Hive,WITHOUT_CLASSIFICATION,//  for singular arg count should not include null   e.g. count(case when i=1 and department_id is not null then 1 else null end) as c0  
Hive,WITHOUT_CLASSIFICATION,//  Put the mapping from part to pruner_pred 
Hive,WITHOUT_CLASSIFICATION,//  HashMap 
Hive,WITHOUT_CLASSIFICATION,//  If parent table is in the same database change it to the actual db on destination   Otherwise keep db name 
Hive,WITHOUT_CLASSIFICATION,/*      * used for buffering appends before flush them out      */
Hive,WITHOUT_CLASSIFICATION,//  IS_IN_UNMANAGED 
Hive,WITHOUT_CLASSIFICATION,//  The index of the child which the last row was forwarded to in a key group. 
Hive,WITHOUT_CLASSIFICATION,//  This means the reader has already been closed. 
Hive,WITHOUT_CLASSIFICATION,//  0.5 added for rounding off 
Hive,WITHOUT_CLASSIFICATION,//  Ceil on an integer argument is a noop but it is less code to handle it this way. 
Hive,WITHOUT_CLASSIFICATION,//  boolean + double + AtomicLong 
Hive,WITHOUT_CLASSIFICATION,//  6.3 Get rid of TOK_SELEXPR 
Hive,WITHOUT_CLASSIFICATION,/*      * Use a different batch for vectorized Input File Format readers so they can do their work     * overlapped with work of the row collection that vector/row deserialization does.  This allows     * the partitions to mix modes (e.g. for us to flush the previously batched rows on file change).      */
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:LlapDaemonProtocol) 
Hive,WITHOUT_CLASSIFICATION,//  This call is accessed from server side 
Hive,WITHOUT_CLASSIFICATION,//  set these streams only if the stripe is different 
Hive,WITHOUT_CLASSIFICATION,//  there is no CTE walk the whole AST 
Hive,WITHOUT_CLASSIFICATION,//  this optimizer is for replacing FS to temp+fetching from temp with   single direct fetching which means FS is not needed any more when conversion completed. 
Hive,WITHOUT_CLASSIFICATION,//  Selectivity: key cardinality of semijoin / domain cardinality 
Hive,WITHOUT_CLASSIFICATION,//  locations if orig-loc becomes important 
Hive,WITHOUT_CLASSIFICATION,//  1) Cancel the previous expansion if any. 
Hive,WITHOUT_CLASSIFICATION,//  Don't read enough data for the first message to be decoded. 
Hive,WITHOUT_CLASSIFICATION,// test params 
Hive,WITHOUT_CLASSIFICATION,/*    * for functions that don't support a Window this provides the rows remaining to be    * added to output. Functions that return a Window can throw a UnsupportedException   * this method shouldn't be called. For Ranking fns return 0; lead/lag fns return the   * lead/lag amt.    */
Hive,WITHOUT_CLASSIFICATION,//  Retrieve creation metadata if needed 
Hive,WITHOUT_CLASSIFICATION,//  there can be only one instance per path 
Hive,WITHOUT_CLASSIFICATION,//  5. Build Rel for Select Clause 
Hive,WITHOUT_CLASSIFICATION,/* if doAs user is different than logged in user need to check that      that logged in user is authorized to run as 'doAs' */
Hive,WITHOUT_CLASSIFICATION,//  3rd task requested unknown host got host2 since host1 is full and only host2 is left in random pool 
Hive,WITHOUT_CLASSIFICATION,//  Replacing an inactive plan. 
Hive,WITHOUT_CLASSIFICATION,//  Update cacheUsage to reference the pending entry. 
Hive,WITHOUT_CLASSIFICATION,//  remember it for additional processing later 
Hive,WITHOUT_CLASSIFICATION,//  If we are not pulling constants OR   we are pulling constants but this is not a constant 
Hive,WITHOUT_CLASSIFICATION,//  Only change txnMgr if the setting has changed 
Hive,WITHOUT_CLASSIFICATION,//  Verify the fetched log (from the beginning of log file) 
Hive,WITHOUT_CLASSIFICATION,//  Since interval types not currently supported as table columns need to create them   as expressions. 
Hive,WITHOUT_CLASSIFICATION,//  Set the move task to be dependent on the current task 
Hive,WITHOUT_CLASSIFICATION,//  Try to read the given named url from the connection configuration file 
Hive,WITHOUT_CLASSIFICATION,//  if FieldCount == 2 get types for key & value 
Hive,WITHOUT_CLASSIFICATION,//  setup the completer for the database 
Hive,WITHOUT_CLASSIFICATION,//  Let's try to populate those stats that don't require full scan. 
Hive,WITHOUT_CLASSIFICATION,//  In the future we can add checking for username groupname etc based on   HiveAuthenticationProvider. For example   "hive_test_user".equals(context.getUserName()); 
Hive,WITHOUT_CLASSIFICATION,//  this tests the case where older data has an ambiguous structure but the   correct interpretation can be determined from the repeated name "array" 
Hive,WITHOUT_CLASSIFICATION,//  likely we found a table scan operator 
Hive,WITHOUT_CLASSIFICATION,//  MY_BYTE 
Hive,WITHOUT_CLASSIFICATION,//  exit the JVM if Ctrl+C is received   and no current statement is executing 
Hive,WITHOUT_CLASSIFICATION,//  11. Finally for all the pools that have changes promote queued queries and rebalance. 
Hive,WITHOUT_CLASSIFICATION,//  Interpret Ctrl+C as a request to cancel the currently   executing query. 
Hive,WITHOUT_CLASSIFICATION,//  following SEL will do CP for columns from UDTF not adding SEL in here 
Hive,WITHOUT_CLASSIFICATION,//  Sort by operator ID so we get deterministic results 
Hive,WITHOUT_CLASSIFICATION,//  Replace any \* that appear in the prefix with a regular * 
Hive,WITHOUT_CLASSIFICATION,/*    * Inverse of 2^63 = 2^-63.  Please see comments for doDecimalToBinaryDivisionRemainder.   *   * Multiply by 1/2^63 = 1.08420217248550443400745280086994171142578125e-19 to divide by 2^63.   * As 16 digit comma'd 108420217248550443400745280086994171142578125   *   * Scale down: 63 = 44 fraction digits + 19 (negative exponent or number of zeros after dot).   *   * 3*16 (48) + 15 --> 63 down shift.    */
Hive,WITHOUT_CLASSIFICATION,//  timestamp NOT BETWEEN 
Hive,WITHOUT_CLASSIFICATION,//  number of columns   a vector for each column   number of rows that qualify (i.e. haven't been filtered out)   array of positions of selected values 
Hive,WITHOUT_CLASSIFICATION,//  Test one random hi-precision decimal add. 
Hive,WITHOUT_CLASSIFICATION,//  First aggregation calculation for group. 
Hive,WITHOUT_CLASSIFICATION,//  write a base file in partition 0 
Hive,WITHOUT_CLASSIFICATION,//  offset to some "offset" in "middle" of the slice (but see TODO for firstStart). 
Hive,WITHOUT_CLASSIFICATION,//  Relocate all assigned slots from the old hash table. 
Hive,WITHOUT_CLASSIFICATION,/*      * Count the number of digits in the mantissa (including the decimal     * point) and also locate the decimal point.      */
Hive,WITHOUT_CLASSIFICATION,//  A delete/update generates a delete event for the original row. 
Hive,WITHOUT_CLASSIFICATION,//  Was using Hadoop-internal API to get tasklogs disable until  MAPREDUCE-5857 is fixed. 
Hive,WITHOUT_CLASSIFICATION,//    Rewrite logic:     The original left input will be joined with the new right input that   has generated correlated variables propagated up. For any generated   cor vars that are not used in the join key pass them along to be   joined later with the CorrelatorRels that produce them.   
Hive,WITHOUT_CLASSIFICATION,//  debugDumpKeyProbe(keyOffset keyLength hashCode slot); 
Hive,WITHOUT_CLASSIFICATION,// run it with each split strategy - make sure there are differences 
Hive,WITHOUT_CLASSIFICATION,//  By default many existing @Explain classes/methods are NON_VECTORIZED.     Vectorized methods/classes have detail levels:       SUMMARY OPERATOR EXPRESSION or DETAIL.   As you go to the right you get more detail and the information for the previous level(s) is   included.  The default is SUMMARY.     The "path" enumerations are used to mark methods/classes that lead to vectorization specific   ones so we can avoid displaying headers for things that have no vectorization information   below.     For example the TezWork class is marked SUMMARY_PATH because it leads to both   SUMMARY and OPERATOR methods/classes. And MapWork.getAllRootOperators is marked OPERATOR_PATH   because we only display operator information for OPERATOR.     EXPRESSION and DETAIL typically live inside SUMMARY or OPERATOR classes.   
Hive,WITHOUT_CLASSIFICATION,//  Hash bits in ref don't match. 
Hive,WITHOUT_CLASSIFICATION,/*  * Specialized class for doing a vectorized map join that is an inner join on a Single-Column String * using a hash map.  */
Hive,WITHOUT_CLASSIFICATION,// gets SS lock on T8 
Hive,WITHOUT_CLASSIFICATION,// No drop part listener events fired for public listeners historically for drop table case.  Limiting to internal listeners for now to avoid unexpected calls for public listeners. 
Hive,WITHOUT_CLASSIFICATION,//  Shuffle read metrics. 
Hive,WITHOUT_CLASSIFICATION,/*      * 2. setup resolve make connections      */
Hive,WITHOUT_CLASSIFICATION,//  JT timeout in msec. 
Hive,WITHOUT_CLASSIFICATION,//  There are 2 cases where we increment CREATED_DYNAMIC_PARTITIONS counters   1) Insert overwrite (all partitions are newly created)   2) Insert into table which creates new partitions (some new partitions) 
Hive,WITHOUT_CLASSIFICATION,/*      * ASCII 01-1F are HTTP control characters that need to be escaped.     * \u000A and \u000D are \n and \r respectively.      */
Hive,WITHOUT_CLASSIFICATION,// Thrift cannot return null result 
Hive,WITHOUT_CLASSIFICATION,//  Set the bucketing Version 
Hive,WITHOUT_CLASSIFICATION,//  the multiple parts to partition predicate are joined using and 
Hive,WITHOUT_CLASSIFICATION,//  Used by readNextField/skipNextField and not by readField. 
Hive,WITHOUT_CLASSIFICATION,//  Get "Script failed with code <some number>" 
Hive,WITHOUT_CLASSIFICATION,//  Restart asynchronously don't block the caller. 
Hive,WITHOUT_CLASSIFICATION,//  easier case. take a quick path 
Hive,WITHOUT_CLASSIFICATION,//  authorization checks passed. 
Hive,WITHOUT_CLASSIFICATION,//  Default is false 
Hive,WITHOUT_CLASSIFICATION,//  LRU. Could also implement LRU as a doubly linked list if CacheEntry keeps its node. 
Hive,WITHOUT_CLASSIFICATION,//  replacing getAliasToWork so should use that information instead. 
Hive,WITHOUT_CLASSIFICATION,//  Short.MAX_VALUE 
Hive,WITHOUT_CLASSIFICATION,// gets SS lock on T7 
Hive,WITHOUT_CLASSIFICATION,/*    * Returns true if the join conditions execute over the same keys    */
Hive,WITHOUT_CLASSIFICATION,//  Get configuration parameters 
Hive,WITHOUT_CLASSIFICATION,//  Next arena is being allocated. 
Hive,WITHOUT_CLASSIFICATION,//  Put the mapping from table scan operator to pruner_pred 
Hive,WITHOUT_CLASSIFICATION,//  Add path components explicitly because simply concatenating two path   string is not safe for example:   "/" + "/foo" yields "//foo" which will be parsed as authority in Path 
Hive,WITHOUT_CLASSIFICATION,//  The default ones are created in case of null; tests override this. 
Hive,WITHOUT_CLASSIFICATION,//  Do not make a remote call under any circumstances - this is supposed to be async. 
Hive,WITHOUT_CLASSIFICATION,//  we should now only have the unexpected folders left 
Hive,WITHOUT_CLASSIFICATION,//  Flush the metastore cache.  This assures that we don't pick up objects from a previous   query running in this same thread.  This has to be done after we get our semantic   analyzer (this is when the connection to the metastore is made) but before we analyze 
Hive,WITHOUT_CLASSIFICATION,//  Note this includes any outer join keys that need to go into the small table "area". 
Hive,WITHOUT_CLASSIFICATION,/*  first_name <=> 'owen'  */
Hive,WITHOUT_CLASSIFICATION,//  LONG_STATS 
Hive,WITHOUT_CLASSIFICATION,//  End PushFilterPastJoinRule.java 
Hive,WITHOUT_CLASSIFICATION,//  No need to set type name it should always be timestamplocaltz 
Hive,WITHOUT_CLASSIFICATION,// update the credential provider location in the jobConf 
Hive,WITHOUT_CLASSIFICATION,//  an external table 
Hive,WITHOUT_CLASSIFICATION,//  The SIMD optimized form of "a == b" is "(((a - b) ^ (b - a)) >>> 63) ^ 1" 
Hive,WITHOUT_CLASSIFICATION,//  keys 
Hive,WITHOUT_CLASSIFICATION,//  map join work 
Hive,WITHOUT_CLASSIFICATION,//  set it back so that column pruner in the optimizer will not do the 
Hive,WITHOUT_CLASSIFICATION,//  No support for statistics. That seems to be a popular answer. 
Hive,WITHOUT_CLASSIFICATION,//  Give up. 
Hive,WITHOUT_CLASSIFICATION,//  Verify that we have got correct set of deltas. 
Hive,WITHOUT_CLASSIFICATION,//  Test gt/lt/lte/gte for numbers. 
Hive,WITHOUT_CLASSIFICATION,//  verify that flattening and unflattenting no-nulls works 
Hive,WITHOUT_CLASSIFICATION,//  As current txn is aborted this won't read any data from other txns. So it is safe to unregister   the min_open_txnid from MIN_HISTORY_LEVEL for the aborted txns. Even if the txns in the list are   partially aborted it is safe to delete from MIN_HISTORY_LEVEL as the remaining txns are either 
Hive,WITHOUT_CLASSIFICATION,//  Reverse the value 
Hive,WITHOUT_CLASSIFICATION,//  AMNodeInfo will only be cleared when a queryComplete is received for this query or   when we detect a failure on the AM side (failure to heartbeat).   A single queueLookupCallable is added here. We have to make sure one instance stays   in the queue till the query completes. 
Hive,WITHOUT_CLASSIFICATION,//  offer accepted and r2 gets evicted 
Hive,WITHOUT_CLASSIFICATION,//  the root path is not useful anymore 
Hive,WITHOUT_CLASSIFICATION,//  TOK_SKEWED_LOCATION_MAP 
Hive,WITHOUT_CLASSIFICATION,//  the partitions that are not required 
Hive,WITHOUT_CLASSIFICATION,// / if COUNT returns true since COUNT produces 0 on empty result set 
Hive,WITHOUT_CLASSIFICATION,//  base env impl simply defers to System.getenv. 
Hive,WITHOUT_CLASSIFICATION,/*  all 32 bit numbers qualify & multiply up to get nano-seconds  */
Hive,WITHOUT_CLASSIFICATION,//  Carefully handle NULLs.. 
Hive,WITHOUT_CLASSIFICATION,//  populate map task 
Hive,WITHOUT_CLASSIFICATION,/*            * If the rhs references table sources and this QBJoinTree has a leftTree;           * hand it to the leftTree and let it recursively handle it.           * There are 3 cases of passing a condition down:           * 1. The leftSide && rightSide don't contains references to the leftTree's rightAlias           *    => pass the lists down as is.           * 2. The leftSide contains refs to the leftTree's rightAlias the rightSide doesn't           *    => switch the leftCondAl1 and leftConAl2 lists and pass down.           * 3. The rightSide contains refs to the leftTree's rightAlias the leftSide doesn't           *    => switch the rightCondAl1 and rightConAl2 lists and pass down.           * 4. In case both contain references to the leftTree's rightAlias           *   => we cannot push the condition down.           * 5. If either contain references to both left & right           *    => we cannot push forward.            */
Hive,WITHOUT_CLASSIFICATION,// 1234567 
Hive,WITHOUT_CLASSIFICATION,//  there are two cases - array<Type> and array<struct<...>>   in either case the element type of the array is represented in a   tuple field schema in the bag's field schema - the second case (struct)   more naturally translates to the tuple - in the first case (array<Type>)   we simulate the tuple by putting the single field in a tuple 
Hive,WITHOUT_CLASSIFICATION,//  Returning null from this fn can serve as an err condition. 
Hive,WITHOUT_CLASSIFICATION,//  crossing reduce sink or file sink means the pruning isn't for this parent. 
Hive,WITHOUT_CLASSIFICATION,//  aggregation for semijoin 
Hive,WITHOUT_CLASSIFICATION,//  Druid Returns 400 Bad Request when not found. 
Hive,WITHOUT_CLASSIFICATION,//  ////// Generate GroupbyOperator for a partial aggregation 
Hive,WITHOUT_CLASSIFICATION,//  merge only if the register length matches 
Hive,WITHOUT_CLASSIFICATION,//  not currently handled 
Hive,WITHOUT_CLASSIFICATION,/*  fall through - miss in locality or no locality-requested  */
Hive,WITHOUT_CLASSIFICATION,//  We assume AM might be bad so we will not try to kill the query here; just scrap the AM. 
Hive,WITHOUT_CLASSIFICATION,//  bloom-1 is known to have higher fpp to make tests pass give room for another 3% 
Hive,WITHOUT_CLASSIFICATION,//  Calculate tags individually since the schema can evolve and can have different tags. In worst case both schemas are same   and we would end up doing calculations twice to get the same tag   Determine index of value from fileSchema   Determine index of value from recordSchema 
Hive,WITHOUT_CLASSIFICATION,/*  13 < id or  */
Hive,WITHOUT_CLASSIFICATION,//  it's essentially a MapJoinDesc 
Hive,WITHOUT_CLASSIFICATION,//  return the url based on the aggregated connection properties 
Hive,WITHOUT_CLASSIFICATION,//  Fill down null flags.   UNDONE 
Hive,WITHOUT_CLASSIFICATION,//  2. Walk through leaf predicates building up JoinLeafPredicateInfo 
Hive,WITHOUT_CLASSIFICATION,//  ip address 
Hive,WITHOUT_CLASSIFICATION,// return "com.microsoft.sqlserver.jdbc.SQLServerDriver"; 
Hive,WITHOUT_CLASSIFICATION,/*  scaleDown  */
Hive,WITHOUT_CLASSIFICATION,//  ensure associated master key is available 
Hive,WITHOUT_CLASSIFICATION,//  UNDONE: UNKNOWN OPTION? 
Hive,WITHOUT_CLASSIFICATION,//  Release memory - simple deallocation. 
Hive,WITHOUT_CLASSIFICATION,//  that it can be read by the input format. 
Hive,WITHOUT_CLASSIFICATION,//  check privileges on input and output objects 
Hive,WITHOUT_CLASSIFICATION,//  The external client handling umbilical responses and the connection to read the incoming   data are not coupled. Calling close() here to make sure an error in one will cause the   other to be closed as well. 
Hive,WITHOUT_CLASSIFICATION,//  Sum all non-null long column values; maintain isGroupResultNull. 
Hive,WITHOUT_CLASSIFICATION,//  Data is expected to be a series of data chunks in the form <chunk size><chunk bytes><chunk size><chunk bytes>   The final data chunk should be a 0-length chunk which will indicate end of input. 
Hive,WITHOUT_CLASSIFICATION,//  From the jar file the parent is /lib folder 
Hive,WITHOUT_CLASSIFICATION,//  Verify if the data are intact even after applying an applied event once again on missing objects 
Hive,WITHOUT_CLASSIFICATION,/* select all locks for this ext ID and see which ones are missing */
Hive,WITHOUT_CLASSIFICATION,//  We don't write rowSeparatorByte because that should be handled by file   format. 
Hive,WITHOUT_CLASSIFICATION,//  Set up cache directory 
Hive,WITHOUT_CLASSIFICATION,//  There are no inputs so rel does not need to be changed. 
Hive,WITHOUT_CLASSIFICATION,//  Fail - No "transactional" property is specified 
Hive,WITHOUT_CLASSIFICATION,//  There are different cases for Group By depending on map/reduce side hash aggregation   grouping sets and column stats. If we don't have column stats we just assume hash   aggregation is disabled. Following are the possible cases and rule for cardinality   estimation 
Hive,WITHOUT_CLASSIFICATION,//  [A: 0 B: 1] 
Hive,WITHOUT_CLASSIFICATION,//  If doAs is set to true for HiveServer2 we will create a proxy object for the session impl. 
Hive,WITHOUT_CLASSIFICATION,//  Stop Kafka Ingestion first 
Hive,WITHOUT_CLASSIFICATION,/* real grant time added by metastore */
Hive,WITHOUT_CLASSIFICATION,/*        * mix -- mix 3 32-bit values reversibly.       * This is reversible so any information in (abc) before mix() is       * still in (abc) after mix().       *       * If four pairs of (abc) inputs are run through mix() or through       * mix() in reverse there are at least 32 bits of the output that       * are sometimes the same for one pair and different for another pair.       *       * This was tested for:       * - pairs that differed by one bit by two bits in any combination       *   of top bits of (abc) or in any combination of bottom bits of       *   (abc).       * - "differ" is defined as + - ^ or ~^.  For + and - I transformed       *   the output delta to a Gray code (a^(a>>1)) so a string of 1's (as       *    is commonly produced by subtraction) look like a single 1-bit       *    difference.       * - the base values were pseudorandom all zero but one bit set or       *   all zero plus a counter that starts at zero.       *       * Some k values for my "a-=c; a^=rot(ck); c+=b;" arrangement that       * satisfy this are       *     4  6  8 16 19  4       *     9 15  3 18 27 15       *    14  9  3  7 17  3       * Well "9 15 3 18 27 15" didn't quite get 32 bits diffing for       * "differ" defined as + with a one-bit base and a two-bit delta.  I       * used http://burtleburtle.net/bob/hash/avalanche.html to choose       * the operations constants and arrangements of the variables.       *       * This does not achieve avalanche.  There are input bits of (abc)       * that fail to affect some output bits of (abc) especially of a.       * The most thoroughly mixed value is c but it doesn't really even       * achieve avalanche in c.       *       * This allows some parallelism.  Read-after-writes are good at doubling       * the number of bits affected so the goal of mixing pulls in the       * opposite direction as the goal of parallelism.  I did what I could.       * Rotates seem to cost as much as shifts on every machine I could lay       * my hands on and rotates are much kinder to the top and bottom bits       * so I used rotates.       *       * #define mix(abc) \       * { \       *   a -= c;  a ^= rot(c 4);  c += b; \       *   b -= a;  b ^= rot(a 6);  a += c; \       *   c -= b;  c ^= rot(b 8);  b += a; \       *   a -= c;  a ^= rot(c16);  c += b; \       *   b -= a;  b ^= rot(a19);  a += c; \       *   c -= b;  c ^= rot(b 4);  b += a; \       * }       *       * mix(abc);        */
Hive,WITHOUT_CLASSIFICATION,//  we have found a reduce sink 
Hive,WITHOUT_CLASSIFICATION,// replace trailing '' 
Hive,WITHOUT_CLASSIFICATION,//  Parse integer portion. 
Hive,WITHOUT_CLASSIFICATION,// actually only at most one loop 
Hive,WITHOUT_CLASSIFICATION,//  previous call to projectNonColumnEquiConditions updated it 
Hive,WITHOUT_CLASSIFICATION,//  Multiply by self. 
Hive,WITHOUT_CLASSIFICATION,//  All key input columns are repeating.  Generate key once.  Lookup once.   Since the key is repeated we must use entry 0 regardless of selectedInUse. 
Hive,WITHOUT_CLASSIFICATION,// plan   Make sure we need locks.  It's possible there's nothing to lock in 
Hive,WITHOUT_CLASSIFICATION,//  test if the group by needs partition level sort if so use the MR style shuffle   SHUFFLE_SORT shouldn't be used for this purpose see HIVE-8542 
Hive,WITHOUT_CLASSIFICATION,//  Nothing else is updated after the first update. 
Hive,WITHOUT_CLASSIFICATION,//  in filter expression since it will be taken care by partition pruner 
Hive,WITHOUT_CLASSIFICATION,/*      * Currently we are not handling dynamic sized windows implied by range     * based windows.      */
Hive,WITHOUT_CLASSIFICATION,//  create a union above all the branches 
Hive,WITHOUT_CLASSIFICATION,//  -ve dates are also valid Timestamps - dates are within 1959 to 2027 
Hive,WITHOUT_CLASSIFICATION,//  should be called after session registry is checked 
Hive,WITHOUT_CLASSIFICATION,//  test null values 
Hive,WITHOUT_CLASSIFICATION,//  Try to deserialize using DeserializeRead our Writable row objects created by SerDe. 
Hive,WITHOUT_CLASSIFICATION,//  for canceling the query (should be bound to session?) 
Hive,WITHOUT_CLASSIFICATION,//  could get either query hint or select expr 
Hive,WITHOUT_CLASSIFICATION,//  get old table 
Hive,WITHOUT_CLASSIFICATION,/*  If every row qualified (newSize==n) then we can ignore the sel vector to streamline         * future operations. So selectedInUse will remain false.          */
Hive,WITHOUT_CLASSIFICATION,//  initialized which may cause it to drop events. 
Hive,WITHOUT_CLASSIFICATION,//  Check whether it is a monotonic preserving cast otherwise we cannot push 
Hive,WITHOUT_CLASSIFICATION,//  sub fields 
Hive,WITHOUT_CLASSIFICATION,//  load hiveserver2-site.xml if this is hiveserver2 and file exists   metastore can be embedded within hiveserver2 in such cases   the conf params in hiveserver2-site.xml will override whats defined 
Hive,WITHOUT_CLASSIFICATION,//  Call set_ugi only in unsecure mode. 
Hive,WITHOUT_CLASSIFICATION,//  if the aggregation type is min/max we extrapolate from the   left/right borders 
Hive,WITHOUT_CLASSIFICATION,//  Output columns ok? 
Hive,WITHOUT_CLASSIFICATION,//  make a list before opening the RPC attack surface 
Hive,WITHOUT_CLASSIFICATION,//  first adjust count() expression if any 
Hive,WITHOUT_CLASSIFICATION,//  Most of the stuff we can handle are generic function descriptions so   handle the special cases. 
Hive,WITHOUT_CLASSIFICATION,/*    * Context for reading a Vectorized Input File Format.    */
Hive,WITHOUT_CLASSIFICATION,//  exponent part 
Hive,WITHOUT_CLASSIFICATION,//  Must be deterministic order map for consistent q-test output across Java versions - see HIVE-9161 
Hive,WITHOUT_CLASSIFICATION,//  3. If we could not transform anything we bail out 
Hive,WITHOUT_CLASSIFICATION,//  names[0] have the Db name and names[1] have the view name 
Hive,WITHOUT_CLASSIFICATION,//  Do this check in case the ciphertext actually makes sense in some way. 
Hive,WITHOUT_CLASSIFICATION,//  1st Txn 
Hive,WITHOUT_CLASSIFICATION,//  For TOK_FUNCTION the function name is stored in the first child   unless it's in our   special dictionary. 
Hive,WITHOUT_CLASSIFICATION,//  Arithmetic with a type timestamp (TimestampColumnVector) and type interval_year_month (LongColumnVector storing 
Hive,WITHOUT_CLASSIFICATION,//  compute keys and values as StandardObjects 
Hive,WITHOUT_CLASSIFICATION,//  If the table was already marked as 'transactional=true' then the new value of   'transactional_properties' must match the old value. Any attempt to alter the previous   value will throw an error. An exception will still be thrown if the previous value was   null and an attempt is made to set it. This behaviour can be changed in the future. 
Hive,WITHOUT_CLASSIFICATION,//  If the reduce sink has not been introduced due to bucketing/sorting ignore it 
Hive,WITHOUT_CLASSIFICATION,//  Once NodeId includes fragmentId - this becomes a lot more reliable. 
Hive,WITHOUT_CLASSIFICATION,//  need to fill in information about the key and value in the reducer 
Hive,WITHOUT_CLASSIFICATION,//  Accumulo token information. 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:TerminateFragmentResponseProto) 
Hive,WITHOUT_CLASSIFICATION,//  Create vectorized expr 
Hive,WITHOUT_CLASSIFICATION,//  compute the total size per bucket 
Hive,WITHOUT_CLASSIFICATION,//  If changing this file make sure to make corresponding changes in llap-daemon-log4j2.properties 
Hive,WITHOUT_CLASSIFICATION,//  Repeating non null 
Hive,WITHOUT_CLASSIFICATION,//  If this is a constant boolean expression return the value. 
Hive,WITHOUT_CLASSIFICATION,//  this offer will be rejected 
Hive,WITHOUT_CLASSIFICATION,//  Create a reduceSink operator followed by another limit 
Hive,WITHOUT_CLASSIFICATION,//  Make a special case for "\\_" and "\\%" 
Hive,WITHOUT_CLASSIFICATION,//  Create a new map join operator 
Hive,WITHOUT_CLASSIFICATION,//  End ASTNodeOrigin.java 
Hive,WITHOUT_CLASSIFICATION,//  We only check one file so exit the loop when we have at least   one. 
Hive,WITHOUT_CLASSIFICATION,//  RUNNING state 
Hive,WITHOUT_CLASSIFICATION,//  Lookup of cache entries by table used in the query for cache invalidation. 
Hive,WITHOUT_CLASSIFICATION,//  create a test table with auto.purge = true 
Hive,WITHOUT_CLASSIFICATION,//  Print a message if we reached at least 1000 rows for a join operand   We won't print a message for the last join operand since the size   will never goes to joinEmitInterval. 
Hive,WITHOUT_CLASSIFICATION,//  https://issues.apache.org/jira/browse/HIVE-17627 
Hive,WITHOUT_CLASSIFICATION,//  EUROPE_UK 
Hive,WITHOUT_CLASSIFICATION,//  show partition information 
Hive,WITHOUT_CLASSIFICATION,//  No group value. 
Hive,WITHOUT_CLASSIFICATION,//  nothing further to test. 
Hive,WITHOUT_CLASSIFICATION,//  Initialize the results 
Hive,WITHOUT_CLASSIFICATION,//  Build the expression based on the partition predicate 
Hive,WITHOUT_CLASSIFICATION,//  Also try other patterns 
Hive,WITHOUT_CLASSIFICATION,/*  Create list bucketing sub-directory only if stored-as-directories is on.  */
Hive,WITHOUT_CLASSIFICATION,//  Fill the column vector with nulls 
Hive,WITHOUT_CLASSIFICATION,//  x events to insert last repl ID: replDumpId+x 
Hive,WITHOUT_CLASSIFICATION,// check that we start with default db 
Hive,WITHOUT_CLASSIFICATION,//  On failure the SASL handler will throw an exception indicating that the SASL   negotiation failed. 
Hive,WITHOUT_CLASSIFICATION,//  The fact that stdev doesn't increase with increasing missCount is captured outside. 
Hive,WITHOUT_CLASSIFICATION,//  we allow null values for map. 
Hive,WITHOUT_CLASSIFICATION,//  If StatOptimization is not applied for any reason the FetchTask should still not have been set 
Hive,WITHOUT_CLASSIFICATION,//  this is the option which will make it a delete writer 
Hive,WITHOUT_CLASSIFICATION,//  we need to do new hashmap since stats object is reused across calls. 
Hive,WITHOUT_CLASSIFICATION,//  Iterate backwards from the destination table to the top of the tree   Based on the output column names get the new columns. 
Hive,WITHOUT_CLASSIFICATION,//  MAX_DECIMAL 9's WITH ROUND. 
Hive,WITHOUT_CLASSIFICATION,//  Add data files to the partitioned table 
Hive,WITHOUT_CLASSIFICATION,// sqlLine.getOpts().setEntireLineAsCommand(true); 
Hive,WITHOUT_CLASSIFICATION,//  Iterate through the list 
Hive,WITHOUT_CLASSIFICATION,//  of newProject plus any aggregates that the oldAgg produces. 
Hive,WITHOUT_CLASSIFICATION,//  assumes deserializer is not buffering itself   position over uncompressed stream. not sure what   effect this has on stats about job 
Hive,WITHOUT_CLASSIFICATION,// check elements of the innermost union 
Hive,WITHOUT_CLASSIFICATION,//  when ';' is not yet seen   number of lines to fetch in batch from remote hive server 
Hive,WITHOUT_CLASSIFICATION,//  child process. so we add it here explicitly 
Hive,WITHOUT_CLASSIFICATION,//  create the project before GB because we need a new project with extra column '1'. 
Hive,WITHOUT_CLASSIFICATION,//  it's hadoop-1 
Hive,WITHOUT_CLASSIFICATION,//  Columns statistics for complex datatypes are not supported yet 
Hive,WITHOUT_CLASSIFICATION,//  TRIGGER_EXPRESSION 
Hive,WITHOUT_CLASSIFICATION,//  Store ugi in transport if the rpc is set_ugi 
Hive,WITHOUT_CLASSIFICATION,/*  first_name = last_name  */
Hive,WITHOUT_CLASSIFICATION,//  This yields empty because starting idx is out of bounds. 
Hive,WITHOUT_CLASSIFICATION,//  For debug tracing: the name of the map or reduce task. 
Hive,WITHOUT_CLASSIFICATION,//  Need to differentiate between an unmatched pattern and a non-existent database 
Hive,WITHOUT_CLASSIFICATION,// downstream code expects it to be set to a valid value 
Hive,WITHOUT_CLASSIFICATION,//  materialized 
Hive,WITHOUT_CLASSIFICATION,//  If cpartcols or ppartcols have constant node expressions avoid the merge. 
Hive,WITHOUT_CLASSIFICATION,//  once called first it will never be able to   write again. 
Hive,WITHOUT_CLASSIFICATION,//  Base case:  we are eager if a child is stateful 
Hive,WITHOUT_CLASSIFICATION,//  Match the given bytes with the like pattern 
Hive,WITHOUT_CLASSIFICATION,//  For some reason even with an MBeanException available to them   Runtime exceptions can still find their way through so treat them   the same as MBeanException 
Hive,WITHOUT_CLASSIFICATION,//  Settable 
Hive,WITHOUT_CLASSIFICATION,//  Instead of retrying with this task we will try to pick a different suitable task. 
Hive,WITHOUT_CLASSIFICATION,//  shared_write 
Hive,WITHOUT_CLASSIFICATION,//  Hive 0.12 behavior where double / decimal -> decimal is gone. 
Hive,WITHOUT_CLASSIFICATION,//  Check that the union has come out unscathed. No scathing of unions allowed. 
Hive,WITHOUT_CLASSIFICATION,//  TODO: Should be checked on server side. On Embedded metastore it throws MetaException   on Remote metastore it throws TProtocolException 
Hive,WITHOUT_CLASSIFICATION,//  map that says which mapjoin belongs to which work item 
Hive,WITHOUT_CLASSIFICATION,//  so we can later run the same logic that is run in ReduceSinkMapJoinProc. 
Hive,WITHOUT_CLASSIFICATION,//  Same union order reveresed 
Hive,WITHOUT_CLASSIFICATION,//  SW.E: Lock we are examining is exclusive 
Hive,WITHOUT_CLASSIFICATION,//  check the character numbers with the length 
Hive,WITHOUT_CLASSIFICATION,//  user wants file store based configuration 
Hive,WITHOUT_CLASSIFICATION,//  partition columns will always at the last 
Hive,WITHOUT_CLASSIFICATION,//  Drop partition will clean the partition entry from the compaction queue and hence cleaner have no effect 
Hive,WITHOUT_CLASSIFICATION,//  sequence file write 
Hive,WITHOUT_CLASSIFICATION,//  List of input expressions. If a particular aggregate needs more it   will add an expression to the end and we will create an extra 
Hive,WITHOUT_CLASSIFICATION,//  Pre-compute group-by keys and store in reduceKeys 
Hive,WITHOUT_CLASSIFICATION,//  Throw an error if the user asked for sort merge bucketed mapjoin to be enforced   and sort merge bucketed mapjoin cannot be performed 
Hive,WITHOUT_CLASSIFICATION,//  type mismatch when string col is filtered by a string that looks like date. 
Hive,WITHOUT_CLASSIFICATION,//  SHOW LOCKS (no filter) 
Hive,WITHOUT_CLASSIFICATION,//    } 
Hive,WITHOUT_CLASSIFICATION,// Attempt extended Acl operations only if its enabled but don't fail the operation regardless. 
Hive,WITHOUT_CLASSIFICATION,//  Additional argument is needed which is the outputcolumn. 
Hive,WITHOUT_CLASSIFICATION,//  in this delta directory can be considered as a base. 
Hive,WITHOUT_CLASSIFICATION,/*  setByValue  */
Hive,WITHOUT_CLASSIFICATION,//  Figure out which stripes we need to read. 
Hive,WITHOUT_CLASSIFICATION,//  skip padded values 
Hive,WITHOUT_CLASSIFICATION,//  Add a projection column to a projection vectorization context. 
Hive,WITHOUT_CLASSIFICATION,//  ArgumentCompletor always adds a space after a matched token.   This is undesirable for function names because a space after   the opening parenthesis is unnecessary (and uncommon) in Hive.   We stack a custom Completor on top of our ArgumentCompletor 
Hive,WITHOUT_CLASSIFICATION,//  if column type is char and constant type is string then convert the constant to char 
Hive,WITHOUT_CLASSIFICATION,//  get result vector 
Hive,WITHOUT_CLASSIFICATION,//  operator (top) 
Hive,WITHOUT_CLASSIFICATION,// implicitConvertable = FunctionRegistry.implicitConvertable(ti1 ti2); 
Hive,WITHOUT_CLASSIFICATION,// verify all scopes were recorded 
Hive,WITHOUT_CLASSIFICATION,//  Already existing table 
Hive,WITHOUT_CLASSIFICATION,//  fetch by name and type 
Hive,WITHOUT_CLASSIFICATION,//  TODO: we could generate vector row batches so that vectorized execution may get triggered 
Hive,WITHOUT_CLASSIFICATION,//  iterate for the second time to get all the dependency. 
Hive,WITHOUT_CLASSIFICATION,//  we are guaranteed that we can get data here (since 'size' is not zero) 
Hive,WITHOUT_CLASSIFICATION,//  -------------------------------- Post Pass ---------------------------------- // 
Hive,WITHOUT_CLASSIFICATION,//  Date high/low value is stored as long in stats DB but allow users to set high/low   value using either date format (yyyy-mm-dd) or numeric format (days since epoch) 
Hive,WITHOUT_CLASSIFICATION,//  LOCKID 
Hive,WITHOUT_CLASSIFICATION,//  to the HCatalog. 
Hive,WITHOUT_CLASSIFICATION,//  Transformation: sq_count_check(count(*) true) FILTER is generated on top    of subquery which is then joined (LEFT or INNER) with outer query    This transformation is done to add run time check using sq_count_check to    throw an error if subquery is producing zero row since with aggregate this    will produce wrong results (because we further rewrite such queries into JOIN) 
Hive,WITHOUT_CLASSIFICATION,//  The first child should be the table we are deleting from 
Hive,WITHOUT_CLASSIFICATION,//  The session is active but not found in the pool - internal error. 
Hive,WITHOUT_CLASSIFICATION,//  CALCITE-1690 
Hive,WITHOUT_CLASSIFICATION,//  complete path futures and schedule split generation 
Hive,WITHOUT_CLASSIFICATION,//  If we want to handle counters 
Hive,WITHOUT_CLASSIFICATION,//  could be mux/demux operators. Currently not supported 
Hive,WITHOUT_CLASSIFICATION,//  We need to insert 'null' before processing first row for the case: X preceding and y preceding 
Hive,WITHOUT_CLASSIFICATION,//  for analyze repl load we walk through the dir structure available in the path   looking at each db and then each table and then setting up the appropriate   import job in its place. 
Hive,WITHOUT_CLASSIFICATION,//  (Don't insist NullStructSerDe produce correct column names). 
Hive,WITHOUT_CLASSIFICATION,//  this sets up the map operator contexts correctly 
Hive,WITHOUT_CLASSIFICATION,//  length of compression buffer (compressed or uncompressed length) 
Hive,WITHOUT_CLASSIFICATION,//  verify that udf in black list fails even though it's included in whitelist 
Hive,WITHOUT_CLASSIFICATION,//  2. CPU cost = HashTable  construction  cost  + 
Hive,WITHOUT_CLASSIFICATION,//  do not fill tokenizer until user requests since filling it could read   in data   not meant for this instantiation. 
Hive,WITHOUT_CLASSIFICATION,//  In case of order by only 1 reducer is used so no need of   another shuffle 
Hive,WITHOUT_CLASSIFICATION,//  number of output columns   array of pathnames each of which corresponds to a column   mapping from pathnames to enum PARTNAME   array of returned column values   object pool of non-null Text avoid creating objects all the time   array of null column values   input ObjectInspectors 
Hive,WITHOUT_CLASSIFICATION,//  ISO-8601 timestamps 
Hive,WITHOUT_CLASSIFICATION,//  populated if column is Map type   @deprecated as of 0.13 slated for removal with 0.15 
Hive,WITHOUT_CLASSIFICATION,//  Assume by default that we would find everything. 
Hive,WITHOUT_CLASSIFICATION,//  Net transfer cost 
Hive,WITHOUT_CLASSIFICATION,//  Remove parent reduce-sink operators 
Hive,WITHOUT_CLASSIFICATION,//  Execute query 
Hive,WITHOUT_CLASSIFICATION,//  We want to try these whether they succeed or fail. 
Hive,WITHOUT_CLASSIFICATION,//  ignore exception - we simply don't add this attribute   back in to the resultant set. 
Hive,WITHOUT_CLASSIFICATION,//  Initialize workload management. 
Hive,WITHOUT_CLASSIFICATION,//  Entire batch is filtered out. 
Hive,WITHOUT_CLASSIFICATION,//  Generate umbilical token (applies to all splits) 
Hive,WITHOUT_CLASSIFICATION,//  Array of String 
Hive,WITHOUT_CLASSIFICATION,//  Smile mapper is used to read query results that are serialized as binary instead of json 
Hive,WITHOUT_CLASSIFICATION,//  PARTS 
Hive,WITHOUT_CLASSIFICATION,/*  * This is the central piece for Bucket Map Join and SMB join. It has the following * responsibilities: * 1. Group incoming splits based on bucketing. * 2. Generate new serialized events for the grouped splits. * 3. Create a routing table for the bucket map join and send a serialized version as payload * for the EdgeManager. * 4. For SMB join generate a grouping according to bucketing for the "small" table side.  */
Hive,WITHOUT_CLASSIFICATION,//  Case 3: Test with originals and deltas => Two split strategies with two splits for each. 
Hive,WITHOUT_CLASSIFICATION,/*  there are NULLs in the inputColVector  */
Hive,WITHOUT_CLASSIFICATION,//  a null object we do not serialize it 
Hive,WITHOUT_CLASSIFICATION,//  If original scale less than 6 use original scale value; otherwise preserve at least 6 fractional digits 
Hive,WITHOUT_CLASSIFICATION,//  Project the subset of fields. 
Hive,WITHOUT_CLASSIFICATION,//  anything else:  preserve original call 
Hive,WITHOUT_CLASSIFICATION,//  hive server's session input stream is not used 
Hive,WITHOUT_CLASSIFICATION,//  first 2 stripes will satisfy the predicate and merged to single split last stripe will be a 
Hive,WITHOUT_CLASSIFICATION,//  skip walking the children 
Hive,WITHOUT_CLASSIFICATION,//  Register comes in before the unregister for the previous dag 
Hive,WITHOUT_CLASSIFICATION,//  MM insert query move itself is a no-op. 
Hive,WITHOUT_CLASSIFICATION,//  Return the mocked StorageDescriptor 
Hive,WITHOUT_CLASSIFICATION,//  Fractional part 
Hive,WITHOUT_CLASSIFICATION,//  Find the base created for IOW. 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise build a timeline of existing segments in metadata storage 
Hive,WITHOUT_CLASSIFICATION,// ---------PTF functions------------ 
Hive,WITHOUT_CLASSIFICATION,//  Need to notify any queries waiting on the change from pending status. 
Hive,WITHOUT_CLASSIFICATION,//  try these best effort 
Hive,WITHOUT_CLASSIFICATION,//  append regexes that user wanted to add 
Hive,WITHOUT_CLASSIFICATION,//  Hostname 
Hive,WITHOUT_CLASSIFICATION,/*    * Specify the columns to deserialize into a range starting at a column number.    */
Hive,WITHOUT_CLASSIFICATION,//  We only need to check conformance if alter table enabled acid.   INSERT_ONLY tables don't have to conform to ACID requirement like ORC or bucketing. 
Hive,WITHOUT_CLASSIFICATION,//  Calculate collection. 
Hive,WITHOUT_CLASSIFICATION,//  totalSize and the numFiles are set. 
Hive,WITHOUT_CLASSIFICATION,//  if bucket columns are empty then numbuckets must be set to -1. 
Hive,WITHOUT_CLASSIFICATION,/*    * Tests with queries which cannot be executed with directSQL because the contain like or in.   * After falling back to ORM the number of partitions cannot be fetched by the   * ObjectStore.getNumPartitionsViaOrmFilter method. They are fetched by the   * ObjectStore.getPartitionNamesPrunedByExprNoTxn method.    */
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setNClob(int java.sql.NClob)    */
Hive,WITHOUT_CLASSIFICATION,//  Retrieve HIVE_TXN_TIMEOUT in MILLISECONDS (it's defined as SECONDS)   then divide it by 2 to give us a safety factor. 
Hive,WITHOUT_CLASSIFICATION,//  Add a maintenance thread that will attempt to trigger a cache clean continuously 
Hive,WITHOUT_CLASSIFICATION,//  If we didn't try to launch a job it either means there was no work to do or we got   here as the result of a communication failure with the DB.  Either way we want to wait 
Hive,WITHOUT_CLASSIFICATION,//  merge it with the downstream col list 
Hive,WITHOUT_CLASSIFICATION,//  We store VARCHAR type stripped of pads. 
Hive,WITHOUT_CLASSIFICATION,//  Then actually do the compaction. 
Hive,WITHOUT_CLASSIFICATION,//  sanity check - we should not receive keys with tags 
Hive,WITHOUT_CLASSIFICATION,//  For unpartitioned table partition values are specified 
Hive,WITHOUT_CLASSIFICATION,//  this parameter is a constant 
Hive,WITHOUT_CLASSIFICATION,/*  10 files x 100 size for 10 splits  */
Hive,WITHOUT_CLASSIFICATION,//  We need to add a non-match row with nulls for small table values. 
Hive,WITHOUT_CLASSIFICATION,//  3.3 Try obtaining UDAF evaluators to determine the ret type 
Hive,WITHOUT_CLASSIFICATION,//  signed comparisons 
Hive,WITHOUT_CLASSIFICATION,//  Not creating a view so no need to track view expansions. 
Hive,WITHOUT_CLASSIFICATION,//  Deserialize just the columns we a buffered batch which has only the non-key inputs and   streamed column outputs. 
Hive,WITHOUT_CLASSIFICATION,//  Operands converted to timestamp result as interval day-time 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) Field  */
Hive,WITHOUT_CLASSIFICATION,//  Clone the token as we'd need to set the service to the one we are talking to. 
Hive,WITHOUT_CLASSIFICATION,//  Alternate connect string specification configuration 
Hive,WITHOUT_CLASSIFICATION,//  Concurrent increase and revocation - before the message is sent. 
Hive,WITHOUT_CLASSIFICATION,//  Add field separator 
Hive,WITHOUT_CLASSIFICATION,//  If we are using a test specific database then we just drop the database 
Hive,WITHOUT_CLASSIFICATION,//  stats again 
Hive,WITHOUT_CLASSIFICATION,/*    * for map-side invocation of PTFs we cannot utilize the currentkeys null check   * to decide on invoking startPartition in streaming mode. Hence this extra flag.    */
Hive,WITHOUT_CLASSIFICATION,//  Reserve 5 bytes for writeValueRecord to fill. There might be junk there so null them. 
Hive,WITHOUT_CLASSIFICATION,//  if enforce bucketing/sorting is disabled numBuckets will not be set. 
Hive,WITHOUT_CLASSIFICATION,//  copy over configs touched by above method 
Hive,WITHOUT_CLASSIFICATION,//  Skewed info 
Hive,WITHOUT_CLASSIFICATION,// set the configuration up such that proxyUser can act on  behalf of all users belonging to the real group(s) that the 
Hive,WITHOUT_CLASSIFICATION,//  skip it  the for loop will skip its value 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:TerminateFragmentRequestProto) 
Hive,WITHOUT_CLASSIFICATION,//  we are closing a file without writing any data in it 
Hive,WITHOUT_CLASSIFICATION,//  Replicate the drop events and check if tables are getting dropped in target as well 
Hive,WITHOUT_CLASSIFICATION,/*  'alan' > first_name  */
Hive,WITHOUT_CLASSIFICATION,//  big table alias 
Hive,WITHOUT_CLASSIFICATION,//  TEST - repeating non-NULL & no-selection 
Hive,WITHOUT_CLASSIFICATION,//  Hive does not support ResultSetMetaData on PreparedStatement and Hive DESCRIBE   does not support queries so we have to execute the query with LIMIT 1 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#getHoldability()    */
Hive,WITHOUT_CLASSIFICATION,//  Retrieve from PK side 
Hive,WITHOUT_CLASSIFICATION,//  Since SerDe reuses memory we will need to make a copy. 
Hive,WITHOUT_CLASSIFICATION,//  Done with this branch 
Hive,WITHOUT_CLASSIFICATION,// assert that c3 has got added to table schema 
Hive,WITHOUT_CLASSIFICATION,//  select operator to project these two columns 
Hive,WITHOUT_CLASSIFICATION,//  repeated string lString = 4; 
Hive,WITHOUT_CLASSIFICATION,//  The fixed size for the aggregation class is already known. Get the   variable portion of the size every NUMROWSESTIMATESIZE rows. 
Hive,WITHOUT_CLASSIFICATION,//  If all the txns in the list have pre-allocated write ids for the given table then just return.   This is for idempotent case. 
Hive,WITHOUT_CLASSIFICATION,//  Find all configurations where the key contains any string from hiddenSet 
Hive,WITHOUT_CLASSIFICATION,//  We provide this public method to help EXPLAIN VECTORIZATION show the evaluator classes. 
Hive,WITHOUT_CLASSIFICATION,//  no privileges required so don't need to check this object privileges 
Hive,WITHOUT_CLASSIFICATION,//  Make sure the key ID mismatch causes error. 
Hive,WITHOUT_CLASSIFICATION,//  Definitely not a long. 
Hive,WITHOUT_CLASSIFICATION,//  Add all columns from lateral view 
Hive,WITHOUT_CLASSIFICATION,//  Constructing the row object etc which will be reused for all rows. 
Hive,WITHOUT_CLASSIFICATION,//  In general a filter cannot be pushed below a windowing calculation.   Applying the filter before the aggregation function changes   the results of the windowing invocation.     When the filter is on the PARTITION BY expression of the OVER clause   it can be pushed down. For now we don't support this. 
Hive,WITHOUT_CLASSIFICATION,/*  Add list bucketing pruner.  */
Hive,WITHOUT_CLASSIFICATION,// (zx) 
Hive,WITHOUT_CLASSIFICATION,/*  there are nulls in the inputColVector  */
Hive,WITHOUT_CLASSIFICATION,//  walking through all active nodes if they don't have potential capacity. 
Hive,WITHOUT_CLASSIFICATION,//  Don't invoke from within a scheduler lock 
Hive,WITHOUT_CLASSIFICATION,//  Instantiate BloomFilterCheck based on input column type 
Hive,WITHOUT_CLASSIFICATION,//  SKEWED_COL_VALUE_LOCATION_MAPS 
Hive,WITHOUT_CLASSIFICATION,//  Since bigTableKeyExpressions may do a calculation and produce a scratch column we   need to map the right column. 
Hive,WITHOUT_CLASSIFICATION,//  adds a null element 
Hive,WITHOUT_CLASSIFICATION,//  Do the conversion by going through a 64 bit integer 
Hive,WITHOUT_CLASSIFICATION,//  We assume the CHAR maximum length was enforced when the object was created. 
Hive,WITHOUT_CLASSIFICATION,/*    * Job callable task for job submit operation. Overrides behavior of execute()   * to submit job. Also overrides the behavior of cleanup() to kill the job in case   * job submission request is timed out or interrupted.    */
Hive,WITHOUT_CLASSIFICATION,//  before the drop. 
Hive,WITHOUT_CLASSIFICATION,//  We cannot to scaled up decimals that cannot be represented.   Instead we use a BigInteger instead. 
Hive,WITHOUT_CLASSIFICATION,//  For each source to read get a shared lock 
Hive,WITHOUT_CLASSIFICATION,//  deleteData ignoreUnknownTable ifPurge 
Hive,WITHOUT_CLASSIFICATION,//      it's not worth adding the extra state. 
Hive,WITHOUT_CLASSIFICATION,//  set the escaping related properties 
Hive,WITHOUT_CLASSIFICATION,//  if exception happens during doCopyOnce then need to call getFilesToRetry with copy error as true in retry. 
Hive,WITHOUT_CLASSIFICATION,//  Validate the second parameter which should be an array of strings 
Hive,WITHOUT_CLASSIFICATION,//  finally add a project to project out the last 2 columns 
Hive,WITHOUT_CLASSIFICATION,//  Handle implementation of Instance and invoke appropriate InputFormat method 
Hive,WITHOUT_CLASSIFICATION,//  add_partitions(empty list) : ok normal operation 
Hive,WITHOUT_CLASSIFICATION,//  don't want the table dir 
Hive,WITHOUT_CLASSIFICATION,//  used for LAZY_FETCH_PARTITIONS cases 
Hive,WITHOUT_CLASSIFICATION,//  Definitely not a short. 
Hive,WITHOUT_CLASSIFICATION,//  First incremental dump 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) TypeList  */
Hive,WITHOUT_CLASSIFICATION,//  ROLE_NAME 
Hive,WITHOUT_CLASSIFICATION,//  child JVM won't need to change debug parameters when creating it's own children 
Hive,WITHOUT_CLASSIFICATION,//  All partitions with blurb="hasNewColumn" were added after the table schema changed 
Hive,WITHOUT_CLASSIFICATION,//  bad input 
Hive,WITHOUT_CLASSIFICATION,//  To remove the primitive types 
Hive,WITHOUT_CLASSIFICATION,//  Cast decimal input to returnType 
Hive,WITHOUT_CLASSIFICATION,//  Keep cause as the original exception 
Hive,WITHOUT_CLASSIFICATION,//  Reached the end of a field? 
Hive,WITHOUT_CLASSIFICATION,//  Now start HS2 with low message size limit. This should prevent any connections 
Hive,WITHOUT_CLASSIFICATION,//  Start the job 
Hive,WITHOUT_CLASSIFICATION,//  user 
Hive,WITHOUT_CLASSIFICATION,//  Use TBLPROPERTIES 
Hive,WITHOUT_CLASSIFICATION,//  remember original string representation of constant. 
Hive,WITHOUT_CLASSIFICATION,//  We bail out 
Hive,WITHOUT_CLASSIFICATION,//  reduce might end up creating an expression with null type   e.g condition(null = null) is reduced to condition (null) with null type   since this is a condition which will always be boolean type we cast it to   boolean type 
Hive,WITHOUT_CLASSIFICATION,//  Open a session and set up the test data 
Hive,WITHOUT_CLASSIFICATION,//  Add default size for columns for which stats were not available 
Hive,WITHOUT_CLASSIFICATION,//  add constant object overhead for struct 
Hive,WITHOUT_CLASSIFICATION,// ************************************************************************************************   Decimal to Binary Conversion. 
Hive,WITHOUT_CLASSIFICATION,// txn 3 is not empty txn so we get a better msg 
Hive,WITHOUT_CLASSIFICATION,//  Transient members initialized by transientInit method. 
Hive,WITHOUT_CLASSIFICATION,//  It does not sort memory footprint is zero 
Hive,WITHOUT_CLASSIFICATION,//  If they are not equal we could zip up till here 
Hive,WITHOUT_CLASSIFICATION,//  Remove the container mapping 
Hive,WITHOUT_CLASSIFICATION,//  Don't need to track anything for this task. No new notifications etc. 
Hive,WITHOUT_CLASSIFICATION,//  Overflow.  This is not expected. 
Hive,WITHOUT_CLASSIFICATION,//  (with 000000_0 000000_0_copy_1 000000_0_copy_2) 
Hive,WITHOUT_CLASSIFICATION,//  Check whether the specified BaseWork's operator tree contains a operator 
Hive,WITHOUT_CLASSIFICATION,//  disable json file writing 
Hive,WITHOUT_CLASSIFICATION,//  create proper table/column desc for spilled tables 
Hive,WITHOUT_CLASSIFICATION,//  check the partitions in partSpec be the same as defined in table schema 
Hive,WITHOUT_CLASSIFICATION,//  TODO HIVE-13454 Add additional information such as #executors container size etc 
Hive,WITHOUT_CLASSIFICATION,//  normal close when there are inserts. 
Hive,WITHOUT_CLASSIFICATION,//  Overrides values from the hive/tez-site. 
Hive,WITHOUT_CLASSIFICATION,//  Build Hive Table Scan Rel 
Hive,WITHOUT_CLASSIFICATION,//  Get old stats object if present 
Hive,WITHOUT_CLASSIFICATION,//  check if they are operating on the same table if not move on. 
Hive,WITHOUT_CLASSIFICATION,//  Bootstrap done now on to incremental. First we test db-level REPL LOADs.   Both db-level and table-level repl.last.id must be updated. 
Hive,WITHOUT_CLASSIFICATION,// the partition did not change 
Hive,WITHOUT_CLASSIFICATION,//  Re-create the remote client if not active any more 
Hive,WITHOUT_CLASSIFICATION,//  optional int32 attempt_number = 4; 
Hive,WITHOUT_CLASSIFICATION,//  Verify that there are no missing privileges 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:UpdateQueryRequestProto) 
Hive,WITHOUT_CLASSIFICATION,//  rowId >= '2014-01-01' 
Hive,WITHOUT_CLASSIFICATION,//  Always localize files from conf; duplicates are handled on FS level.   TODO: we could do the same thing as below and only localize if missing. 
Hive,WITHOUT_CLASSIFICATION,//  get SSL socket 
Hive,WITHOUT_CLASSIFICATION,// Reset buffers to store filter push down columns 
Hive,WITHOUT_CLASSIFICATION,//  close() after *expiry time* and *a cache access* should  have tore down the client 
Hive,WITHOUT_CLASSIFICATION,//  mapreduce.tez.input.initializer.serialize.event.payload should be set   to false when using this plug-in to avoid getting a serialized event at run-time. 
Hive,WITHOUT_CLASSIFICATION,//  The reader doesn't support offsets. We adjust offsets to match future splits.   If cached split was starting at row start that row would be skipped so +1 byte. 
Hive,WITHOUT_CLASSIFICATION,//  This is needed for serde of PagingSpec as it uses JacksonInject for injecting SelectQueryConfig 
Hive,WITHOUT_CLASSIFICATION,//  Now create three types of delete deltas- first has rowIds divisible by 2 but not by 3   second has rowIds divisible by 3 but not by 2 and the third has rowIds divisible by   both 2 and 3. This should produce delete deltas that will thoroughly test the sort-merge   logic when the delete events in the delete delta files interleave in the sort order. 
Hive,WITHOUT_CLASSIFICATION,//  complex tree with multiple parents 
Hive,WITHOUT_CLASSIFICATION,//  constant for now will make it configurable later. 
Hive,WITHOUT_CLASSIFICATION,//  Remaining fields are cells addressed by column name within row. 
Hive,WITHOUT_CLASSIFICATION,// could not abort all txns in this batch - this may happen because in parallel with this  operation there was activity on one of the txns in this batch (commit/abort/heartbeat)  This is not likely but may happen if client experiences long pause between heartbeats or  unusually long/extreme pauses between heartbeat() calls and other logic in checkLock()  lock() etc. 
Hive,WITHOUT_CLASSIFICATION,/*    * @return The multi-set count for the lookup key.    */
Hive,WITHOUT_CLASSIFICATION,//  Then find the leftmost logical sibling select because that's what Hive uses for aliases.  
Hive,WITHOUT_CLASSIFICATION,//  hiveConf getConf and setConf are in this class because AlterHandler extends Configurable.   Always use the configuration from HMS Handler.  Making AlterHandler not extend Configurable   is not in the scope of the fix for HIVE-17942. 
Hive,WITHOUT_CLASSIFICATION,//        a significant effect when 'k'*'pf' is very high. 
Hive,WITHOUT_CLASSIFICATION,//  test min = 0 max = 0 generates each stripe 
Hive,WITHOUT_CLASSIFICATION,//  Do not change the location so it is tested that the location will be changed even if the   location is not set to null just remain the same 
Hive,WITHOUT_CLASSIFICATION,//  If top operator is not a pure limit we bail out 
Hive,WITHOUT_CLASSIFICATION,/*  use zero copy record reader  */
Hive,WITHOUT_CLASSIFICATION,//  QueryInfo will only exist if more work came in after this was scheduled. 
Hive,WITHOUT_CLASSIFICATION,//  move over the separator for next search 
Hive,WITHOUT_CLASSIFICATION,//  MERGEPARTIAL 
Hive,WITHOUT_CLASSIFICATION,//  Deserialize the bloom filter 
Hive,WITHOUT_CLASSIFICATION,//  may be drive this via configuration as well. 
Hive,WITHOUT_CLASSIFICATION,//  Close the connection 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.ICLIService#fetchResults(org.apache.hive.service.cli.OperationHandle)    */
Hive,WITHOUT_CLASSIFICATION,//  We set the signature for the view if it is a materialized view 
Hive,WITHOUT_CLASSIFICATION,//  REPL_SRC_TXN_IDS 
Hive,WITHOUT_CLASSIFICATION,//  set the thread name with the logging prefix. 
Hive,WITHOUT_CLASSIFICATION,//  Derived. 
Hive,WITHOUT_CLASSIFICATION,//  For negative testing purpose.. 
Hive,WITHOUT_CLASSIFICATION,//  A helper object that efficiently copies the big table columns that are for the big table 
Hive,WITHOUT_CLASSIFICATION,//  order in which the results should 
Hive,WITHOUT_CLASSIFICATION,//  Update tags of reduce sinks 
Hive,WITHOUT_CLASSIFICATION,//  Maximum number of open transactions that's allowed 
Hive,WITHOUT_CLASSIFICATION,//  optional int32 myint = 1; 
Hive,WITHOUT_CLASSIFICATION,//  OPERATION_TYPE 
Hive,WITHOUT_CLASSIFICATION,//  Object Hash. 
Hive,WITHOUT_CLASSIFICATION,//  make the new projRel to provide a null indicator 
Hive,WITHOUT_CLASSIFICATION,//  Marker to track if there is starting double quote without an ending double quote 
Hive,WITHOUT_CLASSIFICATION,//  because that is monotonically increasing to give new unique row ids. 
Hive,WITHOUT_CLASSIFICATION,/*    * DOUBLE.    */
Hive,WITHOUT_CLASSIFICATION,//  It is not an external table 
Hive,WITHOUT_CLASSIFICATION,//  Optional vectorized value expressions that need to be run on each batch. 
Hive,WITHOUT_CLASSIFICATION,//  If it a map-reduce job create a temporary file 
Hive,WITHOUT_CLASSIFICATION,/*  Make sure all the NULL entries in this long column output vector have their data vector   * element set to the correct value as per the specification to prevent later arithmetic   * errors (e.g. zero-divide).    */
Hive,WITHOUT_CLASSIFICATION,//  STAGE_ID 
Hive,WITHOUT_CLASSIFICATION,//  Aux values 
Hive,WITHOUT_CLASSIFICATION,/*          * ExecutionException is raised if job execution gets an exception. Return to client         * with the exception.          */
Hive,WITHOUT_CLASSIFICATION,//  if we died for any reason lets get a new set of hosts 
Hive,WITHOUT_CLASSIFICATION,//  See the comment in TimestampStreamReader.setBuffers. 
Hive,WITHOUT_CLASSIFICATION,//  VectorizedBatchUtil.debugDisplayBatch( batch "VectorReduceSinkOperator processOp "); 
Hive,WITHOUT_CLASSIFICATION,/*          * NOT Repeating.          */
Hive,WITHOUT_CLASSIFICATION,//  should be a no-op for sparse 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setTimestamp(java.lang.String   * java.sql.Timestamp java.util.Calendar)    */
Hive,WITHOUT_CLASSIFICATION,//  neg-infinity to start inclusive 
Hive,WITHOUT_CLASSIFICATION,//  Oracle requires special treatment... as usual. 
Hive,WITHOUT_CLASSIFICATION,//  scalar/column 
Hive,WITHOUT_CLASSIFICATION,//  hide constructor 
Hive,WITHOUT_CLASSIFICATION,//  when reading the hashtable MapJoinObjectValue calculates alias filter and provide it to join 
Hive,WITHOUT_CLASSIFICATION,//  we need to set this because with HS2 and client side split   generation we end up not finding the map work. This is   because of thread local madness (tez split generation is   multi-threaded - HS2 plan cache uses thread locals). Setting   VECTOR_MODE/USE_VECTORIZED_INPUT_FILE_FORMAT causes the split gen code to use the conf instead   of the map work. 
Hive,WITHOUT_CLASSIFICATION,//  The list of servers the database/partition/table can locate on 
Hive,WITHOUT_CLASSIFICATION,//  Write the results into the file 
Hive,WITHOUT_CLASSIFICATION,//  Read from the given Accumulo table 
Hive,WITHOUT_CLASSIFICATION,//  Server ok. 
Hive,WITHOUT_CLASSIFICATION,//  make 'm' multiple of 64 
Hive,WITHOUT_CLASSIFICATION,// The keys used to store info into the job Configuration 
Hive,WITHOUT_CLASSIFICATION,//  If no import tasks generated by the event or no table updated for table level load then no   need to update the repl state to any object. 
Hive,WITHOUT_CLASSIFICATION,/*    * Helper to determine the size of the container requested   * from yarn. Falls back to Map-reduce's map size if tez   * container size isn't set.    */
Hive,WITHOUT_CLASSIFICATION,//  clear everything 
Hive,WITHOUT_CLASSIFICATION,//  Parse fraction portion. 
Hive,WITHOUT_CLASSIFICATION,//  This is based on Vectorizer code minus the validation. 
Hive,WITHOUT_CLASSIFICATION,//    Helpers   
Hive,WITHOUT_CLASSIFICATION,//  If in some selected binary operators (= is null etc) one of the   expressions are 
Hive,WITHOUT_CLASSIFICATION,//  in return path we may have aggr($f0) aggr($f1) in GBY   and then select aggr($f1) aggr($f0) in SEL.   Thus we need to use colExp to find out which position is   corresponding to which position. 
Hive,WITHOUT_CLASSIFICATION,//  Look for AppMasterEventOperator or ReduceSinkOperator 
Hive,WITHOUT_CLASSIFICATION,//  See the comment inside updatePartitionBucketSortColumns. 
Hive,WITHOUT_CLASSIFICATION,//  The child is a single Range 
Hive,WITHOUT_CLASSIFICATION,//  rename needs change the data location and move the data to the new location corresponding   to the new name if:   1) the table is not a virtual view and   2) the table is not an external table and   3) the user didn't change the default location (or new location is empty) and 
Hive,WITHOUT_CLASSIFICATION,//  Basic adding and removing operations called only while holding lock 
Hive,WITHOUT_CLASSIFICATION,//  First we delete the materialized views 
Hive,WITHOUT_CLASSIFICATION,//  Null direction 
Hive,WITHOUT_CLASSIFICATION,//  reuse existing perf logger. 
Hive,WITHOUT_CLASSIFICATION,//  check if the new entry contains the existing 
Hive,WITHOUT_CLASSIFICATION,//  Merge the sidefile into the newly created hash table 
Hive,WITHOUT_CLASSIFICATION,//  column value lengths for each of the selected columns 
Hive,WITHOUT_CLASSIFICATION,//  finally open the store 
Hive,WITHOUT_CLASSIFICATION,//  inline map join operator 
Hive,WITHOUT_CLASSIFICATION,//  SMBJoin not supported 
Hive,WITHOUT_CLASSIFICATION,//  if the ast has 3 children the second *has to* be partition spec 
Hive,WITHOUT_CLASSIFICATION,//  CTAS case: the file output format and serde are defined by the create   table command rather than taking the default value 
Hive,WITHOUT_CLASSIFICATION,//  I16_VAL 
Hive,WITHOUT_CLASSIFICATION,//  this position in parent is a constant   reverse look up colExprMap to find the childColName 
Hive,WITHOUT_CLASSIFICATION,//  The utility of this method is not certain. 
Hive,WITHOUT_CLASSIFICATION,//  Setting the hidden list 
Hive,WITHOUT_CLASSIFICATION,//  We assume that AMs and HS2 run under the same user. 
Hive,WITHOUT_CLASSIFICATION,//  check for this pattern   The pattern matching could be simplified if rules can be applied   during decorrelation     CorrelateRel(left correlation condition = true)     LeftInputRel     Project-A (a RexNode)       Aggregate (groupby (0) agg0() agg1()...)         Project-B (references coVar)           rightInputRel 
Hive,WITHOUT_CLASSIFICATION,//  inserts are done. 
Hive,WITHOUT_CLASSIFICATION,//  Transactions should be committed. 
Hive,WITHOUT_CLASSIFICATION,//  code copied over from UDFWeekOfYear implementation 
Hive,WITHOUT_CLASSIFICATION,//  Subscriber can get notification of newly add partition in a   particular table by listening on a topic named "dbName.tableName"   and message selector string as "HCAT_EVENT = HCAT_ADD_PARTITION" 
Hive,WITHOUT_CLASSIFICATION,//  returns name of hashfile made by HASHTABLESINK which is read by MAPJOIN 
Hive,WITHOUT_CLASSIFICATION,//  we'd increase the base limit and adjust dynamically based on IO and processing perf delays. 
Hive,WITHOUT_CLASSIFICATION,//  Skip the potential big table identified above 
Hive,WITHOUT_CLASSIFICATION,//  load hivemetastore-site.xml if this is metastore and file exists 
Hive,WITHOUT_CLASSIFICATION,//  this table_desc does not contain the partitioning columns 
Hive,WITHOUT_CLASSIFICATION,//  The order in which the two paths are added is important. The   lateral view join operator depends on having the select operator   give it the row first. 
Hive,WITHOUT_CLASSIFICATION,//  Owid with the given value found! Searching now for rowId...   Retrieve the actual CompressedOwid that matched.   Check if rowId is outside the range of all rowIds present for this owid. 
Hive,WITHOUT_CLASSIFICATION,//  we first use getParameters() to prune the stats 
Hive,WITHOUT_CLASSIFICATION,//  The following actions are authorized through SQLStdHiveAccessController 
Hive,WITHOUT_CLASSIFICATION,//  Grouping id should be pruned which is the last of key columns   see ColumnPrunerGroupByProc 
Hive,WITHOUT_CLASSIFICATION,//  By default just the Hive catalog should be cached. 
Hive,WITHOUT_CLASSIFICATION,//  partition spec string to input file names (big) 
Hive,WITHOUT_CLASSIFICATION,//  we are using PLAIN Sasl connection with user/password 
Hive,WITHOUT_CLASSIFICATION,//  We can get the table definition from tbl. 
Hive,WITHOUT_CLASSIFICATION,//  alterPartition/alterTable is happening via statsTask or via user. 
Hive,WITHOUT_CLASSIFICATION,/*    * Right trim a slice of a byte array and return the new byte length.    */
Hive,WITHOUT_CLASSIFICATION,//  Overriden to copy start index / end index that is needed through optimization   e.g. for masking/filtering 
Hive,WITHOUT_CLASSIFICATION,//  nothing special - just use the DynamicSerDeFieldList's children methods to 
Hive,WITHOUT_CLASSIFICATION,//  On error close the channel. 
Hive,WITHOUT_CLASSIFICATION,//  Can't subtract NULL. 
Hive,WITHOUT_CLASSIFICATION,//  For subclasses 
Hive,WITHOUT_CLASSIFICATION,//  If the expression is a IS [NOT] NULL on a non-nullable   column then we can either remove the filter or replace   it with an Empty. 
Hive,WITHOUT_CLASSIFICATION,/*    * Submit job request. If maximum concurrent job submit requests are configured then submit   * request will be executed on a thread from thread pool. If job submit request time out is   * configured then request execution thread will be interrupted if thread times out. Also   * does best efforts to identify if job is submitted and kill it quietly.    */
Hive,WITHOUT_CLASSIFICATION,// Input 
Hive,WITHOUT_CLASSIFICATION,//  This query create a pending cache entry but it was never saved with real results cleanup.   This step is required as there may be queries waiting on this pending cache entry.   Removing/invalidating this entry will notify the waiters that this entry cannot be used. 
Hive,WITHOUT_CLASSIFICATION,//  Alright fine we'll use our defaults 
Hive,WITHOUT_CLASSIFICATION,//  day   hour   minute   second 
Hive,WITHOUT_CLASSIFICATION,//  Can this task be merged with the child task. This can happen if a big table is being 
Hive,WITHOUT_CLASSIFICATION,//  impossible to throw any json exceptions. 
Hive,WITHOUT_CLASSIFICATION,//  copy nulls from the non-repeating side 
Hive,WITHOUT_CLASSIFICATION,//  doing a single_value() on the entire input 
Hive,WITHOUT_CLASSIFICATION,// this code doesn't propagate 
Hive,WITHOUT_CLASSIFICATION,//  Check if any of the partitions already exists in destTable. 
Hive,WITHOUT_CLASSIFICATION,//  Test that existing shared_read table with new shared_write coalesces to 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see org.apache.hadoop.hive.ql.lib.Node#getName()    */
Hive,WITHOUT_CLASSIFICATION,//  comment 
Hive,WITHOUT_CLASSIFICATION,// Combine credentials and credentials from job takes precedence for freshness 
Hive,WITHOUT_CLASSIFICATION,//  fetch 2 in same schema 
Hive,WITHOUT_CLASSIFICATION,//  set up service and client 
Hive,WITHOUT_CLASSIFICATION,//  Semijoin DPP work is considered a descendant because work needs 
Hive,WITHOUT_CLASSIFICATION,//  Inner big-table only join specific. 
Hive,WITHOUT_CLASSIFICATION,//  check the stats 
Hive,WITHOUT_CLASSIFICATION,//  TypeInfoBasedObjectInspector typeInfoBasedObjectInspector =   (ObjectInspector)oi;   return typeInfoBasedObjectInspector.getTypeInfo();   } 
Hive,WITHOUT_CLASSIFICATION,//  Finally add the partitioning columns 
Hive,WITHOUT_CLASSIFICATION,//  NEED_RESULT 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#setPoolable(boolean)    */
Hive,WITHOUT_CLASSIFICATION,//  No physical dir gets created. 
Hive,WITHOUT_CLASSIFICATION,//  1) Create two bucketed tables 
Hive,WITHOUT_CLASSIFICATION,//  used if the join   input is too large   to fit in memory 
Hive,WITHOUT_CLASSIFICATION,//  This get should fail because its variance ((10-5)/5) is way past MAX_VARIANCE (0.5) 
Hive,WITHOUT_CLASSIFICATION,/*  1 files x 100 size for 10 splits  */
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) Typedef  */
Hive,WITHOUT_CLASSIFICATION,//  assert bucket listing is as expected 
Hive,WITHOUT_CLASSIFICATION,//  Set up the transaction/locking db in the derby metastore 
Hive,WITHOUT_CLASSIFICATION,//  finally write out the pieces (sign scale digits) 
Hive,WITHOUT_CLASSIFICATION,//  We only increase the targets here. 
Hive,WITHOUT_CLASSIFICATION,//  calling from code that does not use filters as-is. 
Hive,WITHOUT_CLASSIFICATION,//  make some noisy to avoid disk caches data. 
Hive,WITHOUT_CLASSIFICATION,//  required   required   optional   optional   optional 
Hive,WITHOUT_CLASSIFICATION,// multiple clients may initialize the hook at the same time 
Hive,WITHOUT_CLASSIFICATION,//  and it is an insert overwrite or insert into table 
Hive,WITHOUT_CLASSIFICATION,//  is distinct 
Hive,WITHOUT_CLASSIFICATION,//  Send an actual heartbeat only if the task count is > 0 
Hive,WITHOUT_CLASSIFICATION,/*    * Tests whether there is another List element or another Map key/value pair.    */
Hive,WITHOUT_CLASSIFICATION,/*      * ensure that we throw out any exceptions above highWatermark to make     * {@link #isWriteIdValid(long)} faster      */
Hive,WITHOUT_CLASSIFICATION,//  WHITE FLAG WITH HORIZONTAL MIDDLE BLACK STRIPE U+26FF (3 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  with data 
Hive,WITHOUT_CLASSIFICATION,//  mark txn "2L" aborted   mark txn "8L" aborted 
Hive,WITHOUT_CLASSIFICATION,/*   // TODO MS-SPLIT I'm 99% certain we don't need this as MetastoreConf.newMetastoreConf already  adds this resource.  static {    conf.addResource("hive-site.xml");  }   */
Hive,WITHOUT_CLASSIFICATION,//  Logger to the string appender 
Hive,WITHOUT_CLASSIFICATION,//  It's not clear how filtering for e.g. "stringCol > 5" should work (which side is   to be coerced?). Let the expression evaluation sort this one out not metastore. 
Hive,WITHOUT_CLASSIFICATION,//  try dropping table as user2 - should fail 
Hive,WITHOUT_CLASSIFICATION,//  250 seems to be reasonable upper limit for this 
Hive,WITHOUT_CLASSIFICATION,//  We need to make sure that the key type and the value types are settable. 
Hive,WITHOUT_CLASSIFICATION,/*      * 1. Create the PTFDesc from the Qspec attached to this QB.      */
Hive,WITHOUT_CLASSIFICATION,//  if we aren't building a split start a new one. 
Hive,WITHOUT_CLASSIFICATION,//  The following datetime/interval arithmetic operations can be done using the vectorized values. 
Hive,WITHOUT_CLASSIFICATION,//  To Unpartitioned table 
Hive,WITHOUT_CLASSIFICATION,//  Write ID of committed txn should be valid. 
Hive,WITHOUT_CLASSIFICATION,//  Try an invalid state transition on the handle. This ensures that the actual state   change we're interested in actually happened since internally the handle serializes   state changes. 
Hive,WITHOUT_CLASSIFICATION,//  as we are overwriting segments with new versions 
Hive,WITHOUT_CLASSIFICATION,//  UNDONE: Multiple types... 
Hive,WITHOUT_CLASSIFICATION,// create some data 
Hive,WITHOUT_CLASSIFICATION,//  Insert HAVING plan here 
Hive,WITHOUT_CLASSIFICATION,/*    * when a QBJoinTree is merged into this one its left(pos =0) filters can   * refer to any of the srces in this QBJoinTree. If a particular filterForPushing refers   * to multiple srces in this QBJoinTree we collect them into 'postJoinFilters'   * We then add a Filter Operator after the Join Operator for this QBJoinTree.    */
Hive,WITHOUT_CLASSIFICATION,//  blank " " (1 byte)   LATIN LETTER SMALL CAPITAL L U+029F (2 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  Tests for int add_partitions(List<Partition> partitions) method 
Hive,WITHOUT_CLASSIFICATION,//  is not special cased later in subquery remove rule 
Hive,WITHOUT_CLASSIFICATION,//  If cluster info changes qam should be called with the same fractions. 
Hive,WITHOUT_CLASSIFICATION,//  Preempt on specific host 
Hive,WITHOUT_CLASSIFICATION,/*      * Override this for concrete initialization.      */
Hive,WITHOUT_CLASSIFICATION,//  NOT USED 
Hive,WITHOUT_CLASSIFICATION,//  This is map of which vectorized row batch columns are the big table key columns.  Since   we may have key expressions that produce new scratch columns we need a mapping. 
Hive,WITHOUT_CLASSIFICATION,//  DB 
Hive,WITHOUT_CLASSIFICATION,//  final row computation will consider join type 
Hive,WITHOUT_CLASSIFICATION,//  TABLENAME 
Hive,WITHOUT_CLASSIFICATION,// here there is only 1 "split" since we only have data for 1 bucket 
Hive,WITHOUT_CLASSIFICATION,//  The following data might be changed 
Hive,WITHOUT_CLASSIFICATION,//  index is disabled 
Hive,WITHOUT_CLASSIFICATION,//  Drop partition will clean the partition entry from the compaction queue and hence worker have no effect 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setNClob(java.lang.String java.io.Reader)    */
Hive,WITHOUT_CLASSIFICATION,//       } 
Hive,WITHOUT_CLASSIFICATION,//  Generate lineage info for create view statements   if LineageLogger hook is configured. 
Hive,WITHOUT_CLASSIFICATION,//  we always have to find at least one location otw the test is useless 
Hive,WITHOUT_CLASSIFICATION,//  In the future if we support arbitrary characters in   identifiers then we'll need to escape any backticks   in identifier by doubling them up. 
Hive,WITHOUT_CLASSIFICATION,//  Add materializations to planner 
Hive,WITHOUT_CLASSIFICATION,//  There could be multiple keyValuePairs separated by comma 
Hive,WITHOUT_CLASSIFICATION,/*                * Single-Column String specific lookup key.                */
Hive,WITHOUT_CLASSIFICATION,//  Decrease refcount. 
Hive,WITHOUT_CLASSIFICATION,//  For now bail out on decimal constants with larger scale than column scale. 
Hive,WITHOUT_CLASSIFICATION,//  The thread should stop after this.  
Hive,WITHOUT_CLASSIFICATION,//  create TS to read intermediate data 
Hive,WITHOUT_CLASSIFICATION,//  we need the mapping and type information. 
Hive,WITHOUT_CLASSIFICATION,//  Pick the maximum # reducers across all parents as the # of reduce tasks. 
Hive,WITHOUT_CLASSIFICATION,/*    * Use this constructor when only ascending sort order is used.    */
Hive,WITHOUT_CLASSIFICATION,//  default prefix is delta_prefix 
Hive,WITHOUT_CLASSIFICATION,//  Test-only counter. 
Hive,WITHOUT_CLASSIFICATION,//  Dynamic partition keys should be added to field schemas. 
Hive,WITHOUT_CLASSIFICATION,//  Invariant that Avro's tag ordering must match Hive's. 
Hive,WITHOUT_CLASSIFICATION,//  The buffer has lived in the heap all along. Restore heap property. 
Hive,WITHOUT_CLASSIFICATION,//  Configure PREEXECHOOKS with DisallowTransformHook to disallow transform queries 
Hive,WITHOUT_CLASSIFICATION,//  If the main thread throws an exception for some reason propagate the exception to the   client and initiate a safe shutdown 
Hive,WITHOUT_CLASSIFICATION,//  DP columns starts with tableFields.size() 
Hive,WITHOUT_CLASSIFICATION,//  If any child is null set unknown to true 
Hive,WITHOUT_CLASSIFICATION,//  Get the children expr strings 
Hive,WITHOUT_CLASSIFICATION,// -----------------------------------------------------------------------------------------------   Precision/scale enforcement methods.  ----------------------------------------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  Cannot handle NULL scalar parameter. 
Hive,WITHOUT_CLASSIFICATION,//  We only support Decimal64 on 2 columns when the have the same scale. 
Hive,WITHOUT_CLASSIFICATION,//  add the remaining fields 
Hive,WITHOUT_CLASSIFICATION,//  unknown | unknown | unknown 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)     * Serializes this value into the format used by @{link #java.math.BigInteger}     * This is used for fast assignment of a Decimal128 to a HiveDecimalWritable internal storage.     * See OpenJDK BigInteger.toByteArray for a reference implementation.      * @param scratch     * @param signum     * @return      */
Hive,WITHOUT_CLASSIFICATION,//  Struct. 
Hive,WITHOUT_CLASSIFICATION,//  If there's a failure from here to when the metadata is updated   there will be no data in the partition or an error while trying to read   the partition (if the archive files have been moved to the original   partition directory.) But re-running the archive command will allow   recovery 
Hive,WITHOUT_CLASSIFICATION,//  Since this is a dynamic partitioned hash join the work for this join should be a ReduceWork 
Hive,WITHOUT_CLASSIFICATION,//  IGNORE_PROTECTION 
Hive,WITHOUT_CLASSIFICATION,//  Test getter for configuration object. 
Hive,WITHOUT_CLASSIFICATION,//  Note that we do not need a lock for this entity.  This is used by operations like alter   table ... partition where its actually the partition that needs locked even though the table 
Hive,WITHOUT_CLASSIFICATION,//  replace ReduceSinkOp with HashTableSinkOp for the RSops which are parents of MJop 
Hive,WITHOUT_CLASSIFICATION,//  This the is Object Hash class variation. 
Hive,WITHOUT_CLASSIFICATION,//  Augment 
Hive,WITHOUT_CLASSIFICATION,//  Boolean values are stores a 1's and 0's so convert and compare 
Hive,WITHOUT_CLASSIFICATION,//  This column is not included. 
Hive,WITHOUT_CLASSIFICATION,//  Add an initial column to a vectorization context when 
Hive,WITHOUT_CLASSIFICATION,//  if getMacroName is null we always treat it different from others. 
Hive,WITHOUT_CLASSIFICATION,//  update the seed 
Hive,WITHOUT_CLASSIFICATION,//  transactional is found but the value is not in expected range 
Hive,WITHOUT_CLASSIFICATION,//  Use PurgeCacheRequestProto.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,//  We have data until the end of current block if we had it until the beginning. 
Hive,WITHOUT_CLASSIFICATION,//  No record on disk more data in write buffer 
Hive,WITHOUT_CLASSIFICATION,//  Path has writing permissions 
Hive,WITHOUT_CLASSIFICATION,/*  Singleton  */
Hive,WITHOUT_CLASSIFICATION,//  Format a list of Columns for a create statement 
Hive,WITHOUT_CLASSIFICATION,//  set the skipped field to null 
Hive,WITHOUT_CLASSIFICATION,//  check whether HiveConf initialize log4j correctly 
Hive,WITHOUT_CLASSIFICATION,//  partition name to value 
Hive,WITHOUT_CLASSIFICATION,//  Events. 
Hive,WITHOUT_CLASSIFICATION,//  Task has been queued for execution by the driver 
Hive,WITHOUT_CLASSIFICATION,// thrown for example if there is no such user on the system 
Hive,WITHOUT_CLASSIFICATION,//  This method tries to merge the join with its left child. The left 
Hive,WITHOUT_CLASSIFICATION,//  non-qualified types should simply return the TypeInfo associated with that type 
Hive,WITHOUT_CLASSIFICATION,// Output will also be repeating 
Hive,WITHOUT_CLASSIFICATION,//  confirm the batch sizes were 5 5 in the two calls to create partitions 
Hive,WITHOUT_CLASSIFICATION,// avoid NPE below if for some reason -e argument has multi-line command 
Hive,WITHOUT_CLASSIFICATION,//  Check partition exists if it exists skip the overwrite 
Hive,WITHOUT_CLASSIFICATION,//  Check if the query results were cacheable and created a pending cache entry.   If we successfully saved the results the usage would have changed to QUERY_USING_CACHE. 
Hive,WITHOUT_CLASSIFICATION,//  can prevent updates from being sent out to the new node. 
Hive,WITHOUT_CLASSIFICATION,/*        * Finally write out the pieces (sign power digits)        */
Hive,WITHOUT_CLASSIFICATION,//  different paths. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure that the port is unused. 
Hive,WITHOUT_CLASSIFICATION,//  Now that we have the big table index get real numReducers value based on big table RS 
Hive,WITHOUT_CLASSIFICATION,//  Then UKs 
Hive,WITHOUT_CLASSIFICATION,//  with the releases probably running in the other closing thread. 
Hive,WITHOUT_CLASSIFICATION,//  Do not check for ACID; it does not create new parts and this is expensive as hell.   TODO: add an API to get table name list for archived parts with a single call;         nobody uses this so we could skip the whole thing. 
Hive,WITHOUT_CLASSIFICATION,//  number of dynamic partition columns   involved partitions in TableScanOperator/FileSinkOperator 
Hive,WITHOUT_CLASSIFICATION,//  Put in the beginning; relies on the knowledge of internal implementation. Pave? 
Hive,WITHOUT_CLASSIFICATION,// this would usually be at block boundary  this would usually be at block boundary 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setBinaryStream(java.lang.String   * java.io.InputStream)    */
Hive,WITHOUT_CLASSIFICATION,//  this must be a hadoop 2.4 version or earlier.   Resorting to the earlier method of getting the properties which uses SASL_PROPS field 
Hive,WITHOUT_CLASSIFICATION,//  if source exists rename. Otherwise create a empty directory 
Hive,WITHOUT_CLASSIFICATION,// no more original files to read 
Hive,WITHOUT_CLASSIFICATION,//  Re-verify directory layout and query result by using the same logic as above 
Hive,WITHOUT_CLASSIFICATION,//  matches FIL-PROJ-TS 
Hive,WITHOUT_CLASSIFICATION,//  If there are no columns (projection only join?) just assume no weight. 
Hive,WITHOUT_CLASSIFICATION,//  Use GetTokenRequestProto.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,// Read with partition filter 
Hive,WITHOUT_CLASSIFICATION,//  Fraction below 0.5 is implicitly 0. 
Hive,WITHOUT_CLASSIFICATION,//  Filter the name list. Removing elements one by one can be slow on e.g. ArrayList 
Hive,WITHOUT_CLASSIFICATION,/*    * If HIVE_SERVER2_JOB_CREDSTORE_LOCATION is set check HIVE_SERVER2_JOB_CREDSTORE_PASSWORD_ENVVAR before   * checking HADOOP_CREDENTIAL_PASSWORD_ENVVAR    */
Hive,WITHOUT_CLASSIFICATION,// assert this.nextGroupStorage[alias].size() == 0; 
Hive,WITHOUT_CLASSIFICATION,//  Not cleaning the interrupt status. 
Hive,WITHOUT_CLASSIFICATION,//  RCFile specific parameter 
Hive,WITHOUT_CLASSIFICATION,//  Is this a list type? 
Hive,WITHOUT_CLASSIFICATION,//  handle overloaded methods first 
Hive,WITHOUT_CLASSIFICATION,//  Hide constructor for make benefit glorious Singleton. 
Hive,WITHOUT_CLASSIFICATION,//  Nothing to trim (ASCII). 
Hive,WITHOUT_CLASSIFICATION,//  Check Configuration for any user-provided Authorization definition 
Hive,WITHOUT_CLASSIFICATION,//  LOG.info("Writing value at " + valueOffset + " length " + valueLength);   In an unlikely case of 0-length key and value for the very first entry we want to tell   this apart from an empty value. We'll just advance one byte; this byte will be lost. 
Hive,WITHOUT_CLASSIFICATION,//  may need to strip away the STOP marker when in thrift mode 
Hive,WITHOUT_CLASSIFICATION,//  public static MetadataListStructObjectInspector getInstance(int fields) {   return getInstance(ObjectInspectorUtils.getIntegerArray(fields));   } 
Hive,WITHOUT_CLASSIFICATION,//  If we are currently searching the data for a place to begin do not return data yet 
Hive,WITHOUT_CLASSIFICATION,// Map<??> c14Value = (Map<??>) rowValues[13];  assertEquals(0 c14Value.size()); 
Hive,WITHOUT_CLASSIFICATION,// https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2/src/packages/templates/conf/hdfs-site.xml 
Hive,WITHOUT_CLASSIFICATION,// 1) Start from a clean slate (metastore) 
Hive,WITHOUT_CLASSIFICATION,//  reduceSink is only available during compile 
Hive,WITHOUT_CLASSIFICATION,// get partition this partition should not have the newly added column since cascade option 
Hive,WITHOUT_CLASSIFICATION,//  remove from current root task and add conditional task to root tasks 
Hive,WITHOUT_CLASSIFICATION,//  Derby script format is RUN '<file>' 
Hive,WITHOUT_CLASSIFICATION,//  without data 
Hive,WITHOUT_CLASSIFICATION,//  get the avgLen 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.ICLIService#getCrossReference(org.apache.hive.service.cli.SessionHandle)    */
Hive,WITHOUT_CLASSIFICATION,//  Try to deserialize 
Hive,WITHOUT_CLASSIFICATION,//  Have at least 1 non-blank; Skip trailing blank characters. 
Hive,WITHOUT_CLASSIFICATION,//  This check is for controlling the correctness of the current state 
Hive,WITHOUT_CLASSIFICATION,//  could be changed in local execution optimization 
Hive,WITHOUT_CLASSIFICATION,//  set other table properties 
Hive,WITHOUT_CLASSIFICATION,// small optimization - delete delta can't be in raw format 
Hive,WITHOUT_CLASSIFICATION,//  HTTP mode 
Hive,WITHOUT_CLASSIFICATION,//  Retrieve the user name do the final validation step. 
Hive,WITHOUT_CLASSIFICATION,//  if not see if the mesg follows type of format which is typically the   case: 
Hive,WITHOUT_CLASSIFICATION,//  And we have their type infos. 
Hive,WITHOUT_CLASSIFICATION,//  generate the map join operator 
Hive,WITHOUT_CLASSIFICATION,//  Verify escaped partition names don't return partitions 
Hive,WITHOUT_CLASSIFICATION,//  UDAF is assumed to be deterministic 
Hive,WITHOUT_CLASSIFICATION,//  Verify we added an entry for each output. 
Hive,WITHOUT_CLASSIFICATION,//  Convert the bucket map-join operator to a sort-merge map join operator 
Hive,WITHOUT_CLASSIFICATION,//  Not supported for MM tables - sampler breaks separate MM dirs into splits resulting in   mismatch when the downstream task looks at them again assuming they are MM table roots.   We could somehow unset the MM flag for the main job when the sampler succeeds since the   sampler will limit the input to the the correct directories but we don't care about MR. 
Hive,WITHOUT_CLASSIFICATION,//  The context table name can be null if repl load is done on a full db.   But we need table name for alloc write id and that is received from source. 
Hive,WITHOUT_CLASSIFICATION,//  the result is the last 1 character which occupies 4 bytes 
Hive,WITHOUT_CLASSIFICATION,//  update based on the final value of the counters 
Hive,WITHOUT_CLASSIFICATION,//  simply dispatch the call to the right method for the actual (sub-) type of   BaseWork. 
Hive,WITHOUT_CLASSIFICATION,//  Create a mapping from the group by columns to the table columns 
Hive,WITHOUT_CLASSIFICATION,//  1. Generate the statement of analyze table [tablename] compute statistics for columns   In non-partitioned table case it will generate TS-SEL-GBY-RS-GBY-SEL-FS operator   In static-partitioned table case it will generate TS-FIL(partitionKey)-SEL-GBY(partitionKey)-RS-GBY-SEL-FS operator   In dynamic-partitioned table case it will generate TS-SEL-GBY(partitionKey)-RS-GBY-SEL-FS operator   However we do not need to specify the partition-spec because (1) the data is going to be inserted to that specific partition   (2) we can compose the static/dynamic partition using a select operator in replaceSelectOperatorProcess.. 
Hive,WITHOUT_CLASSIFICATION,//  timestamp scalar/column 
Hive,WITHOUT_CLASSIFICATION,//  We just had leading zeroes (and possibly a dot and trailing blanks).   Value is 0. 
Hive,WITHOUT_CLASSIFICATION,//  Get the next "inList" value element if needed. 
Hive,WITHOUT_CLASSIFICATION,//  Do formal conversion... 
Hive,WITHOUT_CLASSIFICATION,//  Create a new union operator 
Hive,WITHOUT_CLASSIFICATION,//  UNDONE: Also remember virtualColumnCount... 
Hive,WITHOUT_CLASSIFICATION,//  The input timestamps are stored as long values 
Hive,WITHOUT_CLASSIFICATION,//  partitioned insert 
Hive,WITHOUT_CLASSIFICATION,//  Write id has changed it is not valid anymore   we need to recompile 
Hive,WITHOUT_CLASSIFICATION,//  Do not remove the parameter yet because we have separate initialization routine   that will use it down below. 
Hive,WITHOUT_CLASSIFICATION,//  4. Extract join key expressions from HiveSortExchange 
Hive,WITHOUT_CLASSIFICATION,//  requested. 
Hive,WITHOUT_CLASSIFICATION,//  in HiveSparkClientFactory 
Hive,WITHOUT_CLASSIFICATION,//  Check that we don't find unexpected columns 
Hive,WITHOUT_CLASSIFICATION,//  JDBC URL: jdbc:hive2://<host>:<port>/dbName;sess_var_list?hive_conf_list#hive_var_list   each list: <key1>=<val1>;<key2>=<val2> and so on   sess_var_list -> sessConfMap   hive_conf_list -> hiveConfMap   hive_var_list -> hiveVarMap 
Hive,WITHOUT_CLASSIFICATION,//  check if the partition exists (it shouldn't) 
Hive,WITHOUT_CLASSIFICATION,//  CATALOG 
Hive,WITHOUT_CLASSIFICATION,// this simulates the completion of "delete from tab1" txn 
Hive,WITHOUT_CLASSIFICATION,//  We copied the entire buffer. 
Hive,WITHOUT_CLASSIFICATION,//  We will be using this for each RG while also sending RGs to processing.   To avoid buffers being unlocked run refcount one ahead; so each RG  
Hive,WITHOUT_CLASSIFICATION,//  Check that all the outputs have been processed; if not insert them into queue   before the current vertex and try again. It's possible e.g. in a structure like this:     _1    / 2   3  4 where 1 may be added to the queue before 2 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise we can reuse the session. Either the kill has failed but the user managed to   return early (in fact can it fail because the query has completed earlier?) or the user 
Hive,WITHOUT_CLASSIFICATION,//  no files at all 
Hive,WITHOUT_CLASSIFICATION,//  CAT_NAME 
Hive,WITHOUT_CLASSIFICATION,//  1. Build map of column name to col index of original schema   Assumption: Hive Table can not contain duplicate column names 
Hive,WITHOUT_CLASSIFICATION,//  The map we're building. 
Hive,WITHOUT_CLASSIFICATION,//  Determine maximum of all non-null decimal column values; maintain isGroupResultNull. 
Hive,WITHOUT_CLASSIFICATION,//  Ignore errors in SSL tests where the connection is misconfigured. 
Hive,WITHOUT_CLASSIFICATION,//  Add filters that apply to more than one input 
Hive,WITHOUT_CLASSIFICATION,//  New metadata always have two parameters. 
Hive,WITHOUT_CLASSIFICATION,//  If the bucket id set component of this data structure proves to be too large there is the   option of moving it to Trove or HPPC in an effort to reduce size. 
Hive,WITHOUT_CLASSIFICATION,//  Copy the padding 
Hive,WITHOUT_CLASSIFICATION,//  The caller could re-check the location but would probably find it locked. 
Hive,WITHOUT_CLASSIFICATION,//  For SEL-SEL(compute) case move column exprs/names of child to parent. 
Hive,WITHOUT_CLASSIFICATION,//  found a DP but there exists ST as subpartition 
Hive,WITHOUT_CLASSIFICATION,//  Timer will be null we aren't using the metrics 
Hive,WITHOUT_CLASSIFICATION,// Found child mapjoin operator.  Its size should already reflect any mapjoins connected to it so stop processing. 
Hive,WITHOUT_CLASSIFICATION,//  TODO Implement to remove all watches for the specified pathString and it's sub-tree 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.operation.Operation#getNextRowSet(org.apache.hive.service.cli.FetchOrientation long)    */
Hive,WITHOUT_CLASSIFICATION,//  No input data. 
Hive,WITHOUT_CLASSIFICATION,//  Default serialization format. 
Hive,WITHOUT_CLASSIFICATION,//  which case user the latter match. 
Hive,WITHOUT_CLASSIFICATION,//  Fill up host1 with p2 tasks.   Leave host2 empty   Try running p1 task on host1 - should preempt 
Hive,WITHOUT_CLASSIFICATION,//  aggregates in group-by. 
Hive,WITHOUT_CLASSIFICATION,//  Unpartitioned table writing to the scratch dir directly is good enough. 
Hive,WITHOUT_CLASSIFICATION,//  Now try to pick another task to update - or potentially the same task. 
Hive,WITHOUT_CLASSIFICATION,//  2.2 Convert ExprNode to RexNode 
Hive,WITHOUT_CLASSIFICATION,// since conflicting txn rolled back commit succeeds 
Hive,WITHOUT_CLASSIFICATION,//  If the directory needs to be changed send the new directory 
Hive,WITHOUT_CLASSIFICATION,//  sizes 
Hive,WITHOUT_CLASSIFICATION,//  If the table is not partitioned return empty list. 
Hive,WITHOUT_CLASSIFICATION,//  Turn on mocked authorization 
Hive,WITHOUT_CLASSIFICATION,//       LOG.info("Args to har : "+ arg);      } 
Hive,WITHOUT_CLASSIFICATION,//  Return zz for "xx.zz" and "xx.yy.zz" 
Hive,WITHOUT_CLASSIFICATION,//  3. Get Calcite Return type for Agg Fn 
Hive,WITHOUT_CLASSIFICATION,//  Handle in next round. 
Hive,WITHOUT_CLASSIFICATION,//  The sorting columns of the child RS are more specific than   those of the parent RS. Assign sorting columns of the child RS   to the parent RS. 
Hive,WITHOUT_CLASSIFICATION,//  this relates to db level event tracked via databaseEventProcessed 
Hive,WITHOUT_CLASSIFICATION,//  all done parsing let's run stuff! 
Hive,WITHOUT_CLASSIFICATION,//  Build the versions list. 
Hive,WITHOUT_CLASSIFICATION,//  File is successfully copied just skip this file from retry. 
Hive,WITHOUT_CLASSIFICATION,// All must be selected otherwise size would be zero  Repeating property will not change. 
Hive,WITHOUT_CLASSIFICATION,//  will make sure the task's place in the wait queue is held until it gets scheduled. 
Hive,WITHOUT_CLASSIFICATION,//  Just spot check because we already checked the logic for long.   The code is from the same template file. 
Hive,WITHOUT_CLASSIFICATION,//  Copy in remainder digits... which start at the top of remainder2. 
Hive,WITHOUT_CLASSIFICATION,/*      * We want to resolve the leftmost name to the Parent Query's RR.     * Hence we do a left walk down the AST until we reach the bottom most DOT.      */
Hive,WITHOUT_CLASSIFICATION,//  no begin + write 
Hive,WITHOUT_CLASSIFICATION,//  repeated int32 lint = 3; 
Hive,WITHOUT_CLASSIFICATION,// since there is txn open we are heartbeating the txn not individual locks 
Hive,WITHOUT_CLASSIFICATION,//  for persistent function   if the function is dropped all functions registered to sessions are needed to be reloaded 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setNCharacterStream(int java.io.Reader   * long)    */
Hive,WITHOUT_CLASSIFICATION,// Need shut down background thread gracefully driver.close will inform background thread  a cancel request is sent. 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: Calcite considers tbls to be equal if their names are the same. Hence   we need to provide Calcite the fully qualified table name (dbname.tblname)   and not the user provided aliases.   However in HIVE DB name can not appear in select list; in case of join   where table names differ only in DB name Hive would require user 
Hive,WITHOUT_CLASSIFICATION,// re-test the locks 
Hive,WITHOUT_CLASSIFICATION,//  Configure http client for cookie based authentication 
Hive,WITHOUT_CLASSIFICATION,//  build the resultset from response 
Hive,WITHOUT_CLASSIFICATION,//  no worker identity 
Hive,WITHOUT_CLASSIFICATION,//  input rel. 
Hive,WITHOUT_CLASSIFICATION,//  in this case we need to get the working directory   and this requires a FileSystem handle. So revert to   original method. 
Hive,WITHOUT_CLASSIFICATION,//  verify table not fuond error 
Hive,WITHOUT_CLASSIFICATION,//  If the given Task is a SparkTask then search its Work DAG for SparkPartitionPruningSinkOperator 
Hive,WITHOUT_CLASSIFICATION,//  Try underlying client 
Hive,WITHOUT_CLASSIFICATION,//  2. Obtain Col Stats for Non Partition Cols 
Hive,WITHOUT_CLASSIFICATION,//  Either we got the tablename from the IMPORT statement (first priority)   or from the export dump. 
Hive,WITHOUT_CLASSIFICATION,//  add ".*" to the regex to match anything else afterwards the partial spec. 
Hive,WITHOUT_CLASSIFICATION,//  Spark configurations are updated close the existing session   In case of async queries or confOverlay is not empty   sessionConf and conf are different objects 
Hive,WITHOUT_CLASSIFICATION,//  2.2.1 Maintain join keys (in child & Join Schema)   2.2.2 Update Join Key to JoinLeafPredicateInfo map with keys 
Hive,WITHOUT_CLASSIFICATION,//  1. Find our bearings in the stream. 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * This processor addresses the RS-MJ case that occurs in spark on the small/hash   * table side of things. The work that RS will be a part of must be connected   * to the MJ work via be a broadcast edge.   * We should not walk down the tree when we encounter this pattern because:   * the type of work (map work or reduce work) needs to be determined   * on the basis of the big table side because it may be a mapwork (no need for shuffle)   * or reduce work.    */
Hive,WITHOUT_CLASSIFICATION,//  TODO: Handle replication of changes to Table-STATS. 
Hive,WITHOUT_CLASSIFICATION,//  Check LLAP-aware split (e.g. OrcSplit) to make sure it's compatible. 
Hive,WITHOUT_CLASSIFICATION,//  n-way: all later small tables 
Hive,WITHOUT_CLASSIFICATION,// this doesn't create a key index presumably because writerOptions are not set on 'options' 
Hive,WITHOUT_CLASSIFICATION,//  get column 
Hive,WITHOUT_CLASSIFICATION,//  We are the last of the concurrent operations to finish. Commit. 
Hive,WITHOUT_CLASSIFICATION,//  Consolidation since all leaves are required. 
Hive,WITHOUT_CLASSIFICATION,//  should set "-foo bar"   should set "-blah"   should be ignored. 
Hive,WITHOUT_CLASSIFICATION,/*    * a subclass must provide the {@link TableFunctionEvaluator} instance.    */
Hive,WITHOUT_CLASSIFICATION,//  add partition keys to table schema   NOTE : this assumes that we do not ever have ptn keys as columns   inside the table schema as well! 
Hive,WITHOUT_CLASSIFICATION,//  unix_timestamp is polymorphic (ignore class annotations) 
Hive,WITHOUT_CLASSIFICATION,//  10^18 - 1 
Hive,WITHOUT_CLASSIFICATION,//  TEMPORARY Until Native Vector Map Join with Hybrid passes tests...   HiveConf.setBoolVar(physicalContext.getConf()      HiveConf.ConfVars.HIVEUSEHYBRIDGRACEHASHJOIN false); 
Hive,WITHOUT_CLASSIFICATION,//  Get the databases 
Hive,WITHOUT_CLASSIFICATION,//  write three files in partition 1 
Hive,WITHOUT_CLASSIFICATION,//  If columns is null then we need to create the leaf 
Hive,WITHOUT_CLASSIFICATION,//  Functions like NVL COALESCE CASE can change a    NULL introduced by a nonpart column removal into a non-null   and cause overaggressive prunning missing data (incorrect result) 
Hive,WITHOUT_CLASSIFICATION,//  input pruning is enough; add the filter for the optimizer to use it   later 
Hive,WITHOUT_CLASSIFICATION,//  for SMB join replaced with number part of task-id  making output file name   if big alias is not partitioned table it's bucket number 
Hive,WITHOUT_CLASSIFICATION,// If HADOOP_PROXY_USER is set in env or property 
Hive,WITHOUT_CLASSIFICATION,//  Worth waiting for the timeout. 
Hive,WITHOUT_CLASSIFICATION,//  [-version|--version] 
Hive,WITHOUT_CLASSIFICATION,//  submit to accept dag (if session is closed this will include re-opening of session time 
Hive,WITHOUT_CLASSIFICATION,/*            * No realativeOffsetWord in last value.  (This was the first value written.)            */
Hive,WITHOUT_CLASSIFICATION,//  should be final but Writable 
Hive,WITHOUT_CLASSIFICATION,// col_old_name col_new_name column_type [COMMENT col_comment] [FIRST|AFTER column_name] [CASCADE|RESTRICT] 
Hive,WITHOUT_CLASSIFICATION,//  http://docs.guava-libraries.googlecode.com/git/javadoc/com/google/common/cache/CacheBuilder.html 
Hive,WITHOUT_CLASSIFICATION,//  Count the tasks in intermediate state as waiting. 
Hive,WITHOUT_CLASSIFICATION,//  Case 1: NO column stats NO hash aggregation NO grouping sets 
Hive,WITHOUT_CLASSIFICATION,//  REWRITE_ENABLED 
Hive,WITHOUT_CLASSIFICATION,//  Check that the data still exist 
Hive,WITHOUT_CLASSIFICATION,//  Meh. 
Hive,WITHOUT_CLASSIFICATION,//  leftTree != null 
Hive,WITHOUT_CLASSIFICATION,//  if partition and bucket columns are sorted in ascending order by default 
Hive,WITHOUT_CLASSIFICATION,//  ////// Generate ReduceSinkOperator2 
Hive,WITHOUT_CLASSIFICATION,//  Submit spark job through local spark context while spark master is local mode otherwise submit   spark job through remote spark context. 
Hive,WITHOUT_CLASSIFICATION,//  Connect this TableScanOperator to child. 
Hive,WITHOUT_CLASSIFICATION,//  DataOutputStream to BytesWritable 
Hive,WITHOUT_CLASSIFICATION,//  1. Test with doAs=false 
Hive,WITHOUT_CLASSIFICATION,/*  first_name in      ('john' 'sue')  */
Hive,WITHOUT_CLASSIFICATION,//  WEIGHT 
Hive,WITHOUT_CLASSIFICATION,/*       * this allows doAs (proxy user) to be passed along across process boundary where      * delegation tokens are not supported.  For example a DDL stmt via WebHCat with      * a doAs parameter forks to 'hcat' which needs to start a Session that      * proxies the end user       */
Hive,WITHOUT_CLASSIFICATION,//  Otherwise just leave it up to Tez to decide how much memory to allocate 
Hive,WITHOUT_CLASSIFICATION,//  Clone readerOptions for deleteEvents. 
Hive,WITHOUT_CLASSIFICATION,/*        * For submit operation tasks are not cancelled. Verify that new job request       * should fail with TooManyRequestsException.        */
Hive,WITHOUT_CLASSIFICATION,// No partitions match the specified partition filter 
Hive,WITHOUT_CLASSIFICATION,/*              * Common inner join result processing.              */
Hive,WITHOUT_CLASSIFICATION,//  Nothing to do here... 
Hive,WITHOUT_CLASSIFICATION,//  versioning (adding/deleting fields). 
Hive,WITHOUT_CLASSIFICATION,//  Remove nested DPPs 
Hive,WITHOUT_CLASSIFICATION,//  The dispatcher fires the processor corresponding to the closest matching rule and passes the context along 
Hive,WITHOUT_CLASSIFICATION,/*  Object Inspectors corresponding to the struct returned by TerminatePartial and the     * fields within the struct - "maxLength" "sumLength" "count" "countNulls" "ndv"      */
Hive,WITHOUT_CLASSIFICATION,//  compute groupby columns from groupby keys 
Hive,WITHOUT_CLASSIFICATION,/*  helper function to allow Set()/Collection() operations with ExprNodeDesc  */
Hive,WITHOUT_CLASSIFICATION,//  make sure that file does not exist 
Hive,WITHOUT_CLASSIFICATION,//  The retainAll method does set intersection. 
Hive,WITHOUT_CLASSIFICATION,//  Test for user "neo" 
Hive,WITHOUT_CLASSIFICATION,//  Add constraints if necessary 
Hive,WITHOUT_CLASSIFICATION,//  Initialize footer buffer. 
Hive,WITHOUT_CLASSIFICATION,// Output 
Hive,WITHOUT_CLASSIFICATION,/*      * This method is to check if the new column list includes all the old columns with same name and     * type. The column comment does not count.      */
Hive,WITHOUT_CLASSIFICATION,/* Case we are partitioning the segments based on time and max row per segment maxPartitionSize */
Hive,WITHOUT_CLASSIFICATION,//  Pull out the first table from the "show extended" json. 
Hive,WITHOUT_CLASSIFICATION,//  For all the other column groups generate new values down. 
Hive,WITHOUT_CLASSIFICATION,//  1. Setup TableScan Desc 
Hive,WITHOUT_CLASSIFICATION,//  but we assume it's extremely rare for individual partitions. 
Hive,WITHOUT_CLASSIFICATION,//  while and should be done when we start up. 
Hive,WITHOUT_CLASSIFICATION,//  Get the single TableScanOperator.  Vectorization only supports one input tree. 
Hive,WITHOUT_CLASSIFICATION,// passing "creds" prevents duplicate tokens from being added 
Hive,WITHOUT_CLASSIFICATION,//  Make sure we don't compact if we don't need to compact; but do if we do. 
Hive,WITHOUT_CLASSIFICATION,//  FULL_TABLE_NAME 
Hive,WITHOUT_CLASSIFICATION,//  Due to HIVE-6404 define our own constant 
Hive,WITHOUT_CLASSIFICATION,//  session.open will unset the queue name from conf but Mockito intercepts the open call 
Hive,WITHOUT_CLASSIFICATION,//  long/double/decimal 
Hive,WITHOUT_CLASSIFICATION,// if row is null it means there are no more rows (closeOp()). another case can be that the buffer is full. 
Hive,WITHOUT_CLASSIFICATION,//  Give the outThread a chance to finish before marking the operator as done 
Hive,WITHOUT_CLASSIFICATION,/*    * Tests whether credential provider is updated when HIVE_JOB_CREDSTORE_PASSWORD is set and when   * hiveConf sets HiveConf.ConfVars.HIVE_SERVER2_JOB_CREDSTORE_LOCATION   *   * JobConf should contain the mapred env variable equal to ${HIVE_JOB_CREDSTORE_PASSWORD} and the   * hadoop.security.credential.provider.path property should be equal to value of   * HiveConf.ConfVars.HIVE_SERVER2_JOB_CREDSTORE_LOCATION    */
Hive,WITHOUT_CLASSIFICATION,/*              * Feed current full batch to operator tree.              */
Hive,WITHOUT_CLASSIFICATION,//  If any table/partition is updated then update repl state in table object 
Hive,WITHOUT_CLASSIFICATION,//  fetch remaining logs 
Hive,WITHOUT_CLASSIFICATION,//  . After the join only selects and filters are allowed. 
Hive,WITHOUT_CLASSIFICATION,//  This might be a deadlock if so let's retry 
Hive,WITHOUT_CLASSIFICATION,//  delete jars added using query2 
Hive,WITHOUT_CLASSIFICATION,//  Setup client side split generation. 
Hive,WITHOUT_CLASSIFICATION,//  If type for column and constant are different we currently do not support pushing them 
Hive,WITHOUT_CLASSIFICATION,//  Now add the key wrapper arrays 
Hive,WITHOUT_CLASSIFICATION,//  Have a non-NULL value on hand. 
Hive,WITHOUT_CLASSIFICATION,//  Lock should be freed up now. 
Hive,WITHOUT_CLASSIFICATION,//  Run Compaction Worker to do compaction.   But we do not compact a MM table but only transit the compaction request to 
Hive,WITHOUT_CLASSIFICATION,//  For a list the value and key lengths of 1st record were overwritten with the   relative offset to a new list record. 
Hive,WITHOUT_CLASSIFICATION,//  NOT selectedInUse 
Hive,WITHOUT_CLASSIFICATION,//  FROM_EVENT_ID 
Hive,WITHOUT_CLASSIFICATION,//  We've switched to Joda/Java Calendar which has a more limited time range.... 
Hive,WITHOUT_CLASSIFICATION,//  This assumes the distribution of variable size keys/aggregates in the input   is the same as the distribution of variable sizes in the hash entries 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#getClientInfo(java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,/*     Sets up a TaskSpec which has vertex1 as it's input and tasks belonging to vertex2      */
Hive,WITHOUT_CLASSIFICATION,//  Do another loop if table is bucketed 
Hive,WITHOUT_CLASSIFICATION,//  We succeeded in adding all the values so 
Hive,WITHOUT_CLASSIFICATION,//  return type should have same length as the input. 
Hive,WITHOUT_CLASSIFICATION,/*    * Only for testing    */
Hive,WITHOUT_CLASSIFICATION,//  This is our use case of not having passwords stored in in the clear in hive conf files. 
Hive,WITHOUT_CLASSIFICATION,//  priority = 20 / (3000 - 100) = 0.0069 
Hive,WITHOUT_CLASSIFICATION,//  for hive udtf operator 
Hive,WITHOUT_CLASSIFICATION,//  We were going to kill some queries and reuse the sessions or maybe restart and put the new   ones back into the AM pool. However the AM pool has shrunk so we will close them instead. 
Hive,WITHOUT_CLASSIFICATION,//  We will test the reconfiguration of the header size by changing the password length. 
Hive,WITHOUT_CLASSIFICATION,//  The lower bits are the absolute value offset. 
Hive,WITHOUT_CLASSIFICATION,//  All are null so none are selected 
Hive,WITHOUT_CLASSIFICATION,//  need to remove by hive .13. Also do not change default (see SMB operator) 
Hive,WITHOUT_CLASSIFICATION,//  the system properties. 
Hive,WITHOUT_CLASSIFICATION,//       LOG.info("Nuking " + dir); 
Hive,WITHOUT_CLASSIFICATION,//  Compute the values 
Hive,WITHOUT_CLASSIFICATION,//  Original bucket files delta directory and delete_delta should have been cleaned up. 
Hive,WITHOUT_CLASSIFICATION,//  Modify partition column type and comment 
Hive,WITHOUT_CLASSIFICATION,// what I want is order by cc_end desc cc_start asc (but derby has a bug https://issues.apache.org/jira/browse/DERBY-6013)  to sort so that currently running jobs are at the end of the list (bottom of screen)  and currently running ones are in sorted by start time 
Hive,WITHOUT_CLASSIFICATION,//  Hive doesn't have the concept of not-null 
Hive,WITHOUT_CLASSIFICATION,//  Check if we start to forward rows to a new child.   If so in the current key group rows will not be forwarded   to those children which have an index less than the currentChildIndex.   We can call flush the buffer of children from lastChildIndex (inclusive)   to currentChildIndex (exclusive) and propagate processGroup to those children. 
Hive,WITHOUT_CLASSIFICATION,//  Split into 16 digit middle and lowest longwords remainder / division. 
Hive,WITHOUT_CLASSIFICATION,//  scrutinize escape pair specifically replace \' to ' 
Hive,WITHOUT_CLASSIFICATION,// would be useful to have enum for Type: insert/delete/load data 
Hive,WITHOUT_CLASSIFICATION,//  denseColIx is index in ORC writer with includes. We -1 to skip the root column; get the   original text file index; then add the root column again. This makes many assumptions.   Also this only works for primitive types; vectordeserializer only supports these anyway.   The mapping for complex types with sub-cols in ORC would be much more difficult to build. 
Hive,WITHOUT_CLASSIFICATION,/*      * Restriction.8.m :: We allow only 1 SubQuery expression per Query.      */
Hive,WITHOUT_CLASSIFICATION,//  3. Outside   we need to create a new limit 0 
Hive,WITHOUT_CLASSIFICATION,//  Set generic options 
Hive,WITHOUT_CLASSIFICATION,/*    * Hive syntax allows to define CASE expressions in two ways:   * - CASE a WHEN b THEN c [WHEN d THEN e]* [ELSE f] END (translated into the   *   "case" function ELSE clause is optional)   * - CASE WHEN a THEN b [WHEN c THEN d]* [ELSE e] END (translated into the   *   "when" function ELSE clause is optional)   * However Calcite only has the equivalent to the "when" Hive function. Thus   * we need to transform the "case" function into "when". Further ELSE clause is   * not optional in Calcite.   *   * Example. Consider the following statement:   * CASE x + y WHEN 1 THEN 'fee' WHEN 2 THEN 'fie' END   * It will be transformed into:   * CASE WHEN =(x + y 1) THEN 'fee' WHEN =(x + y 2) THEN 'fie' ELSE null END    */
Hive,WITHOUT_CLASSIFICATION,/*          * Multi-Key specific repeated lookup.          */
Hive,WITHOUT_CLASSIFICATION,//  shamelessly copied from Path in hadoop-2 
Hive,WITHOUT_CLASSIFICATION,//  * ambiguous case which should be assumed is 3-level according to spec 
Hive,WITHOUT_CLASSIFICATION,//  scalar/scalar IF 
Hive,WITHOUT_CLASSIFICATION,//  pretend that one field is used. 
Hive,WITHOUT_CLASSIFICATION,//  Buffer is at the leaf node. 
Hive,WITHOUT_CLASSIFICATION,//  just drop transactional=false.  For backward compatibility in case someone has scripts   with transactional=false 
Hive,WITHOUT_CLASSIFICATION,//  2. We create the join aux structures 
Hive,WITHOUT_CLASSIFICATION,//  operator (below) 
Hive,WITHOUT_CLASSIFICATION,/* Some HiveExceptions (e.g. SemanticException) don't set          canonical ErrorMsg explicitly but there is logic          (e.g. #compile()) to find an appropriate canonical error and          return its code as error code. In this case we want to          preserve it for downstream code to interpret */
Hive,WITHOUT_CLASSIFICATION,//  the update statement (remember split-update U=D+I)! 
Hive,WITHOUT_CLASSIFICATION,//  Free up the HTable connections 
Hive,WITHOUT_CLASSIFICATION,//  Only a single double was passed as parameter 2 a single quantile is being requested 
Hive,WITHOUT_CLASSIFICATION,//  col > -1 
Hive,WITHOUT_CLASSIFICATION,/*    * build:   *          ^(TOK_WHERE   *             {is null check for joining column}    *           )    */
Hive,WITHOUT_CLASSIFICATION,//  A type date (LongColumnVector storing epoch days) minus a type date produces a   type interval_day_time (IntervalDayTimeColumnVector storing nanosecond interval in 2 longs). 
Hive,WITHOUT_CLASSIFICATION,/*    * Initialize using an ObjectInspector array and a column projection array.    */
Hive,WITHOUT_CLASSIFICATION,//  All columns: data partition and virtual are added. 
Hive,WITHOUT_CLASSIFICATION,//  unlimited lifetime 
Hive,WITHOUT_CLASSIFICATION,//  Parse out the kerberos principal host realm. 
Hive,WITHOUT_CLASSIFICATION,//  Copy credentials and any new config added back to JobContext 
Hive,WITHOUT_CLASSIFICATION,//  This type of VectorizedOrcAcidRowBatchReader can only be created when split-update is 
Hive,WITHOUT_CLASSIFICATION,//  obtain delegation token for the give user from metastore 
Hive,WITHOUT_CLASSIFICATION,//  list of paths that don't need to merge but need to move to the dest location 
Hive,WITHOUT_CLASSIFICATION,//  Exception expected 
Hive,WITHOUT_CLASSIFICATION,// Negative tests 
Hive,WITHOUT_CLASSIFICATION,//  Sort itself should not reference cor vars. 
Hive,WITHOUT_CLASSIFICATION,//  additional bookkeeping info for the stored stats 
Hive,WITHOUT_CLASSIFICATION,//  call-1: open to read - split 1 => mock:/mocktable1/0_0 
Hive,WITHOUT_CLASSIFICATION,//  7. Return result 
Hive,WITHOUT_CLASSIFICATION,//  add the bits to the bottom of the current word 
Hive,WITHOUT_CLASSIFICATION,//  then remove all the grants 
Hive,WITHOUT_CLASSIFICATION,//  fractional part has starting with zeros 
Hive,WITHOUT_CLASSIFICATION,//  create table as select 
Hive,WITHOUT_CLASSIFICATION,//  Ensure the correct task was preempted. 
Hive,WITHOUT_CLASSIFICATION,//  Note : The reason this method exists outside the no-arg getDeserializer method is in   case there is a user-implemented MessageFactory that's used and some the messages   are in an older format and the rest in another. Then what MessageFactory is default   is irrelevant we should always use the one that was used to create it to deserialize.     There exist only 2 implementations of this - json and jms     Additional note : rather than as a config parameter does it make sense to have   this use jdbc-like semantics that each MessageFactory made available register   itself for discoverability? Might be worth pursuing. 
Hive,WITHOUT_CLASSIFICATION,//  Set bit in NULL byte when a field is NOT NULL. 
Hive,WITHOUT_CLASSIFICATION,//  1.5% tolerance for long range bias (when no bias enabled) and 5% when (no   bias is disabled) and   0.5% for short range bias 
Hive,WITHOUT_CLASSIFICATION,//  extract the raw data size and update the stats for the current partition 
Hive,WITHOUT_CLASSIFICATION,//  Don't evaluate nondeterministic function since the value can only calculate during runtime. 
Hive,WITHOUT_CLASSIFICATION,//  Since the output of the UDTF is a struct we can just forward that 
Hive,WITHOUT_CLASSIFICATION,//  Get the standard ObjectInspector of the row 
Hive,WITHOUT_CLASSIFICATION,//  Test a single high-precision divide of random inputs. 
Hive,WITHOUT_CLASSIFICATION,//  Add it to result in order we are processing. 
Hive,WITHOUT_CLASSIFICATION,//  Get col object out 
Hive,WITHOUT_CLASSIFICATION,//  testcase.testWithColumnNumber(count 2 checkCorrect codec);   testcase.testWithColumnNumber(count 10 checkCorrect codec); 
Hive,WITHOUT_CLASSIFICATION,//  If the child is also decimal no cast is needed (we hope - can target type be narrower?). 
Hive,WITHOUT_CLASSIFICATION,//  replace-overwrite introduces no new files 
Hive,WITHOUT_CLASSIFICATION,// In DbTxnManager.acquireLocks() we have   1 ReadEntity: default@values__tmp__table__1 
Hive,WITHOUT_CLASSIFICATION,//  check if the sample columns are the same as the table bucket columns 
Hive,WITHOUT_CLASSIFICATION,//    throw new HiveException("allMatchs is not in sort order and unique");   } 
Hive,WITHOUT_CLASSIFICATION,//  Inform the routing purgePolicy.   Send out a fake log message at the ERROR level with the MDC for this query setup. With an   LLAP custom appender this message will not be logged. 
Hive,WITHOUT_CLASSIFICATION,//  desired parallelism of the reduce task. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *    * @see   * org.apache.hadoop.hive.ql.udf.ptf.TableFunctionEvaluator#canAcceptInputAsStream   * ()   *    * WindowTableFunction supports streaming if all functions meet one of these   * conditions: 1. The Function implements ISupportStreamingModeForWindowing 2.   * Or returns a non null Object for the getWindowingEvaluator that implements   * ISupportStreamingModeForWindowing. 3. Is an invocation on a 'fixed' window.   * So no Unbounded Preceding or Following.    */
Hive,WITHOUT_CLASSIFICATION,//  Test that write blocks write but read can still acquire 
Hive,WITHOUT_CLASSIFICATION,/*              * Single-Column Long outer get key.              */
Hive,WITHOUT_CLASSIFICATION,//  Since right has a longer digit tail and it doesn't move; we will shift the left digits   as we do our addition into the result. 
Hive,WITHOUT_CLASSIFICATION,//  If old table is *not* in the cache but the new table can be cached 
Hive,WITHOUT_CLASSIFICATION,//  interval types can use long version 
Hive,WITHOUT_CLASSIFICATION,//  2. Convert NONACIDORCTBL to ACID table 
Hive,WITHOUT_CLASSIFICATION,//  Don't set dagClient to null here - execute will only clean up operators if it's set. 
Hive,WITHOUT_CLASSIFICATION,//  Should only be called for testing. 
Hive,WITHOUT_CLASSIFICATION,//  make one entry produce false in result 
Hive,WITHOUT_CLASSIFICATION,//  Add INT values 
Hive,WITHOUT_CLASSIFICATION,//  Empty string 
Hive,WITHOUT_CLASSIFICATION,//  Timestamps are stored as long so convert and compare 
Hive,WITHOUT_CLASSIFICATION,//  If we get past this then the column name did match the hive pattern for an internal   column name such as _col0 etc so it *MUST* match the schema for the appropriate column.   This means people can't use arbitrary column names such as _col0 and expect us to ignore it 
Hive,WITHOUT_CLASSIFICATION,//  return worst case if unknown 
Hive,WITHOUT_CLASSIFICATION,//  internal names. 
Hive,WITHOUT_CLASSIFICATION,//  Remove unnecessary information from target 
Hive,WITHOUT_CLASSIFICATION,//  auto-determine local mode if allowed 
Hive,WITHOUT_CLASSIFICATION,//  Try the basic test with non-chunked stream 
Hive,WITHOUT_CLASSIFICATION,//  REPL DUMP 
Hive,WITHOUT_CLASSIFICATION,// done - output does not need to be committed as hive does not use outputcommitter 
Hive,WITHOUT_CLASSIFICATION,//  Transaction states 
Hive,WITHOUT_CLASSIFICATION,//  list the current connections 
Hive,WITHOUT_CLASSIFICATION,//  This map is used for set the stats flag for the cloned FileSinkOperators in later process 
Hive,WITHOUT_CLASSIFICATION,//  convert the partition filter expression into a string expected by   hcat and pass it in setLocation() 
Hive,WITHOUT_CLASSIFICATION,//  Type doesn't require any qualifiers. 
Hive,WITHOUT_CLASSIFICATION,// start reading role names from next position 
Hive,WITHOUT_CLASSIFICATION,//  We do not know what it is we bail out for safety 
Hive,WITHOUT_CLASSIFICATION,//  not a column 
Hive,WITHOUT_CLASSIFICATION,//  Make sure I can add it back 
Hive,WITHOUT_CLASSIFICATION,//  Disable it to avoid verbose app state report in yarn-cluster mode 
Hive,WITHOUT_CLASSIFICATION,//  Case 4: Test with originals and deltas but now with only one bucket covered i.e. we will   have originals & insert_deltas for only one bucket but the delete_deltas will be for two   buckets => Two strategies with one split for each.   When split-update is enabled we do not need to account for buckets that aren't covered.   The reason why we are able to do so is because the valid user data has already been considered   as base for the covered buckets. Hence the uncovered buckets do not have any relevant 
Hive,WITHOUT_CLASSIFICATION,// check first otherwise webhcat.log is full of stack traces from FileSystem when  clients check for status ('exitValue' 'completed' etc.) 
Hive,WITHOUT_CLASSIFICATION,//  Remove the previously peeked element. 
Hive,WITHOUT_CLASSIFICATION,//  ignore if the parent already exists 
Hive,WITHOUT_CLASSIFICATION,//  construct valueTableDescs and valueFilteredTableDescs 
Hive,WITHOUT_CLASSIFICATION,//  Offset before which this RG is guaranteed to end. Can only be estimated. 
Hive,WITHOUT_CLASSIFICATION,//  Return greater than because of left's digits below right's scale. 
Hive,WITHOUT_CLASSIFICATION,//  Creation time will be set by server and not us. 
Hive,WITHOUT_CLASSIFICATION,//  This flow is usually taken for IMPORT command 
Hive,WITHOUT_CLASSIFICATION,//  CONSIDER: Cleaning up this code and eliminating the arrays.  Vectorization only handles   one operator tree. 
Hive,WITHOUT_CLASSIFICATION,//  Ignore starting quote 
Hive,WITHOUT_CLASSIFICATION,//  MySQL returns 0 if the string is not a well-formed numeric value.   return IntWritable.valueOf(0);   But we decided to return NULL instead which is more conservative. 
Hive,WITHOUT_CLASSIFICATION,//  Convert the work containing to sort-merge join into a work as if it had a regular join.   Note that the operator tree is not changed - is still contains the SMB join but the   plan is changed (aliasToWork etc.) to contain all the paths as if it was a regular join.   This is used to convert the plan to a map-join and then the original SMB join plan is used 
Hive,WITHOUT_CLASSIFICATION,//  singleton 
Hive,WITHOUT_CLASSIFICATION,//  9. Rerun PPD through Project as column pruning would have introduced   DT above scans; By pushing filter just above TS Hive can push it into   storage (incase there are filters on non partition cols). This only 
Hive,WITHOUT_CLASSIFICATION,//  entry 2 is null due to zero-divide 
Hive,WITHOUT_CLASSIFICATION,//  For SparkTEZ we rely on the generated SelectOperator to do the type casting.   Consider:      SEL_1 (int)   SEL_2 (int)    SEL_3 (double)   If we first merge SEL_1 and SEL_2 into a UNION_1 and then merge UNION_1   with SEL_3 to get UNION_2 then no SelectOperator will be inserted. Hence error   will happen afterwards. The solution here is to insert one after UNION_1 which 
Hive,WITHOUT_CLASSIFICATION,//  elements of queue (Integer) are index to FetchOperator[] (segments) 
Hive,WITHOUT_CLASSIFICATION,//  create partition specs 
Hive,WITHOUT_CLASSIFICATION,//  Check if all the input txns are in open state. Write ID should be allocated only for open transactions. 
Hive,WITHOUT_CLASSIFICATION,//  Do not exceed the configured max reducers. 
Hive,WITHOUT_CLASSIFICATION,//  No dependency check depth 
Hive,WITHOUT_CLASSIFICATION,/*  All AST nodes must implement this interface.  It provides basic machinery for constructing the parent and child relationships between nodes.  */
Hive,WITHOUT_CLASSIFICATION,//  Check that the files are removed 
Hive,WITHOUT_CLASSIFICATION,//  Write lock for add evict and clean operation 
Hive,WITHOUT_CLASSIFICATION,/*  1 files x 100 size for 9 splits  */
Hive,WITHOUT_CLASSIFICATION,//                    12346678.901234667890123466789012346678 
Hive,WITHOUT_CLASSIFICATION,// strip '(' and ')' 
Hive,WITHOUT_CLASSIFICATION,/*      * row resolver of the SubQuery.     * Set by the SemanticAnalyzer after the Plan for the SubQuery is genned.     * This is needed in case the SubQuery select list contains a TOK_ALLCOLREF      */
Hive,WITHOUT_CLASSIFICATION,// no Worker so it stays in initiated state  w/o AND WAIT the above alter table retunrs almost immediately so the test here to check that  > 2 seconds pass i.e. that the command in Driver actually blocks before cancel is fired 
Hive,WITHOUT_CLASSIFICATION,//  The column number and type information for this one column long reduce key. 
Hive,WITHOUT_CLASSIFICATION,//  No lock required here 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setAsciiStream(int java.io.InputStream   * int)    */
Hive,WITHOUT_CLASSIFICATION,//  if unspecified default one or [\r\n] will be used for line break 
Hive,WITHOUT_CLASSIFICATION,//  Prefixed with incrementalLoadFailAndRetry to avoid finding entry in cmpath 
Hive,WITHOUT_CLASSIFICATION,//  indicates that the recorded value is null 
Hive,WITHOUT_CLASSIFICATION,//  Entire query can be run locally.   Save the current tracker value and restore it when done. 
Hive,WITHOUT_CLASSIFICATION,//  shallow copy ASTNode 
Hive,WITHOUT_CLASSIFICATION,//  recursive types. 
Hive,WITHOUT_CLASSIFICATION,//        This computes stats and should be in stats (de-duplicated too). 
Hive,WITHOUT_CLASSIFICATION,//  OPERATION_STATE 
Hive,WITHOUT_CLASSIFICATION,//  Most general case where the left and right keys might have nulls and   caller requires 3-valued logic return.     select e.deptno e.deptno in (select deptno from emp)     becomes     select e.deptno     case     when ct.c = 0 then false     when dt.i is not null then true     when e.deptno is null then null     when ct.ck < ct.c then null     else false     end   from e   left join (     (select count(*) as c count(deptno) as ck from emp) as ct     cross join (select distinct deptno true as i from emp)) as dt     on e.deptno = dt.deptno     If keys are not null we can remove "ct" and simplify to     select e.deptno     case     when dt.i is not null then true     else false     end   from e   left join (select distinct deptno true as i from emp) as dt     on e.deptno = dt.deptno     We could further simplify to     select e.deptno     dt.i is not null   from e   left join (select distinct deptno true as i from emp) as dt     on e.deptno = dt.deptno     but have not yet.     If the logic is TRUE we can just kill the record if the condition   evaluates to FALSE or UNKNOWN. Thus the query simplifies to an inner   join:     select e.deptno     true   from e   inner join (select distinct deptno from emp) as dt     on e.deptno = dt.deptno   
Hive,WITHOUT_CLASSIFICATION,/*  * Encapsulates statistics about the duration of all reduce tasks * corresponding to a specific JobId. * The stats are computed in the HadoopJobExecHelper when the * job completes and then populated inside the QueryPlan for * each job from where it can be later on accessed. * The reducer statistics consist of minimum/maximum/mean/stdv of the * run times of all the reduce tasks for a job. All the Run times are * in Milliseconds.  */
Hive,WITHOUT_CLASSIFICATION,//  Values 
Hive,WITHOUT_CLASSIFICATION,//  get the last colName for the reduce KEY 
Hive,WITHOUT_CLASSIFICATION,//        2) Some parts of session state like mrStats and vars need proper synchronization. 
Hive,WITHOUT_CLASSIFICATION,//  First drop any databases in catalog 
Hive,WITHOUT_CLASSIFICATION,/*  input data     *     * col0       col1     * ===============     * blue       red     * green      green     * red        blue     * NULL       red            col0 data is empty string if we un-set NULL property      */
Hive,WITHOUT_CLASSIFICATION,//  Both inputs non-negative 
Hive,WITHOUT_CLASSIFICATION,//  The real work-horse. Spend time and energy in this method if there is   need to keep HCatStorer lean and go fast. 
Hive,WITHOUT_CLASSIFICATION,//  expected error 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setSQLXML(int java.sql.SQLXML)    */
Hive,WITHOUT_CLASSIFICATION,//  Get next batch 
Hive,WITHOUT_CLASSIFICATION,//  Note we print to System.err instead of ss.err because if we can't parse our   commandline we haven't even begun and therefore cannot be expected to have   reasonably constructed or started the SessionState. 
Hive,WITHOUT_CLASSIFICATION,// AddNotNullConstraintEvent addDefaultConstraintEvent = new AddNotNullConstraintEvent(defaultConstraintCols true this);  listener.onAddDefaultConstraint(addDefaultConstraintEvent); 
Hive,WITHOUT_CLASSIFICATION,//  An item for new partition is queued now. 
Hive,WITHOUT_CLASSIFICATION,//  ConversionHelper can be called without method parameter length   checkings   for terminatePartial() and merge() calls. 
Hive,WITHOUT_CLASSIFICATION,//  First known state was COMPLETED. Wait for the app launch to start. 
Hive,WITHOUT_CLASSIFICATION,//  Mapping from the regex to lines in the log file where find() == true 
Hive,WITHOUT_CLASSIFICATION,//  2) Copy INSERT branch and duplicate it the first branch will be the UPDATE   for the MERGE statement while the new branch will be the INSERT for the 
Hive,WITHOUT_CLASSIFICATION,//  No isNull copying necessary. 
Hive,WITHOUT_CLASSIFICATION,//  not use map join in case of cross product 
Hive,WITHOUT_CLASSIFICATION,//  we have reached RUNNING state now check if running nodes threshold is met 
Hive,WITHOUT_CLASSIFICATION,//  We will wait for 30 seconds for the task to be cancelled.   If it's still not cancelled (unlikely) we will just move on. 
Hive,WITHOUT_CLASSIFICATION,//  sit in the cache while not in use. 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) Include  */
Hive,WITHOUT_CLASSIFICATION,//  Set up a timeout to undo everything. 
Hive,WITHOUT_CLASSIFICATION,//  Create table 
Hive,WITHOUT_CLASSIFICATION,//  Don't register with deleteOnExit 
Hive,WITHOUT_CLASSIFICATION,//  Non-empty java opts with -Xmx specified in B 
Hive,WITHOUT_CLASSIFICATION,//  add partition column stats 
Hive,WITHOUT_CLASSIFICATION,//  This can use significant resources and should not be done on the main query thread. 
Hive,WITHOUT_CLASSIFICATION,// as this is corr scalar subquery with agg we expect one aggregate 
Hive,WITHOUT_CLASSIFICATION,//  spark-llap always wraps query under a subquery until that is removed from spark-llap 
Hive,WITHOUT_CLASSIFICATION,//  Make sure the default value expression type is exactly same as column's type. 
Hive,WITHOUT_CLASSIFICATION,//  3. dynamic partition columns 
Hive,WITHOUT_CLASSIFICATION,//  gbInputRel's schema is like this 
Hive,WITHOUT_CLASSIFICATION,//  The connection should fail since it the dry run 
Hive,WITHOUT_CLASSIFICATION,//  Always set these so EXPLAIN can see. 
Hive,WITHOUT_CLASSIFICATION,//  If a table is partitioned and immutable then the presence   of the partition alone is enough to throw an error - we do   not need to check for emptiness to decide to throw an error 
Hive,WITHOUT_CLASSIFICATION,//  test for boolean type 
Hive,WITHOUT_CLASSIFICATION,//  marker annotations for functions that Reflector should ignore / pretend it does not exist 
Hive,WITHOUT_CLASSIFICATION,//  Drop occured as part of replicating a drop but the destination   table was newer than the event being replicated. Ignore but drop   any partitions inside that are older. 
Hive,WITHOUT_CLASSIFICATION,//  Column Type 
Hive,WITHOUT_CLASSIFICATION,// sqlLine.getOpts().setAllowMultiLineCommand(false);  System.setProperty("sqlline.isolation""TRANSACTION_READ_COMMITTED");   We can be pretty sure that an entire line can be processed as a single command since   we always add a line separator at the end while calling dbCommandParser.buildCommand. 
Hive,WITHOUT_CLASSIFICATION,/*        * If the input to the GBy has a tab alias for the column then add an entry       * based on that tab_alias.       * For e.g. this query:       * select b.x count(*) from t1 b group by x       * needs (tab_alias=b col_alias=x) in the GBy RR.       * tab_alias=b comes from looking at the RowResolver that is the ancestor       * before any GBy/ReduceSinks added for the GBY operation.        */
Hive,WITHOUT_CLASSIFICATION,//  inputs 
Hive,WITHOUT_CLASSIFICATION,//  Good performance for common case where small table has no complex objects. 
Hive,WITHOUT_CLASSIFICATION,/*  * Specialized class for doing a vectorized map join that is an inner join on a Multi-Key * using a hash map.  */
Hive,WITHOUT_CLASSIFICATION,//  Create post-filtering evaluators if needed 
Hive,WITHOUT_CLASSIFICATION,//  We want no lock here as the database lock will cover the tables   and putting a lock will actually cause us to deadlock on ourselves. 
Hive,WITHOUT_CLASSIFICATION,//  before readBatch initial the size of offsets & lengths as the default value 
Hive,WITHOUT_CLASSIFICATION,//  CLIENT_PROTOCOL 
Hive,WITHOUT_CLASSIFICATION,//  write the value out 
Hive,WITHOUT_CLASSIFICATION,//  Handler multi-line sql 
Hive,WITHOUT_CLASSIFICATION,//  Test setting fetch size below max 
Hive,WITHOUT_CLASSIFICATION,//  Candidate for preemption. 
Hive,WITHOUT_CLASSIFICATION,//  remove this task from its children tasks 
Hive,WITHOUT_CLASSIFICATION,//  nulls possible on left right 
Hive,WITHOUT_CLASSIFICATION,//  INTEGER_FLAG 
Hive,WITHOUT_CLASSIFICATION,//  Used Memory = totalMemory() - freeMemory(); 
Hive,WITHOUT_CLASSIFICATION,//  start would throw if it already existed here 
Hive,WITHOUT_CLASSIFICATION,/*                the tableTracker here should be a new instance and not an existing one as this can               only happen when we break in between loading partitions.            */
Hive,WITHOUT_CLASSIFICATION,//  then load the SparkClientImpl config 
Hive,WITHOUT_CLASSIFICATION,// Peel off the n-1 levels to get to the underlying array 
Hive,WITHOUT_CLASSIFICATION,//  to this task in the callback instead. 
Hive,WITHOUT_CLASSIFICATION,//  Find functions which name contains _to_find_ in the default database 
Hive,WITHOUT_CLASSIFICATION,//  MIN 
Hive,WITHOUT_CLASSIFICATION,//  isset id assignments 
Hive,WITHOUT_CLASSIFICATION,//  For integers we have optional min/max filtering. 
Hive,WITHOUT_CLASSIFICATION,//  -----------------------------------------------------------------------------------------------     Compare timestamp against timestamp long (seconds) and double (seconds with fractional   nanoseconds).      TimestampCol         {Equal|Greater|GreaterEqual|Less|LessEqual|NotEqual}   TimestampColumn    TimestampCol         {Equal|Greater|GreaterEqual|Less|LessEqual|NotEqual}   {Long|Double}Column  * {Long|Double}Col     {Equal|Greater|GreaterEqual|Less|LessEqual|NotEqual}   TimestampColumn      TimestampCol         {Equal|Greater|GreaterEqual|Less|LessEqual|NotEqual}   TimestampScalar    TimestampCol         {Equal|Greater|GreaterEqual|Less|LessEqual|NotEqual}   {Long|Double}Scalar  * {Long|Double}Col     {Equal|Greater|GreaterEqual|Less|LessEqual|NotEqual}   TimestampScalar      TimestampScalar      {Equal|Greater|GreaterEqual|Less|LessEqual|NotEqual}   TimestampColumn    TimestampScalar      {Equal|Greater|GreaterEqual|Less|LessEqual|NotEqual}   {Long|Double}Column  * {Long|Double}Scalar  {Equal|Greater|GreaterEqual|Less|LessEqual|NotEqual}   TimestampColumn     ----------------------------------------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  Specifies a DB 
Hive,WITHOUT_CLASSIFICATION,//  tracks the number of elements with the same rank at the current time 
Hive,WITHOUT_CLASSIFICATION,//  if table is partitionedadd partDir and partitionDesc 
Hive,WITHOUT_CLASSIFICATION,//  At this point we have a number.  Save it in fastResult.  Round it.  If we have an exponent   we will do a power 10 operation on fastResult. 
Hive,WITHOUT_CLASSIFICATION,//  set true for columns that needed to skip loading into memory. 
Hive,WITHOUT_CLASSIFICATION,//  Simulate the unknown source 
Hive,WITHOUT_CLASSIFICATION,//  blank " " (1 byte)   blank " " (1 byte)   blank " " (1 byte)   blank " " (1 byte)   blank " " (1 byte)   WHITE START U+2606 (3 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  The only way to get the return object inspector (and its return type) is to   initialize it... 
Hive,WITHOUT_CLASSIFICATION,//  From the moment that we have two destination clauses   we know that this is a multi-insert query.   Thus set property to right value.   Using qbp.getClauseNamesForDest().size() >= 2 would be   equivalent but we use == to avoid setting the property   multiple times 
Hive,WITHOUT_CLASSIFICATION,//  expressions 
Hive,WITHOUT_CLASSIFICATION,//  max value stored in registered is cached to determine the bit width for 
Hive,WITHOUT_CLASSIFICATION,//  common code 
Hive,WITHOUT_CLASSIFICATION,//  val 
Hive,WITHOUT_CLASSIFICATION,//  workersPath is the directory path where all the worker znodes are located. 
Hive,WITHOUT_CLASSIFICATION,//  if the variable was on the right we need to swap things around 
Hive,WITHOUT_CLASSIFICATION,//  test third IF argument with nulls 
Hive,WITHOUT_CLASSIFICATION,//  Entry either expired or was invalidated due to table updates 
Hive,WITHOUT_CLASSIFICATION,//  Because the length of ListColumnVector.child can't be known now 
Hive,WITHOUT_CLASSIFICATION,//  static partition spec ends with a '/' 
Hive,WITHOUT_CLASSIFICATION,//  Use the earlier match. 
Hive,WITHOUT_CLASSIFICATION,//  Return true if the table is bucketed/sorted by the specified positions   The number of buckets the sort order should also match along with the 
Hive,WITHOUT_CLASSIFICATION,//  skip empty lines 
Hive,WITHOUT_CLASSIFICATION,//  Base with delete deltas 
Hive,WITHOUT_CLASSIFICATION,//  remember this rel so we don't fire rule on it again   REVIEW jhyde 29-Oct-2007: rules should not save state; rule   should recognize patterns where it does or does not need to do 
Hive,WITHOUT_CLASSIFICATION,//  It is possible that the background init thread has finished in parallel queued   the message for us but also returned the session to the user. 
Hive,WITHOUT_CLASSIFICATION,//  let's use the table from the cache. 
Hive,WITHOUT_CLASSIFICATION,//  Create the list of children 
Hive,WITHOUT_CLASSIFICATION,//  WARNING NOTE : at this point createDbExportDump lives only in a world where ReplicationSpec is in replication scope   If we later make this work for non-repl cases analysis of this logic might become necessary. Also this is using   Replv2 semantics i.e. with listFiles laziness (no copy at export time) 
Hive,WITHOUT_CLASSIFICATION,//  Would be nice if there was a way to determine if quotes are needed 
Hive,WITHOUT_CLASSIFICATION,//  One input table 
Hive,WITHOUT_CLASSIFICATION,//  2. Get Left Table Alias 
Hive,WITHOUT_CLASSIFICATION,//  3.3.1 Get UDAF Evaluator 
Hive,WITHOUT_CLASSIFICATION,//  Find the last matching -Xmx following word boundaries   Format: -Xmx<size>[g|G|m|M|k|K] 
Hive,WITHOUT_CLASSIFICATION,//  Add custom cookies if passed to the jdbc driver 
Hive,WITHOUT_CLASSIFICATION,//  We are doing work here we'd normally do in VectorGroupByCommonOperator's constructor.   So if we later decide not to specialize we'll just waste any scratch columns allocated... 
Hive,WITHOUT_CLASSIFICATION,//  set some info for the query 
Hive,WITHOUT_CLASSIFICATION,//  remember min value and ignore it from the denominator 
Hive,WITHOUT_CLASSIFICATION,/*        * Interrupt all thread and verify we get InterruptedException and expected Message.        */
Hive,WITHOUT_CLASSIFICATION,//  returns false if index already exists in map 
Hive,WITHOUT_CLASSIFICATION,//  Update condition 
Hive,WITHOUT_CLASSIFICATION,/*    * Reads the the next field.   *   * Afterwards reading is positioned to the next field.   *   * @return  Return true when the field was not null and data is put in the appropriate   *          current* member.   *          Otherwise false when the field is null.   *    */
Hive,WITHOUT_CLASSIFICATION,//  otherwise discard the escape char 
Hive,WITHOUT_CLASSIFICATION,//  due to data freshness) 
Hive,WITHOUT_CLASSIFICATION,//  Create top Project fixing nullability of fields 
Hive,WITHOUT_CLASSIFICATION,// Test is failing due to Guava dependency Druid 0.13.0 should have less dependency on Guava 
Hive,WITHOUT_CLASSIFICATION,// allow operation in a txn 
Hive,WITHOUT_CLASSIFICATION,//  we have tez installed 
Hive,WITHOUT_CLASSIFICATION,//  Extract the bits of num into value[] from right to left 
Hive,WITHOUT_CLASSIFICATION,//  Need to deep copy here since doing something like lastFrom = from instead will make 
Hive,WITHOUT_CLASSIFICATION,/*    * Serialize the row into a ByteStream.   *   * @param obj           The object for the current field.   * @param objInspector  The ObjectInspector for the current Object.   * @param level         The current level of separator.   * @param writeBinary   Whether to write a primitive object as an UTF8 variable length string or   *                      as a fixed width byte array onto the byte stream.   * @throws IOException  On error in writing to the serialization stream.   * @return true         On serializing a non-null object otherwise false.    */
Hive,WITHOUT_CLASSIFICATION,//  we expect json file to be updated 
Hive,WITHOUT_CLASSIFICATION,//  Replace unparsable synonyms. 
Hive,WITHOUT_CLASSIFICATION,//  Examine the buddy block and its sub-blocks in detail. 
Hive,WITHOUT_CLASSIFICATION,//  Test drop_partition_by_name 
Hive,WITHOUT_CLASSIFICATION,//  Hive DESCRIBE outputs "empty_string NULL" row before partition information 
Hive,WITHOUT_CLASSIFICATION,//  this is to keep track if a subquery is correlated and contains aggregate 
Hive,WITHOUT_CLASSIFICATION,//  We flip the bits because Calcite considers that '1'   means that the column participates in the GroupBy   and '0' does not as opposed to grouping_id. 
Hive,WITHOUT_CLASSIFICATION,//  Must obtain vectorized equivalents for filter and value expressions 
Hive,WITHOUT_CLASSIFICATION,//  CREATE DB currently replicated as Noop. 
Hive,WITHOUT_CLASSIFICATION,//  2. We will ask WM for a preliminary mapping. This allows us to escape to the unmanaged path      quickly in the common case. It's still possible that resource plan will be updated and 
Hive,WITHOUT_CLASSIFICATION,//  if there are actual accumulo index columns defined then build   the comma separated list of accumulo columns 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: All dist cols have single output col name; 
Hive,WITHOUT_CLASSIFICATION,//  We should prepare the valid write ids list based on validTxnList of current txn.   If no txn exists in the caller then they would pass null for validTxnList and so it is   required to get the current state of txns to make validTxnList 
Hive,WITHOUT_CLASSIFICATION,//  extra fields but we don't.) 
Hive,WITHOUT_CLASSIFICATION,//  create base OutputFormat 
Hive,WITHOUT_CLASSIFICATION,//  PARTITION_VALS 
Hive,WITHOUT_CLASSIFICATION,//  gives progress over uncompressed stream   assumes deserializer is not buffering itself 
Hive,WITHOUT_CLASSIFICATION,// create and drop some additional metadata to test drop counts. 
Hive,WITHOUT_CLASSIFICATION,//  STRING_VALUE 
Hive,WITHOUT_CLASSIFICATION,//  ACCUMULO-4670 RangeInputSplit doesn't preserve useSasl on the ClientConfiguration/ZooKeeperInstance 
Hive,WITHOUT_CLASSIFICATION,//  Send a 401 to the client 
Hive,WITHOUT_CLASSIFICATION,//  See addToExpirationQueue for why we re-check the queue. 
Hive,WITHOUT_CLASSIFICATION,// -----------------------------------------------------------------------------------------------   Rounding / setScale methods.  ----------------------------------------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,// in case of Compaction this is the 1st file of the current bucket 
Hive,WITHOUT_CLASSIFICATION,//  Column expression of the table being filtered by the semijoin optimization. 
Hive,WITHOUT_CLASSIFICATION,/*    * This method is overridden in each Task. TODO execute should return a TaskHandle.   *   * @return status of executing the task    */
Hive,WITHOUT_CLASSIFICATION,//  double column/column IF 
Hive,WITHOUT_CLASSIFICATION,//  dummy value for use in tests 
Hive,WITHOUT_CLASSIFICATION,/*    * Called after the tasks have been generated to run another round of optimization    */
Hive,WITHOUT_CLASSIFICATION,//  If it is a map-only job the task needs to be processed 
Hive,WITHOUT_CLASSIFICATION,//  get metastore/thrift privilege object for this principal and object not looking at 
Hive,WITHOUT_CLASSIFICATION,//  Null should be smaller than any other value so put a null at the front   end 
Hive,WITHOUT_CLASSIFICATION,//  We need to shift everything 8 bits left and then shift back to populate the sign field. 
Hive,WITHOUT_CLASSIFICATION,/*    * An expression is either the left/right side of an Equality predicate in the SubQuery where   * clause; or it is the entire conjunct. For e.g. if the Where Clause for a SubQuery is:   * where R1.X = R2.Y and R2.Z > 7   * Then the expressions analyzed are R1.X R2.X ( the left and right sides of the Equality   * predicate); and R2.Z > 7.   *   * The ExprType tracks whether the expr:   * - has a reference to a SubQuery table source   * - has a reference to Outer(parent) Query table source    */
Hive,WITHOUT_CLASSIFICATION,//  role names are case-insensitive 
Hive,WITHOUT_CLASSIFICATION,//  PARTITION_KEYS 
Hive,WITHOUT_CLASSIFICATION,//  initialize the user's process only when you receive the first row 
Hive,WITHOUT_CLASSIFICATION,//  mapjoin should not be affected by join reordering 
Hive,WITHOUT_CLASSIFICATION,//  Unexpected. 
Hive,WITHOUT_CLASSIFICATION,//  File handle 
Hive,WITHOUT_CLASSIFICATION,//  Specify the external warehouse root 
Hive,WITHOUT_CLASSIFICATION,//  RS-GB-RS 
Hive,WITHOUT_CLASSIFICATION,//  Indicates whether a node is disabled - for whatever reason - commFailure busy etc. 
Hive,WITHOUT_CLASSIFICATION,//  Note: the following code (removing folded constants in exprs) is deeply coupled with      ColumnPruner optimizer.   Assuming ColumnPrunner will remove constant columns so we don't deal with output columns.      Except one case that the join operator is followed by a redistribution (RS operator). 
Hive,WITHOUT_CLASSIFICATION,//  Make sure we skip backward-compat checking for those tests that don't generate events 
Hive,WITHOUT_CLASSIFICATION,//  convert to hcatschema and pass to HCatInputFormat 
Hive,WITHOUT_CLASSIFICATION,//  Add those that are not part of the final set to residual 
Hive,WITHOUT_CLASSIFICATION,//  parse a value 
Hive,WITHOUT_CLASSIFICATION,//  Options for the python script that are here because our option parser cannot ignore the unknown ones 
Hive,WITHOUT_CLASSIFICATION,//  Handle structs composed of partition columns 
Hive,WITHOUT_CLASSIFICATION,//  Read and decode dictionary ids. 
Hive,WITHOUT_CLASSIFICATION,//  SR.SR: Lock we are examining is shared read 
Hive,WITHOUT_CLASSIFICATION,//  that's what this this alter is and if so swallow it. 
Hive,WITHOUT_CLASSIFICATION,//  The output of the key expression is the input column. 
Hive,WITHOUT_CLASSIFICATION,//  Unregister may come in after the new dag has started running. The methods are expected to   be synchronized hence the following check is sufficient. 
Hive,WITHOUT_CLASSIFICATION,/*      * used to capture view to SQ conversions. This is used to check for     * recursive CTE invocations.      */
Hive,WITHOUT_CLASSIFICATION,/*    * Calculate the variance family {VARIANCE VARIANCE_SAMPLE STANDARD_DEVIATION or   * STANDARD_DEVIATION_STAMPLE) result when count > 1.  Public so vectorization code can   * use it etc.    */
Hive,WITHOUT_CLASSIFICATION,//  Optimize for most common case -- primitive. 
Hive,WITHOUT_CLASSIFICATION,//  Check if the pipeout files are removed 
Hive,WITHOUT_CLASSIFICATION,// Volatile ensures that static access returns Metrics instance in fully-initialized state.  Alternative is to synchronize static access which has performance penalties. 
Hive,WITHOUT_CLASSIFICATION,//  fields but do it for uniformity 
Hive,WITHOUT_CLASSIFICATION,//  EVENT_TIME 
Hive,WITHOUT_CLASSIFICATION,//  The sort-merge join creates the output sorted and bucketized by the same columns. 
Hive,WITHOUT_CLASSIFICATION,//  (none) 
Hive,WITHOUT_CLASSIFICATION,/*  Have to be able to peek ahead one byte  */
Hive,WITHOUT_CLASSIFICATION,//  Note: Not currently part of the HiveRelNode interface 
Hive,WITHOUT_CLASSIFICATION,//  add one more record and close 
Hive,WITHOUT_CLASSIFICATION,//  Add any redirects 
Hive,WITHOUT_CLASSIFICATION,/*      * get from conf to pick up changes; make sure not to set too low and kill the metastore     * MAX_SLEEP is the max time each backoff() will wait for thus the total time to wait for     * successful lock acquisition is approximately (see backoff()) maxNumWaits * MAX_SLEEP.      */
Hive,WITHOUT_CLASSIFICATION,// in case schema is not a file system 
Hive,WITHOUT_CLASSIFICATION,//  Wait before launching the next round of connection retries. 
Hive,WITHOUT_CLASSIFICATION,//  We create new view 
Hive,WITHOUT_CLASSIFICATION,//  whether we need to do transformation for each parent 
Hive,WITHOUT_CLASSIFICATION,//  Found UDF in metastore - now add it to the function registry 
Hive,WITHOUT_CLASSIFICATION,//  Remove operator 
Hive,WITHOUT_CLASSIFICATION,// all currently open txns (if any) have txnid >= than commitHighWaterMark 
Hive,WITHOUT_CLASSIFICATION,//  move works following the current reduce work into a new spark work 
Hive,WITHOUT_CLASSIFICATION,//  add sub-directory to the work queue if maxDepth is not yet reached 
Hive,WITHOUT_CLASSIFICATION,//  Protection against construction. 
Hive,WITHOUT_CLASSIFICATION,//  4. Update the existing row and insert another row to newly-converted ACID table 
Hive,WITHOUT_CLASSIFICATION,/*    * These parameters controls the maximum time job submit/status/list operation is   * executed in templeton service. On time out the execution is interrupted and   * TimeoutException is returned to client. On time out   *   For list and status operation there is no action needed as they are read requests.   *   For submit operation we do best effort to kill the job if its generated. Enabling   *     this parameter may have following side effects   *     1) There is a possibility for having active job for some time when the client gets   *        response for submit operation and a list operation from client could potential   *        show the newly created job which may eventually be killed with no guarantees.   *     2) If submit operation retried by client then there is a possibility of duplicate   *        jobs triggered.   *   * Time out configs should be configured in seconds.   *    */
Hive,WITHOUT_CLASSIFICATION,//  inputObjectInspectors 
Hive,WITHOUT_CLASSIFICATION,//  -Xmx specified in KB 
Hive,WITHOUT_CLASSIFICATION,//  Test various combinations. 
Hive,WITHOUT_CLASSIFICATION,//  For non-views we need to do some extra fixes 
Hive,WITHOUT_CLASSIFICATION,// test owner 
Hive,WITHOUT_CLASSIFICATION,//  total characters = 4; byte length = 9 
Hive,WITHOUT_CLASSIFICATION,//  add owner privilege if user is owner of the object 
Hive,WITHOUT_CLASSIFICATION,// remove WRITE_SET info for current txn since it's about to abort 
Hive,WITHOUT_CLASSIFICATION,//  there is no backup servers; 
Hive,WITHOUT_CLASSIFICATION,/*  Spot check correctness of decimal column multiply decimal scalar. The case for   * addition checks all the cases for the template so don't do that redundantly here.    */
Hive,WITHOUT_CLASSIFICATION,//  invariant: rightLength = leftLength   rightOffset is within the buffers 
Hive,WITHOUT_CLASSIFICATION,//  get names of these roles and its ancestors 
Hive,WITHOUT_CLASSIFICATION,/*  Dynamic partition pruning is enabled in some or all cases    */
Hive,WITHOUT_CLASSIFICATION,//  Get the skewed values in all the tables 
Hive,WITHOUT_CLASSIFICATION,//  skip the test if Java Cryptography Extension (JCE) Unlimited Strength   Jurisdiction Policy Files not installed 
Hive,WITHOUT_CLASSIFICATION,//  Should return "tbl" and "tbl2" 
Hive,WITHOUT_CLASSIFICATION,//  TestHS2ConnectionConfigFileManager 
Hive,WITHOUT_CLASSIFICATION,//  Grouping sets are not allowed 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:FragmentRuntimeInfo) 
Hive,WITHOUT_CLASSIFICATION,/*  * This hook is used for verifying the column access information * that is generated and maintained in the QueryPlan object by the * ColumnAccessAnalyzer. All the hook does is print out the columns * accessed from each table as recorded in the ColumnAccessInfo * in the QueryPlan.  */
Hive,WITHOUT_CLASSIFICATION,//  STATS_DATA 
Hive,WITHOUT_CLASSIFICATION,//  Get the exprNodeDesc corresponding to the first start node; 
Hive,WITHOUT_CLASSIFICATION,//  This is the first time we have realized we are in a stack trace.  In this case   the previous line was the error message add that to the stack trace as well 
Hive,WITHOUT_CLASSIFICATION,//  map built during translation 
Hive,WITHOUT_CLASSIFICATION,/*      * Process the input columns to find a non-NULL value for each row.     *     * We track the unassigned batchIndex of the rows that have not received     * a non-NULL value yet.  Similar to a selected array.      */
Hive,WITHOUT_CLASSIFICATION,//  GenericUDTF is stateful too copy 
Hive,WITHOUT_CLASSIFICATION,//  We could not get stats we cannot convert 
Hive,WITHOUT_CLASSIFICATION,//  Put into the map that this task was in before we decided to update it. 
Hive,WITHOUT_CLASSIFICATION,//  We don't currently support the BETWEEN ends being columns.  They must be scalars. 
Hive,WITHOUT_CLASSIFICATION,//  verify that the new version is added to schema 
Hive,WITHOUT_CLASSIFICATION,//  The same object. 
Hive,WITHOUT_CLASSIFICATION,//  For testing 
Hive,WITHOUT_CLASSIFICATION,//  Turn escape off. 
Hive,WITHOUT_CLASSIFICATION,//  drop table over10k; 
Hive,WITHOUT_CLASSIFICATION,//  This is a rebuild there's nothing to do here 
Hive,WITHOUT_CLASSIFICATION,//  Default value is true however if an optimization deems this edge   important it should set this to false. This does not guarantee that   the edge will stay however it increases the chances. 
Hive,WITHOUT_CLASSIFICATION,//  and test dropping this specific table 
Hive,WITHOUT_CLASSIFICATION,//  joinKeys/joinKeysOI are initialized after making merge queue so setup lazily at runtime 
Hive,WITHOUT_CLASSIFICATION,// tries to get X lock on T7.p=1 and gets Waiting state 
Hive,WITHOUT_CLASSIFICATION,//  write an intermediate file to the specified path   the format of the path is: tmpPath/targetWorkId/sourceWorkId/randInt 
Hive,WITHOUT_CLASSIFICATION,//  that it's easy to find reason for local mode execution failures 
Hive,WITHOUT_CLASSIFICATION,// "delete from tab1" 
Hive,WITHOUT_CLASSIFICATION,/*     Sets up a TaskSpec with no inputs and tasks belonging to vertex1      */
Hive,WITHOUT_CLASSIFICATION,//  Verify r1 was preempted. Also verify that it finished (single executor) otherwise   r2 could have run anyway. 
Hive,WITHOUT_CLASSIFICATION,//  We refer to grouping_id column 
Hive,WITHOUT_CLASSIFICATION,/*        * HIVE-6356       * The following code change is only needed for hbase-0.96.0 due to HBASE-9165 and       * will not be required once Hive bumps up its hbase version). At that time  we will       * only need TableMapReduceUtil.addDependencyJars(jobConf) here.        */
Hive,WITHOUT_CLASSIFICATION,//  This constructor is used to momentarily create the object so match can be called. 
Hive,WITHOUT_CLASSIFICATION,//  Caller will return the batch. 
Hive,WITHOUT_CLASSIFICATION,//  check for required fields   check for sub-struct validity 
Hive,WITHOUT_CLASSIFICATION,// @Test 
Hive,WITHOUT_CLASSIFICATION,//  Use the same logic as ReduceSinkOperator.toHiveKey.   
Hive,WITHOUT_CLASSIFICATION,//  SerDe Properties 
Hive,WITHOUT_CLASSIFICATION,//  If a parameter is added to the restricted list add a test in TestRestrictedList.Java 
Hive,WITHOUT_CLASSIFICATION,//  INSERT DATA 
Hive,WITHOUT_CLASSIFICATION,//  Thread pool for callbacks on completion of execution of a work unit. 
Hive,WITHOUT_CLASSIFICATION,//  Only the big table input source should be vectorized (if applicable) 
Hive,WITHOUT_CLASSIFICATION,//  Key to be used to save the partition to be dropped in partSpecs 
Hive,WITHOUT_CLASSIFICATION,//  plain acid table   acid table with customized tblproperties 
Hive,WITHOUT_CLASSIFICATION,//  Optional vectorized key expressions that need to be run on each batch. 
Hive,WITHOUT_CLASSIFICATION,//  initialize with estimated element size 10   Record initial buffer size 
Hive,WITHOUT_CLASSIFICATION,//  by JAR spec if there is a manifest it must be the first entry in   the   ZIP. 
Hive,WITHOUT_CLASSIFICATION,//  Exclude the newly-generated select columns from */etc. resolution. 
Hive,WITHOUT_CLASSIFICATION,//  the "-foo bar" and "-blah" params order is not guaranteed 
Hive,WITHOUT_CLASSIFICATION,//  This should be a cost based decision but till we enable the extended cost   model we will use the given value for the variable 
Hive,WITHOUT_CLASSIFICATION,//  todo authorization 
Hive,WITHOUT_CLASSIFICATION,/*  10 files x 100 size for 99 splits  */
Hive,WITHOUT_CLASSIFICATION,/*    * Returns the root node of the AST. It only makes sense to call this after a   * successful parse.    */
Hive,WITHOUT_CLASSIFICATION,//  Input and Output Serdes 
Hive,WITHOUT_CLASSIFICATION,//  non-cbo path retries to execute create view and   we believe it will throw the same error message 
Hive,WITHOUT_CLASSIFICATION,//  11. Apply Druid transformation rules 
Hive,WITHOUT_CLASSIFICATION,//  Here we know nd represents a group by expression. 
Hive,WITHOUT_CLASSIFICATION,//  5 seconds 
Hive,WITHOUT_CLASSIFICATION,//  Add identity 
Hive,WITHOUT_CLASSIFICATION,// there is one repeated field for mapCol the field name is "map" and its original Type is MAP_KEY_VALUE; 
Hive,WITHOUT_CLASSIFICATION,//  Pause for a just a bit for retrying to avoid immediately jumping back into the deadlock. 
Hive,WITHOUT_CLASSIFICATION,/*    * Tries to get the job result if job request is completed. Otherwise it sets job status   * to FAILED such that execute thread can do necessary clean up based on FAILED state.    */
Hive,WITHOUT_CLASSIFICATION,//  Use synchronized map since even read actions cause the lru to get updated. 
Hive,WITHOUT_CLASSIFICATION,//  If the columns of the old column descriptor != the columns of the new one   then change the old storage descriptor's column descriptor.   Convert the MFieldSchema's to their thrift object counterparts because we maintain   datastore identity (i.e. identity of the model objects are managed by JDO   not the application). 
Hive,WITHOUT_CLASSIFICATION,//  logger can be a resource stream or a real file (cannot use copy) 
Hive,WITHOUT_CLASSIFICATION,//  Replace filter 
Hive,WITHOUT_CLASSIFICATION,//  the base writer 
Hive,WITHOUT_CLASSIFICATION,//  can directly add positions into corDefOutputs since join 
Hive,WITHOUT_CLASSIFICATION,// create column info with new tableAlias 
Hive,WITHOUT_CLASSIFICATION,//  In LRR case if we just store 2 boundaries (which could be split boundaries or reader   positions) we wouldn't be able to account for torn rows correctly because the semantics of   our "exact" reader positions and inexact split boundaries are different. We cannot even   tell LRR to use exact boundaries as there can be a mismatch in an original mid-file split   wrt first row when caching - we may produce incorrect result if we adjust the split   boundary and also if we don't adjust it depending where it falls. At best we'd end up   with spurious disk reads if we cache on row boundaries but splits include torn rows.   This structure implies that when reading a split we skip the first torn row but fully   read the last torn row (as LineRecordReader does). If we want to support a different scheme   we'd need to store more offsets and make logic account for that. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setNClob(int java.io.Reader)    */
Hive,WITHOUT_CLASSIFICATION,//  hive.mapjoin.bucket.cache.size has been replaced by hive.smbjoin.cache.row 
Hive,WITHOUT_CLASSIFICATION,//  {Small Value Bytes}   (use small length from valueWordRef) 
Hive,WITHOUT_CLASSIFICATION,//  If hint is true shouldRemove is redundant anyway 
Hive,WITHOUT_CLASSIFICATION,//  TABLE 
Hive,WITHOUT_CLASSIFICATION,//  rowSetLog should contain execution as well as performance logs 
Hive,WITHOUT_CLASSIFICATION,//  There are 2 paths under which the instances get registered   1) Standard path used by ZkRegistryBase where all instances register themselves (also stores metadata)   Secure: /hs2ActivePassiveHA-sasl/instances/instance-0000000000   Unsecure: /hs2ActivePassiveHA-unsecure/instances/instance-0000000000   2) Leader latch path used for HS2 HA Active/Passive configuration where all instances register under _LEADER      path but only one among them is the leader   Secure: /hs2ActivePassiveHA-sasl/_LEADER/xxxx-latch-0000000000   Unsecure: /hs2ActivePassiveHA-unsecure/_LEADER/xxxx-latch-0000000000 
Hive,WITHOUT_CLASSIFICATION,//  The Tokens have no distinction between Identifiers and QuotedIdentifiers.   Ugly solution is just to surround all identifiers with quotes. 
Hive,WITHOUT_CLASSIFICATION,//  if there is any aggregate function this group by is not un-necessary 
Hive,WITHOUT_CLASSIFICATION,//  The condition fetched here can reference a udf that is not deterministic but defined   as part of the select list when a view is in play.  But the condition after the pushdown   will resolve to using the udf from select list.  The check here for deterministic filters   should be based on the resolved expression.  Refer to test case cbo_ppd_non_deterministic.q. 
Hive,WITHOUT_CLASSIFICATION,//  and must have 3 columns. Also the partition locations must lie within the table directory. 
Hive,WITHOUT_CLASSIFICATION,//  O1 
Hive,WITHOUT_CLASSIFICATION,//  unable to get the database set the dbName empty 
Hive,WITHOUT_CLASSIFICATION,//   UDFToString we need the following mappings 
Hive,WITHOUT_CLASSIFICATION,/*  * An bytes key hash multi-set optimized for vector map join. * * This is the abstract base for the multi-key and string bytes key hash multi-set implementations.  */
Hive,WITHOUT_CLASSIFICATION,//  We need to update rootToWorkMap in case the op is a key since even 
Hive,WITHOUT_CLASSIFICATION,//  Also compute the correct cf:cq pairs so we can assert the right argument was passed 
Hive,WITHOUT_CLASSIFICATION,//  value needs to be converted to match the type params (length etc). 
Hive,WITHOUT_CLASSIFICATION,//  Serialize 
Hive,WITHOUT_CLASSIFICATION,//  then need to truncate the exceptions list accordingly. 
Hive,WITHOUT_CLASSIFICATION,//  What can I do about it? 
Hive,WITHOUT_CLASSIFICATION,//  4. Build new TS 
Hive,WITHOUT_CLASSIFICATION,//  Verify if the data are intact even after applying an applied event once again on existing objects 
Hive,WITHOUT_CLASSIFICATION,//  alter partitioned table set table property 
Hive,WITHOUT_CLASSIFICATION,//  character then reverse the whole string. 
Hive,WITHOUT_CLASSIFICATION,// db.table -> return table 
Hive,WITHOUT_CLASSIFICATION,//  convert integer to string 
Hive,WITHOUT_CLASSIFICATION,//  test that underflow produces NULL 
Hive,WITHOUT_CLASSIFICATION,//  index 1 set by child 
Hive,WITHOUT_CLASSIFICATION,//  Map from integer tag to non-distinct aggrs with key parameters. 
Hive,WITHOUT_CLASSIFICATION,//  Copy ColumnVectors to overflowBatch.  We remember buffered columns compactly in the   buffered VRBs without other columns or scratch columns. 
Hive,WITHOUT_CLASSIFICATION,//  instantiate default values if not specified 
Hive,WITHOUT_CLASSIFICATION,//  function calls from the query plan. 
Hive,WITHOUT_CLASSIFICATION,//  add the partition again so that drop table with a partition can be 
Hive,WITHOUT_CLASSIFICATION,//  Getters 
Hive,WITHOUT_CLASSIFICATION,// -----------------------------------------------------------------------------------------------   Attribute methods.  ----------------------------------------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  [url] [host] [port] [db] 
Hive,WITHOUT_CLASSIFICATION,//  If any input has not been rewritten do not rewrite this rel. 
Hive,WITHOUT_CLASSIFICATION,//  Mock BeeLine 
Hive,WITHOUT_CLASSIFICATION,//  Set conf to use LLAP user rather than current user for LLAP Zk registry. 
Hive,WITHOUT_CLASSIFICATION,//  Currently only print the first port to be consistent with old behavior 
Hive,WITHOUT_CLASSIFICATION,//  O3 
Hive,WITHOUT_CLASSIFICATION,//  project everything from the LHS and then those from the original 
Hive,WITHOUT_CLASSIFICATION,//  do not need update stats in alter table/partition operations 
Hive,WITHOUT_CLASSIFICATION,//  Number of rows that match the regex but have missing groups. 
Hive,WITHOUT_CLASSIFICATION,//  Create partial Select query 
Hive,WITHOUT_CLASSIFICATION,//  and a preemption should be attempted on host1 despite host2 having available capacity 
Hive,WITHOUT_CLASSIFICATION,//  Session has expired and will be returned to us later. 
Hive,WITHOUT_CLASSIFICATION,//  generate the cmd line to run in the child jvm 
Hive,WITHOUT_CLASSIFICATION,//  3. Apply SARG if needed and otherwise determine what RGs to read. 
Hive,WITHOUT_CLASSIFICATION,//  Found a best match during this processing use it. 
Hive,WITHOUT_CLASSIFICATION,//  compare with old cacheEnd 
Hive,WITHOUT_CLASSIFICATION,//  can be mux operator 
Hive,WITHOUT_CLASSIFICATION,//  null for tables VIRTUAL_VIEW for views MATERIALIZED_VIEW for MVs 
Hive,WITHOUT_CLASSIFICATION,//  Now that the properties are in we can instantiate SessionState. 
Hive,WITHOUT_CLASSIFICATION,//  O2 
Hive,WITHOUT_CLASSIFICATION,//  repeated string tablesWritten = 9; 
Hive,WITHOUT_CLASSIFICATION,//  Generic UDTF's 
Hive,WITHOUT_CLASSIFICATION,// Output will also be repeating and null 
Hive,WITHOUT_CLASSIFICATION,//  Add the table spec for the destination table. 
Hive,WITHOUT_CLASSIFICATION,//  a>0 
Hive,WITHOUT_CLASSIFICATION,//  Same session object is expected. 
Hive,WITHOUT_CLASSIFICATION,//  If partitioning columns of the parent RS are not assigned   assign partitioning columns of the child RS to the parent RS. 
Hive,WITHOUT_CLASSIFICATION,//  Create 5 dbs 
Hive,WITHOUT_CLASSIFICATION,//  matches 
Hive,WITHOUT_CLASSIFICATION,//  this dependency is removed for HBase 1.0 
Hive,WITHOUT_CLASSIFICATION,// ensures that FS object is cached so that everyone uses the same instance 
Hive,WITHOUT_CLASSIFICATION,//  try to create RCFile.Reader 
Hive,WITHOUT_CLASSIFICATION,//  And their types. 
Hive,WITHOUT_CLASSIFICATION,// The tests here are heavily based on some timing so there is some chance to fail. 
Hive,WITHOUT_CLASSIFICATION,//  perform incremental normalization 
Hive,WITHOUT_CLASSIFICATION,//  Set the inferred sort columns for the file this FileSink produces 
Hive,WITHOUT_CLASSIFICATION,//  round up 
Hive,WITHOUT_CLASSIFICATION,//  LlapIoImpl.LOG.debug("diskData " + diskData); 
Hive,WITHOUT_CLASSIFICATION,//  O5 
Hive,WITHOUT_CLASSIFICATION,//  Mock BeeLineOpts 
Hive,WITHOUT_CLASSIFICATION,//  Intentionally set this high so that it will not trigger major compaction for ttp1. 
Hive,WITHOUT_CLASSIFICATION,// make sure to check for side file in case streaming ingest died 
Hive,WITHOUT_CLASSIFICATION,//  Rewrite the delete or update into an insert.  Crazy but it works as deletes and update   actually are inserts into the delta file in Hive.  A delete   DELETE FROM _tablename_ [WHERE ...]   will be rewritten as   INSERT INTO TABLE _tablename_ [PARTITION (_partcols_)] SELECT ROW__ID[   _partcols_] from _tablename_ SORT BY ROW__ID   An update   UPDATE _tablename_ SET x = _expr_ [WHERE...]   will be rewritten as   INSERT INTO TABLE _tablename_ [PARTITION (_partcols_)] SELECT _all_   _partcols_from _tablename_ SORT BY ROW__ID   where _all_ is all the non-partition columns.  The expressions from the set clause will be   re-attached later.   The where clause will also be re-attached later.   The sort by clause is put in there so that records come out in the right order to enable   merge on read. 
Hive,WITHOUT_CLASSIFICATION,//  We consider this an enable issue not a not vectorized issue. 
Hive,WITHOUT_CLASSIFICATION,//  Our outputs are the transitive outputs of our inputs. 
Hive,WITHOUT_CLASSIFICATION,//  we need to know if aggregate is COUNT since IN corr subq with count aggregate 
Hive,WITHOUT_CLASSIFICATION,//  do this only when not initialized but we may need to find a way to   tell the caller how to initialize the valid size 
Hive,WITHOUT_CLASSIFICATION,//  Pass unparsed db name here 
Hive,WITHOUT_CLASSIFICATION,//  add expr to the list of predicates rejected from further pushing   so that we know to add it in createFilter() 
Hive,WITHOUT_CLASSIFICATION,//  This is a partition 
Hive,WITHOUT_CLASSIFICATION,//  Exception is expected only if filter is enabled and injection is disabled 
Hive,WITHOUT_CLASSIFICATION,//  O4 
Hive,WITHOUT_CLASSIFICATION,//  catch up with the big table. 
Hive,WITHOUT_CLASSIFICATION,//  Get service ticket from the authorization header 
Hive,WITHOUT_CLASSIFICATION,/*    * Call this method may be called after all the all fields have been read to check   * for unread fields.   *   * Note that when optimizing reading to stop reading unneeded include columns worrying   * about whether all data is consumed is not appropriate (often we aren't reading it all by   * design).   *   * Since LazySimpleDeserializeRead parses the line through the last desired column it does   * support this function.    */
Hive,WITHOUT_CLASSIFICATION,//  Bad format. 
Hive,WITHOUT_CLASSIFICATION,// process join filters 
Hive,WITHOUT_CLASSIFICATION,//  Event 2 3 4 
Hive,WITHOUT_CLASSIFICATION,//  COMPACTS 
Hive,WITHOUT_CLASSIFICATION,//  test with a batch size of 30 and decaying factor of 2 
Hive,WITHOUT_CLASSIFICATION,//  load set 
Hive,WITHOUT_CLASSIFICATION,//  Position to beginning. 
Hive,WITHOUT_CLASSIFICATION,//  Input to the script 
Hive,WITHOUT_CLASSIFICATION,//  Set global member indicating which virtual columns are possible to be used by 
Hive,WITHOUT_CLASSIFICATION,//  removes the threadlocal variables closes underlying HMS connection 
Hive,WITHOUT_CLASSIFICATION,/*    * Tests the case when tblPath/p1=a/p2=b/p3=c/file for a table with partition (p1 p2)   * does not throw HiveException    */
Hive,WITHOUT_CLASSIFICATION,//  exceeds this value 
Hive,WITHOUT_CLASSIFICATION,//  Set the table write id in all of the acid file sinks 
Hive,WITHOUT_CLASSIFICATION,//  The get_splits call should have resulted in a lock on ACIDTBL 
Hive,WITHOUT_CLASSIFICATION,/*   * (non-Javadoc)  *  * @see  * org.apache.hadoop.hive.ql.security.authorization.HiveAuthorizationProvider  * #init(org.apache.hadoop.conf.Configuration)   */
Hive,WITHOUT_CLASSIFICATION,// do this for all complex types and binary 
Hive,WITHOUT_CLASSIFICATION,//  In case of KeepAlive ensure that timeout handler does not close connection until entire 
Hive,WITHOUT_CLASSIFICATION,//  some tests expected to pass invalid schema 
Hive,WITHOUT_CLASSIFICATION,//  max 
Hive,WITHOUT_CLASSIFICATION,//  Replace the reducer with our fully vectorized reduce operator tree. 
Hive,WITHOUT_CLASSIFICATION,//  No longer relevant for WM. 
Hive,WITHOUT_CLASSIFICATION,/*    * Set of functions to create the Null Check Query for Not-In SubQuery predicates.   * For a SubQuery predicate like:   *   a not in (select b from R2 where R2.y > 5)   * The Not In null check query is:   *   (select count(*) as c from R2 where R2.y > 5 and b is null)   * This Subquery is joined with the Outer Query plan on the join condition 'c = 0'.   * The join condition ensures that in case there are null values in the joining column   * the Query returns no rows.   *    * The AST tree for this is:   *    * ^(TOK_QUERY   *    ^(TOK FROM   *        ^(TOK_SUBQUERY   *            {the input SubQuery with correlation removed}   *            subQueryAlias    *          )    *     )   *     ^(TOK_INSERT   *         ^(TOK_DESTINATION...)   *         ^(TOK_SELECT   *             ^(TOK_SELECTEXPR {ast tree for count *}   *          )   *          ^(TOK_WHERE   *             {is null check for joining column}    *           )   *      )   * )    */
Hive,WITHOUT_CLASSIFICATION,//  Supports keeping a HiveIntervalDayTimeWritable object without having to import   that definition... 
Hive,WITHOUT_CLASSIFICATION,//  Preven subsequent runs until a new trigger is set. 
Hive,WITHOUT_CLASSIFICATION,// since HIVE-17089 if here then it's not an acid table so there should never be any deltas 
Hive,WITHOUT_CLASSIFICATION,//  Then try the brute force search for something to throw away. 
Hive,WITHOUT_CLASSIFICATION,//  O6 
Hive,WITHOUT_CLASSIFICATION,//  Get the Job Handle id associated with the Spark job 
Hive,WITHOUT_CLASSIFICATION,//  just a safe check to ensure that we are not reading empty delete files. 
Hive,WITHOUT_CLASSIFICATION,//  Since we are creating with scale 0 no fraction digits to zero trim. 
Hive,WITHOUT_CLASSIFICATION,//           LOG.info("Getting parent of "+ptnRoot.getName()); 
Hive,WITHOUT_CLASSIFICATION,//  synthetic predicate with dynamic values 
Hive,WITHOUT_CLASSIFICATION,//  To get around hbase failure on single node see BUG-4383 
Hive,WITHOUT_CLASSIFICATION,//  terminate the old task and make current task dependent on it 
Hive,WITHOUT_CLASSIFICATION,//  after concatenating them with AND operator 
Hive,WITHOUT_CLASSIFICATION,//  Start the Shuffle service before the listener - until it's a service as well. 
Hive,WITHOUT_CLASSIFICATION,// e.g. map z->ColumnInfo for a 
Hive,WITHOUT_CLASSIFICATION,//  Replicate table definition. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure that the number of column aliases in the AS clause matches 
Hive,WITHOUT_CLASSIFICATION,//  If it contains a reducer the optimization is always on.   Since there exists a reducer the sorting/bucketing properties due to the   sort-merge join operator are lost anyway. So the plan cannot be wrong by 
Hive,WITHOUT_CLASSIFICATION,/*    * Runs the templeton controller job with 'args'. Utilizes ToolRunner to run   * the actual job.    */
Hive,WITHOUT_CLASSIFICATION,// intentional fall through 
Hive,WITHOUT_CLASSIFICATION,//  HiveConf hive.stats.ndv.error default produces 16 vectors 
Hive,WITHOUT_CLASSIFICATION,/*        * Raise custom exception like IOException and verify expected Message.       * This should not invoke cancel operation.        */
Hive,WITHOUT_CLASSIFICATION,//  if we're performing a binary search we need to restart it 
Hive,WITHOUT_CLASSIFICATION,//  Close the client connection with ZooKeeper 
Hive,WITHOUT_CLASSIFICATION,//  do loop once again with the new cause of "current" 
Hive,WITHOUT_CLASSIFICATION,// why is this checking for deltas.isEmpty() - HIVE-18110 
Hive,WITHOUT_CLASSIFICATION,//  Retrieve attempt log into logDir 
Hive,WITHOUT_CLASSIFICATION,// verify data 
Hive,WITHOUT_CLASSIFICATION,//  No type promotion. Everything goes to decimal. 
Hive,WITHOUT_CLASSIFICATION,//  The field bits (i.e. which fields to include) or "id" for each grouping set. 
Hive,WITHOUT_CLASSIFICATION,//  the size of the biggest small table 
Hive,WITHOUT_CLASSIFICATION,//  test forward scan 
Hive,WITHOUT_CLASSIFICATION,//  Small case: Just write the value bytes only. 
Hive,WITHOUT_CLASSIFICATION,//  Generate the kerberos ticket under the following scenarios:   1. Cookie Authentication is disabled OR   2. The first time when the request is sent OR   3. The server returns a 401 which sometimes means the cookie has expired 
Hive,WITHOUT_CLASSIFICATION,//  we tried .. 
Hive,WITHOUT_CLASSIFICATION,/*    * If a CTE is referenced in a QueryBlock:   * - add it as a SubQuery for now.   *   - SQ.alias is the alias used in QB. (if no alias is specified   *     it used the CTE name. Works just like table references)   *   - Adding SQ done by:   *     - copying AST of CTE   *     - setting ASTOrigin on cloned AST.   *   - trigger phase 1 on new QBExpr.   *   - update QB data structs: remove this as a table reference move it to a SQ invocation.    */
Hive,WITHOUT_CLASSIFICATION,//  number of rows -1 means that statistics from metastore is not reliable 
Hive,WITHOUT_CLASSIFICATION,//  Repeated non-NULL fill down column. 
Hive,WITHOUT_CLASSIFICATION,//  2.1 Handle the case for unpartitioned table. 
Hive,WITHOUT_CLASSIFICATION,//  try a zero-divide to show a repeating NULL is produced 
Hive,WITHOUT_CLASSIFICATION,//  END pattern 
Hive,WITHOUT_CLASSIFICATION,//  Setup hashcode 
Hive,WITHOUT_CLASSIFICATION,//  Test setter for map object. 
Hive,WITHOUT_CLASSIFICATION,//  Choose array size. We have two hash tables to hold entries so the sum   of the two should have a bit more than twice as much space as the 
Hive,WITHOUT_CLASSIFICATION,//  Added conf member to set the REPL command specific config entries without affecting the configs 
Hive,WITHOUT_CLASSIFICATION,//  The number of reducers of the child RS is more specific than   that of the parent RS. Assign the number of reducers of the child RS   to the parent RS. 
Hive,WITHOUT_CLASSIFICATION,//  won't happen 
Hive,WITHOUT_CLASSIFICATION,//  Wrap the transport exception in an RTE since Subject.doAs() then goes   and unwraps this for us out of the doAs block. We then unwrap one   more time in our catch clause to get back the TTE. (ugh) 
Hive,WITHOUT_CLASSIFICATION,//  3) We propagate 
Hive,WITHOUT_CLASSIFICATION,//  Do nothing in case proc is null 
Hive,WITHOUT_CLASSIFICATION,//  The output precision is 10 greater than the input which should cover at least   10b rows. The scale is the same as the input. 
Hive,WITHOUT_CLASSIFICATION,//  1. Convert inputs 
Hive,WITHOUT_CLASSIFICATION,//  tables that were serialized with columnsetSerDe doesn't have metadata   so this hack applies to all such tables 
Hive,WITHOUT_CLASSIFICATION,//  Cancel currently executing tasks 
Hive,WITHOUT_CLASSIFICATION,//  the list element object inspector 
Hive,WITHOUT_CLASSIFICATION,//  Skip rest of checks if user is admin 
Hive,WITHOUT_CLASSIFICATION,//  standard error allowed for ndv estimates for FM-sketch. A lower value indicates higher accuracy and a 
Hive,WITHOUT_CLASSIFICATION,//  replace existing view 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setArray(int java.sql.Array)    */
Hive,WITHOUT_CLASSIFICATION,//  ////// 1. Generate ReduceSinkOperator   There is a special case when we want the rows to be randomly distributed   to   reducers for load balancing problem. That happens when there is no   DISTINCT   operator. We set the numPartitionColumns to -1 for this purpose. This is 
Hive,WITHOUT_CLASSIFICATION,//  Drop any left over catalogs 
Hive,WITHOUT_CLASSIFICATION,//  TreeSet anyway uses TreeMap; so use plain TreeMap to be able to get value in collisions. 
Hive,WITHOUT_CLASSIFICATION,// this is idempotent 
Hive,WITHOUT_CLASSIFICATION,//  Adding column names used later by org.apache.hadoop.hive.druid.serde.DruidSerDe 
Hive,WITHOUT_CLASSIFICATION,//  We expect cache requests from the middle here 
Hive,WITHOUT_CLASSIFICATION,/*      * Count *any* input except null which is for COUNT(*) and output is LONG.     *     * Just modes (PARTIAL1 COMPLETE).      */
Hive,WITHOUT_CLASSIFICATION,//  Some filters may have been specified in the SHOW LOCKS statement. Add them to the query. 
Hive,WITHOUT_CLASSIFICATION,//  2. Gen GB-RS-GB-RS-GB pipeline 
Hive,WITHOUT_CLASSIFICATION,//  it will be considered ENABLE and NOVALIDATE and RELY=false 
Hive,WITHOUT_CLASSIFICATION,//  if the driver is not already available in the URL add the one provided 
Hive,WITHOUT_CLASSIFICATION,//  check that src and dest are on the same file system 
Hive,WITHOUT_CLASSIFICATION,//  of dynamic partition list to the StatsTask 
Hive,WITHOUT_CLASSIFICATION,/* if this method ends with anything except a retry signal the caller should fail the operation      and propagate the error up to the its caller (Metastore client); thus must reset retry counters */
Hive,WITHOUT_CLASSIFICATION,/*    * Job Request type.    */
Hive,WITHOUT_CLASSIFICATION,//  Start the scheduled poll task 
Hive,WITHOUT_CLASSIFICATION,//  load data 
Hive,WITHOUT_CLASSIFICATION,//  All the vertices belong to the same DAG so we just use numbers. 
Hive,WITHOUT_CLASSIFICATION,//  Make sure the table in the target database didn't get clobbered 
Hive,WITHOUT_CLASSIFICATION,//  Fall through... 
Hive,WITHOUT_CLASSIFICATION,//  this input rel is not rewritten 
Hive,WITHOUT_CLASSIFICATION,//  Add a single child and restart the loop 
Hive,WITHOUT_CLASSIFICATION,// write credential with token to file 
Hive,WITHOUT_CLASSIFICATION,//  Use UpdateQueryResponseProto.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,//  read the schema version stored in metastore db 
Hive,WITHOUT_CLASSIFICATION,//  It is possible that read and write entities contain a old version   of the object before it was modified by StatsTask.   Get the latest versions of the object 
Hive,WITHOUT_CLASSIFICATION,//  The buffer is not in the (full) heap. Demote the top item of the heap into the list. 
Hive,WITHOUT_CLASSIFICATION,//  make sure all leaves are visited at least once 
Hive,WITHOUT_CLASSIFICATION,//  successfully convert to bucket map join 
Hive,WITHOUT_CLASSIFICATION,//  Evaluate the HashCode 
Hive,WITHOUT_CLASSIFICATION,/*    * Represents a Select Expression in the context of Windowing. These can   * refer to the output of Windowing Functions and can navigate the   * Partition using Lead/Lag functions.    */
Hive,WITHOUT_CLASSIFICATION,//  If filter condition is TRUE we ignore it 
Hive,WITHOUT_CLASSIFICATION,//        actually run (which is a different under doAs=false). This seems to be intended. 
Hive,WITHOUT_CLASSIFICATION,//        reducers don't produce enough files; we'll do the same for MM tables for now. 
Hive,WITHOUT_CLASSIFICATION,//  jar then this would be needed 
Hive,WITHOUT_CLASSIFICATION,//  Don't retry immediately - use delay with exponential backoff 
Hive,WITHOUT_CLASSIFICATION,//  LRFU cache policy doesn't store locked blocks. When we cache the block is locked so   we simply do nothing here. The fact that it was never updated will allow us to add it   properly on the first notifyUnlock.   We'll do is set priority to account for the inbound one. No lock - not in heap. 
Hive,WITHOUT_CLASSIFICATION,/*      * Extract information.      */
Hive,WITHOUT_CLASSIFICATION,//  fold after replacing if possible 
Hive,WITHOUT_CLASSIFICATION,//  Should have also been thrown out. 
Hive,WITHOUT_CLASSIFICATION,//  Add the newly generated IN clause to subExpr. 
Hive,WITHOUT_CLASSIFICATION,//  \x05 
Hive,WITHOUT_CLASSIFICATION,//  test that we don't drop the unnecessary tuple if the table has the corresponding Struct 
Hive,WITHOUT_CLASSIFICATION,//  get children of key node 
Hive,WITHOUT_CLASSIFICATION,// if this wasn't an empty txn we'd get a better msg 
Hive,WITHOUT_CLASSIFICATION,//  will be set to the larger of the parents 
Hive,WITHOUT_CLASSIFICATION,//  If so mark that branch as the big table branch. 
Hive,WITHOUT_CLASSIFICATION,//  this will create a project which will project out the column in positions 
Hive,WITHOUT_CLASSIFICATION,//  return the next back zk server's port 
Hive,WITHOUT_CLASSIFICATION,//  merge should convert hll3 to DENSE 
Hive,WITHOUT_CLASSIFICATION,//  In case the expression is TABLE.COL (col can be regex).   This can only happen without AS clause   We don't allow this for ExprResolver - the Group By case 
Hive,WITHOUT_CLASSIFICATION,// Schema only 
Hive,WITHOUT_CLASSIFICATION,//  calculate filter propagation directions for each alias   L<->R for inner/semi join L<-R for left outer join R<-L for right outer 
Hive,WITHOUT_CLASSIFICATION,//  non-native and non-managed tables are not supported as MoveTask requires filenames to be in specific format 
Hive,WITHOUT_CLASSIFICATION,//    Extract each entry from the pathenv   
Hive,WITHOUT_CLASSIFICATION,//    return true;   } 
Hive,WITHOUT_CLASSIFICATION,//  as possible 
Hive,WITHOUT_CLASSIFICATION,//  value needs to be converted to match type params 
Hive,WITHOUT_CLASSIFICATION,//  Dump metrics to string as JSON 
Hive,WITHOUT_CLASSIFICATION,//  Dump all the events except DROP 
Hive,WITHOUT_CLASSIFICATION,//  Gained it again. 
Hive,WITHOUT_CLASSIFICATION,//  not using FileInputFormat.setInputPaths() here because it forces a connection to the 
Hive,WITHOUT_CLASSIFICATION,//  by default we aggregate counters across the entire DAG. Example: SHUFFLE_BYTES would mean SHUFFLE_BYTES   of each vertex aggregated together to create DAG level SHUFFLE_BYTES.   Use case: If SHUFFLE_BYTES across the entire DAG is > limit perform action 
Hive,WITHOUT_CLASSIFICATION,//  Skewed Info 
Hive,WITHOUT_CLASSIFICATION,//  Make sure the updates are not sent to ZK out of order compared to how we apply them in AM. 
Hive,WITHOUT_CLASSIFICATION,/*  Number of mantissa digits BEFORE decimal				 * point.  */
Hive,WITHOUT_CLASSIFICATION,//  3 5 8 
Hive,WITHOUT_CLASSIFICATION,//  6. Let Cleaner delete obsolete files/dirs 
Hive,WITHOUT_CLASSIFICATION,//  Release all the previous buffers that we may not have been able to release due to reuse 
Hive,WITHOUT_CLASSIFICATION,//  Get the actual length first 
Hive,WITHOUT_CLASSIFICATION,//  Ensure this is set in the config so that the AM can read it. 
Hive,WITHOUT_CLASSIFICATION,//  drop test db and its tables and views 
Hive,WITHOUT_CLASSIFICATION,//  Change the engine to tez 
Hive,WITHOUT_CLASSIFICATION,//  Test for only colNames being empty 
Hive,WITHOUT_CLASSIFICATION,//  This is a guard for special Druid types e.g. hyperUnique   (http://druid.io/docs/0.9.1.1/querying/aggregations.html#hyperunique-aggregator).   Currently we do not support doing anything special with them in Hive.   However those columns are there and they can be actually read as normal   dimensions e.g. with a select query. Thus we print the warning and just read them   as String. 
Hive,WITHOUT_CLASSIFICATION,//  operations that have objects of type COMMAND_PARAMS FUNCTION are authorized   solely on the type 
Hive,WITHOUT_CLASSIFICATION,//  Note: this doesn't maintain proper newStream semantics (if any).          We could either clone this instead or enforce that this is only called once. 
Hive,WITHOUT_CLASSIFICATION,//  str 
Hive,WITHOUT_CLASSIFICATION,/*  Move logic to PrunerUtils.walkOperatorTree() so that it can be reused.  */
Hive,WITHOUT_CLASSIFICATION,//  separator for open write ids   separator for aborted write ids 
Hive,WITHOUT_CLASSIFICATION,//  Process the position alias in GROUPBY and ORDERBY 
Hive,WITHOUT_CLASSIFICATION,//  There are none or they're not readable. 
Hive,WITHOUT_CLASSIFICATION,//  Get the character/byte at the offset in the string equal to the fieldID 
Hive,WITHOUT_CLASSIFICATION,// default column name 
Hive,WITHOUT_CLASSIFICATION,//  Definitely a int; most ints fall here 
Hive,WITHOUT_CLASSIFICATION,/*    * Right trim a slice of a byte array and place the result into element i of a vector.    */
Hive,WITHOUT_CLASSIFICATION,//  though id is given as a Short by hcat the map will emit it as an 
Hive,WITHOUT_CLASSIFICATION,//  0 NULL 
Hive,WITHOUT_CLASSIFICATION,//  columns have been added. 
Hive,WITHOUT_CLASSIFICATION,// needed by initArgs for certain execution paths 
Hive,WITHOUT_CLASSIFICATION,/*          * Single-Column String specific variables.          */
Hive,WITHOUT_CLASSIFICATION,//  Multiple concurrent local mode job submissions can cause collisions in   working dirs and system dirs   Workaround is to rename map red working dir to a temp dir in such cases 
Hive,WITHOUT_CLASSIFICATION,//  1 + 2 + 4 + 8 + 4 + 8 + 3 + 4 + 3 + 4 + 4 + 4 + 3 + 4 + 2 + 4 + 3 + 5 + 4 + 5 + 7 + 4 + 7 = 
Hive,WITHOUT_CLASSIFICATION,//  get forwarded hosts address 
Hive,WITHOUT_CLASSIFICATION,/*      * validate and setup patternStr      */
Hive,WITHOUT_CLASSIFICATION,//  no duplicate column names   currently it is a simple n*n algorithm - this can be optimized later if   need be   but it should not be a major bottleneck as the number of columns are   anyway not so big 
Hive,WITHOUT_CLASSIFICATION,//  Should only need to insert the token the first time. 
Hive,WITHOUT_CLASSIFICATION,//  Deserialize key into vector row columns. 
Hive,WITHOUT_CLASSIFICATION,//  That Union[T NULL] is converted to just T. 
Hive,WITHOUT_CLASSIFICATION,//  BitSet for flagging aborted transactions. Bit is true if aborted false if open  default value means there are no open txn in the snapshot 
Hive,WITHOUT_CLASSIFICATION,/*  Test DatabaseMetaData queries which do not have a parent Statement  */
Hive,WITHOUT_CLASSIFICATION,//  Looks like some pools were removed; kill running queries re-queue the queued ones. 
Hive,WITHOUT_CLASSIFICATION,//     top. 
Hive,WITHOUT_CLASSIFICATION,//       Hive3 probably won't support MR so do we really care?  
Hive,WITHOUT_CLASSIFICATION,//  Copy log file 
Hive,WITHOUT_CLASSIFICATION,/*      * For fully specified ptn follow strict checks for existence of partitions in metadata     * For unpartitioned tables follow filechecks     * For partially specified tables:     *    This would then need filechecks at the start of a ptn write     *    Doing metadata checks can get potentially very expensive (fat conf) if     *    there are a large number of partitions that match the partial specifications      */
Hive,WITHOUT_CLASSIFICATION,//  Get partitions by name - ascending or descending 
Hive,WITHOUT_CLASSIFICATION,//  Start the process to add MV to the cache 
Hive,WITHOUT_CLASSIFICATION,//  Make sure all partitioning columns referenced actually   exist and are in the correct order at the end   of the list of columns produced by the view. Also move the field   schema descriptors from derivedSchema to the partitioning key 
Hive,WITHOUT_CLASSIFICATION,//  We assume each SD has an unique serde. 
Hive,WITHOUT_CLASSIFICATION,// Set the key check if this is a new group or same group 
Hive,WITHOUT_CLASSIFICATION,// Short Running updated nothing so we expect 0 rows in WRITE_SET 
Hive,WITHOUT_CLASSIFICATION,//  PART_VALUES 
Hive,WITHOUT_CLASSIFICATION,/*  * The interface for a single long key hash map lookup method.  */
Hive,WITHOUT_CLASSIFICATION,/*        * If the thread is still active and needs to be cancelled then cancel it. This may       * happen in case task got interrupted or timed out.        */
Hive,WITHOUT_CLASSIFICATION,//  replace the cRS to SEL operator 
Hive,WITHOUT_CLASSIFICATION,//  let's remember the join operators we have processed 
Hive,WITHOUT_CLASSIFICATION,//  Transaction and locking methods 
Hive,WITHOUT_CLASSIFICATION,//  Remove the semijoin optimization branch along with ALL the mappings   The parent GB2 has all the branches. Collect them and remove them. 
Hive,WITHOUT_CLASSIFICATION,//  Race with queryComplete 
Hive,WITHOUT_CLASSIFICATION,//  Updated when we add this to the queue. 
Hive,WITHOUT_CLASSIFICATION,//  Wait for the current future. 
Hive,WITHOUT_CLASSIFICATION,//  STAGES: 03/04            [==================>>-----] 86%  ELAPSED TIME: 1.71 s 
Hive,WITHOUT_CLASSIFICATION,//  Time after which metastore cache is updated from metastore DB by the background update thread 
Hive,WITHOUT_CLASSIFICATION,//  Don't push a sampling predicate since createFilter() always creates filter   with isSamplePred = false. Also the filterop with sampling pred is always 
Hive,WITHOUT_CLASSIFICATION,//  bunch of things get setup in the context based on conf but we need only the MR tmp directory 
Hive,WITHOUT_CLASSIFICATION,//  Web port 
Hive,WITHOUT_CLASSIFICATION,//  If we did not add any factor or there are no common factors we can 
Hive,WITHOUT_CLASSIFICATION,// will succeed and transition to Initiated->Working->Ready for Cleaning 
Hive,WITHOUT_CLASSIFICATION,//  Overlay the values of any system properties whose names appear in the list of ConfVars 
Hive,WITHOUT_CLASSIFICATION,//  this conditions need to be pushed into semi-join since this condition   corresponds to IN 
Hive,WITHOUT_CLASSIFICATION,//  Create db2/t1/part1                /part2                /part3   Test: recycle single file (part1)         recycle table t1 
Hive,WITHOUT_CLASSIFICATION,//  create the temp directories 
Hive,WITHOUT_CLASSIFICATION,//  Remove the paths which are not part of aliasToPartitionInfo 
Hive,WITHOUT_CLASSIFICATION,//  Both neededColumnIDs and neededColumns should never be null.   When neededColumnIDs is an empty list   it means no needed column (e.g. we do not need any column to evaluate 
Hive,WITHOUT_CLASSIFICATION,//  store types and tables   separately because one cannot use a table (ie service.method) as a Struct 
Hive,WITHOUT_CLASSIFICATION,/*    * Used by Struct and Union complex type readers to indicate the (final) field has been fully   * read and the current complex type is finished.    */
Hive,WITHOUT_CLASSIFICATION,/*      * OPTIMIZATION     * The ConditionalTask avoids linking 2 MoveTask that are expensive on blobstorage systems. Instead of     * linking it creates one MoveTask where the source is the first MoveTask source and target is the     * second MoveTask target.      */
Hive,WITHOUT_CLASSIFICATION,// p=10 needs major compaction 
Hive,WITHOUT_CLASSIFICATION,//  We only can have a single partition spec 
Hive,WITHOUT_CLASSIFICATION,//  All others from the remote service cause the task to FAIL. 
Hive,WITHOUT_CLASSIFICATION,//  This is a file or something we don't hold locks for. 
Hive,WITHOUT_CLASSIFICATION,//  v[10] -- since left integer #5 is always 0 some products here are not included. 
Hive,WITHOUT_CLASSIFICATION,/*      * We have a field and are positioned to it.  Read it.      */
Hive,WITHOUT_CLASSIFICATION,//  by default for all other objects this is false 
Hive,WITHOUT_CLASSIFICATION,/*    * STRING CHAR VARCHAR and BINARY.   *   * For CHAR and VARCHAR when the caller takes responsibility for   * truncation/padding issues.   *   * When currentExternalBufferNeeded is true conversion is needed into an external buffer of   * at least currentExternalBufferNeededLen bytes.  Use copyToExternalBuffer to get the result.   *   * Otherwise currentBytes currentBytesStart and currentBytesLength are the result.    */
Hive,WITHOUT_CLASSIFICATION,//  group path alias according to work 
Hive,WITHOUT_CLASSIFICATION,//  - There cannot exist any sampling predicate. 
Hive,WITHOUT_CLASSIFICATION,//  all rows from right side will be present in resultset 
Hive,WITHOUT_CLASSIFICATION,//  This will work with the new support of rewriting load into IAS. 
Hive,WITHOUT_CLASSIFICATION,//  By assumption ACID columns are currently always in the beginning of the arrays. 
Hive,WITHOUT_CLASSIFICATION,/*  Authorization Errors 3000 - 3999  */
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getCharacterStream(java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  Combine/sort temp and normal table results 
Hive,WITHOUT_CLASSIFICATION,//  We have estimation lowerbound and higherbound. We use estimation if   it is between lowerbound and higherbound. 
Hive,WITHOUT_CLASSIFICATION,//  only do split pruning if HIVE-8732 has been fixed in the writer 
Hive,WITHOUT_CLASSIFICATION,//  Set temp file containing error output to be sent to client 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *    * @see   * org.apache.hadoop.hive.ql.udf.ptf.TableFunctionEvaluator#startPartition()    */
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.CLIServiceClient#getColumns(org.apache.hive.service.cli.SessionHandle java.lang.String java.lang.String java.lang.String java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  Create tmp dir for MergeFileWork 
Hive,WITHOUT_CLASSIFICATION,/*    * The small key length.   *   * If the key is big (i.e. length >= allBitsOn) then the key length is stored in the   * WriteBuffers.    */
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.ICLIService#getSchemas(org.apache.hive.service.cli.SessionHandle java.lang.String java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  DataNucleus objects get detached all over the place for no (real) reason. 
Hive,WITHOUT_CLASSIFICATION,//  now let's take a look at input sizes 
Hive,WITHOUT_CLASSIFICATION,//  2. We extract possible candidates to be pushed down 
Hive,WITHOUT_CLASSIFICATION,//  remove restrictions on the variables that can be set using set command 
Hive,WITHOUT_CLASSIFICATION,//  we can generate ranges from e.g. rowid > (4 + 5) 
Hive,WITHOUT_CLASSIFICATION,//  ArrayListMultimap is important here to retain the ordering for the splits. 
Hive,WITHOUT_CLASSIFICATION,//  Lookup nDVs on TS side. 
Hive,WITHOUT_CLASSIFICATION,//  If the RS has other RS siblings we will add it to be considered in next iteration 
Hive,WITHOUT_CLASSIFICATION,//  Cannot wrap a reader for non-vectorized pipeline. 
Hive,WITHOUT_CLASSIFICATION,//  Example: "000126" => 126 => "126" 
Hive,WITHOUT_CLASSIFICATION,/*          * this is the small table side. In case of SMB join we need to send each split to the         * corresponding bucket-based task on the other side. In case a split needs to go to         * multiple downstream tasks we need to clone the event and send it to the right         * destination.          */
Hive,WITHOUT_CLASSIFICATION,//  Keep order by name consistent with JDO. 
Hive,WITHOUT_CLASSIFICATION,/*  A delta may be present from a previous failed task attempt.  */
Hive,WITHOUT_CLASSIFICATION,//  MIN_HISTORY_LEVEL will have 1 entry for the open txn. 
Hive,WITHOUT_CLASSIFICATION,//  nested complex types cannot be folded cleanly 
Hive,WITHOUT_CLASSIFICATION,//  the same process. This will still only get the functions from the first metastore. 
Hive,WITHOUT_CLASSIFICATION,//  add only if the corresponding family has not already been added 
Hive,WITHOUT_CLASSIFICATION,//  write the byte to stream every 4 key-value pairs 
Hive,WITHOUT_CLASSIFICATION,//  base  = JAVA64_OBJECT + PRIMITIVES1 * 2 + JAVA64_FIELDREF;   entry = JAVA64_OBJECT + JAVA64_FIELDREF * 2 
Hive,WITHOUT_CLASSIFICATION,//  start writing array contents 
Hive,WITHOUT_CLASSIFICATION,//  Skip past blank characters. 
Hive,WITHOUT_CLASSIFICATION,//  vectorized row batch not for example an original inspector for an ORC table etc. 
Hive,WITHOUT_CLASSIFICATION,//  Stats part 
Hive,WITHOUT_CLASSIFICATION,//  If all of them were false return false 
Hive,WITHOUT_CLASSIFICATION,//  12 hours 
Hive,WITHOUT_CLASSIFICATION,//  Get the sort by aliases - these are aliased to the entries in the   select list 
Hive,WITHOUT_CLASSIFICATION,//  Grab the oldest in-memory buffered batch and dump it to disk. 
Hive,WITHOUT_CLASSIFICATION,//  statics for when the mock fs is created via FileSystem.get 
Hive,WITHOUT_CLASSIFICATION,//  this must be hadoop 2.4  where getDefaultProperties was protected 
Hive,WITHOUT_CLASSIFICATION,//  map table name to the correct ColumnStatsTask 
Hive,WITHOUT_CLASSIFICATION,//  Use system zone when converting from timestamp to timestamptz 
Hive,WITHOUT_CLASSIFICATION,//  This tests checks that appropriate delta and delete_deltas are included when minor   compactions specifies a valid open txn range. 
Hive,WITHOUT_CLASSIFICATION,//  only case is full outer join with SMB enabled which is not possible. Convert to regular   join. 
Hive,WITHOUT_CLASSIFICATION,//  print next vertex 
Hive,WITHOUT_CLASSIFICATION,//  to dbname-matching alone. 
Hive,WITHOUT_CLASSIFICATION,//  ATTRIBUTES 
Hive,WITHOUT_CLASSIFICATION,// TODO: Even listener for default  AddDefaultConstraintEvent addDefaultConstraintEvent = new AddDefaultConstraintEvent(defaultConstraintCols true this); 
Hive,WITHOUT_CLASSIFICATION,/*    * join current union task to old task    */
Hive,WITHOUT_CLASSIFICATION,//  Verify the eventID was passed to the non-transactional listener 
Hive,WITHOUT_CLASSIFICATION,//  2. We check whether there is a column needed by the      windowing operation that is missing in the      project expressions. For instance if the windowing      operation is over an aggregation column Hive expects      that column to be in the Select clause of the query.      The idea is that if there is a column missing we will      replace the old project operator by two new project      operators:      - a project operator containing the original columns        of the project operator plus all the columns that were        missing      - a project on top of the previous one that will take        out the columns that were missing and were added by the        previous project 
Hive,WITHOUT_CLASSIFICATION,//  2. Insert the current constant value into exprNodeStructs list.   If there is no struct corresponding to the current element create a new one insert 
Hive,WITHOUT_CLASSIFICATION,//  notify listeners 
Hive,WITHOUT_CLASSIFICATION,//  Comparing paths multiple times creates lots of objects &   creates GC pressure for tables having large number of partitions.   In such cases use pre-computed paths for comparison 
Hive,WITHOUT_CLASSIFICATION,//  Skip duplicated grouping keys it happens when define column alias. 
Hive,WITHOUT_CLASSIFICATION,//  link SEL to FS 
Hive,WITHOUT_CLASSIFICATION,//  try repeating on both sides 
Hive,WITHOUT_CLASSIFICATION,//  miniHS2_2 will become leader 
Hive,WITHOUT_CLASSIFICATION,//  Update the last access time for this node 
Hive,WITHOUT_CLASSIFICATION,//  check input object's length if it doesn't match   then output new writable with correct params. 
Hive,WITHOUT_CLASSIFICATION,//  We have an IOException other than a BlockMissingException. 
Hive,WITHOUT_CLASSIFICATION,//  expectedRestrictedMap 
Hive,WITHOUT_CLASSIFICATION,/*            * Vectorizer does not vectorize in row deserialize mode if the input format has           * VectorizedInputFormat so input formats will be clear if the isVectorized flag           * is on they are doing VRB work.            */
Hive,WITHOUT_CLASSIFICATION,//  byte 
Hive,WITHOUT_CLASSIFICATION,//  Values outside the column type bounds will fail at runtime. 
Hive,WITHOUT_CLASSIFICATION,//  process join keys 
Hive,WITHOUT_CLASSIFICATION,//  It must have a column name followed with type. 
Hive,WITHOUT_CLASSIFICATION,//  Subtraction with a type date (LongColumnVector storing days) and type timestamp produces a 
Hive,WITHOUT_CLASSIFICATION,//  Process the combine splits 
Hive,WITHOUT_CLASSIFICATION,//  spilled small tables 
Hive,WITHOUT_CLASSIFICATION,//  The first directory becomes the base for combining. 
Hive,WITHOUT_CLASSIFICATION,//  Use the Tez hash table loader. 
Hive,WITHOUT_CLASSIFICATION,//  field expression should be resolved 
Hive,WITHOUT_CLASSIFICATION,//  This is SQL standard - max_n of zero items should be null. 
Hive,WITHOUT_CLASSIFICATION,//  Look for functions without pattern 
Hive,WITHOUT_CLASSIFICATION,/*  Default list bucketing directory name. internal use only not for client.  */
Hive,WITHOUT_CLASSIFICATION,//  test acid with vectorization no combine 
Hive,WITHOUT_CLASSIFICATION,//  node already exists 
Hive,WITHOUT_CLASSIFICATION,//  Get all items into an array and sort them 
Hive,WITHOUT_CLASSIFICATION,//  Wait for the child process to finish 
Hive,WITHOUT_CLASSIFICATION,//  create new union and sort 
Hive,WITHOUT_CLASSIFICATION,//  finally we can create the grouped edge 
Hive,WITHOUT_CLASSIFICATION,//  We do not need to do anything 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:UpdateQueryResponseProto) 
Hive,WITHOUT_CLASSIFICATION,// ************************************************************************************************   Decimal Addition / Subtraction. 
Hive,WITHOUT_CLASSIFICATION,//  5. Setup Expr Col Map 
Hive,WITHOUT_CLASSIFICATION,// since raw data was (possibly) escaped to make split work  now need to remove escape chars so they don't interfere with downstream processing 
Hive,WITHOUT_CLASSIFICATION,//  get the map for posToVertex 
Hive,WITHOUT_CLASSIFICATION,//  Compactor states (Should really be enum) 
Hive,WITHOUT_CLASSIFICATION,// check privileges 
Hive,WITHOUT_CLASSIFICATION,//  Copy files with retry logic on failure or source file is dropped or changed. 
Hive,WITHOUT_CLASSIFICATION,//  We only consider tables for which we hold either an exclusive   or a shared write lock 
Hive,WITHOUT_CLASSIFICATION,//  Create a new SparkWork for all the small tables of this work 
Hive,WITHOUT_CLASSIFICATION,//  leadership status change happens inside synchronized methods LeaderLatch.setLeadership().   Also we use single threaded executor service for handling notifications which guarantees ordering for   notification handling. if a leadership status change happens when tez sessions are getting created   the notLeader notification will get queued in executor service. 
Hive,WITHOUT_CLASSIFICATION,//  The next row will require another call to increaseBufferSpace() since this new buffer should be used up. 
Hive,WITHOUT_CLASSIFICATION,//  only one of them 
Hive,WITHOUT_CLASSIFICATION,//  Iterate over the selects search for aggregation Trees.   Use String as keys to eliminate duplicate trees. 
Hive,WITHOUT_CLASSIFICATION,//  The denominator of the TABLESAMPLE clause 
Hive,WITHOUT_CLASSIFICATION,//  un-partitioned table 
Hive,WITHOUT_CLASSIFICATION,//  Now that we have exited read lock it is safe to remove any invalid entries. 
Hive,WITHOUT_CLASSIFICATION,//  Authentication only.   Authentication and integrity checking by using signatures.   Authentication integrity and confidentiality checking 
Hive,WITHOUT_CLASSIFICATION,//  Following is special cases for different type of subqueries which have aggregate and no implicit group by   and are correlatd   * EXISTS/NOT EXISTS - NOT allowed throw an error for now. We plan to allow this later   * SCALAR - This should return true since later in subquery remove                rule we need to know about this case.   * IN - always allowed BUT returns true for cases with aggregate other than COUNT since later in subquery remove          rule we need to know about this case. 
Hive,WITHOUT_CLASSIFICATION,//  Initialize common server configs needed in both binary & http modes 
Hive,WITHOUT_CLASSIFICATION,//  Partitioned table - delete all 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   required   optional   optional   optional   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  Test that existing shared_write table with new shared_read coalesces to 
Hive,WITHOUT_CLASSIFICATION,//  The serialized all null key and its hash code. 
Hive,WITHOUT_CLASSIFICATION,//  if the evaluate yields true then pass all rows else pass 0 rows 
Hive,WITHOUT_CLASSIFICATION,//  configuration for the application master 
Hive,WITHOUT_CLASSIFICATION,//  1. HDFS scratch dir 
Hive,WITHOUT_CLASSIFICATION,//  Event 18 
Hive,WITHOUT_CLASSIFICATION,//  Move the specified work from the sparkWork to the targetWork   Note that in order not to break the graph (since we need it for the edges) 
Hive,WITHOUT_CLASSIFICATION,//  print current state before exiting 
Hive,WITHOUT_CLASSIFICATION,//  Retrieve results 
Hive,WITHOUT_CLASSIFICATION,//  Other integer types not supported yet. 
Hive,WITHOUT_CLASSIFICATION,//  file locations to be searched in the correct order 
Hive,WITHOUT_CLASSIFICATION,//  Add tracking information. Check if source state already known and send out an update if it is. 
Hive,WITHOUT_CLASSIFICATION,//  Finishable state is checked on the task via an explicit query to the TaskRunnerCallable 
Hive,WITHOUT_CLASSIFICATION,//  with the RS parent based on its position in the list of parents. 
Hive,WITHOUT_CLASSIFICATION,//  the objects that have been printed. 
Hive,WITHOUT_CLASSIFICATION,/*      we have to  add this one manually as for tests the db is initialized via the metastoreDiretSQL     and we don't run the schema creation sql that includes the an insert for notification_sequence     which can be locked. the entry in notification_sequence happens via notification_event insertion.     */
Hive,WITHOUT_CLASSIFICATION,//  error in storage specification 
Hive,WITHOUT_CLASSIFICATION,//  add input path 
Hive,WITHOUT_CLASSIFICATION,//  F | F | F 
Hive,WITHOUT_CLASSIFICATION,//  Construct the EdgeManager descriptor to be used by all edges which need   the routing table. 
Hive,WITHOUT_CLASSIFICATION,// parser only allows foo(ab) not foo(foo.a foo.b) 
Hive,WITHOUT_CLASSIFICATION,/*    * Assign a row from a list of standard objects up to a count    */
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setDate(int java.sql.Date   * java.util.Calendar)    */
Hive,WITHOUT_CLASSIFICATION,//  when there are no live nodes in the cluster and this timeout elapses the query is failed 
Hive,WITHOUT_CLASSIFICATION,//  required   optional   optional   optional   optional   optional   optional   optional   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  GCE firewall is set through instance tags 
Hive,WITHOUT_CLASSIFICATION,// First handle special cases.  If one of the special case methods cannot handle it   it returns null. 
Hive,WITHOUT_CLASSIFICATION,//  This case happens only when pRS key is empty in which case we can use   number of distribution keys and key serialization info from cRS 
Hive,WITHOUT_CLASSIFICATION,//  Do nothing in this case. 
Hive,WITHOUT_CLASSIFICATION,//  path of the FileSinkOperator table is a blobstore path. 
Hive,WITHOUT_CLASSIFICATION,//  aggregate size from aggregation buffers 
Hive,WITHOUT_CLASSIFICATION,//  the union operators from the operator tree later. 
Hive,WITHOUT_CLASSIFICATION,//  since SQL is case insenstive just to make sure that the comparison b/w column names   and check expression's column reference work convert the key to lower case 
Hive,WITHOUT_CLASSIFICATION,//  We can get away with the use of varname here because varname == hiveName for PWD 
Hive,WITHOUT_CLASSIFICATION,//  The assumption here is the path is a file. Only case this is different is ACID deltas.   The isFile check is avoided here for performance reasons. 
Hive,WITHOUT_CLASSIFICATION,//  Integer.MAX_VALUE 
Hive,WITHOUT_CLASSIFICATION,//  these 5 delims passed as serde params   comment passed as table params 
Hive,WITHOUT_CLASSIFICATION,//  The values from HiveIntervalDayTime.getNanos(). 
Hive,WITHOUT_CLASSIFICATION,//  max # of rows = rows from left side 
Hive,WITHOUT_CLASSIFICATION,//  There should only be column in sourceOperator 
Hive,WITHOUT_CLASSIFICATION,//  To avoid denominator getting larger and aggressively reducing   number of rows we will ease out denominator. 
Hive,WITHOUT_CLASSIFICATION,// ---------------------------------------------------------------------------   Process Single-Column String Left-Semi Join on a vectorized row batch.   
Hive,WITHOUT_CLASSIFICATION,//  get the table from the client again verify the name has been updated 
Hive,WITHOUT_CLASSIFICATION,// TxnManagerFactory is a singleton so if the default is true it has already been  created and won't throw 
Hive,WITHOUT_CLASSIFICATION,//  If hint is provided use that size. 
Hive,WITHOUT_CLASSIFICATION,//  In case the dynamic value resolves to a null value 
Hive,WITHOUT_CLASSIFICATION,//  clean 
Hive,WITHOUT_CLASSIFICATION,//  We will transform using clause and make it look like an on-clause.   So lets generate a valid on-clause AST from using. 
Hive,WITHOUT_CLASSIFICATION,//  2/ serialize the union - tag/value 
Hive,WITHOUT_CLASSIFICATION,//  for shell commands use unstripped command 
Hive,WITHOUT_CLASSIFICATION,//  is used as an alias) 
Hive,WITHOUT_CLASSIFICATION,//  try nulls on both sides 
Hive,WITHOUT_CLASSIFICATION,//  to know if the job has finished is to check the futures here ourselves. 
Hive,WITHOUT_CLASSIFICATION,//  alterPartition is only for changing the partition location in the table rename 
Hive,WITHOUT_CLASSIFICATION,//  Create the final Group By Operator 
Hive,WITHOUT_CLASSIFICATION,// check whether the username in the token is what we expect 
Hive,WITHOUT_CLASSIFICATION,//  the task is no longer required and asks for a de-allocation. 
Hive,WITHOUT_CLASSIFICATION,//  Check the last node 
Hive,WITHOUT_CLASSIFICATION,//  4M   the conf string for COLUMNS_BUFFER_SIZE 
Hive,WITHOUT_CLASSIFICATION,//  keep this within 80 chars width. If more columns needs to be added then update min terminal   width requirement and SEPARATOR width accordingly 
Hive,WITHOUT_CLASSIFICATION,//  Should only be managed tables passed in here.   Check if table is in the default table location based on the old warehouse root.   If so then change the table location to the default based on the current warehouse root.   The existing table directory will also be moved to the new default database directory. 
Hive,WITHOUT_CLASSIFICATION,//  track of which small tables haven't been processed yet. 
Hive,WITHOUT_CLASSIFICATION,//  10^8 - 1 
Hive,WITHOUT_CLASSIFICATION,//  HIVE-6672: In HiveServer2 the JARs for this UDF may have been loaded by a different thread   and the current thread may not be able to resolve the UDF. Test for this condition 
Hive,WITHOUT_CLASSIFICATION,//  add_partitions(123) : ok normal operation 
Hive,WITHOUT_CLASSIFICATION,// create type with nestingLevel levels of nesting 
Hive,WITHOUT_CLASSIFICATION,//  Write final 0-length chunk 
Hive,WITHOUT_CLASSIFICATION,//  We might have multiple ranges coming from children 
Hive,WITHOUT_CLASSIFICATION,//  Serialize the row component using the RowIdFactory. In the normal case this will just 
Hive,WITHOUT_CLASSIFICATION,//  build a map which tracks the name of column in input's signature to corresponding table column name   this will be used to replace column references in CHECK expression AST with corresponding column name   in input 
Hive,WITHOUT_CLASSIFICATION,//  Specifying the right type info length tells LazyBinaryDeserializeRead which is the last   column. 
Hive,WITHOUT_CLASSIFICATION,//  Pull out Deterministic exprs from non-deterministic and push down   deterministic expressions as a separate filter 
Hive,WITHOUT_CLASSIFICATION,//  convert the metastore thrift objects to result objects 
Hive,WITHOUT_CLASSIFICATION,//  running the MoveTask and MR task in parallel may   cause the mvTask write to /ds=1 and MR task write   to /ds=1_1 for the same partition. 
Hive,WITHOUT_CLASSIFICATION,//  Currently not used in hive code-base but intended to authorize actions   that are directly user-level. As there's no storage based aspect to this   we can follow one of two routes:   a) We can allow by default - that way this call stays out of the way   b) We can deny by default - that way no privileges are authorized that   is not understood and explicitly allowed.   Both approaches have merit but given that things like grants and revokes   that are user-level do not make sense from the context of storage-permission   based auth denying seems to be more canonical here. 
Hive,WITHOUT_CLASSIFICATION,//  Now go the correct way through objectinspectors 
Hive,WITHOUT_CLASSIFICATION,//  YARN Service has started llap application now if for some reason   state changes to COMPLETE then fail fast 
Hive,WITHOUT_CLASSIFICATION,//  the parent ops for hashTableSinkOp 
Hive,WITHOUT_CLASSIFICATION,//  simply need to remember that we've seen a union. 
Hive,WITHOUT_CLASSIFICATION,//  If there are no skewed values nothing needs to be done 
Hive,WITHOUT_CLASSIFICATION,// different locks from same txn should not conflict with each other 
Hive,WITHOUT_CLASSIFICATION,//  Temporary selected vector 
Hive,WITHOUT_CLASSIFICATION,//  Transform CASE WHEN with just a THEN/ELSE into an IF statement. 
Hive,WITHOUT_CLASSIFICATION,//  currently metastore does not store column stats for   partition column so we calculate the NDV from partition list 
Hive,WITHOUT_CLASSIFICATION,/*       * Sleep until all threads with clean up tasks are completed.       */
Hive,WITHOUT_CLASSIFICATION,//  get_table checks whether database exists it should be moved here 
Hive,WITHOUT_CLASSIFICATION,//  return the serialized bytes 
Hive,WITHOUT_CLASSIFICATION,//  read the keys and values 
Hive,WITHOUT_CLASSIFICATION,//  check if list elements are primitive or Objects 
Hive,WITHOUT_CLASSIFICATION,//  Create three catalogs 
Hive,WITHOUT_CLASSIFICATION,//  Accurate short value cannot be obtained. 
Hive,WITHOUT_CLASSIFICATION,// export command uses _metadata.... 
Hive,WITHOUT_CLASSIFICATION,//  Don't call builder.setWorkSpecSignature() - Tez doesn't sign fragments 
Hive,WITHOUT_CLASSIFICATION,//  Because of the implementation of the JsonParserFactory we are sure   that we can get a TezJsonParser. 
Hive,WITHOUT_CLASSIFICATION,/*      * Algorithm:     * 1) Convert decimal to three 56-bit words (three is enough for the decimal since we     *    represent the decimal with trailing zeroes trimmed).     * 2) Skip leading zeroes in the words.     * 3) Once we find real data (i.e. a non-zero byte) add a sign byte to buffer if necessary.     * 4) Add bytes from the (rest of) 56-bit words.     * 5) Return byte count.      */
Hive,WITHOUT_CLASSIFICATION,//  Create temp table directory 
Hive,WITHOUT_CLASSIFICATION,/*    * TIMESTAMP.    */
Hive,WITHOUT_CLASSIFICATION,//  Try one sorted. 
Hive,WITHOUT_CLASSIFICATION,//  Input row resolver 
Hive,WITHOUT_CLASSIFICATION,//  and pass it to setTaskPlan as the last parameter 
Hive,WITHOUT_CLASSIFICATION,//  no child no need for pruning 
Hive,WITHOUT_CLASSIFICATION,/*  Validate location string.  */
Hive,WITHOUT_CLASSIFICATION,//  Ignore this exception if there is a problem it'll fail when trying to read or write. 
Hive,WITHOUT_CLASSIFICATION,//  If the drop has to fail on non-existent partitions we cannot batch expressions.   That is because we actually have to check each separate expression for existence.   We could do a small optimization for the case where expr has all columns and all   operators are equality if we assume those would always match one partition (which   may not be true with legacy non-normalized column values). This is probably a   popular case but that's kinda hacky. Let's not do it for now. 
Hive,WITHOUT_CLASSIFICATION,//  tokenSig could be null 
Hive,WITHOUT_CLASSIFICATION,//  Return true if this data type is handled in the output vector as an integer. 
Hive,WITHOUT_CLASSIFICATION,//  otherwise we don't know what to do so make it a maybe 
Hive,WITHOUT_CLASSIFICATION,//  No SerDes here. 
Hive,WITHOUT_CLASSIFICATION,//  This method is used to validate check expression since check expression isn't allowed to have subquery 
Hive,WITHOUT_CLASSIFICATION,//  Try running a priority 1 task 
Hive,WITHOUT_CLASSIFICATION,//  0 length files cannot be ORC files not valid for MR. 
Hive,WITHOUT_CLASSIFICATION,//  By default we can always use the multi-key class. 
Hive,WITHOUT_CLASSIFICATION,//  There was a parallel cache eviction - the evictor is accounting for the memory. 
Hive,WITHOUT_CLASSIFICATION,//  partition or mixed case) 
Hive,WITHOUT_CLASSIFICATION,//  But for now we will just retry. We will evict more each time. 
Hive,WITHOUT_CLASSIFICATION,//  test default table types returned in 
Hive,WITHOUT_CLASSIFICATION,//  Set metastoreOverlay parameters 
Hive,WITHOUT_CLASSIFICATION,//  retrieve the stats obj that was just written 
Hive,WITHOUT_CLASSIFICATION,//  Start of the split falls somewhere within or before this slice.   Note the ">=" - LineRecordReader will skip the first row even if we start   directly at its start because it cannot know if it's the start or not.   Unless it's 0; note that we DO give 0 special treatment here unlike the EOF below 
Hive,WITHOUT_CLASSIFICATION,/*   * (non-Javadoc)  *  * @see  * org.apache.hadoop.hive.ql.security.authorization.HiveAuthorizationProvider  * #authorize(org.apache.hadoop.hive.ql.security.authorization.Privilege[]  * org.apache.hadoop.hive.ql.security.authorization.Privilege[])   */
Hive,WITHOUT_CLASSIFICATION,/*          * for the Virtual columns:         * - the internalName is UPPER Case and the alias is lower case         * - since we put them in an OI the fieldnames became lower cased.         * - so we look in the inputRR for the fieldName as an alias.          */
Hive,WITHOUT_CLASSIFICATION,//  if multiple MOVE happens only first move will be chosen 
Hive,WITHOUT_CLASSIFICATION,//  If making this public note that its ordering is undefined. 
Hive,WITHOUT_CLASSIFICATION,//  add any partition key values provided as part of job info 
Hive,WITHOUT_CLASSIFICATION,//  for remote JDBC client try to set the conf var using 'set foo=bar' 
Hive,WITHOUT_CLASSIFICATION,//  Wait for all the events to be written off the order of service is important 
Hive,WITHOUT_CLASSIFICATION,// Test for duplicate publish 
Hive,WITHOUT_CLASSIFICATION,//  also initialize a paritioned table to test against. 
Hive,WITHOUT_CLASSIFICATION,//  --------------------------------------------------------------   DATA SHOULD GET SORTED BY YOUR ETL/MERGE PROCESS HERE     Group the data by (partitionValues ROW__ID.bucketId)   Order the groups by (ROW__ID.writeId ROW__ID.rowId)   -------------------------------------------------------------- 
Hive,WITHOUT_CLASSIFICATION,//  Throw if the tx wasn't rolled back. 
Hive,WITHOUT_CLASSIFICATION,//  Hour granularity 
Hive,WITHOUT_CLASSIFICATION,// Map<??> c6Value = (Map<??>) rowValues[5];  assertEquals(0 c6Value.size()); 
Hive,WITHOUT_CLASSIFICATION,//  ELSE expression 
Hive,WITHOUT_CLASSIFICATION,// Tstage is just a simple way to generate test data 
Hive,WITHOUT_CLASSIFICATION,//  use a list for easy cumtomize 
Hive,WITHOUT_CLASSIFICATION,//  Pairwise: InitOuputColHasNulls InitOuputColIsRepeating ColumnHasNulls ColumnIsRepeating 
Hive,WITHOUT_CLASSIFICATION,//  then try to get it from all 
Hive,WITHOUT_CLASSIFICATION,//  conditions for being partition column 
Hive,WITHOUT_CLASSIFICATION,//  this method could go beyond the integer ranges until we scale back   so we need twice more variables. 
Hive,WITHOUT_CLASSIFICATION,//  Now release a single session from A. 
Hive,WITHOUT_CLASSIFICATION,//  could generate different error messages 
Hive,WITHOUT_CLASSIFICATION,// Check if the record record is already encoded once. If it does  reuse the encoder. 
Hive,WITHOUT_CLASSIFICATION,//  This method takes Object so it accepts whatever types that are   passed in. 
Hive,WITHOUT_CLASSIFICATION,//  Call this first then send in an interrupt to the thread. 
Hive,WITHOUT_CLASSIFICATION,//  DELETE_RULE 
Hive,WITHOUT_CLASSIFICATION,//  ROWS 
Hive,WITHOUT_CLASSIFICATION,//  Finally we remove the rest of the expression from the tree 
Hive,WITHOUT_CLASSIFICATION,//  NOTE! It is necessary merge task is the parent of the move task and not   the other way around for the proper execution of the execute method of 
Hive,WITHOUT_CLASSIFICATION,//  Verify the union has been hidden and just the main type has been returned. 
Hive,WITHOUT_CLASSIFICATION,// build new environmentContext with ifPurge; 
Hive,WITHOUT_CLASSIFICATION,//  not anti-symmetric 
Hive,WITHOUT_CLASSIFICATION,//  ensure that we are consistent when comparing to the base class 
Hive,WITHOUT_CLASSIFICATION,//  has its ReduceSink parent removed. 
Hive,WITHOUT_CLASSIFICATION,//  deleted then it is good.  So the last parameter ifexists is set to true 
Hive,WITHOUT_CLASSIFICATION,//  test repeating case 
Hive,WITHOUT_CLASSIFICATION,//  retrieve delegation token for the given user 
Hive,WITHOUT_CLASSIFICATION,//  check to see that the vertices are correct 
Hive,WITHOUT_CLASSIFICATION,//  Escape the escape and escape the asterisk 
Hive,WITHOUT_CLASSIFICATION,//  add the tables as well to outputs 
Hive,WITHOUT_CLASSIFICATION,//   /* in case of grouping sets; groupby1 will output values for every setgroup; this is the index of the column that information will be sent */ 
Hive,WITHOUT_CLASSIFICATION,//  Set parameter to be false in connection 1.  int to smallint allowed 
Hive,WITHOUT_CLASSIFICATION,//  all IFace APIs throw TException 
Hive,WITHOUT_CLASSIFICATION,//  TarArchiveOutputStream seemed not to close files properly in error situation 
Hive,WITHOUT_CLASSIFICATION,//  legacy handling 
Hive,WITHOUT_CLASSIFICATION,/*  Release all locks - including PERSISTENT locks  */
Hive,WITHOUT_CLASSIFICATION,//  Should make ['f' 'm\0') 
Hive,WITHOUT_CLASSIFICATION,//  within a range specified. 
Hive,WITHOUT_CLASSIFICATION,//  Check highest digit for rounding. 
Hive,WITHOUT_CLASSIFICATION,//  start removing LRU nodes 
Hive,WITHOUT_CLASSIFICATION,//  suppress here; if it is a real issue will get caught in where clause handling. 
Hive,WITHOUT_CLASSIFICATION,//  The included columns of the reader / file schema that   include ACID columns if present. 
Hive,WITHOUT_CLASSIFICATION,//  LOG.debug(CLASS_NAME + " logical " + logical + " batchIndex " + batchIndex + " Key Continues " + saveKey + " " + saveJoinResult.name()); 
Hive,WITHOUT_CLASSIFICATION,// {2} should be lockid 
Hive,WITHOUT_CLASSIFICATION,//  query will get cancelled before creating 57 partitions 
Hive,WITHOUT_CLASSIFICATION,//  Copy order 
Hive,WITHOUT_CLASSIFICATION,//  Some non-zero offsets. 
Hive,WITHOUT_CLASSIFICATION,//  F | T | T 
Hive,WITHOUT_CLASSIFICATION,//  add shutdown hook to flush the history to history file 
Hive,WITHOUT_CLASSIFICATION,//  store partition key expr in map-targetWork 
Hive,WITHOUT_CLASSIFICATION,// Cancel HCat and JobTracker tokens 
Hive,WITHOUT_CLASSIFICATION,//  We have estimation lowerbound and higherbound. We use estimation   if it is between lowerbound and higherbound. 
Hive,WITHOUT_CLASSIFICATION,//  Aggregate mode - it should be followed by union   that we need to analyze 
Hive,WITHOUT_CLASSIFICATION,//  Need to preserve currentDate 
Hive,WITHOUT_CLASSIFICATION,//  newer overrides the older. 
Hive,WITHOUT_CLASSIFICATION,//  4. continue analyzing from the child ASTNode. 
Hive,WITHOUT_CLASSIFICATION,//  Cannot create NullWritable instances 
Hive,WITHOUT_CLASSIFICATION,//  Warm up couple times 
Hive,WITHOUT_CLASSIFICATION,//  TODO : simple wrap & rethrow for now clean up with error 
Hive,WITHOUT_CLASSIFICATION,//  explain analyze is composed of two steps   step 1 (ANALYZE_STATE.RUNNING) run the query and collect the runtime #rows 
Hive,WITHOUT_CLASSIFICATION,//  the the validate input method 
Hive,WITHOUT_CLASSIFICATION,//  Shouldn't happen in getAll. 
Hive,WITHOUT_CLASSIFICATION,//  end of string 
Hive,WITHOUT_CLASSIFICATION,//  Read all the fields and create partitions SDs and serdes. 
Hive,WITHOUT_CLASSIFICATION,//  merge histograms 
Hive,WITHOUT_CLASSIFICATION,//  Do not allow users to override zero-copy setting. The rest can be taken from user config. 
Hive,WITHOUT_CLASSIFICATION,//  a local temp dir specific to this driver 
Hive,WITHOUT_CLASSIFICATION,//  print inline vertex 
Hive,WITHOUT_CLASSIFICATION,//  overflow is not an error here. it just means "this" is   smaller 
Hive,WITHOUT_CLASSIFICATION,//  Allow undecorated CHAR and VARCHAR to support scratch column type names. 
Hive,WITHOUT_CLASSIFICATION,//  with all input columns repeating 
Hive,WITHOUT_CLASSIFICATION,//  Make sure "this" has enough integer room to accomodate other's integer digits. 
Hive,WITHOUT_CLASSIFICATION,//  DateWritableV2 is mutable DateStatsAgg needs its own copy 
Hive,WITHOUT_CLASSIFICATION,//  print information about calls that took longer time at INFO level 
Hive,WITHOUT_CLASSIFICATION,/*          * validate input - Both new and old URI should contain valid host names and valid schemes.         * port is optional in both the URIs since HDFS HA NN URI doesn't have a port.          */
Hive,WITHOUT_CLASSIFICATION,//  Enable metric collection for HiveServer2 
Hive,WITHOUT_CLASSIFICATION,/*  Must check that x is not blank because otherwise you could     * get a false positive if the blank value was a value you     * were legitimately testing to see if it was in the set.      */
Hive,WITHOUT_CLASSIFICATION,//  DAG specific counters 
Hive,WITHOUT_CLASSIFICATION,//  could be exponential notations 
Hive,WITHOUT_CLASSIFICATION,//  first search the classpath 
Hive,WITHOUT_CLASSIFICATION,//  If many fileSinkDescs are linked to each other it is a good idea to keep track of   tasks for first fileSinkDesc. others can use it 
Hive,WITHOUT_CLASSIFICATION,//  positive number flip the first bit 
Hive,WITHOUT_CLASSIFICATION,//  Do nothing by default 
Hive,WITHOUT_CLASSIFICATION,//  Virtual 
Hive,WITHOUT_CLASSIFICATION,//  PathChildrenCache tried to mkdir when the znode wasn't there and failed. 
Hive,WITHOUT_CLASSIFICATION,//  production is: double 
Hive,WITHOUT_CLASSIFICATION,//  allow partial partition specification for nonscan since noscan is fast. 
Hive,WITHOUT_CLASSIFICATION,//  Create semijoin optimizations ONLY for hinted columns 
Hive,WITHOUT_CLASSIFICATION,//  Ignore temporary tables 
Hive,WITHOUT_CLASSIFICATION,//  use 3 as the row buffer size to force lots of re-buffering. 
Hive,WITHOUT_CLASSIFICATION,//  not from a sub-query. 
Hive,WITHOUT_CLASSIFICATION,//  both parts are scaling up. easy. Just check overflow. 
Hive,WITHOUT_CLASSIFICATION,//  An exception from runtime that will show the full stack to client 
Hive,WITHOUT_CLASSIFICATION,//  Revert hive.server2.restrict_information_schema to false 
Hive,WITHOUT_CLASSIFICATION,//  TypeCheckProcFactor expects typecheckctx to have unparse translator 
Hive,WITHOUT_CLASSIFICATION,//  3. Finally try WM. 
Hive,WITHOUT_CLASSIFICATION,//  If the number of joins < number of input tables-1 this is not a star join. 
Hive,WITHOUT_CLASSIFICATION,// run Minor compaction 
Hive,WITHOUT_CLASSIFICATION,//  This is how many bytes we need to store those additonal bits as a VInt. 
Hive,WITHOUT_CLASSIFICATION,//  The index where the current char starts 
Hive,WITHOUT_CLASSIFICATION,/*      * setup SymbolFunction chain.      */
Hive,WITHOUT_CLASSIFICATION,//  Only if DAG is FAILED or KILLED the vertex status is fetched from AM. 
Hive,WITHOUT_CLASSIFICATION,//  Get the RS and TS for this branch 
Hive,WITHOUT_CLASSIFICATION,//  Clean up trash 
Hive,WITHOUT_CLASSIFICATION,//  Map to keep track of which SMB Join operators and their information to annotate their MapWork with. 
Hive,WITHOUT_CLASSIFICATION,//  needed for type parity 
Hive,WITHOUT_CLASSIFICATION,//  Create the Parquet FilterPredicate without including columns that do not exist   on the schema (such as partition columns). 
Hive,WITHOUT_CLASSIFICATION,// 2 from txnid:1 1 from txnid:2 1 from txnid:3 
Hive,WITHOUT_CLASSIFICATION,//  SR.SR.acquired Lock we are examining is acquired;  We can acquire   because two shared reads can acquire together and there must be 
Hive,WITHOUT_CLASSIFICATION,//  insert filter operator between target(child) and input(parent) 
Hive,WITHOUT_CLASSIFICATION,// if here it's a non-acid schema file - check if from before table was marked transactional  or in base_x/delta_x_x from Load Data 
Hive,WITHOUT_CLASSIFICATION,//  found a sub-directory at a depth less than number of partition keys   validate if the partition directory name matches with the corresponding   partition colName at currentDepth 
Hive,WITHOUT_CLASSIFICATION,//  full outer join 
Hive,WITHOUT_CLASSIFICATION,//  the resulting privileges need to be filtered on privilege type and   username 
Hive,WITHOUT_CLASSIFICATION,//  authorized to perform action 
Hive,WITHOUT_CLASSIFICATION,//  Check optimized-only hash table restrictions. 
Hive,WITHOUT_CLASSIFICATION,//  Note: the definitions of what ODBC and JDBC keywords exclude are different in different         places. For now just return the ODBC version here; that excludes Hive keywords          that are also ODBC reserved keywords. We could also exclude SQL:2003. 
Hive,WITHOUT_CLASSIFICATION,//  Determine row schema for TSOP. 
Hive,WITHOUT_CLASSIFICATION,// Configure the output key and value classes. 
Hive,WITHOUT_CLASSIFICATION,//  VALIDATION_LEVEL 
Hive,WITHOUT_CLASSIFICATION,// Test for setting the maximum partition count 
Hive,WITHOUT_CLASSIFICATION,//  6.2 EXPR AS (ALIAS...) parses but is only allowed for UDTF's   This check is not needed and invalid when there is a transform b/c   the 
Hive,WITHOUT_CLASSIFICATION,// test random scan 
Hive,WITHOUT_CLASSIFICATION,//  For partitioned table partitionVals are specified 
Hive,WITHOUT_CLASSIFICATION,//  Oid for SPNego GSS-API mechanism. 
Hive,WITHOUT_CLASSIFICATION,//  The aggregation batch vector needs to know when we start a new batch 
Hive,WITHOUT_CLASSIFICATION,//  sort 
Hive,WITHOUT_CLASSIFICATION,//  1 integer digit; 2 fraction digits.   Trailing zeroes are suppressed. 
Hive,WITHOUT_CLASSIFICATION,// init lock manager 
Hive,WITHOUT_CLASSIFICATION,//  Retrieve from FK side 
Hive,WITHOUT_CLASSIFICATION,//  Dummy registry does not cache information and forwards all requests to metastore 
Hive,WITHOUT_CLASSIFICATION,//  we are only trying to convert a BucketMapJoin to sort-BucketMapJoin. 
Hive,WITHOUT_CLASSIFICATION,// use int as outputTypeInfo 
Hive,WITHOUT_CLASSIFICATION,//  Calculate all the arguments 
Hive,WITHOUT_CLASSIFICATION,//  note: explicit format to use Throwable instead of var-args 
Hive,WITHOUT_CLASSIFICATION,//  Handle synthetic row IDs for the original files. 
Hive,WITHOUT_CLASSIFICATION,//  Use task attempt number from conf if provided 
Hive,WITHOUT_CLASSIFICATION,//  GrpSet Col needs to be constructed 
Hive,WITHOUT_CLASSIFICATION,//  Just insert the record in the usual way i.e. default to the simple behavior. 
Hive,WITHOUT_CLASSIFICATION,//  Find the argument to the operator which is a constant 
Hive,WITHOUT_CLASSIFICATION,//  if inverse is word-shifted for accuracy shift it back here. 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  Keeps track of completed DAGS. QueryIdentifiers need to be unique across applications. 
Hive,WITHOUT_CLASSIFICATION,//  We'll treat this as the aggregate col stats for part1...part9 of tab1 col1 
Hive,WITHOUT_CLASSIFICATION,//  Setters 
Hive,WITHOUT_CLASSIFICATION,//  verifyTable.verify(map); 
Hive,WITHOUT_CLASSIFICATION,//  that would block us. 
Hive,WITHOUT_CLASSIFICATION,//  validate connection 
Hive,WITHOUT_CLASSIFICATION,//  Pick the correct parent only one of the parents is not   ReduceSink that is what we are looking for. 
Hive,WITHOUT_CLASSIFICATION,// Check if different encryption zones 
Hive,WITHOUT_CLASSIFICATION,//  3. Get Table Logical Schema (Row Type)   NOTE: Table logical schema = Non Partition Cols + Partition Cols +   Virtual Cols 
Hive,WITHOUT_CLASSIFICATION,//  We've already obtained a lock on the table don't lock the partition too 
Hive,WITHOUT_CLASSIFICATION,//  Create list of one. 
Hive,WITHOUT_CLASSIFICATION,/*  Unregister a task from the known and running structures  */
Hive,WITHOUT_CLASSIFICATION,//  clean out previous contents 
Hive,WITHOUT_CLASSIFICATION,// note that "update" uses dynamic partitioning thus lock is on the table not partition 
Hive,WITHOUT_CLASSIFICATION,//  Default timestamp format still works? 
Hive,WITHOUT_CLASSIFICATION,//  Read data from the znode for this server node   This data could be either config string (new releases) or server end 
Hive,WITHOUT_CLASSIFICATION,//  get mapping of tables to columns used 
Hive,WITHOUT_CLASSIFICATION,//  We need to store this record (if it is not done yet) in case   we should produce a result 
Hive,WITHOUT_CLASSIFICATION,//  TODO: We don't want some random jars of unknown provenance sitting around. Or do we care?         Ideally we should try to reuse jars and verify using some checksum. 
Hive,WITHOUT_CLASSIFICATION,//  handle password 
Hive,WITHOUT_CLASSIFICATION,//  We will not try partial rewriting for non-rebuild if incremental rewriting is disabled 
Hive,WITHOUT_CLASSIFICATION,//  In HS2 the client should have been cached already for the common case.   Otherwise this may actually introduce delay to compilation for the first query. 
Hive,WITHOUT_CLASSIFICATION,//  Job vars 
Hive,WITHOUT_CLASSIFICATION,//  lets take a look at the operator memory requirements. 
Hive,WITHOUT_CLASSIFICATION,/*    * Since the operator tree is a DAG nodes with mutliple parents will be   * visited more than once. This can be made configurable.    */
Hive,WITHOUT_CLASSIFICATION,// Always inc the batch buffer index 
Hive,WITHOUT_CLASSIFICATION,//  COL_TYPE 
Hive,WITHOUT_CLASSIFICATION,//  We failed to do something that was rendered irrelevant while we were failing. 
Hive,WITHOUT_CLASSIFICATION,//  Confirm the file is really fixed and replace the old file. 
Hive,WITHOUT_CLASSIFICATION,/*    * StringExpr uses Boyer Moore Horspool algorithm to find faster.   * It is thread-safe because it holds final member instances only.   * See https://en.wikipedia.org/wiki/Boyer–Moore–Horspool_algorithm .    */
Hive,WITHOUT_CLASSIFICATION,/*      * add any input columns referenced in WindowFn args or expressions.      */
Hive,WITHOUT_CLASSIFICATION,//  The values from Timestamp.getTime(). 
Hive,WITHOUT_CLASSIFICATION,// txn X write to b0 + b1   txn X + 1 write to b2 + b3  txn X + 2 write to b0 + b1  txn X + 3 write to b2 + b3 
Hive,WITHOUT_CLASSIFICATION,//  Form result from lower and middle words. 
Hive,WITHOUT_CLASSIFICATION,//  if input is not rewritten or if it produces correlated   variables terminate rewrite 
Hive,WITHOUT_CLASSIFICATION,/*  id between 23 and 45  */
Hive,WITHOUT_CLASSIFICATION,//  Filter timestamp against long (seconds) or double (seconds with fractional   nanoseconds). 
Hive,WITHOUT_CLASSIFICATION,//  test second IF argument with nulls and repeating 
Hive,WITHOUT_CLASSIFICATION,//  Add nothing more. 
Hive,WITHOUT_CLASSIFICATION,// Out of allocated columns 
Hive,WITHOUT_CLASSIFICATION,//  checking var exists and its value is right 
Hive,WITHOUT_CLASSIFICATION,// HIVE-12631 
Hive,WITHOUT_CLASSIFICATION,// Table name will be lower case unless specified by hbase.table.name property 
Hive,WITHOUT_CLASSIFICATION,//  Open the next file 
Hive,WITHOUT_CLASSIFICATION,//  Maximum tolerable variance in number of partitions between cached node and our request 
Hive,WITHOUT_CLASSIFICATION,//  Drops partitions in batches.  partNotInFs is split into batches based on batchSize   and dropped.  The dropping will be through RetryUtilities which will retry when there is a   failure after reducing the batchSize by decayingFactor.  Retrying will cease when maxRetries 
Hive,WITHOUT_CLASSIFICATION,//  cellValueTransformers is corresponding to the columns.   Its size should be the same as columns.   For example if a table has two columns "key" and "value"   we may mask "value" as "reverse(value)". Then cellValueTransformers 
Hive,WITHOUT_CLASSIFICATION,//  ObjectRegistry is available via the Input/Output/ProcessorContext.   This is setup as part of the Tez Processor construction so that it is available whenever an   instance of the ObjectCache is created. The assumption is that Tez will initialize the Processor   before anything else. 
Hive,WITHOUT_CLASSIFICATION,//  Create SelectOp with granularity column 
Hive,WITHOUT_CLASSIFICATION,//  so directly invoke ExecDriver 
Hive,WITHOUT_CLASSIFICATION,//  Adjust negative result again doing what SerializationUtils.readBigInteger does. 
Hive,WITHOUT_CLASSIFICATION,//  F | T | F 
Hive,WITHOUT_CLASSIFICATION,//  Need to check if there are overflow digits in the high word. 
Hive,WITHOUT_CLASSIFICATION,/*  List of registered applications  */
Hive,WITHOUT_CLASSIFICATION,/*    * Write a VInt using our temporary byte buffer instead of paying the thread local performance   * cost of LazyBinaryUtils.writeVInt    */
Hive,WITHOUT_CLASSIFICATION,//  For Varchar or char type return the max length of the type 
Hive,WITHOUT_CLASSIFICATION,//  for the grouping set (corresponding to the rollup). 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) SenumDef  */
Hive,WITHOUT_CLASSIFICATION,//  set the related attributes according to the keys and values 
Hive,WITHOUT_CLASSIFICATION,//  handles cases where the query has a predicate "constant=column-name" 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: We are overwriting the constant vector value... 
Hive,WITHOUT_CLASSIFICATION,//  do not do impersonation in CLI mode 
Hive,WITHOUT_CLASSIFICATION,//  no compression 
Hive,WITHOUT_CLASSIFICATION,//  2.1.1 Record Column Names that we needed stats for but couldn't 
Hive,WITHOUT_CLASSIFICATION,//  complete split futures 
Hive,WITHOUT_CLASSIFICATION,//  4) We check whether one of the operators is part of a work that is an input for   the work of the other operator.       Work1            (merge TS in W1 & W3)        Work1       |                        ->                   |        X     Work2                                         Work2       |                                             |     Work3                                         Work1   
Hive,WITHOUT_CLASSIFICATION,//  Currently the unions are not merged - each union has only 2 parents. So   a n-way union will lead to (n-1) union operators. 
Hive,WITHOUT_CLASSIFICATION,//  Original bucket files delta directories and previous base directory should have been cleaned up. 
Hive,WITHOUT_CLASSIFICATION,//  Return the fully-qualified path of path f resolving the path   through any symlinks or mount point 
Hive,WITHOUT_CLASSIFICATION,//  Create database and table 
Hive,WITHOUT_CLASSIFICATION,//  Simulate different filesystems by returning a different URI 
Hive,WITHOUT_CLASSIFICATION,//  ArrayList 
Hive,WITHOUT_CLASSIFICATION,//  Note : No DDL way to alter a partition so we use the MSC api directly. 
Hive,WITHOUT_CLASSIFICATION,//  TODO JDK 1.7 
Hive,WITHOUT_CLASSIFICATION,//  the following code is used to collect column stats when   hive.stats.autogather=true 
Hive,WITHOUT_CLASSIFICATION,/* e.g. ON source.t=1        * this is not strictly speaking invlaid but it does ensure that all columns from target        * table are all NULL for every row.  This would make any WHEN MATCHED clause invalid since        * we don't have a ROW__ID.  The WHEN NOT MATCHED could be meaningful but it's just data from        * source satisfying source.t=1...  not worth the effort to support this */
Hive,WITHOUT_CLASSIFICATION,//  Nodes go stale after this 
Hive,WITHOUT_CLASSIFICATION,//  Here only register the whole table for post-exec hook if no DP present   in the case of DP we will register WriteEntity in MoveTask when the   list of dynamically created partitions are known. 
Hive,WITHOUT_CLASSIFICATION,//  Move the result of getColumns() forward to match the columns of the query   c13   c14   c15   c16   c17 
Hive,WITHOUT_CLASSIFICATION,//  do this to verify that Utilities.removeTempOrDuplicateFiles does not revert to default scheme information 
Hive,WITHOUT_CLASSIFICATION,//  The background operation thread was cancelled 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: distinct expr can be part of of GB key 
Hive,WITHOUT_CLASSIFICATION,//  Note although HiveProxy has a method that allows us to check if we're being   called from the metastore or from the client we don't have an initialized HiveProxy   till we explicitly initialize it as being from the client side. So we have a   chicken-and-egg problem. So we now track whether or not we're running from client-side   in the SBAP itself. 
Hive,WITHOUT_CLASSIFICATION,//  Split by "/" to identify partition parts 
Hive,WITHOUT_CLASSIFICATION,//  First throw away digits below round digit. 
Hive,WITHOUT_CLASSIFICATION,//  Add the lb path to the list of input paths 
Hive,WITHOUT_CLASSIFICATION,//  stop the appenders for the operation log 
Hive,WITHOUT_CLASSIFICATION,//  redact sensitive information before logging 
Hive,WITHOUT_CLASSIFICATION,//  40 and 50 
Hive,WITHOUT_CLASSIFICATION,//  Sharing this state assumes splits will succeed or fail to get it together (same FS).   We also start with null and only set it to true on the first call so we would only do   the global-disable thing on the first failure w/the API error not any random failure. 
Hive,WITHOUT_CLASSIFICATION,//  load properties from hive configurations including both spark.* properties 
Hive,WITHOUT_CLASSIFICATION,//  mark the original as abandoned. Don't need it anymore. 
Hive,WITHOUT_CLASSIFICATION,//  Write record to byte buffer 
Hive,WITHOUT_CLASSIFICATION,//  denom = Product of all NDVs except the least of all 
Hive,WITHOUT_CLASSIFICATION,//  In order to expedite things in a general case we are not actually going to reopen   anything. Instead we will try to give out an existing session from the pool and restart   the problematic one in background. 
Hive,WITHOUT_CLASSIFICATION,//  Iterate through each day of the year make sure Date/DateWritableV2 match 
Hive,WITHOUT_CLASSIFICATION,// Serialize the output info into the configuration 
Hive,WITHOUT_CLASSIFICATION,//  map b/w table alias   to RowContainer 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#getTypeMap()    */
Hive,WITHOUT_CLASSIFICATION,//  Not async or wasn't submitted for some reason (failure etc.) 
Hive,WITHOUT_CLASSIFICATION,//  INT can happen in cases where grouping() is used without grouping sets in all other cases it should be LONG. 
Hive,WITHOUT_CLASSIFICATION,//  Files created on Windows machines have different line endings   than files created on Unix/Linux. Windows uses carriage return and line feed   ("\r\n") as a line ending whereas Unix uses just line feed ("\n"). 
Hive,WITHOUT_CLASSIFICATION,/*     LOG.info("Modifying config values for ACID write");    conf.setBoolVar(ConfVars.HIVEOPTREDUCEDEDUPLICATION true);    conf.setIntVar(ConfVars.HIVEOPTREDUCEDEDUPLICATIONMINREDUCER 1);    These props are now enabled elsewhere (see commit diffs).  It would be better instead to throw    if they are not set.  For exmaple if user has set hive.optimize.reducededuplication=false for    some reason we'll run a query contrary to what they wanted...  But throwing now would be    backwards incompatible.     */
Hive,WITHOUT_CLASSIFICATION,//  on it 
Hive,WITHOUT_CLASSIFICATION,//  new transactions should be allowed to open 
Hive,WITHOUT_CLASSIFICATION,// txns overlap; could replace ws_txnid   with txnid though any decent DB should infer this  make sure RHS of join only has rows we just inserted as   part of this commitTxn() op  and LHS only has committed txns  U+U and U+D is a conflict but D+D is not and we don't currently track I in WRITE_SET at all 
Hive,WITHOUT_CLASSIFICATION,//  Event 5 6 (alter: stats update event) 
Hive,WITHOUT_CLASSIFICATION,//  whether to cache current RDD. 
Hive,WITHOUT_CLASSIFICATION,//  Null first 
Hive,WITHOUT_CLASSIFICATION,//  The table was dropped before we got around to cleaning it. 
Hive,WITHOUT_CLASSIFICATION,//  Indicate if the read buffer has data for example   when in reading data on disk could be pull in 
Hive,WITHOUT_CLASSIFICATION,//  tests a multimap structure for PARQUET-26 
Hive,WITHOUT_CLASSIFICATION,//  Some other key (collision) - keep probing. 
Hive,WITHOUT_CLASSIFICATION,//  Safe to cancel delegation tokens now. 
Hive,WITHOUT_CLASSIFICATION,//  Update column expression map 
Hive,WITHOUT_CLASSIFICATION,//  To make (almost) sure we get definite order touch blocks in order large number of times. 
Hive,WITHOUT_CLASSIFICATION,//  class Builder; 
Hive,WITHOUT_CLASSIFICATION,//  Event 15 16 17 
Hive,WITHOUT_CLASSIFICATION,//  if any of bigTableCandidates is from multi-sourced bigTableCandidates should 
Hive,WITHOUT_CLASSIFICATION,//  VIEW/MATERIALIZED_VIEW 
Hive,WITHOUT_CLASSIFICATION,//  Scan the "output" directory for existing files and add watches 
Hive,WITHOUT_CLASSIFICATION,//  Note: it's not clear that we need to track this - unlike PoolManager we don't have non-pool         sessions so the pool itself could internally track the ses  sions it gave out since 
Hive,WITHOUT_CLASSIFICATION,//  mix functions 
Hive,WITHOUT_CLASSIFICATION,//  create tables and load data 
Hive,WITHOUT_CLASSIFICATION,//  We are calling this here because we expect the method to be completely async. We also don't   want this call itself to go on a thread because we want the percent-to-physics conversion   logic to be consistent between all the separate calls in one master thread processing round.   Note: If allocation manager does not have cluster state it won't update anything. When the 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) FieldList  */
Hive,WITHOUT_CLASSIFICATION,//  Default value set to 100 milliseconds for test purpose 
Hive,WITHOUT_CLASSIFICATION,//  The auto-commit mode is always enabled for this connection. Per JDBC spec 
Hive,WITHOUT_CLASSIFICATION,//  Constant propagation optimizer 
Hive,WITHOUT_CLASSIFICATION,// augment source with a col which has 1 if it will cause an update in target 0 otherwise 
Hive,WITHOUT_CLASSIFICATION,//  QUERY_PARALLELISM 
Hive,WITHOUT_CLASSIFICATION,//  if it is only one digit add a leading 0. 
Hive,WITHOUT_CLASSIFICATION,//  TODO: we can support date int .. any types which would have a fixed length value 
Hive,WITHOUT_CLASSIFICATION,//  Obtain relevant object inspector for this typeinfo 
Hive,WITHOUT_CLASSIFICATION,/*    * If the final PTF in a PTFChain can stream its output then set the OI of its OutputShape   * to the OI returned by the TableFunctionEvaluator.    */
Hive,WITHOUT_CLASSIFICATION,//  remember rhs table for semijoin 
Hive,WITHOUT_CLASSIFICATION,// note that (X % 0) is illegal and (X % -1) = 0   -1 is a common default when the value is missing 
Hive,WITHOUT_CLASSIFICATION,//  If a time zone is found in file metadata (property name: writer.time.zone) convert the   timestamp to that (writer) time zone in order to emulate time zone agnostic behavior.   If not then the file was written by an older version of hive so we convert the timestamp   to the server's (reader) time zone for backwards compatibility reasons - unless the   session level configuration hive.avro.timestamp.skip.conversion is set to true in which   case we assume it was written by a time zone agnostic writer so we don't convert it. 
Hive,WITHOUT_CLASSIFICATION,//  Memory manager uses cache policy to trigger evictions so create the policy first. 
Hive,WITHOUT_CLASSIFICATION,//  find whether exists a local driver to accept the url 
Hive,WITHOUT_CLASSIFICATION,//  shrinked size for this split. counter part of this in normal mode is   InputSplitShim.shrinkedLength.   what's different is that this is evaluated by unit of row using RecordReader.getPos()   and that is evaluated by unit of split using InputSplit.getLength(). 
Hive,WITHOUT_CLASSIFICATION,//  methods need not be called many times. 
Hive,WITHOUT_CLASSIFICATION,//  String including invalid '\000' style literal characters. 
Hive,WITHOUT_CLASSIFICATION,//  Run Spark Dynamic Partition Pruning 
Hive,WITHOUT_CLASSIFICATION,//  And mark group keys as repeating. 
Hive,WITHOUT_CLASSIFICATION,//  Return true in case one of the children is column expr. 
Hive,WITHOUT_CLASSIFICATION,//  invalid partition exception 
Hive,WITHOUT_CLASSIFICATION,//  Note: by closing stmt object we are also reverting any session specific config changes. 
Hive,WITHOUT_CLASSIFICATION,//  Query that should return nothing 
Hive,WITHOUT_CLASSIFICATION,//  If a Spark installation is provided use the spark-submit script. Otherwise call the   SparkSubmit class directly which has some caveats (like having to provide a proper 
Hive,WITHOUT_CLASSIFICATION,//  First try our cast method that will handle a few special cases. 
Hive,WITHOUT_CLASSIFICATION,//  getBytes function says: pos the ordinal position of the first byte in   the BLOB value to be extracted; the first byte is at position 1 
Hive,WITHOUT_CLASSIFICATION,//  Save original projection. 
Hive,WITHOUT_CLASSIFICATION,//  StatsTask require table to already exist 
Hive,WITHOUT_CLASSIFICATION,//  TODO error handling; distinguish IO/connection failures        attribute to appropriate spill output 
Hive,WITHOUT_CLASSIFICATION,//  Convert just the decimal digits (no dot sign etc) into bytes.     This is much faster than converting the BigInteger value from unscaledValue() which is no 
Hive,WITHOUT_CLASSIFICATION,//  The table names match so check on the partitions 
Hive,WITHOUT_CLASSIFICATION,//  verify it 
Hive,WITHOUT_CLASSIFICATION,//  postpone the join processing for this pair by also spilling this big table row. 
Hive,WITHOUT_CLASSIFICATION,//  ... and one without 
Hive,WITHOUT_CLASSIFICATION,/*      * Look for normal match.      */
Hive,WITHOUT_CLASSIFICATION,//  Check if we're operating on the same database if not move on 
Hive,WITHOUT_CLASSIFICATION,//  Get the tables in the default database 
Hive,WITHOUT_CLASSIFICATION,//  compareTo() 
Hive,WITHOUT_CLASSIFICATION,//  since we can rely on approx lastAccessTime but don't want a performance hit 
Hive,WITHOUT_CLASSIFICATION,//  only 32bits but long to behave as unsigned 
Hive,WITHOUT_CLASSIFICATION,//  Cache size 
Hive,WITHOUT_CLASSIFICATION,//  be done only for non-views. 
Hive,WITHOUT_CLASSIFICATION,//  Create a planner with a hook to update the mapping tables when a   node is copied when it is registered. 
Hive,WITHOUT_CLASSIFICATION,//  remove the location of container tokens 
Hive,WITHOUT_CLASSIFICATION,//  At this point transport must contain client ugi if it doesn't then its an old client. 
Hive,WITHOUT_CLASSIFICATION,//  Get the error details from the underlying exception 
Hive,WITHOUT_CLASSIFICATION,//  compare sorted strings rather than comparing exact strings. 
Hive,WITHOUT_CLASSIFICATION,//  do no filtering in old authorizer 
Hive,WITHOUT_CLASSIFICATION,// Change the selected vector 
Hive,WITHOUT_CLASSIFICATION,//  This string constant is used by AlterHandler to figure out that it should not attempt to   update stats. It is set by any client-side task which wishes to signal that no stats 
Hive,WITHOUT_CLASSIFICATION,//  sum size of all files in the partition is smaller than size required 
Hive,WITHOUT_CLASSIFICATION,//  a copy is required to allow incremental replication to work correctly. 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) TypeDouble  */
Hive,WITHOUT_CLASSIFICATION,//  getColumn() instead of using colValLenBufferReadIn directly. 
Hive,WITHOUT_CLASSIFICATION,//  parent op can understand this expression 
Hive,WITHOUT_CLASSIFICATION,//  If child keys are null or empty we bail out 
Hive,WITHOUT_CLASSIFICATION,//  No-op when authType is NOSASL 
Hive,WITHOUT_CLASSIFICATION,//  Vectorized implementation of BROUND(Col N) function 
Hive,WITHOUT_CLASSIFICATION,//  if stats are same no need to update 
Hive,WITHOUT_CLASSIFICATION,// now convert T to acid 
Hive,WITHOUT_CLASSIFICATION,//  Ignore and hope for the best. 
Hive,WITHOUT_CLASSIFICATION,//  Prepare StringBuilder-s for "in (...)" lists to use in one-to-many queries. 
Hive,WITHOUT_CLASSIFICATION,//  Get the base values w/o cache. 
Hive,WITHOUT_CLASSIFICATION,// 1 databases created 
Hive,WITHOUT_CLASSIFICATION,//  We have just obtained all we needed by splitting some block; now we need   to put the space remaining from that block into lower free lists.   We'll put at most one block into each list since 2 blocks can always be combined   to make a larger-level block. Each bit in the remaining target-sized blocks count   is one block in a list offset from target-sized list by bit index.   We do the merges here too since the block we just allocated could immediately be   moved out then the resulting free space abandoned. 
Hive,WITHOUT_CLASSIFICATION,//  If the stack has been explored already till that level   obtained cached String 
Hive,WITHOUT_CLASSIFICATION,//  get current bucket file name 
Hive,WITHOUT_CLASSIFICATION,//  Combine NOT operator with the child operator. Otherwise the following optimization   from bottom up could lead to incorrect result such as not(x > 3 and x is not null)   should not be optimized to not(x > 3) but (x <=3 or x is null). 
Hive,WITHOUT_CLASSIFICATION,//  re-use existing text member in char writable 
Hive,WITHOUT_CLASSIFICATION,//  considered using URLEncoder but it seemed too much 
Hive,WITHOUT_CLASSIFICATION,//  max. This table is either the the big table or we cannot convert. 
Hive,WITHOUT_CLASSIFICATION,//  Set port 
Hive,WITHOUT_CLASSIFICATION,//  setValue() should be able to handle null input 
Hive,WITHOUT_CLASSIFICATION,//  NEW_PARTS 
Hive,WITHOUT_CLASSIFICATION,// hl_txnid <> 0 means it's associated with a transaction 
Hive,WITHOUT_CLASSIFICATION,//  create/drop functions are marked as ADMIN functions   Usage of available functions in query are not restricted by sql   standard authorization. 
Hive,WITHOUT_CLASSIFICATION,//  Hash bits don't match. 
Hive,WITHOUT_CLASSIFICATION,//  Need to make sure that the this HiveServer2's session's SessionState is   stored in the thread local for the handler thread. 
Hive,WITHOUT_CLASSIFICATION,//  Try appending to non extendable shard spec 
Hive,WITHOUT_CLASSIFICATION,//  The import specification asked for only a particular partition to be loaded   We load only that and ignore all the others. 
Hive,WITHOUT_CLASSIFICATION,//  no stripe will satisfy the predicate 
Hive,WITHOUT_CLASSIFICATION,//  for use in DDL statements that require an exclusive lock 
Hive,WITHOUT_CLASSIFICATION,//  ideally we would like to do this check based on the number of splits   in the absence of an easy way to get the number of splits - do this   based on the total number of files (pessimistically assumming that 
Hive,WITHOUT_CLASSIFICATION,/* On Tez below (T is transactional) we get the following layoutekoifman:apache-hive-3.0.0-SNAPSHOT-bin ekoifman$ tree  ~/dev/hiverwgit/itests/hive-unit/target/tmp/org.apache.hadoop.hive.ql.TestAcidOnTez-1505500035574/warehouse/t/.hive-staging_hive_2017-09-15_11-28-33_960_9111484239090506828-1//Users/ekoifman/dev/hiverwgit/itests/hive-unit/target/tmp/org.apache.hadoop.hive.ql.TestAcidOnTez-1505500035574/warehouse/t/.hive-staging_hive_2017-09-15_11-28-33_960_9111484239090506828-1/└── -ext-10000    ├── HIVE_UNION_SUBDIR_1    │   └── 000000_0    │       ├── _orc_acid_version    │       └── delta_0000001_0000001_0001    │           └── bucket_00000    ├── HIVE_UNION_SUBDIR_2    │   └── 000000_0    │       ├── _orc_acid_version    │       └── delta_0000001_0000001_0002    │           └── bucket_00000    └── HIVE_UNION_SUBDIR_3        └── 000000_0            ├── _orc_acid_version            └── delta_0000001_0000001_0003                └── bucket_0000010 directories 6 files      */
Hive,WITHOUT_CLASSIFICATION,//  Check if results need to be emitted.   Results only need to be emitted if there is a non-null entry in a table   that is preserved or if there are no non-null entries 
Hive,WITHOUT_CLASSIFICATION,//  If we do a rename for a non-local file we will be transfering the original   file permissions from source to the destination. Else in case of mvFile() where we   copy from source to destination we will inherit the destination's parent group ownership. 
Hive,WITHOUT_CLASSIFICATION,//  Parse out sentences using Java's text-handling API 
Hive,WITHOUT_CLASSIFICATION,//  Authorize all dropped-partitions in one shot. 
Hive,WITHOUT_CLASSIFICATION,//  class HCatPartitionIterator; 
Hive,WITHOUT_CLASSIFICATION,//        if possible 
Hive,WITHOUT_CLASSIFICATION,//  JAVA32_OBJECT + PRIMITIVES1 * 2 + JAVA32_ARRAY; 
Hive,WITHOUT_CLASSIFICATION,//  Read parameters 
Hive,WITHOUT_CLASSIFICATION,//  if we have issues with stats just scale linearily 
Hive,WITHOUT_CLASSIFICATION,//  mgr == true 
Hive,WITHOUT_CLASSIFICATION,//  user asked for map-side join 
Hive,WITHOUT_CLASSIFICATION,//  Add 1 to counter default rounding 
Hive,WITHOUT_CLASSIFICATION,//  High word gets integer rounding; middle and lower longwords are cleared. 
Hive,WITHOUT_CLASSIFICATION,//  get the destination and check if it is TABLE 
Hive,WITHOUT_CLASSIFICATION,//  don't check version if its a dry run 
Hive,WITHOUT_CLASSIFICATION,//  4.3) Finally we add SORT clause this is needed for the UPDATE.         TOK_SORTBY           TOK_TABSORTCOLNAMEASC              TOK_NULLS_FIRST                 .                    TOK_TABLE_OR_COL                       cmv_basetable_2 
Hive,WITHOUT_CLASSIFICATION,//  allowing fallback to default timestamp parsing if custom patterns fail. 
Hive,WITHOUT_CLASSIFICATION,//  metastore returns object type such as global GLOBAL   when no object is specified.   such privileges are not applicable to this authorization mode so   ignore them 
Hive,WITHOUT_CLASSIFICATION,//  Use SimpleEntry to save the offset and rowcount of limit clause   KEY of SimpleEntry: offset 
Hive,WITHOUT_CLASSIFICATION,//  MergeFileWork is sub-class of MapWork we don't need to distinguish here 
Hive,WITHOUT_CLASSIFICATION,//  4. Walk through Window Expressions & Construct RexNodes for those 
Hive,WITHOUT_CLASSIFICATION,//  nothing to unregister 
Hive,WITHOUT_CLASSIFICATION,//  bootstrap we skip current table update. 
Hive,WITHOUT_CLASSIFICATION,//  first two stripes will satisfy condition and hence single split 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.ICLIService#getTables(org.apache.hive.service.cli.SessionHandle java.lang.String java.lang.String java.lang.String java.util.List)    */
Hive,WITHOUT_CLASSIFICATION,//  use version of existing max segment to generate new shard spec 
Hive,WITHOUT_CLASSIFICATION,//  We assume a DAG is a DAG and that it's connected. Add direct dependencies. 
Hive,WITHOUT_CLASSIFICATION,//  create the aggregate 
Hive,WITHOUT_CLASSIFICATION,//  No move pending the allocator can release. 
Hive,WITHOUT_CLASSIFICATION,//  Joda DateTime only has precision to millis cut off any fractional portion 
Hive,WITHOUT_CLASSIFICATION,//  Add files to compare to the arguments list 
Hive,WITHOUT_CLASSIFICATION,//  Calculate window size 
Hive,WITHOUT_CLASSIFICATION,/*    * Initialize one column's array entries.    */
Hive,WITHOUT_CLASSIFICATION,//  estimate the size of each entry -   a datatype with unknown size (String/Struct etc. - is assumed to be 256   bytes for now). 
Hive,WITHOUT_CLASSIFICATION,//  See if we can arrive at a smaller number using distinct stats from key columns. 
Hive,WITHOUT_CLASSIFICATION,//  Logger to console 
Hive,WITHOUT_CLASSIFICATION,//  3.1 Add Column info for non partion cols (Object Inspector fields) 
Hive,WITHOUT_CLASSIFICATION,//  Get the tag value. 
Hive,WITHOUT_CLASSIFICATION,// when minor compaction runs we collapse per statement delta files inside a single  transaction so we no longer need a statementId in the file name 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: fetchOne doesn't throw new SQLFeatureNotSupportedException("Method not supported"). 
Hive,WITHOUT_CLASSIFICATION,//  SOURCE_TABLES_UPDATE_DELETE_MODIFIED 
Hive,WITHOUT_CLASSIFICATION,//  Spot check decimal scalar-column modulo 
Hive,WITHOUT_CLASSIFICATION,/*    * Test whether a precision will fit within a decimal64 (64-bit signed long with <= 18 decimal   * digits).    */
Hive,WITHOUT_CLASSIFICATION,//  instantiate empty list so that we don't error out on iterator fetching.   If we're here then the next check of pos will show our caller that   that we've exhausted our event supply 
Hive,WITHOUT_CLASSIFICATION,//  Use QueryIdentifierProto.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,// LIB_JARS should only be set if Sqoop is auto-shipped 
Hive,WITHOUT_CLASSIFICATION,// verify data and layout 
Hive,WITHOUT_CLASSIFICATION,//  get the sign of the big decimal 
Hive,WITHOUT_CLASSIFICATION,//  Rather unexpected usage exception. 
Hive,WITHOUT_CLASSIFICATION,//  No matter whether it has acquired or not we cannot pass an exclusive. 
Hive,WITHOUT_CLASSIFICATION,//  4. Push down limit through outer join   NOTE: We run this after PPD to support old style join syntax.   Ex: select * from R1 left outer join R2 where ((R1.x=R2.x) and R1.y<10) or 
Hive,WITHOUT_CLASSIFICATION,// save work to be initialized later with SMB information. 
Hive,WITHOUT_CLASSIFICATION,//  SKEWED_COL_VALUES 
Hive,WITHOUT_CLASSIFICATION,//  check if we should use delegation tokens to authenticate   the call below gets hold of the tokens if they are set up by hadoop   this should happen on the map/reduce tasks if the client added the   tokens into hadoop's credential store in the front end during job   submission. 
Hive,WITHOUT_CLASSIFICATION,//  This is default implementation. Locking only works for incremental maintenance   which only works for DB transactional manager thus we cannot acquire a lock. 
Hive,WITHOUT_CLASSIFICATION,//  if this ast has only one child then no partition spec specified. 
Hive,WITHOUT_CLASSIFICATION,//  add into conditional task 
Hive,WITHOUT_CLASSIFICATION,//  hashMap += JAVA32_OBJECT 
Hive,WITHOUT_CLASSIFICATION,//  5% tolerance for long range bias and 2.5% for short range bias 
Hive,WITHOUT_CLASSIFICATION,//  HIVE-18977 
Hive,WITHOUT_CLASSIFICATION,//  dump information if call took more than 1 sec (1000ms) 
Hive,WITHOUT_CLASSIFICATION,//  number of rows -1 means that statistics from metastore is not reliable   and 0 means statistics gathering is disabled   estimate only if num rows is -1 since 0 could be actual number of rows 
Hive,WITHOUT_CLASSIFICATION,/*    * PTF variables   *  */
Hive,WITHOUT_CLASSIFICATION,//  We start iterating through the foreign keys. This list might contain more than a single   foreign key and each foreign key might contain multiple columns. The outer loop retrieves   the information that is common for a single key (table information) while the inner loop   checks / adds information about each column. 
Hive,WITHOUT_CLASSIFICATION,//  Just go from the back and throw away everything we think is wrong; skip last item the file. 
Hive,WITHOUT_CLASSIFICATION,//  Compare the results 
Hive,WITHOUT_CLASSIFICATION,//  Create the RecordReader 
Hive,WITHOUT_CLASSIFICATION,//  remaining size needed after putting files in the return path list 
Hive,WITHOUT_CLASSIFICATION,//  if the currently read token is a beginning of an array or object move stream forward   skipping any child tokens till we're at the corresponding END_ARRAY or END_OBJECT token 
Hive,WITHOUT_CLASSIFICATION,// fetch the row inserted after schema is altered and verify 
Hive,WITHOUT_CLASSIFICATION,//  Set the current UGI to a fake user 
Hive,WITHOUT_CLASSIFICATION,//  1. First start the queries from the queue. 
Hive,WITHOUT_CLASSIFICATION,//  Ignore 
Hive,WITHOUT_CLASSIFICATION,//  now try to invalid alter table 
Hive,WITHOUT_CLASSIFICATION,//  copy a value 
Hive,WITHOUT_CLASSIFICATION,//  Properties passed by the client to be used in execution hooks. 
Hive,WITHOUT_CLASSIFICATION,//  The datastructure doing the actual storage during mapjoins has some per row overhead 
Hive,WITHOUT_CLASSIFICATION,//  Split around the 'tab' character 
Hive,WITHOUT_CLASSIFICATION,//  of it for a possible series of equal keys. 
Hive,WITHOUT_CLASSIFICATION,//  map-reduce jobs will be run locally based on data size 
Hive,WITHOUT_CLASSIFICATION,//  check isRepeating handling 
Hive,WITHOUT_CLASSIFICATION,//  PartitionList is not evaluated until the run phase. 
Hive,WITHOUT_CLASSIFICATION,//  The original exception is lost.   Not changing the interface to maintain backward compatibility 
Hive,WITHOUT_CLASSIFICATION,//  For simplicity to always have parents while storing pools in a flat structure we'll   first distribute them by levels then add level by level. 
Hive,WITHOUT_CLASSIFICATION,//  Acquire 2nd Txn Batch 
Hive,WITHOUT_CLASSIFICATION,//  All fields have been parsed or bytes have been parsed.   We need to set the startPosition of fields.length to ensure we   can use the same formula to calculate the length of each field.   For missing fields their starting positions will all be the same   which will make their lengths to be -1 and uncheckedGetField will   return these fields as NULLs. 
Hive,WITHOUT_CLASSIFICATION,//  All ReduceSinkOperators in this sub-tree. This set is used when we start to remove unnecessary 
Hive,WITHOUT_CLASSIFICATION,//  the operator stack. The dispatcher generates the plan from the operator tree 
Hive,WITHOUT_CLASSIFICATION,/*      * the rewritten where Clause      */
Hive,WITHOUT_CLASSIFICATION,/*    * construct the ASTNode for the SQ column that will join with the OuterQuery Expression.   * So for 'select ... from R1 where A in (select B from R2...)'   * this will build (= outerQueryExpr 'ast returned by call to buildSQJoinExpr')    */
Hive,WITHOUT_CLASSIFICATION,//  contains aliases from sub-query 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * This provides a LazyDouble like class which can be initialized from data stored in a   * binary format.   *   * @see org.apache.hadoop.hive.serde2.lazy.LazyObject#init   *        (org.apache.hadoop.hive.serde2.lazy.ByteArrayRef int int)    */
Hive,WITHOUT_CLASSIFICATION,//  4. Apply join order optimizations: reordering MST algorithm      If join optimizations failed because of missing stats we continue with 
Hive,WITHOUT_CLASSIFICATION,//  No SDs probably a view. 
Hive,WITHOUT_CLASSIFICATION,//  RELY_CSTR 
Hive,WITHOUT_CLASSIFICATION,//  or the same day of the month 
Hive,WITHOUT_CLASSIFICATION,//  E: Lock we are trying to acquire is exclusive 
Hive,WITHOUT_CLASSIFICATION,// assuming this means we are not doing Auth 
Hive,WITHOUT_CLASSIFICATION,//  Unsupported in-memory structure. 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) Typei32  */
Hive,WITHOUT_CLASSIFICATION,//  STRING_VAL 
Hive,WITHOUT_CLASSIFICATION,//  DDLSemanticAnalyzer has already checked if partial partition specs are allowed   thus we should not need to check it here. 
Hive,WITHOUT_CLASSIFICATION,//  create the dest directory if not exist 
Hive,WITHOUT_CLASSIFICATION,//  Since addition is commutative we can add in any order. 
Hive,WITHOUT_CLASSIFICATION,//  If it's marked as too many aborted we already know we need to compact 
Hive,WITHOUT_CLASSIFICATION,//  Add the parameter here if it cannot change at runtime 
Hive,WITHOUT_CLASSIFICATION,//  Now that we reordered QBJoinTrees update leftaliases of all 
Hive,WITHOUT_CLASSIFICATION,//  If the target table exists and is newer or same as current update based on repl.last.id then just noop it. 
Hive,WITHOUT_CLASSIFICATION,//  multiple distincts is not supported with skew in data 
Hive,WITHOUT_CLASSIFICATION,//  part is also a virtual column but part col should not in this   list. 
Hive,WITHOUT_CLASSIFICATION,//  Create parent if it does not exist recreation is not an error 
Hive,WITHOUT_CLASSIFICATION,//  Now we need to de-scratchify this location - i.e. get rid of any   _SCRATCH[\d].?[\d]+ from the location. 
Hive,WITHOUT_CLASSIFICATION,//  read the entire data back and see if did everything right 
Hive,WITHOUT_CLASSIFICATION,//  get table 
Hive,WITHOUT_CLASSIFICATION,//  Iterate through all the elements in Pig Schema and do validations as   dictated by semantics consult HCatSchema of table when need be.  helps with debug messages 
Hive,WITHOUT_CLASSIFICATION,//  add this partition to post-execution hook 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setNCharacterStream(java.lang.String   * java.io.Reader long)    */
Hive,WITHOUT_CLASSIFICATION,//  Skip method finding if the method name didn't change and class name didn't change. 
Hive,WITHOUT_CLASSIFICATION,//  create expression tree with type cast from string to timestamp 
Hive,WITHOUT_CLASSIFICATION,//  Just copy the information since there is nothing so far 
Hive,WITHOUT_CLASSIFICATION,//  Iterate over all the fields picking up the nested structs within them 
Hive,WITHOUT_CLASSIFICATION,//  Additional combinations of (longdouble)X(columnscalar) for each of the second   and third arguments are omitted. We have coverage of all the source templates   already. 
Hive,WITHOUT_CLASSIFICATION,//  Date and time parts 
Hive,WITHOUT_CLASSIFICATION,//  We store the position of the argument for the function in the input. 
Hive,WITHOUT_CLASSIFICATION,//  When a URI instance is initialized it creates a bunch of private String   fields never bothering about their possible duplication. It would be   best if we could tell URI constructor to intern these strings right away.   Without this option we can only use reflection to "fix" strings in these   fields after a URI has been created. 
Hive,WITHOUT_CLASSIFICATION,//  The grouping set key is present after the grouping keys before the distinct keys 
Hive,WITHOUT_CLASSIFICATION,//  See javadoc - no need to clean up the cache data anymore. 
Hive,WITHOUT_CLASSIFICATION,// we have "insert into foo(ab)..."; parser will enforce that 1+ columns are listed if TOK_TABCOLNAME is present 
Hive,WITHOUT_CLASSIFICATION,//  Move on with our counts. 
Hive,WITHOUT_CLASSIFICATION,//  Need to initialize the lock manager 
Hive,WITHOUT_CLASSIFICATION,//  Verify the fetched logs from the beginning of the log file 
Hive,WITHOUT_CLASSIFICATION,// final String query = tabMetaData.getProperty("hive.sql.query"); 
Hive,WITHOUT_CLASSIFICATION,//  enable/disable bitpacking 
Hive,WITHOUT_CLASSIFICATION,//  All must be selected otherwise size would be zero Repeating property will not change. 
Hive,WITHOUT_CLASSIFICATION,//  verify the scratch directories has been cleaned up 
Hive,WITHOUT_CLASSIFICATION,//  BitSet::wordsInUse is transient so force dumping into a lower form 
Hive,WITHOUT_CLASSIFICATION,// Subset of counters that should be of interest for hive.client.stats.publishers (when one wants to limit their publishing). Non-display names should be used". 
Hive,WITHOUT_CLASSIFICATION,//  UNSCALED 
Hive,WITHOUT_CLASSIFICATION,// clear state from previous txn 
Hive,WITHOUT_CLASSIFICATION,/*  alternate1 = useLazySimpleEscapes  */
Hive,WITHOUT_CLASSIFICATION,//           analyzeDatabaseLoad(dbNameOrPattern fs dir);          } 
Hive,WITHOUT_CLASSIFICATION,//  Turn on metastore-side authorization 
Hive,WITHOUT_CLASSIFICATION,//  Marked where the projected expr is coming from so that the types will   become nullable for the original projections which are now coming out 
Hive,WITHOUT_CLASSIFICATION,//  Set the system properties needed by Pig 
Hive,WITHOUT_CLASSIFICATION,//  Interrupt the current thread after 1 second 
Hive,WITHOUT_CLASSIFICATION,//  null gets stored into column g which is a binary field. 
Hive,WITHOUT_CLASSIFICATION,//  since it is a sort-merge join only follow the big table 
Hive,WITHOUT_CLASSIFICATION,//  1. Fully contained   topOffset + topLimit <= bottomLimit 
Hive,WITHOUT_CLASSIFICATION,//  Backtrack bucket columns of cRS to pRS (if any) 
Hive,WITHOUT_CLASSIFICATION,//  Note: never instantiate a task without TaskFactory.get() if you're not   okay with .equals() breaking. Doing it via TaskFactory.get makes sure   that an id is generated and two tasks of the same type don't show   up as "equal" which is important for things like iterating over an   array. Without this DTa DTb and DTc would show up as one item in   the list of children. Thus we're instantiating via a helper method   that instantiates via TaskFactory.get() 
Hive,WITHOUT_CLASSIFICATION,//  Authorization header must have a payload 
Hive,WITHOUT_CLASSIFICATION,//  Retain only valid intersections (discard disjoint ranges) 
Hive,WITHOUT_CLASSIFICATION,//  param had no scheme so not a URL 
Hive,WITHOUT_CLASSIFICATION,//  Whether the native vectorized map join operator has performed its 
Hive,WITHOUT_CLASSIFICATION,//  whether current batch has any forwarded keys   mapping of index (lined up w/keys) to index in the batch   mapping of index in the batch (linear) to hash result   Size of the current batch. 
Hive,WITHOUT_CLASSIFICATION,//  interface if so they aggregate the size of the aggregation buffer 
Hive,WITHOUT_CLASSIFICATION,//  The unassigned batchIndex for the rows that have not received a non-NULL value yet.   A temporary work array. 
Hive,WITHOUT_CLASSIFICATION,//  Cross with outer join: currently we do not merge 
Hive,WITHOUT_CLASSIFICATION,//  8. Build Calcite Rel 
Hive,WITHOUT_CLASSIFICATION,// non-acid to transactional conversion (property itself) must be mutexed to prevent concurrent writes.   See HIVE-16688 for use cases. 
Hive,WITHOUT_CLASSIFICATION,//  As of writing this there is no case where this could be false this is just protection   from possible future changes 
Hive,WITHOUT_CLASSIFICATION,//  This flow is usually taken for REPL LOAD   Our input is the result of a _files listing we should expand out _files. 
Hive,WITHOUT_CLASSIFICATION,//  For sub-queries the id. and alias should be appended since same aliases can be re-used   within different sub-queries.   For a query like:   select ...     (select * from T1 a where ...) subq1    join     (select * from T2 a where ...) subq2   .. 
Hive,WITHOUT_CLASSIFICATION,//  For a kerberos setup 
Hive,WITHOUT_CLASSIFICATION,/*  * Interface for a vector map join hash table (which could be a hash map hash multi-set or * hash set) for a single byte array key.  */
Hive,WITHOUT_CLASSIFICATION,//  after "."? 
Hive,WITHOUT_CLASSIFICATION,// create this in doAs() so that it gets a security context based passed in 'ugi' 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getDate(java.lang.String   * java.util.Calendar)    */
Hive,WITHOUT_CLASSIFICATION,//  Why is this even in metastore? 
Hive,WITHOUT_CLASSIFICATION,//  Remove DPP predicates 
Hive,WITHOUT_CLASSIFICATION,//  such as "%abc" 
Hive,WITHOUT_CLASSIFICATION,//  Found an expression that we can try to reduce 
Hive,WITHOUT_CLASSIFICATION,//  Set to 2 so insert and update don't set it off but delete does 
Hive,WITHOUT_CLASSIFICATION,//  Or the existing table is newer than our update. So don't allow the update. 
Hive,WITHOUT_CLASSIFICATION,//  Precondition check: verify whether the table is created and data is fetched correctly. 
Hive,WITHOUT_CLASSIFICATION,//  Meta-conf cleanup should trigger an event to listener 
Hive,WITHOUT_CLASSIFICATION,//  Bitwise OR the bitvector with the bitvector in the agg buffer 
Hive,WITHOUT_CLASSIFICATION,//  When a new buffer is fetched ResultSet.next() should be called "incrementalBufferRows" more times 
Hive,WITHOUT_CLASSIFICATION,//  if key doesn't contain CF it's an encoded value from a previous iterator. 
Hive,WITHOUT_CLASSIFICATION,//  one. 
Hive,WITHOUT_CLASSIFICATION,//  This method gets the basic stats from metastore for table/partitions. This will make use of the statistics from   AnnotateWithStatistics optimizer when available. If execution engine is tez or spark AnnotateWithStatistics   optimization is applied only during physical compilation because of DPP changing the stats. In such case we   we will get the basic stats from metastore. When statistics is absent in metastore we will use the fallback of 
Hive,WITHOUT_CLASSIFICATION,//  Pre-allocated member for storing index into the hashMapResults for each spilled row. 
Hive,WITHOUT_CLASSIFICATION,// remove this alias from the alias list 
Hive,WITHOUT_CLASSIFICATION,//  print out nth partition key for debugging 
Hive,WITHOUT_CLASSIFICATION,//  1. If the schema is the same then bail out 
Hive,WITHOUT_CLASSIFICATION,/*  * Test that the server code exists and responds to basic requests.  */
Hive,WITHOUT_CLASSIFICATION,//  This statement will attempt to move kv1.txt out of stickyBitDir as user foo.  HS2 is   expected to return 20009. 
Hive,WITHOUT_CLASSIFICATION,//  DPP. Now look up nDVs on both sides to see the selectivity.   <Parent Ops>-SEL-GB1-RS1-GB2-RS2 
Hive,WITHOUT_CLASSIFICATION,//  additional bits (beyond 31 bits) of the seconds-since-epoch part of timestamp. 
Hive,WITHOUT_CLASSIFICATION,//  Equals 
Hive,WITHOUT_CLASSIFICATION,//  Hive doesn't have an auto-increment concept 
Hive,WITHOUT_CLASSIFICATION,//  Get a list of joins which cannot be converted to a sort merge join   Only selects and filters operators are allowed between the table scan and   join currently. More operators can be added - the method supportAutomaticSortMergeJoin 
Hive,WITHOUT_CLASSIFICATION,//  We have filled HiveDecimal.MAX_PRECISION digits and have no more room in our limit precision   fast decimal.  However since we are processing fractional digits we do rounding.   away. 
Hive,WITHOUT_CLASSIFICATION,//  The summary query returns only one row         
Hive,WITHOUT_CLASSIFICATION,//  I couldn't think of a good way to reuse the keys and value objects   without even more allocations so take the easy and safe approach. 
Hive,WITHOUT_CLASSIFICATION,//  Compute distribution 
Hive,WITHOUT_CLASSIFICATION,//  Arena cannot change after we have marked it as released. 
Hive,WITHOUT_CLASSIFICATION,//  1.3. Set Partition cols in TSDesc 
Hive,WITHOUT_CLASSIFICATION,// the token file location should be first argument of pig 
Hive,WITHOUT_CLASSIFICATION,//  Extraction can be a subset of columns so this is the projection --   the batch column numbers. 
Hive,WITHOUT_CLASSIFICATION,//  ignore shutting down anyway 
Hive,WITHOUT_CLASSIFICATION,/*    * Simulate the join by driving the test big table data by our test small table HashMap and   * create the expected output as a multi-set of TestRow (i.e. TestRow and occurrence count).    */
Hive,WITHOUT_CLASSIFICATION,//  No type name difference or adornment. 
Hive,WITHOUT_CLASSIFICATION,//  We have a stream for included column but in future it might have no data streams.   It's more like "has at least one column included that has an index stream". 
Hive,WITHOUT_CLASSIFICATION,//  dynamic partitioning with custom path; resolve the custom path   using partition column values 
Hive,WITHOUT_CLASSIFICATION,//  The first call to markFailed() should have removed the record from   COMPACTION_QUEUE so a repeated call should fail 
Hive,WITHOUT_CLASSIFICATION,//  This doesn't get used but it's still necessary see 
Hive,WITHOUT_CLASSIFICATION,//  First Segment Granularity has to be here. 
Hive,WITHOUT_CLASSIFICATION,// Is this a filter that should perform a comparison for sorted searches 
Hive,WITHOUT_CLASSIFICATION,//  List of partitions 
Hive,WITHOUT_CLASSIFICATION,/* ├── base_0000002│   ├── bucket_00000│   └── bucket_00001├── delete_delta_0000002_0000002_0000│   └── bucket_00000|   └── bucket_00001├── delta_0000001_0000001_0000│   ├── bucket_00000│   └── bucket_00001└── delta_0000002_0000002_0000    └── bucket_00000     */
Hive,WITHOUT_CLASSIFICATION,//  These data structures are needed to create the new project 
Hive,WITHOUT_CLASSIFICATION,//  Add the value to the vector 
Hive,WITHOUT_CLASSIFICATION,// ************************************************************************************************   Decimal Validation. 
Hive,WITHOUT_CLASSIFICATION,//  Verify if no create table/function calls. Only add foreign key constraints on table t2. 
Hive,WITHOUT_CLASSIFICATION,//  Case with nulls 
Hive,WITHOUT_CLASSIFICATION,//  change session's default queue to tezq1 and rerun test sequence 
Hive,WITHOUT_CLASSIFICATION,//  after constant folding 
Hive,WITHOUT_CLASSIFICATION,//  separator for open txns   separator for aborted txns 
Hive,WITHOUT_CLASSIFICATION,//  for top constraining Sel 
Hive,WITHOUT_CLASSIFICATION,//  Pick the first host always. Weak attempt at cache affinity. 
Hive,WITHOUT_CLASSIFICATION,//  The key given by user is ignored - in case of Parquet we need to supply null 
Hive,WITHOUT_CLASSIFICATION,//  check table params 
Hive,WITHOUT_CLASSIFICATION,//  Test that adding a file to the remote context makes it available to executors. 
Hive,WITHOUT_CLASSIFICATION,// if set determines that task is complete. 
Hive,WITHOUT_CLASSIFICATION,//  Assume this is the table we are at now. 
Hive,WITHOUT_CLASSIFICATION,//  Generate a new task 
Hive,WITHOUT_CLASSIFICATION,//  Read big value length we wrote with the value. 
Hive,WITHOUT_CLASSIFICATION,//  Compute the number of values we want to read in this page. 
Hive,WITHOUT_CLASSIFICATION,//  pattern to identify errors related to the client closing the socket early   idea borrowed from Netty SslHandler 
Hive,WITHOUT_CLASSIFICATION,//  SQL standard - return null for zero elements 
Hive,WITHOUT_CLASSIFICATION,//  all columns need to be at least a subset of the parentOfParent's bucket cols 
Hive,WITHOUT_CLASSIFICATION,//  Replace table scan operator 
Hive,WITHOUT_CLASSIFICATION,//  added by the multi group by optimization) 
Hive,WITHOUT_CLASSIFICATION,//  The test table has 500 rows so total query time should be ~ 500*500ms 
Hive,WITHOUT_CLASSIFICATION,//  We assume the latter is pretty high so we don't check for now. 
Hive,WITHOUT_CLASSIFICATION,//  Generate the beeline args per hive conf and execute the given script 
Hive,WITHOUT_CLASSIFICATION,//       LOG.info("System.getenv(\"HADOOP_TOKEN_FILE_LOCATION\") =["+  System.getenv("HADOOP_TOKEN_FILE_LOCATION")+"]"); 
Hive,WITHOUT_CLASSIFICATION,//  TSimpleJSONProtocol does not support deserialization.   protocols.add(org.apache.thrift.protocol.TSimpleJSONProtocol.class.getName());   isBinaries.add(false);   additionalParams.add(null); 
Hive,WITHOUT_CLASSIFICATION,//  It was not present in the cache (maybe because it was added by another HS2) 
Hive,WITHOUT_CLASSIFICATION,//  prefer left cause right might be missing 
Hive,WITHOUT_CLASSIFICATION,//  prettier error messages to frontend 
Hive,WITHOUT_CLASSIFICATION,//  -ddddddddd hh:mm:ss.nnnnnnnnn 
Hive,WITHOUT_CLASSIFICATION,//  If there is a sort-merge join followed by a regular join the SMBJoinOperator may not   get initialized at all. Consider the following query:   A SMB B JOIN C   For the mapper processing C The SMJ is not initialized no need to close it either. 
Hive,WITHOUT_CLASSIFICATION,/*  * Simple one long key map join benchmarks. * * Build with "mvn clean install -DskipTests -Pdistitests" at main hive directory. * * From itests/hive-jmh directory run: *     java -jar target/benchmarks.jar org.apache.hive.benchmark.vectorization.mapjoin.MapJoinOneLongKeyBench * *  {INNER INNER_BIG_ONLY LEFT_SEMI OUTER} *    X *  {ROW_MODE_HASH_MAP ROW_MODE_OPTIMIZED VECTOR_PASS_THROUGH NATIVE_VECTOR_OPTIMIZED NATIVE_VECTOR_FAST} *  */
Hive,WITHOUT_CLASSIFICATION,//  recursively remove non-parent task from its children 
Hive,WITHOUT_CLASSIFICATION,//  write out serialized plan with counters to log file 
Hive,WITHOUT_CLASSIFICATION,/*  Object Inspector corresponding to the input parameter.      */
Hive,WITHOUT_CLASSIFICATION,//  Already existing database 
Hive,WITHOUT_CLASSIFICATION,//  Now all txns are removed from MIN_HISTORY_LEVEL. So all entries from TXN_TO_WRITE_ID would be cleaned. 
Hive,WITHOUT_CLASSIFICATION,//  delta writer 
Hive,WITHOUT_CLASSIFICATION,//  default to origin in given time zone when aligning multi-period granularities 
Hive,WITHOUT_CLASSIFICATION,//  Destroy before returning to the pool. 
Hive,WITHOUT_CLASSIFICATION,//  Set the inferred bucket columns for the file this FileSink produces 
Hive,WITHOUT_CLASSIFICATION,//     ii) if the project is trivial a raw join 
Hive,WITHOUT_CLASSIFICATION,//  If all of them were true return true 
Hive,WITHOUT_CLASSIFICATION,//  TODO: also account for Tez-internal session restarts; 
Hive,WITHOUT_CLASSIFICATION,//  JDK 1.7 
Hive,WITHOUT_CLASSIFICATION,//  Test partition listing with a partial spec - ds is specified but hr is not 
Hive,WITHOUT_CLASSIFICATION,//  Rename fails if the file with same name already exist. 
Hive,WITHOUT_CLASSIFICATION,//  stats from metastore only once. 
Hive,WITHOUT_CLASSIFICATION,//  bd is greater than or equal to 1 
Hive,WITHOUT_CLASSIFICATION,//  no dictionary 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#isPoolable()    */
Hive,WITHOUT_CLASSIFICATION,//  this should fail 
Hive,WITHOUT_CLASSIFICATION,//  check rightInputRel contains no correlation 
Hive,WITHOUT_CLASSIFICATION,//  extra capacity in case we overrun to avoid resizing 
Hive,WITHOUT_CLASSIFICATION,//  Try another table. 
Hive,WITHOUT_CLASSIFICATION,//  set the lock object with a dummy data and then do a set if needed. 
Hive,WITHOUT_CLASSIFICATION,// Evaluate the predicate expression 
Hive,WITHOUT_CLASSIFICATION,//  sum(VCol*c) 
Hive,WITHOUT_CLASSIFICATION,// INT64 is not yet supported 
Hive,WITHOUT_CLASSIFICATION,//  6. Read data. 
Hive,WITHOUT_CLASSIFICATION,//  timeout after reset 
Hive,WITHOUT_CLASSIFICATION,//  future. 
Hive,WITHOUT_CLASSIFICATION,//  Call the process function 
Hive,WITHOUT_CLASSIFICATION,//  2.2 All the other FKs. 
Hive,WITHOUT_CLASSIFICATION,//  use them. 
Hive,WITHOUT_CLASSIFICATION,// complete T1 transaction (simulate writing to 2 partitions) 
Hive,WITHOUT_CLASSIFICATION,//  We never resize the pool so assume this is initialization.   If that changes we might have to make the factory interface more complicated. 
Hive,WITHOUT_CLASSIFICATION,//  Get the user/groups for checking permissions based on the current UGI. 
Hive,WITHOUT_CLASSIFICATION,//  Middle word gets integer rounding. 
Hive,WITHOUT_CLASSIFICATION,/*      * We check UDFs against the supportedGenericUDFs when     * hive.vectorized.adaptor.usage.mode=chosen or none.     *     * We allow all UDFs for hive.vectorized.adaptor.usage.mode=all.      */
Hive,WITHOUT_CLASSIFICATION,/*    * True only for operators which produce atmost 1 output row per input   * row to it. This will allow the output column names to be directly   * translated to input column names.    */
Hive,WITHOUT_CLASSIFICATION,//  To avoid that we will remove the RS (and EX) inserted by enforce bucketing/sorting. 
Hive,WITHOUT_CLASSIFICATION,// We need to factor this in to prevent overwhelming Spark executor-memory. 
Hive,WITHOUT_CLASSIFICATION,//  1.3. Add all distinct params   NOTE: distinct expr can not be part of of GB key (we assume plan 
Hive,WITHOUT_CLASSIFICATION,//  The canAccept part of this log message does not account for this allocation. 
Hive,WITHOUT_CLASSIFICATION,//  Another task at a higher priority may have come in during the wait. Lookup the   queue again to pick up the task at the highest priority. 
Hive,WITHOUT_CLASSIFICATION,//  For outer joins since the small table key can be null when there is no match   we must have a physical (scratch) column for those keys.  We cannot use the   projection optimization used by inner joins above. 
Hive,WITHOUT_CLASSIFICATION,//  BFS 
Hive,WITHOUT_CLASSIFICATION,//  TODO:   1) Handle compound partition keys (partition by k1+k2)   2) When multiple window clauses are present in same select Even if   Predicate can not pushed past all of them we might still able to   push   it below some of them.   Ex: select * from (select key value avg(c_int) over (partition by   key) sum(c_float) over(partition by value) from t1)t1 where value <   10   --> select * from (select key value avg(c_int) over (partition by   key) from (select key value sum(c_float) over(partition by value)   from t1 where value < 10)t1)t2 
Hive,WITHOUT_CLASSIFICATION,//  Note: we only run "for columns" command and assume no basic stats means no col stats. 
Hive,WITHOUT_CLASSIFICATION,//  5% tolerance for estimated count 
Hive,WITHOUT_CLASSIFICATION,//  they all modify primordial rows 
Hive,WITHOUT_CLASSIFICATION,//  there are no fields in the struct 
Hive,WITHOUT_CLASSIFICATION,//  test path; SQL is enabled and broken. 
Hive,WITHOUT_CLASSIFICATION,//  5s timeout 
Hive,WITHOUT_CLASSIFICATION,//  Once the eventId reaches 5-20-100 then just increment it sequentially. This is to avoid longer values. 
Hive,WITHOUT_CLASSIFICATION,//  If the output column is of type string initialize the buffer to receive data. 
Hive,WITHOUT_CLASSIFICATION,//  A jump table to figure out whether to wait acquire   or keep looking .  Since   java doesn't have function pointers (grumble grumble) we store a   character that we'll use to determine which function to call.   The table maps the lock type of the lock we are looking to acquire to   the lock type of the lock we are checking to the lock state of the lock 
Hive,WITHOUT_CLASSIFICATION,// PTF declarations 
Hive,WITHOUT_CLASSIFICATION,//  load upgrade order for the given dbType 
Hive,WITHOUT_CLASSIFICATION,//  The optimizer will automatically convert it to a map-only job. 
Hive,WITHOUT_CLASSIFICATION,//  construct a path pattern (e.g. /*/*) to find all dynamically generated paths 
Hive,WITHOUT_CLASSIFICATION,//  in the case of proxy users the getCurrentUser will return the   real user (for e.g. oozie) due to the doAs that happened just before the   server started executing the method getDelegationToken in the MetaStore 
Hive,WITHOUT_CLASSIFICATION,//  UNDONE: Used by tests... 
Hive,WITHOUT_CLASSIFICATION,//  no authority - use default one if it applies 
Hive,WITHOUT_CLASSIFICATION,//  hardcoded for reproducibility. 
Hive,WITHOUT_CLASSIFICATION,// ensure txn timesout 
Hive,WITHOUT_CLASSIFICATION,// unique to the store func and out file name (table in our case). 
Hive,WITHOUT_CLASSIFICATION,//  path format of segmentOutputPath -- > .../dataSource/interval/version/partitionNum/ 
Hive,WITHOUT_CLASSIFICATION,//  create alias to work which contains the merge operator 
Hive,WITHOUT_CLASSIFICATION,//  Template <ClassName> <ValueType> 
Hive,WITHOUT_CLASSIFICATION,//  Output keys and aggregates into the output batch. 
Hive,WITHOUT_CLASSIFICATION,//  Check permisssion on partition dirs and files created 
Hive,WITHOUT_CLASSIFICATION,//  If Druid table is not an external table store the schema in metadata store. 
Hive,WITHOUT_CLASSIFICATION,//  Inserting hive variables 
Hive,WITHOUT_CLASSIFICATION,//  Set ours. 
Hive,WITHOUT_CLASSIFICATION,//  2. Now read all of the ranges from cache or disk. 
Hive,WITHOUT_CLASSIFICATION,//  ==== HiveServer2 metadata api types ends here ==== // 
Hive,WITHOUT_CLASSIFICATION,//  '-' sign and '.' 
Hive,WITHOUT_CLASSIFICATION,//  that we can only process records 
Hive,WITHOUT_CLASSIFICATION,//  Read from the stream using the protocol for each column in final schema 
Hive,WITHOUT_CLASSIFICATION,//  Get key columns from inputs. Those are the columns on which we will distribute on.   It is also the columns we will sort on. 
Hive,WITHOUT_CLASSIFICATION,// owner = "testOwner1" 
Hive,WITHOUT_CLASSIFICATION,//  Don't enforce during test driver setup or shutdown. 
Hive,WITHOUT_CLASSIFICATION,//  A Statement#cancel after ResultSet#close should be a no-op 
Hive,WITHOUT_CLASSIFICATION,//  For every pattern 
Hive,WITHOUT_CLASSIFICATION,//  MRv2 job tag used to identify Templeton launcher child jobs. Each child job   will be tagged with the parent jobid so that on launcher task restart all   previously running child jobs can be killed before the child job is launched   again. 
Hive,WITHOUT_CLASSIFICATION,//  throw an error if default value isn't what hive allows 
Hive,WITHOUT_CLASSIFICATION,// start with an empty priv set; 
Hive,WITHOUT_CLASSIFICATION,//  If the CTAS query does specify a location use the table location else use the db location 
Hive,WITHOUT_CLASSIFICATION,// http://www.oratable.com/oracle-insert-all/  https://livesql.oracle.com/apex/livesql/file/content_BM1LJQ87M5CNIOKPOWPV6ZGR3.html 
Hive,WITHOUT_CLASSIFICATION,//  Verify that the schemaTool ran pre-upgrade scripts and ignored errors 
Hive,WITHOUT_CLASSIFICATION,//  Use any non-NULL values found; remember the remaining unassigned. 
Hive,WITHOUT_CLASSIFICATION,//  restrict with any ranges found from WHERE predicates. 
Hive,WITHOUT_CLASSIFICATION,//  First INSERT round. 
Hive,WITHOUT_CLASSIFICATION,//  Go over the tables and populate the related structures.   We have to materialize the table alias list since we might 
Hive,WITHOUT_CLASSIFICATION,//  arrays never change. So we will just do a shallow assignment here instead of copy. 
Hive,WITHOUT_CLASSIFICATION,//  fastIsByte returns false. 
Hive,WITHOUT_CLASSIFICATION,//  Come ride the API roller-coaster #2! The best part is that ctx has TezTaskAttemptID inside. 
Hive,WITHOUT_CLASSIFICATION,//  having seen the root operator before means there was a branch in the   operator graph. There's typically two reasons for that: a) mux/demux   b) multi insert. Mux/Demux will hit the same leaf again multi insert   will result into a vertex with multiple FS or RS operators. 
Hive,WITHOUT_CLASSIFICATION,//  Incremental Repl B -> C with alters on db/table/partition 
Hive,WITHOUT_CLASSIFICATION,//  generate the meta data for key   index for key is -1 
Hive,WITHOUT_CLASSIFICATION,//  Nothing for the zkCreate models 
Hive,WITHOUT_CLASSIFICATION,//  timestamp column/column IF 
Hive,WITHOUT_CLASSIFICATION,//  generate output column names 
Hive,WITHOUT_CLASSIFICATION,//  cleanup 
Hive,WITHOUT_CLASSIFICATION,//  Assignment is the last thing in the try so if it happen we assume success. 
Hive,WITHOUT_CLASSIFICATION,//  in order to determine the sum field type (precision/scale) for Mode.PARTIAL2 and Mode.FINAL. 
Hive,WITHOUT_CLASSIFICATION,//  the base table for the group by matches the skewed keys 
Hive,WITHOUT_CLASSIFICATION,// case substring from index with length 
Hive,WITHOUT_CLASSIFICATION,//  Swallow the exception and let the call determine what to do. 
Hive,WITHOUT_CLASSIFICATION,/*  * Abstract class for a hash multi-set result.  */
Hive,WITHOUT_CLASSIFICATION,//       hcatDriver.run("drop table "+TBL_NAME);      hcatDriver.run("create table junit_sem_analysis (a int) partitioned by (b string) stored as RCFILE");      hcatDriver.run("alter table "+TBL_NAME+" add partition (b='2010-10-10')");        List<String> partVals = new ArrayList<String>(1);      partVals.add("2010-10-10");        Map<StringString> map = client.getPartition(MetaStoreUtils.DEFAULT_DATABASE_NAME TBL_NAME partVals).getParameters();      assertEquals(map.get(InitializeInput.HOWL_ISD_CLASS) RCFileInputStorageDriver.class.getName());      assertEquals(map.get(InitializeInput.HOWL_OSD_CLASS) RCFileOutputStorageDriver.class.getName());    } 
Hive,WITHOUT_CLASSIFICATION,//  create a standard settable struct object inspector. 
Hive,WITHOUT_CLASSIFICATION,/* we acquire all locks for a given query atomically; if 1 blocks all go into (remain) in                * Waiting state.  wait() will undo any 'acquire()' which may have happened as part of                * this (metastore db) transaction and then we record which lock blocked the lock                * we were testing ('info'). */
Hive,WITHOUT_CLASSIFICATION,//  Validate query materialization (materialized views query results caching.   This check needs to occur before constant folding which may remove some 
Hive,WITHOUT_CLASSIFICATION,//  create a new InputFormat instance if this is the first time to see this class 
Hive,WITHOUT_CLASSIFICATION,//  HDFS scratch dir 
Hive,WITHOUT_CLASSIFICATION,//  Dynamic partitioning usecase 
Hive,WITHOUT_CLASSIFICATION,//  val == sign * significand * 2**exponent.   this == sign * unscaledValue / 10**scale.   so to make val==this we need to scale it up/down such that:   unscaledValue = significand * 2**exponent * 10**scale   Notice that we must do the scaling carefully to check overflow and 
Hive,WITHOUT_CLASSIFICATION,//  Drop every table in the default database 
Hive,WITHOUT_CLASSIFICATION,//  No parallel edge was found for the given mapjoin op   no need to go down further skip this TS operator pipeline. 
Hive,WITHOUT_CLASSIFICATION,//  Move the clock forward 2000ms and check the delayed queue 
Hive,WITHOUT_CLASSIFICATION,//  Whether number of open transactions reaches the threshold 
Hive,WITHOUT_CLASSIFICATION,//  subscribe feeds from the MoveTask so that MoveTask can forward the list 
Hive,WITHOUT_CLASSIFICATION,//  we merge those that can be merged 
Hive,WITHOUT_CLASSIFICATION,//  Reducers do not benefit from LLAP IO so no point in printing 
Hive,WITHOUT_CLASSIFICATION,// to test initial metadata count metrics. 
Hive,WITHOUT_CLASSIFICATION,//  test null on both sides 
Hive,WITHOUT_CLASSIFICATION,//  DROP 
Hive,WITHOUT_CLASSIFICATION,/*   @Override  public com.esotericsoftware.kryo.io.Output getHybridBigTableSpillOutput(int partitionId) {    throw new RuntimeException("Not applicable");  }   */
Hive,WITHOUT_CLASSIFICATION,//  D3. Calculate Q hat - estimation of the next digit 
Hive,WITHOUT_CLASSIFICATION,//  We currently only give the initial event to the task on the first heartbeat. Given   that the split is ready it seems pointless to wait but that's how Tez works. 
Hive,WITHOUT_CLASSIFICATION,// if we got here it means it's ok to acquire 'info' lock 
Hive,WITHOUT_CLASSIFICATION,// we want to preserve 'columnName' as it was in original input query so that rewrite 
Hive,WITHOUT_CLASSIFICATION,//  the persistent function is discarded. try reload 
Hive,WITHOUT_CLASSIFICATION,//  Record repeating and no nulls state to be restored later. 
Hive,WITHOUT_CLASSIFICATION,//  The session will be restarted and return to us. 
Hive,WITHOUT_CLASSIFICATION,//  this doesn't create partition. 
Hive,WITHOUT_CLASSIFICATION,//  Test long 
Hive,WITHOUT_CLASSIFICATION,//  Column numbers of batch corresponding to expression result arguments 
Hive,WITHOUT_CLASSIFICATION,//  if serialization fails we will throw incompatible metastore error to the client. 
Hive,WITHOUT_CLASSIFICATION,//  If the regex is changed make sure we compile the regex again. 
Hive,WITHOUT_CLASSIFICATION,//  Reprocess the spilled data 
Hive,WITHOUT_CLASSIFICATION,//  key and value objects are created once in initialize() and then reused   for every getCurrentKey() and getCurrentValue() call. This is important   since RCFile makes an assumption of this fact. 
Hive,WITHOUT_CLASSIFICATION,//  Non-null ConfVar only defined in ConfVars 
Hive,WITHOUT_CLASSIFICATION,//  Expected. 
Hive,WITHOUT_CLASSIFICATION,//  Fail the retry. 
Hive,WITHOUT_CLASSIFICATION,// ************************************************************************************************   Decimal Precision / Trailing Zeroes. 
Hive,WITHOUT_CLASSIFICATION,//  Note if metrics have not been initialized this will return null which means we aren't 
Hive,WITHOUT_CLASSIFICATION,//  If no writeIds allocated by txns under txnHwm then find writeHwm from NEXT_WRITE_ID. 
Hive,WITHOUT_CLASSIFICATION,//  renaming test to make test framework skip it 
Hive,WITHOUT_CLASSIFICATION,//  optional string key = 1; 
Hive,WITHOUT_CLASSIFICATION,//  We will try to reuse this but session3 is queued before us. 
Hive,WITHOUT_CLASSIFICATION,//  hm.getTable result will not have privileges set (it does not retrieve   that part from metastore) so unset privileges to null before comparing 
Hive,WITHOUT_CLASSIFICATION,//  to handle the different Map definition in Parquet eg:   definition has 1 group:     repeated group map (MAP_KEY_VALUE)       {required binary key (UTF8); optional binary value (UTF8);}   definition has 2 groups:     optional group m1 (MAP) {       repeated group map (MAP_KEY_VALUE)         {required binary key (UTF8); optional binary value (UTF8);} 
Hive,WITHOUT_CLASSIFICATION,//       LOG.info("Searching for "+dynPathSpec); 
Hive,WITHOUT_CLASSIFICATION,/*  ignore  */
Hive,WITHOUT_CLASSIFICATION,// Inserts are not tracked by WRITE_SET 
Hive,WITHOUT_CLASSIFICATION,//  FileSink cannot be simply cloned - it requires some special processing.   Sub-queries for the union will be processed as independent map-reduce jobs   possibly running in parallel. Those sub-queries cannot write to the same   directory. Clone the filesink but create a sub-directory in the final path 
Hive,WITHOUT_CLASSIFICATION,//  allow DP 
Hive,WITHOUT_CLASSIFICATION,//  This is a dfs file 
Hive,WITHOUT_CLASSIFICATION,//  This config contains all the configuration that master node wants to provide   to the HCatalog. 
Hive,WITHOUT_CLASSIFICATION,//  If the command has an associated schema make sure it gets printed to use 
Hive,WITHOUT_CLASSIFICATION,// the Group By args are passed to cardinality_violation to add the violating value to the error msg 
Hive,WITHOUT_CLASSIFICATION,//  Test equals operator for strings and integers. 
Hive,WITHOUT_CLASSIFICATION,//  Code borrowed from VectorReduceSinkOperator 
Hive,WITHOUT_CLASSIFICATION,//  Add the expression into the BloomFilter 
Hive,WITHOUT_CLASSIFICATION,//  Get to the SelectOperator ancestor 
Hive,WITHOUT_CLASSIFICATION,//  Rewrite the above plan:     CorrelateRel(left correlation condition = true)     LeftInputRel     Project-A (a RexNode)       Aggregate (groupby(0) agg0()agg1()...)         Project-B (may reference coVar)           Filter (references corVar)             RightInputRel (no correlated reference)   
Hive,WITHOUT_CLASSIFICATION,//  is compressed? 
Hive,WITHOUT_CLASSIFICATION,//  The SecurityContext set by AuthFilter 
Hive,WITHOUT_CLASSIFICATION,//  We check the sizes of neededColumns and partNames here. If either   size is 0 aggrStats is null after several retries. Thus we can 
Hive,WITHOUT_CLASSIFICATION,//  default to Monday as beginning of the week 
Hive,WITHOUT_CLASSIFICATION,//  if nLines <= 0 read all lines in log file. 
Hive,WITHOUT_CLASSIFICATION,//  same for char 
Hive,WITHOUT_CLASSIFICATION,//  Using a shared instance of the umbilical server. 
Hive,WITHOUT_CLASSIFICATION,//  try again with some different data values 
Hive,WITHOUT_CLASSIFICATION,//  By default we should set sparkCloneConfiguration to true in the Spark config 
Hive,WITHOUT_CLASSIFICATION,//  insert into should skip and increment partition number to 3 
Hive,WITHOUT_CLASSIFICATION,//  add non-null parameters to the schema 
Hive,WITHOUT_CLASSIFICATION,//  static partitions 
Hive,WITHOUT_CLASSIFICATION,/*      * Skim off the exponent.      */
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#createStatement(int int int)    */
Hive,WITHOUT_CLASSIFICATION,// using old config value tests backwards compatibility 
Hive,WITHOUT_CLASSIFICATION,//  OPERATION_COMPLETED 
Hive,WITHOUT_CLASSIFICATION,/*  Whether the cache has been initialized or not.  */
Hive,WITHOUT_CLASSIFICATION,//  One of these runs at the output of each reducer 
Hive,WITHOUT_CLASSIFICATION,//  Column was not found in table schema. Its a new column 
Hive,WITHOUT_CLASSIFICATION,//  user does not specify queue so use session default 
Hive,WITHOUT_CLASSIFICATION,//  Set "global" member indicating where to store "not vectorized" information if necessary. 
Hive,WITHOUT_CLASSIFICATION,//  Run our value expressions over whole batch. 
Hive,WITHOUT_CLASSIFICATION,//  This is called once per AM so we don't get the starting duck count here. 
Hive,WITHOUT_CLASSIFICATION,// Authorization checks are performed by the storageHandler.getAuthorizationProvider() if  StorageDelegationAuthorizationProvider is used. 
Hive,WITHOUT_CLASSIFICATION,//  -> ^(TOK_REPLICATION $replId $isMetadataOnly) 
Hive,WITHOUT_CLASSIFICATION,//  Only used by spillBigTableRow? 
Hive,WITHOUT_CLASSIFICATION,//  AMReporter after the server so that it gets the correct address. It knows how to deal with 
Hive,WITHOUT_CLASSIFICATION,//  We just logged an exception with (in case of JDO) a humongous callstack. Make a new one. 
Hive,WITHOUT_CLASSIFICATION,//  Merge the two closest bins into their average x location weighted by their heights.   The height of the new bin is the sum of the heights of the old bins.   double d = bins[smallestdiffloc].y + bins[smallestdiffloc+1].y;   bins[smallestdiffloc].x *= bins[smallestdiffloc].y / d;   bins[smallestdiffloc].x += bins[smallestdiffloc+1].x / d *     bins[smallestdiffloc+1].y;   bins[smallestdiffloc].y = d; 
Hive,WITHOUT_CLASSIFICATION,//  Nothing new added to the queue while analyze runs. 
Hive,WITHOUT_CLASSIFICATION,//  if we are running in local mode - then the amount of memory used   by the child jvm can no longer default to the memory used by the   parent jvm 
Hive,WITHOUT_CLASSIFICATION,//  empty out the file 
Hive,WITHOUT_CLASSIFICATION,//  Methods to set/reset getTable modifier 
Hive,WITHOUT_CLASSIFICATION,//  ORIENTATION 
Hive,WITHOUT_CLASSIFICATION,//  get session   update session allocation   kill query   destroy session   restart session   return session back to pool   move session to different pool 
Hive,WITHOUT_CLASSIFICATION,//  Prefix partition with something to avoid it being a hidden file. 
Hive,WITHOUT_CLASSIFICATION,//  Note: all the fields are only modified by master thread. 
Hive,WITHOUT_CLASSIFICATION,//  Create the walker the rules dispatcher and the context.   create a walker which walks the tree in a DFS manner while maintaining   the operator stack. The dispatcher 
Hive,WITHOUT_CLASSIFICATION,//  If we're inside a replication scope then the table not existing is not an error. 
Hive,WITHOUT_CLASSIFICATION,//  Must be deterministic order map - see HIVE-8707     => we use Maps.newLinkedHashMap instead of Maps.newHashMap 
Hive,WITHOUT_CLASSIFICATION,//  find the min/max based on the offset and length (and more for 'original') 
Hive,WITHOUT_CLASSIFICATION,//  parameter value not changed to false in connection 2.  int to smallint throws exception 
Hive,WITHOUT_CLASSIFICATION,//  ColumnInfos for table alias "". 
Hive,WITHOUT_CLASSIFICATION,//  32767 % 256 = 255 
Hive,WITHOUT_CLASSIFICATION,//  get all partitions that matches with the partition spec 
Hive,WITHOUT_CLASSIFICATION,//  NULL does equal NULL here. 
Hive,WITHOUT_CLASSIFICATION,//  #reducer is already 1 
Hive,WITHOUT_CLASSIFICATION,//  Try with erroneously generated VOID 
Hive,WITHOUT_CLASSIFICATION,//  Here we create a project for the following reasons:   (1) GBy only accepts arg as a position of the input however we need to sum on VCol*c   (2) This can better reuse the function createSingleArgAggCall. 
Hive,WITHOUT_CLASSIFICATION,//  We have extracted the existence from the hash set result so we don't keep it. 
Hive,WITHOUT_CLASSIFICATION,//  this method should be called by MoveTask when there are dynamic   partitions generated 
Hive,WITHOUT_CLASSIFICATION,// try not to leave any files open 
Hive,WITHOUT_CLASSIFICATION,//  String value = (String)en.getValue(); // does not apply variable   expansion   does variable expansion 
Hive,WITHOUT_CLASSIFICATION,//  Add negative self. 
Hive,WITHOUT_CLASSIFICATION,//  Table location should not be printed with hbase backed tables 
Hive,WITHOUT_CLASSIFICATION,//  it seems that it is not used by anything. 
Hive,WITHOUT_CLASSIFICATION,//  repl metadata export has repl.last.id and repl.scope=metadata   import repl metadata dump table metadata changed allows override has repl.last.id 
Hive,WITHOUT_CLASSIFICATION,//  May need to setup localDir for re-localization which is usually setup as Environment.PWD.   Used for re-localization to add the user specified configuration (conf_pb_binary_stream) 
Hive,WITHOUT_CLASSIFICATION,//  We set the thread local username in ThriftHttpServlet. 
Hive,WITHOUT_CLASSIFICATION,/*    * HdfsUtils.setFullFileStatus(..) is called from multiple parallel threads. If AclEntries   * is modifiable the method will not be thread safe and could cause random concurrency issues   * This test case checks if the aclEntries returned from HadoopFileStatus is thread-safe or not    */
Hive,WITHOUT_CLASSIFICATION,/*  * Directly deserialize with the caller reading field-by-field a serialization format. * * The caller is responsible for calling the read method for the right type of each field * (after calling readNextField). * * Reading some fields require a results object to receive value information.  A separate * results object is created by the caller at initialization per different field even for the same * type. * * Some type values are by reference to either bytes in the deserialization buffer or to * other type specific buffers.  So those references are only valid until the next time set is * called.  */
Hive,WITHOUT_CLASSIFICATION,//  Commenting as part of HIVE-12274 != and <> are not supported for CLOBs   tableNames = client.listTableNamesByFilter(dbName filter (short) 2);   assertEquals(2 tableNames.size()); 
Hive,WITHOUT_CLASSIFICATION,//  get nanos since [epoch at fromZone] 
Hive,WITHOUT_CLASSIFICATION,/* cloneToWork.containsKey(mapWork) */
Hive,WITHOUT_CLASSIFICATION,//  Change the plan to this structure.     Project-A' (replace corvar to input ref from Join)     Join (left condition = true)       LeftInputRel       Aggregate(groupby(0) single_value(0) s_v(1)....)         Project-B (everything from input plus literal true)           ProjInputRel 
Hive,WITHOUT_CLASSIFICATION,//  SR: Lock we are trying to acquire is shared read 
Hive,WITHOUT_CLASSIFICATION,//  Find all of the agg expressions. We use a List (for all count(distinct)) 
Hive,WITHOUT_CLASSIFICATION,//  check for partition 
Hive,WITHOUT_CLASSIFICATION,//  Index of where the buffer is; in minAllocation units (headers array). 
Hive,WITHOUT_CLASSIFICATION,// sort the list to get sorted (deterministic) output (for ease of testing) 
Hive,WITHOUT_CLASSIFICATION,//  capture stderr 
Hive,WITHOUT_CLASSIFICATION,// constant just return 
Hive,WITHOUT_CLASSIFICATION,//  because zero is zero. Need to mention it in Javadoc. 
Hive,WITHOUT_CLASSIFICATION,//  First just allocate just the output columns we will be using. 
Hive,WITHOUT_CLASSIFICATION,//  in this case we've determined that there's too much data   to prune dynamically. 
Hive,WITHOUT_CLASSIFICATION,//  The return type will be the concatenation of input type and original values type 
Hive,WITHOUT_CLASSIFICATION,//  INSERT OVERWRITE 
Hive,WITHOUT_CLASSIFICATION,//  if call isn't EQUAL type and it has been determined that value generate might be   required we should rather generate value generator 
Hive,WITHOUT_CLASSIFICATION,//  Convert the column to the correct type when needed and set in row obj 
Hive,WITHOUT_CLASSIFICATION,//  This is a valid error message. 
Hive,WITHOUT_CLASSIFICATION,//  For nested sub-queries the alias mapping is not maintained in QB currently. 
Hive,WITHOUT_CLASSIFICATION,//  Since DemuxOperator may appear multiple times in MuxOperator's parents list.   We use newChildIndexTag instead of childOperatorsTag.   Example:           JOIN             |            MUX           / | \          /  |  \         /   |   \         |  GBY  |         \   |   /          \  |  /           DEMUX   In this case the parent list of MUX is [DEMUX GBY DEMUX]   so we need to have two childOperatorsTags (the index of this DemuxOperator in 
Hive,WITHOUT_CLASSIFICATION,//  Testing no nulls and no repeating 
Hive,WITHOUT_CLASSIFICATION,//  Non aggregate mode - analyze union operator 
Hive,WITHOUT_CLASSIFICATION,//  t1 is inside v1 we should not care about its access info. 
Hive,WITHOUT_CLASSIFICATION,//  PROGRESS_UPDATE_RESPONSE 
Hive,WITHOUT_CLASSIFICATION,//  It's important to read the correct nulls! (in truth the path is needed for SplitGrouper). 
Hive,WITHOUT_CLASSIFICATION,//  prefix extend start 
Hive,WITHOUT_CLASSIFICATION,//  Debug only 
Hive,WITHOUT_CLASSIFICATION,//  We run constant propagation twice because after predicate pushdown filter expressions   are combined and may become eligible for reduction (like is not null filter). 
Hive,WITHOUT_CLASSIFICATION,//  UNIQUE_CONSTRAINTS 
Hive,WITHOUT_CLASSIFICATION,//  We assume this always comes from a user operation that took the lock. 
Hive,WITHOUT_CLASSIFICATION,//  For password based authentication 
Hive,WITHOUT_CLASSIFICATION,//  Build Druid query 
Hive,WITHOUT_CLASSIFICATION,//  Lock ids are unique across the system. 
Hive,WITHOUT_CLASSIFICATION,//  allow this form 
Hive,WITHOUT_CLASSIFICATION,//  we start at index 1 since at 0 is the variable from table column 
Hive,WITHOUT_CLASSIFICATION,//  -------------------------------------------------------------------------------   VERTICES: 03/04            [=================>>-----] 86%  ELAPSED TIME: 1.71 s 
Hive,WITHOUT_CLASSIFICATION,//  Restored the renamed tables 
Hive,WITHOUT_CLASSIFICATION,//  We can only flush after the updateAggregations is done or the   potentially new entry "aggs"   can be flushed out of the hash table. 
Hive,WITHOUT_CLASSIFICATION,//  Whatever. 
Hive,WITHOUT_CLASSIFICATION,// 012345678901234567890123456789 
Hive,WITHOUT_CLASSIFICATION,// Assert.assertEquals(4 stat.length); 
Hive,WITHOUT_CLASSIFICATION,//  validate the create view statement at this point the createVwDesc gets   all the information for semanticcheck 
Hive,WITHOUT_CLASSIFICATION,//  First field is the row key. 
Hive,WITHOUT_CLASSIFICATION,//  Move marker according to delta change delta to 0. 
Hive,WITHOUT_CLASSIFICATION,//  Update stats for transactional tables (MM or full ACID with overwrite) even   though we are marking stats as not being accurate. 
Hive,WITHOUT_CLASSIFICATION,//  Export is trivially retriable (after clearing out the staging dir provided.) 
Hive,WITHOUT_CLASSIFICATION,// prevent instantiation 
Hive,WITHOUT_CLASSIFICATION,/*      * Now a having clause can contain a SubQuery predicate;     * so we invoke genFilterPlan to handle SubQuery algebraic transformation     * just as is done for SubQuery predicates appearing in the Where Clause.      */
Hive,WITHOUT_CLASSIFICATION,//  UDAF in filter condition group-by caluse param of funtion etc. 
Hive,WITHOUT_CLASSIFICATION,//  IN clauses need to be combined by keeping only common elements 
Hive,WITHOUT_CLASSIFICATION,//  format: partition=p_val   Add only when table partition colName matches 
Hive,WITHOUT_CLASSIFICATION,//  Create a lock but send the heartbeat with a long delay. The lock will get expired. 
Hive,WITHOUT_CLASSIFICATION,//  all of the integer types   float and double   string char varchar 
Hive,WITHOUT_CLASSIFICATION,// We currently commit after selecting the TXNS to abort.  So whether SERIALIZABLE  READ_COMMITTED the effect is the same.  We could use FOR UPDATE on Select from TXNS  and do the whole performTimeOuts() in a single huge transaction but the only benefit  would be to make sure someone cannot heartbeat one of these txns at the same time.  The attempt to heartbeat would block and fail immediately after it's unblocked.  With current (RC + multiple txns) implementation it is possible for someone to send  heartbeat at the very end of the expire interval and just after the Select from TXNS  is made in which case heartbeat will succeed but txn will still be Aborted.  Solving this corner case is not worth the perf penalty.  The client should heartbeat in a  timely way. 
Hive,WITHOUT_CLASSIFICATION,//  Check for column encoding specification 
Hive,WITHOUT_CLASSIFICATION,//  Set temp location. 
Hive,WITHOUT_CLASSIFICATION,//  Outer key copying is only used when we are using the input BigTable batch as the output. 
Hive,WITHOUT_CLASSIFICATION,//  Generate the temporary file name 
Hive,WITHOUT_CLASSIFICATION,//  there may be multi distinct clauses for one column 
Hive,WITHOUT_CLASSIFICATION,//  for debugging 
Hive,WITHOUT_CLASSIFICATION,//  check if this table is sampled and needs more than input pruning 
Hive,WITHOUT_CLASSIFICATION,//  set the session configuration 
Hive,WITHOUT_CLASSIFICATION,//  optional bytes token = 2; 
Hive,WITHOUT_CLASSIFICATION,/*    * Serializes a distinctValueEstimator object to Text for transport.   *   * <b>4 byte header</b> is encoded like below 2 bytes - FM magic string to   * identify serialized stream 2 bytes - numbitvectors because   * BIT_VECTOR_SIZE=31 4 bytes are enough to hold positions of 0-31    */
Hive,WITHOUT_CLASSIFICATION,//  null filters are supported to simplify client code 
Hive,WITHOUT_CLASSIFICATION,//  A step function to increase the polling timeout by 500 ms every 10 sec    starting from 500 ms up to HIVE_SERVER2_LONG_POLLING_TIMEOUT 
Hive,WITHOUT_CLASSIFICATION,//  bytes. The higher-order bits come from the second VInt that follows the nanos field. 
Hive,WITHOUT_CLASSIFICATION,//  METADATA 
Hive,WITHOUT_CLASSIFICATION,//  the case that return type of the GenericUDF is not boolean and if not all partition   agree on result we make the node UNKNOWN. If they all agree we replace the node 
Hive,WITHOUT_CLASSIFICATION,//  The entry relevant to aborted txns shouldn't be removed from TXN_TO_WRITE_ID as   aborted txn would be removed from TXNS only after the compaction. Also committed txn > open txn is retained. 
Hive,WITHOUT_CLASSIFICATION,//  Merge the other estimation into the current one 
Hive,WITHOUT_CLASSIFICATION,//  Provide an instance of the code doesn't try to make a real Instance   We just want to test that we fail before trying to make a connector   with null password 
Hive,WITHOUT_CLASSIFICATION,//  For example      SELECT deptno COUNT(*) SUM(bonus) MIN(DISTINCT sal)      FROM emp      GROUP BY deptno     becomes        SELECT deptno SUM(cnt) SUM(bonus) MIN(sal)      FROM (            SELECT deptno COUNT(*) as cnt SUM(bonus) sal            FROM EMP            GROUP BY deptno sal)            // Aggregate B 
Hive,WITHOUT_CLASSIFICATION,//  Positive number 
Hive,WITHOUT_CLASSIFICATION,//  Extract the delegation Token from the UGI and add it to the job 
Hive,WITHOUT_CLASSIFICATION,// Unpartitioned table: 1 row for Delete; Inserts are not tracked in WRITE_SET 
Hive,WITHOUT_CLASSIFICATION,/*        * We need a total of poolThreadCount + 1 threads to start at same. There are       * poolThreadCount threads in thread pool and another one which has started them.       * The thread which sees atomic counter as poolThreadCount+1 is the last thread`       * to join and wake up all threads to start all at once.        */
Hive,WITHOUT_CLASSIFICATION,//  SESSION_ID 
Hive,WITHOUT_CLASSIFICATION,//  Shutdown HiveServer2 if it has been deregistered from ZooKeeper and has no active sessions 
Hive,WITHOUT_CLASSIFICATION,//  There's some bogus code that can modify the queue name. Force-set it for pool sessions. 
Hive,WITHOUT_CLASSIFICATION,//  for avro type the serialization class parameter is optional 
Hive,WITHOUT_CLASSIFICATION,//  Prepare 
Hive,WITHOUT_CLASSIFICATION,//  if our dbName is null we're interested in all wh events 
Hive,WITHOUT_CLASSIFICATION,//  One and only one. 
Hive,WITHOUT_CLASSIFICATION,//  init exec and set parameters included 
Hive,WITHOUT_CLASSIFICATION,//  2nd Txn Batch 
Hive,WITHOUT_CLASSIFICATION,//  Add 'n' rows corresponding to the grouping sets. For each row create 'n' rows   one for each grouping set key. Since map-side aggregation has already been performed   the number of rows would have been reduced. Moreover the rows corresponding to the   grouping keys come together so there is a higher chance of finding the rows in the hash   table. 
Hive,WITHOUT_CLASSIFICATION,// outerRR belongs to outer query and is required to resolve correlated references 
Hive,WITHOUT_CLASSIFICATION,//  set up the operator plan 
Hive,WITHOUT_CLASSIFICATION,//  top is distinct we can always merge whether bottom is distinct or not   top is all we can only merge if bottom is also all   that is to say we should bail out if top is all and bottom is distinct 
Hive,WITHOUT_CLASSIFICATION,//  7. HDFS temp table space 
Hive,WITHOUT_CLASSIFICATION,//  in the big table to bucket file names in small tables. 
Hive,WITHOUT_CLASSIFICATION,//  This is serious black magic as the following 2 lines do nothing AFAICT but without them   the subsequent call to listPartitionValues fails. 
Hive,WITHOUT_CLASSIFICATION,//  Since getBucketHashCode uses this HiveDecimal return the old (much slower) but   compatible hash code. 
Hive,WITHOUT_CLASSIFICATION,//  operator that handles the output of these e.g.: JoinOperator). 
Hive,WITHOUT_CLASSIFICATION,//  Remove from the running list. 
Hive,WITHOUT_CLASSIFICATION,/*    * In the non explain code path we don't need to track Query rewrites.   * All add fns during Plan generation are Noops.   * If the get Rewrite methods are called an UnsupportedOperationException is thrown.    */
Hive,WITHOUT_CLASSIFICATION,//  This is a mapping of which big table columns (input and key/value expressions) will be 
Hive,WITHOUT_CLASSIFICATION,//  Large cross product: generate the vector optimization using repeating vectorized   row batch optimization in the overflow batch. 
Hive,WITHOUT_CLASSIFICATION,//  Not public since we must have column information. 
Hive,WITHOUT_CLASSIFICATION,// Create the parameter declaration string 
Hive,WITHOUT_CLASSIFICATION,//  map may not contain all sources since input list may have been   optimized out   or non-existent tho such sources may still be referenced by the   TableScanOperator   if it's null then the partition probably doesn't exist so let's use   table permission 
Hive,WITHOUT_CLASSIFICATION,//  The file is still cached. 
Hive,WITHOUT_CLASSIFICATION,//  Set recursive traversal in case the cached query was UNION generated by Tez. 
Hive,WITHOUT_CLASSIFICATION,//  zero check 
Hive,WITHOUT_CLASSIFICATION,// make it look like streaming API use case 
Hive,WITHOUT_CLASSIFICATION,//  For vectorized reduce-side operators getting inputs from a reduce sink   the row object inspector will get a flattened version of the object inspector   where the nested key/value structs are replaced with a single struct:   Example: { key: { reducesinkkey0:int } value: { _col0:int _col1:int .. } }   Would get converted to the following for a vectorized input:     { 'key.reducesinkkey0':int 'value._col0':int 'value._col1':int .. }   The ExprNodeEvaluator initialzation below gets broken with the flattened   object inpsectors so convert it back to the a form that contains the   nested key/value structs. 
Hive,WITHOUT_CLASSIFICATION,//  Keep-alive information. The client should be informed and will have to take care of re-submitting the work.   Some parts of fault tolerance go here. 
Hive,WITHOUT_CLASSIFICATION,//  Object that can take a set of columns in row in a vectorized row batch and serialized it. 
Hive,WITHOUT_CLASSIFICATION,//  Don't change the table object returned by the metastore as we'll mess with it's caches. 
Hive,WITHOUT_CLASSIFICATION,//  SKEWED_INFO 
Hive,WITHOUT_CLASSIFICATION,// create 1 more delta_x_x so that compactor has > dir file to compact 
Hive,WITHOUT_CLASSIFICATION,//  write key element 
Hive,WITHOUT_CLASSIFICATION,//  We decided to treat this map as regular object. 
Hive,WITHOUT_CLASSIFICATION,//  NEED_MERGE 
Hive,WITHOUT_CLASSIFICATION,//  We return the key itself since no mapping was available/returned 
Hive,WITHOUT_CLASSIFICATION,// nothing can do here 
Hive,WITHOUT_CLASSIFICATION,/*    * Propagate null values for a two-input operator and set isRepeating and noNulls appropriately.    */
Hive,WITHOUT_CLASSIFICATION,//  Since local jobs are run sequentially all relevant information is already available   Therefore no need to fetch job debug info asynchronously 
Hive,WITHOUT_CLASSIFICATION,//  there are nulls so null array entries are already initialized 
Hive,WITHOUT_CLASSIFICATION,//  This is a combination of the jar stuff from conf and not from conf. 
Hive,WITHOUT_CLASSIFICATION,//  Don't allow for public. 
Hive,WITHOUT_CLASSIFICATION,//  Boundary case: require at least one non-partitioned column 
Hive,WITHOUT_CLASSIFICATION,//  Generate the new queryId if needed 
Hive,WITHOUT_CLASSIFICATION,//  Fail - trying to set "transactional" to "true" but doesn't satisfy bucketing and Input/OutputFormat requirement 
Hive,WITHOUT_CLASSIFICATION,//  Consider a query like:   insert overwrite table T3 select ... from T1 join T2 on T1.key = T2.key;   where T1 T2 and T3 are sorted and bucketed by key into the same number of buckets   We dont need a reducer to enforce bucketing and sorting for T3.   The field below captures the fact that the reducer introduced to enforce sorting/   bucketing of T3 has been removed.   In this case a sort-merge join is needed and so the sort-merge join between T1 and T2 
Hive,WITHOUT_CLASSIFICATION,//  op.outputVertexName may be null 
Hive,WITHOUT_CLASSIFICATION,// should not happen as we take care of all existing types 
Hive,WITHOUT_CLASSIFICATION,//  Sign - whether interval is positive or negative 
Hive,WITHOUT_CLASSIFICATION,// depending on FileSystem implementation flush() may or may not do anything  
Hive,WITHOUT_CLASSIFICATION,//  Sleep-time in milliseconds between batches of delegation tokens dropped. 
Hive,WITHOUT_CLASSIFICATION,//  later we can extend this to the union all case as well 
Hive,WITHOUT_CLASSIFICATION,//  We implement this logic using replaceChildren instead of replacing   the root node itself because windowing logic stores multiple   pointers to the AST and replacing root might lead to some pointers   leading to non-rewritten version 
Hive,WITHOUT_CLASSIFICATION,//  We cannot send the ecb to consumer. Discard whatever is already there. 
Hive,WITHOUT_CLASSIFICATION,//  set create time 
Hive,WITHOUT_CLASSIFICATION,//  Compare start Position 
Hive,WITHOUT_CLASSIFICATION,/*    * DbNotificationListener keys reserved for updating ListenerEvent parameters.   *   * DB_NOTIFICATION_EVENT_ID_KEY_NAME This key will have the event identifier that DbNotificationListener   *                                   processed during an event. This event identifier might be shared   *                                   across other MetaStoreEventListener implementations.    */
Hive,WITHOUT_CLASSIFICATION,//  Make sure the broken signature doesn't work. 
Hive,WITHOUT_CLASSIFICATION,//  Invalid cases 
Hive,WITHOUT_CLASSIFICATION,//  This time it completes by adding remaining partitions. 
Hive,WITHOUT_CLASSIFICATION,//  queryId of the command   time at which lock was acquired   mode of the lock: EXPLICIT(lock command)/IMPLICIT(query) 
Hive,WITHOUT_CLASSIFICATION,//  shift one 
Hive,WITHOUT_CLASSIFICATION,//  rebuild that is more efficient than the full rebuild. 
Hive,WITHOUT_CLASSIFICATION,/*  !inputColVector1.noNulls && !inputColVector2.noNulls  */
Hive,WITHOUT_CLASSIFICATION,//  Methods to set/reset listPartitionNames modifier 
Hive,WITHOUT_CLASSIFICATION,//  Must send on to VectorPTFOperator... 
Hive,WITHOUT_CLASSIFICATION,//  if its false we need to close recordReader. 
Hive,WITHOUT_CLASSIFICATION,//  A scratch batch that will be used to play back big table rows that were spilled 
Hive,WITHOUT_CLASSIFICATION,/*    * INT.    */
Hive,WITHOUT_CLASSIFICATION,//  INSERT EVENT to partitioned table with dynamic ADD_PARTITION 
Hive,WITHOUT_CLASSIFICATION,//  Arbitrary... we don't expect caller to hang out for 7+ mins. 
Hive,WITHOUT_CLASSIFICATION,//  Replace with the milliseconds conversion 
Hive,WITHOUT_CLASSIFICATION,//  child 1 is the type of the column 
Hive,WITHOUT_CLASSIFICATION,//  Distribute the available memory between the tasks. 
Hive,WITHOUT_CLASSIFICATION,//  If we are using a test specific database then we just drop the database and recreate 
Hive,WITHOUT_CLASSIFICATION,//  Write back the final NULL byte before the last fields. 
Hive,WITHOUT_CLASSIFICATION,//  Need to close the dummyOps as well. The operator pipeline   is not considered "closed/done" unless all operators are   done. For broadcast joins that includes the dummy parents. 
Hive,WITHOUT_CLASSIFICATION,// this simulates that cleaning thread will error out while cleaning the notifications 
Hive,WITHOUT_CLASSIFICATION,//  TODO:pc validate that there are no types that refer to this 
Hive,WITHOUT_CLASSIFICATION,//  test after recovery 
Hive,WITHOUT_CLASSIFICATION,//  Sign zero dot 2 * digits (to support toFormatString which can add a lot of trailing zeroes). 
Hive,WITHOUT_CLASSIFICATION,// if no sort keys are specified use an edge that does not sort 
Hive,WITHOUT_CLASSIFICATION,//  conversion functions take a single parameter 
Hive,WITHOUT_CLASSIFICATION,//  We will break the uncompressed data in the cache in the chunks that are the size   of the prevalent ORC compression buffer (the default) or maximum allocation (since we   cannot allocate bigger chunks) whichever is less. 
Hive,WITHOUT_CLASSIFICATION,//  Resets the aggregation calculation variable(s). 
Hive,WITHOUT_CLASSIFICATION,// CHARARRAY is unbounded so Hive->Pig is lossless 
Hive,WITHOUT_CLASSIFICATION,//  We could be scheduling a guaranteed task when a higher priority task cannot be   scheduled. Try to take a duck away from a lower priority task here. 
Hive,WITHOUT_CLASSIFICATION,//  close is called by UDTFOperator 
Hive,WITHOUT_CLASSIFICATION,//  Get serializable details of the destination tables 
Hive,WITHOUT_CLASSIFICATION,//  If it is a function we try to fold it 
Hive,WITHOUT_CLASSIFICATION,/*      * Check.4.h :: For Exists and Not Exists the Sub Query must     * have 1 or more correlated predicates.      */
Hive,WITHOUT_CLASSIFICATION,//  String should have been truncated. 
Hive,WITHOUT_CLASSIFICATION,/*    * @param currentKey   *          The current key.   * @param currentValue   *          The current value.    */
Hive,WITHOUT_CLASSIFICATION,// tries to get X lock on T6 and gets Waiting state 
Hive,WITHOUT_CLASSIFICATION,//  0.09765625BD * 0.09765625BD * 0.0125BD * 578992BD 
Hive,WITHOUT_CLASSIFICATION,//  same jobs running side-by-side 
Hive,WITHOUT_CLASSIFICATION,//  Finally evaluate the aggregators 
Hive,WITHOUT_CLASSIFICATION,//  sort bucket names for the big table 
Hive,WITHOUT_CLASSIFICATION,//  Special date formatting functions 
Hive,WITHOUT_CLASSIFICATION,//  see the indexes for colstats in IExtrapolatePartStatus 
Hive,WITHOUT_CLASSIFICATION,//  Now we read the big-endian compacted two's complement int parts   Compacted means they are stripped of leading 0x00s and 0xFFs   This is why we do the intLength/pos tricks bellow   'length' is all the bytes we have to read after we skip 'skip'   'pos' is where to start reading the current int   'intLength' is how many bytes we read for the current int 
Hive,WITHOUT_CLASSIFICATION,//  Remove this entry from the table usage mappings. 
Hive,WITHOUT_CLASSIFICATION,//  The group spans a VectorizedRowBatch.  Swap the relevant columns into our batch buffers   or write the batch to temporary storage. 
Hive,WITHOUT_CLASSIFICATION,//  No location should be created for views 
Hive,WITHOUT_CLASSIFICATION,//  This can only happen once at decompress time. 
Hive,WITHOUT_CLASSIFICATION,//  we should update it. Currently it refers to the source database name. 
Hive,WITHOUT_CLASSIFICATION,//  Part or virtual 
Hive,WITHOUT_CLASSIFICATION,//  Verify that getNextNotification() returns all events 
Hive,WITHOUT_CLASSIFICATION,//  update startIndex 
Hive,WITHOUT_CLASSIFICATION,//  If the from and to strings haven't changed we don't need to preprocess again to regenerate   the mappings of code points that need to replaced or deleted 
Hive,WITHOUT_CLASSIFICATION,//  Get the internal array structure 
Hive,WITHOUT_CLASSIFICATION,/*   Schema provided by user and the schema computed by Pig    * at the time of calling store must match.     */
Hive,WITHOUT_CLASSIFICATION,//  No exception for type checking for simplicity   Constructing the row ObjectInspector: 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#getUpdateCount()    */
Hive,WITHOUT_CLASSIFICATION,// populate target 
Hive,WITHOUT_CLASSIFICATION,//  if not from cache we still need to hook up the plans. 
Hive,WITHOUT_CLASSIFICATION,//  Done with this part. 
Hive,WITHOUT_CLASSIFICATION,//  Give it a value. 
Hive,WITHOUT_CLASSIFICATION,//  We explicitly create immutable lists here as it forces the guava lib to run the transformations   and not do them lazily. The reason being the function class used for transformations additionally   also creates the corresponding replCopyTasks which cannot be evaluated lazily. since the query 
Hive,WITHOUT_CLASSIFICATION,//  Example from HiveDecimal.add header comments. 
Hive,WITHOUT_CLASSIFICATION,//  We rebuild in-place the selected array with rows destine to be forwarded. 
Hive,WITHOUT_CLASSIFICATION,//  The number of spark tasks executed by the HiveServer2 since the last restart 
Hive,WITHOUT_CLASSIFICATION,//  Test more than one lock can be handled in a lock request 
Hive,WITHOUT_CLASSIFICATION,//  repeated .org.apache.hadoop.hive.serde2.proto.test.IntString lintString = 5; 
Hive,WITHOUT_CLASSIFICATION,//    throw new HiveException("sortMerged is not in sort order and unique");   } 
Hive,WITHOUT_CLASSIFICATION,//  Batch allocation should always happen atomically. Either write ids for all txns is allocated or none. 
Hive,WITHOUT_CLASSIFICATION,//  the probe failed we must allocate a set of aggregation buffers   and push the (keywrapperbuffers) pair into the hash.   is very important to clone the keywrapper the one we have from our   keyWrappersBatch is going to be reset/reused on next batch. 
Hive,WITHOUT_CLASSIFICATION,//  DPP work is considered a child because work needs   to finish for it to execute 
Hive,WITHOUT_CLASSIFICATION,//  If we evict a key that is not from this batch initial i = (-1) + 1 = 0 as intended. 
Hive,WITHOUT_CLASSIFICATION,// newTable has to exist at this point to compile 
Hive,WITHOUT_CLASSIFICATION,//  Using endpoint identification algorithm as HTTPS enables us to do 
Hive,WITHOUT_CLASSIFICATION,//  reset the buffer 
Hive,WITHOUT_CLASSIFICATION,//  Need to update the keys? 
Hive,WITHOUT_CLASSIFICATION,//  Since compilation is always a blocking RPC call and schema is ready after compilation   we can return when are in the RUNNING state. 
Hive,WITHOUT_CLASSIFICATION,//  Theoretically the key prefix could be any unique string shared   between TableScanOperator (when publishing) and StatsTask (when aggregating).   Here we use   db_name.table_name + partitionSec   as the prefix for easy of read during explain and debugging. 
Hive,WITHOUT_CLASSIFICATION,// this is to break a tie if insert + delete of a given row is done within the same  txn (so that currentWriteId is the same for both events) and we want the  delete event to sort 1st since it needs to be sent up so that   OrcInputFormat.getReader(InputSplit inputSplit Options options) can skip it. 
Hive,WITHOUT_CLASSIFICATION,//  Add the entry to the cache structures while under write lock. 
Hive,WITHOUT_CLASSIFICATION,//  Remove any cached results from the previous test. 
Hive,WITHOUT_CLASSIFICATION,/*      * In case of a select use a fetch task instead of a move task.     * If the select is from analyze table column rewrite don't create a fetch task. Instead create     * a column stats task later.      */
Hive,WITHOUT_CLASSIFICATION,//  if the task has started all operators within the task have   started 
Hive,WITHOUT_CLASSIFICATION,//  nothing can be done 
Hive,WITHOUT_CLASSIFICATION,//  Read the altered partition via CachedStore 
Hive,WITHOUT_CLASSIFICATION,//  Read the tag 
Hive,WITHOUT_CLASSIFICATION,//  No partitions need update. 
Hive,WITHOUT_CLASSIFICATION,//  should be "key" and "reverse(value)" 
Hive,WITHOUT_CLASSIFICATION,/*  * Abstract class for a hash set result.  */
Hive,WITHOUT_CLASSIFICATION,//  As columns go down the DAG the LVJ will transform internal column   names from something like 'key' to '_col0'. Because of this we need   to undo this transformation using the column expression map as the   column names propagate up the DAG. 
Hive,WITHOUT_CLASSIFICATION,/*  * Common hash code routines.  */
Hive,WITHOUT_CLASSIFICATION,/*     * todo: parse    * convertToAcid_1527286288784.sql make sure it has    * ALTER TABLE default.tflat SET TBLPROPERTIES ('transactional'='true');    * convertToMM_1527286288784.sql make sure it has    * ALTER TABLE default.tflattext SET TBLPROPERTIES ('transactional'='true' 'transactional_properties'='insert_only');    *  */
Hive,WITHOUT_CLASSIFICATION,//  if o is zero easy. 
Hive,WITHOUT_CLASSIFICATION,//  Reuse the same type for all. Only Ivy can return more than one probably all jars. 
Hive,WITHOUT_CLASSIFICATION,//  assert mapJoinPos == 0; 
Hive,WITHOUT_CLASSIFICATION,//  Fail some inserts so that we have records in TXN_COMPONENTS 
Hive,WITHOUT_CLASSIFICATION,//  rcfile read 
Hive,WITHOUT_CLASSIFICATION,//  Test string column to CHAR literal comparison 
Hive,WITHOUT_CLASSIFICATION,/*      * @return The multi-set count for the lookup key.      */
Hive,WITHOUT_CLASSIFICATION,//  Credentials can change across DAGs. Ideally construct only once per DAG. 
Hive,WITHOUT_CLASSIFICATION,//  initialize load path 
Hive,WITHOUT_CLASSIFICATION,//  NEW_PART 
Hive,WITHOUT_CLASSIFICATION,//  Some Hive features depends on several MR configuration legacy build and add   these configuration to JobConf here. 
Hive,WITHOUT_CLASSIFICATION,//  Note: for collapse == false this just sets keysSame. 
Hive,WITHOUT_CLASSIFICATION,//   int length = output.getLength() - offset; 
Hive,WITHOUT_CLASSIFICATION,//  This column is not included 
Hive,WITHOUT_CLASSIFICATION,//  Fail compaction so that we have failed records in COMPLETED_COMPACTIONS 
Hive,WITHOUT_CLASSIFICATION,//  Note: for now we don't have to setError here caller will setError if we throw. 
Hive,WITHOUT_CLASSIFICATION,//  resultDec = dec.scaleByPowerOfTen(2);   Assert.assertEquals( 
Hive,WITHOUT_CLASSIFICATION,//  Set up the hook that will disallow creating non-whitelisted UDFs anywhere in the plan.   We are not using a specific hook for GenericUDFBridge - that doesn't work in MiniLlap   because the daemon is embedded so the client also gets this hook and Kryo is brittle. 
Hive,WITHOUT_CLASSIFICATION,/*      * Do careful maintenance of the outputColVector.noNulls flag.      */
Hive,WITHOUT_CLASSIFICATION,/*    * Checks if the value contains any of the PASSWORD_STRINGS and if yes   * return true    */
Hive,WITHOUT_CLASSIFICATION,// java calendar index starting at 1. 
Hive,WITHOUT_CLASSIFICATION,//  ignore error 
Hive,WITHOUT_CLASSIFICATION,//  reset conf vars 
Hive,WITHOUT_CLASSIFICATION,//  total characters = 4; byte length = 6 
Hive,WITHOUT_CLASSIFICATION,//  if we can not have correct table stats then both the table stats and column stats are not useful. 
Hive,WITHOUT_CLASSIFICATION,/*      * Returns absolute offset of the match      */
Hive,WITHOUT_CLASSIFICATION,//  take top-k closest neighbors and compute the bias corrected cardinality 
Hive,WITHOUT_CLASSIFICATION,//  whether to optimize union followed by select followed by filesink   It creates sub-directories in the final output so should not be turned on in systems 
Hive,WITHOUT_CLASSIFICATION,//  Find all the valid cookies associated with the request. 
Hive,WITHOUT_CLASSIFICATION,//  unable to parse the connect command 
Hive,WITHOUT_CLASSIFICATION,//  1) We extract the conditions that can be useful 
Hive,WITHOUT_CLASSIFICATION,//  Now go back to bed until it's time to do this again 
Hive,WITHOUT_CLASSIFICATION,//  Not using OP stats and this is the first sink in the path meaning that   we should use TS stats to infer parallelism 
Hive,WITHOUT_CLASSIFICATION,//  repeating 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getTimestamp(int)    */
Hive,WITHOUT_CLASSIFICATION,//  Cartesian product of our ranges to the child ranges 
Hive,WITHOUT_CLASSIFICATION,//  Temp macros are not allowed to have qualified names. 
Hive,WITHOUT_CLASSIFICATION,//  To compare among potentially multiple matches 
Hive,WITHOUT_CLASSIFICATION,//  Insert one more row - this should trigger hive.compactor.delta.pct.threshold to be reached for ttp2 
Hive,WITHOUT_CLASSIFICATION,//  this function will merge csOld into csNew. 
Hive,WITHOUT_CLASSIFICATION,//  BloomFilter: object(BitSet: object(data: long[]) numBits: int numHashFunctions: int) 
Hive,WITHOUT_CLASSIFICATION,//  FUNCTION_CAT   FUNCTION_SCHEM   FUNCTION_NAME   REMARKS 
Hive,WITHOUT_CLASSIFICATION,//  Throw an exception if the table/partition is bucketed on one of the columns 
Hive,WITHOUT_CLASSIFICATION,/*    * this happens either when the input file of the big table is changed or in   * closeop. It needs to fetch all the left data from the small tables and try   * to join them.    */
Hive,WITHOUT_CLASSIFICATION,//  Ok to run CBO. 
Hive,WITHOUT_CLASSIFICATION,//  In case there are multiple columns referenced to the same column name we won't 
Hive,WITHOUT_CLASSIFICATION,//  No parsing necessary -- the end is the parent's end.   Move past parent field separator. 
Hive,WITHOUT_CLASSIFICATION,/*    * returns number of lines in the printed throwable stack trace.    */
Hive,WITHOUT_CLASSIFICATION,//  A single source can process multiple columns and will send an event for each of them. 
Hive,WITHOUT_CLASSIFICATION,//  A match was found so add the clause to the corresponding list 
Hive,WITHOUT_CLASSIFICATION,//  projections are handled by using generate not "as" on the Load 
Hive,WITHOUT_CLASSIFICATION,//  Operators that belong to each work 
Hive,WITHOUT_CLASSIFICATION,//  restore the previous properties for framework name RM address etc. 
Hive,WITHOUT_CLASSIFICATION,//  filters 
Hive,WITHOUT_CLASSIFICATION,//  Tracks containerIds and taskAttemptIds so can be kept independent of the running DAG. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setNClob(java.lang.String java.io.Reader   * long)    */
Hive,WITHOUT_CLASSIFICATION,//  Cleanup baseFsDir since it can be shared across tests. 
Hive,WITHOUT_CLASSIFICATION,//  SHOW LOCKS t14 PARTITION ds='today' 
Hive,WITHOUT_CLASSIFICATION,//  cant happen 
Hive,WITHOUT_CLASSIFICATION,//  get the maxLen 
Hive,WITHOUT_CLASSIFICATION,//  used to hook up unions 
Hive,WITHOUT_CLASSIFICATION,//  utc -> default 
Hive,WITHOUT_CLASSIFICATION,//  explictly ignoring as Getter visibility is ANY for auto-json serialization of Trigger based on getters 
Hive,WITHOUT_CLASSIFICATION,//  Try to deserialize using SerDe class our Writable row objects created by SerializeWrite. 
Hive,WITHOUT_CLASSIFICATION,//  Joda pattern matching expects fractional seconds length to match   the number of 'S' in the pattern. So if you want to match .1 .12 .123   you need 3 different patterns with .S .SS .SSS 
Hive,WITHOUT_CLASSIFICATION,//  The first bounds check requires at least one more byte beyond for 2nd int (hence >=).   Parse the first byte of a vint/vlong to determine the number of bytes. 
Hive,WITHOUT_CLASSIFICATION,//  Conf.get takes care of parameter replacement iterator.value does not. 
Hive,WITHOUT_CLASSIFICATION,//  create table and load kv1.txt 
Hive,WITHOUT_CLASSIFICATION,//  Used to determine if cleaner thread is already running 
Hive,WITHOUT_CLASSIFICATION,//  table aliased (select a.* for example) 
Hive,WITHOUT_CLASSIFICATION,//  try again 
Hive,WITHOUT_CLASSIFICATION,// Read the record with **different** record reader ID and **evolved** schema 
Hive,WITHOUT_CLASSIFICATION,//  SessionState.get().setCommandType(HiveOperation.EXPLAIN); 
Hive,WITHOUT_CLASSIFICATION,//  verify that unpartitioned table rename succeeded. 
Hive,WITHOUT_CLASSIFICATION,//  execute set command 
Hive,WITHOUT_CLASSIFICATION,//  Add credential provider password to the child process's environment 
Hive,WITHOUT_CLASSIFICATION,// Scalar queries should expect value/count less than 1 
Hive,WITHOUT_CLASSIFICATION,//  Expect query to return an error state 
Hive,WITHOUT_CLASSIFICATION,//  LOG.info("VectorKeySeriesMultiSerialized processBatch size " + currentBatchSize + " numCols " + batch.numCols + " selectedInUse " + batch.selectedInUse); 
Hive,WITHOUT_CLASSIFICATION,// ignore this - multiple clients may be trying to create the same partition  AddPartitionDesc has ifExists flag but it's not propagated to   HMSHnalder.add_partitions_core() and so it throws... 
Hive,WITHOUT_CLASSIFICATION,//  If we have some sort of expression tree try SQL filter pushdown. 
Hive,WITHOUT_CLASSIFICATION,//  Tell ReduceRecordSource to flush last record as this is a reduce   side SMB 
Hive,WITHOUT_CLASSIFICATION,//  Time based counters. If DAG is done already don't update these counters. 
Hive,WITHOUT_CLASSIFICATION,// again 1st split is for base/ 
Hive,WITHOUT_CLASSIFICATION,//  No transactions - just the header row 
Hive,WITHOUT_CLASSIFICATION,// found delete events - this 'location' needs compacting 
Hive,WITHOUT_CLASSIFICATION,//  Determine if this (or previous) is the last slice we need to read for this split. 
Hive,WITHOUT_CLASSIFICATION,//  Get int view of the buffer 
Hive,WITHOUT_CLASSIFICATION,//  From https://msdn.microsoft.com/en-us/library/ms190476.aspx   e1 + e2   Precision: max(s1 s2) + max(p1-s1 p2-s2) + 1   Scale: max(s1 s2) 
Hive,WITHOUT_CLASSIFICATION,//  total characters = 17; byte length = 30 
Hive,WITHOUT_CLASSIFICATION,//  2nd level GB: create a GB (col0 col1 count(c)) for each branch 
Hive,WITHOUT_CLASSIFICATION,/*  * Helper class to generate mocked response.  */
Hive,WITHOUT_CLASSIFICATION,//  The primary's nextRecord is the next value to return 
Hive,WITHOUT_CLASSIFICATION,//  When processing dynamic partitioned hash joins some of the small tables may not get processed   before the mapjoin's parents are removed during GenTezWork.process(). This is to keep 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) FunctionType  */
Hive,WITHOUT_CLASSIFICATION,//  DB topic - Alan. 
Hive,WITHOUT_CLASSIFICATION,//  figure out the newLocalOrdinal relative to the newInput. 
Hive,WITHOUT_CLASSIFICATION,//  This should never happen as we just added the lock id 
Hive,WITHOUT_CLASSIFICATION,// Check if hive returns results correctly 
Hive,WITHOUT_CLASSIFICATION,//  Create STRUCT clause 
Hive,WITHOUT_CLASSIFICATION,//  Plan maybe null if Driver.close is called in another thread for the same Driver object 
Hive,WITHOUT_CLASSIFICATION,//  no column attributes provided - create list of null attributes. 
Hive,WITHOUT_CLASSIFICATION,//  This means that in UPDATE T SET x = _something_   _something_ can be whatever is supported in SELECT _something_ 
Hive,WITHOUT_CLASSIFICATION,//  check that src exists and also checks permissions necessary rename src to dest 
Hive,WITHOUT_CLASSIFICATION,//  This should fail once it finds out the threshold has been reached 
Hive,WITHOUT_CLASSIFICATION,//  Throw in some canFinish variations just for fun. 
Hive,WITHOUT_CLASSIFICATION,// now copy over the data where isNull[index] is false 
Hive,WITHOUT_CLASSIFICATION,//  Byte.MIN_VALUE 
Hive,WITHOUT_CLASSIFICATION,//  First start HS2 with high message size limit. This should allow connections 
Hive,WITHOUT_CLASSIFICATION,//  this the data copy 
Hive,WITHOUT_CLASSIFICATION,//  SettableTreeReader so that we can avoid this check. 
Hive,WITHOUT_CLASSIFICATION,//  should throw 
Hive,WITHOUT_CLASSIFICATION,/*  tasks finished but some failed  */
Hive,WITHOUT_CLASSIFICATION,//  We try to infer a common primitive category 
Hive,WITHOUT_CLASSIFICATION,//  Types are different we need to check whether we can convert them to 
Hive,WITHOUT_CLASSIFICATION,//  with repeating 
Hive,WITHOUT_CLASSIFICATION,//  subExpr is the list containing generated IN clauses as a result of this optimization. 
Hive,WITHOUT_CLASSIFICATION,//  decimal_64 column vectors gets the same weight as long column vectors 
Hive,WITHOUT_CLASSIFICATION,//  Not failing the job due to a failure constructing the log url 
Hive,WITHOUT_CLASSIFICATION,//  different from sql compat mode 
Hive,WITHOUT_CLASSIFICATION,//  Hold the aggregation results for each row in the partition   Number of rows processed in the partition. 
Hive,WITHOUT_CLASSIFICATION,/*  the buffer has n+sync bytes  */
Hive,WITHOUT_CLASSIFICATION,//  INFO_TYPE 
Hive,WITHOUT_CLASSIFICATION,//  ResultSet serialization settings 
Hive,WITHOUT_CLASSIFICATION,//  This method is necessary to synchronize lazy-creation to the timers. 
Hive,WITHOUT_CLASSIFICATION,//  Ignore priority. 
Hive,WITHOUT_CLASSIFICATION,//  Here we build an aux structure that is used to verify that the foreign key that is declared   is actually referencing a valid primary key or unique key. We also check that the types of 
Hive,WITHOUT_CLASSIFICATION,//  should only be one object 
Hive,WITHOUT_CLASSIFICATION,//  make array with QBJoinTree : outer most(0) --> inner most(n) 
Hive,WITHOUT_CLASSIFICATION,//  cannot be estimated. sample it at runtime. 
Hive,WITHOUT_CLASSIFICATION,//  The Write Ids returned for the transaction batch is also sequential 
Hive,WITHOUT_CLASSIFICATION,//  total rows to generate   # of rows to cache at most   percentile of extra rows to generate by a different thread 
Hive,WITHOUT_CLASSIFICATION,//  4. Finally decompress data map per RG and return to caller. 
Hive,WITHOUT_CLASSIFICATION,//  --- From here on out we choose whether we *want* to run in llap 
Hive,WITHOUT_CLASSIFICATION,//  since we only have single distinct call 
Hive,WITHOUT_CLASSIFICATION,//  k1 equals k2 
Hive,WITHOUT_CLASSIFICATION,//  .0 returned if the fractional part not set 
Hive,WITHOUT_CLASSIFICATION,//  See if there are additional knownFragments. If there are more fragments came in   after this cleanup was scheduled and there's nothing to be done. 
Hive,WITHOUT_CLASSIFICATION,//  If the query here is an INSERT_INTO and the target is an immutable table   verify that our destination is empty before proceeding 
Hive,WITHOUT_CLASSIFICATION,//  set setting read column ids with an empty list 
Hive,WITHOUT_CLASSIFICATION,//  read from dumpfile and instantiate self 
Hive,WITHOUT_CLASSIFICATION,//  check that all correlated refs in the filter condition are 
Hive,WITHOUT_CLASSIFICATION,//  Calculate number of different entries and evaluate 
Hive,WITHOUT_CLASSIFICATION,//  Alter table can change the type of partition key now.   So check the column name only. 
Hive,WITHOUT_CLASSIFICATION,//  We rely on the fact that poll() checks interrupt even when there's something in the queue.   If the structure is replaced with smth that doesn't we MUST check interrupt here because   Hive operators rely on recordreader to handle task interruption and unlike most RRs we 
Hive,WITHOUT_CLASSIFICATION,//  for multi-insert queries. Thus nodeOfInterest is the FROM clause 
Hive,WITHOUT_CLASSIFICATION,//  4. Read the null terminator. 
Hive,WITHOUT_CLASSIFICATION,//  test when third argument has nulls 
Hive,WITHOUT_CLASSIFICATION,//  Skip writing tags when feeding into mapjoin hashtable   Whether this RS can forward records directly instead of shuffling/sorting 
Hive,WITHOUT_CLASSIFICATION,//  An array of hash multi-set results so we can do lookups on the whole batch before output result 
Hive,WITHOUT_CLASSIFICATION,//  find the root of all custom paths from custom pattern. The root is the   largest prefix in input pattern string that doesn't match customPathPattern 
Hive,WITHOUT_CLASSIFICATION,//  if s is shorter than the required pattern 
Hive,WITHOUT_CLASSIFICATION,//  The session is taken out of the pool but is waiting for registration. 
Hive,WITHOUT_CLASSIFICATION,//  last work we've processed (in order to hook it up to the current 
Hive,WITHOUT_CLASSIFICATION,//  Test various set methods and copy constructors. 
Hive,WITHOUT_CLASSIFICATION,//  YARN property in Spark on YARN mode. 
Hive,WITHOUT_CLASSIFICATION,//  A task kill while the request is still in PENDING state means the request should be retried. 
Hive,WITHOUT_CLASSIFICATION,//  build the exprNodeFuncDesc with recursively built children. 
Hive,WITHOUT_CLASSIFICATION,//  Sum all non-null long column values for avg; maintain isGroupResultNull; after last row of   last group batch compute the group avg when sum is non-null. 
Hive,WITHOUT_CLASSIFICATION,//  allocate a little extra space to limit need to re-allocate 
Hive,WITHOUT_CLASSIFICATION,//  SERIALIZER_CLASS 
Hive,WITHOUT_CLASSIFICATION,//  find the absolute minimum transaction 
Hive,WITHOUT_CLASSIFICATION,//  1 NULL   NULL NULL 
Hive,WITHOUT_CLASSIFICATION,//  increment cursor for elements per 'IN'/'NOT IN' clause. 
Hive,WITHOUT_CLASSIFICATION,//  The passed argument matches somewhat closely with an accepted argument 
Hive,WITHOUT_CLASSIFICATION,/*    * The following members have context information for the current partition file being read.    */
Hive,WITHOUT_CLASSIFICATION,//  A row format terminated by clause 
Hive,WITHOUT_CLASSIFICATION,//  --property-file <file> 
Hive,WITHOUT_CLASSIFICATION,//  incorrect precision: expected:<1.2[]> but was:<1.2[0]> 
Hive,WITHOUT_CLASSIFICATION,//  get the root operator 
Hive,WITHOUT_CLASSIFICATION,/*    * If no filtering has been applied yet selectedInUse is false   * meaning that all rows qualify. If it is true then the selected[] array   * records the offsets of qualifying rows.    */
Hive,WITHOUT_CLASSIFICATION,//  Created by hint skip it 
Hive,WITHOUT_CLASSIFICATION,//  We are composing a query that returns a single row if an update happened after 
Hive,WITHOUT_CLASSIFICATION,//  Dimension 
Hive,WITHOUT_CLASSIFICATION,//  Includes the columns that have no data 
Hive,WITHOUT_CLASSIFICATION,//  as it is always using the ROW__ID column. 
Hive,WITHOUT_CLASSIFICATION,/*  Keeps track of vertices from which events are expected  */
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getBytes(java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  create connection as user1 
Hive,WITHOUT_CLASSIFICATION,//  is the binary data. 
Hive,WITHOUT_CLASSIFICATION,//  Return nulls for conversion operators 
Hive,WITHOUT_CLASSIFICATION,//  We cannot backtrack the expression we bail out 
Hive,WITHOUT_CLASSIFICATION,//  Can't infer a type. 
Hive,WITHOUT_CLASSIFICATION,//  measured in nanoseconds from the epoch. 
Hive,WITHOUT_CLASSIFICATION,//  TOK_SKEWED_LOCATIONS 
Hive,WITHOUT_CLASSIFICATION,//  create a batch with one string ("Bytes") column 
Hive,WITHOUT_CLASSIFICATION,//  did we find the file/dir itself? 
Hive,WITHOUT_CLASSIFICATION,//  Either there was nothing which could be pushed down (size = 0)   there were complex predicates which we don't support yet.   Currently supported are one of the form:   1. key < 20                        (size = 1)   2. key = 20                        (size = 1)   3. key < 20 and key > 10           (size = 2)   Add to residual 
Hive,WITHOUT_CLASSIFICATION,// aggExpr is part of distinct key 
Hive,WITHOUT_CLASSIFICATION,//  Support for dynamic partitions can be added later 
Hive,WITHOUT_CLASSIFICATION,//  Now do the operation with Java BigDecimal 
Hive,WITHOUT_CLASSIFICATION,//  If optimize hive.optimize.bucketmapjoin.sortedmerge is set add both 
Hive,WITHOUT_CLASSIFICATION,//  Semi join specific. 
Hive,WITHOUT_CLASSIFICATION,//  Reset grace hashjoin context so that there is no state maintained when operator/work is 
Hive,WITHOUT_CLASSIFICATION,//  if the jobtracker signalled that the threshold is not exceeded 
Hive,WITHOUT_CLASSIFICATION,//  check if they are operating on the same partition if not move on. 
Hive,WITHOUT_CLASSIFICATION,//  Flush final partial batch. 
Hive,WITHOUT_CLASSIFICATION,//  check for sub-struct validity 
Hive,WITHOUT_CLASSIFICATION,//  Drop the tables when we're done. This makes the test work inside an IDE 
Hive,WITHOUT_CLASSIFICATION,//  FULL STOP "." (1 byte) 
Hive,WITHOUT_CLASSIFICATION,// create 2 partitions 
Hive,WITHOUT_CLASSIFICATION,//  this can only be possible if there is merge work followed by the union 
Hive,WITHOUT_CLASSIFICATION,//  No problem use a new name 
Hive,WITHOUT_CLASSIFICATION,//  last character ends a token?   if there are quotes all the text between the quotes   is considered a single token (this can happen for   timestamp with local time-zone) 
Hive,WITHOUT_CLASSIFICATION,//  Input: do Java/Writable conversion if needed 
Hive,WITHOUT_CLASSIFICATION,//  Right input positions are shifted by newLeftFieldCount. 
Hive,WITHOUT_CLASSIFICATION,//  Value for the flag 
Hive,WITHOUT_CLASSIFICATION,//  APPLY_DISTINCT 
Hive,WITHOUT_CLASSIFICATION,//  In case the expression is a regex COL.   This can only happen without AS clause   We don't allow this for ExprResolver - the Group By case 
Hive,WITHOUT_CLASSIFICATION,//  fileread writes to the writer which writes to orcWriter which writes to cacheWriter 
Hive,WITHOUT_CLASSIFICATION,//  uses sampling which means it's not bucketed 
Hive,WITHOUT_CLASSIFICATION,//  At this point everything that can be consumed from AppStatusBuilder has been consumed. 
Hive,WITHOUT_CLASSIFICATION,/*    * The absolute offset to the beginning of the key within the WriteBuffers.    */
Hive,WITHOUT_CLASSIFICATION,//  no table could be the big table; there is no need to convert 
Hive,WITHOUT_CLASSIFICATION,//  Filter long/double. 
Hive,WITHOUT_CLASSIFICATION,//  File ownership/permission checks should be done on the new table path. 
Hive,WITHOUT_CLASSIFICATION,// Read the record with **different** record reader ID 
Hive,WITHOUT_CLASSIFICATION,//  execute in process 
Hive,WITHOUT_CLASSIFICATION,//  the last char is an escape char. read the actual char 
Hive,WITHOUT_CLASSIFICATION,//  referenced later. 
Hive,WITHOUT_CLASSIFICATION,//  getAllWork returns a topologically sorted list which we use to make   sure that vertices are created before they are used in edges. 
Hive,WITHOUT_CLASSIFICATION,//  debug instrumenter - useful in finding which fns get called and how often 
Hive,WITHOUT_CLASSIFICATION,//  3 (test #readFully(1)): 
Hive,WITHOUT_CLASSIFICATION,//  First check temp tables 
Hive,WITHOUT_CLASSIFICATION,//  Make sure we qualify the name from the outset so there's no ambiguity. 
Hive,WITHOUT_CLASSIFICATION,//  it is a column family   primitive type for Map<Key Value> can be stored in binary format. Pass in the   qualifier prefix to cherry pick the qualifiers that match the prefix instead of picking   up everything 
Hive,WITHOUT_CLASSIFICATION,/*  partitioned table + query has only pruning filters  */
Hive,WITHOUT_CLASSIFICATION,//  index into a list 
Hive,WITHOUT_CLASSIFICATION,//  Container affinity can be implemented as Host affinity for LLAP. Not required until   1:1 edges are used in Hive. 
Hive,WITHOUT_CLASSIFICATION,//  Check parameter set validity as a public method. 
Hive,WITHOUT_CLASSIFICATION,//  if we didn't have predicate pushdown read everything 
Hive,WITHOUT_CLASSIFICATION,//  load property file 
Hive,WITHOUT_CLASSIFICATION,//  String comparison is good enough since its of form date=yyyy-MM-dd 
Hive,WITHOUT_CLASSIFICATION,//  Main path - found it incRef-ed it. 
Hive,WITHOUT_CLASSIFICATION,//  such as "abc\%de%" 
Hive,WITHOUT_CLASSIFICATION,//  if we reached this condition we had replication state on record for the   object but its replacement has no state. Disallow replacement 
Hive,WITHOUT_CLASSIFICATION,//  sets the env variable HADOOP_CREDSTORE_PASSWORD to value defined by HADOOP_CREDSTORE_PASSWORD   sets hadoop.security.credential.provider.path property to simulate default credential 
Hive,WITHOUT_CLASSIFICATION,/*    * Setup our inner join specific members.    */
Hive,WITHOUT_CLASSIFICATION,//  We are going to fail so it is ok to do expensive stuff. Ranges are broken play it safe. 
Hive,WITHOUT_CLASSIFICATION,//                total merge cost 
Hive,WITHOUT_CLASSIFICATION,//  We've seen this already. 
Hive,WITHOUT_CLASSIFICATION,//  the fallback from failed SQL to JDO is not possible. 
Hive,WITHOUT_CLASSIFICATION,//  Some joins might be null (see processNode for LeafNode) clean them up. 
Hive,WITHOUT_CLASSIFICATION,//  We do not modify the header here; the caller will use this space. 
Hive,WITHOUT_CLASSIFICATION,//  Skip leading zeroes in word2. 
Hive,WITHOUT_CLASSIFICATION,//  Success 
Hive,WITHOUT_CLASSIFICATION,//  and the new join rel 
Hive,WITHOUT_CLASSIFICATION,//  Note: this path should be specific to concatenate; never executed in a select query.   modify the existing move task as it is already in the candidate running tasks 
Hive,WITHOUT_CLASSIFICATION,// /////// -------- UTILS ------- ///////// 
Hive,WITHOUT_CLASSIFICATION,//  Spill previously loaded tables to make more room 
Hive,WITHOUT_CLASSIFICATION,//  We could not heartbeat the lock i.e. the operation has finished   hence we interrupt this work 
Hive,WITHOUT_CLASSIFICATION,//  These will be handled by the output to the table instead. 
Hive,WITHOUT_CLASSIFICATION,//  Copy the tezSessionState from the old CliSessionState. 
Hive,WITHOUT_CLASSIFICATION,//  closing the underlying ByteStream should have no effect the data should still be   accessible 
Hive,WITHOUT_CLASSIFICATION,//  Fetch the first group for all small table aliases. 
Hive,WITHOUT_CLASSIFICATION,//  stores mappings from local to hdfs location for all resource types. 
Hive,WITHOUT_CLASSIFICATION,//  DESERIALIZER_CLASS 
Hive,WITHOUT_CLASSIFICATION,//  store the type for later retrieval 
Hive,WITHOUT_CLASSIFICATION,//  If the operator is AND we need to determine if any of the children are   final candidates. 
Hive,WITHOUT_CLASSIFICATION,//  Remove unnecessary expressions 
Hive,WITHOUT_CLASSIFICATION,//  some debug information 
Hive,WITHOUT_CLASSIFICATION,//  get parent schema 
Hive,WITHOUT_CLASSIFICATION,//  string 
Hive,WITHOUT_CLASSIFICATION,//  and must have locations within the table directory. 
Hive,WITHOUT_CLASSIFICATION,//  Not much I can do about it. 
Hive,WITHOUT_CLASSIFICATION,//  the max value of number of zeroes for 64 bit hash can be encoded using   only 6 bits. So we will disable bit packing for any values >6 
Hive,WITHOUT_CLASSIFICATION,//  Will be true if there is a non-null entry 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:SourceStateUpdatedRequestProto) 
Hive,WITHOUT_CLASSIFICATION,//  the structure inside CTE is like this   TOK_CTE   TOK_SUBQUERY   sq1 (may refer to sq2)   ...   TOK_SUBQUERY   sq2 
Hive,WITHOUT_CLASSIFICATION,//  3.1 Obtain UDAF name 
Hive,WITHOUT_CLASSIFICATION,//  preempt only on specific hosts if no preemptions already exist on those. 
Hive,WITHOUT_CLASSIFICATION,//  PARTITION_LIST 
Hive,WITHOUT_CLASSIFICATION,//  If there is no grouping key and no row came to this operator 
Hive,WITHOUT_CLASSIFICATION,//  PARENT_CATALOG_NAME 
Hive,WITHOUT_CLASSIFICATION,//  Throw away middle and lowest words. 
Hive,WITHOUT_CLASSIFICATION,//  takes place during optimization 
Hive,WITHOUT_CLASSIFICATION,//  Bootstrap load which should also replicate the aborted write ids on both tables. 
Hive,WITHOUT_CLASSIFICATION,//  Default separators are 1-indexed (instead of 0-indexed) thus the separator at offset 1 is   (byte) 2   The separator for the hive row is \x02 for the row Id struct \x03 and the maps \x04 and 
Hive,WITHOUT_CLASSIFICATION,//  optional .QueryIdentifierProto query_identifier = 1; 
Hive,WITHOUT_CLASSIFICATION,//  Friday 30th August 1985 02:47:02 AM 
Hive,WITHOUT_CLASSIFICATION,//  Read through all values. 
Hive,WITHOUT_CLASSIFICATION,//  reset everything 
Hive,WITHOUT_CLASSIFICATION,// 3. populate the load file work so that ColumnStatsTask can work 
Hive,WITHOUT_CLASSIFICATION,//  update join statistics 
Hive,WITHOUT_CLASSIFICATION,//  DP/LB 
Hive,WITHOUT_CLASSIFICATION,//  If an operator wants to do some work at the end of a group 
Hive,WITHOUT_CLASSIFICATION,//  there should be only 1 dummy object in the RowContainer 
Hive,WITHOUT_CLASSIFICATION,//  Combined: last_access<=3000 and (Owner="Tester" or param1="param2") 
Hive,WITHOUT_CLASSIFICATION,//  Skip the partitions in progress and the ones for which stats update is disabled.   We could filter the skipped partititons out as part of the initial names query 
Hive,WITHOUT_CLASSIFICATION,//  Input file has header or footer cannot be splitted. 
Hive,WITHOUT_CLASSIFICATION,//  Check that the output is done 
Hive,WITHOUT_CLASSIFICATION,//  we create FILTER (sq_count_check(count()) > 0) instead of PROJECT   because RelFieldTrimmer ends up getting rid of Project 
Hive,WITHOUT_CLASSIFICATION,//  read operation mode 
Hive,WITHOUT_CLASSIFICATION,//  Change if we could not retrieve for all partitions 
Hive,WITHOUT_CLASSIFICATION,//  FILE_IDS 
Hive,WITHOUT_CLASSIFICATION,//  parse the response   message   = [authzid] UTF8NUL authcid UTF8NUL passwd' 
Hive,WITHOUT_CLASSIFICATION,//  disconnect the connection to union work and connect to merge work 
Hive,WITHOUT_CLASSIFICATION,//  Convert the search condition into a restriction on the HBase scan 
Hive,WITHOUT_CLASSIFICATION,//  should be merge join 
Hive,WITHOUT_CLASSIFICATION,//  c6:map<intstring> 
Hive,WITHOUT_CLASSIFICATION,//  For the second one explicitly set a location to make sure it ends up in the specified place. 
Hive,WITHOUT_CLASSIFICATION,//  Array of Byte 
Hive,WITHOUT_CLASSIFICATION,// now make the select produce <regular columns><dynamic partition columns> with 
Hive,WITHOUT_CLASSIFICATION,// NOP 
Hive,WITHOUT_CLASSIFICATION,//  Test that opening a JDBC connection to a non-existent database throws a HiveSQLException 
Hive,WITHOUT_CLASSIFICATION,//  First allocation of write id should add the table to the next_write_id meta table   The initial value for write id should be 1 and hence we add 1 with number of write ids   allocated here 
Hive,WITHOUT_CLASSIFICATION,//  x events to insert last repl ID: replDumpId+3x+y 
Hive,WITHOUT_CLASSIFICATION,//  since new statistics is derived from all relations involved in 
Hive,WITHOUT_CLASSIFICATION,//  Force locality 
Hive,WITHOUT_CLASSIFICATION,//  Add more complex types. 
Hive,WITHOUT_CLASSIFICATION,//  set the stats publishing/aggregating key prefix   the same as directory name. The directory name   can be changed in the optimizer but the key should not be changed 
Hive,WITHOUT_CLASSIFICATION,//  A under-flows if nn is large. 
Hive,WITHOUT_CLASSIFICATION,//  change it to choose the appropriate file system 
Hive,WITHOUT_CLASSIFICATION,//  A null result from AccumuloRangeGenerator is all ranges 
Hive,WITHOUT_CLASSIFICATION,//  there is no join-value or join-key has all null elements 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hadoop.hive.ql.optimizer.Transform#transform   * (org.apache.hadoop.hive.ql.parse.ParseContext)    */
Hive,WITHOUT_CLASSIFICATION,//  Since we have to create space for 1 if we find an expired node we will remove it & 
Hive,WITHOUT_CLASSIFICATION,//  Useful when the type of column vector has not be determined yet. 
Hive,WITHOUT_CLASSIFICATION,//  This parameter is left for compatibility when reading existing configs to be removed in Druid 0.12. 
Hive,WITHOUT_CLASSIFICATION,//  Note: query priorities if we add them might go here. 
Hive,WITHOUT_CLASSIFICATION,//  It seems these two operators can be merged.   Check that plan meets some preconditions before doing it.   In particular in the presence of map joins in the upstream plan:   - we cannot exceed the noconditional task size and   - if we already merged the big table we cannot merge the broadcast 
Hive,WITHOUT_CLASSIFICATION,// When init(true) combine with genResolvedParseTree it will generate Resolved Parse tree from syntax tree  ReadEntity created under these conditions should be all relevant to the syntax tree even the ones without parents  set mergeIsDirect to true here. 
Hive,WITHOUT_CLASSIFICATION,// DecimalFormat longFormatter = new DecimalFormat("######"); 
Hive,WITHOUT_CLASSIFICATION,//  read once to gain access to key and value objects 
Hive,WITHOUT_CLASSIFICATION,//  check the contents of second row 
Hive,WITHOUT_CLASSIFICATION,//  Trigger bootstrap dump which just creates table t1 and other tables (t2 t3) and constraints not loaded. 
Hive,WITHOUT_CLASSIFICATION,// alter table commands require table ownership   There should not be output object but just in case the table is incorrectly added 
Hive,WITHOUT_CLASSIFICATION,//  add a key for reduce sink 
Hive,WITHOUT_CLASSIFICATION,//  Evaluate the aggregation over one of the group's batches. 
Hive,WITHOUT_CLASSIFICATION,//  Intentionally do nothing 
Hive,WITHOUT_CLASSIFICATION,//  idempotent case and just return. 
Hive,WITHOUT_CLASSIFICATION,/*        * Clear out any rows in the batch from previous partition since we are going to change       * the repeating partition column values.        */
Hive,WITHOUT_CLASSIFICATION,//  TODO: See comments under blacklistNode. 
Hive,WITHOUT_CLASSIFICATION,//  Ensures maps can be deserialized when avro.java.string=String.   See http://stackoverflow.com/a/19868919/312944 for why that might be used. 
Hive,WITHOUT_CLASSIFICATION,//  HS2 
Hive,WITHOUT_CLASSIFICATION,// sorting makes tests easier to write since file names and ROW__IDs depend on statementId  so this makes (file name -> data) mapping stable 
Hive,WITHOUT_CLASSIFICATION,// batching is not enabled. Try to add all the partitions in one call 
Hive,WITHOUT_CLASSIFICATION,//  for non-native table property storage_handler should be retained 
Hive,WITHOUT_CLASSIFICATION,//  The length of the scratch buffer that needs to be passed to toBytes toFormatBytes 
Hive,WITHOUT_CLASSIFICATION,//  We will inherit the name and status from the plan we are replacing. 
Hive,WITHOUT_CLASSIFICATION,//  NEVER call this function without first calling heartbeat(long long) 
Hive,WITHOUT_CLASSIFICATION,//  Look for tables with empty pattern 
Hive,WITHOUT_CLASSIFICATION,// see commitTxn() for more info on this inequality 
Hive,WITHOUT_CLASSIFICATION,//  Table dropped after "repl dump" 
Hive,WITHOUT_CLASSIFICATION,//  If db cache is not yet prewarmed add this to a set which the prewarm thread can check   so that the prewarm thread does not add it back 
Hive,WITHOUT_CLASSIFICATION,//  FUTURE: Can we reuse this conversion? 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getTime(java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,// If current split is from the same file as preceding split and the preceding split has footerbuffer 
Hive,WITHOUT_CLASSIFICATION,/*          * SubQuery was only condition in where clause          */
Hive,WITHOUT_CLASSIFICATION,//  no filter no projection. no need to stage 
Hive,WITHOUT_CLASSIFICATION,//  Can make this configurable. 
Hive,WITHOUT_CLASSIFICATION,//  The start of the split was in the middle of the previous slice. 
Hive,WITHOUT_CLASSIFICATION,//  2. Create a new union operator 
Hive,WITHOUT_CLASSIFICATION,//  Set different uri as it is one of the criteria deciding whether to return the same client or not   URIs are checked for string equivalence even spaces make them different 
Hive,WITHOUT_CLASSIFICATION,//  get the hashtable file and path 
Hive,WITHOUT_CLASSIFICATION,//  get conf from user payload 
Hive,WITHOUT_CLASSIFICATION,//  to be used please do so 
Hive,WITHOUT_CLASSIFICATION,//  replace the default input & output file format with those found in 
Hive,WITHOUT_CLASSIFICATION,//  The number of single value rows that were generated in the big table batch. 
Hive,WITHOUT_CLASSIFICATION,//  We hit the end after getting optional integer and optional dot and optional blank padding. 
Hive,WITHOUT_CLASSIFICATION,//  Positive number. 
Hive,WITHOUT_CLASSIFICATION,/*  For a given row put it into proper partition based on its hash value.   * When memory threshold is reached the biggest hash table in memory will be spilled to disk.   * If the hash table of a specific partition is already on disk all later rows will be put into   * a row container for later use.    */
Hive,WITHOUT_CLASSIFICATION,//  just creating orc reader is going to do sanity checks to make sure its valid ORC file 
Hive,WITHOUT_CLASSIFICATION,//  Retrieve primary key constraints (cannot be null) 
Hive,WITHOUT_CLASSIFICATION,//  Table Metadata 
Hive,WITHOUT_CLASSIFICATION,//  NUM_FALSES 
Hive,WITHOUT_CLASSIFICATION,//  Finally if we do not reduce the size input enough we bail out 
Hive,WITHOUT_CLASSIFICATION,//  drop tables 
Hive,WITHOUT_CLASSIFICATION,//  v[6] -- since integer #5 is always 0 some products here are not included. 
Hive,WITHOUT_CLASSIFICATION,//  Same primitive category but different qualifiers.   Rely on getTypeInfoForPrimitiveCategory() to sort out the type params. 
Hive,WITHOUT_CLASSIFICATION,//  We may need to peel off the GenericUDFBridge that is added by CBO or user 
Hive,WITHOUT_CLASSIFICATION,// for other usually not used types just quote the value 
Hive,WITHOUT_CLASSIFICATION,//  names 
Hive,WITHOUT_CLASSIFICATION,//  table write id for this operation 
Hive,WITHOUT_CLASSIFICATION,//  3) Return new Project 
Hive,WITHOUT_CLASSIFICATION,//  Note: schema evolution currently does not support column index changes. 
Hive,WITHOUT_CLASSIFICATION,//  This next section repeats the tests of testRightTrimWithOffset with a maxLength parameter that is   exactly the number of current characters in the string.  This shouldn't affect the trim. 
Hive,WITHOUT_CLASSIFICATION,//  Verify the output! 
Hive,WITHOUT_CLASSIFICATION,//  Evaluate children only of scalar is FALSE. 
Hive,WITHOUT_CLASSIFICATION,//  Input fullTableName is of format <db_name>.<table_name> 
Hive,WITHOUT_CLASSIFICATION,//  when it is registered to the system registry. 
Hive,WITHOUT_CLASSIFICATION,//  Deserialize and append new row using the current batch size as the index. 
Hive,WITHOUT_CLASSIFICATION,//  6. Construct aggregation function Info 
Hive,WITHOUT_CLASSIFICATION,//  The id of the tracking node -- must be a SEQUENTIAL node 
Hive,WITHOUT_CLASSIFICATION,//  One dead session with dry-run 
Hive,WITHOUT_CLASSIFICATION,//  Trailing spaces are significant 
Hive,WITHOUT_CLASSIFICATION,//  Right child 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(enum_scope:SubmissionStateProto) 
Hive,WITHOUT_CLASSIFICATION,//  3. Copy the data. 
Hive,WITHOUT_CLASSIFICATION,//  Apply best effort to fetch the correct table alias. If not   found fallback to old logic. 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)  * @see org.apache.hadoop.mapreduce.RecordReader#getCurrentKey()   */
Hive,WITHOUT_CLASSIFICATION,//  be emitted from join operator will depend on this factor 
Hive,WITHOUT_CLASSIFICATION,//  Note: we no longer call addTaskLocalFiles because all the resources are correctly         updated in the session resource lists now and thus added to vertices.         If something breaks dag.addTaskLocalFiles might need to be called here. 
Hive,WITHOUT_CLASSIFICATION,//  prepare output descriptors for the input opt 
Hive,WITHOUT_CLASSIFICATION,//  When Kerberos is enabled we have to add the Accumulo delegation token to the   Job so that it gets passed down to the YARN/Tez task. 
Hive,WITHOUT_CLASSIFICATION,//  5. All the sessions in use that were not destroyed or returned with a failed update now die. 
Hive,WITHOUT_CLASSIFICATION,//  (create table sets it to empty (non null) structures) 
Hive,WITHOUT_CLASSIFICATION,//  test repeating case no nulls 
Hive,WITHOUT_CLASSIFICATION,//  We have a cycle! 
Hive,WITHOUT_CLASSIFICATION,//  If the sizes match prefer the table with fewer partitions 
Hive,WITHOUT_CLASSIFICATION,//  partSpec is an ORDERED hash map   number of dynamic partition columns   number of static partition columns   path name corresponding to SP columns   the root path DP columns paths start from   number of buckets in each partition 
Hive,WITHOUT_CLASSIFICATION,//  Asynchronously shutdown this instance of HiveServer2   if there are no active client sessions 
Hive,WITHOUT_CLASSIFICATION,//  REPL STATUS should return NULL 
Hive,WITHOUT_CLASSIFICATION,//  We need to figure out the current transaction number and the list of   open transactions.  To avoid needing a transaction on the underlying   database we'll look at the current transaction number first.  If it   subsequently shows up in the open list that's ok. 
Hive,WITHOUT_CLASSIFICATION,//  Note that this doesn't include appId. We assume that all the subsequent instances   of the same user+cluster are logically the same i.e. all the ZK paths will be reused   all the security tokens/etc. should transition between them etc. 
Hive,WITHOUT_CLASSIFICATION,//  2. Insert ReduceSide GB 
Hive,WITHOUT_CLASSIFICATION,//  checkPermissions returns false if query is not found throws on failure. 
Hive,WITHOUT_CLASSIFICATION,//  Set confOverlay parameters 
Hive,WITHOUT_CLASSIFICATION,//  Validation will later exclude vectorization of virtual columns usage if necessary. 
Hive,WITHOUT_CLASSIFICATION,/*      * Output columns.      */
Hive,WITHOUT_CLASSIFICATION,//  Reference to vectorization description needed for EXPLAIN VECTORIZATION hash table loading   etc. 
Hive,WITHOUT_CLASSIFICATION,//  files with write IDs may not be valid. It may affect snapshot isolation for on-going txns as well. 
Hive,WITHOUT_CLASSIFICATION,//  Copy data/files/alltypesorc to workDir 
Hive,WITHOUT_CLASSIFICATION,// the ACL api's also expect the tradition user/group/other permission in the form of ACL 
Hive,WITHOUT_CLASSIFICATION,//  cleanup pathToAliases 
Hive,WITHOUT_CLASSIFICATION,//  The node may have been blacklisted at this point - which means it may not be in the   activeNodeList. 
Hive,WITHOUT_CLASSIFICATION,//  Iterate through any records.   Because our read offset was past the stripe offset the rows from the last stripe will 
Hive,WITHOUT_CLASSIFICATION,//  Insert entries to TXN_TO_WRITE_ID for newly allocated write ids 
Hive,WITHOUT_CLASSIFICATION,//  Adding keys is PITA - there's no way to plug into timed rolling; just create a new fsm. 
Hive,WITHOUT_CLASSIFICATION,/*  partColsIsNull  */
Hive,WITHOUT_CLASSIFICATION,//  OWNER 
Hive,WITHOUT_CLASSIFICATION,//  Prevent construction. 
Hive,WITHOUT_CLASSIFICATION,/*       Check for conditions that will lead to local copy checks are:      1. we are testing hive.      2. either source or destination is a "local" FileSystem("file")      3. aggregate fileSize of all source Paths(can be directory /  file) is less than configured size.      4. number of files of all source Paths(can be directory /  file) is less than configured size.   */
Hive,WITHOUT_CLASSIFICATION,//  single-line 
Hive,WITHOUT_CLASSIFICATION,// setting statementId == -1 makes compacted delta files use 
Hive,WITHOUT_CLASSIFICATION,//  we depend on linux openssl exit codes 
Hive,WITHOUT_CLASSIFICATION,//  TODO: We don't do anything for now just log this for debugging.         We may be able to make use of this later e.g. for workload management. 
Hive,WITHOUT_CLASSIFICATION,//  Update the LRU node from what we've seen so far 
Hive,WITHOUT_CLASSIFICATION,//  for each input file 
Hive,WITHOUT_CLASSIFICATION,// retest WAITING locks (both have same ext id) 
Hive,WITHOUT_CLASSIFICATION,//  If a operator needs to invoke specific cleanup that operator can override 
Hive,WITHOUT_CLASSIFICATION,//  The ptned table will not be dumped as getTable will return null 
Hive,WITHOUT_CLASSIFICATION,//  If it is a widening cast we do not change NDV min max 
Hive,WITHOUT_CLASSIFICATION,//  Test to validate that all tables exist in the HMS metastore. 
Hive,WITHOUT_CLASSIFICATION,//  how many rows in this split 
Hive,WITHOUT_CLASSIFICATION,//  No match. 
Hive,WITHOUT_CLASSIFICATION,//  check for existence of table 
Hive,WITHOUT_CLASSIFICATION,//  update non-distinct groupby key or value aggregations: 'KEY._COLx or VALUE._colx' 
Hive,WITHOUT_CLASSIFICATION,//  HIVE-15410: Though there are not restrictions to Hive table property key and it could be any   combination of the letters digits and even punctuations we support conventional property   name in WebHCat (e.g. prepery name starting with a letter or digit probably with period (.)   underscore (_) and hyphen (-) only in the middle like auto.purge last_modified_by etc) 
Hive,WITHOUT_CLASSIFICATION,//  CONSIDER: Looked at the possibility of faster decimal to double conversion by using some             of their lower level logic that extracts the various parts out of a double.             The difficulty is Java's rounding rules are byzantine. 
Hive,WITHOUT_CLASSIFICATION,//  the reduce plan inputs have tags add all inputs that have tags 
Hive,WITHOUT_CLASSIFICATION,//  number of bits to address registers 
Hive,WITHOUT_CLASSIFICATION,//  are allowed. A interface 'supportMapSideGroupBy has been added for the same 
Hive,WITHOUT_CLASSIFICATION,//  already accounted for 
Hive,WITHOUT_CLASSIFICATION,//  r-----r-- 
Hive,WITHOUT_CLASSIFICATION,//  current partitioned table with last partition replicated denoted by "lastPartitionReplicated" 
Hive,WITHOUT_CLASSIFICATION,//  key is token start index 
Hive,WITHOUT_CLASSIFICATION,//  Try appending segment with conflicting interval 
Hive,WITHOUT_CLASSIFICATION,//  first operator of a reduce task. 
Hive,WITHOUT_CLASSIFICATION,//  2. remove old join op from child set of all the RSs 
Hive,WITHOUT_CLASSIFICATION,//  Methods that return scalar expressions 
Hive,WITHOUT_CLASSIFICATION,//  har://underlyingfsscheme-host:port/archivepath 
Hive,WITHOUT_CLASSIFICATION,//  If the job is not empty (but runs fast) we have to wait until all the TaskEnd/JobEnd 
Hive,WITHOUT_CLASSIFICATION,//  Are we currently performing a binary search 
Hive,WITHOUT_CLASSIFICATION,//  Log final state to CONSOLE_LOGGER 
Hive,WITHOUT_CLASSIFICATION,//  1. Decompose Join condition to a number of leaf predicates 
Hive,WITHOUT_CLASSIFICATION,//  the union operator has been processed 
Hive,WITHOUT_CLASSIFICATION,//  constant list projection of known length 
Hive,WITHOUT_CLASSIFICATION,//  We could have this as a protected method w/no class but half of Hive is static so there. 
Hive,WITHOUT_CLASSIFICATION,//  Less frequently set parameter not passing in as a param. 
Hive,WITHOUT_CLASSIFICATION,//  Bail out 
Hive,WITHOUT_CLASSIFICATION,//  Determine the size of small table inputs 
Hive,WITHOUT_CLASSIFICATION,//  This will make the object completely unusable. Semantics of clear are not defined... 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:org.apache.hadoop.hive.ql.hooks.proto.MapFieldEntry) 
Hive,WITHOUT_CLASSIFICATION,//  must be <= 38. 
Hive,WITHOUT_CLASSIFICATION,//  This method should be called by sub-classes in a @BeforeClass initializer 
Hive,WITHOUT_CLASSIFICATION,/*  * Directly serialize field-by-field the BinarySortable format. * * This is an alternative way to serialize than what is provided by BinarySortableSerDe.  */
Hive,WITHOUT_CLASSIFICATION,/*    * In the following evaluate* methods since we are supporting scratch column reuse we must   * assume the column may have noNulls of false and some isNull entries true.   *   * So do a proper assignments.    */
Hive,WITHOUT_CLASSIFICATION,//  hashcode should be positive flip all the bits if it's negative 
Hive,WITHOUT_CLASSIFICATION,//  immutable 
Hive,WITHOUT_CLASSIFICATION,//  Outer join specific. 
Hive,WITHOUT_CLASSIFICATION,//  if schemaPattern is null it means that the schemaPattern value should not be used to narrow the search 
Hive,WITHOUT_CLASSIFICATION,/*          * for now just adding a true condition(1=1) to where clause.         * Can remove the where clause from the AST; requires moving all subsequent children         * left.          */
Hive,WITHOUT_CLASSIFICATION,//  SMALL_INT_VALUE 
Hive,WITHOUT_CLASSIFICATION,//  This is basically the same as LazySimpleSerDe.serialize. Except that we don't use   Base64 to encode binary data because we're using printable string as delimiter.   Consider such a row "strAQ==\1" str is a string AQ== is the delimiter and \1 
Hive,WITHOUT_CLASSIFICATION,//  set() not implemented - ignore 
Hive,WITHOUT_CLASSIFICATION,//  they will be file:// URLs 
Hive,WITHOUT_CLASSIFICATION,// look in COMPLETED_TXN_COMPONENTS because driver.run() committed!!!! 
Hive,WITHOUT_CLASSIFICATION,//  We need to check with 'instanceof' instead of just checking   vectorized because the row can be a VectorizedRowBatch when   FetchOptimizer kicks in even if the operator pipeline is not   vectorized 
Hive,WITHOUT_CLASSIFICATION,//  change the children of the original join operator to point to the map   join operator 
Hive,WITHOUT_CLASSIFICATION,//  The number of keys (with sequential duplicates collapsed both NULL and non-NULL) in the batch. 
Hive,WITHOUT_CLASSIFICATION,// no more timedout txns 
Hive,WITHOUT_CLASSIFICATION,//  Write record to Parquet format 
Hive,WITHOUT_CLASSIFICATION,//  Done with all the things. 
Hive,WITHOUT_CLASSIFICATION,//  whitespace characters / { } \ 
Hive,WITHOUT_CLASSIFICATION,//  It could be renewed return that information 
Hive,WITHOUT_CLASSIFICATION,/*    * Returns true if trailing slash is needed to be appended to the url    */
Hive,WITHOUT_CLASSIFICATION,//  4rd task provided no location preference got host2 since host1 is full and only host2 is left in random pool 
Hive,WITHOUT_CLASSIFICATION,//  Delayed due to temporary resource availability 
Hive,WITHOUT_CLASSIFICATION,//  Spot check Decimal Col-Scalar Modulo 
Hive,WITHOUT_CLASSIFICATION,// log classpaths 
Hive,WITHOUT_CLASSIFICATION,//  Schedule task to invalidate cache entry and remove from lookup. 
Hive,WITHOUT_CLASSIFICATION,//  Need to go in and check if any of the tasks is running in LLAP mode. 
Hive,WITHOUT_CLASSIFICATION,//  Contains results from last processed input record. 
Hive,WITHOUT_CLASSIFICATION,//  Remove the operators till a certain depth. 
Hive,WITHOUT_CLASSIFICATION,//  If the user has HIVEMERGEMAPREDFILES set to false the idea was the   number of reducers are few so the number of files anyway are small.   However with this optimization we are increasing the number of files   possibly by a big margin. So merge aggresively.
Hive,WITHOUT_CLASSIFICATION,//  only worry about getting schema if we are dealing with Avro 
Hive,WITHOUT_CLASSIFICATION,//  full precision 
Hive,WITHOUT_CLASSIFICATION,//  This assumes LLAP cluster owner is always the HS2 user. 
Hive,WITHOUT_CLASSIFICATION,//  The number of files for the table should be same as number of   buckets. 
Hive,WITHOUT_CLASSIFICATION,//  Note: this is a no-op for custom UDFs 
Hive,WITHOUT_CLASSIFICATION,//  set a marker that this conf has been processed. 
Hive,WITHOUT_CLASSIFICATION,//  don't instantiate 
Hive,WITHOUT_CLASSIFICATION,//  get the kind of expression 
Hive,WITHOUT_CLASSIFICATION,//  5%   5% 
Hive,WITHOUT_CLASSIFICATION,//  Get unique skewed value list. 
Hive,WITHOUT_CLASSIFICATION,//  Currently expressions are not allowed in cluster by distribute by   order by or a sort by clause. For each of the above clause types check 
Hive,WITHOUT_CLASSIFICATION,//  Generate a unique ID for temp table path.   This path will be fixed for the life of the temp table. 
Hive,WITHOUT_CLASSIFICATION,// With nulls and selected 
Hive,WITHOUT_CLASSIFICATION,//  We have to tell apart partitions resulting from spec with different prefix lengths.   So if we already have smth for the same prefix length we can OR the two. 
Hive,WITHOUT_CLASSIFICATION,//  See HIVE-11915 for details 
Hive,WITHOUT_CLASSIFICATION,//  The update has failed but the state has changed since then - no retry needed. 
Hive,WITHOUT_CLASSIFICATION,//  Now the dumped path can be one of three things:   a) It can be a db dump in which case we expect a set of dirs each with a   db name and with a _metadata file in each and table dirs inside that.   b) It can be a table dump dir in which case we expect a _metadata dump of   a table in question in the dir and individual ptn dir hierarchy.   c) A dump can be an incremental dump which means we have several subdirs   each of which have the evid as the dir name and each of which correspond   to a event-level dump. Currently only CREATE_TABLE and ADD_PARTITION are   handled so all of these dumps will be at a table/ptn level. 
Hive,WITHOUT_CLASSIFICATION,// all inserts should be in baseReader for normal read so this should always be delete delta if not compacting 
Hive,WITHOUT_CLASSIFICATION,//  Patch up the projection list for updates putting back the original set expressions. 
Hive,WITHOUT_CLASSIFICATION,//  Pick up any system properties that start with "hive." and set them in our config.  This   way we can properly pull any Hive values from the environment without needing to know all 
Hive,WITHOUT_CLASSIFICATION,//  For non-native tables we need to do an exact match to avoid   HIVE-1903.  (The table location contains no files and the string   representation of its path does not have a trailing slash.) 
Hive,WITHOUT_CLASSIFICATION,//  of beeline. 
Hive,WITHOUT_CLASSIFICATION,//  Comparison Operations 
Hive,WITHOUT_CLASSIFICATION,//  Only our parent class can call this. 
Hive,WITHOUT_CLASSIFICATION,// if acid is off there can't be any acid tables - nothing to compact 
Hive,WITHOUT_CLASSIFICATION,//  Check and update partition cols if necessary. Ideally this should be done   in CreateValue as the partition is constant per split. But since Hive uses   CombineHiveRecordReader and   as this does not call CreateValue for each new RecordReader it creates this check is   required in next() 
Hive,WITHOUT_CLASSIFICATION,//  function was properly called but threw it's own exception.   Unwrap it   and pass it on. 
Hive,WITHOUT_CLASSIFICATION,//  if this child of DemuxOperator does not use tag we just set the oldTag to 0. 
Hive,WITHOUT_CLASSIFICATION,//  Parameter 1 was an array of primitives so make sure the primitives are strings. 
Hive,WITHOUT_CLASSIFICATION,//  skip MAP processing for the first path element if root is array 
Hive,WITHOUT_CLASSIFICATION,//  ignore 
Hive,WITHOUT_CLASSIFICATION,//  only uses transactional (MM and ACID) tables 
Hive,WITHOUT_CLASSIFICATION,//  the same operator is present 2 times 
Hive,WITHOUT_CLASSIFICATION,//  Set up some base data then stream some inserts/updates/deletes to a number of partitions 
Hive,WITHOUT_CLASSIFICATION,// Test that data inserted through hcatoutputformat is readable from hive 
Hive,WITHOUT_CLASSIFICATION,//  No effect since 10^0 = 1. 
Hive,WITHOUT_CLASSIFICATION,//  If we have a base the original files are obsolete. 
Hive,WITHOUT_CLASSIFICATION,//  @formatter:off 
Hive,WITHOUT_CLASSIFICATION,//  Close the writer 
Hive,WITHOUT_CLASSIFICATION,//  After bootstrap dump all the opened txns should be aborted. Verify it. 
Hive,WITHOUT_CLASSIFICATION,//  Which field we are on.  We start with -1 to be consistent in style with 
Hive,WITHOUT_CLASSIFICATION,//  optional int32 aint = 1; 
Hive,WITHOUT_CLASSIFICATION,//  Base scan only 
Hive,WITHOUT_CLASSIFICATION,//  valid merge -- register set size gets bigger (also 4k items  
Hive,WITHOUT_CLASSIFICATION,//  dealing with String type 
Hive,WITHOUT_CLASSIFICATION,//  Move past union separator. 
Hive,WITHOUT_CLASSIFICATION,//    Implementation notes.     1. Since only local file systems are supported there is no need to use Hadoop      version of Path class.   2. java.nio package provides modern implementation of file and directory operations      which is better then the traditional java.io so we are using it here.      In particular it supports atomic creation of temporary files with specified      permissions in the specified directory. This also avoids various attacks possible      when temp file name is generated first followed by file creation.      See http://www.oracle.com/technetwork/articles/javase/nio-139333.html for      the description of NIO API and      http://docs.oracle.com/javase/tutorial/essential/io/legacy.html for the      description of interoperability between legacy IO api vs NIO API.   3. To avoid race conditions with readers of the metrics file the implementation      dumps metrics to a temporary file in the same directory as the actual metrics      file and then renames it to the destination. Since both are located on the same      filesystem this rename is likely to be atomic (as long as the underlying OS      support atomic renames.     NOTE: This reporter is very similar to         org.apache.hadoop.hive.common.metrics.metrics2.JsonFileMetricsReporter.         org.apache.hadoop.hive.metastore.metrics.JsonReporter.         It would be good to unify the two.   
Hive,WITHOUT_CLASSIFICATION,//  Scale fractional digits dot integer digits. 
Hive,WITHOUT_CLASSIFICATION,//  a "long" count and a "double" sum. 
Hive,WITHOUT_CLASSIFICATION,//  Can't assume JDK 1.8 so implementing this explicitly.   return Integer.compare(x + Integer.MIN_VALUE y + Integer.MIN_VALUE); 
Hive,WITHOUT_CLASSIFICATION,//  do not group across files in case of side work because there is only 1 KV reader per   grouped split. This would affect SMB joins where we want to find the smallest key in   all the bucket files. 
Hive,WITHOUT_CLASSIFICATION,//  Populate the group-by keys with the remapped arguments for aggregate A   The top groupset is basically an identity (first X fields of aggregate B's 
Hive,WITHOUT_CLASSIFICATION,//  (containing the archived version of the files) to intermediateArchiveDir 
Hive,WITHOUT_CLASSIFICATION,/*  Objective here is to ensure that when exceptions are thrown in HiveMetaStore in API methods     * they bubble up and are stored in the MetaStoreEndFunctionContext objects      */
Hive,WITHOUT_CLASSIFICATION,//  REPLACE 
Hive,WITHOUT_CLASSIFICATION,//  Evaluation of the bytes Constant Vector Expression after the vector is 
Hive,WITHOUT_CLASSIFICATION,//  CONSIDER: Validate type information 
Hive,WITHOUT_CLASSIFICATION,//  If we use CBO and we may apply masking/filtering policies we create a copy of the ast.   The reason is that the generation of the operator tree may modify the initial ast   but if we need to parse for a second time we would like to parse the unmodified ast. 
Hive,WITHOUT_CLASSIFICATION,//  fields 
Hive,WITHOUT_CLASSIFICATION,//  number of entries to store before being merged to sparse map 
Hive,WITHOUT_CLASSIFICATION,//  Same file offset different lengths 
Hive,WITHOUT_CLASSIFICATION,// Pig DATETIME can map to DATE or TIMESTAMP (see HCatBaseStorer#validateSchema()) which  is controlled by Hive target table information 
Hive,WITHOUT_CLASSIFICATION,//  Must call makeLiteral not makeTimestampLiteral   to have the RexBuilder.roundTime logic kick in 
Hive,WITHOUT_CLASSIFICATION,/*      * (non-Javadoc)     * @see org.apache.hadoop.hive.ql.udf.ptf.TableFunctionResolver#carryForwardNames()     * Setting to true is correct only for special internal Functions.      */
Hive,WITHOUT_CLASSIFICATION,//  Bucketing. 
Hive,WITHOUT_CLASSIFICATION,//  also remove the '.' after the prefix 
Hive,WITHOUT_CLASSIFICATION,//  destination table if any   true for full ACID table and MM table   should the destination table be written to using ACID 
Hive,WITHOUT_CLASSIFICATION,//  followed by a select star is completely removed. 
Hive,WITHOUT_CLASSIFICATION,//  At this point we have arrived at the level where we need all the data and the 
Hive,WITHOUT_CLASSIFICATION,//  otherwise the planner will throw an Exception (different planners) 
Hive,WITHOUT_CLASSIFICATION,//  transaction manager. 
Hive,WITHOUT_CLASSIFICATION,//  numPartitionFields = -1 means random partitioning 
Hive,WITHOUT_CLASSIFICATION,//  null input 
Hive,WITHOUT_CLASSIFICATION,//  Map values can be primitive or complex 
Hive,WITHOUT_CLASSIFICATION,//  When split-update is not enabled then all the deltas in the current directories   should be considered as usual. 
Hive,WITHOUT_CLASSIFICATION,//  If retrieveCD is false we do not need to do a deep retrieval of the Table Column Descriptor.   For instance this is the case when we are creating the table. 
Hive,WITHOUT_CLASSIFICATION,//  This is not a rebuild we retrieve all the materializations. In turn we do not need   to force the materialization contents to be up-to-date as this is not a rebuild and   we apply the user parameters (HIVE_MATERIALIZED_VIEW_REWRITING_TIME_WINDOW) instead. 
Hive,WITHOUT_CLASSIFICATION,//  PART_VALS 
Hive,WITHOUT_CLASSIFICATION,//  get all the variable names being converted to regex in HiveConf using reflection 
Hive,WITHOUT_CLASSIFICATION,//  in theory the include path should come from the configuration 
Hive,WITHOUT_CLASSIFICATION,//  this should be connection urlusernamepasswordquerycolumn1[columnn]* 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   required   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  we trim the Clob value to a max length an int can hold 
Hive,WITHOUT_CLASSIFICATION,//  Test string "A" 
Hive,WITHOUT_CLASSIFICATION,//  number of partitions for the chosen big table 
Hive,WITHOUT_CLASSIFICATION,/*  1 files x 1000 size for 1 splits  */
Hive,WITHOUT_CLASSIFICATION,//  Hence the uncovered buckets do not have any relevant data and we can just ignore them. 
Hive,WITHOUT_CLASSIFICATION,//  The update options for outside the lock - see below the synchronized block. 
Hive,WITHOUT_CLASSIFICATION,//  Non-hive catalogs should not be transactional 
Hive,WITHOUT_CLASSIFICATION,//  Start up this ZK server 
Hive,WITHOUT_CLASSIFICATION,//  Only a scale adjustment is needed. 
Hive,WITHOUT_CLASSIFICATION,/*  Iterate the global (keywrapperaggregationbuffers) map and emit       a row for each key  */
Hive,WITHOUT_CLASSIFICATION,//  also allow lower-case versions of all the keywords 
Hive,WITHOUT_CLASSIFICATION,//  1. Run a query against a non-ACID table and we shouldn't have txn logged in conf 
Hive,WITHOUT_CLASSIFICATION,//  used for GenericUDAFEvaluator 
Hive,WITHOUT_CLASSIFICATION,// bucketed just so that we get 2 files 
Hive,WITHOUT_CLASSIFICATION,//  update changed properties (stats) 
Hive,WITHOUT_CLASSIFICATION,//  Add ops to existing collection 
Hive,WITHOUT_CLASSIFICATION,//  Event 19 20 21 
Hive,WITHOUT_CLASSIFICATION,//  start a log cleaner at the start of each test 
Hive,WITHOUT_CLASSIFICATION,//  boolean that says whether the data distribution is uniform hash (not java HashCode) 
Hive,WITHOUT_CLASSIFICATION,//  We have kerberos credentials 
Hive,WITHOUT_CLASSIFICATION,//       runStatementOnDriver("create table T like " + Table.ACIDTBL); 
Hive,WITHOUT_CLASSIFICATION,//  Input provides the definition of a correlated variable. 
Hive,WITHOUT_CLASSIFICATION,//  Copy uncompressed data to cache.   Put call moves position forward by the size of the data. 
Hive,WITHOUT_CLASSIFICATION,//  CONFIGURATION 
Hive,WITHOUT_CLASSIFICATION,//  1.1. If it is not a RexCall we bail out 
Hive,WITHOUT_CLASSIFICATION,//  DATE conversions supported by GenericUDFDecimal. 
Hive,WITHOUT_CLASSIFICATION,//  call-1: listLocatedStatus - mock:/mocktable   call-2: check existence of side file for mock:/mocktable/0_0   call-3: open - mock:/mocktable/0_0   call-4: check existence of side file for mock:/mocktable/0_1   call-5: open - mock:/mocktable/0_1 
Hive,WITHOUT_CLASSIFICATION,//  IS_SUPPORTED 
Hive,WITHOUT_CLASSIFICATION,// add the previous nextKVReader back to queue 
Hive,WITHOUT_CLASSIFICATION,//  Set host name in conf 
Hive,WITHOUT_CLASSIFICATION,//  Verify that the provided object inspector can pull out these same values 
Hive,WITHOUT_CLASSIFICATION,/*    * Reset the previously supplied buffer that will receive the serialized data.    */
Hive,WITHOUT_CLASSIFICATION,//  Test the length first so in most cases we avoid doing a byte[]   comparison. 
Hive,WITHOUT_CLASSIFICATION,/* overwrite */
Hive,WITHOUT_CLASSIFICATION,// checked for overflow based on the outputTypeInfo 
Hive,WITHOUT_CLASSIFICATION,//  Init conf 
Hive,WITHOUT_CLASSIFICATION,//  multi-small-table-valued) indexes during a process call. 
Hive,WITHOUT_CLASSIFICATION,//  each iterator creates a level of encoding. 
Hive,WITHOUT_CLASSIFICATION,//  check the input to projRel is an aggregate on the entire input 
Hive,WITHOUT_CLASSIFICATION,//  4) the table was not initially created with a specified location 
Hive,WITHOUT_CLASSIFICATION,//  Add a table via ObjectStore 
Hive,WITHOUT_CLASSIFICATION,//  Unexpected error placeholder tag is not found throw 
Hive,WITHOUT_CLASSIFICATION,//  add permanent UDFs being used 
Hive,WITHOUT_CLASSIFICATION,//  return (hiveSite - jobConf); 
Hive,WITHOUT_CLASSIFICATION,//  CREATE_TABLE EVENT with multiple partitions 
Hive,WITHOUT_CLASSIFICATION,//  1) Cancel the kills if any to avoid killing the returned sessions.      Also sets the count for the async initialization. 
Hive,WITHOUT_CLASSIFICATION,//  Load Hash table for Bucket MapJoin 
Hive,WITHOUT_CLASSIFICATION,//  check cor var references are valid 
Hive,WITHOUT_CLASSIFICATION,//  and the logs 
Hive,WITHOUT_CLASSIFICATION,//  to output instead of input adding owner requirement on output will catch that as well 
Hive,WITHOUT_CLASSIFICATION,// initialize the rowbatchContext 
Hive,WITHOUT_CLASSIFICATION,// check if there is data in the resultset 
Hive,WITHOUT_CLASSIFICATION,// 0. initialization 
Hive,WITHOUT_CLASSIFICATION,// still working 
Hive,WITHOUT_CLASSIFICATION,//  Input operator is not in the same position 
Hive,WITHOUT_CLASSIFICATION,//  Call the metastore to get the currently queued and running compactions. 
Hive,WITHOUT_CLASSIFICATION,//  7. Projection Pruning (this introduces select above TS & hence needs to be run last due to PP) 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setNull(int int java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  this is total free memory available per executor in case of LLAP 
Hive,WITHOUT_CLASSIFICATION,//  add an interceptor that adds the X-Forwarded-For header with given ips 
Hive,WITHOUT_CLASSIFICATION,//  Not needed without semi-join reduction or mapjoins or when semijoins   are enabled for parallel mapjoins. 
Hive,WITHOUT_CLASSIFICATION,//  Cleanup the dag lock here since it may have been created after the query completed 
Hive,WITHOUT_CLASSIFICATION,//  The reader schema always comes in without ACID columns. 
Hive,WITHOUT_CLASSIFICATION,//  HIGHTEST_TXN_ID 
Hive,WITHOUT_CLASSIFICATION,//  If this is a split-update we initialize a delete delta file path in anticipation that   they would write update/delete events to that separate file.   This writes to a file in directory which starts with "delete_delta_..."   The actual initialization of a writer only happens if any delete events are written  to avoid empty files. 
Hive,WITHOUT_CLASSIFICATION,//  Check explicit pool specifications - valid cases where priority is changed. 
Hive,WITHOUT_CLASSIFICATION,/*    * Extract value from a comma-separated key=value pairs    */
Hive,WITHOUT_CLASSIFICATION,//  10. Attach CTAS/Insert-Commit-hooks for Storage Handlers 
Hive,WITHOUT_CLASSIFICATION,//  for alter partition events 
Hive,WITHOUT_CLASSIFICATION,//  both inputs repeat 
Hive,WITHOUT_CLASSIFICATION,//  field.type < 0 means that this is a faked Thrift field e.g.   TControlSeparatedProtocol which does not   serialize the field id in the stream. As a result the only way to get   the field id is to fall back to   the position "i".   The intention of this hack (field.type < 0) is to make   TControlSeparatedProtocol a real Thrift prototype   but there are a lot additional work to do to fulfill that and that   protocol inherently does not support 
Hive,WITHOUT_CLASSIFICATION,//  May be resized later. 
Hive,WITHOUT_CLASSIFICATION,//  singleAggRel produces a nullable type so create the new 
Hive,WITHOUT_CLASSIFICATION,//  let it create 64 more partitions (total 57 + 64 = 121) without any triggers 
Hive,WITHOUT_CLASSIFICATION,//  1. We extract the information necessary to create the predicate for the new      filter 
Hive,WITHOUT_CLASSIFICATION,//  Error stream always uses the default serde with a single column 
Hive,WITHOUT_CLASSIFICATION,//  Hive requires this TaskAttemptId to be unique. MR's TaskAttemptId is composed   of "attempt_timestamp_jobNum_m/r_taskNum_attemptNum". The counterpart for   Spark should be "attempt_timestamp_stageNum_m/r_partitionId_attemptNum".   When there're multiple attempts for a task Hive will rely on the partitionId   to figure out if the data are duplicate or not when collecting the final outputs   (see org.apache.hadoop.hive.ql.exec.Utils.removeTempOrDuplicateFiles) 
Hive,WITHOUT_CLASSIFICATION,//  Multiple newTags can point to the same child (e.g. when the child is a JoinOperator).   So we first check if childInputObjInspectors contains the key of childIndex. 
Hive,WITHOUT_CLASSIFICATION,//  no-arg ctor required for Kyro serialization 
Hive,WITHOUT_CLASSIFICATION,//  Drop a named primary key 
Hive,WITHOUT_CLASSIFICATION,//  prefix is of the form dbName.tblName 
Hive,WITHOUT_CLASSIFICATION,//  check if source partition exists 
Hive,WITHOUT_CLASSIFICATION,//  Singleton behaviour: create the cache instance if required. 
Hive,WITHOUT_CLASSIFICATION,//  This yields empty because starting index is out of bounds 
Hive,WITHOUT_CLASSIFICATION,//  Inspect the output type of each key expression.  And remember the output columns. 
Hive,WITHOUT_CLASSIFICATION,//  try isRepeating path (left input only) no nulls 
Hive,WITHOUT_CLASSIFICATION,//  2 Add Direction token 
Hive,WITHOUT_CLASSIFICATION,//  Does any operator in the tree stop the task from being converted to a conditional task 
Hive,WITHOUT_CLASSIFICATION,/*  * An single LONG key hash map optimized for vector map join.  */
Hive,WITHOUT_CLASSIFICATION,//  GRANT_INFO 
Hive,WITHOUT_CLASSIFICATION,/*    * Element for Key: byte[] x Hash Table: HashMap    */
Hive,WITHOUT_CLASSIFICATION,//  Results 
Hive,WITHOUT_CLASSIFICATION,// map max nesting level is one less because it uses an additional separator 
Hive,WITHOUT_CLASSIFICATION,//  Project can also generate constants. We need to include them. 
Hive,WITHOUT_CLASSIFICATION,//  first argument is charCount which is consumed here 
Hive,WITHOUT_CLASSIFICATION,//  the correct plugin. 
Hive,WITHOUT_CLASSIFICATION,//  Hive doesn't have an Enum type so we're going to treat them as Strings.   During the deserialize/serialize stage we'll check for enumness and 
Hive,WITHOUT_CLASSIFICATION,//  a lock is used for synchronizing the state transition and its associated   resource releases 
Hive,WITHOUT_CLASSIFICATION,// get all parents of reduce sink 
Hive,WITHOUT_CLASSIFICATION,//  Give it some time then don't delay shutdown too much. 
Hive,WITHOUT_CLASSIFICATION,//  id column we cannot push the predicate 
Hive,WITHOUT_CLASSIFICATION,//  De-allocated now   Will be de-allocated later. 
Hive,WITHOUT_CLASSIFICATION,//  No group key. 
Hive,WITHOUT_CLASSIFICATION,//  field present in partition but not in table 
Hive,WITHOUT_CLASSIFICATION,//  count(*) cares not about NULLs nor selection 
Hive,WITHOUT_CLASSIFICATION,//  for IN clause 
Hive,WITHOUT_CLASSIFICATION,/*        End of cleanup     */
Hive,WITHOUT_CLASSIFICATION,// do nothing currently 
Hive,WITHOUT_CLASSIFICATION,//  1. Update Col Stats Map with col stats for columns from left side of 
Hive,WITHOUT_CLASSIFICATION,//  FUNCTION_TYPE 
Hive,WITHOUT_CLASSIFICATION,//  small table HTS. But since it's idempotent it should be OK. 
Hive,WITHOUT_CLASSIFICATION,//  unknown type 
Hive,WITHOUT_CLASSIFICATION,//  if the table is in a different dfs than the partition 
Hive,WITHOUT_CLASSIFICATION,//  remove the last " " 
Hive,WITHOUT_CLASSIFICATION,//  For comparison purposes we can scale away those digits.  And we can not scale up since   that could overflow. 
Hive,WITHOUT_CLASSIFICATION,//  It simplifies things to just add default ones for partitions. 
Hive,WITHOUT_CLASSIFICATION,//  ORDER 
Hive,WITHOUT_CLASSIFICATION,//  Nothing matched. See comment at top. 
Hive,WITHOUT_CLASSIFICATION,//  scaled value might be not equal but after scaling it should. 
Hive,WITHOUT_CLASSIFICATION,//  ignore NSOE because that means there's nothing to drop. 
Hive,WITHOUT_CLASSIFICATION,//  1 Pending task which is not finishable 
Hive,WITHOUT_CLASSIFICATION,//  Recurse 
Hive,WITHOUT_CLASSIFICATION,//  Deprecated Hive values that we are keeping for backwards compatibility. 
Hive,WITHOUT_CLASSIFICATION,//  Assuming this is only being done for join keys. As a result we shouldn't have to recursively   check any nested child expressions because the result of the expression should exist as an 
Hive,WITHOUT_CLASSIFICATION,//  Only fetch the table if we have a listener that needs it. 
Hive,WITHOUT_CLASSIFICATION,//  be removed if this becomes a performance issue. 
Hive,WITHOUT_CLASSIFICATION,//  must reuse super as info.getPassword is not accessible 
Hive,WITHOUT_CLASSIFICATION,//  The value is before the offset.  Make byte segment reference absolute. 
Hive,WITHOUT_CLASSIFICATION,//  If we don't have a file cache we will add this one as is. 
Hive,WITHOUT_CLASSIFICATION,/*    * Support for null constant object    */
Hive,WITHOUT_CLASSIFICATION,//  or it is not up to date. 
Hive,WITHOUT_CLASSIFICATION,//  Re-enable the node if preempted 
Hive,WITHOUT_CLASSIFICATION,//  a deadlock possible in extreme cases if not handled. This will be detected by heartbeat. 
Hive,WITHOUT_CLASSIFICATION,//  Regardless of acquired or waiting one shared write cannot pass another. 
Hive,WITHOUT_CLASSIFICATION,//  If `currentUnionOperators` is not empty it means we are creating BaseWork whose operator tree   contains union operators. In this case we need to save these BaseWorks and remove 
Hive,WITHOUT_CLASSIFICATION,//  Need to spill from write buffer to disk 
Hive,WITHOUT_CLASSIFICATION,//  If replicating then the partition already existing means we need to replace maybe if   the destination ptn's repl.last.id is older than the replacement's. 
Hive,WITHOUT_CLASSIFICATION,//  str is empty string 
Hive,WITHOUT_CLASSIFICATION,//  We remove the limit operator 
Hive,WITHOUT_CLASSIFICATION,//  Only used in bucket map join. 
Hive,WITHOUT_CLASSIFICATION,//  There should be 2 delta dirs plus 1 base dir in the location 
Hive,WITHOUT_CLASSIFICATION,//  this call is deleting partitions that are already missing from filesystem   so 3rd parameter (deleteData) is set to false   msck is doing a clean up of hms.  if for some reason the partition is already 
Hive,WITHOUT_CLASSIFICATION,//  Either DELAYED_RESOURCES or DELAYED_LOCALITY with an unknown requested host.   Request for a preemption if there's none pending. If a single preemption is pending   and this is the next task to be assigned it will be assigned once that slot becomes available. 
Hive,WITHOUT_CLASSIFICATION,//  the map_field is to test multiple level map definition 
Hive,WITHOUT_CLASSIFICATION,//  Use the colfam and colqual to get the value 
Hive,WITHOUT_CLASSIFICATION,//  get a evaluator for a simple field expression 
Hive,WITHOUT_CLASSIFICATION,//  If the output has some extra fields set them to NULL. 
Hive,WITHOUT_CLASSIFICATION,//  Get the total number of columns selected and for each output column store the   base table it points to. For   insert overwrite table T3   select T1.key T1.key2 UDF(T1.value T2.value)   from T1 join T2 on T1.key = T2.key and T1.key2 = T2.key2   the following arrays are created   [0 0 0 1] --> [T1 T1 T1 T2] (table mapping) 
Hive,WITHOUT_CLASSIFICATION,//  There are separate configuration parameters to control whether to   merge for a map-only job 
Hive,WITHOUT_CLASSIFICATION,// put existing column in new list to make sure it is in the right position 
Hive,WITHOUT_CLASSIFICATION,//  Can never have more than this in elements. 
Hive,WITHOUT_CLASSIFICATION,//  LOJ Join preserves LHS types 
Hive,WITHOUT_CLASSIFICATION,/*  100 files x 100 size for 9 splits  */
Hive,WITHOUT_CLASSIFICATION,//  Perform some sanity checks on the arguments. 
Hive,WITHOUT_CLASSIFICATION,//  File operations failed 
Hive,WITHOUT_CLASSIFICATION,//  Leave this ctor around for backward compat. 
Hive,WITHOUT_CLASSIFICATION,//  The value will have already been set before we're called so don't overwrite it 
Hive,WITHOUT_CLASSIFICATION,//  Reader is using a blocking socket .. interrupt it. 
Hive,WITHOUT_CLASSIFICATION,//  AGENT_INFO 
Hive,WITHOUT_CLASSIFICATION,//  HEARTBEAT_COUNT 
Hive,WITHOUT_CLASSIFICATION,//  Later the properties have to come from the partition as opposed   to from the table in order to support versioning. 
Hive,WITHOUT_CLASSIFICATION,//  remove the tag from key coming out of reducer   and store it in separate variable. 
Hive,WITHOUT_CLASSIFICATION,//  This first section repeats the tests of testRightTrimWithOffset with a large maxLength parameter. 
Hive,WITHOUT_CLASSIFICATION,//  creates objects in recursive manner 
Hive,WITHOUT_CLASSIFICATION,//  v[6] -- since left integer #5 is always 0 some products here are not included. 
Hive,WITHOUT_CLASSIFICATION,//  change the value for the next instance. 
Hive,WITHOUT_CLASSIFICATION,//  though intnum5 is handed as a Byte by hcat the map() will emit it as 
Hive,WITHOUT_CLASSIFICATION,//  TEMPORARY 
Hive,WITHOUT_CLASSIFICATION,//  ensure that both of the partitions are in the complete list. 
Hive,WITHOUT_CLASSIFICATION,//  guaranteed that there is only 1 list within this list because   a reduce sink always brings down the bucketing cols to a single list. 
Hive,WITHOUT_CLASSIFICATION,//  no base only deltas 
Hive,WITHOUT_CLASSIFICATION,//  marker comment to look at stats read ops in target/surefire-reports/*-output.txt 
Hive,WITHOUT_CLASSIFICATION,//  Safety check: if we are merging join operators and there are post-filtering   conditions they cannot be outer joins 
Hive,WITHOUT_CLASSIFICATION,//  since we were provided a qualifier prefix only accept qualifiers that start with this   prefix 
Hive,WITHOUT_CLASSIFICATION,// http://www.postgresql.org/docs/9.0/static/sql-select.html 
Hive,WITHOUT_CLASSIFICATION,//  Not an EXTERNAL table 
Hive,WITHOUT_CLASSIFICATION,//  used only for insert events this is the number of rows held in memory before flush() is invoked 
Hive,WITHOUT_CLASSIFICATION,//  remove env var that would default child jvm to use parent's memory   as default. child jvm would use default memory for a hadoop client 
Hive,WITHOUT_CLASSIFICATION,//  No elements 
Hive,WITHOUT_CLASSIFICATION,//  set state in current thread 
Hive,WITHOUT_CLASSIFICATION,//  We could verify precisely at write time but just do approximate at allocation time. 
Hive,WITHOUT_CLASSIFICATION,//  4/ write element by element from the list 
Hive,WITHOUT_CLASSIFICATION,//  because we already confirm that the stats is accurate   it is impossible that the column types have been changed while the   column stats is still accurate. 
Hive,WITHOUT_CLASSIFICATION,// (timeout = 10000) 
Hive,WITHOUT_CLASSIFICATION,//  get all the values from getXXX methods 
Hive,WITHOUT_CLASSIFICATION,//  Map of String to String 
Hive,WITHOUT_CLASSIFICATION,// add the token to the clientUgi for securely talking to the metastore 
Hive,WITHOUT_CLASSIFICATION,//  colAccessInfo is set only in case of SemanticAnalyzer 
Hive,WITHOUT_CLASSIFICATION,//  exceptional use case for avro 
Hive,WITHOUT_CLASSIFICATION,//  "[]" : LSQUARE/INDEX Expression 
Hive,WITHOUT_CLASSIFICATION,//  If there are no grouping keys grouping sets cannot be present 
Hive,WITHOUT_CLASSIFICATION,//  TOKEN_IDENTIFIER 
Hive,WITHOUT_CLASSIFICATION,//  ifExists is currently verified in DDLSemanticAnalyzer 
Hive,WITHOUT_CLASSIFICATION,//  Strip off the file type if any so we don't make:   000000_0.gz -> 000000_0.gz_copy_1 
Hive,WITHOUT_CLASSIFICATION,//     readHiveDecimal.equals(dec)); 
Hive,WITHOUT_CLASSIFICATION,//  The dests can have different non-distinct aggregations so we have to iterate over all of 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(class_scope:GetTokenResponseProto) 
Hive,WITHOUT_CLASSIFICATION,//  There should be no valid txns in newer list that are not also in older.   - All values in oldInvalidIds should also be in newInvalidIds.   - if oldHWM < newHWM then all IDs between oldHWM .. newHWM should exist in newInvalidTxns.     A Gap in the sequence means a committed txn in newer list (lists are not equivalent) 
Hive,WITHOUT_CLASSIFICATION,// derby oracle 
Hive,WITHOUT_CLASSIFICATION,//  No-op 
Hive,WITHOUT_CLASSIFICATION,// test success if exception caught 
Hive,WITHOUT_CLASSIFICATION,//  The validateGroupByOperator method will update vectorGroupByDesc. 
Hive,WITHOUT_CLASSIFICATION,/*      * Add these 3 values:     *     * mixedUp     * green     * NULL      */
Hive,WITHOUT_CLASSIFICATION,//  Right pad longer strings with multi-byte characters. 
Hive,WITHOUT_CLASSIFICATION,//  OBJECT_NAME 
Hive,WITHOUT_CLASSIFICATION,//    Rewrite logic:     1. change the collations field to reference the new input.   
Hive,WITHOUT_CLASSIFICATION,//  Set output column vector entry.  Since we have one output column the logical index = 0. 
Hive,WITHOUT_CLASSIFICATION,//  More than 38 digits. 
Hive,WITHOUT_CLASSIFICATION,//  Third time. 
Hive,WITHOUT_CLASSIFICATION,//  get all parent tasks 
Hive,WITHOUT_CLASSIFICATION,//  check if the columns as well as value types in the partition() clause are valid 
Hive,WITHOUT_CLASSIFICATION,//  Setup timeouts for various services. 
Hive,WITHOUT_CLASSIFICATION,//  Declared cursor 
Hive,WITHOUT_CLASSIFICATION,//  fields populated from builder 
Hive,WITHOUT_CLASSIFICATION,//  Simple implementation for now - currently Parquet uses heap buffers. 
Hive,WITHOUT_CLASSIFICATION,//  Start the CachedStore update service 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: OldHiveDecimal.toFormatString returns decimal strings with more than > 38 digits! 
Hive,WITHOUT_CLASSIFICATION,//  This method should not by synchronized. Can lead to deadlocks since it calls a sync method.   Meanwhile the scheduler could try updating states via a synchronized method. 
Hive,WITHOUT_CLASSIFICATION,// gets S lock on T8 
Hive,WITHOUT_CLASSIFICATION,//  If table properties do not match we currently do not merge 
Hive,WITHOUT_CLASSIFICATION,//  Build a map to map the original FileSinkOperator and the cloned FileSinkOperators 
Hive,WITHOUT_CLASSIFICATION,//  optional bytes history_text = 3; 
Hive,WITHOUT_CLASSIFICATION,//  load data into table   NOTE: filepath has to be local to the hive server 
Hive,WITHOUT_CLASSIFICATION,/*      * Challenge: How to do the math to get this raw binary back to our decimal form.     *     * Briefly for the middle and upper binary words convert the middle/upper word into a decimal     * long words and then multiply those by the binary word's power of 2.     *     * And add the multiply results into the result decimal longwords.     *      */
Hive,WITHOUT_CLASSIFICATION,//  since we only have one MM table with data - we don't compact MM tables. 
Hive,WITHOUT_CLASSIFICATION,// If so peel off. Otherwise return itself. 
Hive,WITHOUT_CLASSIFICATION,//  Not valid range add to residual 
Hive,WITHOUT_CLASSIFICATION,// gets S lock on T7 
Hive,WITHOUT_CLASSIFICATION,//  total characters = 13; byte length = 24 
Hive,WITHOUT_CLASSIFICATION,//  test with schema evolution and include 
Hive,WITHOUT_CLASSIFICATION,//  Also creates the root directory 
Hive,WITHOUT_CLASSIFICATION,//  if admin has already customized this list honor that 
Hive,WITHOUT_CLASSIFICATION,//  Try with supplementary characters 
Hive,WITHOUT_CLASSIFICATION,//  if the max column width is too large reset it to max allowed Column width 
Hive,WITHOUT_CLASSIFICATION,//  1. gather references from original query   This is a map from aliases to references.   We keep all references as we will need to modify them after creating 
Hive,WITHOUT_CLASSIFICATION,//  Already verified that we should have the rowId mapping 
Hive,WITHOUT_CLASSIFICATION,//  add this task into task tree   set all parent tasks 
Hive,WITHOUT_CLASSIFICATION,//  if this filter is generated one predicates need not to be extracted 
Hive,WITHOUT_CLASSIFICATION,//  two int   one double   two Random 
Hive,WITHOUT_CLASSIFICATION,//   Since partVal is a constant it is safe to cast ExprNodeDesc to ExprNodeConstantDesc.    Its value should be in normalized format (e.g. no leading zero in integer date is in    format of YYYY-MM-DD etc) 
Hive,WITHOUT_CLASSIFICATION,//  select count(1) 
Hive,WITHOUT_CLASSIFICATION,//  essential properties that shouldn't be overridden by users 
Hive,WITHOUT_CLASSIFICATION,//  CATALOG_NAME 
Hive,WITHOUT_CLASSIFICATION,//  don't generate for null-safes. 
Hive,WITHOUT_CLASSIFICATION,//  Temporary map so we only create one partition context entry. 
Hive,WITHOUT_CLASSIFICATION,// for minor compaction there is no progress report and we don't filter deltas 
Hive,WITHOUT_CLASSIFICATION,//  this as is so the functionality matches. 
Hive,WITHOUT_CLASSIFICATION,// gets S lock on T6 
Hive,WITHOUT_CLASSIFICATION,//  add writer.time.zone property to file metadata 
Hive,WITHOUT_CLASSIFICATION,// add all function arguments to a map 
Hive,WITHOUT_CLASSIFICATION,//  set to 1 for single threading 
Hive,WITHOUT_CLASSIFICATION,//  just write out the value as-is 
Hive,WITHOUT_CLASSIFICATION,//  Now read the relative offset to next record. Next record is always before the 
Hive,WITHOUT_CLASSIFICATION,//  // This may happen for queries like select 1; (no source table) 
Hive,WITHOUT_CLASSIFICATION,//  we can now retry adding key/value into hash which is flushed.   but for simplicity just forward them 
Hive,WITHOUT_CLASSIFICATION,// create LazyBinary initialed with inputBA 
Hive,WITHOUT_CLASSIFICATION,//  It is weird but we need a placeholder   otherwise rename cannot move file to the right place 
Hive,WITHOUT_CLASSIFICATION,//  Check for it to be recreated. 
Hive,WITHOUT_CLASSIFICATION,// catch InterruptedException to make sure locks can be released when the query is cancelled. 
Hive,WITHOUT_CLASSIFICATION,//  Read "tbl2" via CachedStore 
Hive,WITHOUT_CLASSIFICATION,//  Should never reach here unless there were no failed tasks. 
Hive,WITHOUT_CLASSIFICATION,/*    * TODO: Some thoughts here : We have a current todo to move some of these methods over to   * MessageFactory instead of being here so we can override them but before we move them over   * we should keep the following in mind:   *   * a) We should return Iterables not Lists. That makes sure that we can be memory-safe when   * implementing it rather than forcing ourselves down a path wherein returning List is part of   * our interface and then people use .size() or somesuch which makes us need to materialize   * the entire list and not change. Also returning Iterables allows us to do things like   * Iterables.transform for some of these.   * b) We should not have "magic" names like "tableObjJson" because that breaks expectation of a   * couple of things - firstly that of serialization format although that is fine for this   * JSONMessageFactory and secondly that makes us just have a number of mappings one for each   * obj type and sometimes as the case is with alter have multiples. Also any event-specific   * item belongs in that event message / event itself as opposed to in the factory. It's okay to   * have utility accessor methods here that are used by each of the messages to provide accessors.   * I'm adding a couple of those here.   *    */
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:UpdateQueryResponseProto) 
Hive,WITHOUT_CLASSIFICATION,//  IDs used to ensure two TaskInfos are different without using the underlying task instance. 
Hive,WITHOUT_CLASSIFICATION,//  LazyString has no so-called NULL sequence. The value is empty string if not. 
Hive,WITHOUT_CLASSIFICATION,//  default is to return earliest possible state. 
Hive,WITHOUT_CLASSIFICATION,//  if they are different we throw an error 
Hive,WITHOUT_CLASSIFICATION,//  Check for timed out remote workers. 
Hive,WITHOUT_CLASSIFICATION,//  Returns the result File object which will contain the query results 
Hive,WITHOUT_CLASSIFICATION,//  Try to merge multiple ranges together 
Hive,WITHOUT_CLASSIFICATION,//  If it's a void we change the type to a byte because once the types   are run through getCommonClass() a byte and any other type T will   resolve to type T 
Hive,WITHOUT_CLASSIFICATION,//  Methods to set/reset caller checker 
Hive,WITHOUT_CLASSIFICATION,//  - Semi-shared for UPDATE/DELETE. 
Hive,WITHOUT_CLASSIFICATION,//  Extrapolation is not needed. 
Hive,WITHOUT_CLASSIFICATION,//  COL_STATS 
Hive,WITHOUT_CLASSIFICATION,//  the vertex that this operator output to 
Hive,WITHOUT_CLASSIFICATION,//  We assume here nobody will try to get session before open() returns. 
Hive,WITHOUT_CLASSIFICATION,//  Create a list of topOp nodes 
Hive,WITHOUT_CLASSIFICATION,//  Implicitly handles users providing invalid authorizations 
Hive,WITHOUT_CLASSIFICATION,//  Storage is instantiated in the constructor 
Hive,WITHOUT_CLASSIFICATION,//  The list of expressions after SELECT or SELECT TRANSFORM. 
Hive,WITHOUT_CLASSIFICATION,//  quotes to use for quoting tables where necessary 
Hive,WITHOUT_CLASSIFICATION,//  8. Handle all the get/reuse requests. We won't actually give out anything here but merely      map all the requests and place them in an appropriate order in pool queues. The only      exception is the reuse without queue contention; can be granted immediately. If we can't      reuse the session immediately we will convert the reuse to a normal get because we 
Hive,WITHOUT_CLASSIFICATION,//  For ORC & Parquet all the following statements are the same   ANALYZE TABLE T [PARTITION (...)] COMPUTE STATISTICS   ANALYZE TABLE T [PARTITION (...)] COMPUTE STATISTICS noscan; 
Hive,WITHOUT_CLASSIFICATION,//  Group stats by colName for each partition 
Hive,WITHOUT_CLASSIFICATION,//  FINGERPRINT 
Hive,WITHOUT_CLASSIFICATION,//  Run this optimization early since it is expanding the operator pipeline. 
Hive,WITHOUT_CLASSIFICATION,//  the inputOps in this vertex. 
Hive,WITHOUT_CLASSIFICATION,//  MY_ENUM_STRINGLIST_MAP 
Hive,WITHOUT_CLASSIFICATION,//  1 read database auth calls for each authorization provider 
Hive,WITHOUT_CLASSIFICATION,//  Returning either a vectorized or non-vectorized reader from the same call requires breaking 
Hive,WITHOUT_CLASSIFICATION,//  we need to fill MapWork with 'local' work and bucket information for SMB Join. 
Hive,WITHOUT_CLASSIFICATION,//  count how many fields are there 
Hive,WITHOUT_CLASSIFICATION,//  prevents under subscription 
Hive,WITHOUT_CLASSIFICATION,//  this may happen if we are not projecting any column from current operator   think count(*) where we are projecting rows without any columns   in such a case we estimate empty row to be of size of empty java object. 
Hive,WITHOUT_CLASSIFICATION,/*  Use a large prime number as a seed to the random number generator.     * Java's random number generator uses the Linear Congruential Generator to generate random     * numbers using the following recurrence relation     *     * X(n+1) = (a X(n) + c ) mod m     *     *  where X0 is the seed. Java implementation uses m = 2^48. This is problematic because 2^48     *  is not a prime number and hence the set of numbers from 0 to m don't form a finite field.     *  If these numbers don't come from a finite field any give X(n) and X(n+1) may not be pair     *  wise independent.     *     *  However empirically passing in prime numbers as seeds seems to work better than when passing     *  composite numbers as seeds. Ideally Java's Random should pick m such that m is prime.     *      */
Hive,WITHOUT_CLASSIFICATION,//  Initialize an indexBuilder for deleteEvents. (HIVE-17284) 
Hive,WITHOUT_CLASSIFICATION,//  Sampling predicates can be merged with predicates from children because PPD/PPR is   already applied. But to clarify the intention of sampling just skips merging. 
Hive,WITHOUT_CLASSIFICATION,//  Don't make any calls but catalog calls until the catalog has been created as we just told 
Hive,WITHOUT_CLASSIFICATION,/*    * Relative end position of the windowing. Can be negative.    */
Hive,WITHOUT_CLASSIFICATION,//  isolate query conf 
Hive,WITHOUT_CLASSIFICATION,//  show partition level privileges 
Hive,WITHOUT_CLASSIFICATION,//  The way this works is as such. originalColumnNames is the equivalent on getNeededColumns   from TSOP. They are assumed to be in the same order as the columns in ORC file AND they are   assumed to be equivalent to the columns in includedColumns (because it was generated from   the same column list at some point in the past) minus the subtype columns. Therefore when   we go thru all the top level ORC file columns that are included in order they match   originalColumnNames. This way we do not depend on names stored inside ORC for SARG leaf   column name resolution (see mapSargColumns method). 
Hive,WITHOUT_CLASSIFICATION,//  1: Create a db after dropping if needed => 1 or 2 events 
Hive,WITHOUT_CLASSIFICATION,//  This submit blocks if no background threads are available to run this operation 
Hive,WITHOUT_CLASSIFICATION,// easier to read logs and for assumption done in replication flow 
Hive,WITHOUT_CLASSIFICATION,// Load Data 
Hive,WITHOUT_CLASSIFICATION,//  We expect all the levels to have items. 
Hive,WITHOUT_CLASSIFICATION,//  2. if returnpath is on and hivetestmode is on bail 
Hive,WITHOUT_CLASSIFICATION,/*  We use the Flajolet-Martin estimator to estimate the number of distinct values.FM uses the   * location of the least significant zero as an estimate of log2(phi*ndvs).    */
Hive,WITHOUT_CLASSIFICATION,//  Use Max-Min Range as NDV gets scaled by selectivity. 
Hive,WITHOUT_CLASSIFICATION,//  Add URI entity for transform script. script assumed t be local unless downloadable 
Hive,WITHOUT_CLASSIFICATION,//  TABLE_CAT   TABLE_SCHEM   TABLE_NAME   COLUMN_NAME   DATA_TYPE   TYPE_NAME   COLUMN_SIZE   BUFFER_LENGTH unused   DECIMAL_DIGITS   NUM_PREC_RADIX 
Hive,WITHOUT_CLASSIFICATION,//  TODO: we could actually store a bit flag in ref indicating whether this is a hash         match or a probe and in the former case use hash bits (for a first few resizes).   int hashCodeOrPart = oldSlot | Ref.getNthHashBit(oldRef startingHashBitCount newHashBitCount); 
Hive,WITHOUT_CLASSIFICATION,//  input aliases of this RS for join (used for PPD) 
Hive,WITHOUT_CLASSIFICATION,//  close the previous fsp as it is no longer needed 
Hive,WITHOUT_CLASSIFICATION,//  Decide skewed value directory selection. 
Hive,WITHOUT_CLASSIFICATION,//  MiniDFSCluster litters files and folders all over the place. 
Hive,WITHOUT_CLASSIFICATION,//  new logic. 
Hive,WITHOUT_CLASSIFICATION,//  Session-scope compile lock. 
Hive,WITHOUT_CLASSIFICATION,//  1 for addition -1 for subtraction 
Hive,WITHOUT_CLASSIFICATION,//  Helper class to set up a ChunkedInput/Output stream for testing 
Hive,WITHOUT_CLASSIFICATION,//  merge currTask from multiple topOps 
Hive,WITHOUT_CLASSIFICATION,//  tblName can be null in cases of Helper being used at a higher   abstraction level such as with datbases 
Hive,WITHOUT_CLASSIFICATION,//  One cannot simply reuse the session if there are other queries waiting; to maintain   fairness we'll try to take a query slot instantly and if that fails we'll return   this session back to the pool and give the user a new session later. 
Hive,WITHOUT_CLASSIFICATION,//  array level 
Hive,WITHOUT_CLASSIFICATION,//  needs to set these values.  We should do the work to detangle this. 
Hive,WITHOUT_CLASSIFICATION,//  Test for aborted transactions 
Hive,WITHOUT_CLASSIFICATION,//  A map from new tags to indices of children of DemuxOperator (the first Operator at the 
Hive,WITHOUT_CLASSIFICATION,/*    * Helper function to create Vertex from MapWork.    */
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) ConstMapContents  */
Hive,WITHOUT_CLASSIFICATION,//  The table has implemented the project in the obvious way - by   creating project with 0 fields. Strip it away and create our own   project with one field. 
Hive,WITHOUT_CLASSIFICATION,//  Escaped byte unescape it. 
Hive,WITHOUT_CLASSIFICATION,//  new merge 
Hive,WITHOUT_CLASSIFICATION,//  We are going to use this counter as a pseudo-random number for the start of the search.   This is to avoid churning at the beginning of the arena all the time. 
Hive,WITHOUT_CLASSIFICATION,// cascade only occurs at table level then cascade to partition level 
Hive,WITHOUT_CLASSIFICATION,//  We remember any matching rows in matchs / matchSize.  At the end of the loop   selected / batch.size will represent both matching and non-matching rows for outer join.   Only deferred rows will have been removed from selected. 
Hive,WITHOUT_CLASSIFICATION,//  pool to min. 
Hive,WITHOUT_CLASSIFICATION,//  Check for NULL's just to be safe 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) Function  */
Hive,WITHOUT_CLASSIFICATION,//  TODO: check view references too 
Hive,WITHOUT_CLASSIFICATION,//  special handling for count similar to PlanModifierForASTConv::replaceEmptyGroupAggr() 
Hive,WITHOUT_CLASSIFICATION,//  index has to be a primitive 
Hive,WITHOUT_CLASSIFICATION,// to get all partitions 
Hive,WITHOUT_CLASSIFICATION,//  in it. 
Hive,WITHOUT_CLASSIFICATION,//  parent in current pipeline 
Hive,WITHOUT_CLASSIFICATION,/*    * Generate the map-side GroupByOperator for the Query Block   * (qb.getParseInfo().getXXX(dest)). The new GroupByOperator will be a child   * of the inputOperatorInfo.   *   * @param mode   *          The mode of the aggregation (HASH)   * @param genericUDAFEvaluators   *          If not null this function will store the mapping from Aggregation   *          StringTree to the genericUDAFEvaluator in this parameter so it   *          can be used in the next-stage GroupBy aggregations.   * @return the new GroupByOperator    */
Hive,WITHOUT_CLASSIFICATION,//  Meanwhile the init succeeds! 
Hive,WITHOUT_CLASSIFICATION,//  Save away the original AST 
Hive,WITHOUT_CLASSIFICATION,//  End serves as final separator. 
Hive,WITHOUT_CLASSIFICATION,//  safely sorting 
Hive,WITHOUT_CLASSIFICATION,//  Logger with int base 
Hive,WITHOUT_CLASSIFICATION,//  if not it should be value 
Hive,WITHOUT_CLASSIFICATION,//  Don't try to operate with less than MIN_SIZE allocator space it will just give you grief. 
Hive,WITHOUT_CLASSIFICATION,//  get the number retries 
Hive,WITHOUT_CLASSIFICATION,//  isExternal: set to false here can be overwritten by the IMPORT stmt 
Hive,WITHOUT_CLASSIFICATION,//  Is this a map type? 
Hive,WITHOUT_CLASSIFICATION,//  Truncate a table in the wrong catalog 
Hive,WITHOUT_CLASSIFICATION,//  Zero special case. 
Hive,WITHOUT_CLASSIFICATION,//  unique key of the filterInputRel 
Hive,WITHOUT_CLASSIFICATION,//  Already visited 
Hive,WITHOUT_CLASSIFICATION,//  allocate map bucket id to grouped splits 
Hive,WITHOUT_CLASSIFICATION,// See the javadoc on HiveOutputFormatImpl and HadoopShims.prepareJobOutput() 
Hive,WITHOUT_CLASSIFICATION,//  When comparing the CompressedOwid the one with the lesser value is smaller. 
Hive,WITHOUT_CLASSIFICATION,//  materialized views 
Hive,WITHOUT_CLASSIFICATION,//  The name of the Hive column 
Hive,WITHOUT_CLASSIFICATION,//  update partition column info in FS descriptor 
Hive,WITHOUT_CLASSIFICATION,//  current code version   data's version   data's FC version 
Hive,WITHOUT_CLASSIFICATION,//  do we need to flatten? 
Hive,WITHOUT_CLASSIFICATION,// this can be reasonable for an empty txn START/COMMIT or read-only txn  also an IUD with DP that didn't match any rows. 
Hive,WITHOUT_CLASSIFICATION,//  Impossible to get ranges for row <= 'aaa' and row >= 'bbb' 
Hive,WITHOUT_CLASSIFICATION,//  whether the sub-directory has any file 
Hive,WITHOUT_CLASSIFICATION,//  3) rename the partition directory if it is not an external table 
Hive,WITHOUT_CLASSIFICATION,//  Create the mapping between the output of the old correlation rel 
Hive,WITHOUT_CLASSIFICATION,//    scale = 2 length = 6 value = -6065716379.11     \002\006\255\114\197\131\083\105             \255\114\197\131\083\105 
Hive,WITHOUT_CLASSIFICATION,//  If we have a connection error the JDO connection URL hook might 
Hive,WITHOUT_CLASSIFICATION,//  With this option we're assuming that the external application   using the JDBC driver has done a JAAS kerberos login already 
Hive,WITHOUT_CLASSIFICATION,//  Naked E/e. 
Hive,WITHOUT_CLASSIFICATION,//  By setting the comparison to greater the search should use the block [0 50] 
Hive,WITHOUT_CLASSIFICATION,//  Output is type HiveIntervalDayTime. 
Hive,WITHOUT_CLASSIFICATION,/*    * These members hold the current value that was read when readNextField return false.    */
Hive,WITHOUT_CLASSIFICATION,/*       * We add filters for each of the URIs supported by templeton.     * If we added the entire sub-structure using '/*' the mapreduce      * notification cannot give the callback to templeton in secure mode.     * This is because mapreduce does not use secure credentials for      * callbacks. So jetty would fail the request as unauthorized.      */
Hive,WITHOUT_CLASSIFICATION,//  Turn off client-side authorization 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   required   required   required   required   required   required   required 
Hive,WITHOUT_CLASSIFICATION,//  FOREIGN_TABLE_NAME 
Hive,WITHOUT_CLASSIFICATION,//  Handled later only struct will be supported. 
Hive,WITHOUT_CLASSIFICATION,//  This starts the reader in the background. 
Hive,WITHOUT_CLASSIFICATION,/* (non-Javadoc)   * Serializes one int part into the given @{link #ByteBuffer}    *  considering two's complement for negatives.    */
Hive,WITHOUT_CLASSIFICATION,//  If the sorted columns can't all be found in the values then the data is only sorted on   the columns seen up until now 
Hive,WITHOUT_CLASSIFICATION,// for each bucket file only keep its base files and store into a new list. 
Hive,WITHOUT_CLASSIFICATION,//  Wait until either all messages are processed or a maximum time limit is reached. 
Hive,WITHOUT_CLASSIFICATION,//  This time it fails when try to load the foreign key constraints. All other constraints are loaded. 
Hive,WITHOUT_CLASSIFICATION,/*    * Create the additional vectorization PTF information needed by the VectorPTFOperator during   * execution.    */
Hive,WITHOUT_CLASSIFICATION,//  Is there anything to check here? 
Hive,WITHOUT_CLASSIFICATION,//  combine all predicates into a single expression 
Hive,WITHOUT_CLASSIFICATION,// An LRU cache using a linked hash map 
Hive,WITHOUT_CLASSIFICATION,//  THROW_EXCEPTION 
Hive,WITHOUT_CLASSIFICATION,//  Get group-by keys and store in reduceKeys 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) Async  */
Hive,WITHOUT_CLASSIFICATION,//  TODO: To make it work for JDK9 use CleanerUtil from https://issues.apache.org/jira/browse/HADOOP-12760 
Hive,WITHOUT_CLASSIFICATION,//  SERDE_INFO 
Hive,WITHOUT_CLASSIFICATION,//  no timeout before reset 
Hive,WITHOUT_CLASSIFICATION,//  Probably the app does not exist 
Hive,WITHOUT_CLASSIFICATION,//  This should not happen we cannot merge 
Hive,WITHOUT_CLASSIFICATION,//  To apply this optimization in the input query:   - There cannot exist any order by/sort by clause   thus existsOrdering should be false.   - There cannot exist any distribute by clause thus   existsPartitioning should be false.   - There cannot exist any cluster by clause thus 
Hive,WITHOUT_CLASSIFICATION,//  Create a table with smallint/tinyint columns load data and query from Hive. 
Hive,WITHOUT_CLASSIFICATION,//  Load conf files 
Hive,WITHOUT_CLASSIFICATION,//  Construct a pattern of the form: partKey=partVal/partKey2=partVal2/...   where partVal is either the escaped partition value given as input   or a regex of the form ".*"   This works because the "=" and "/" separating key names and partition key/values   are not escaped. 
Hive,WITHOUT_CLASSIFICATION,//  Transport would have got closed via client.shutdown() so we dont need this but   just in case we make this call. 
Hive,WITHOUT_CLASSIFICATION,//  (FETCH_FIRST) fetch again from the same operation handle with FETCH_FIRST orientation 
Hive,WITHOUT_CLASSIFICATION,//  Guaranteed flag is inconsistent based on heartbeat - another message should be send. 
Hive,WITHOUT_CLASSIFICATION,//  Note: for now we don't actually pass the queryForCbo to CBO because   it accepts qb not AST and can also access all the private stuff in   SA. We rely on the fact that CBO ignores the unknown tokens (create   table destination) so if the query is otherwise ok it is as if we 
Hive,WITHOUT_CLASSIFICATION,//  match multijoin or join 
Hive,WITHOUT_CLASSIFICATION,//  Missing database in the query 
Hive,WITHOUT_CLASSIFICATION,//  aggregationClasses[i].reset(aggs[i]); 
Hive,WITHOUT_CLASSIFICATION,//  In case the server's idletimeout is set to a lower value it might close it's side of 
Hive,WITHOUT_CLASSIFICATION,//  Init closeable utils in case register is not called (see HIVE-13322) 
Hive,WITHOUT_CLASSIFICATION,//  where null is same as where false 
Hive,WITHOUT_CLASSIFICATION,//  The dispatcher fires the processor corresponding to the closest   matching rule and passes the context along 
Hive,WITHOUT_CLASSIFICATION,//  typically target/tmp   typically target 
Hive,WITHOUT_CLASSIFICATION,// return as no further processing is needed 
Hive,WITHOUT_CLASSIFICATION,//  Once the lines of the log file have been fed into the ErrorHeuristics   see if they have detected anything. If any has record   what ErrorAndSolution it gave so we can later return the most 
Hive,WITHOUT_CLASSIFICATION,//  Type checking and implicit type conversion for join keys 
Hive,WITHOUT_CLASSIFICATION,//  supported 
Hive,WITHOUT_CLASSIFICATION,//  recursively remove task from its children tasks if this task doesn't have any parent task 
Hive,WITHOUT_CLASSIFICATION,/*  * This is a plug-able policy to chose the candidate map-join table for converting a join to a * sort merge join. The policy can decide the big table position. Some of the existing policies * decide the big table based on size or position of the tables.  */
Hive,WITHOUT_CLASSIFICATION,//  if true prune it 
Hive,WITHOUT_CLASSIFICATION,//  This will return null if the metastore is not being accessed from a metastore Thrift server   or if the TTransport being used to connect is not an instance of TSocket or if kereberos 
Hive,WITHOUT_CLASSIFICATION,//  FILTER 
Hive,WITHOUT_CLASSIFICATION,//  Adjust right collation 
Hive,WITHOUT_CLASSIFICATION,//  Aggregation buffer methods. We wrap GenericUDAFHistogramNumeric's aggregation buffer 
Hive,WITHOUT_CLASSIFICATION,//  the partitions used. 
Hive,WITHOUT_CLASSIFICATION,//  write a delta file in partition 0 
Hive,WITHOUT_CLASSIFICATION,//  set hiveLockMgr to null just in case this invalid manager got set to   next query's ctx. 
Hive,WITHOUT_CLASSIFICATION,//  session string is supposed to be unique so its got to be of some reasonable size 
Hive,WITHOUT_CLASSIFICATION,//  Put 2 records into COMPACTION_QUEUE and do nothing 
Hive,WITHOUT_CLASSIFICATION,//  last split 
Hive,WITHOUT_CLASSIFICATION,//  Location of JSON file 
Hive,WITHOUT_CLASSIFICATION,// CLOSED state not interesting state before (FINISHED ERROR) is. 
Hive,WITHOUT_CLASSIFICATION,//  distributed attribute with N1 * ... * Nm distinct values. 
Hive,WITHOUT_CLASSIFICATION,//  In case of failure send back whatever is constructed so far -   which would be from the AppReport 
Hive,WITHOUT_CLASSIFICATION,//  Load the version stored in the metastore db 
Hive,WITHOUT_CLASSIFICATION,//  MapJoin 
Hive,WITHOUT_CLASSIFICATION,//  Create the parents first 
Hive,WITHOUT_CLASSIFICATION,//  Set the default. 
Hive,WITHOUT_CLASSIFICATION,//  store partition key expr in map-work 
Hive,WITHOUT_CLASSIFICATION,//  set the extra fields to null 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(enum_scope:SourceStateProto) 
Hive,WITHOUT_CLASSIFICATION,/*       We are doing this both in load table and load partitions        */
Hive,WITHOUT_CLASSIFICATION,//  using vint instead of 4 bytes   Parse the first byte of a vint/vlong to determine the number of bytes. 
Hive,WITHOUT_CLASSIFICATION,//  poll the Tasks to see which one completed 
Hive,WITHOUT_CLASSIFICATION,//  8. Generate column access stats if required - wait until column pruning 
Hive,WITHOUT_CLASSIFICATION,/* use DDL_EXCLUSIVE to cause X lock to prevent races between concurrent add partition calls        with IF NOT EXISTS.  w/o this 2 concurrent calls to add the same partition may both add        data since for transactional tables creating partition metadata and moving data there are        2 separate actions.  */
Hive,WITHOUT_CLASSIFICATION,//  NULL out the remaining columns. 
Hive,WITHOUT_CLASSIFICATION,//   endReason shows up as OTHER for CONTAINER_TIME_OUT 
Hive,WITHOUT_CLASSIFICATION,//  First 10 calls to resultSet.next() should return true 
Hive,WITHOUT_CLASSIFICATION,//  if parent statistics is null then that branch of the tree is not   walked yet. don't update the stats until all branches are walked 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree)  */
Hive,WITHOUT_CLASSIFICATION,//  Retrieve stats from metastore 
Hive,WITHOUT_CLASSIFICATION,// Aborted is a terminal state so nothing about the txn can change  after that so READ COMMITTED is sufficient. 
Hive,WITHOUT_CLASSIFICATION,//  while we scan the css we also get the densityAvg lowerbound and 
Hive,WITHOUT_CLASSIFICATION,//  Processing directories 
Hive,WITHOUT_CLASSIFICATION,//  Test a set of random multiplications at high precision. 
Hive,WITHOUT_CLASSIFICATION,//  enable read authorization in metastore 
Hive,WITHOUT_CLASSIFICATION,//  fetch the xml tag <dogc>xxx</dogc> 
Hive,WITHOUT_CLASSIFICATION,//  destination hash partition has just be spilled 
Hive,WITHOUT_CLASSIFICATION,//  Validate mainly for includes / excludes working as they should. 
Hive,WITHOUT_CLASSIFICATION,//  We could rewrite into a subquery 
Hive,WITHOUT_CLASSIFICATION,//  check if there are IOExceptions 
Hive,WITHOUT_CLASSIFICATION,//  rightInputRel has this shape:           Filter (references corvar) 
Hive,WITHOUT_CLASSIFICATION,//  Total Free Memory = maxMemory() - Used Memory; 
Hive,WITHOUT_CLASSIFICATION,//  notice that command line options take precedence over the   deprecated (old style) naked args... 
Hive,WITHOUT_CLASSIFICATION,//  Update top Project positions 
Hive,WITHOUT_CLASSIFICATION,//  Second input parameter but 3rd column. 
Hive,WITHOUT_CLASSIFICATION,//  Refer to Flajolet-Martin'86 for the value of phi 
Hive,WITHOUT_CLASSIFICATION,//  Double-check. 
Hive,WITHOUT_CLASSIFICATION,// ---------------------------------------------------------------------------   Process Single-Column Long Left-Semi Join on a vectorized row batch.   
Hive,WITHOUT_CLASSIFICATION,//  range of register index bits 
Hive,WITHOUT_CLASSIFICATION,//  empty keyset is basically () 
Hive,WITHOUT_CLASSIFICATION,//  from ZooKeeperMain private method 
Hive,WITHOUT_CLASSIFICATION,//  Lump all partitions outside the tablePath into one PartSpec. 
Hive,WITHOUT_CLASSIFICATION,//  Drop a table from the wrong catalog 
Hive,WITHOUT_CLASSIFICATION,/*     * the table name can potentially be a dot-format one with column names    * specified as part of the table name. e.g. a.b.c where b is a column in    * a and c is a field of the object/column b etc. For authorization    * purposes we should use only the first part of the dotted name format.    *     */
Hive,WITHOUT_CLASSIFICATION,//  The following fields specify the criteria on objects for this priv to be required 
Hive,WITHOUT_CLASSIFICATION,//  The session will go to B with the new mapping; check it. 
Hive,WITHOUT_CLASSIFICATION,//  First let's try connecting using the last successful url - if that fails then we error out. 
Hive,WITHOUT_CLASSIFICATION,//  Use QueryCompleteRequestProto.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,//  set alias to size mapping this can be used to determine if one table   is chosen as big table what's the total size of left tables which 
Hive,WITHOUT_CLASSIFICATION,//  Set some conf parameters 
Hive,WITHOUT_CLASSIFICATION,//  empty regex (should be one WARN message) 
Hive,WITHOUT_CLASSIFICATION,//  invariant: k1.size == k2.size 
Hive,WITHOUT_CLASSIFICATION,//  Generate split strategy for non-acid schema original files if any. 
Hive,WITHOUT_CLASSIFICATION,//  Add the group by expressions 
Hive,WITHOUT_CLASSIFICATION,//  4. Delete unneeded directories that were replaced by other ones via reopen. 
Hive,WITHOUT_CLASSIFICATION,//  verify output 
Hive,WITHOUT_CLASSIFICATION,//  class TransactionBatchImpl 
Hive,WITHOUT_CLASSIFICATION,//  which affects the locality matching 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Statement#getConnection()    */
Hive,WITHOUT_CLASSIFICATION,/*  Return false if any input column is non-repeating otherwise true.   * This returns false if all the arguments are constant or there   * are zero arguments.   *   * A possible future optimization is to set the output to isRepeating   * for cases of all-constant arguments for deterministic functions.    */
Hive,WITHOUT_CLASSIFICATION,//  modifying the meastore.uri property 
Hive,WITHOUT_CLASSIFICATION,//  output job properties 
Hive,WITHOUT_CLASSIFICATION,//  Start with the destination: T2 bucketed/sorted position is [1]   At the source T1 the column corresponding to that position is [key] which   maps to column [0] of T1 which is also bucketed/sorted into the same 
Hive,WITHOUT_CLASSIFICATION,//  Vectorization should be the last optimization because it doesn't modify the plan   or any operators. It makes a very low level transformation to the expressions to 
Hive,WITHOUT_CLASSIFICATION,//  3. analyze create view command 
Hive,WITHOUT_CLASSIFICATION,//  Matches only GroupByOperators which are reducers rather than map group by operators 
Hive,WITHOUT_CLASSIFICATION,//  check the local work 
Hive,WITHOUT_CLASSIFICATION,//  this is changed to be *under* tmp dir   not sure if this will have any effect.. 
Hive,WITHOUT_CLASSIFICATION,// so just pass everything that syntax supports. 
Hive,WITHOUT_CLASSIFICATION,/*    * Spill.    */
Hive,WITHOUT_CLASSIFICATION,//  The lock may have multiple components e.g. DbHiveLock hence we need   to check for each of them 
Hive,WITHOUT_CLASSIFICATION,//  check that the error code is present in the error description:  
Hive,WITHOUT_CLASSIFICATION,//  encountered column or field which cannot be found in sources 
Hive,WITHOUT_CLASSIFICATION,// todo: HIVE-16952 
Hive,WITHOUT_CLASSIFICATION,// txnid:1 
Hive,WITHOUT_CLASSIFICATION,//  mGby2 ---already contains key remove distinct and change all the others 
Hive,WITHOUT_CLASSIFICATION,//  TODO: allow defaults for e.g. scheduling policy. 
Hive,WITHOUT_CLASSIFICATION,//  Someone is using this buffer; eventually it will be evicted. 
Hive,WITHOUT_CLASSIFICATION,//  3. IO cost = cost of writing intermediary results to local FS +                cost of reading from local FS for transferring to join + 
Hive,WITHOUT_CLASSIFICATION,//  This time it completes by adding just constraints for table t4. 
Hive,WITHOUT_CLASSIFICATION,//  3. For uncompressed case we need some special processing before read.      Basically we are trying to create artificial consistent ranges to cache as there are      no CBs in an uncompressed file. At the end of this processing the list would contain      either cache buffers or buffers allocated by us and not cached (if we are only reading      parts of the data for some ranges and don't want to cache it). Both are represented by 
Hive,WITHOUT_CLASSIFICATION,//  Recursively going into ObjectInspector structure 
Hive,WITHOUT_CLASSIFICATION,//  Set "global" separator member to next level. 
Hive,WITHOUT_CLASSIFICATION,//  Generate a split for any buckets that weren't covered.   This happens in the case where a bucket just has deltas and no 
Hive,WITHOUT_CLASSIFICATION,//  to introduce some randomness and to avoid hammering the metastore at the same time (same logic as DbTxnManager) 
Hive,WITHOUT_CLASSIFICATION,//  Convert everything to writable if types of arguments are the same   but ObjectInspectors are different. 
Hive,WITHOUT_CLASSIFICATION,//  First $ separated substring would be txnId and the rest are ValidReaderWriteIdList 
Hive,WITHOUT_CLASSIFICATION,//  re-run insert into but this time no new partitions will be created so there will be no violation 
Hive,WITHOUT_CLASSIFICATION,//  object that we added to the cache 
Hive,WITHOUT_CLASSIFICATION,//  or multi group by optimization specific operators 
Hive,WITHOUT_CLASSIFICATION,//  drop in case leftover from unsuccessful run 
Hive,WITHOUT_CLASSIFICATION,//  String 
Hive,WITHOUT_CLASSIFICATION,// -1 because 'null' literal doesn't work for all DBs... 
Hive,WITHOUT_CLASSIFICATION,//  get new location 
Hive,WITHOUT_CLASSIFICATION,//  We're looking for the udf with the smallest maximum numeric type. 
Hive,WITHOUT_CLASSIFICATION,//  partition can be archived if during recovery 
Hive,WITHOUT_CLASSIFICATION,//  if encoding is still SPARSE use linear counting with increase   accuracy (as we use pPrime bits for register index) 
Hive,WITHOUT_CLASSIFICATION,//  test the UDF adaptor for a generic UDF (as opposed to a legacy UDF) 
Hive,WITHOUT_CLASSIFICATION,//  Annotation OP tree with statistics 
Hive,WITHOUT_CLASSIFICATION,//  Add the reducer 
Hive,WITHOUT_CLASSIFICATION,//  Flush here if the memory usage is too high. After that we have the entire 
Hive,WITHOUT_CLASSIFICATION,//  we are provided with a prefix 
Hive,WITHOUT_CLASSIFICATION,//  create an external table 
Hive,WITHOUT_CLASSIFICATION,//  Test that adding a jar to the remote context makes it show up in the classpath. 
Hive,WITHOUT_CLASSIFICATION,//  Open a txn which allocate write ID and remain open state. 
Hive,WITHOUT_CLASSIFICATION,//  if map mode run iff work is map work 
Hive,WITHOUT_CLASSIFICATION,//  -Xmx specified in MB 
Hive,WITHOUT_CLASSIFICATION,//  The current txn is either in open or aborted state. 
Hive,WITHOUT_CLASSIFICATION,//  Stub out a mocked Helper instance 
Hive,WITHOUT_CLASSIFICATION,//  prep 
Hive,WITHOUT_CLASSIFICATION,//  Call ReduceSinkOperator with new input inspector. 
Hive,WITHOUT_CLASSIFICATION,//  Set timezone based on user timezone if origin is not already set   as it is default Hive time semantics to consider user timezone. 
Hive,WITHOUT_CLASSIFICATION,//  reconstruct the sparse map from delta encoded and varint input stream 
Hive,WITHOUT_CLASSIFICATION,//  For each field 
Hive,WITHOUT_CLASSIFICATION,//  If stats are not available just assume its a useful edge 
Hive,WITHOUT_CLASSIFICATION,//  let's see if doubles work ok 
Hive,WITHOUT_CLASSIFICATION,//  JAVA 
Hive,WITHOUT_CLASSIFICATION,//  If currRecord >= numRecords we have already fetched the top #numRecords 
Hive,WITHOUT_CLASSIFICATION,//  Alias to operator map from the semantic analyzer. 
Hive,WITHOUT_CLASSIFICATION,//  to output batch scratch columns for the small table portion. 
Hive,WITHOUT_CLASSIFICATION,//  All the parents are locked in shared mode 
Hive,WITHOUT_CLASSIFICATION,//  as a backup task. 
Hive,WITHOUT_CLASSIFICATION,//  connect using token via Beeline with inputStream 
Hive,WITHOUT_CLASSIFICATION,//  This is to test session temporary files are cleaned up after HIVE-11768 
Hive,WITHOUT_CLASSIFICATION,//  TOK_DESTINATION TOK_TAB TOK_TABNAME <materialization_name> 
Hive,WITHOUT_CLASSIFICATION,//  the caller needs to gurrantee that they are the same type based on numBitVectors 
Hive,WITHOUT_CLASSIFICATION,//  10^38 - 1 
Hive,WITHOUT_CLASSIFICATION,//  No action. 
Hive,WITHOUT_CLASSIFICATION,//  once SessionState for thread is set CliDriver picks conf from it 
Hive,WITHOUT_CLASSIFICATION,//  Minute granularity 
Hive,WITHOUT_CLASSIFICATION,//  MAX 
Hive,WITHOUT_CLASSIFICATION,//  only first call throws exception 
Hive,WITHOUT_CLASSIFICATION,/*          * isDead is only set internally by this class.  {@link #markDead(boolean)} will abort all         * remaining txns so make this no-op to make sure that a well-behaved client that calls abortTransaction()         * error doesn't get misleading errors          */
Hive,WITHOUT_CLASSIFICATION,//  handle secure connection if specified 
Hive,WITHOUT_CLASSIFICATION,//  Test a normal retriable client 
Hive,WITHOUT_CLASSIFICATION,/*      * 1. Walk RelNode Graph; note from where gBy.. nodes.      */
Hive,WITHOUT_CLASSIFICATION,//  take a look to see if it is escaped 
Hive,WITHOUT_CLASSIFICATION,//  Updating several local structures 
Hive,WITHOUT_CLASSIFICATION,//  Unwrap the tuple. 
Hive,WITHOUT_CLASSIFICATION,//  now rewrite the plan to     Project-A' (all LHS plus transformed original projections               replacing references to count() with case statement)     Correlator(left correlation condition = true)       LeftInputRel       Aggregate (groupby (0) agg0() agg1()...) 
Hive,WITHOUT_CLASSIFICATION,//  all the inputs for the tez processor 
Hive,WITHOUT_CLASSIFICATION,//  write fourth byte of header 
Hive,WITHOUT_CLASSIFICATION,/*    * Deserializes 64-bit decimals up to the maximum 64-bit precision (18 decimal digits).   *   * NOTE: Major assumption: the input decimal64 has already been bounds checked and a least   * has a precision <= DECIMAL64_DECIMAL_DIGITS.  We do not bounds check here for better   * performance.    */
Hive,WITHOUT_CLASSIFICATION,//  Unregister from the AMReporter since the task is now running. 
Hive,WITHOUT_CLASSIFICATION,//  Just to trigger auto creation of needed metastore tables 
Hive,WITHOUT_CLASSIFICATION,// not partitioned 
Hive,WITHOUT_CLASSIFICATION,// txnid:4 
Hive,WITHOUT_CLASSIFICATION,// make sure 2700 is not the default so that we are testing if tblproperties indeed propagate 
Hive,WITHOUT_CLASSIFICATION,//  This assumes that the LLAP cluster and session are both running under HS2 user. 
Hive,WITHOUT_CLASSIFICATION,//  column stats will be inaccurate 
Hive,WITHOUT_CLASSIFICATION,//  Remove MAP extra level. 
Hive,WITHOUT_CLASSIFICATION,//  make sure REDUCE task environment points to HIVE_JOB_CREDSTORE_PASSWORD 
Hive,WITHOUT_CLASSIFICATION,/*     This is what we expect on disk    ekoifman:warehouse ekoifman$ tree nonacidpart/    nonacidpart/    └── p=1    ├── 000000_0    ├── HIVE_UNION_SUBDIR__1    │   └── 000000_0    ├── HIVE_UNION_SUBDIR_2    │   └── 000000_0    └── HIVE_UNION_SUBDIR_3        └── 000000_04 directories 4 files    * */
Hive,WITHOUT_CLASSIFICATION,/*      * Sum input and output are DECIMAL_64.     *     * Any mode (PARTIAL1 PARTIAL2 FINAL COMPLETE).      */
Hive,WITHOUT_CLASSIFICATION,//  finally add the event broadcast operator 
Hive,WITHOUT_CLASSIFICATION,//  means that expression can't be pushed either because it is value in   group by 
Hive,WITHOUT_CLASSIFICATION,//  Convert input arguments to Text if necessary. 
Hive,WITHOUT_CLASSIFICATION,//  If table write ID is already allocated for the given transaction then just use it 
Hive,WITHOUT_CLASSIFICATION,/*    * Once we have decided on the map join the tree would transform from   *   *        |                   |   *       Join               MapJoin   *       / \                /   \   *     RS   RS   --->     RS    TS (big table)   *    /      \           /   *   TS       TS        TS (small table)   *   * for spark.    */
Hive,WITHOUT_CLASSIFICATION,//  Read from the new table 
Hive,WITHOUT_CLASSIFICATION,//  Rest of the types e.g. DATE CHAR VARCHAR etc are already registered 
Hive,WITHOUT_CLASSIFICATION,//  We traverse the leaf nodes of the tree. The stack entries indicate the existing leaf 
Hive,WITHOUT_CLASSIFICATION,//  The byte length of the scratch byte array that needs to be passed to serializationUtilsRead. 
Hive,WITHOUT_CLASSIFICATION,//  Event 8 9 10 
Hive,WITHOUT_CLASSIFICATION,//  Reset the aggregations   For distincts optimization with sorting/bucketing perform partial aggregation 
Hive,WITHOUT_CLASSIFICATION,//  config log4j with customized files 
Hive,WITHOUT_CLASSIFICATION,//  The new session will also go to B now. 
Hive,WITHOUT_CLASSIFICATION,//  Get the Serialization object and the class being deserialized 
Hive,WITHOUT_CLASSIFICATION,//  Kill the VM on second ctrl+c 
Hive,WITHOUT_CLASSIFICATION,//  let the job retry several times which eventually lead to failure. 
Hive,WITHOUT_CLASSIFICATION,//  pRS-cRS-cGBYr (no map aggregation) --> pRS-cGBYr(COMPLETE)   revert expressions of cGBYr to that of cRS 
Hive,WITHOUT_CLASSIFICATION,//  Check if DPP branches are equal 
Hive,WITHOUT_CLASSIFICATION,//  Configure http client for kerberos/password based authentication 
Hive,WITHOUT_CLASSIFICATION,/*  Allow for improved schemes.  */
Hive,WITHOUT_CLASSIFICATION,//  AcidUtils.getAcidState() is already called to verify there is no input split.   Thus for a GroupByOperator summary row set finalDirs and add a Dummy split here. 
Hive,WITHOUT_CLASSIFICATION,//  Discard all the locked blocks. 
Hive,WITHOUT_CLASSIFICATION,//  closeOp can be overriden 
Hive,WITHOUT_CLASSIFICATION,//  TRIGGER_NAME 
Hive,WITHOUT_CLASSIFICATION,//  It's possible that user session is closed while creating Spark client. 
Hive,WITHOUT_CLASSIFICATION,//  Zone part 
Hive,WITHOUT_CLASSIFICATION,// Acid and MM tables support Load Data with transactional semantics.  This will allow Load Data  in a txn assuming we can determine the target is a suitable table type. 
Hive,WITHOUT_CLASSIFICATION,//  All the operators need to be initialized before process 
Hive,WITHOUT_CLASSIFICATION,//  bug if it throws an exception 
Hive,WITHOUT_CLASSIFICATION,//  in reduce side GBY we don't know if the grouping set was present or not. so get it   from map side GBY 
Hive,WITHOUT_CLASSIFICATION,//  Secure the web server with kerberos 
Hive,WITHOUT_CLASSIFICATION,//  Use the new faster hash code since we are hashing memory objects. 
Hive,WITHOUT_CLASSIFICATION,//  should not be allowed after a query complete is received. 
Hive,WITHOUT_CLASSIFICATION,//  whether of pattern "SEL - GBY - DPP" 
Hive,WITHOUT_CLASSIFICATION,//  float 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise we return the expression 
Hive,WITHOUT_CLASSIFICATION,// txnid:9 
Hive,WITHOUT_CLASSIFICATION,//  Open the original path we've been given and find the list of original buckets 
Hive,WITHOUT_CLASSIFICATION,/*      * Determine input type info.      */
Hive,WITHOUT_CLASSIFICATION,//  First get the appropriate field schema for this field 
Hive,WITHOUT_CLASSIFICATION,//  call the actual operator initialization function 
Hive,WITHOUT_CLASSIFICATION,//  from ZooKeeperHiveLockManager 
Hive,WITHOUT_CLASSIFICATION,//  The set of virtual columns that vectorized readers *MAY* support. 
Hive,WITHOUT_CLASSIFICATION,//  Verify that if environment context has STATS_GENERATED set to task 
Hive,WITHOUT_CLASSIFICATION,//  Extract innerRecord field refs 
Hive,WITHOUT_CLASSIFICATION,//  pmod calculation can overflow based on the type of arguments   casting the arguments according to outputTypeInfo so that the   results match with GenericUDFPosMod implementation 
Hive,WITHOUT_CLASSIFICATION,//  Change connector if SSL is used 
Hive,WITHOUT_CLASSIFICATION,//  Skip leading zeroes in word0. 
Hive,WITHOUT_CLASSIFICATION,//  Need to rollback because we did a select that acquired locks but we didn't   actually update anything.  Also we may have locked some locks as   acquired that we now want to not acquire.  It's ok to rollback because   once we see one wait we're done we won't look for more.   Only rollback to savepoint because we want to commit our heartbeat   changes. 
Hive,WITHOUT_CLASSIFICATION,//  Teardown the cluster 
Hive,WITHOUT_CLASSIFICATION,//  since we may split current task use a pre-order walker 
Hive,WITHOUT_CLASSIFICATION,//  setString can override this 
Hive,WITHOUT_CLASSIFICATION,//  Check whether the have the same schema 
Hive,WITHOUT_CLASSIFICATION,//  put the exe context into all the operators 
Hive,WITHOUT_CLASSIFICATION,//  First row determines isGroupResultNull and decimal firstValue; stream fill result as repeated. 
Hive,WITHOUT_CLASSIFICATION,//  First we get the UTC midnight for that day (which always exists a small island of sanity). 
Hive,WITHOUT_CLASSIFICATION,//  since old orc format doesn't support binary statistics 
Hive,WITHOUT_CLASSIFICATION,// bytes in o1 are same as o2  in case o2 was longer 
Hive,WITHOUT_CLASSIFICATION,//  Create test tables with 3 partitions 
Hive,WITHOUT_CLASSIFICATION,//  a delete delta file with 50000 delete events. 
Hive,WITHOUT_CLASSIFICATION,//  Save to DB 
Hive,WITHOUT_CLASSIFICATION,//  failures will not be retried (to avoid fork + exec running sysctl command) 
Hive,WITHOUT_CLASSIFICATION,//  Decompose the incoming text row into fields. 
Hive,WITHOUT_CLASSIFICATION,//  If it was internal column lets try to get name from columnExprMap 
Hive,WITHOUT_CLASSIFICATION,/*    * Deserializes from string to FastBitSet; Creates a NumDistinctValueEstimator   * object and returns it.    */
Hive,WITHOUT_CLASSIFICATION,//  Case 8: column stats grouping sets 
Hive,WITHOUT_CLASSIFICATION,/*            * Read the relative offset word at the beginning 2nd and beyond records.            */
Hive,WITHOUT_CLASSIFICATION,//  disable backtracking 
Hive,WITHOUT_CLASSIFICATION,//  Operator is a file sink or reduce sink. Something that forces 
Hive,WITHOUT_CLASSIFICATION,//  Obtain table props in query 
Hive,WITHOUT_CLASSIFICATION,//  This stream is for entire stripe and needed for every RG; uncompress once and reuse. 
Hive,WITHOUT_CLASSIFICATION,//  Coming from a ReduceSink the aggregations would be in the form VALUE._col0 VALUE._col1 
Hive,WITHOUT_CLASSIFICATION,//  3. construct SetOp Output RR using original left & right Input 
Hive,WITHOUT_CLASSIFICATION,//  Pre-allocated member for storing index into the hashSetResults for each spilled row. 
Hive,WITHOUT_CLASSIFICATION,//  topN == 0 will cause a short-circuit don't need any initialization 
Hive,WITHOUT_CLASSIFICATION,//  DOUBLE_VALUE 
Hive,WITHOUT_CLASSIFICATION,//  whether this is a mv rebuild rewritten expression 
Hive,WITHOUT_CLASSIFICATION,//  Add the output dir to the watch set scan it and cancel current watch. 
Hive,WITHOUT_CLASSIFICATION,//  its corresponding TableScanOperator. 
Hive,WITHOUT_CLASSIFICATION,/*        * Logically each bucket consists of 0000_0 0000_0_copy_1... 0000_0_copy_N. etc  We don't       * know N a priori so if this is true then the current split is from 0000_0_copy_N file.       * It's needed to correctly set maxKey.  In particular set maxKey==null if this split       * is the tail of the last file for this logical bucket to include all deltas written after       * non-acid to acid table conversion (todo: HIVE-17320).       * Also see comments at {@link OriginalReaderPair} about unbucketed tables.        */
Hive,WITHOUT_CLASSIFICATION,//  set and parse the row 
Hive,WITHOUT_CLASSIFICATION,//  Finally we are going to use "i"! 
Hive,WITHOUT_CLASSIFICATION,//  Retry once. 
Hive,WITHOUT_CLASSIFICATION,//  Propagate the cluster name to the script. 
Hive,WITHOUT_CLASSIFICATION,//  craete table and check dir ownership 
Hive,WITHOUT_CLASSIFICATION,//  If so check if we can merge mapJoinTask into that child. 
Hive,WITHOUT_CLASSIFICATION,//  making sure this is not initialized unless needed 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.ICLIService#getResultSetMetadata(org.apache.hive.service.cli.OperationHandle)    */
Hive,WITHOUT_CLASSIFICATION,//  authorize the grant 
Hive,WITHOUT_CLASSIFICATION,//  same idea only set for non-native tables 
Hive,WITHOUT_CLASSIFICATION,//  The 'next' parsedDelta may have everything equal to the 'prev' parsedDelta except   the path. This may happen when we have split update and we have two types of delta   directories- 'delta_x_y' and 'delete_delta_x_y' for the SAME txn range. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#prepareCall(java.lang.String int int int)    */
Hive,WITHOUT_CLASSIFICATION,//  increment the CREATED_FILES counter 
Hive,WITHOUT_CLASSIFICATION,//  Update has failed. We should try task2. 
Hive,WITHOUT_CLASSIFICATION,// may be -1 if no statementId 
Hive,WITHOUT_CLASSIFICATION,//  does not change the output ordering from the inputs. 
Hive,WITHOUT_CLASSIFICATION,//  Process column constraint 
Hive,WITHOUT_CLASSIFICATION,//  This input is the big table if it is contained in the big candidates set and either:   1) we have not chosen a big table yet or   2) it has been chosen as the big table above or   3) the cumulative cardinality for this input is higher or 
Hive,WITHOUT_CLASSIFICATION,//  Assumes stored data schema = [acid fields]stringintstring 
Hive,WITHOUT_CLASSIFICATION,//  Process the current data point 
Hive,WITHOUT_CLASSIFICATION,//  BucketMapJoinOptimizer and SortedMergeBucketMapJoinOptimizer 
Hive,WITHOUT_CLASSIFICATION,//  We have essentially deallocated this. 
Hive,WITHOUT_CLASSIFICATION,//  HIGH_VALUE 
Hive,WITHOUT_CLASSIFICATION,//  By default do not wait. 
Hive,WITHOUT_CLASSIFICATION,//  Create an ACID table with DbTxnManager 
Hive,WITHOUT_CLASSIFICATION,//  data stream could be empty stream or already reached end of stream before present stream. 
Hive,WITHOUT_CLASSIFICATION,//  Only populate corrupt IDs for the things we couldn't deserialize if we are not using   ppd. We assume that PPD makes sure the cached values are correct (or fails otherwise);   also we don't use the footers in PPD case. 
Hive,WITHOUT_CLASSIFICATION,//  BIT_VECTORS 
Hive,WITHOUT_CLASSIFICATION,//  How do we handle different scales? 
Hive,WITHOUT_CLASSIFICATION,//  Skip word1 also. 
Hive,WITHOUT_CLASSIFICATION,//  We try to rewrite COUNT(x) into COUNT(*) if x is not nullable.   We remove duplicate aggregate calls as well. 
Hive,WITHOUT_CLASSIFICATION,//  replace the partition's dfs with the table's dfs. 
Hive,WITHOUT_CLASSIFICATION,//  Cant use equals because the walker depends on them being object equal   The default graph walker processes a node after its kids have been   processed. That comparison needs 
Hive,WITHOUT_CLASSIFICATION,//  lock operations not controlled for now 
Hive,WITHOUT_CLASSIFICATION,//  Import will mark the parent db as a WriteEntity thus ensuring that we check for table creation privileges. 
Hive,WITHOUT_CLASSIFICATION,//        We assume here it won't be lower. Maybe we should just read and not guess... 
Hive,WITHOUT_CLASSIFICATION,// no conflict 
Hive,WITHOUT_CLASSIFICATION,//  2^62 - 1 
Hive,WITHOUT_CLASSIFICATION,//  catch-all call in cases like those with CTAS onto an unpartitioned table (see HIVE-1887) 
Hive,WITHOUT_CLASSIFICATION,//  Don't bust existing setups. 
Hive,WITHOUT_CLASSIFICATION,//  Interrupt the CLI thread to stop the current statement and return 
Hive,WITHOUT_CLASSIFICATION,//  Call when nextReadIndex == nextReadCount. 
Hive,WITHOUT_CLASSIFICATION,//  if orc table restrict reordering columns as it will break schema evolution 
Hive,WITHOUT_CLASSIFICATION,//  Direct access. 
Hive,WITHOUT_CLASSIFICATION,//  Increment dropKey to get a new key for hash map 
Hive,WITHOUT_CLASSIFICATION,//  Lowest word gets integer rounding. 
Hive,WITHOUT_CLASSIFICATION,//  length UTF8 string or a fixed width bytes if serializing in binary format 
Hive,WITHOUT_CLASSIFICATION,//  Note: for now LLAP is only supported in Tez tasks. Will never come to MR; others may         be added here although this is only necessary to have extra debug information. 
Hive,WITHOUT_CLASSIFICATION,//  expand list to correct size 
Hive,WITHOUT_CLASSIFICATION,//  Filter didn't do anything 
Hive,WITHOUT_CLASSIFICATION,//  When getPos is called it should return the same value signaling the end of the search so   the search should continue linearly and it should sync to the beginning of the block [0 50] 
Hive,WITHOUT_CLASSIFICATION,/*        * HIVE-9038: Join tests fail in tez when we have more than 1 join on the same key and there is       * an outer join down the join tree that requires filterTag. We disable this conversion to map       * join here now. We need to emulate the behavior of HashTableSinkOperator as in MR or create a       * new operation to be able to support this. This seems like a corner case enough to special       * case this for now.        */
Hive,WITHOUT_CLASSIFICATION,//  Use thrift transportable formatter 
Hive,WITHOUT_CLASSIFICATION,//  For metadataonly or empty rows optimizations null/onerow input format can be selected. 
Hive,WITHOUT_CLASSIFICATION,//  Not supported 
Hive,WITHOUT_CLASSIFICATION,// because rexInputRefs represent ref expr corresponding to value in inputRefs it is used to get    corresponding index 
Hive,WITHOUT_CLASSIFICATION,//  We use "Clip" in the name because this method will return a corrupted value when 
Hive,WITHOUT_CLASSIFICATION,/*      * If the user didn't specify a SerDe we use the default.      */
Hive,WITHOUT_CLASSIFICATION,//  optional   optional   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  required   required   required   required   required   optional 
Hive,WITHOUT_CLASSIFICATION,//  2^56 - 1 
Hive,WITHOUT_CLASSIFICATION,//  wrong type here 
Hive,WITHOUT_CLASSIFICATION,//  VIEW_EXPANDED_TEXT 
Hive,WITHOUT_CLASSIFICATION,//  production is: list<FieldType()> 
Hive,WITHOUT_CLASSIFICATION,//  nothing to stop 
Hive,WITHOUT_CLASSIFICATION,//  Technically methods run on a threadpool that is created externally with the UGI.   However that is brittle so we'd save the UGI explicitly here. 
Hive,WITHOUT_CLASSIFICATION,//  Try with types that have type params 
Hive,WITHOUT_CLASSIFICATION,//  Drop the table but not its data 
Hive,WITHOUT_CLASSIFICATION,//  3 Build Calcite Rel Node for project using converted projections & col 
Hive,WITHOUT_CLASSIFICATION,//  Perform conversion of null map values 
Hive,WITHOUT_CLASSIFICATION,//  SHOW LOCKS t15 
Hive,WITHOUT_CLASSIFICATION,//  initialize HCatOutputFormat 
Hive,WITHOUT_CLASSIFICATION,//  for backwards compatibility with old metastore persistence 
Hive,WITHOUT_CLASSIFICATION,//  get the counters for the task 
Hive,WITHOUT_CLASSIFICATION,//  3 element map 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.Connection#clearWarnings()    */
Hive,WITHOUT_CLASSIFICATION,//  Get the LRU key value 
Hive,WITHOUT_CLASSIFICATION,//  Get new client 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) Enum  */
Hive,WITHOUT_CLASSIFICATION,//  The path string contains the dag Identifier 
Hive,WITHOUT_CLASSIFICATION,//  used for buffer a column's values 
Hive,WITHOUT_CLASSIFICATION,//  Drop a table/partition corresponding records in COMPACTION_QUEUE and COMPLETED_COMPACTIONS should disappear 
Hive,WITHOUT_CLASSIFICATION,//  get column name from custom path matcher and column value from dynamic path matcher 
Hive,WITHOUT_CLASSIFICATION,// private static MiniCluster cluster = MiniCluster.buildCluster(); 
Hive,WITHOUT_CLASSIFICATION,//  Now add to cache the dummy colstats for these 10 partitions 
Hive,WITHOUT_CLASSIFICATION,/*    * VARCHAR.    */
Hive,WITHOUT_CLASSIFICATION,//  SHOW LOCKS t14 
Hive,WITHOUT_CLASSIFICATION,//  join which takes place in a separate task. 
Hive,WITHOUT_CLASSIFICATION,//  TASK_LIST 
Hive,WITHOUT_CLASSIFICATION,//  compareSupported returns false because Union can contain 
Hive,WITHOUT_CLASSIFICATION,//  required   optional   optional   optional   optional   optional   optional 
Hive,WITHOUT_CLASSIFICATION,//  Thus we use 'finishPushSortPastUnion' as a flag to identify if we have finished pushing the   sort past a union. 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.Operation#getResultSetSchema()    */
Hive,WITHOUT_CLASSIFICATION,//  -create table as select- should not return a ResultSet 
Hive,WITHOUT_CLASSIFICATION,//  map operators only   all operators. Launch containers if user code etc prevents running inside llap.   no operators   Try running everything in llap fail if that is not possible (non blessed user code script etc)   please hive choose for me 
Hive,WITHOUT_CLASSIFICATION,//  @@protoc_insertion_point(builder_scope:VertexOrBinary) 
Hive,WITHOUT_CLASSIFICATION,//  This is not the first table and we are not using it as big table 
Hive,WITHOUT_CLASSIFICATION,//  We are getting a session from TezSessionPool   We have the session but it doesn't have registry info yet.   We have the session with registry info or we have failed.   The master thread has CANCELED this and will never look at it again. 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) Definition  */
Hive,WITHOUT_CLASSIFICATION,//  Always configure storage handler with jobproperties/jobconf before calling any methods on it 
Hive,WITHOUT_CLASSIFICATION,/*      * Get the AST tree      */
Hive,WITHOUT_CLASSIFICATION,/*    * Cleanup method called to run cleanup tasks if job state is FAILED. By default   * no cleanup is provided.    */
Hive,WITHOUT_CLASSIFICATION,//  changing the sort-merge join to a map-join 
Hive,WITHOUT_CLASSIFICATION,//  Finalize the headers. 
Hive,WITHOUT_CLASSIFICATION,//  check whether exception is thrown when fetching log from a closed operation. 
Hive,WITHOUT_CLASSIFICATION,//  if ratio is greater than 1 then number of rows increases. This can happen   when some operators like GROUPBY duplicates the input rows in which 	case   number of distincts should not change. Update the distinct count only when   the output number of rows is less than input number of rows. 
Hive,WITHOUT_CLASSIFICATION,// load into existing empty table T 
Hive,WITHOUT_CLASSIFICATION,//  Do not update metrics - see above. 
Hive,WITHOUT_CLASSIFICATION,//  Validate resource plan. 
Hive,WITHOUT_CLASSIFICATION,// No segments to load still need to honer overwrite 
Hive,WITHOUT_CLASSIFICATION,// list of operation states to measure duration of. 
Hive,WITHOUT_CLASSIFICATION,//  if this is a semijoin we need to add the condition 
Hive,WITHOUT_CLASSIFICATION,//  Execute SELECT statement and verify that aborted INSERT statement is not counted. 
Hive,WITHOUT_CLASSIFICATION,/*      * Add these 3 values:     *     * red     * green     * NULL      */
Hive,WITHOUT_CLASSIFICATION,//  The size of the array is equal to the number of selected columns 
Hive,WITHOUT_CLASSIFICATION,//  Loop through the partitions and form the expression 
Hive,WITHOUT_CLASSIFICATION,//  test long->long version 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setClob(java.lang.String java.io.Reader   * long)    */
Hive,WITHOUT_CLASSIFICATION,//  If the key column is not a column then dont apply this optimization.   This will be fixed as part of https://issues.apache.org/jira/browse/HIVE-3445   for type conversion UDFs. 
Hive,WITHOUT_CLASSIFICATION,// txinid:8 
Hive,WITHOUT_CLASSIFICATION,//  additional information about stats (e.g. virtual column number 
Hive,WITHOUT_CLASSIFICATION,//  Example from HiveDecimal.subtract header comments. 
Hive,WITHOUT_CLASSIFICATION,//  Initialize the transaction manager.  This must be done before analyze is called. 
Hive,WITHOUT_CLASSIFICATION,//  After dedup we should be left with 2 locks:   [path1 exclusive] 
Hive,WITHOUT_CLASSIFICATION,//  load the expected results 
Hive,WITHOUT_CLASSIFICATION,//  2 (test #read(3)): 
Hive,WITHOUT_CLASSIFICATION,//  Set fetch size in session conf map 
Hive,WITHOUT_CLASSIFICATION,//  write the data type 
Hive,WITHOUT_CLASSIFICATION,//  Table directory (which includes the partition directory) has already been moved   just update the partition location in the metastore. 
Hive,WITHOUT_CLASSIFICATION,//  This is only executed for outer joins with residual filters 
Hive,WITHOUT_CLASSIFICATION,//  Retrieve information about cache usage for the query. 
Hive,WITHOUT_CLASSIFICATION,//  Believe it or not some tools do generate queries with limit 0 and than expect   query to run quickly. Lets meet their requirement. 
Hive,WITHOUT_CLASSIFICATION,//  4. Determine which columns requires cast on left/right input (Calcite 
Hive,WITHOUT_CLASSIFICATION,// currently ACID requires table to be bucketed 
Hive,WITHOUT_CLASSIFICATION,/*    * The vectorization context for creating the VectorizedRowBatch for the node.    */
Hive,WITHOUT_CLASSIFICATION,//  referencing correlated variables. 
Hive,WITHOUT_CLASSIFICATION,//  Update existing stat object's field 
Hive,WITHOUT_CLASSIFICATION,// for tables other than the big table we need to fetch more data until reach a new group or done. 
Hive,WITHOUT_CLASSIFICATION,//  First incremental load 
Hive,WITHOUT_CLASSIFICATION,//             } 
Hive,WITHOUT_CLASSIFICATION,//  short year should work 
Hive,WITHOUT_CLASSIFICATION,// ********************************************************************************************** 
Hive,WITHOUT_CLASSIFICATION,//  Separator for multiple tables' ValidWriteIdList. Also skip it for last entry. 
Hive,WITHOUT_CLASSIFICATION,// check the ouput specs only if it is a storage handler (native tables's outputformats does  not set the job's output properties correctly) 
Hive,WITHOUT_CLASSIFICATION,//  and is thus valid. Both times flowed at the same pace. We congratulate ourselves and bail. 
Hive,WITHOUT_CLASSIFICATION,//  LONG_VALUE 
Hive,WITHOUT_CLASSIFICATION,//  For incremental repl we will have individual events which can   be other things like roles and fns as well.   At this point all dump dirs should contain a _dumpmetadata file that   tells us what is inside that dumpdir. 
Hive,WITHOUT_CLASSIFICATION,//  Fill the prefix bytes with deterministic data based on the actual meaningful data. 
Hive,WITHOUT_CLASSIFICATION,//  Including parameters passed in the query 
Hive,WITHOUT_CLASSIFICATION,//  reset the behaviour 
Hive,WITHOUT_CLASSIFICATION,/*    * When we have operators that have multiple parents it is not clear which   * parent's traits we need to propagate forward.    */
Hive,WITHOUT_CLASSIFICATION,/*      * Sum input TIMESTAMP and output DOUBLE.     *     * Just modes (PARTIAL1 COMPLETE).      */
Hive,WITHOUT_CLASSIFICATION,//  get view column authorization. 
Hive,WITHOUT_CLASSIFICATION,//  Note: ReentrantReadWriteLock deos not allow upgrading a read lock to a write lock.   Care must be taken while under read lock to make sure we do not perform any actions   which attempt to take a write lock. 
Hive,WITHOUT_CLASSIFICATION,//  private final Map<String Integer> columnMap; 
Hive,WITHOUT_CLASSIFICATION,//  SerdeInfo 
Hive,WITHOUT_CLASSIFICATION,//  all index. 
Hive,WITHOUT_CLASSIFICATION,//  if Filter.g does date parsing for quoted strings we'd need to verify there's no 
Hive,WITHOUT_CLASSIFICATION,//  For each column are we converting the row column object? 
Hive,WITHOUT_CLASSIFICATION,//  Verify we can get from cache. 
Hive,WITHOUT_CLASSIFICATION,//  An array of hash set results so we can do lookups on the whole batch before output result 
Hive,WITHOUT_CLASSIFICATION,//  Extract the integer portion to get the quotient. 
Hive,WITHOUT_CLASSIFICATION,//  for static partition it may not exist when HIVESTATSCOLAUTOGATHER is   set to true 
Hive,WITHOUT_CLASSIFICATION,/*      * Extract information about the old value.      */
Hive,WITHOUT_CLASSIFICATION,//  Find if there's any DPP sink branch of the branchingOP that is equivalent 
Hive,WITHOUT_CLASSIFICATION,//  We use a scratch buffer with the HiveDecimalWritable toBytes method so   we don't incur poor performance creating a String result. 
Hive,WITHOUT_CLASSIFICATION,//  There are some partitions with no state (or we didn't fetch any state).   Update the stats with empty list to reflect that in the   state/initialize structures. 
Hive,WITHOUT_CLASSIFICATION,//  use default configuration for no-auth mode 
Hive,WITHOUT_CLASSIFICATION,//  Skip leading zeros and compute number of digits in magnitude 
Hive,WITHOUT_CLASSIFICATION,//  indicates if read buffer has data   number of rows in the temporary read buffer   cursor during reading   total number of pairs in output 
Hive,WITHOUT_CLASSIFICATION,//  system include path 
Hive,WITHOUT_CLASSIFICATION,//  Add two decimals. 
Hive,WITHOUT_CLASSIFICATION,//  if ctx.getCurrTask() is in rootTasks should be removed 
Hive,WITHOUT_CLASSIFICATION,/*    * Below method returns the dependencies for the passed in query to EXPLAIN.   * The dependencies are the set of input tables and partitions and are   * provided back as JSON output for the EXPLAIN command.   * Example output:   * {"input_tables":[{"tablename": "default@test_sambavi_v1" "tabletype": "TABLE"}]   *  "input partitions":["default@srcpart@ds=2008-04-08/hr=11"]}    */
Hive,WITHOUT_CLASSIFICATION,//  Obtain a delegation token from Accumulo 
Hive,WITHOUT_CLASSIFICATION,//  Check if HIVE_CONF_DIR is defined 
Hive,WITHOUT_CLASSIFICATION,//  but can be backported. So we disable setup/cleanup in all versions >= 0.19 
Hive,WITHOUT_CLASSIFICATION,//  We have received a new directory information make split strategies. 
Hive,WITHOUT_CLASSIFICATION,//  MapOperator is out of SparkWork SparkMapRecordHandler use it to bridge   Spark transformation and Hive operators in SparkWork. 
Hive,WITHOUT_CLASSIFICATION,//  no alter the table is missing either due to drop/rename which follows the alter.   or the existing table is newer than our update. 
Hive,WITHOUT_CLASSIFICATION,//  If serializer is ThriftJDBCBinarySerDe then it buffers rows to a certain limit (hive.server2.thrift.resultset.max.fetch.size)   and serializes the whole batch when the buffer is full. The serialize returns null if the buffer is not full   (the size of buffer is kept track of in the ThriftJDBCBinarySerDe). 
Hive,WITHOUT_CLASSIFICATION,//  based on whitelist/blacklist 
Hive,WITHOUT_CLASSIFICATION,//  the same server 
Hive,WITHOUT_CLASSIFICATION,// todo: try using set VerifyNumReducersHook.num.reducers=10; 
Hive,WITHOUT_CLASSIFICATION,//  close() also calls flush() 
Hive,WITHOUT_CLASSIFICATION,//  If a failure occurs here the directory containing the original files 
Hive,WITHOUT_CLASSIFICATION,//  remember in case we need to connect additional work later 
Hive,WITHOUT_CLASSIFICATION,//  If its not an exception caused by auth check ignore it 
Hive,WITHOUT_CLASSIFICATION,/*    * Generate the second ReduceSinkOperator for the Group By Plan   * (parseInfo.getXXX(dest)). The new ReduceSinkOperator will be a child of   * groupByOperatorInfo.   *   * The second ReduceSinkOperator will put the group by keys in the map-reduce   * sort key and put the partial aggregation results in the map-reduce value.   *   * @param numPartitionFields   *          the number of fields in the map-reduce partition key. This should   *          always be the same as the number of Group By keys. We should be   *          able to remove this parameter since in this phase there is no   *          distinct any more.   * @return the new ReduceSinkOperator.   * @throws SemanticException    */
Hive,WITHOUT_CLASSIFICATION,//  We sort by state (acquired vs waiting) and then by LockType then by id 
Hive,WITHOUT_CLASSIFICATION,//  some prime numbers spaced about at powers of 2 in magnitude 
Hive,WITHOUT_CLASSIFICATION,//  The output of this UDF is constant so don't even bother evaluating. 
Hive,WITHOUT_CLASSIFICATION,//   int offset = output.getLength(); 
Hive,WITHOUT_CLASSIFICATION,//  break immediately if timeout is 0 
Hive,WITHOUT_CLASSIFICATION,//  Final preds 
Hive,WITHOUT_CLASSIFICATION,//  only right input repeating and has no nulls 
Hive,WITHOUT_CLASSIFICATION,//  Time part 
Hive,WITHOUT_CLASSIFICATION,//  The delta directory should also have only 1 bucket file (bucket_00001) 
Hive,WITHOUT_CLASSIFICATION,//  Everything prefixed by ^unitTests.   Everything prefixed by ^ut. 
Hive,WITHOUT_CLASSIFICATION,//  enforce uniqueness of column names 
Hive,WITHOUT_CLASSIFICATION,//  Hive history is disabled create a no-op proxy 
Hive,WITHOUT_CLASSIFICATION,//  null means ALL for show grants GLOBAL for grant/revoke 
Hive,WITHOUT_CLASSIFICATION,//  VERIFY tables and partitions on destination for equivalence. 
Hive,WITHOUT_CLASSIFICATION,//  required 
Hive,WITHOUT_CLASSIFICATION,//  clear existing cookie 
Hive,WITHOUT_CLASSIFICATION,//  #3 - Cast to timestamp 
Hive,WITHOUT_CLASSIFICATION,//  constant string projection Ex: select "hello" from table 
Hive,WITHOUT_CLASSIFICATION,//  The AccumuloRangeGenerator produces an Object (due to the limitations of the   traversal interface) which requires interpretation of that Object into Ranges.   Changes in the return object from the AccumuloRangeGenerator must also represent   a change in the AccumuloPredicateHandler. 
Hive,WITHOUT_CLASSIFICATION,//  this setups auth filtering in build() 
Hive,WITHOUT_CLASSIFICATION,/*  If the result is null throw an exception. This can be caught     * by calling code in the vectorized code path and made to yield     * a SQL NULL value.      */
Hive,WITHOUT_CLASSIFICATION,//  only one result column   verify the system generated column name 
Hive,WITHOUT_CLASSIFICATION,//  Constants and nulls are OK 
Hive,WITHOUT_CLASSIFICATION,//  For now we don't know which virtual columns are going to be included.  We'll add them 
Hive,WITHOUT_CLASSIFICATION,//  Need to preserve currentGroups 
Hive,WITHOUT_CLASSIFICATION,//  Metrics will have already been initialized if we're using them since HMSHandler 
Hive,WITHOUT_CLASSIFICATION,//  We are not calling super.seek since we handle the present stream differently. 
Hive,WITHOUT_CLASSIFICATION,/*        * add row to chain. except in case of UNB preceding: - only 1 max needs       * to be tracked. - current max will never become out of range. It can       * only be replaced by a larger max.        */
Hive,WITHOUT_CLASSIFICATION,// We need to make sure that Null Operator (LIM or FIL) is present in all branches of multi-insert query before  applying the optimization. This method does full tree traversal starting from TS and will return true only if  it finds target Null operator on each branch. 
Hive,WITHOUT_CLASSIFICATION,//  No need to set null data entries because the input NaN values   will automatically propagate to the output. 
Hive,WITHOUT_CLASSIFICATION,//  hashMap += JAVA64_FIELDREF + PRIMITIVES1   hashMap.entry += JAVA64_FIELDREF * 2 
Hive,WITHOUT_CLASSIFICATION,//  Create path to hive-contrib JAR on local filesystem 
Hive,WITHOUT_CLASSIFICATION,// to do the final move 
Hive,WITHOUT_CLASSIFICATION,//  A column qualifier with a colon 
Hive,WITHOUT_CLASSIFICATION,//  Adjust the number of reducers of this correlation based on 
Hive,WITHOUT_CLASSIFICATION,//  disconnect the reduce work from its child. this should produce two isolated sub graphs 
Hive,WITHOUT_CLASSIFICATION,//  Wait 5 seconds too in case of an exception so we do not end up in busy waiting for   the solution for this exception 
Hive,WITHOUT_CLASSIFICATION,// "load data local inpath" doesn't delete source files so clean it here 
Hive,WITHOUT_CLASSIFICATION,/*    * Element for Key: Long x Hash Table: HashMap    */
Hive,WITHOUT_CLASSIFICATION,//  derived from the alias V3:V2:V1:T 
Hive,WITHOUT_CLASSIFICATION,//  SW: Lock we are trying to acquire is shared write 
Hive,WITHOUT_CLASSIFICATION,//  2^32-1 
Hive,WITHOUT_CLASSIFICATION,//  The reducer needs to be restored - Consider a query like:   select count(*) FROM bucket_big a JOIN bucket_small b ON a.key = b.key; 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#setBlob(java.lang.String java.sql.Blob)    */
Hive,WITHOUT_CLASSIFICATION,//  Always start in the running state. Requests for state updates will be sent out after registration. 
Hive,WITHOUT_CLASSIFICATION,//  optional int32 fragment_number = 3; 
Hive,WITHOUT_CLASSIFICATION,//  n-way join 
Hive,WITHOUT_CLASSIFICATION,//  Now change it's child 
Hive,WITHOUT_CLASSIFICATION,//  No input expression for COUNT(*).   evaluateInputExpr(batch); 
Hive,WITHOUT_CLASSIFICATION,//  Expect query to be completed now 
Hive,WITHOUT_CLASSIFICATION,//  For PARTIAL2 and FINAL: ObjectInspectors for partial aggregations (list of doubles) 
Hive,WITHOUT_CLASSIFICATION,/*      * We will transform GB-RS-GBY to mGby1-rs1-mGby2-mGby3-rs2-rGby1      */
Hive,WITHOUT_CLASSIFICATION,//  for backward compatibility 
Hive,WITHOUT_CLASSIFICATION,//  grouping is same but category is not. 
Hive,WITHOUT_CLASSIFICATION,//  Decrease qp check that the pool shrinks incl. killing the unused and returned sessions. 
Hive,WITHOUT_CLASSIFICATION,//  in case of custom dynamic partitions we can't just move the sub-tree of partition root   directory since the partitions location contain regex pattern. We need to first find the   final destination of each partition and move its output. 
Hive,WITHOUT_CLASSIFICATION,//  Verify hive.exec.schema.evolution is true or we have an ACID table so we are producing   the table schema from ORC.  The Vectorizer class assures this. 
Hive,WITHOUT_CLASSIFICATION,//  Store the results produced by the dispatcher 
Hive,WITHOUT_CLASSIFICATION,//  this assumes all paths are bucket names (which means no lookup is needed) 
Hive,WITHOUT_CLASSIFICATION,//  according to hiveTypeToSqlType possible options are: 
Hive,WITHOUT_CLASSIFICATION,//  no more batches to read exhausted the reader. 
Hive,WITHOUT_CLASSIFICATION,// the record with valid CQ_ID has disappeared - this is a sign of something wrong 
Hive,WITHOUT_CLASSIFICATION,//  Detect UDTF's in nested SELECT GROUP BY etc as they aren't   supported 
Hive,WITHOUT_CLASSIFICATION,/*          * sz Estimate = sz needed by underlying AggBuffer + sz for results + sz         * for intermediates + 3 * JavaDataModel.PRIMITIVES1 sz of results = sz         * of underlying * wdwSz sz of intermediates = sz of underlying * wdwSz          */
Hive,WITHOUT_CLASSIFICATION,//  Surprisingly these privs are already granted. 
Hive,WITHOUT_CLASSIFICATION,//  lower case role names for case insensitive behavior 
Hive,WITHOUT_CLASSIFICATION,//  Check log files look OK 
Hive,WITHOUT_CLASSIFICATION,/*    * Set the range of bytes to be deserialized.    */
Hive,WITHOUT_CLASSIFICATION,//  If the FS has no access() method we can try DefaultFileAccess .. 
Hive,WITHOUT_CLASSIFICATION,/*  @bgen(jjtree) TypeSet  */
Hive,WITHOUT_CLASSIFICATION,//  if there is more than 1 argument specified a different natural language   locale is being specified 
Hive,WITHOUT_CLASSIFICATION,//  internal input format class for CombineHiveInputFormat 
Hive,WITHOUT_CLASSIFICATION,// specified in the query 
Hive,WITHOUT_CLASSIFICATION,//  Row ID 
Hive,WITHOUT_CLASSIFICATION,//  expected failure 
Hive,WITHOUT_CLASSIFICATION,//  Assume all columns are null except the dummy column is always non-null. 
Hive,WITHOUT_CLASSIFICATION,//  Compare the field types 
Hive,WITHOUT_CLASSIFICATION,//  Arithmetic on two type interval_day_time (TimestampColumnVector storing nanosecond interval 
Hive,WITHOUT_CLASSIFICATION,//  TODO - Currently no way to test alter table as this interface doesn't support alter table 
Hive,WITHOUT_CLASSIFICATION,//  sanity check 
Hive,WITHOUT_CLASSIFICATION,//  empty 
Hive,WITHOUT_CLASSIFICATION,//  since we cannot directly set the private byte[] field inside Text. 
Hive,WITHOUT_CLASSIFICATION,//  If we did not reduce check the children nodes 
Hive,WITHOUT_CLASSIFICATION,//  Test the sequence validation functionality 
Hive,WITHOUT_CLASSIFICATION,//  Binary search only works if we know the size of the split and the recordReader is an   RCFileRecordReader 
Hive,WITHOUT_CLASSIFICATION,//  show user level privileges 
Hive,WITHOUT_CLASSIFICATION,//  We must release the connection before we call other pm methods. 
Hive,WITHOUT_CLASSIFICATION,//  adopted Hadoop-5476 (calling new SequenceFile.Reader(...) leaves an 
Hive,WITHOUT_CLASSIFICATION,//  TODO 
Hive,WITHOUT_CLASSIFICATION,//  Operator tree is now done. 
Hive,WITHOUT_CLASSIFICATION,//  get the connection properties from user specific config file 
Hive,WITHOUT_CLASSIFICATION,//  parent op is guaranteed to have a single list because it is a reduce sink 
Hive,WITHOUT_CLASSIFICATION,//  check whether session log dir is deleted after session is closed. 
Hive,WITHOUT_CLASSIFICATION,//  Nothing to aggregate 
Hive,WITHOUT_CLASSIFICATION,//  Read event from notification 
Hive,WITHOUT_CLASSIFICATION,//  just return stats gathering should not block the main query 
Hive,WITHOUT_CLASSIFICATION,//  Greater than (or equal) and less than (or equal) 
Hive,WITHOUT_CLASSIFICATION,//  should return all ok 
Hive,WITHOUT_CLASSIFICATION,//  Test select abs(root.col1.b) from table test(root struct<col1:struct<a:booleanb:double> 
Hive,WITHOUT_CLASSIFICATION,//  Ignore exception 
Hive,WITHOUT_CLASSIFICATION,//  Succeed - "transactional" is set to true and the table is bucketed and uses ORC 
Hive,WITHOUT_CLASSIFICATION,//  The current position in the key series. 
Hive,WITHOUT_CLASSIFICATION,//  Partition Column 
Hive,WITHOUT_CLASSIFICATION,//  Predicates without field references can be pushed to both inputs 
Hive,WITHOUT_CLASSIFICATION,/*  256 files x 100 size for 111 splits  */
Hive,WITHOUT_CLASSIFICATION,//  check if standard out is a terminal 
Hive,WITHOUT_CLASSIFICATION,//  get the session specified class loader from SessionState 
Hive,WITHOUT_CLASSIFICATION,//  No confusing directories in export. 
Hive,WITHOUT_CLASSIFICATION,//  get the key to store in map 
Hive,WITHOUT_CLASSIFICATION,//  No match? 
Hive,WITHOUT_CLASSIFICATION,//  Construct using org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.QueryIdentifierProto.newBuilder() 
Hive,WITHOUT_CLASSIFICATION,// adds database.name == dbName to the filter 
Hive,WITHOUT_CLASSIFICATION,//  Special-casing for ADMIN-level operations that do not require object checking. 
Hive,WITHOUT_CLASSIFICATION,//  So no need to attempt to merge the files again. 
Hive,WITHOUT_CLASSIFICATION,//  check if there are privileges to be filtered 
Hive,WITHOUT_CLASSIFICATION,//  Free list indices of each unallocated block for quick lookup. 
Hive,WITHOUT_CLASSIFICATION,//  add Hive operator level statistics. 
Hive,WITHOUT_CLASSIFICATION,//  appropriate operators to the TS 
Hive,WITHOUT_CLASSIFICATION,// HBase stuff 
Hive,WITHOUT_CLASSIFICATION,//  isRepeating and there are nulls 
Hive,WITHOUT_CLASSIFICATION,//  Remove the dead session dir 
Hive,WITHOUT_CLASSIFICATION,// Entire batch is filtered out. 
Hive,WITHOUT_CLASSIFICATION,//  Check column number 
Hive,WITHOUT_CLASSIFICATION,/*  Set the output string entry i to the contents of Text object t.   * If t is a null object reference record that the value is a SQL NULL.    */
Hive,WITHOUT_CLASSIFICATION,//  walk-around of TEZ-1403 
Hive,WITHOUT_CLASSIFICATION,//  Initialize input 
Hive,WITHOUT_CLASSIFICATION,//  all values are null so none qualify 
Hive,WITHOUT_CLASSIFICATION,//  Since schedule() can be called from multiple threads we peek the wait queue try   scheduling the task and then remove the task if scheduling is successful. This 
Hive,WITHOUT_CLASSIFICATION,//  Skip leading zeroes in word1. 
Hive,WITHOUT_CLASSIFICATION,//  Replace all TOK_TABREF with fully qualified table name if it is not already fully qualified. 
Hive,WITHOUT_CLASSIFICATION,//  nodes that we need to see siblings for and sibling levels. 
Hive,WITHOUT_CLASSIFICATION,//  alterOpType is null in case of stats update 
Hive,WITHOUT_CLASSIFICATION,//  Just need to initialize the ProxyUsers for the first time given that the conf will not change on the fly 
Hive,WITHOUT_CLASSIFICATION,/*  * Contains functionality that helps with understanding how a SubQuery was rewritten.  */
Hive,WITHOUT_CLASSIFICATION,//  We could also have one metricssource for all the pools and add all the pools to the collector   in its getMetrics call (as separate records). Not clear if that's supported.   Also we'd have to initialize the metrics ourselves instead of using @Metric annotation. 
Hive,WITHOUT_CLASSIFICATION,//  set to max possible value 
Hive,WITHOUT_CLASSIFICATION,//  Set the thread local username to be used for doAs if true 
Hive,WITHOUT_CLASSIFICATION,//  Check the original partitions of the dest table 
Hive,WITHOUT_CLASSIFICATION,//  For direct DB connections we don't yet support reestablishing connections. 
Hive,WITHOUT_CLASSIFICATION,//  No child-task to merge nothing to do or there are more than one   child-tasks in which case we don't want to do anything. 
Hive,WITHOUT_CLASSIFICATION,//  no valid events this batch but we're still not done processing events 
Hive,WITHOUT_CLASSIFICATION,//  Split work into multiple branches one for each childWork in childWorks. 
Hive,WITHOUT_CLASSIFICATION,//  Generate types for column mapping 
Hive,WITHOUT_CLASSIFICATION,//  table descriptor of the final 
Hive,WITHOUT_CLASSIFICATION,//  the verifyAndSet in this case is expected to fail with the IllegalArgumentException 
Hive,WITHOUT_CLASSIFICATION,//  (FETCH_FIRST) execute a sql and fetch its sql operation log as expected value 
Hive,WITHOUT_CLASSIFICATION,//  Validate after compaction. 
Hive,WITHOUT_CLASSIFICATION,//  Fixed doesn't exist in Hive. Fixeds go in lists of bytes go out. 
Hive,WITHOUT_CLASSIFICATION,/*  256 files x 100 size for 10 splits  */
Hive,WITHOUT_CLASSIFICATION,//  The code should account for the bug and update the iterators on the split 
Hive,WITHOUT_CLASSIFICATION,/*  256 files x 1000 size for 10 splits  */
Hive,WITHOUT_CLASSIFICATION,// should not happen as default value is set 
Hive,WITHOUT_CLASSIFICATION,//  we do the scaling down _during_ multiplication to avoid   unnecessary overflow.   note that even this could overflow if newScale is too small. 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: some code uses this list to correlate with column names and yet these lists may         contain duplicates which this call will remove and the other won't. As far as I can         tell no code will actually use these two methods together; all is good if the code         gets the ID list without relying on this method. Or maybe it just works by magic. 
Hive,WITHOUT_CLASSIFICATION,//  Output will be same in both partial or full aggregation modes. 
Hive,WITHOUT_CLASSIFICATION,//  Flag to control that always threads are initialized only once 
Hive,WITHOUT_CLASSIFICATION,//  If this is a materialized view this stores the view descriptor 
Hive,WITHOUT_CLASSIFICATION,//  Setup connection information 
Hive,WITHOUT_CLASSIFICATION,//  add the index of expr in reduceKeys to distinctIndices 
Hive,WITHOUT_CLASSIFICATION,//  null evicted task means offer accepted   evictedTask is not equal taskWrapper means current task is accepted and it evicted 
Hive,WITHOUT_CLASSIFICATION,//  True if the logs should be removed after the operation. Should be used only in test mode 
Hive,WITHOUT_CLASSIFICATION,//  See if this is an explicit cast. 
Hive,WITHOUT_CLASSIFICATION,//  In non-impersonation mode map scheduler queue to current user   if fair scheduler is configured. 
Hive,WITHOUT_CLASSIFICATION,//  column or constant 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.Operation#getNextRowSet(org.apache.hive.service.cli.FetchOrientation long)    */
Hive,WITHOUT_CLASSIFICATION,//  Get completed attempts from jobtasks.jsp 
Hive,WITHOUT_CLASSIFICATION,//  Already set 
Hive,WITHOUT_CLASSIFICATION,//  clean up 
Hive,WITHOUT_CLASSIFICATION,//  Scale down right and compare. 
Hive,WITHOUT_CLASSIFICATION,//  returns Map<??> 
Hive,WITHOUT_CLASSIFICATION,//  Add field with a comment... 
Hive,WITHOUT_CLASSIFICATION,/*              * We can have an unaliased and one aliased mapping to a Column.              */
Hive,WITHOUT_CLASSIFICATION,//  Test that we can search correctly using a buffer and pulling   a sequence of bytes out of the middle of it. In this case it 
Hive,WITHOUT_CLASSIFICATION,//  test null on right 
Hive,WITHOUT_CLASSIFICATION,//  Increment count of values seen so far 
Hive,WITHOUT_CLASSIFICATION,//  the directory might be db/table/partition 
Hive,WITHOUT_CLASSIFICATION,/*          * Get our Single-Column Long hash set information for this specialized class.          */
Hive,WITHOUT_CLASSIFICATION,//  GroupByOperators 
Hive,WITHOUT_CLASSIFICATION,//  After the timeout just force abort the open txns 
Hive,WITHOUT_CLASSIFICATION,/*  fastScale  */
Hive,WITHOUT_CLASSIFICATION,//  The processing thread will switch between these two objects. 
Hive,WITHOUT_CLASSIFICATION,//  If hive.groupby.skewindata is set to true the operator tree is as below 
Hive,WITHOUT_CLASSIFICATION,//  Is this a struct type? 
Hive,WITHOUT_CLASSIFICATION,/*    * @param statusDir directory of statusDir defined for the webhcat job. It is supposed   *                  to contain stdout/stderr/syslog for the webhcat controller job   * @param jobType   Currently we support pig/hive/stream/generic mapreduce. The specific   *                  parser will parse the log of the controller job and retrieve job_id   *                  of all mapreduce jobs it launches. The generic mapreduce parser works   *                  when the program use JobClient.runJob to submit the job but if the program   *                  use other API generic mapreduce parser is not guaranteed to find the job_id   * @param conf      Configuration for webhcat    */
Hive,WITHOUT_CLASSIFICATION,//  nothing to do with nulls 
Hive,WITHOUT_CLASSIFICATION,//  partition columns in the table level schema. 
Hive,WITHOUT_CLASSIFICATION,//  INSERT EVENT to partitioned table on existing partition 
Hive,WITHOUT_CLASSIFICATION,//  waitForInitialCreate must have already been called in registerServiceRecord. 
Hive,WITHOUT_CLASSIFICATION,//  Set invoking HMSHandler on threadLocal this will be used later to notify 
Hive,WITHOUT_CLASSIFICATION,//  The state for guaranteed task tracking. Synchronized on 'this'.   In addition "isGuaranteed" is only modified under the epic lock (because it involves   modifying the corresponding structures that contain the task objects at the same time). 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#setTime(int java.sql.Time   * java.util.Calendar)    */
Hive,WITHOUT_CLASSIFICATION,//  Dump and load only first insert (1 record) 
Hive,WITHOUT_CLASSIFICATION,//  Try to populate correlation variables using local fields. 
Hive,WITHOUT_CLASSIFICATION,//  CTAS cannot be part of multi-txn stmt 
Hive,WITHOUT_CLASSIFICATION,//  By now the job is initialized so no reason to do   rj.getJobState() again and we do not want to do an extra RPC call 
Hive,WITHOUT_CLASSIFICATION,//  we know how to handle DPP sinks 
Hive,WITHOUT_CLASSIFICATION,//  do nothing if implicitConversions > leastImplicitConversions 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: It is critical to do this prior to initializing log4j otherwise 
Hive,WITHOUT_CLASSIFICATION,//  check basic operation 
Hive,WITHOUT_CLASSIFICATION,//  extract all the inputFormatClass names for each chunk in the   CombinedSplit. 
Hive,WITHOUT_CLASSIFICATION,//  from script.. no need to load history and no need of completer either 
Hive,WITHOUT_CLASSIFICATION,//  Check if the partitions don't exist in the destTable 
Hive,WITHOUT_CLASSIFICATION,//  Ok we need to convert. 
Hive,WITHOUT_CLASSIFICATION,//  load required JDBC driver 
Hive,WITHOUT_CLASSIFICATION,//  Change the resource plan to use fifo policy. 
Hive,WITHOUT_CLASSIFICATION,//  columnVector entry is byte array representing serialized BloomFilter.   BloomFilter.mergeBloomFilterBytes() does a simple byte ORing   which should be faster than deserialize/merge. 
Hive,WITHOUT_CLASSIFICATION,//  Allocate 2-1-1-2-1-1; free 03 and optionally 1 or 5; allocate 4 
Hive,WITHOUT_CLASSIFICATION,//  because percentile (really quantile) values should generally be strictly between 0 and 1. 
Hive,WITHOUT_CLASSIFICATION,//  The user may have passed a list of files - comma separated 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getNClob(int)    */
Hive,WITHOUT_CLASSIFICATION,//  Heap is not full add the buffer to the heap and restore heap property up. 
Hive,WITHOUT_CLASSIFICATION,//  public String rid; // Specific Zemanta use 
Hive,WITHOUT_CLASSIFICATION,//  put the jks file in the current test path only for test purpose 
Hive,WITHOUT_CLASSIFICATION,/*  as found in LazySimpleSerDe's nullSequence  */
Hive,WITHOUT_CLASSIFICATION,//  if serializer is ThriftJDBCBinarySerDe then recordValue is null if the buffer is not full (the size of buffer   is kept track of in the SerDe) 
Hive,WITHOUT_CLASSIFICATION,//  Once we have read the VectorizedRowBatchBase from the file there are two kinds of cases   for which we might have to discard rows from the batch:   Case 1- when the row is created by a transaction that is not valid or   Case 2- when the row has been deleted.   We will go through the batch to discover rows which match any of the cases and specifically   remove them from the selected vector. Of course selectedInUse should also be set. 
Hive,WITHOUT_CLASSIFICATION,//  CREATE_TABLE - TRUNCATE - INSERT - The result is just one record. 
Hive,WITHOUT_CLASSIFICATION,//  Test CHAR literal to string column comparison 
Hive,WITHOUT_CLASSIFICATION,//  Is there a conflicting lock on the same object with a lower sequence   number 
Hive,WITHOUT_CLASSIFICATION,/*      * final -- final mixing of 3 32-bit values (abc) into c     *     * Pairs of (abc) values differing in only a few bits will usually     * produce values of c that look totally different.  This was tested for     * - pairs that differed by one bit by two bits in any combination     *   of top bits of (abc) or in any combination of bottom bits of     *   (abc).     *     * - "differ" is defined as + - ^ or ~^.  For + and - I transformed     *   the output delta to a Gray code (a^(a>>1)) so a string of 1's (as     *   is commonly produced by subtraction) look like a single 1-bit     *   difference.     *     * - the base values were pseudorandom all zero but one bit set or     *   all zero plus a counter that starts at zero.     *     * These constants passed:     *   14 11 25 16 4 14 24     *   12 14 25 16 4 14 24     * and these came close:     *    4  8 15 26 3 22 24     *   10  8 15 26 3 22 24     *   11  8 15 26 3 22 24     *     * #define final(abc) \     * {     *   c ^= b; c -= rot(b14); \     *   a ^= c; a -= rot(c11); \     *   b ^= a; b -= rot(a25); \     *   c ^= b; c -= rot(b16); \     *   a ^= c; a -= rot(c4);  \     *   b ^= a; b -= rot(a14); \     *   c ^= b; c -= rot(b24); \     * }     *      */
Hive,WITHOUT_CLASSIFICATION,//  Tracks total pending preemptions. 
Hive,WITHOUT_CLASSIFICATION,//  this one has the mixed-size chars 
Hive,WITHOUT_CLASSIFICATION,//  Update the table column stats for a table in cache 
Hive,WITHOUT_CLASSIFICATION,//  Write a header 
Hive,WITHOUT_CLASSIFICATION,// make sure to escape separator char in prop values 
Hive,WITHOUT_CLASSIFICATION,//  Checking for status of table 
Hive,WITHOUT_CLASSIFICATION,// 4)  test few field names 
Hive,WITHOUT_CLASSIFICATION,//  unique identity for this instance 
Hive,WITHOUT_CLASSIFICATION,//  If we're here proxy user is set. 
Hive,WITHOUT_CLASSIFICATION,//  recheck if it got verified by another thread while we were waiting 
Hive,WITHOUT_CLASSIFICATION,/*  Convert input row to standard objects.  */
Hive,WITHOUT_CLASSIFICATION,//  The rel which is being visited 
Hive,WITHOUT_CLASSIFICATION,//  Whatever 
Hive,WITHOUT_CLASSIFICATION,// check if the REST command specified explicitly to use hcatalog   or if it says that implicitly using the pig -useHCatalog arg 
Hive,WITHOUT_CLASSIFICATION,//  There was an error adding partitions : rollback fs copy and rethrow 
Hive,WITHOUT_CLASSIFICATION,//  basePlan.getCluster.getPlanner is the VolcanoPlanner from apply()   both planners need to use the correct executor 
Hive,WITHOUT_CLASSIFICATION,// newPath is the base/delta dir 
Hive,WITHOUT_CLASSIFICATION,//  Update the metadata for the materialized view 
Hive,WITHOUT_CLASSIFICATION,//  The partitioning columns of the parent RS are more specific than   those of the child RS. 
Hive,WITHOUT_CLASSIFICATION,/*  (non-Javadoc)   * @see org.apache.hive.service.cli.Operation#close()    */
Hive,WITHOUT_CLASSIFICATION,//  longer part of the HiveDecimal representation anymore to string then bytes. 
Hive,WITHOUT_CLASSIFICATION,//  e.g. -(17#).e-#### 
Hive,WITHOUT_CLASSIFICATION,//  pass through group key (+ indicators if present) 
Hive,WITHOUT_CLASSIFICATION,//  year   month   day   hour   minute   second 
Hive,WITHOUT_CLASSIFICATION,//  Periodic task to time out submitted tasks that have not been updated with umbilical heartbeat. 
Hive,WITHOUT_CLASSIFICATION,//  We found an old valid block for this key in the cache. 
Hive,WITHOUT_CLASSIFICATION,//  Continue reading from the input stream until the desired number of byte has been read 
Hive,WITHOUT_CLASSIFICATION,/*  * Test that the server code exists.  */
Hive,WITHOUT_CLASSIFICATION,//  MODIFIED_ROW_COUNT 
Hive,WITHOUT_CLASSIFICATION,//  This will also be invoked for tasks which have been KILLED / rejected by the daemon.   Informing the daemon becomes necessary once the LlapScheduler supports preemption   and/or starts attempting to kill tasks which may be running on a node. 
Hive,WITHOUT_CLASSIFICATION,//  Get base type since type string may be parameterized 
Hive,WITHOUT_CLASSIFICATION,/*      * Once enough rows have been output there is no need to generate more output.      */
Hive,WITHOUT_CLASSIFICATION,//  twice (returns not cleaned cache) 
Hive,WITHOUT_CLASSIFICATION,//  Add select expression 
Hive,WITHOUT_CLASSIFICATION,//  All accesses synchronized on the object itself. Could be replaced with CAS. 
Hive,WITHOUT_CLASSIFICATION,//  Using MiniDFS the permissions don't work properly because   the current user gets treated as a superuser.   For this test specify a different (0non-super) user.  
Hive,WITHOUT_CLASSIFICATION,//  Break out of the loop fast if watchMode is disabled. 
Hive,WITHOUT_CLASSIFICATION,//  Bail out on first missed column. 
Hive,WITHOUT_CLASSIFICATION,/*  stage is waiting for input/slots or complete  */
Hive,WITHOUT_CLASSIFICATION,//  remove the last " || " 
Hive,WITHOUT_CLASSIFICATION,// Block on semantic analysis to check 'active_calls' 
Hive,WITHOUT_CLASSIFICATION,//  create a Schema object containing the give column 
Hive,WITHOUT_CLASSIFICATION,//  The final match we intend to return 
Hive,WITHOUT_CLASSIFICATION,//  Limit to below milliseconds only... 
Hive,WITHOUT_CLASSIFICATION,//  A match is found   No match is found and the current row will be dropped   The current row has been spilled to disk as the join is postponed 
Hive,WITHOUT_CLASSIFICATION,//  construct unionObjectInspector without Map field. 
Hive,WITHOUT_CLASSIFICATION,//  Store the given version and comment in the metastore 
Hive,WITHOUT_CLASSIFICATION,//  Just an digits? 
Hive,WITHOUT_CLASSIFICATION,//  Convert seconds since the epoch (with fraction) to nanoseconds as a long integer. 
Hive,WITHOUT_CLASSIFICATION,//  can fail with NoSuchObjectException 
Hive,WITHOUT_CLASSIFICATION,//  The delta dirs should have been cleaned up. 
Hive,WITHOUT_CLASSIFICATION,//  Prepare data for the source table 
Hive,WITHOUT_CLASSIFICATION,// get the submap 
Hive,WITHOUT_CLASSIFICATION,//  SEQ_NUMBER 
Hive,WITHOUT_CLASSIFICATION,//  Now add any scratch columns needed for children operators. 
Hive,WITHOUT_CLASSIFICATION,// because it's using a DP write 
Hive,WITHOUT_CLASSIFICATION,//  restore the old out stream 
Hive,WITHOUT_CLASSIFICATION,//  initialize 2 ListColumnVector for keys and values 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.PreparedStatement#addBatch()    */
Hive,WITHOUT_CLASSIFICATION,//  request accepted   request rejected as wait queue is full   request accepted but evicted other low priority task 
Hive,WITHOUT_CLASSIFICATION,//  the tail of each task chain. 
Hive,WITHOUT_CLASSIFICATION,//  Can the join operator be converted to a bucket map-merge join operator ? 
Hive,WITHOUT_CLASSIFICATION,/*      * We don't measure data generation execution cost -- generate the big table into memory first.      */
Hive,WITHOUT_CLASSIFICATION,//  load the list of DP partitions and return the list of partition specs 
Hive,WITHOUT_CLASSIFICATION,//  Save results to the cache for future queries to use. 
Hive,WITHOUT_CLASSIFICATION,//  Use UpdateFragmentRequestProto.newBuilder() to construct. 
Hive,WITHOUT_CLASSIFICATION,//  drop messages for the dropped partitions 
Hive,WITHOUT_CLASSIFICATION,//  we link filesink that will write to the same final location 
Hive,WITHOUT_CLASSIFICATION,/*  * This class populates the following operator traits for the entire operator tree: * 1. Bucketing columns. * 2. Table * 3. Pruned partitions * * Bucketing columns refer to not to the bucketing columns from the table object but instead * to the dynamic 'bucketing' done by operators such as reduce sinks and group-bys. * All the operators have a translation from their input names to the output names corresponding * to the bucketing column. The colExprMap that is a part of every operator is used in this * transformation. * * The table object is used for the base-case in map-reduce when deciding to perform a bucket * map join. This object is used in the BucketMapJoinProc to find if number of files for the * table correspond to the number of buckets specified in the meta data. * * The pruned partition information has the same purpose as the table object at the moment. * * The traits of sorted-ness etc. can be populated as well for future optimizations to make use of.  */
Hive,WITHOUT_CLASSIFICATION,//  This makes sure we can use the same formula to compute the 
Hive,WITHOUT_CLASSIFICATION,//  This should be validated at change time; let's fall back to a default here. 
Hive,WITHOUT_CLASSIFICATION,//  If this is set all move tasks at the end of a multi-insert query will only begin once all 
Hive,WITHOUT_CLASSIFICATION,//  not able to push anything down 
Hive,WITHOUT_CLASSIFICATION,//  Test with table name which does not exists 
Hive,WITHOUT_CLASSIFICATION,// c belongs to target table; strictly speaking there maybe an ambiguous ref but  this will be caught later when multi-insert is parsed 
Hive,WITHOUT_CLASSIFICATION,//  do we need to prune the select operator? 
Hive,WITHOUT_CLASSIFICATION,//  For HDFS we could avoid serializing file ID and just replace the path with inode-based   path. However that breaks bunch of stuff because Hive later looks up things by split path. 
Hive,WITHOUT_CLASSIFICATION,//  Now we consolidate all the events that happenned during the objdump into the objdump 
Hive,WITHOUT_CLASSIFICATION,//  Not adding the registry as a service since we need to control when it is initialized - conf used to pickup properties. 
Hive,WITHOUT_CLASSIFICATION,//  Prepare the expression to filter on the columns. 
Hive,WITHOUT_CLASSIFICATION,//  No need to process here. 
Hive,WITHOUT_CLASSIFICATION,//  create new session ctx object with HS2 as client type 
Hive,WITHOUT_CLASSIFICATION,//  corVar offset should point to the leftInput of currentRel 
Hive,WITHOUT_CLASSIFICATION,//  Is reducer auto-parallelism unset (FIXED UNIFORM PARALLEL) 
Hive,WITHOUT_CLASSIFICATION,// null constant could be typed so we need to check the value 
Hive,WITHOUT_CLASSIFICATION,//  1. remove RS as parent for the big table branch 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise recurse. 
Hive,WITHOUT_CLASSIFICATION,//  End AggregateJoinTransposeRule.java 
Hive,WITHOUT_CLASSIFICATION,//  Release them at the same time. 
Hive,WITHOUT_CLASSIFICATION,//  2 hosts. 2 per host. 5 requests at the same priority.   First 3 on host1 Next at host2 Last with no host.   Third request on host1 should not be allocated immediately. 
Hive,WITHOUT_CLASSIFICATION,/*    * Tests if it returns the first file present in the lookup order when files are present in the   * lookup order    */
Hive,WITHOUT_CLASSIFICATION,//  are going to be small tables. 
Hive,WITHOUT_CLASSIFICATION,//  read result over SSL 
Hive,WITHOUT_CLASSIFICATION,//  Split the partition predicate to identify column and value 
Hive,WITHOUT_CLASSIFICATION,//  recursively go through expression and make sure the following: 
Hive,WITHOUT_CLASSIFICATION,// this exception indicates that a {@code record} could not be parsed and the  caller can decide whether to drop it or send it to dead letter queue.  rolling back the txn and retrying won'table help since the tuple will be exactly the same  when it's replayed. 
Hive,WITHOUT_CLASSIFICATION,//  The reader that currently has the lowest key. 
Hive,WITHOUT_CLASSIFICATION,//  v[9] -- since integer #5 is always 0 some products here are not included. 
Hive,WITHOUT_CLASSIFICATION,//  TODO: Verify that this works for systems using UGI.doAs() (e.g. Oozie). 
Hive,WITHOUT_CLASSIFICATION,//  we need to update event operators with the cloned table scan 
Hive,WITHOUT_CLASSIFICATION,//  we can "trick" the InputFormat into using a MockInstance 
Hive,WITHOUT_CLASSIFICATION,//  Otherwise we just removed a locked/invalid item from heap; we continue. 
Hive,WITHOUT_CLASSIFICATION,//  Ideally test like this should be a qfile test. However the explain output from qfile is always 
Hive,WITHOUT_CLASSIFICATION,//  Nothing changes - no cache. 
Hive,WITHOUT_CLASSIFICATION,//  Network cost of DPHJ 
Hive,WITHOUT_CLASSIFICATION,// cc ? -:U-(1/2)     D-(1/2)         cc ? U-(1/3):-             D-(2/2)       I-(1/1) - new part 2 
Hive,WITHOUT_CLASSIFICATION,//  The lock has a single components e.g. SimpleHiveLock or ZooKeeperHiveLock.   Pos 0 of lock paths array contains dbname pos 1 contains tblname 
Hive,WITHOUT_CLASSIFICATION,//  nothing to intern 
Hive,WITHOUT_CLASSIFICATION,//  We just check for writing permissions. If it fails with AccessControException then it   means the location may be read-only. 
Hive,WITHOUT_CLASSIFICATION,//  the parser should not allow this 
Hive,WITHOUT_CLASSIFICATION,//  First data dir contains 2 files. 
Hive,WITHOUT_CLASSIFICATION,//  Set some reasonable defaults 
Hive,WITHOUT_CLASSIFICATION,//  Since we are going to be creating a new table in a db we should mark that db as a write entity   so that the auth framework can go to work there. 
Hive,WITHOUT_CLASSIFICATION,//  remove it from the residual predicate 
Hive,WITHOUT_CLASSIFICATION,//  The max age of a task allowed 
Hive,WITHOUT_CLASSIFICATION,//  Build RelOptAbstractTable 
Hive,WITHOUT_CLASSIFICATION,//  signal new failure to map-reduce 
Hive,WITHOUT_CLASSIFICATION,//  for special modes. In that case SessionState.get() is empty. 
Hive,WITHOUT_CLASSIFICATION,// create new ugi and add to map 
Hive,WITHOUT_CLASSIFICATION,//  Set up job. 
Hive,WITHOUT_CLASSIFICATION,//  print out the vertex dependency in root stage 
Hive,WITHOUT_CLASSIFICATION,//     the join key) 
Hive,WITHOUT_CLASSIFICATION,// this is used in multiple places SemanticAnalyzer.getBucketingSortingDest() among others 
Hive,WITHOUT_CLASSIFICATION,//  Loop through the bits that are set to true and mark those rows as false if their 
Hive,WITHOUT_CLASSIFICATION,//  Use LazySimpleSerDe for MetadataTypedColumnsetSerDe.   NOTE: LazySimpleSerDe does not support tables with a single column of   col   of type "array<string>". This happens when the table is created using   an 
Hive,WITHOUT_CLASSIFICATION,//  NOTE: if "columns.types" is missing all columns will be of String type 
Hive,WITHOUT_CLASSIFICATION,//  new input inspector. 
Hive,WITHOUT_CLASSIFICATION,//  Template <ClassName> <ValueType> <IfDefined> 
Hive,WITHOUT_CLASSIFICATION,/*  user supplied data for that object  */
Hive,WITHOUT_CLASSIFICATION,//  Middle word gets integer rounding; lower longword is cleared. 
Hive,WITHOUT_CLASSIFICATION,//  job. 
Hive,WITHOUT_CLASSIFICATION,//  create another DynamicPartitionCtx which has a different input-to-DP column mapping 
Hive,WITHOUT_CLASSIFICATION,//  Also allow constraint creation only on t1 and t3. Foreign key creation on t2 fails. 
Hive,WITHOUT_CLASSIFICATION,//  clean history 
Hive,WITHOUT_CLASSIFICATION,/*  * Check each MapJoin and ShuffleJoin Operator to see they are performing a cross product. * If yes output a warning to the Session's console. * The Checks made are the following: * 1. MR Shuffle Join: * Check the parent ReduceSinkOp of the JoinOp. If its keys list is size = 0 then * this is a cross product. * The parent ReduceSinkOp is in the MapWork for the same Stage. * 2. MR MapJoin: * If the keys expr list on the mapJoin Desc is an empty list for any input * this implies a cross product. * 3. Tez Shuffle Join: * Check the parent ReduceSinkOp of the JoinOp. If its keys list is size = 0 then * this is a cross product. * The parent ReduceSinkOp checked is based on the ReduceWork.tagToInput map on the * reduceWork that contains the JoinOp. * 4. Tez Map Join: * If the keys expr list on the mapJoin Desc is an empty list for any input * this implies a cross product.  */
Hive,WITHOUT_CLASSIFICATION,//  is applied to the table. 
Hive,WITHOUT_CLASSIFICATION,//  table.column AS alias 
Hive,WITHOUT_CLASSIFICATION,//  Move unprocessed remainder to beginning of buffer. 
Hive,WITHOUT_CLASSIFICATION,/*    * (non-Javadoc)   *   * @see java.sql.CallableStatement#getURL(java.lang.String)    */
Hive,WITHOUT_CLASSIFICATION,//  Create too many partitions just enough to validate over limit requests 
Hive,WITHOUT_CLASSIFICATION,//  INSCRIPTIONAL YODH U+10B49 (4 bytes) 
Hive,WITHOUT_CLASSIFICATION,//  this may happen when enablebitvector is false 
Hive,WITHOUT_CLASSIFICATION,// if Importing into existing table FileFormat is checked by   ImportSemanticAnalzyer.checked checkTable() 
Hive,WITHOUT_CLASSIFICATION,//  If row mode will not catch this input file format then not enabled. 
Hive,WITHOUT_CLASSIFICATION,// no map aggregation. 
Hive,WITHOUT_CLASSIFICATION,//  send failover request to miniHS2_2 and make sure miniHS2_1 takes over (returning back to leader test listeners) 
Hive,WITHOUT_CLASSIFICATION,//  Test a query where timeout kicks in 
Hive,WITHOUT_CLASSIFICATION,//  Lookup of UDf class failed 
Hive,WITHOUT_CLASSIFICATION,//  Notify the master thread and the user. 
Hive,WITHOUT_CLASSIFICATION,//  Try to read the dropped db after cache update 
Hive,WITHOUT_CLASSIFICATION,/*        * Set or clear the rest of the reading variables based on {vector|row} deserialization.        */
Hive,WITHOUT_CLASSIFICATION,//  generics... this is how vectorization currently works. 
Hive,WITHOUT_CLASSIFICATION,//  Store the differing configuration for each alias in the job 
Hive,WITHOUT_CLASSIFICATION,//  error crosses threshold inside close() if we want to. 
Hive,WITHOUT_CLASSIFICATION,//  This is an unnecessary check and forced configuration in the property file. Maybe   replace with an enforced empty value string. 
Hive,WITHOUT_CLASSIFICATION,//  reverse the list since we checked the part from leaf dir to table's base dir 
Hive,WITHOUT_CLASSIFICATION,//  if user hasn't specify partition spec generate it from table's partition spec   do this only if it is INSERT/INSERT INTO/INSERT OVERWRITE/ANALYZE 
Hive,WITHOUT_CLASSIFICATION,//  see comment at "Dumping rows via SQL..." for why this doesn't work (for all types) 
Hive,WITHOUT_CLASSIFICATION,//  Copy without retry 
Hive,WITHOUT_CLASSIFICATION,//  Repeat and drop partition without purge. 
Hive,WITHOUT_CLASSIFICATION,//  Obsolete list should include the two original bucket files and the old base dir 
Hive,WITHOUT_CLASSIFICATION,//  Replace the edge manager for all vertices which have routing type custom. 
Hive,WITHOUT_CLASSIFICATION,//  Not included in the input collations but can be propagated as this Join   might enforce it 
Hive,WITHOUT_CLASSIFICATION,//  We will download into fn-scoped subdirectories to avoid name collisions (we assume there   are no collisions within the same fn). That doesn't mean we download for every fn. 
Hive,WITHOUT_CLASSIFICATION,//  Get all the 5 sessions; validate cluster fractions. 
Hive,WITHOUT_CLASSIFICATION,//  Mapping from task ID to the number of failures 
Hive,WITHOUT_CLASSIFICATION,//  default file system - which may or may not be online during pure metadata operations 
Hive,WITHOUT_CLASSIFICATION,//  deterministic to ease testing 
Hive,WITHOUT_CLASSIFICATION,//  If this UnionOperator is inside the reduce side of an MR job generated   by Correlation Optimizer which means all inputs of this UnionOperator are   from DemuxOperator. If so we should not touch this UnionOperator in genMapRedTasks. 
Hive,WITHOUT_CLASSIFICATION,//  ambiguous. 
